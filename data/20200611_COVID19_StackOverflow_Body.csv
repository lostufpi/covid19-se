Id,Body
61512747,"<p>I'm still currently trying to create a checklist with points as a reference if you are unsure you have COVID-19. ex. ""if you have 1 point then you are still fine""</p>

<p>Right now all checkboxes work except for one which is the second checkbox</p>

<pre><code>    Public Class Form1

    Dim pts As Byte
    Private Sub Button1_Click(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles Button1.Click
        Label1.Text = ""You have "" &amp; pts
    End Sub

    Private Sub CheckBox1_CheckedChanged(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles CheckBox1.CheckedChanged

        If Me.CheckBox1.Checked = True Then
            pts = pts + 1
        End If

    End Sub

    Private Sub CheckBox2_CheckedChanged(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles CheckBox2.CheckedChanged

        If Me.CheckBox2.Checked = True Then
            pts = pts + 1
        End If

    End Sub

    Private Sub CheckBox3_CheckedChanged(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles CheckBox3.CheckedChanged

        If Me.CheckBox1.Checked = True Then
            pts = pts + 98

        End If

    End Sub

    Private Sub btnReset_Click(ByVal sender As System.Object, ByVal e As System.EventArgs) Handles Button2.Click

        CheckBox1.CheckState = 0
        CheckBox2.CheckState = 0
        CheckBox3.CheckState = 0
        Label1.Text = """"
        pts = 0

    End Sub
 End Class
</code></pre>

<p>I don't know what else I can do really</p>
"
61101956,"<p>I am trying to get COVID-19 data with the API but I have a problem like this</p>

<p>Here is my code:</p>

<pre><code>var deserial = new JsonDeserializer();
            var client = new RestClient(""https://api.thevirustracker.com/free-api?countryTotals=ALL"");
            var request = new RestRequest(Method.GET);
            request.AddHeader(""content-type"", ""application/json"");
            var response = client.Execute(request);
            var output = deserial.Deserialize&lt;Dictionary&lt;string, string&gt;&gt;(response);
            var data = output[""countryitems""];
            var allData = JsonConvert.DeserializeObject&lt;List&lt;CountryItemViewModel&gt;&gt;(data);
</code></pre>

<p>My CountryItemViewModel :</p>

<pre><code>public class CountryItemModelView
{
    [JsonProperty(""ourid"")]
    public long Ourid { get; set; }

    [JsonProperty(""title"")]
    public string Title { get; set; }

    [JsonProperty(""code"")]
    public string Code { get; set; }

    [JsonProperty(""source"")]
    public Uri Source { get; set; }

    [JsonProperty(""total_cases"")]
    public long TotalCases { get; set; }

    [JsonProperty(""total_recovered"")]
    public long TotalRecovered { get; set; }

    [JsonProperty(""total_unresolved"")]
    public long TotalUnresolved { get; set; }

    [JsonProperty(""total_deaths"")]
    public long TotalDeaths { get; set; }

    [JsonProperty(""total_new_cases_today"")]
    public long TotalNewCasesToday { get; set; }

    [JsonProperty(""total_new_deaths_today"")]
    public long TotalNewDeathsToday { get; set; }

    [JsonProperty(""total_active_cases"")]
    public long TotalActiveCases { get; set; }

    [JsonProperty(""total_serious_cases"")]
    public long TotalSeriousCases { get; set; }
}
</code></pre>

<p>I can take the necessary part, but I can't bring the rest.</p>
"
69675,"<p>I'm trying to analyse if the fatality rate from my country (A third world country) vary significantly from the world's fatality rate.</p>

<p>So I'd basically have two samples, labeled (Philippines) and (World excluding the Philippines) then i can compute the fatality rate for the 2 groups.</p>

<p>Does Mcnemar's test apply here for me to check if fatality rate in the Philippines is higher, or do you have any suggestions? Thanks</p>
"
61428212,"<p>I have a COVID-19 reporting web app hosted on Heroku(<a href=""http://www.rajcovid19.info"" rel=""noreferrer"">http://www.rajcovid19.info</a>), the data for which I get from the John Hopkins University Git Repository. I have added the repository as a submodule of my main project repository which I use to push changes to Heroku. This enables me to pull updates to the COVID-19 repository on my computer and then push those changes to Heroku. However, I am not able to pull the latest commits to the COVID-19 submodule directly to the Heroku App. I tried using GitPython but it produces an ""Invalid Git Repository"" error whenever I try to pull changes. </p>

<p>My current working solution for this problem is to make a script on my laptop which periodically checks the COVID-19 repository for changes and then pushes them to the Heroku App.</p>

<p>This works but requires me to open my laptop at least once each day.</p>

<p>Is it possible to somehow make Heroku pull the latest commits to the submodule automatically?</p>

<p>EDIT:</p>

<p>According to Heroku, the service has an ""ephemeral storage"":
<a href=""https://i.stack.imgur.com/POYfY.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/POYfY.png"" alt=""Heroku Ephemeral Storage""></a></p>

<p>I think this might complicate things as well?</p>

<p>As for my GitPython code that didn't work, here it is:</p>

<p><a href=""https://i.stack.imgur.com/6cgit.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/6cgit.png"" alt=""GitPython 1""></a></p>

<p><a href=""https://i.stack.imgur.com/0eMVa.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/0eMVa.png"" alt=""GitPython 2""></a></p>

<p>That is:</p>

<pre class=""lang-py prettyprint-override""><code># Root directory for the COVID-19 Local repository root=os.getcwd()

if os. path.isdir(root+""/COVID-19""):
  root+=""/COVID-19""
  repo=Repo(root) git=repo.git git. pull
else:
  root+=""/COVID-19""
  os.system(""git clone https://github.com/CSSEGISandData/COVID-19.git"")
</code></pre>

<p>This works with my computer but this gives me an ""Invalid Git Repo"" error on the Heroku app. I did some debugging and made sure that the path of the repository was correct on the Heroku App but it just didn't seem to help.</p>
"
61561269,"<p><strong><em>PROBLEM</em></strong></p>

<p>There are N people on a street (numbered 1 through N). For simplicity, we'll view them as points on a line. For each valid i, the position of the i-th person is Xi.</p>

<p>It turns out that exactly one of these people is infected with the virus COVID-19, but we do not know which one. The virus will spread from an infected person to a non-infected person whenever the distance between them is at most 2. If we wait long enough, a specific set of people (depending on the person that was infected initially) will become infected; let's call the size of this set the final number of infected people.</p>

<p>Your task is to find the smallest and largest value of the final number of infected people, i.e. this number in the best and in the worst possible scenario.</p>

<p>Input The first line of the input contains a single integer T denoting the number of test cases. The description of T test cases follows. The first line of each test case contains a single integer N. The second line contains N space-seperated integers X1,X2,…,XN. Output For each test case, print a single line containing two space-separated integers ― the minimum and maximum possible final number of infected people.</p>

<p>Constraints 1≤T≤2,000 2≤N≤8 0≤Xi≤10 for each valid i X1</p>

<p>Example Input 3 2 3 6 3 1 3 5 5 1 2 5 6 7 Example Output 1 1 3 3 2 3 Explanation: Example case 1: The distance between the two people is 3, so the virus cannot spread and at the end, there will always be only one infected person.</p>

<p>Example case 2: The distance between each two adjacent people is 2, so all of them will eventually get infected.</p>

<p>Example case 3:</p>

<p>In one of the best possible scenarios, the person at the position 1 is infected initially and the virus will also infect the person at the position 2. In one of the worst possible scenarios, the person at the position 5 is infected initially and the virus will also infect the people at the positions 6 and 7.</p>

<p><strong><em>MY CODE</em></strong></p>

<pre><code>#include ""stdio.h""

int main()
{
    int t;
    scanf (""%d"",&amp;t);
    for (int k=0; k&lt;t; k++)
    {
        int n, i;
        scanf (""%d"",&amp;n);
        int x[n];
        for (i=0; i&lt;n; i++)
        {
            scanf (""%d"",&amp;x[i]);
        }
        int infected=x[0], c=0, a=1;
        int min=1, max=1;
        for (i=0; i&lt;n-1; i++)
        {
            if (c!=1)
            {
                if ((x[i+1]-infected)&lt;=2)
                {
                    min++;
                    infected = x[i+1];
                }
                else if ((x[i+1]-infected)&gt;2)
                {
                    infected = x[i+1];
                    c++;
                }
            }
            else
            {
                if ((x[i+1]-infected)&lt;=2)
                {
                    infected = x[i+1];
                    a++;
                }
            }
        }
        if (a&gt;min)
        max=a;
        else
        max=min;
        printf (""%d %d\n"",min,max);
    }
    return 0;
}
</code></pre>
"
61513039,"<p>I'm using cygwin 64 bit for gcc compiler.I'm trying something new with this code and my reading file(covid-19.csv) has about 12600 lines. After about 2250 lines cygwin returns,</p>

<pre><code>0 [main] myalgo 872 cygwin_exception::open_stackdumpfile: Dumping stack trace to myalgo.exe.stackdump
</code></pre>

<p>And <code>ulimit -s</code> gives only <strong>2032</strong>. Yes, I know this can be done easily with c functions but I wanted to try without using some functions.</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

int main(int argCount, char *argv[])
{
    char fileName[] = ""covid-19.csv"";
    int getFields(int, int, char*);
    char* heading; 
    char* subHeading;
    char charTaken;
    int count;
    int arg1 = 1;
    int arg2 = 1;
    char buildStr[25];
    int argument1Col = 0;
    int argument2Col = 0;

    if(argCount != 3)
    {
        printf(""invalid amount of arguments\n datalyze [arg1] [arg2]\ndateRep  day  month  year  cases  deaths  countriesAndTerritories  geoId  countryterritoryCode  popData2018  continentExp"");
        return(-1);
    }

    heading = argv[1];
    subHeading = argv[2];

    FILE *openFile = fopen(fileName, ""r"");
    if(openFile == NULL)
    {
        printf(""No file can be found %s."", fileName);
        return(-1);
    }

    while(1) 
    { 
        charTaken = fgetc(openFile); 
        if(charTaken == ',')
        {
            buildStr[count] = '\0';
            if(strcmp(buildStr, heading) == 0)
            {
                argument1Col = arg1;
            }

            if(strcmp(buildStr, subHeading) == 0)
            {
                argument2Col = arg2;
            }
            arg1++;
            arg2++;
            count = 0;
            continue;
        }
        if(charTaken == '\n')
        {
            break;
        }
        buildStr[count] = charTaken; 
        count++;
    } 
    fclose(openFile);

    if(argument1Col == 0 || argument2Col == 0)
    {
        printf(""Entered Fields are wrong.\n"");
        return(-1);
    }
    if(argument1Col &gt; argument2Col)
    {
        argument1Col = argument1Col + argument2Col;
        argument2Col = argument1Col - argument2Col;
        argument1Col = argument1Col - argument2Col;
    }
        getFields(argument1Col, argument2Col, fileName);

}

int getFields(int field1, int field2, char* fileName)
{
    char c;
    char buildWord[25];
    int count = 0;
    int commaCount = 0;
    FILE *openFile = fopen(fileName, ""r"");
    if(openFile == NULL)
    {
        printf(""No file can be found %s."", fileName);
        return(-1);
    }
    printf(""\n"");
    while(1)
    {
        c = fgetc(openFile);
        if(c == ',')
        {
            commaCount++;
            if(commaCount == field1)
            {
                buildWord[count] = '\0';
                printf(""%s     "", buildWord);
            }
            else if(commaCount == field2)
            {
                buildWord[count] = '\0';
                printf(""%s"", buildWord);
            }
            count = 0;
            continue;
        }
        if(c == '\n')
        {
            count = 0;
            commaCount = 0;
            printf(""\n"");
        } 
        if(c == EOF) break;
        buildWord[count] = c;
        count++;
    }
    fclose(openFile);
}
</code></pre>

<p>The covid-19 file looks like this.  </p>

<pre><code>dateRep,day,month,year,cases,deaths,countriesAndTerritories,geoId,countryterritoryCode,popData2018,continentExp
23/04/2020,23,4,2020,84,4,Afghanistan,AF,AFG,37172386,Asia
22/04/2020,22,4,2020,61,1,Afghanistan,AF,AFG,37172386,Asia
21/04/2020,21,4,2020,35,2,Afghanistan,AF,AFG,37172386,Asia
20/04/2020,20,4,2020,88,3,Afghanistan,AF,AFG,37172386,Asia
...
...
</code></pre>

<p>If there is any way to solve this error and read whole file please help.
Thank you.</p>
"
61661970,"<p>in <a href=""https://www.codechef.com/problems/COVIDLQ"" rel=""nofollow noreferrer"">https://www.codechef.com/problems/COVIDLQ</a> problem my test cases are giving me correct answer. But after submitting it says wrong answer(WA). Can anyone explain what is wrong in this code.</p>

<pre><code>#include&lt;stdlib.h&gt;

int main()
{
    int test_case,j,N,x=0,diff=0,yes;
    int *a;
    int *b;
    scanf(""%d"",&amp;test_case);
    while(test_case--&gt;0)
    {
        scanf(""%d"",&amp;N);
        a=(int*)malloc(N*sizeof(int));
        b=(int*)malloc(N*sizeof(int));
        for(j=0;j&lt;N;j++)
        scanf(""%d"",&amp;a[j]);

            for(j=0;j&lt;N;j++)
            {
                if(a[j]==1)
                {
                    b[x++]=j;
                }
            }
            for(j=0;j&lt;x-1;j++)
            {
                diff=b[j+1]-b[j];
                if(diff&gt;=6)
                yes=1;else yes=0;
            }


            if(yes==1 || x==1)
                printf(""YES\n"");
                else
                printf(""NO\n"");

    }
}
</code></pre>
"
60765858,"<p>I'm trying to drive the <a href=""https://www.analog.com/media/en/technical-documentation/data-sheets/1664fa.pdf"" rel=""nofollow noreferrer"">LTC1664 DAC</a> from an Arduino (<em>Mega 2560</em>). The SPI data and clock coming out of the Arduino is always synched (<em>rise and falls</em>) for all 4 modes when the DAC data sheet indicates phasing</p>

<p>I've tried all modes, the SS line on the chip is being brought low during the writes (<em>as it should</em>) and I've tried different speeds and <strong>shiftOut(), setClockDivider(), setDataMode(), beginTransaction()</strong> and <strong>endTransaction()</strong>.</p>

<p>Is this a bug in Arduino SPI, something specific to the Mega 2560, should I try an Uno or Due? <strong>Help please!</strong> Code below o-scope traces.</p>

<p>BTW: The 16 bit word I'm trying to transmit is, 0x3600 (<em>o-scope trace truncated</em>).</p>

<p><a href=""https://i.stack.imgur.com/JwgpE.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JwgpE.jpg"" alt=""&quot;MODE1&quot;""></a>
<a href=""https://i.stack.imgur.com/ZZXB8.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZZXB8.jpg"" alt=""&quot;MODE0&quot;""></a></p>

<pre><code>/*
  Test DAC Control

  created 18 Mar 2020 (Covid-19, oppsies)
  by Danny Holstein

*/


// inslude the SPI library:
#include &lt;SPI.h&gt;

void DAC(unsigned short value, unsigned char channel, int SS_Pin, int model);
enum models{LTC1664};
enum models model;

// set pin 10 as the slave select for the digital pot:
const int DAC_SS_Pin = 22;

void setup() {
  // set the DAC_SS_Pin as an output:
  // initialize SPI:
  Serial.begin(115200);
  SPI.begin();
  Serial.println(""SPI.begin"");
  pinMode(DAC_SS_Pin, OUTPUT);

}

void loop() {
  // go through the six channels of the digital pot:
    for (int channel = 1; channel &lt; 6; channel++) {
        delay(500);
        DAC(128*channel, channel, DAC_SS_Pin, LTC1664);
    }
    delay(1000);
 Serial.println(""new loop"");
}

/*
  DAC Control

  This function controls an LTC1664 Micropower Quad 10-Bit DAC.

 The LTC1664 is SPI-controlled,and to command it, you send one 16 bit word,
  A3 A2 A1 A0 D9 D8 D7 D6 D5 D4 D3 D2 D1 D0 X1 X0
  |  ADDR   |         INPUT CODE           | DON'T CARE

 The circuit:
  * CS - to digital pin 22  (SS pin)
  * SDI - to digital pin 51 (MOSI pin)
  * SDO - to digital pin 50 (MISO pin, not used in this function)
  * CLK - to digital pin 52 (SCK pin)

 created 18 Mar 2020 (Covid-19, oppsies)
 by Danny Holstein

*/

void DAC(unsigned short value, unsigned char channel, int SS_Pin, int model) {
  // take the SS pin low to select the chip:
    digitalWrite(SS_Pin, LOW); delay(100);
    unsigned short buf, b16;
    unsigned char *c, b; c = (unsigned char *) &amp;buf;
    switch (model)
    {
        case LTC1664:
            if (channel &gt; 4) channel = 0xF;
            buf = (channel &lt;&lt; 12) | ((value &amp; 0x3FF) &lt;&lt; 2);
            SPI.beginTransaction(SPISettings(1000000, MSBFIRST, SPI_MODE0));
            b16 = SPI.transfer16(buf);
            Serial.print(""0x"" + String(buf, HEX)); Serial.println(""\t0x"" + String(b16, HEX) + ""\t"");
            SPI.endTransaction();
            break;
        default:
            break;
    }   
    delay(100);
  // take the SS pin high to de-select the chip:
    digitalWrite(SS_Pin, HIGH);
    // printf(""value = 0x%04x"", buf);
}
</code></pre>
"
61033050,"<p>Hello I was trying to do this project and I was getting exit status 1 error</p>

<p>my code is: </p>

<pre><code>#include &lt;WiFi.h&gt;
#include &lt;WiFiClientSecure.h&gt;
#include ""ArduinoJson.h""
#include &lt;Wire.h&gt; 
#include &lt;LiquidCrystal_I2C.h&gt;





LiquidCrystal_I2C lcd(0x27,20,4);




WiFiClientSecure client;

unsigned long checkerStartTime = 300000;

void setup() {
  Serial.begin(115200);
  while (! Serial);
  lcd.begin();
  lcd.backlight();
  unsigned long wifiStart = millis();
  WiFi.begin(""NETGEAR75"", ""rusticelephant208"");
  while (WiFi.status() != WL_CONNECTED) {
    if (millis() - wifiStart &gt; 10000) 
  Serial.println(""Connected Wifi..."");
   }
}

void loop() {

  if (millis() - checkerStartTime &gt; 300000) {// 1hr timer
    checkerStartTime = millis();
    if (WiFi.status() != WL_CONNECTED)
    if (client.connect(""cdc.gov"", 443)) {
      Serial.println(""connected to cdc..."");

      String http = String(""GET https://www.cdc.gov/coronavirus/2019-ncov/map-cases-us.json HTTP/1.1\r\nHost: cdc.gov\r\nConnection: close\r\nAccept: Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\r\n\r\n"");
      client.print(http);
      Serial.println(""requesting..."");
      //let's wait for something to come back... only a few seconds
      unsigned long startTime = millis();
      while (millis() - startTime &lt; 5000) {
        if (client.available()) {
          Serial.println(""From Server"");
          break;
        }
      }
      delay(1000);
      String jsonData = client.readStringUntil('{');

      jsonData = ""{"";
      startTime = millis();
      while (millis() - startTime &lt; 1000) {
        if (client.available()) {
          jsonData.concat(char(client.read()));
          startTime = millis();
        }
      }
      client.stop();

      //https://arduinojson.org/v6/assistant/
      DynamicJsonDocument doc(20000);
      // Deserialize the JSON document
      deserializeJson(doc, jsonData);
      JsonObject obj = doc.as&lt;JsonObject&gt;();

      String cases = obj[""data""];

      for (int i = 0; i &lt; obj[""data""].size(); i++) {
        String names = obj[""data""][i][""Name""];
        //Serial.print(names);
        //Serial.print("" "");
        String cases = obj[""data""][i][""Cases Reported""];
        //Serial.println(cases);
        if (names == ""Florida"") {
          Serial.print(""Cases in Ohio = "");
          Serial.println(cases);


          lcd.setCursor(3, 0);
          lcd.println(""Covid 19 Status"");
          lcd.println("""");
          lcd.println("""");
          lcd.println(""Cases Reported in: "");
          lcd.print(""-&gt; "");
          lcd.println(names);
          lcd.print(""-&gt; "");
          lcd.print(cases);
         }
      }
    }
  }
}   
</code></pre>

<p>and the error code I get is</p>

<pre><code>Arduino: 1.8.9 (Windows Store 1.8.21.0) (Windows 10), Board: ""NodeMCU 1.0 (ESP-12E Module), 80 MHz, Flash, Legacy (new can return nullptr), All SSL ciphers (most compatible), 4MB (FS:2MB OTA:~1019KB), 2, v2 Lower Memory, Disabled, None, Only Sketch, 115200""

In file included from C:\Users\moghd\OneDrive\Documents\ArduinoData\packages\esp8266\hardware\esp8266\2.6.3\libraries\ESP8266WiFi\src/WiFiClientSecure.h:41:0,

                 from C:\Users\moghd\OneDrive\Desktop\arduino\sketch_apr04a\sketch_apr04a.ino:3:

C:\Users\moghd\OneDrive\Documents\ArduinoData\packages\esp8266\hardware\esp8266\2.6.3\libraries\ESP8266WiFi\src/WiFiClientSecureBearSSL.h:262:36: error: expected ')' before '*' token

     WiFiClientSecure(ClientContext *client, const X509List *chain, unsigned cert_issuer_key_type,

                                    ^

C:\Users\moghd\OneDrive\Documents\ArduinoData\packages\esp8266\hardware\esp8266\2.6.3\libraries\ESP8266WiFi\src/WiFiClientSecureBearSSL.h:264:35: error: expected ')' before '*' token

     WiFiClientSecure(ClientContext* client, const X509List *chain, const PrivateKey *sk,

                                   ^

C:\Users\moghd\OneDrive\Documents\ArduinoData\packages\esp8266\hardware\esp8266\2.6.3\libraries\ESP8266WiFi\src/WiFiClientSecureBearSSL.h:38:5: error: 'BearSSL::WiFiClientSecure::~WiFiClientSecure()' marked override, but does not override

     ~WiFiClientSecure() override;

     ^

C:\Users\moghd\OneDrive\Documents\ArduinoData\packages\esp8266\hardware\esp8266\2.6.3\libraries\ESP8266WiFi\src/WiFiClientSecureBearSSL.h:43:9: error: 'int BearSSL::WiFiClientSecure::connect(const String&amp;, uint16_t)' marked override, but does not override

     int connect(const String&amp; host, uint16_t port) override;

         ^

C:\Users\moghd\OneDrive\Documents\ArduinoData\packages\esp8266\hardware\esp8266\2.6.3\libraries\ESP8266WiFi\src/WiFiClientSecureBearSSL.h:48:12: error: 'size_t BearSSL::WiFiClientSecure::write_P(const char*, size_t)' marked override, but does not override

     size_t write_P(PGM_P buf, size_t size) override;

            ^

C:\Users\moghd\OneDrive\Documents\ArduinoData\packages\esp8266\hardware\esp8266\2.6.3\libraries\ESP8266WiFi\src/WiFiClientSecureBearSSL.h:60:12: error: 'size_t BearSSL::WiFiClientSecure::peekBytes(uint8_t*, size_t)' marked override, but does not override

     size_t peekBytes(uint8_t *buffer, size_t length) override;

            ^

C:\Users\moghd\OneDrive\Desktop\arduino\sketch_apr04a\sketch_apr04a.ino: In function 'void setup()':

C:\Users\moghd\OneDrive\Desktop\arduino\sketch_apr04a\sketch_apr04a.ino:27:46: warning: deprecated conversion from string constant to 'char*' [-Wwrite-strings]

   WiFi.begin(""NETGEAR76"", ""rusticelephant208"");

                                              ^

Multiple libraries were found for ""LiquidCrystal_I2C.h""
 Used: C:\Users\moghd\OneDrive\Documents\Arduino\libraries\LiquidCrystal_I2C-master
 Not used: C:\Users\moghd\OneDrive\Documents\Arduino\libraries\LiquidCrystal_I2C-1.1.2
exit status 1
Error compiling for board NodeMCU 1.0 (ESP-12E Module).

This report would have more information with
""Show verbose output during compilation""
option enabled in File -&gt; Preferences.
</code></pre>

<p>How do I fix this? I have tried restarting everything and nothing seems to work.
i am creating this code to pull json data and show it on a i2c lcd screen. 
ESP8266, 20 by 4 I2C LCD are the equipment used.</p>
"
61260999,"<p>I am trying to replicate this figure from the BBC. I'm close, but I'm struggling to make the legend symbols thin. Is this possible?</p>

<p><a href=""https://i.stack.imgur.com/XHsF2.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/XHsF2.png"" alt=""enter image description here""></a></p>

<pre><code>library(tidyverse)
library(""rio"")
url &lt;- ""https://gist.githubusercontent.com/ericpgreen/a728be304b811fe7708699682eb4ba42/raw/fd924596e30c131dbaf97c00c9d9863bb40abb9a/bbcCovid.R""
df_plot &lt;- rio::import(url)

ggplot(df_plot, aes(x=date, 
                    y=reorder(Country.Region, 
                              total, 
                              order=TRUE))) +
  geom_tile(aes(fill=casesRollf), 
            color=""white"", 
            na.rm = TRUE
            #, key_glyph = draw_key_timeseries
  ) +
  theme_bw() + theme_minimal() +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        legend.title = element_blank(),
        plot.title.position = ""plot"") +
  scale_x_date(breaks = as.Date(c(""2020-02-14"",
                                  ""2020-03-05"",
                                  ""2020-03-25"",
                                  ""2020-04-14"")),
               date_labels = ""%d %b"") +
  scale_fill_manual(values=
                      c(""#e4e4e4"", ""#ffeed2"", 
                        ""#ffda64"", ""#faab19"", 
                        ""#d2700d"",  
                        ""#d56666"", ""#9a1200"", 
                        ""#5b0600"", ""#000000""),
                    guide = guide_legend(reverse = TRUE),
                    labels=c(""No cases"", ""1 to 10"",
                             ""11 to 50"", ""51 to 100"",
                             ""101 to 250"", ""251 to 500"",
                             ""501 to 1,000"", ""1,001 to 5,000"",
                             ""&gt; 5,000"")) +
  labs(title = ""Where are the most new coronavirus cases?"",
       subtitle = ""New confirmed cases, three-day rolling average"",
       x="""",
       y="""")
</code></pre>

<p><a href=""https://i.stack.imgur.com/BdPIw.png"" rel=""noreferrer""><img src=""https://i.stack.imgur.com/BdPIw.png"" alt=""enter image description here""></a></p>
"
61011300,"<p>I have been trying to show some information to user on clicking button of my bot.</p>

<pre><code>var card = new HeroCard
{
    Title = ""Welcome to Covid-19 Tracker"",
    Text = ""Type 'help' to see what bot can do?"",
    Subtitle = ""Know more about Covid-19."",
    Buttons = new List&lt;CardAction&gt;
    { 
        new CardAction(ActionTypes.PostBack, ""How it spreads?"", value: ""spread""),
        new CardAction(ActionTypes.MessageBack, ""Symptoms"" , value: ""Symptom""),
        new CardAction(ActionTypes.MessageBack, ""Prevention Guidelines"" , value: ""Prevention"")
    },
};
</code></pre>

<p>When i am clicking on these button from emulator i am able to read the value to property but when i am deploying it to Teams, value is coming as {}.
I am retrieving value using below code.</p>

<pre><code>turnContext.Activity.Value.ToString()
</code></pre>
"
60641361,"<p>This is a problem I am having when I try to run a simple web scrapping code.</p>

<p>I will appreciate any help, even other (easy) methods to try to get the same result. </p>

<p>I get the error: The SSL/TLS connection could not be established.</p>

<p>It is from System.Net.Http.HttpRequestException.</p>

<p>Many Thanks, Again.</p>

<p>(The comments are some of the solutions mentioned on other threads and I have tried them with the same problem occurring).</p>

<pre><code>   class Program
        {
            static void Main(string[] args)
            {
            Console.WriteLine(""Hello World!"");

            var url = string.Format(""https://www.worldometers.info/coronavirus/"");

            getHtmlAsync(url);

            Console.Read();

        }

        private static async void getHtmlAsync(string url)
        {
         // ServicePointManager.ServerCertificateValidationCallback = delegate { return true; };
         //System.Net.ServicePointManager.SecurityProtocol = System.Net.SecurityProtocolType.Tls12;
           // ServicePointManager.Expect100Continue = true;
           // ServicePointManager.SecurityProtocol = (SecurityProtocolType)3072;
           // ServicePointManager.DefaultConnectionLimit = 9999;

        //    client.DefaultRequestHeaders.Add(""Accept-Encoding"", ""gzip, deflate"");
        //    client.DefaultRequestHeaders.Add(""Accept-Language"", ""en-US,en;q=0.5"");
        //    client.DefaultRequestHeaders.Add(""User-Agent"", ""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:58.0) Gecko/20100101 Firefox/58.0"");
         //   client.DefaultRequestHeaders.Add(""Accept"", ""text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"");

            Console.WriteLine(""I am here"");

            var client = new HttpClient();
            var html = await client.GetStringAsync(url);
            var htmlDocument = new HtmlAgilityPack.HtmlDocument();
            htmlDocument.LoadHtml(html);

       }
}
</code></pre>
"
61427540,"<p>I added a div to the user control. But when I am trying to access the div in page_load method in code behind, I am getting NullReferenceException.</p>

<pre><code>&lt;div id=""divCOVIDQuestion"" runat=""server""&gt;&lt;/div&gt;
</code></pre>

<p>and in page_load method</p>

<pre><code>divCOVIDQuestion.Visible = Client == ""FI"";
</code></pre>
"
61037876,"<p>The NY Times is maintaining a GitHub repository at <a href=""https://github.com/nytimes/covid-19-data"" rel=""nofollow noreferrer"">https://github.com/nytimes/covid-19-data</a>. This repository contains License, ReadMe, and two data files. The data files are us-states.csv and us-counties.csv. Both contain a time-series collection of the daily number of cases and deaths of COVID-19 by state or county.</p>

<p>I am trying to download the us-states.csv file. The program that I developed is:</p>

<pre><code>using System;
using System.Net;

namespace NYTimes_Console
    {

    // ************************************************* class Program

    class Program
        {

        // ****************************************************** Main

        static void Main ( string [ ] args )
            {
            byte [ ] bytes; 
            string   url = 
                        ""https://raw.githubusercontent.com/nytimes/"" + 
                        ""covid-19-data/blob/master/us-states.csv"";
            //string   url = 
            //            ""https://github.com/nytimes/"" + 
            //            ""covid-19-data/blob/master/us-states.csv"";


            try
                {
                using ( WebClient client = new WebClient ( ) )
                    {
                    client.Headers.Add(""user-agent"", ""Anything"");
                    bytes = client.DownloadData ( url );
                    }
                Console.WriteLine ( ""Download Successful"" );
                }
            catch ( Exception ex )
                {
                Console.WriteLine ( ""Download Failed\n{0}"",
                                    ex.Message.ToString ( ) );
                }
            Console.Write ( ""Enter to exit"");
            Console.ReadLine ( );
            }

        } // class Program

    } // namespace NYTimes_Console
</code></pre>

<p>When the url is ""<a href=""https://github.com/nytimes/covid-19-data/blob/master/us-states.csv"" rel=""nofollow noreferrer"">https://github.com/nytimes/covid-19-data/blob/master/us-states.csv</a>"", I receive the following:</p>

<pre><code>Download Failed
The underlying connection was closed: An unexpected error occurred on a send.
</code></pre>

<p>When I look into the exception, I find:</p>

<pre><code>InnerException = {""Received an unexpected EOF or 0 bytes from the transport stream.""}
</code></pre>

<p>When the url is ""<a href=""https://raw.githubusercontent.com/nytimes/covid-19-data/blob/master/us-states.csv"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/nytimes/covid-19-data/blob/master/us-states.csv</a>"", I receive the following:</p>

<pre><code>Download Failed
The remote server returned an error: (404) Not Found.
</code></pre>

<p>and the InnerException is null.</p>

<p>I appear to misunderstand the GitHub repositories and access to them.</p>
"
61558485,"<p>I am using google maps in my project. And I have a select field consisting of a country and it's counties. On changing the location with the select I zoom in to that location and draw a polygon on the map. It works fine when I am drawing a polygon for one location. 
But, if I select a country with, in this case 20 polygons that needs to be drawn and then zoom out from the map to be visible, the whole animation process becomes glitchy. I have tried to wrap the zooming into a Promise object and wait until it is finished and then center the map and draw polygons in hope it would help make it a smooth animation. Below I have the select onchange event, where depending on the value that was selected I zoom in or zoom out from the map and draw polygons. If the selected value was a county I zoom in to the map and draw polygon just for that county. If the country was selected I zoom out and draw polygons of all counties of that country:</p>

<pre><code>        let regions = geodata;
        let center = MAP_CENTER;
        let zoomLevel = 7;

        if (select.value !== country) {
            const location = geodata.find(({ Name }) =&gt; Name.includes(select.value));
            regions = [location];
            center = { lat: Number(location.Lat), lng: Number(location.Lng) };
            zoomLevel = 9;
        }

        smoothZoomPromise(map, zoomLevel, map.getZoom()).then((googleMap) =&gt; {
            googleMap.panTo(center);
            if (!(select.value === country &amp;&amp; polygons.state.arrayOfPolygons.length === geodata.length)) {
                drawRegions(googleMap, regions);
            }
        });
</code></pre>

<p>This is the <strong>smoothZoomPromise</strong> function:</p>

<pre><code>const smoothZoomPromise = (map, wantedLevel, startingLevel) =&gt; {
    return new Promise((resolve) =&gt; {
        if (wantedLevel === startingLevel) {
            return resolve(map);
        }
        const smoothZoom = (googleMap, finishLevel, startLevel) =&gt; {
            if (finishLevel === startLevel) {
                return;
            }
            const current = startLevel &gt; finishLevel ? startLevel - 1 : startLevel + 1;
            const z = google.maps.event.addListener(googleMap, 'zoom_changed', event =&gt; {
                google.maps.event.removeListener(z);
                smoothZoom(googleMap, finishLevel, current);
            })

            doZoom(googleMap, current, resolve, current === finishLevel);
        }

        smoothZoom(map, wantedLevel, startingLevel);
    });
}

const doZoom = (map, cnt, resolve, last) =&gt; {
    setTimeout(() =&gt; {
        map.setZoom(cnt);
        if(last) {resolve(map)}
    }, 80);
}
</code></pre>

<p>And this is how I draw polygons:</p>

<pre><code>export const polygons = {
    state: {
        arrayOfPolygons: []
    },
    clearState: function () {
        this.state.arrayOfPolygons.forEach(polygon =&gt; polygon.setMap(null));
        this.state.arrayOfPolygons = []
    }
};

export const drawRegions = (map, regions) =&gt; {
    polygons.clearState();
    regions.forEach(region =&gt; {
        const coords = region.Coordinates.map(item =&gt; ({
            lat: item[1], lng: item[0],
        }))

        // Construct the polygon.
        const color = colorMapper(getStatsData(region.Name));
        const polygon = new google.maps.Polygon({
            paths: coords,
            strokeColor: color,
            strokeOpacity: 0.8,
            strokeWeight: 2,
            fillColor: color,
            fillOpacity: 0.35
        });
        polygon.setMap(map);
        polygons.state.arrayOfPolygons.push(polygon)
    })
}
</code></pre>

<p>But, like I mentioned, the problem that I have is that when I select a country and zoom out from 9 to 7 zoom level, and draw 20 polygons for it, the zooming out of the map becomes glitchy. Is there a way I can make this smooth and fix it?</p>

<p>I made an example <a href=""https://codesandbox.io/s/gifted-leakey-35mh9?file=/src/index.js"" rel=""noreferrer"">codesanbox</a>. The only thing that is needed to have it working, is a valid <strong>API_KEY</strong> in <code>index.js</code>:</p>

<pre><code>if (document.querySelector("".js-map"")) {
  gmap.GMap("".js-map"", ""YOUR_API_KEY"");
}
</code></pre>

<p>I would like to achieve the same transition as it is done <a href=""https://news.google.com/covid19/map?hl=en-US&amp;gl=US&amp;ceid=US%3Aen&amp;mid=%2Fm%2F09c7w0"" rel=""noreferrer"">here</a> with google maps. Where if you zoom all the way in, and then change location with select, the map is not rendered until it is zoomed out. How can I achieve that effect?</p>
"
60583372,"<pre><code>jQuery.ajax({
    url: ""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"",
    type: 'get',
    dataType: 'json',
    success: function(data) {
        console.log(data);
    },
    error: function(jqXHR, textStatus, errorThrow){
        alert(""Error: "" + jqXHR['responseText']);
    }
});
</code></pre>

<p>I need the output as formatted json but It's going to error, basically trying to parse this</p>

<p><a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv</a></p>

<p><strong>UPDATE</strong></p>

<p>They've changed the link</p>

<p><a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv</a></p>
"
61309591,"<p>Hi I have an 8GB file which I need to do some analysis. However my RAM is not that great. To efficiently work, I decided to split my csv file based on rows with following code:</p>

<pre class=""lang-r prettyprint-override""><code>library(tidyverse)

sample_df &lt;- readr::read_csv(""sample.csv"") #Read in the csv file
dput(sample_df)

#break the large CSV so RAM and Rstudio doesn't crash

groups &lt;- (split(sample_df, (seq(nrow(sample_df))-1) %/% 20)) #here I want 20 rows per file until last row is reached

for (i in seq_along(groups)) {
  write.csv(groups[[i]], paste0(""sample_output_file"", i, "".csv"")) #iterate and write file
}
</code></pre>

<p>This worked perfectly until my senior mentor asked me to do analysis based on each date/days. I ran into a problem, because by splitting by rows, I ended up spreading the dates to multiple csvs. And this creates a problem of low RAM and memory management when I try to read 3-4 csvs to do analysis based on each day. </p>

<p>Sample file is here: <a href=""https://github.com/THsTestingGround/SO_splitbydate_question/blob/master/sample.csv"" rel=""nofollow noreferrer"">https://github.com/THsTestingGround/SO_splitbydate_question/blob/master/sample.csv</a></p>

<p>So could someone please assist me how do split following sample csv file which I read in initailly, based on date? I wanted all the Aprl1 together in one csv file, then Aprl2 into another and so on. I did made an attempt, but I couldn't succeed. </p>

<p>Also I was wondering if <code>readr::read_csv_chunked</code> can help us in any ways? From the documentation I couldn't see anything specific.</p>

<p>here is <code>dput</code> of the csv file:</p>

<pre class=""lang-r prettyprint-override""><code>dput(sample_df)
structure(list(createdAt = c(""Fri Apr 01 04:04:32 +0000 2020"", 
""Fri Apr 01 04:04:36 +0000 2020"", ""Fri Apr 01 04:04:37 +0000 2020"", 
""Fri Apr 02 04:04:40 +0000 2020"", ""Fri Apr 02 04:04:44 +0000 2020"", 
""Fri Apr 02 04:04:46 +0000 2020"", ""Fri Apr 02 04:04:54 +0000 2020"", 
""Fri Apr 02 04:04:56 +0000 2020"", ""Fri Apr 02 04:05:07 +0000 2020"", 
""Fri Apr 02 04:05:12 +0000 2020"", ""Fri Apr 03 04:05:12 +0000 2020"", 
""Fri Apr 03 04:05:19 +0000 2020"", ""Fri Apr 03 04:05:27 +0000 2020"", 
""Fri Apr 03 04:05:33 +0000 2020"", ""Fri Apr 03 04:05:36 +0000 2020"", 
""Fri Apr 03 04:06:11 +0000 2020"", ""Fri Apr 03 04:07:08 +0000 2020"", 
""Fri Apr 03 04:07:14 +0000 2020"", ""Fri Apr 03 04:07:15 +0000 2020"", 
""Fri Apr 03 04:07:20 +0000 2020"", ""Fri Apr 03 04:07:30 +0000 2020"", 
""Fri Apr 03 04:07:51 +0000 2020"", ""Fri Apr 03 04:08:04 +0000 2020"", 
""Fri Apr 03 04:08:09 +0000 2020"", ""Fri Apr 03 04:08:15 +0000 2020"", 
""Fri Apr 03 04:08:22 +0000 2020"", ""Fri Apr 03 04:08:36 +0000 2020"", 
""Fri Apr 03 04:08:46 +0000 2020"", ""Fri Apr 03 04:08:46 +0000 2020"", 
""Fri Apr 03 04:09:01 +0000 2020"", ""Fri Apr 03 04:09:08 +0000 2020"", 
""Fri Apr 03 04:09:10 +0000 2020"", ""Fri Apr 03 04:09:15 +0000 2020"", 
""Fri Apr 03 04:09:26 +0000 2020"", ""Fri Apr 03 04:09:27 +0000 2020"", 
""Fri Apr 03 04:09:28 +0000 2020"", ""Fri Apr 03 04:09:28 +0000 2020"", 
""Fri Apr 03 04:09:35 +0000 2020"", ""Fri Apr 03 04:09:36 +0000 2020"", 
""Fri Apr 03 04:09:41 +0000 2020"", ""Fri Apr 03 04:09:45 +0000 2020"", 
""Fri Apr 03 04:10:16 +0000 2020"", ""Fri Apr 03 04:10:19 +0000 2020"", 
""Fri Apr 03 04:10:22 +0000 2020"", ""Fri Apr 03 04:10:26 +0000 2020"", 
""Fri Apr 03 04:10:31 +0000 2020"", ""Fri Apr 03 04:10:48 +0000 2020"", 
""Fri Apr 04 04:11:19 +0000 2020"", ""Fri Apr 04 04:11:32 +0000 2020"", 
""Fri Apr 04:11:44 +0000 2020""), timestamp = c(1.58589e+12, 1.58589e+12, 
1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 
1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 
1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 
1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 
1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 
1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 
1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 
1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 
1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 1.58589e+12, 
1.58589e+12, 1.58589e+12, 1.58589e+12), id_str = c(1.24593e+18, 
1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 
1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 
1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 
1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 
1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 
1.24593e+18, 1.25e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 
1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 
1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 
1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18, 
1.24593e+18, 1.24593e+18, 1.24593e+18, 1.24593e+18), text = c(""Finally. Make your own mask. Protect yourself and others. #coronavirus"", 
""@ArvinderSoin do you feel the use of only masks for IPD rounds, in an environment where no patients have been teste…"", 
""India, you actually deserve him for electing him.\n\nAb batti bhujao aur #corona bhagav.\n\nNo testing kits, no masks,…"", 
""great picture to sum up everything\n#mask #maskefficiency #noclothmask #maskprotection #surgicalmask #N95 #FFP1…"", 
""The greatest hazard to public health is official misinformation.\n\nAsian countries were wearing masks from the begin…"", 
""#Florida official says @3M is selling face masks to foreign countries instead of his state amid #COVID19 crisis.\n"", 
""Wearing masks is one of the protective measures preventing catching the novel #Coronavirus as the pandemic spreads…"", 
""It took Americans two and a half months to start wearing masks. Think about why, maybe it could explain why the peo…"", 
""#coronavirus watching me put on the same surgical mask 2 shifts in a row\n\n#COVID&lt;U+30FC&gt;19 #nurse"", 
""Back in stock! NIOSH N95, go to our website.\nOnly 11,000 masks \n\n#facemask #facemasks #N95…"", 
""Hence the vital importance of wearing masks when outside - #coronavirus #coronavirusindia #COVID2019india…"", 
""@Read5000YrLeap @SenSchumer buy trump facemasks. support trump 2020 and be safe. ships from midwest. #Boycott3M… "", 
""When going out for essential activities, members of the public should wear reusable, non-medical cloth face coverin…"", 
""@jmcmaccarr buy trump facemasks. support trump 2020 and be safe. ships from midwest. #Boycott3M @seanhannity…"", 
""It took Americans two and a half months to start wearing masks. Think about why, maybe it could explain why the peo…"", 
""@CNN Just #WearMask People    wearing a mask Nationwide ... SAVES…"", 
""That is less than 4 million per week.  In Taiwan, everyone is allocated 3 surgical masks per week.  For Australia t…"", 
""@Constitution999 @ChuckCallesto @realDonaldTrump buy trump facemasks. support trump 2020 and be safe. ships from mi…"", 
""Regard the debate of face mask in general public, the evidence of effectiveness is quite clear #Covid19…"", 
""Normalize putting on of masks. #COVID19 came to change the world order."", 
""@TwitterSafety the Honduran gov’t is lying on Twitter. Saying that they are making thousands of masks, protective v…"", 
""Trump explaining that if you need a mask you can go to Walmart. Also that Costco has some great deals on caskets an…"", 
""When lockdown is over... I just may add this to my “don’t forget..” along with my wallet, gloves, mask, hand saniti…"", 
""Make your own mask: #covid19\n"", ""Please, everyone should wear a mask in public. Use whatever you can get hold of. Something is better than nothing (…"", 
""@kittywuv1 So incredibly mesmerizing, even with the custom #covid19 mask!&lt;U+0001F970&gt;&lt;U+0001F60D&gt;&lt;U+0001F618&gt;&lt;U+0001F637&gt;&lt;U+0001F497&gt;"", 
""@BeauTFC Happy to report that we’ve developed a 3-D printed mask. Passed N95 equivalent fit-test with Bitrex (surgi…"", 
""On a lighter note. \n\nIt is questionable if these common surgical masks and cloth masks will protect us from…"", 
""Medical workers face big mask shortage. This UF doctor came up with way to make many \n\n…"", 
""Homemade face coverings. Well, I tried it didn't come out straight but it should work. &lt;U+0001F637&gt; #homemade #facecoverings…"", 
""#covid19 In Africa, \""where are no masks, no treatment, no reanimation\"", \""the same way experimental treatment for AI…"", 
""@theblondeMD Happy to report that we’ve developed a 3-D printed mask. Passed N95 equivalent fit-test with Bitrex (s…"", 
""I wouldn’t do a thing anyone from #China says to do. The masks they keep sending around the world are faulty, they…"", 
""@TIME [covid19],important:\n1.from_air-&amp;gt;mask-&amp;gt;mask_reuse.\n2.from_touch-&amp;gt;clean_hands.\n\nps1.20200328.…"", 
""@3M stop selling masks to foreign companies. We WILL remember this!\n#COVID19Pandemic \n#covid19\n#N95masks"", 
""Awareness for using mask by @WHO #recommendations @CMOTamilNadu #COVID19 #Corona @MoHFW_INDIA #TNHealth #CVB…"", 
""@Rakshitwa @beingdumber @taapsee Nitish Kumar asked for 10 lakh N95 masks but got 50,000. Sought five lakh PPE kits…"", 
""@CNN You mean the masks everyone was saying #Covit19 #COVID&lt;U+30FC&gt;19 #coronavirus can pass right through as per what was…"", 
""2 BILLION masks = global production capacity in 2.5 MONTHS = quantity of what China imported in 5 WEEKS since Jan…"", 
""@CDCgov @CDCDirector @SF_DPH Please remember those with #COPD #LungDisease #HeartDisease when requiring #masks for…"", 
""If you have to go out and can’t avoid being around people, wear a mask.  Masks are a complement to social distancin…"", 
""@CTVVancouver According to Dr \""doom\"" Bonnie Henry, masks aren't of any use to the general public, in fact, she clai…"", 
""@maddow Next time you talk about the government stating everyone needs to wear a mask ask a government official whe…"", 
""Wear a mask in you are unwell or taking care of a person with suspected 2019-nCoV infection.\nInfo source: WHO…"", 
""7/9 For those who need a #COVID19 mask ASAP and have no talent, time or materials to make a mask. We give you the e…"", 
""jasminesade_art\nIs taking orders for masks (w/ filter pocket) \nMsg jasminesade_art if interested &lt;U+0001F496&gt; \n.\n.\n.\n.\n.\n."", 
""What China do to cut down the spread dramatically are only to make people stay at home and wear masks!!!!!@PHE_uk…"", 
""@CNN hey i thought we were boycotting China\nthen why the Americans need Chinese masks?\ngo fuck yourself \n#BoycottChina #coronavirus"", 
""@CNN @CillizzaCNN [covid19],important:\n1.from_air-&amp;gt;mask-&amp;gt;mask_reuse.\n2.from_touch-&amp;gt;clean_hands.\n\nps1.20200328.…"", 
""@kr3at #WearMask Everyone  !!!\n\n\nSimply  wearing a mask Nationwide ... SAVES #CZECHOSLOVAKIA…""
), retweetCount = c(1372, 9, NA, 8, 30, NA, NA, NA, NA, NA, 34, 
NA, NA, NA, NA, NA, 192, NA, NA, NA, 50, NA, 221, NA, NA, NA, 
NA, NA, NA, NA, NA, NA, 17, 1948, NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, 53, NA, 1948, NA), favorite_count = c(3488, 
23, NA, 7, 46, NA, NA, NA, NA, NA, 62, NA, NA, NA, NA, NA, 710, 
NA, NA, NA, 48, NA, 506, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
29, 4963, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 164, 
NA, 4963, NA), url = c(""twitter.com/33617860/status/1245925124483809280"", 
""twitter.com/1106803026/status/1245925141046935552"", ""twitter.com/421517829/status/1245925143479595008"", 
""twitter.com/1245594213795778560/status/1245925159724171264"", 
""twitter.com/2178012643/status/1245925173858975744"", ""twitter.com/1220529001241989120/status/1245925183010963456"", 
""twitter.com/1115874631/status/1245925217790124032"", ""twitter.com/1243781317747077120/status/1245925225327235072"", 
""twitter.com/2729830110/status/1245925273230438400"", ""twitter.com/1240114893178667008/status/1245925291374964736"", 
""twitter.com/88875512/status/1245925292972969984"", ""twitter.com/1245907384993812480/status/1245925320282136576"", 
""twitter.com/3431854829/status/1245925357116481536"", ""twitter.com/1245907384993812480/status/1245925380973871104"", 
""twitter.com/1243781317747077120/status/1245925393095217152"", 
""twitter.com/1230706447257751552/status/1245925541644992512"", 
""twitter.com/4437322348/status/1245925779117985792"", ""twitter.com/1245907384993812480/status/1245925802442555392"", 
""twitter.com/829633267942903808/status/1245925807211663360"", 
""twitter.com/403961389/status/1245925829755969536"", ""twitter.com/17183161/status/1245925869010292736"", 
""twitter.com/1408320152/status/1245925960550993920"", ""twitter.com/1245663286881902592/status/1245926011679600640"", 
""twitter.com/244306637/status/1245926036321103872"", ""twitter.com/24327965/status/1245926059318448128"", 
""twitter.com/1164222471639318528/status/1245926089068646400"", 
""twitter.com/16328861/status/1245926148967727104"", ""twitter.com/6125082/status/1.24592618943e+18"", 
""twitter.com/3685052935/status/1245926191850065920"", ""twitter.com/868528766355558400/status/1245926251455365120"", 
""twitter.com/1223273206636851200/status/1245926283093012480"", 
""twitter.com/16328861/status/1245926292274311168"", ""twitter.com/1160039103905390592/status/1245926310670565376"", 
""twitter.com/1236738668905127936/status/1245926356468162560"", 
""twitter.com/400431217/status/1245926363833532416"", ""twitter.com/1244269086088945664/status/1245926365116809216"", 
""twitter.com/850227053139853312/status/1245926366781902848"", 
""twitter.com/244314850/status/1245926393822605312"", ""twitter.com/1244446404178665472/status/1245926398578978816"", 
""twitter.com/3184694718/status/1245926421601509376"", ""twitter.com/82208845/status/1245926438143807488"", 
""twitter.com/1216588869530836992/status/1245926569303891968"", 
""twitter.com/4770303330/status/1245926579936432128"", ""twitter.com/1245580876047499264/status/1245926591806361600"", 
""twitter.com/904740870817120256/status/1245926610181574656"", 
""twitter.com/934146138/status/1245926629022433280"", ""twitter.com/1223547711468777472/status/1245926703257366528"", 
""twitter.com/840838036707393536/status/1245926832618131456"", 
""twitter.com/1236738668905127936/status/1245926888087773184"", 
""twitter.com/1230706447257751552/status/1245926935042994176""), 
    friendCount = c(1018, 326, 1205, 48, 3690, 1584, 55, 42, 
    580, 11, 3610, 13, 110, 13, 42, 382, 43, 13, 106, 4195, 599, 
    8, 89, 414, 280, 931, 5001, 1602, 1327, 227, 310, 5001, 26, 
    65, 2371, 31, 523, 228, 8, 671, 499, 1324, 333, 5, 852, 5457, 
    7, 48, 65, 382), screenNames = c(""DayssiOK"", ""DrAmbrishMithal"", 
    ""LuvAminaKausar"", ""Sunnie09370280"", ""balajis"", ""World_In_Mins"", 
    ""CGTNOfficial"", ""a7BdaSSeyL4czNw"", ""ShellBell915"", ""remedair"", 
    ""RitasArtCafe"", ""trumpfacemasks"", ""SCC_OES"", ""trumpfacemasks"", 
    ""a7BdaSSeyL4czNw"", ""REX38225222"", ""e2p71828"", ""trumpfacemasks"", 
    ""lamsonlinshen"", ""SteveJumaaa"", ""patfloTO"", ""tenforadollar"", 
    ""sashir_milne"", ""rdesai711"", ""agrothey"", ""foreskinjim1"", 
    ""rover223"", ""scanman"", ""AlDubest2Evry1"", ""HurtadoMarleen"", 
    ""johnmik63542947"", ""rover223"", ""CowlSolomon"", ""spacetinyearth"", 
    ""jmegown52302"", ""DrPonnarasu"", ""pankajupa120"", ""JoaoNewman"", 
    ""LalalaHK1"", ""SaturniaC"", ""NYCMediaMix"", ""ToscasReturn"", 
    ""JamesDallas9175"", ""cornzal"", ""CEDRdigital"", ""NadraRae"", 
    ""SiluMa4"", ""1Wa49R41L3pVzQj"", ""spacetinyearth"", ""REX38225222""
    ), userID = c(33617860, 1106803026, 421517829, 1.24559e+18, 
    2178012643, 1.22e+18, 1115874631, 1.24e+18, 2729830110, 1.24e+18, 
    88875512, 1.24591e+18, 3431854829, 1.24591e+18, 1.24e+18, 
    1.23071e+18, 4437322348, 1.24591e+18, 8.29633e+17, 403961389, 
    17183161, 1408320152, 1.24566e+18, 244306637, 24327965, 1.16422e+18, 
    16328861, 6125082, 3685052935, 8.68529e+17, 1.22327e+18, 
    16328861, 1.16004e+18, 1.24e+18, 400431217, 1.24427e+18, 
    8.50227e+17, 244314850, 1.24445e+18, 3184694718, 82208845, 
    1.22e+18, 4770303330, 1.24558e+18, 9.04741e+17, 934146138, 
    1.22355e+18, 8.40838e+17, 1.24e+18, 1.23071e+18), language = c(""en"", 
    ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", 
    ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", 
    ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", 
    ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", 
    ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en"", ""en""), replyToScreenName = c(""None"", 
    ""ArvinderSoin"", ""None"", ""None"", ""None"", ""World_In_Mins"", 
    ""None"", ""None"", ""None"", ""None"", ""None"", ""Read5000YrLeap"", 
    ""None"", ""jmcmaccarr"", ""None"", ""CNN"", ""None"", ""Constitution999"", 
    ""None"", ""None"", ""TwitterSafety"", ""None"", ""None"", ""None"", 
    ""None"", ""kittywuv1"", ""BeauTFC"", ""None"", ""None"", ""None"", ""None"", 
    ""theblondeMD"", ""None"", ""TIME"", ""3M"", ""None"", ""Rakshitwa"", 
    ""CNN"", ""None"", ""CDCgov"", ""None"", ""CTVVancouver"", ""maddow"", 
    ""None"", ""CEDRdigital"", ""None"", ""None"", ""CNN"", ""CNN"", ""kr3at""
    ), replyToID = c(""None"", ""1.13442E+18"", ""None"", ""None"", ""None"", 
    ""1.22053E+18"", ""None"", ""None"", ""None"", ""None"", ""None"", ""154243839"", 
    ""None"", ""48150879"", ""None"", ""759251"", ""None"", ""1.04747E+18"", 
    ""None"", ""None"", ""95731075"", ""None"", ""None"", ""None"", ""None"", 
    ""1.21653E+18"", ""1.05676E+18"", ""None"", ""None"", ""None"", ""None"", 
    ""230792524"", ""None"", ""14293310"", ""378197959"", ""None"", ""9.81585E+17"", 
    ""759251"", ""None"", ""146569971"", ""None"", ""16313405"", ""16129920"", 
    ""None"", ""9.04741E+17"", ""None"", ""None"", ""759251"", ""759251"", 
    ""139283160""), retweetUserScreenName = c(NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA
    ), retweetUserID = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), followersCount = c(1452, 
    3844, 2398, 1, 179896, 1283, 14036740, 24, 329, 3, 7133, 
    2, 1050, 2, 24, 121, 4, 2, 38, 2533, 235, 2, 5, 148, 2312, 
    265, 1572, 8067, 1265, 167, 13, 1574, 1, 2, 972, 1, 107, 
    7, 0, 73, 295, 1160, 849, 1, 7519, 1749, 0, 4, 2, 121), userMentions = c(NA, 
    ""ArvinderSoin"", NA, NA, NA, ""3M"", NA, NA, NA, NA, NA, ""Read5000YrLeap"", 
    NA, ""jmcmaccarr"", NA, ""CNN"", NA, ""Constitution999"", NA, NA, 
    ""TwitterSafety"", NA, NA, NA, NA, ""kittywuv1"", ""BeauTFC"", 
    NA, NA, NA, NA, ""theblondeMD"", NA, ""TIME"", ""3M"", ""WHO"", ""Rakshitwa"", 
    ""CNN"", NA, ""CDCgov"", NA, ""CTVVancouver"", ""maddow"", NA, NA, 
    NA, NA, ""CNN"", ""CNN"", ""kr3at""), userMentionsID = c(NA, 1.13442e+18, 
    NA, NA, NA, 378197959, NA, NA, NA, NA, NA, 154243839, NA, 
    48150879, NA, 759251, NA, 1.05e+18, NA, NA, 95731075, NA, 
    NA, NA, NA, 1.21653e+18, 1.05676e+18, NA, NA, NA, NA, 230792524, 
    NA, 14293310, 378197959, 14499829, 9.81585e+17, 759251, NA, 
    146569971, NA, 16313405, 16129920, NA, NA, NA, NA, 759251, 
    759251, 139283160), hashtag1 = c(""coronavirus"", NA, ""corona"", 
    ""mask"", NA, ""Florida"", ""Coronavirus"", NA, ""coronavirus"", 
    ""facemask"", ""coronavirus"", ""Boycott3M"", NA, ""Boycott3M"", 
    NA, ""WearMask"", NA, NA, ""Covid19"", ""COVID19"", NA, NA, NA, 
    ""covid19"", NA, ""covid19"", NA, NA, NA, ""homemade"", ""covid19"", 
    NA, ""China"", NA, ""COVID19Pandemic"", ""recommendations"", NA, 
    ""Covit19"", NA, ""COPD"", NA, NA, NA, NA, ""COVID19"", NA, NA, 
    ""BoycottChina"", NA, ""WearMask""), hashtag2 = c(NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA), mediatype = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), mediaURL = c(NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
    NA, NA, NA, NA)), class = c(""spec_tbl_df"", ""tbl_df"", ""tbl"", 
""data.frame""), row.names = c(NA, -50L), spec = structure(list(
    cols = list(createdAt = structure(list(), class = c(""collector_character"", 
    ""collector"")), timestamp = structure(list(), class = c(""collector_double"", 
    ""collector"")), id_str = structure(list(), class = c(""collector_double"", 
    ""collector"")), text = structure(list(), class = c(""collector_character"", 
    ""collector"")), retweetCount = structure(list(), class = c(""collector_double"", 
    ""collector"")), favorite_count = structure(list(), class = c(""collector_double"", 
    ""collector"")), url = structure(list(), class = c(""collector_character"", 
    ""collector"")), friendCount = structure(list(), class = c(""collector_double"", 
    ""collector"")), screenNames = structure(list(), class = c(""collector_character"", 
    ""collector"")), userID = structure(list(), class = c(""collector_double"", 
    ""collector"")), language = structure(list(), class = c(""collector_character"", 
    ""collector"")), replyToScreenName = structure(list(), class = c(""collector_character"", 
    ""collector"")), replyToID = structure(list(), class = c(""collector_character"", 
    ""collector"")), retweetUserScreenName = structure(list(), class = c(""collector_logical"", 
    ""collector"")), retweetUserID = structure(list(), class = c(""collector_logical"", 
    ""collector"")), followersCount = structure(list(), class = c(""collector_double"", 
    ""collector"")), userMentions = structure(list(), class = c(""collector_character"", 
    ""collector"")), userMentionsID = structure(list(), class = c(""collector_double"", 
    ""collector"")), hashtag1 = structure(list(), class = c(""collector_character"", 
    ""collector"")), hashtag2 = structure(list(), class = c(""collector_logical"", 
    ""collector"")), mediatype = structure(list(), class = c(""collector_logical"", 
    ""collector"")), mediaURL = structure(list(), class = c(""collector_logical"", 
    ""collector""))), default = structure(list(), class = c(""collector_guess"", 
    ""collector"")), skip = 1), class = ""col_spec""))
&gt; groups &lt;- (split(sample_df, (seq(nrow(sample_df))-1) %/% 20)) #here I want 20 rows per file until last row is reached
&gt; for (i in seq_along(groups)) {
+   write.csv(groups[[i]], paste0(""sample_output_file"", i, "".csv"")) #iterate and write file
+ }
</code></pre>
"
60967840,"<p>I need a little help to validate an xml file in c # ...
I have the following code:</p>

<pre><code>    private const string XSDFOLDER = ""XMLSchema/0.1"";

[...]

public bool validaXML(MemoryStream ms)
{
    XmlReader xmlReader = null;
    try {
        //define the settings while reading the XML file
        XmlReaderSettings settings = new XmlReaderSettings();
        settings.ValidationType = ValidationType.Schema;
        var localPath = Path.Combine(Server.MapPath("".""), XSDFOLDER);
        settings.Schemas.Add(""http://covid-19.iss.it/XMLSchema/0.1/"", Path.Combine(localPath, ""covid-19.xsd""));
        settings.ValidationFlags |= XmlSchemaValidationFlags.ProcessSchemaLocation;
        settings.ValidationFlags |= XmlSchemaValidationFlags.ReportValidationWarnings;
        settings.ValidationEventHandler += new ValidationEventHandler(this.ValidationEventHandle);

        //validate the file with the given settings
        xmlReader = XmlReader.Create(ms, settings);

        //iterate over the XML
        while (xmlReader.Read()) { }
        return true;
    } catch (Exception ex)
    {
        Debug.WriteLine(ex.Message);
        return false;
    }
    finally
    {
        if (xmlReader != null)
        {
            xmlReader.Close();
        }
    }
}
private void ValidationEventHandle(object sender, ValidationEventArgs args)
{
    //if were are here, it's becouse something is wrong with our XML
    Debug.WriteLine(""\r\n\tValidation error: "" + args.Message);
    //lbStatus.Text = ""Validation failed. message: "" + args.Message;

    if (args.Severity == XmlSeverityType.Warning)
        Debug.WriteLine(""\tWarning: Matching schema not found.  No validation occurred."" + args.Message);
    else
        Debug.WriteLine(""\tValidation error: "" + args.Message);

    //throw and exception
    throw new Exception((""Validation failed. message: "") + args.Message);
}
</code></pre>

<p>if in the xml file I have (with the space between the namespace and the xsd name in xsi: schemaLocation):</p>

<pre><code>&lt;covid-19 xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://covid-19.iss.it/XMLSchema/0.1/ covid-19.xsd"" xmlns=""http://covid-19.iss.it/XMLSchema/0.1/""&gt;
</code></pre>

<p>I get invalid xml with error:
Validation error: Cannot load the schema for the namespace '<a href=""http://covid-19.iss.it/XMLSchema/0.1/"" rel=""nofollow noreferrer"">http://covid-19.iss.it/XMLSchema/0.1/</a>' - Could not find file 'C:\Program Files (x86)\IIS Express\covid-19.xsd'.
Warning: Matching schema not found.  No validation occurred.Cannot load the schema for the namespace '<a href=""http://covid-19.iss.it/XMLSchema/0.1/"" rel=""nofollow noreferrer"">http://covid-19.iss.it/XMLSchema/0.1/</a>' - Could not find file 'C:\Program Files (x86)\IIS Express\covid-19.xsd'.</p>

<p>while if in the XML I have:</p>

<pre><code>&lt;covid-19 xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://covid-19.iss.it/XMLSchema/0.1/covid-19.xsd"" xmlns=""http://covid-19.iss.it/XMLSchema/0.1/""&gt;
</code></pre>

<p>or any string in xsi.schemaLocation, like:</p>

<pre><code>&lt;covid-19 xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://covid-19.iss.it/XMLSchema/0.1/aaaaaaaaaaa.xsd"" xmlns=""http://covid-19.iss.it/XMLSchema/0.1/""&gt;
</code></pre>

<p>validation is ok.</p>

<p>The xml of the first example is correct and valid in xmlspy</p>

<p>I also tried using </p>

<pre><code>settings.Schemas.Add(""http://covid-19.iss.it/XMLSchema/0.1/"", ""http://covid-19.iss.it/XMLSchema/0.1/covid-19.xsd"");
</code></pre>

<p>and changing the xml as this: (in xmlspy is still valid):</p>

<pre><code>&lt;covid-19 xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://covid-19.iss.it/XMLSchema/0.1/ http://covid-19.iss.it/XMLSchema/0.1/covid-19.xsd"" xmlns=""http://covid-19.iss.it/XMLSchema/0.1/""&gt;
</code></pre>

<p>but I get the error:
Exception thrown: 'System.Net.WebException' in System.dll
The underlying connection was closed: An unexpected error occurred on a send.</p>

<p>Could you please help me?
Thank you in advance.</p>
"
60793702,"<p>I am new to both .NET Core home somebody can guide me through this.</p>

<p>I need to make a request to this url and save the data into database:
url:
<a href=""https://covid19.mathdro.id/api"" rel=""nofollow noreferrer"">https://covid19.mathdro.id/api</a></p>

<p>JSON output looks like this:</p>

<pre><code>{""confirmed"":{""value"":303001,""detail"":""https://covid19.mathdro.id/api/confirmed""},""recovered"":{""value"":91669,""detail"":""https://covid19.mathdro.id/api/recovered""},""deaths"":{""value"":12762,""detail"":""https://covid19.mathdro.id/api/deaths""},""dailySummary"":""https://covid19.mathdro.id/api/daily"",""dailyTimeSeries"":{""pattern"":""https://covid19.mathdro.id/api/daily/[dateString]"",""example"":""https://covid19.mathdro.id/api/daily/2-14-2020""},""image"":""https://covid19.mathdro.id/api/og"",""source"":""https://github.com/mathdroid/covid19"",""countries"":""https://covid19.mathdro.id/api/countries"",""countryDetail"":{""pattern"":""https://covid19.mathdro.id/api/countries/[country]"",""example"":""https://covid19.mathdro.id/api/countries/USA""},""lastUpdate"":""2020-03-21T20:13:21.000Z""}
</code></pre>

<p>Model: Totals</p>

<pre><code>public class Total
{
    [Key]
    public int Id { get; set; }
    [Column(TypeName = ""int"")]
    [Required]
    public string Confirmed { get; set; }
    [Column(TypeName = ""int"")]
    [Required]
    public string Recovered { get; set; }
    [Column(TypeName = ""int"")]
    [Required]
    public string Deaths { get; set; }
    [Column(TypeName = ""datetime2"")]
    [Required]
    public string LastUpdated { get; set; }
}
</code></pre>

<p>My import model:</p>

<pre><code>client.BaseAddress = new Uri(""https://covid19.mathdro.id/api"");
var response = await client.GetAsync($"""");
response.EnsureSuccessStatusCode();
var stringResult = await response.Content.ReadAsStringAsync();
</code></pre>

<p>I am stuck from here and cant continue.
How do I fetch the data, I need only: confirmed, recovered, deaths and lastUpdate</p>

<p>Pls. anybody help here...</p>
"
61370635,"<p>Related question <a href=""https://stackoverflow.com/questions/28082302/signal-sigterm-handling-of-multi-thread-process-under-linux"">here</a> and <a href=""https://stackoverflow.com/q/6949025/841108"">here</a>.</p>

<p>In the Linux GPLv3+ project <a href=""https://github.com/bstarynk/helpcovid/"" rel=""nofollow noreferrer"">https://github.com/bstarynk/helpcovid/</a> (multi-threaded, C++17, web server application) commit <a href=""https://github.com/bstarynk/helpcovid/commit/b616defc5e54ba86980f4d90310c5e62f6b6188b"" rel=""nofollow noreferrer"">b616defc5e54ba869</a>. The need is to be able to terminate gracefully such a web server (interacting with some <a href=""https://postgresql.org/"" rel=""nofollow noreferrer"">PostGreSQL</a> database using <code>libpqxx</code>). So <a href=""https://github.com/bstarynk/helpcovid/issues/35"" rel=""nofollow noreferrer"">issue#35</a>.</p>

<p>I did read both <a href=""http://man7.org/linux/man-pages/man7/signal.7.html"" rel=""nofollow noreferrer"">signal(7)</a> and <a href=""http://man7.org/linux/man-pages/man7/signal-safety.7.html"" rel=""nofollow noreferrer"">signal-safety(7)</a> and <a href=""http://man7.org/linux/man-pages/man2/signalfd.2.html"" rel=""nofollow noreferrer"">signalfd(2)</a>. And I am aware of <a href=""https://ldpreload.com/blog/signalfd-is-useless"" rel=""nofollow noreferrer"">criticisms against signalfd</a>.</p>

<p>I have a single background C++ <code>std::thread</code>  <a href=""http://man7.org/linux/man-pages/man2/poll.2.html"" rel=""nofollow noreferrer"">poll(2)</a>-ing on several file descriptors. See file <a href=""https://github.com/bstarynk/helpcovid/blob/master/hcv_background.cc"" rel=""nofollow noreferrer""><code>hcv_background.cc</code></a> where the <code>hcv_start_background_thread</code>  function is called from <code>main</code> function  in file <a href=""https://github.com/bstarynk/helpcovid/blob/master/hcv_main.cc"" rel=""nofollow noreferrer""><code>hcv_main.cc</code></a> and the created <code>std::thread</code> runs the <code>hcv_background_thread_body</code> function (an event loop doing the <a href=""http://man7.org/linux/man-pages/man2/poll.2.html"" rel=""nofollow noreferrer"">poll(2)</a>....)</p>

<p>So <code>hcv_start_background_thread</code>  has:</p>

<pre><code>  {
    sigset_t  sigmaskbits;
    memset (&amp;sigmaskbits, 0, sizeof(sigmaskbits));
    sigemptyset(&amp;sigmaskbits);
    sigaddset(&amp;sigmaskbits, SIGTERM);
    sigaddset(&amp;sigmaskbits, SIGHUP);
    sigaddset(&amp;sigmaskbits, SIGXCPU);
    sigaddset(&amp;sigmaskbits, SIGPIPE);
    /// http://man7.org/linux/man-pages/man2/sigprocmask.2.html
    if (sigprocmask(SIG_UNBLOCK, &amp;sigmaskbits, nullptr))
      HCV_FATALOUT(""hcv_start_background_thread: sigprocmask failure"");
    HCV_DEBUGOUT(""hcv_start_background_thread sigprocmask done"");
    hcv_bg_signal_fd = signalfd(-1, &amp;sigmaskbits, SFD_NONBLOCK | SFD_CLOEXEC);
    if (hcv_bg_signal_fd &lt; 0)
      HCV_FATALOUT(""hcv_start_background_thread: signalfd failure"");
    HCV_DEBUGOUT(""hcv_start_background_thread hcv_bg_signal_fd="" &lt;&lt; hcv_bg_signal_fd);
  }
</code></pre>

<p>and the <code>hcv_background_thread_body</code> function has an  event loop doing</p>

<pre><code>  while (!hcv_should_stop_bg_thread.load())
    {
      struct pollfd polltab[4];
      memset(&amp;polltab, 0, sizeof(polltab));
      polltab[0].fd = hcv_bg_event_fd;
      polltab[0].events = POLL_IN;
      polltab[1].fd = hcv_bg_signal_fd;
      polltab[1].events = POLL_IN;
      polltab[1].fd = hcv_bg_timer_fd;
      polltab[1].events = POLL_IN;
      HCV_DEBUGOUT(""hcv_background_thread_body before poll"");
      int nbfd = poll(polltab, 3,
                      hcv_debugging.load()?(2*HCV_BACKGROUND_TICK_TIMEOUT):HCV_BACKGROUND_TICK_TIMEOUT);
</code></pre>

<p>and later in the same event loop</p>

<pre><code> if (nbfd&gt;0)   /* some file descriptor is readable */
        {
          HCV_DEBUGOUT(""hcv_background_thread_body: after poll nbfd:"" &lt;&lt; nbfd);
          if ((polltab[0].revents &amp; POLL_IN) &amp;&amp; polltab[0].fd == hcv_bg_event_fd)
            {
              int64_t evrk=0;

              HCV_DEBUGOUT(""hcv_background_thread_body pollable hcv_bg_event_fd=""
                           &lt;&lt; hcv_bg_event_fd);
              int byrd = read (hcv_bg_event_fd, &amp;evrk, sizeof(evrk));
              if (byrd==sizeof(evrk))
                {
                  HCV_DEBUGOUT(""hcv_background_thread_body: got "" &lt;&lt; evrk
                               &lt;&lt; "" from hcv_bg_event_fd="" &lt;&lt; hcv_bg_event_fd);
                  hcv_bg_do_event(evrk);
                }
              else
                HCV_SYSLOGOUT(LOG_WARNING,
                              ""hcv_background_thread_body read hcv_bg_event_fd#"" &lt;&lt;hcv_bg_event_fd &lt;&lt; "" failed, byrd="" &lt;&lt; byrd);
            };
          if ((polltab[1].revents &amp; POLL_IN) &amp;&amp; polltab[1].fd == hcv_bg_signal_fd)
            {
              HCV_DEBUGOUT(""hcv_background_thread_body pollable hcv_bg_signal_fd=""
                           &lt;&lt; hcv_bg_signal_fd);
              struct signalfd_siginfo signalinfo;
              memset (&amp;signalinfo, 0, sizeof(signalinfo));
              int byrd = read(hcv_bg_signal_fd, &amp;signalinfo, sizeof(signalinfo));
              if (byrd &lt; 0)
                HCV_FATALOUT(""hcv_background_thread_body: failed read of hcv_bg_signal_fd=""
                             &lt;&lt; hcv_bg_signal_fd);
              else if (byrd != sizeof(signalinfo))
                // should never happen... see signalfd(2)
                HCV_FATALOUT(""hcv_background_thread_body: corrupted read of hcv_bg_signal_fd=""
                             &lt;&lt; hcv_bg_signal_fd &lt;&lt; "", byrd="" &lt;&lt; byrd);
              HCV_DEBUGOUT(""hcv_background_thread_body: got signalinfo #"" &lt;&lt; signalinfo.ssi_signo
                           &lt;&lt; "" from hcv_bg_signal_fd="" &lt;&lt; hcv_bg_signal_fd);
              if (signalinfo.ssi_signo == SIGTERM)
                {
                  HCV_SYSLOGOUT(LOG_NOTICE, ""hcv_background_thread_body got SIGTERM at ""
                                &lt;&lt; (hcv_monotonic_real_time() - hcv_monotonic_start_time)
                                &lt;&lt; "" elapsed seconds"");
                  hcv_process_SIGTERM_signal();
                  hcv_should_stop_bg_thread.store (true);
                }
</code></pre>

<p>But <code>hcv_process_SIGTERM_signal</code>  never got called.</p>

<p>What am I doing wrong?</p>
"
61169609,"<p>This question has two parts, one more general and the other a specific case:</p>

<ol>
<li><p>Is there a theme or template in R for producing plots that have similar appearance to the charts published in ""The Economist"" magazine? Examples in other contexts include: <a href=""https://stackoverflow.com/questions/29859565/create-the-economist-style-graphs-from-python"">Create &quot;The Economist&quot; style graphs from python</a> for python and <code>set scheme economist</code> for Stata.</p></li>
<li><p>Specifically, what would be the syntax (e.g., in <code>ggplot2</code>) to produce a groups bar plot that would look like the example below, colored shaped markers with bold lines spanning the range between them (left panel), or rectangular confidence intervals (right panel)? </p></li>
</ol>

<p><a href=""https://i.stack.imgur.com/1rRof.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1rRof.png"" alt=""enter image description here""></a></p>

<p>Source: <a href=""https://www.economist.com/graphic-detail/2020/04/01/covid-19-may-be-far-more-prevalent-than-previously-thought"" rel=""nofollow noreferrer"">https://www.economist.com/graphic-detail/2020/04/01/covid-19-may-be-far-more-prevalent-than-previously-thought</a></p>
"
61005170,"<p>I am new to  angular and  trying to make an COVID-19 app in angular where I am showing data in tabular form. I have two components, a state component and district component.</p>

<p>State component is listing all state in table and when I click on any state. It should load all districts listed below that state. But it is expanding my width of my state column of state component which results in unexpected width of table. </p>

<p>Here is my stack blitz link: <a href=""https://stackblitz.com/github/mehulk05/COVOID-19"" rel=""nofollow noreferrer"">enter link description here</a></p>

<p>Here is my expected result link: <a href=""https://www.covid19india.org/"" rel=""nofollow noreferrer"">Expected result</a></p>

<p>Here is my piece of code</p>

<p><strong>State.component.html</strong></p>

<pre><code>&lt;table&gt;
    &lt;tbody *ngFor=""let data of statewisedata;let i=index ""&gt;
        &lt;span class=""dropdown rotateDownRight ""&gt;
            &lt;svg xmlns=""http://www.w3.org/2000/svg "" width=""24 "" height=""24 "" viewBox=""0 0 24 24 "" fill=""none "" stroke=""currentColor "" stroke-width=""2 "" stroke-linecap=""round "" stroke-linejoin=""round""&gt;
                &lt;polyline points=""6 9 12 15 18 9 ""&gt;&lt;/polyline&gt;
            &lt;/svg&gt;
        &lt;/span&gt;

        &lt;tr class=""state ""&gt;
            &lt;td (click)=""OngetState(data.state); showHideData(data) "" style=""font-weight: 600; ""&gt;{{data.state}}&lt;/td&gt;
            &lt;td style=""color: inherit; ""&gt;
                &lt;span *ngIf='DailystateStatus[i]?.confirmed !==0 || DailystateStatus[i]?.confirmed &lt; 0 ;' class=""deltas "" style=""color: rgb(255, 7, 58); ""&gt;
                    &lt;svg xmlns=""http://www.w3.org/2000/svg "" width=""24 "" height=""24 "" viewBox=""0 0 24 24"" fill=""none "" stroke=""currentColor "" stroke-width=""2 "" stroke-linecap=""round "" stroke-linejoin=""round ""&gt;
                        &lt;line x1=""12 "" y1=""19 "" x2=""12 "" y2=""5 ""&gt;&lt;/line&gt;
                        &lt;polyline points=""5 12 12 5 19 12 ""&gt;&lt;/polyline&gt;
                    &lt;/svg&gt;    
                    {{DailystateStatus[i]?.confirmed}}
                 &lt;/span&gt; 
                 {{data.confirmed}}
             &lt;/td&gt;

             &lt;td style=""color: inherit; ""&gt;{{data.active}}&lt;/td&gt;
             &lt;td style=""color: inherit; ""&gt;{{data.recovered}}&lt;/td&gt;
             &lt;td style=""color: inherit; ""&gt;{{data.deaths}}&lt;/td&gt;
         &lt;/tr&gt;

         &lt;tr app-district *ngIf=""data[ 'show'] ""&gt;&lt;/tr&gt;   //here loading list 
    &lt;/tbody&gt;
&lt;/table&gt;
</code></pre>

<p><strong>District.component.html</strong></p>

<pre><code>&lt;tr *ngFor=""let data of districtdata|keyvalue"" class=""district"" style=""background: rgb(248, 249, 250);""&gt;

    &lt;td style=""font-weight: 600;""&gt; {{data.key}}&lt;/td&gt;
    &lt;td&gt;&lt;span class=""deltas"" style=""color: rgb(255, 7, 58);""&gt;&lt;/span&gt;{{data.value.confirmed}}&lt;/td&gt;

&lt;/tr&gt;
</code></pre>

<p><strong>District.component.ts</strong></p>

<pre><code>
@Component({
  selector: '[app-district]',
  templateUrl: './district.component.html',
  styleUrls: ['./district.component.css']
})
</code></pre>

<p>If I try to wrap my  district component in div instead of tr and If I try to increase width of that div it increase width of my state column in state component</p>

<pre><code>&lt;div *ngFor=""let data of districtdata|keyvalue"" class=""district"" style=""width:500px""&gt;

    &lt;td style=""font-weight: 600;""&gt; {{data.key}}&lt;/td&gt;
    &lt;td&gt;&lt;span class=""deltas"" style=""color: rgb(255, 7, 58);""&gt;&lt;/span&gt;{{data.value.confirmed}}&lt;/td&gt;

&lt;/div&gt;
</code></pre>
"
60919160,"<p>I am able to fetch the data but it is incomplete.</p>

<p>CSV URL : <a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv</a></p>

<p>The library that I am using to fetch the data is <code>csv_reader</code>, <a href=""https://pub.dev/packages/csv_reader"" rel=""nofollow noreferrer"">https://pub.dev/packages/csv_reader</a></p>

<p>code snippet :</p>

<pre><code>Future&lt;List&lt;DataRow&gt;&gt; fetchRows() async {

    var myCSV = CSV.from(
    url: 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',
      delimiter: "","",
      title: false);

    await myCSV.initFinished; 

    print(myCSV.shape); //prints 28x71

    return [];
}
</code></pre>

<p>The URL has 274 rows but the above snippet is printing 28.</p>

<p>How can I fetch all 274 rows?</p>
"
60818246,"<p>The ""data"" value in setstate of else part in ""filterSearchResults"" is getting empty value. The data value is what I am passing from the previous page.</p>

<p>I am getting an empty value in variable data as setstate of else part in ""filterSearchResults"" function.</p>

<pre><code>import 'package:flutter/material.dart';

class Country extends StatefulWidget {
  final List data;

  Country(this.data);

  @override
  _CountryState createState() =&gt; _CountryState(this.data);
}

class _CountryState extends State&lt;Country&gt; {
  TextEditingController editingController = TextEditingController();
  List data;
  _CountryState(this.data);

  List data1;

//  search function

  void filterSearchResults(String query) {
    List&lt;dynamic&gt; dummySearchList = List&lt;dynamic&gt;();

    List&lt;dynamic&gt; dummyList = List&lt;dynamic&gt;();
    dummySearchList.addAll(data1);
    print(""dummy sreach List : $dummySearchList"");

    if (query.isNotEmpty) {
      for (var i = 0; i &lt; data1.length; i++) {
        var keys = data1[i].keys.toList();

        var val = data1[i][keys[0]];

        print(""val is: ${val.toLowerCase()}"");

        if (val.toLowerCase().contains((query.toLowerCase()))) {
          dummyList.add(data1[i]);

          print(""dummy list is : $dummyList"");
        }
      }
      setState(() {
        print(""if set"");
        data1.clear();
        data1 = dummyList;
        print(""data1 : $data1"");
      });

      return;
    } else {
      print(""else started"");
      setState(() {
        data1.clear();
        print(""CLEAR DATA : $data1"");
        print('original data: $data'); 
        data1 = data;                     //this is where the problem is.. 
        print('else data1: $data1');
        print(""else ended"");
      });
    }
  }

  void setData1() {
    setState(() {
      this.data1 = data;
      print(""set data : $data"");
    });
  }

  @override
  void initState() {
    super.initState();
    setData1();
    print(""init state started"");
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: Text(""Covid 19""),
      ),
      body: Container(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: &lt;Widget&gt;[
            TextField(
              controller: editingController,
              decoration: InputDecoration(
                  labelText: ""Search"",
                  hintText: ""Search"",
                  prefixIcon: Icon(Icons.search),
                  border: OutlineInputBorder(
                      borderRadius: BorderRadius.all(Radius.circular(25.0)))),
              onChanged: (value) {
                filterSearchResults(value);
              },
            ),
            Expanded(
              child: ListView.builder(
                itemCount: data1.length,
                shrinkWrap: true,
                itemBuilder: (context, index) {
                  Padding(padding: EdgeInsets.fromLTRB(8, 5, 8, 5));
                  return Card(
                    elevation: 5,
                    child: Container(
                      height: 200,
                      width: MediaQuery.of(context).size.width,
                      child: Column(
                        mainAxisAlignment: MainAxisAlignment.start,
                        children: &lt;Widget&gt;[
                          Padding(
                            padding: EdgeInsets.only(top: 10),
                          ),
                          Text(
                            data1[index]['country'],
                            style: TextStyle(fontSize: 30, color: Colors.black),
                          ),
                          Padding(
                            padding: EdgeInsets.only(top: 20),
                          ),
                          Row(
                            children: &lt;Widget&gt;[
                              Expanded(
                                child: Column(
                                  mainAxisAlignment: MainAxisAlignment.start,
                                  children: &lt;Widget&gt;[
                                    Text(
                                      ""Cases"",
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Text(
                                      data1[index][""cases""].toString(),
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Padding(
                                      padding: EdgeInsets.only(top: 25),
                                    ),
                                    Text(
                                      ""TodayCases"",
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Text(
                                      data1[index][""todayCases""].toString(),
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                  ],
                                ),
                              ),
                              Expanded(
                                child: Column(
                                  mainAxisAlignment: MainAxisAlignment.start,
                                  children: &lt;Widget&gt;[
                                    Text(
                                      ""Deaths"",
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Text(
                                      data1[index][""deaths""].toString(),
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Padding(
                                      padding: EdgeInsets.only(top: 25),
                                    ),
                                    Text(
                                      ""TodayDeaths"",
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Text(
                                      data1[index][""todayDeaths""].toString(),
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                  ],
                                ),
                              ),
                              Expanded(
                                child: Column(
                                  mainAxisAlignment: MainAxisAlignment.start,
                                  children: &lt;Widget&gt;[
                                    Text(
                                      ""Active"",
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Text(
                                      data1[index][""active""].toString(),
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Padding(
                                      padding: EdgeInsets.only(top: 25),
                                    ),
                                    Text(
                                      ""Recovered"",
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Text(
                                      data1[index][""recovered""].toString(),
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                  ],
                                ),
                              ),
                              Expanded(
                                child: Column(
                                  mainAxisAlignment: MainAxisAlignment.start,
                                  children: &lt;Widget&gt;[
                                    Text(
                                      ""Critical"",
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Text(
                                      data1[index][""critical""].toString(),
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Padding(
                                      padding: EdgeInsets.only(top: 25),
                                    ),
                                    Text(
                                      ""PerOneMillion"",
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                    Text(
                                      data1[index][""casesPerOneMillion""]
                                          .toString(),
                                      style: TextStyle(
                                          fontSize: 15, color: Colors.black),
                                    ),
                                  ],
                                ),
                              ),
                            ],
                          ),
                        ],
                      ),
                    ),
                  );
                },
              ),
            ),
          ],
        ),
      ),
    );
  }
}
</code></pre>
"
60820920,"<p>'variable' is final and was given a value when it was declared,so it can't be set to a new value.Try removing one of the initializations.
This is the error that keep giving.How can I remove the error?I need it for a http post request.</p>

<pre><code>  Future&lt;User&gt; fetchUser() async {
  final response =
  await http.get('https://coronavirus-med.herokuapp.com/api/v1/auth/register');

  if (response.statusCode == 200) {
    // If the server did return a 200 OK response,
    // then parse the JSON.
    return User.fromJson(json.decode(response.body));
  } else {
    // If the server did not return a 200 OK response,
    // then throw an exception.
    throw Exception('Failed to load request');
  }
}

  class User{
  final String name = ' ';
  final String email = ' ';
  final String password = ' ';
  final String passwordConfirm = ' ';
  final String role = ' ';

  User({this.name, this.email, this.password, this.passwordConfirm, this.role});

  factory User.fromJson(Map&lt;String, dynamic&gt; json){
    return User(
      name: json['name'],
      email: json['email'],
      password: json['password'],
      passwordConfirm: json['passwordConfirm'],
      role: json['role'],
    );
  }
}
</code></pre>
"
60963842,"<p>I am trying to change a String variable to a int via the int.parse function but I kept getting the error =>
'[VERBOSE-2:ui_dart_state.cc(157)] Unhandled Exception: FormatException: Invalid radix-36 number (at character 1)
83059‬
^'</p>

<p>I tried int.tryParse but not all data will be shown.</p>

<pre><code>  void getData() async {
    String jsonURL =
        'https://interactive-static.scmp.com/sheet/wuhan/viruscases.json?fbclid=IwAR2x0mm3kcJJElCMDWr18Lvjyoh6B1XLamvX1Hecf_7Tw7XO7Oy5OG3wBFM';

    var client = Client();
    Response response2 = await client.get(jsonURL);
    var decodedData = json.decode(utf8.decode(response2.bodyBytes));

    totalNumber = decodedData['entries'].length;
    lastUpdated = decodedData['last_updated'].substring(0, 10);

    for (var i = 0; i &lt; decodedData['entries'].length; i++) {
      String tempString = decodedData['entries'][i]['cases'];
      String tempDeath = decodedData['entries'][i]['deaths'];

      //To remove the commas so I can parse it to int variable
      tempDeath = tempDeath.replaceAll(',', '');
      tempString = tempString.replaceAll(',', '');

//
      //Adding to a List&lt;CovidData&gt;
      listOfData.add(
        CovidData(
            country: decodedData['entries'][i]['country'],
            cases: tempString,
            recovered: decodedData['entries'][i]['recovered'],
            death: tempDeath),
      );
    }
    //Sorting via int
    listOfData.sort((b, a) =&gt; int.parse(a.cases).compareTo(int.parse(b.cases)));
    setState(() {});
    unTouchedData = listOfData;
  }
</code></pre>
"
61354382,"<p>I am tying retrieve data from an api on Rapid Api using Dart's http package and displaying it using Flutter however the content never loads and the api doesn't return an error.</p>

<pre class=""lang-dart prettyprint-override""><code>class APIService {
  // API key
  static const _api_key = &lt;MYAPIKEY&gt;;
  // Base API url
  static const String _baseUrl = ""covid-19-data.p.rapidapi.com"";
  // Base headers for Response url
  static const Map&lt;String, String&gt; _headers = {
    ""content-type"": ""application/json"",
    ""x-rapidapi-host"": ""covid-19-data.p.rapidapi.com"",
    ""x-rapidapi-key"": _api_key,
  };

  Future&lt;CovidNumbers&gt; fetchData(
      {@required String endpoint, @required Map&lt;String, String&gt; query}) async {
    Uri uri = Uri.https(_baseUrl, endpoint, query);

    final response = await http.get(uri, headers: _headers);
    if (response.statusCode == 200) {
      return CovidNumbers.fromJson(json.decode(response.body));
    } else {
      throw Exception('Failed to load Data');
    }
  }
}
</code></pre>

<p>The method is then called onInit</p>

<pre class=""lang-dart prettyprint-override""><code>  Future&lt;CovidNumbers&gt; data;
  APIService apiService = APIService();

  @override
  void initState() {
    super.initState();
    data = apiService.fetchData(
        endpoint: ""/country"", query: {""format"": ""json"", ""name"": ""malta""});
  }
</code></pre>

<p>And finally I display it in a FutureBuilder</p>

<pre class=""lang-dart prettyprint-override""><code>FutureBuilder&lt;CovidNumbers&gt;(
          //future: futureCovidNumbers,
          builder: (context, snapshot) {
            if (snapshot.hasData) {
              return Text(
                  ""Confirmed Cases: ${snapshot.data.confirmed.toString()}"");
            } else if (snapshot.hasError) {
              return Text(""${snapshot.error}"");
            }

            return CircularProgressIndicator();
          },
        ));
</code></pre>

<p>The app remains stuck on the CircularProgressIndicator and does not display an error.</p>
"
61080366,"<p>i have a problem with my dart code. I'm trying to fetch some data from an API, it returns a JSON array. I created a model which parses my JSON. After that I try to pass to my function the data I fetched, but this error shows up: ""A value of type 'List can't be returned from function 'fetchCountries' because it has a return type of 'Future'"".</p>

<p>Does anyone have a clue?</p>

<h2>Country model</h2>

<pre class=""lang-dart prettyprint-override""><code>import 'dart:convert';

List&lt;Country&gt; countryFromJson(String str) =&gt; List&lt;Country&gt;.from(json.decode(str).map((x) =&gt; Country.fromJson(x)));

class Country {
    String country;
    int cases;
    int todayCases;
    int deaths;
    int todayDeaths;
    int recovered;
    int active;
    int critical;
    int casesPerOneMillion;
    int deathsPerOneMillion;
    int totalTests;
    int testsPerOneMillion;

    Country({
        this.country,
        this.cases,
        this.todayCases,
        this.deaths,
        this.todayDeaths,
        this.recovered,
        this.active,
        this.critical,
        this.casesPerOneMillion,
        this.deathsPerOneMillion,
        this.totalTests,
        this.testsPerOneMillion,
    });

    factory Country.fromJson(Map&lt;String, dynamic&gt; json) =&gt; Country(
        country: json[""country""],
        cases: json[""cases""],
        todayCases: json[""todayCases""],
        deaths: json[""deaths""],
        todayDeaths: json[""todayDeaths""],
        recovered: json[""recovered""],
        active: json[""active""],
        critical: json[""critical""],
        casesPerOneMillion: json[""casesPerOneMillion""],
        deathsPerOneMillion: json[""deathsPerOneMillion""],
        totalTests: json[""totalTests""],
        testsPerOneMillion: json[""testsPerOneMillion""],
    );
}

</code></pre>

<h2>Country service</h2>

<pre class=""lang-dart prettyprint-override""><code>import 'dart:async';
import 'package:http/http.dart' as http;
import '../models/country.dart';

Future&lt;Country&gt; fetchCountries() async {
  final response = await http.get('https://coronavirus-19-api.herokuapp.com/countries');

  if(response.statusCode == 200) {
    return countryFromJson(response.body);
  }
  else {
    throw Exception('Failed to load Country')
  }
}
</code></pre>

<p><a href=""https://i.stack.imgur.com/tlNzR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tlNzR.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/M36ks.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/M36ks.png"" alt=""enter image description here""></a></p>
"
61082413,"<p>I am writing a really simple app to download some data from an API. However, the API returns a JSON array. I tried to parse this JSON array, but unfortunately I didn't do it correctly and the program returns an error. IS there any way how I can fix it? Is there anyone who can help me?</p>

<h2>Countries view</h2>

<pre class=""lang-dart prettyprint-override""><code>import 'package:flutter/material.dart';
import '../../models/country.dart';
import '../../data/countries_service.dart';

class CountriesScreenAndroid extends StatefulWidget {
  @override
  _CountriesScreenAndroidState createState() =&gt; _CountriesScreenAndroidState();
}

class _CountriesScreenAndroidState extends State&lt;CountriesScreenAndroid&gt; {
  Future&lt;List&lt;Country&gt;&gt; futureCountries;

  @override
  void initState() {
    super.initState();
    futureCountries = fetchCountries();
  }


  @override
  Widget build(BuildContext context) {
    return Container(
      padding: EdgeInsets.all(8.0),
      child: FutureBuilder(
        future: futureCountries,
        builder: (context, snapshot) {

          if (snapshot.hasData) {
            return ListView.builder(
              itemCount: snapshot.data.length,
              itemBuilder: (context, index) {
                return ListTile(
                  title: Text(snapshot.data.country[index]), // Here is the problem
                );
              },
            );
          }

          return Center(
            child: CircularProgressIndicator()
          );
        },
      )
    );
  }
}
</code></pre>

<h2>Countries service</h2>

<pre class=""lang-dart prettyprint-override""><code>import 'dart:async';
import 'package:http/http.dart' as http;
import '../models/country.dart';

Future&lt;List&lt;Country&gt;&gt; fetchCountries() async {
  final response = await http.get('https://coronavirus-19-api.herokuapp.com/countries');

  if(response.statusCode == 200) {
    return countryFromJson(response.body);
  }
  else {
    throw Exception('Failed to load Country');
  }
}
</code></pre>

<h2>Countries model</h2>

<pre class=""lang-dart prettyprint-override""><code>import 'dart:convert';

List&lt;Country&gt; countryFromJson(String str) =&gt; List&lt;Country&gt;.from(json.decode(str).map((x) =&gt; Country.fromJson(x)));

class Country {
    String country;
    int cases;
    int todayCases;
    int deaths;
    int todayDeaths;
    int recovered;
    int active;
    int critical;
    int casesPerOneMillion;
    int deathsPerOneMillion;
    int totalTests;
    int testsPerOneMillion;

    Country({
        this.country,
        this.cases,
        this.todayCases,
        this.deaths,
        this.todayDeaths,
        this.recovered,
        this.active,
        this.critical,
        this.casesPerOneMillion,
        this.deathsPerOneMillion,
        this.totalTests,
        this.testsPerOneMillion,
    });

    factory Country.fromJson(Map&lt;String, dynamic&gt; json) =&gt; Country(
        country: json[""country""],
        cases: json[""cases""],
        todayCases: json[""todayCases""],
        deaths: json[""deaths""],
        todayDeaths: json[""todayDeaths""],
        recovered: json[""recovered""],
        active: json[""active""],
        critical: json[""critical""],
        casesPerOneMillion: json[""casesPerOneMillion""],
        deathsPerOneMillion: json[""deathsPerOneMillion""],
        totalTests: json[""totalTests""],
        testsPerOneMillion: json[""testsPerOneMillion""],
    );
}
</code></pre>
"
60888269,"<p>i want to set a background location tracker for that i use the location_background plugin and follow the steps in <a href=""https://github.com/Lyokone/flutterlocation/wiki/Background-Location-Updates"" rel=""nofollow noreferrer"">background location wiki</a> 
but when i run build task i get this error :</p>

<blockquote>
  <p>/home/walid/Desktop/covid19/covid19/android/app/src/main/kotlin/com/example/covid19/Application.java:17:
  error: incompatible types: PluginRegistry cannot be converted to
  FlutterEngine GeneratedPluginRegistrant.registerWith(registry); ^
  Note: Some messages have been simplified; recompile with
  -Xdiags:verbose to get full output 1 error</p>
  
  <p>FAILURE: Build failed with an exception.</p>
  
  <p>What went wrong: Execution failed for task
  ':app:compileDebugJavaWithJavac'. Compilation failed; see the compiler
  error output for details.</p>
  
  <p>Try: Run with --stacktrace option to get the stack trace. Run with
  --info or --debug option to get more log output. Run with --scan to get full insights.</p>
  
  <p>Get more help at <a href=""https://help.gradle.org"" rel=""nofollow noreferrer"">https://help.gradle.org</a></p>
  
  <p>BUILD FAILED in 4m 52s</p>
</blockquote>

<p>the Application.java code :</p>

<pre><code>package com.example.app;

import com.lyokone.location.LocationPlugin;
import io.flutter.app.FlutterApplication;
import io.flutter.plugin.common.PluginRegistry;
import io.flutter.plugins.GeneratedPluginRegistrant;


public class Application  extends FlutterApplication implements PluginRegistry.PluginRegistrantCallback {
    @Override
    public void onCreate() {
        super.onCreate();
        LocationPlugin.setPluginRegistrant(this);
    }

    @Override
    public void registerWith(PluginRegistry registry) {
        GeneratedPluginRegistrant.registerWith(registry);
    }
}
</code></pre>

<p>android SDK 28
Flutter 1.12.13+hotfix.8</p>
"
61474362,"<p>I've created an app on VS Code using Flutter and have had no issues until I started geting the app ready for build. I started changing the package name from ""com.example.careona19"" to ""com.covid19rsa.app"" but then started getting this error:</p>

<pre><code>```Launching lib\main.dart on VOG L09 in debug mode...

FAILURE: Build failed with an exception.

* Where:
Build file 'C:\Users\pkirby\development\careona19\android\app\build.gradle' line: 24

* What went wrong:
A problem occurred evaluating project ':app'.
&gt; Plugin with id 'com.covid19rsa.app' not found.

* Try:
Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.

* Get more help at https://help.gradle.org

BUILD FAILED in 1m 16s
Gradle task assembleDebug failed with exit code 1
Exited (sigterm)```
</code></pre>

<p>Android level build.gradle:</p>

<pre><code>```buildscript {
    ext.kotlin_version = '1.3.50'
    repositories {
        google()
        jcenter()
    }

    dependencies {
        classpath 'com.android.tools.build:gradle:3.6.1'
        //classpath 'com.android.tools.build:gradle:3.5.0' - original
        //classpath 'com.android.tools.build:gradle:3.3.2'
        classpath ""org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version""
        classpath 'com.google.gms:google-services:4.2.0'
    }
}

allprojects {
    repositories {
        google()
        jcenter()
    }
}

rootProject.buildDir = '../build'
subprojects {
    project.buildDir = ""${rootProject.buildDir}/${project.name}""
}
subprojects {
    project.evaluationDependsOn(':app')
}

task clean(type: Delete) {
    delete rootProject.buildDir
}
```
</code></pre>

<p>App level build.gradle:</p>

<pre><code>```def localProperties = new Properties()
def localPropertiesFile = rootProject.file('local.properties')
if (localPropertiesFile.exists()) {
    localPropertiesFile.withReader('UTF-8') { reader -&gt;
        localProperties.load(reader)
    }
}

def flutterRoot = localProperties.getProperty('flutter.sdk')
if (flutterRoot == null) {
    throw new GradleException(""Flutter SDK not found. Define location with flutter.sdk in the local.properties file."")
}

def flutterVersionCode = localProperties.getProperty('flutter.versionCode')
if (flutterVersionCode == null) {
    flutterVersionCode = '1'
}

def flutterVersionName = localProperties.getProperty('flutter.versionName')
if (flutterVersionName == null) {
    flutterVersionName = '1.0'
}

apply plugin: 'com.covid19rsa.app'
apply plugin: 'kotlin-android'
apply from: ""$flutterRoot/packages/flutter_tools/gradle/flutter.gradle""
//apply plugin: 'com.google.gms.google-services'

def keystoreProperties = new Properties()
   def keystorePropertiesFile = rootProject.file('key.properties')
   if (keystorePropertiesFile.exists()) {
       keystoreProperties.load(new FileInputStream(keystorePropertiesFile))
   }

android {
    compileSdkVersion 28

    sourceSets {
        main.java.srcDirs += 'src/main/kotlin'
    }

    lintOptions {
        disable 'InvalidPackage'
    }

    defaultConfig {
        // TODO: Specify your own unique Application ID (https://developer.android.com/studio/build/application-id.html).
        applicationId ""com.covid19rsa.app""
        minSdkVersion 16
        targetSdkVersion 28
        versionCode flutterVersionCode.toInteger()
        versionName flutterVersionName
        testInstrumentationRunner ""androidx.test.runner.AndroidJUnitRunner""
        multiDexEnabled true
    }

    signingConfigs {
       release {
           keyAlias keystoreProperties['keyAlias']
           keyPassword keystoreProperties['keyPassword']
           storeFile keystoreProperties['storeFile'] ? file(keystoreProperties['storeFile']) : null
           storePassword keystoreProperties['storePassword']
       }
   }
   buildTypes {
       release {
           signingConfig signingConfigs.release
       }
   }
}

flutter {
    source '../..'
}

dependencies {
    implementation ""org.jetbrains.kotlin:kotlin-stdlib-jdk7:$kotlin_version""
    testImplementation 'junit:junit:4.12'
    implementation 'com.google.firebase:firebase-core:16.0.1'
    androidTestImplementation 'androidx.test:runner:1.1.1'
    androidTestImplementation 'androidx.test.espresso:espresso-core:3.1.1'
    //implementation 'com.google.firebase:firebase-analytics:17.2.2'
}
apply plugin: 'com.google.gms.google-services'
```
</code></pre>

<p>I've been trying every solution I can find but nothing seems to work. Is there something obvious I'm missing?</p>
"
61179819,"<p>I'm trying out the <a href=""https://c3.ai/covid/"" rel=""nofollow noreferrer"">COVID-19 Data Lake</a> with Postman. I am running <code>POST https://api.c3.ai/covid/api/1/therapeuticasset/fetch</code> to get vaccines produced by a specific organization. But it looks like developers can include multiple organizations, so I can't just filter on the name like <code>""developer == 'Vanderbilt'""</code>.</p>

<p>I also tried <code>""'Vanderbilt' in developer""</code>.  How do I find all of the therapies that involve a specific university?</p>
"
61194028,"<p>So I have been trying to get it so there is a label at the end of each line giving the name of the country, then I can remove the legend. Have tried playing with <code>transform_filter</code> but no luck.</p>

<p>I used data from here <a href=""https://ourworldindata.org/coronavirus-source-data"" rel=""nofollow noreferrer"">https://ourworldindata.org/coronavirus-source-data</a> I cleaned and reshaped the data so it looks like this:-</p>

<pre><code>    index   days    date    country value
0   1219    0   2020-03-26  Australia   11.0
1   1220    1   2020-03-27  Australia   13.0
2   1221    2   2020-03-28  Australia   13.0
3   1222    3   2020-03-29  Australia   14.0
4   1223    4   2020-03-30  Australia   16.0
5   1224    5   2020-03-31  Australia   19.0
6   1225    6   2020-04-01  Australia   20.0
7   1226    7   2020-04-02  Australia   21.0
8   1227    8   2020-04-03  Australia   23.0
9   1228    9   2020-04-04  Australia   30.0
</code></pre>

<pre><code>import altair as alt

countries_list = ['Australia', 'China', 'France', 'Germany', 'Iran', 'Italy','Japan', 'South Korea', 'Spain', 'United Kingdom', 'United States']

chart = alt.Chart(data_core_sub).mark_line().encode(
                                            alt.X('days:Q'),
                                            alt.Y('value:Q', scale=alt.Scale(type='log')),
                                            alt.Color('country:N', scale=alt.Scale(domain=countries_list,type='ordinal')),    
                                        )

labels = alt.Chart(data_core_sub).mark_text().encode(
                                            alt.X('days:Q'),
                                            alt.Y('value:Q', scale=alt.Scale(type='log')),
                                            alt.Text('country'),
                                            alt.Color('country:N', legend=None, scale=alt.Scale(domain=countries_list,type='ordinal')), 
                                        ).properties(title='COVID-19 total deaths', width=600)


alt.layer(chart, labels).resolve_scale(color='independent')
</code></pre>

<p>This is the current mess that the chart is in. </p>

<p><a href=""https://i.stack.imgur.com/fY2PH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fY2PH.png"" alt=""enter image description here""></a></p>

<p>How would I go about just showing the last 'country' name?</p>

<h1>EDIT</h1>

<p>Here is the result. I might look at adjusting some of the countries separately as adjusting as a group means that some of the labels are always badly positioned no matter what I do with the <code>dx</code> and <code>dy</code> alignment.</p>

<p><a href=""https://i.stack.imgur.com/642n0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/642n0.png"" alt=""enter image description here""></a></p>
"
60780430,"<pre><code>from bs4 import BeautifulSoup
URL = ""https://www.worldometers.info/coronavirus/""
r = requests.get(URL)
soup = BeautifulSoup(r.content, 'html5lib')
countHTML = soup.find('div', attrs = {'class':'content-inner'})

for countVar in countHTML.findAll('div', attrs = {'class':'maincounter-number'}):
    count = countVar.span
</code></pre>

<p>Right now variable <code>count</code> returns:</p>

<pre><code>&lt;span style=""color:#aaa""&gt;270,069&lt;/span&gt;
&lt;span&gt;11,271&lt;/span&gt;
&lt;span&gt;90,603&lt;/span&gt;
</code></pre>

<p>I need help on extracting 3 separate integers from this string, I have tried <code>count[0]</code> but this is not an array so it does not work.</p>

<pre><code>String1 = ""270,069""
String2 = ""11,271""
String3 = ""90,603""
</code></pre>

<p>Then converts into 3 integers by removing the comma</p>

<pre><code>Int1 = 270069
Int2 = 11271
Int3 = 90603
</code></pre>

<p>Perhaps Regex will help?</p>

<p>Edit:</p>

<p>I currently have <code>numbers = []</code> as one value in a list, such as</p>

<pre><code>numbers = """"""
270069
11271
90603""""""
</code></pre>

<p>so if I do numbers[0], all 3 integers will show up as 1 value, how do I strip new lines, and make them into a list or array with 3 separate values?</p>
"
61438529,"<p>I am using python requests and bs4 to scrape a website, but having some trouble with decoding (I think..)</p>

<pre><code>logurl = 'https://login.flash.co.za/apex/f?p=pwfone:login'

with requests.Session() as s:
    s.headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36',
        ""accept-encoding"": ""gzip, deflate"",
    }
    response = s.get(logurl)
    response.encoding = 'utf-8'
    print response.status_code 
    # return 200
    print (response.content)
    # returns: b'&lt;html lang=""en-us"" xmlns:htmldb=""http://htmldb.oracle.com""&gt;\r\n&lt;head&gt;\r\n&lt;meta http-equiv=""x-ua-compatible"" content=""IE=edge"" /&gt;\r\n&lt;title&gt;Pay with Flash Login&lt;/title&gt;\r\n&lt;link rel=""stylesheet"" href=""/i/themes/SPhone/payback/theme_3_1.css"" type=""text/css"" /&gt;\r\n\r\n&lt;!--[if IE]&gt;&lt;link rel=""stylesheet"" href=""/i/themes/SPhone/payback/ie.css"" type=""text/css"" /&gt;&lt;![endif]--&gt;\r\n&lt;link rel=""stylesheet"" href=""/i/app_ui/css/Core.min.css?v=19.1.0.00.15"" type=""text/css"" /&gt;\n&lt;link rel=""stylesheet"" href=""/i/app_ui/css/Theme-Standard.min.css?v=19.1.0.00.15"" type=""text/css"" /&gt;\n&lt;link rel=""stylesheet"" href=""/i/libraries/jquery-ui/1.12.1/jquery-ui-apex.min.css?v=19.1.0.00.15"" type=""text/css"" /&gt;\n\r\n&lt;link rel=""stylesheet"" href=""/i/legacy_ui/css/5.0.min.css?v=19.1.0.00.15"" type=""text/css"" /&gt;\n\r\n\r\n\r\n\r\n\r\n\n&lt;script&gt;\nvar apex_img_dir = ""/i/"", htmldb_Img_Dir = apex_img_dir;\n&lt;/script&gt;\n&lt;script src=""/i/libraries/apex/minified/desktop_all.min.js?v=19.1.0.00.15""&gt;&lt;/script&gt;\n&lt;script src=""wwv_flow.js_messages?p_app_id=1500&amp;p_lang=en-us&amp;p_version=19.1.0.00.15-94050580561""&gt;&lt;/script&gt;\n&lt;script src=""/i/libraries/apex/minified/legacy_pre18.min.js?v=19.1.0.00.15""&gt;&lt;/script&gt;\n&lt;script src=""/i/libraries/apex/minified/legacy_18.min.js?v=19.1.0.00.15""&gt;&lt;/script&gt;\n&lt;script src=""/i/libraries/jquery-migrate/3.0.1/jquery-migrate-3.0.1.min.js?v=19.1.0.00.15""&gt;&lt;/script&gt;\n\r\n\r\n\r\n\r\n\r\n\n&lt;meta http-equiv=""Content-Type"" content=""text/html; charset=utf-8"" /&gt;\n\r\n&lt;/head&gt;\r\n&lt;body &gt;&lt;form action=""wwv_flow.accept"" method=""post"" name=""wwv_flow"" id=""wwvFlowForm"" novalidate  autocomplete=""off""&gt;\n&lt;input type=""hidden"" name=""p_flow_id"" value=""1500"" id=""pFlowId"" /&gt;&lt;input type=""hidden"" name=""p_flow_step_id"" value=""101"" id=""pFlowStepId"" /&gt;&lt;input type=""hidden"" name=""p_instance"" value=""5488556618334"" id=""pInstance"" /&gt;&lt;input type=""hidden"" name=""p_page_submission_id"" value=""119891457853323246540979814026507745288"" id=""pPageSubmissionId"" /&gt;&lt;input type=""hidden"" name=""p_request"" value="""" id=""pRequest"" /&gt;&lt;input type=""hidden"" name=""p_reload_on_submit"" value=""A"" id=""pReloadOnSubmit"" /&gt;&lt;input type=""hidden"" value=""119891457853323246540979814026507745288"" id=""pSalt"" /&gt;&lt;table border=""0"" cellpadding=""0"" cellspacing=""0"" summary="""" id=""t18PageBodyHead"" width=""80%"" height=""10%"" align=""center""&gt;\r\n&lt;tr&gt;\r\n&lt;td align=""center"" id=""t18Logo"" valign=""top""&gt;&lt;br /&gt;&lt;/td&gt;\r\n&lt;td id=""t18HeaderMiddle""  valign=""top"" width=""100%""&gt;&lt;br /&gt;&lt;/td&gt;\r\n&lt;td id=""t18NavBar"" valign=""top""&gt;&lt;br /&gt;&lt;br /&gt;&lt;/td&gt;\r\n&lt;/tr&gt;\r\n&lt;/table&gt;\r\n&lt;table border=""0"" cellpadding=""0"" cellspacing=""0"" summary="""" id=""t18PageBody""  width=""80%"" height=""70%"" align=""center""&gt;\r\n&lt;tr id=""t18tabscolor""&gt;\r\n&lt;td valign=""top"" id=""t18Tabs""  width=""110%""&gt;&lt;/td&gt;&lt;/tr&gt;\r\n&lt;tr&gt;\r\n&lt;td valign=""top"" id=""t18Tabs""&gt;&lt;/td&gt;&lt;/tr&gt;\r\n&lt;tr&gt;\r\n&lt;td valign=""top""&gt;&lt;/td&gt;\r\n&lt;td class=""t18PageRight""&gt;&lt;br /&gt;&lt;/td&gt;\r\n&lt;/tr&gt;\r\n&lt;td valign=""top"" id=""t18ContentBody"" height=""100%"" width=""100%""&gt;\r\n&lt;div id=""t18Messages""&gt;&lt;span id=""APEX_SUCCESS_MESSAGE"" data-template-id=""165783099126927032_S"" class=""apex-page-success u-hidden""&gt;&lt;/span&gt;&lt;span id=""APEX_ERROR_MESSAGE"" data-template-id=""165783099126927032_E"" class=""apex-page-error u-hidden""&gt;&lt;/span&gt;&lt;/div&gt;\r\n&lt;div id=""t18ContentMiddle""&gt;&lt;table id=""apex_layout_83448022784534430"" border=""0"" class=""formlayout""  role=""presentation""&gt;&lt;tr&gt;&lt;td  align=""right""&gt;&lt;label for=""P101_USERNAME"" id=""P101_USERNAME_LABEL"" tabindex=""999""&gt;&lt;a class=""t18OptionalLabelwithHelp"" href=""javascript:popupFieldHelp(\'83448127760534444\',\'5488556618334\')"" tabindex=""999""&gt;Username&lt;/a&gt;&lt;/label&gt;&lt;/td&gt;&lt;td colspan=""2""  align=""left""&gt;&lt;input type=""text""  id=""P101_USERNAME"" name=""P101_USERNAME"" class=""text_field&amp;#x20;apex-item-text"" value="""" size=""40"" maxlength=""100""  /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td  align=""right""&gt;&lt;label for=""P101_PASSWORD"" id=""P101_PASSWORD_LABEL"" tabindex=""999""&gt;&lt;a class=""t18OptionalLabelwithHelp"" href=""javascript:popupFieldHelp(\'83448212820534447\',\'5488556618334\')"" tabindex=""999""&gt;Password&lt;/a&gt;&lt;/label&gt;&lt;/td&gt;&lt;td  align=""left""&gt;&lt;input type=""password"" name=""P101_PASSWORD"" size=""40"" maxlength=""100"" value=""""  id=""P101_PASSWORD"" class=""password&amp;#x20;apex-item-text""  onkeypress=""return apex.submit({request:\'P101_PASSWORD\',submitIfEnter:event})""  /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td  align=""left""&gt;&lt;table class=""t18ButtonAlternative1"" cellspacing=""0"" cellpadding=""0"" border=""0""  summary=""""&gt;\n&lt;tr&gt;\n&lt;td class=""t18L""&gt;&lt;img src=""/i/themes/theme_18/button_alt1_l.gif"" alt="""" width=""11"" height=""18"" /&gt;&lt;/td&gt;\n&lt;td class=""t18C""&gt;&lt;a href=""javascript:apex.submit(%7Brequest:&amp;#x27;LOGIN&amp;#x27;%7D);""&gt;Login&lt;/a&gt;&lt;/td&gt;\n&lt;td class=""t18R""&gt;&lt;img src=""/i/themes/theme_18/button_alt1_r.gif"" alt="""" width=""11"" height=""18"" /&gt;&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/table&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/div&gt;\r\n&lt;/td&gt;\r\n&lt;tr&gt;\r\n&lt;td valign=""top"" align=""left"" &gt;&lt;div&gt;&lt;/div&gt;&lt;div&gt;&lt;table border=""0"" cellpadding=""0"" cellspacing=""0"" summary="""" id=""t18PageFooter"" width=""100%"" style=""clear:both""&gt;\r\n&lt;tr&gt;\r\n&lt;td id=""t18Left"" valign=""top""&gt;&lt;/td&gt;\r\n&lt;td id=""t18Center"" valign=""top""&gt;&lt;/td&gt;\r\n                &lt;div class=""coronaBanner""&gt;\r\n  &lt;div class=""coronaBanner__content""&gt;\r\n      &lt;strong&gt;HAVE QUESTIONS ABOUT CORONAVIRUS? VISIT SOUTH AFRICA\xe2\x80\x99S OFFICIAL COVID-19 RESOURCE HERE:&lt;br&gt;\r\n      &lt;a href=""https://sacoronavirus.co.za/""&gt;https://sacoronavirus.co.za/&lt;/a&gt;&lt;/strong&gt;&lt;br&gt;&lt;br&gt;\r\n    &lt;a class=""coronaBanner__websiteLink"" href=""https://sacoronavirus.co.za/"" rel=""noopener nofollow"" title=""SAcoronavirus.co.za""&gt;\r\n      &lt;img class=""coronaBanner__websiteLinkImg"" border=""0"" /&gt;\r\n    &lt;/a&gt;&lt;br&gt;&lt;br&gt;\r\n    &lt;a class=""coronaBanner__hotlineLink"" href=""tel:+27800029999""&gt;\r\n      &lt;strong&gt;Emergency Hotline: 0800 029 999&lt;/strong&gt;\r\n    &lt;/a&gt;&lt;br&gt;\r\n    &lt;a class=""coronaBanner__whatsappLink"" href=""https://wa.me/27600123456?text=Hi"" rel=""noopener nofollow""&gt;\r\n      &lt;strong&gt;WhatsApp Support Line: 0600-123456&lt;/strong&gt;\r\n    &lt;/a&gt;\r\n  &lt;/div&gt;\r\n&lt;/div&gt;\r\n&lt;td id=""t18Right"" valign=""top""&gt;&lt;span id=""t18Customize""&gt;&lt;/span&gt;&lt;br /&gt;&lt;/td&gt;\r\n&lt;/tr&gt;\r\n&lt;/table&gt;&lt;/div&gt;&lt;/td&gt;\r\n&lt;td class=""t18PageRight""&gt;&lt;br /&gt;&lt;/td&gt;\r\n&lt;/tr&gt;\r\n&lt;tr&gt;\r\n&lt;/tr&gt;\r\n&lt;/table&gt;\r\n&lt;br class=""t18Break""/&gt;\r\n&lt;input type=""hidden"" id=""pPageFormRegionChecksums"" value=""&amp;#x5B;&amp;#x5D;""&gt;\n&lt;input type=""hidden"" id=""pPageItemsRowVersion"" value="""" /&gt;&lt;input type=""hidden"" id=""pPageItemsProtected"" value=""CpJ-L5-9OTxTAYpkj4TifA"" /&gt;&lt;/form&gt; \r\n\r\n\r\n\n\n\n\n\n&lt;script type=""text/javascript""&gt;\napex.jQuery( function() {\napex.page.init( this, function() {\napex.jQuery.when.apply( apex.jQuery, apex.page.loadingDeferreds ).done(function() {\ntry {\n(function(){\nvar lTimeoutField = document.getElementById(""apex_login_throttle_sec""),\n    lTimeout      = lTimeoutField ? +lTimeoutField.innerHTML : 0;\nif (lTimeout) {\n    var lTimer = window.setInterval (\n        function() {\n            if (lTimeout &gt; 0) {\n                lTimeoutField.innerHTML = lTimeout;\n                lTimeout--;\n            } else {\n                window.clearInterval(lTimer);\n                var lDiv = document.getElementById(""apex_login_throttle_div"");\n                if (lDiv) {\n                    lDiv.parentNode.removeChild(lDiv);\n                    return true;\n                }\n            }\n        },\n        1000 );\n}})();\n\n\napex.item( \'P101_USERNAME\' ).setFocus();\n} finally {\napex.event.trigger(apex.gPageContext$,\'apexreadyend\');\n}\n});\n});\n});&lt;/script&gt;\n\r\n&lt;/body&gt;\r\n&lt;/html&gt;'
    print (response.text)
    #return nothing
    soup = BeautifulSoup(response.content ,""html5lib"") #returns nothing
    soup = BeautifulSoup(response.text ,""html5lib"") #returns nothing
    soup = BeautifulSoup(response.content ,""html.parser"") #returns nothing
    soup = BeautifulSoup(response.text ,""html.parser"") #returns nothing
</code></pre>

<p>The strange thing is this works fine on my local environment (python 3.7 and even python 2.7), but not on the server I am using, which uses python 3.5.  </p>

<p>How can I correctly decode the response for bs4?</p>
"
61138367,"<p>I have three <code>csv</code> files which contains data about covid 19. The first <code>csv</code> has information about number of <code>confirmed cases</code>, the second one has information about <code>number of deaths</code> and the third one has information about <code>number of recovery</code>.</p>

<p>So this is how the dataframes looks like</p>

<pre><code>import pandas as pd

df1 = pd.read_csv('/Users/sr/covid_csvs/confirmed.csv')

df2 = pd.read_csv('/Users/sr/covid_csvs/deaths.csv')

df3 = pd.read_csv('/Users/sr/covid_csvs/recovery.csv')

print(df1.head(5))

  Province/State Country/Region      Lat     Long     Date  Confirmed
0            NaN    Afghanistan  33.0000  65.0000  1/22/20          0
1            NaN        Albania  41.1533  20.1683  1/22/20          0
2            NaN        Algeria  28.0339   1.6596  1/22/20          0
3            NaN        Andorra  42.5063   1.5218  1/22/20          0
4            NaN         Angola -11.2027  17.8739  1/22/20          0


print(df2.head(5))

  Province/State Country/Region      Lat     Long     Date     Deaths
0            NaN    Afghanistan  33.0000  65.0000  1/22/20          0
1            NaN        Albania  41.1533  20.1683  1/22/20          0
2            NaN        Algeria  28.0339   1.6596  1/22/20          0
3            NaN        Andorra  42.5063   1.5218  1/22/20          0
4            NaN         Angola -11.2027  17.8739  1/22/20          0


print(df3.head(5))

  Province/State Country/Region      Lat     Long     Date  Recovery
0            NaN    Afghanistan  33.0000  65.0000  1/22/20         0
1            NaN        Albania  41.1533  20.1683  1/22/20         0
2            NaN        Algeria  28.0339   1.6596  1/22/20         0
3            NaN        Andorra  42.5063   1.5218  1/22/20         0
4            NaN         Angola -11.2027  17.8739  1/22/20         0
</code></pre>

<p>Now I want to merge all the three dataframes such that I get the below result</p>

<pre><code>  Province/State Country/Region      Lat     Long     Date  Confirmed  Deaths Recovery
0            NaN    Afghanistan  33.0000  65.0000  1/22/20          0       0        0
1            NaN        Albania  41.1533  20.1683  1/22/20          0       0        0
2            NaN        Algeria  28.0339   1.6596  1/22/20          0       0        0
3            NaN        Andorra  42.5063   1.5218  1/22/20          0       0        0
4            NaN         Angola -11.2027  17.8739  1/22/20          0       0        0
</code></pre>

<p>So I tried doing something like below</p>

<pre><code>df_merged = pd.concat([df1, df2, df3])    
df_merged.to_csv('merged.csv', sep=',', encoding='utf-8', index=False)
</code></pre>

<p>But I do not get the required <code>csv</code>. How do I do this?</p>
"
60682567,"<p>Currently, I'm working with the COVID dataset to do some insights.</p>

<p>The dataset is of this form:</p>

<pre><code>    Country Province    Lat Lon         Date                    Cases   Status
0   Thailand        15.0000 101.0000    2020-01-22 00:00:00+00:00   2   confirmed
1   Thailand        15.0000 101.0000    2020-01-23 00:00:00+00:00   3   confirmed
2   Thailand        15.0000 101.0000    2020-01-24 00:00:00+00:00   5   confirmed
3   Thailand        15.0000 101.0000    2020-01-25 00:00:00+00:00   7   confirmed
4   Thailand        15.0000 101.0000    2020-01-26 00:00:00+00:00   8   confirmed
</code></pre>

<p>I want to group by country, summing over the ""Cases"" column (we'll call this case sum column), but I run into a problem with latitude and longitude: I want to take the lat/long of the max of the case column. In other words, I would like the latitude and longitude from the row with the largest number of cases. To clarify, the use case is that a country like France has rows with multiple latitude and longitudes (like French Polynesia for example) but I just want to take the lat/long in the grouping from the area which has the most cases.</p>

<p>I currently am running an aggregation as follows:</p>

<pre><code>nonzero_cases[(nonzero_cases['Date'] == ""03/13/2020"")].groupby(""Country"").agg({""Lat"":""first"",""Lon"":""first"",""Cases"":""sum""})
</code></pre>

<p>This yields:</p>

<pre><code>Country     Lat     Lon     Cases
Afghanistan 33.0000 65.0000 7
Albania 41.1533 20.1683 33
Algeria 28.0339 1.6596  26
Andorra 42.5063 1.5218  1
...
</code></pre>

<p>But this is not quite what I want since it doesn't take into account the case numbers, and just picks the first Lat/Lon.</p>
"
61182363,"<p>I have a Pandas DataFrame that has a categorical column as such:</p>

<pre><code>df = pd.DataFrame({'Source': ['Coronavirus','Sars','sars','coronavirus',
                          'CoronaVirus','Sars']})
df[""Source""] = df[""Source""].astype('category')
print(df)
        Source
0  Coronavirus
1         Sars
2         sars
3  coronavirus
4  CoronaVirus
5         Sars
</code></pre>

<p>Please note the difference in the way the text is written e.g.(CoronaVirus vs. Coronavirus vs. coronavirus).
What I wish to achieve is to convert all the <strong>same</strong> text i.e. <strong>coronavirus</strong> and <strong>sars</strong>, but regardless of how it is written (first letter capital, etc.), and unify all of them. So the desired output would be:</p>

<pre><code>        Source
0  Coronavirus
1         Sars
2         Sars
3  Coronavirus
4  Coronavirus
5         Sars
</code></pre>

<p>It doesn't matter how is the final result is produced (Coronavirus or coronavirus).</p>

<p>Thanks in advance.</p>
"
61150699,"<p>I'd like to use the <code>https://api.c3.ai/covid/api/1/linelistrecord/fetch</code> API but only get 2000 records back. I know that there are more than 2000 records -- how do I get them? </p>

<p>Here's my code in R:</p>

<pre><code>library(tidyverse)
library(httr)
library(jsonlite)

resp &lt;- POST(
  ""https://api.c3.ai/covid/api/1/linelistrecord/fetch"",
  body = list(
    spec = {}
  ) %&gt;% toJSON(auto_unbox = TRUE),
  accept(""application/json"")
)

length(content(resp)$objs)
</code></pre>

<p>I get 2000 records.</p>
"
61217213,"<p>I've been producing animated maps showing the progression of COVID case data.  In the interest of producing a minimal example I have skinnied the code down to the below, which only produces one frame.  In practice I also read a number of csv files.  I've tried to eliminate that in this example, but there is still one with county population data.  I have posted it at <a href=""https://pastebin.com/jCD9tP0X"" rel=""nofollow noreferrer"">https://pastebin.com/jCD9tP0X</a></p>

<pre><code>library(urbnmapr) # For map
library(ggplot2)  # For map
library(dplyr)    # For summarizing
library(tidyr)    # For reshaping
library(stringr)  # For padding leading zeros
library(ggrepel)
library(ggmap)
library(usmap)
library(gganimate)
library(magrittr)
library(gifski)
library(scales)


#first run setup tasks
#these can be commented out once the data frames are in place

###################begin first run only################################

#define census regions
NE_region &lt;- c(""ME"",""NH"",""VT"",""MA"", ""CT"", ""RI"", ""NY"", ""PA"", ""NJ"")

ne_region_bases &lt;-c(""Hanscom AFB"", ""Rome, NY"")

# Get COVID cases, available from:
url &lt;- ""https://static.usafacts.org/public/data/covid-19/covid_confirmed_usafacts.csv""
COV &lt;- read.csv(url, stringsAsFactors = FALSE)

#sometimes there are encoding issues with the first column name
names(COV)[1] &lt;- ""countyFIPS""

Covid &lt;- pivot_longer(COV, cols=starts_with(""X""),
                      values_to=""cases"",
                      names_to=c(""X"",""date_infected""),
                      names_sep=""X"") %&gt;%
  mutate(infected = as.Date(date_infected, format=""%m.%d.%Y""),
         countyFIPS = str_pad(as.character(countyFIPS), 5, pad=""0""))

# Obtain map data for counties (to link with covid data) and states (for showing borders)
states_sf &lt;- get_urbn_map(map = ""states"", sf = TRUE)
counties_sf &lt;- get_urbn_map(map = ""counties"", sf = TRUE)

# Merge county map with total cases of cov
#use this line to produce animated maps
#pop_counties_cov &lt;- inner_join(counties_sf, Covid, by=c(""county_fips""=""countyFIPS""))

#use this one for a single map of the latest data
pop_counties_cov &lt;- inner_join(counties_sf, group_by(Covid, countyFIPS) %&gt;%
                             summarise(cases=sum(cases)), by=c(""county_fips""=""countyFIPS""))

#read the county population data
#csv at https://pastebin.com/jCD9tP0X
counties_pop &lt;- read.csv(""countyPopulations.csv"", header=TRUE, stringsAsFactors = FALSE)

#pad the single digit state FIPS states
counties_pop &lt;- counties_pop %&gt;% mutate(CountyFIPS=str_pad(as.character(CountyFIPS),5,pad=""0""))

#merge the population and covid data by FIPS
pop_counties_cov$population &lt;- counties_pop$Population[match(pop_counties_cov$county_fips,counties_pop$CountyFIPS)]

#calculate the infection rate
pop_counties_cov &lt;- pop_counties_cov %&gt;% mutate(infRate = (cases/population)*100)

#counties with 0 infections don't appear in the usafacts data, so didn't get a population
#set them to 0
pop_counties_cov$population[is.na(pop_counties_cov$population)] &lt;- 0
pop_counties_cov$infRate[is.na(pop_counties_cov$infRate)] &lt;- 0

plotDate=""April14""
basepath = ""your/output file/path/here/""
naColor = ""white""
lowColor = ""green""
midColor = ""maroon""
highColor = ""red""
baseFill = ""dodgerblue4""
baseColor = ""firebrick""
baseShape = 23
###################end first run only################################


###################Northeast Map################################
#filter out states
ne_pop_counties_cov &lt;- pop_counties_cov %&gt;% filter(state_abbv %in% NE_region)
ne_states_sf &lt;- states_sf %&gt;% filter(state_abbv %in% NE_region)
ne_counties_sf &lt;- counties_sf %&gt;% filter(state_abbv %in% NE_region)

#filter out bases
neBases &lt;- structure(list(Base = c(""Hanscom AFB"", ""Rome, NY""), longitude = c(-71.2743123, 
                                                                             -75.4557303), 
                          latitude = c(42.4579955, 43.2128473), 
                          personnel = c(2906L,822L), 
                          longitude.1 = c(2296805.44531269, 1951897.82199569), 
                          latitude.1 = c(128586.352781279, 99159.9145180969)), 
                          row.names = c(NA, -2L), class = ""data.frame"")

p &lt;- ne_pop_counties_cov %&gt;%
  ggplot() +
  geom_sf(mapping = aes(fill = infRate, geometry=geometry), color = NA) +
  geom_sf(data = ne_states_sf, fill = NA, color = ""black"", size = 0.25) +
  coord_sf(datum = NA) +   
  scale_fill_gradient(name = ""% Pop \nInfected"", trans = ""log"",low=lowColor, high=highColor,
                      breaks=c(0, max(ne_pop_counties_cov$infRate)),
                      na.value = naColor) +
  geom_point(data=neBases, 
             aes(x=longitude.1, y=latitude.1,size=personnel), 
             shape = baseShape,
             color = baseColor,
             fill = baseFill) +
  theme_bw() + 
  labs(size='AFMC \nMil + Civ') +
  theme(legend.position=""bottom"",
        panel.border = element_blank(),
        axis.title.x=element_blank(), 
        axis.title.y=element_blank())

print(p)

###################End Northeast Map################################
</code></pre>

<p>If you run this you should get a single frame...when I do the whole animation, here is the final frame</p>

<p><a href=""https://i.stack.imgur.com/wzd2h.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wzd2h.png"" alt=""enter image description here""></a></p>

<p>The diamonds represent the locations of air force bases we're interested in within the region, and they are sized by how many personnel are there.  </p>

<p>What I have been asked to do is to make the diamonds the same size, but ""color code"" the fill based on the number of personnel.  I don't think this is a good idea, but I'm not the boss.  </p>

<p>I'm not sure how to have two gradient fills on a single plot?</p>
"
61286756,"<p>I designed a web app using the Flutter web. I hosted it with Firebase host. But It's not showing changes of my code after deploying to firebase. It's still showing my older version of web app. But I can overcome this problem by clearing cache memory of browser. But I don't want to do this everytime I deploy to firebase. How to stop saving my web app in cache memory?</p>

<p>hosted link: <a href=""https://frcovid19dashboard.web.app"" rel=""nofollow noreferrer"">https://frcovid19dashboard.web.app</a></p>
"
61180924,"<p>My local government has thrown the idea of open public data into the bin and chosen instead to publish its COVID-19 updates via an online Power BI dashboard (with no download option). The dashboard lacks a static <code>url</code>, but you can <a href=""https://stackoverflow.com/questions/52079733/data-scraping-from-published-power-bi-visual"">access it here</a>.</p>

<p>When published online, Power BI dashboards have a complex HTML structure that doesn't seem to respond to scrapers like a normal <code>HTML</code> doc.</p>

<p>Using <a href=""https://www.npmjs.com/package/puppeteer"" rel=""nofollow noreferrer"">Puppeteer</a> (a Node.js module), I can scrape some elements from the first page of the dashboard. What I really need is to access the second page. To get this, I need to 'click' on the right arrow at the bottom of the screen. This can be selected successfully with <code>document.querySelector("".pbi-glyph-chevronrightmedium"")</code>.</p>

<p>However, I can't <em>interact</em> with that element to reach the second page. While Puppeteer can find it, it can't click it. The first line here works; the second doesn't:</p>

<pre><code>await page.waitForSelector("".pbi-glyph-chevronrightmedium"");
await page.click("".pbi-glyph-chevronrightmedium"");
</code></pre>

<p>Any ideas? There was another question published about <a href=""https://stackoverflow.com/questions/55063265/scraping-data-from-a-website-which-uses-power-bi-retrieving-data-from-power-bi"">scraping from a Power BI dashboard</a> but it covered different aspects. I can't perform the simple task of clicking the 'Next page' arrow.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""true"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code snippet-currently-hidden"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>const puppeteer = require(""puppeteer"");
async function scrape() {
  var browser = await puppeteer.launch(),
      page = await browser.newPage();
  return new Promise(async function(resolve, reject) {
    try {
      await page.goto(""https://www.covid19.act.gov.au/updates/confirmed-case-information"");
      await page.waitForSelector("".col-md-12 a"");
      let dashboardUrl = await page.evaluate(function() {
        return document.querySelector("".col-md-12 a"").href;
      });
      await page.goto(dashboardUrl);
      await page.waitForSelector("".pbi-glyph-chevronrightmedium"");
      console.log(""Found the arrow!"");
      await page.click("".pbi-glyph-chevronrightmedium"");
      console.log(""Clicked the arrow!"");
      browser.close();
      return resolve(""end scrape"");
    } catch (error) {
      return reject(error);
    }
  });
}
scrape()
  .then(console.log)
  .catch(console.error);</code></pre>
</div>
</div>
</p>
"
61509734,"<p>In order to meaningfully compare across territories, I would like to normalize the COVID-19 confirmed cases by the starting date of the outbreak in different countries. For any territory, the day that territory reaches or exceeds 10 confirmed cases is considered as 'day 0 of the outbreak.</p>

<p>Example dataframe:</p>

<pre><code>[in]
import pandas as pd
confirmed_cases = {'Date':['1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20'], 'Australia':[0, 0, 0, 30, 50], 'Albania':[0, 20, 25, 30, 50], 'Algeria':[25, 40, 50, 50, 70]}
df = pd.DataFrame(confirmed_cases)
df

[out]
    Date    Australia   Albania     Algeria
0   1/22/20        0         0          25
1   1/23/20        0        20          40
2   1/24/20        0        25          50
3   1/25/20       30        30          50
4   1/26/20       50        50          70
</code></pre>

<p>Desired Results:</p>

<pre><code>    Day Since Outbreak     Australia    Albania     Algeria
0           0                    30         20          25
1           1                    50         25          40
2           2                   NaN         30          50
3           3                   NaN         50          50
4           4                   NaN        NaN          70
</code></pre>

<p>Are there any ways to perform this task with simple lines of Python/Panda code?</p>
"
61198666,"<p>I am using the C3.ai's APIs for analyzing unified COVID-19 data. For generating a time series of confirmed cases and deaths across locations of COVID outbreaks, I successfully called the <code>evalMetrics</code> API, but the response received is <code>JSON</code>. </p>

<p>How can I best convert this to a pandas dataframe in python so that I can easily perform my analyses on this data?</p>

<p>Here is the code I have used to call the <code>evalMetrics</code> API successfully:</p>

<pre><code>import json, requests
locations_to_evaluate = [""China"",""Italy""]
expressions_to_evaluate = [""JHU_ConfirmedCases"",""JHU_ConfirmedDeaths""]
url = ""https://api.c3.ai/covid/api/1/outbreaklocation/evalmetrics/""
request_data = {
    ""spec"": {
        ""ids"": locations_to_evaluate,
        ""expressions"": expressions_to_evaluate,
        ""start"": ""2020-02-01"",
        ""end"": ""2020-03-01"",
        ""interval"": ""DAY""
    }
}
headers = {
    ""Accept"": ""application/json"",
    ""Content-Type"": ""application/json""
}
response = requests.post(url=url, json=request_data, headers=headers)
eval_metrics_result = json.loads(response.text)
</code></pre>

<p>I want to convert <code>eval_metrics_result</code> to a pandas dataframe. Is there a generic function I can use to convert any <code>eval_metrics_result</code> to a pandas dataframe?</p>
"
61182225,"<p>I am querying C3.ai API's for analyzing unified COVID-19 data. I see that all the API's return an xml formatted string, by default. Currently, I am converting the format to json using the python library, <code>xmltodict</code>. Is there a way I can directly request a JSON response?</p>

<p>Here's the code I am running:</p>

<pre><code>import json, requests, xmltodict
url = ""https://api.c3.ai/covid/api/1/outbreaklocation/fetch/""
request_data = {
    ""spec"": {
        ""include"": ""id"",
        ""limit"": 1
    }
}
response = requests.post(url=url, json=request_data)
print(response.text)
</code></pre>

<p>And the corresponding response I get is as follows:</p>

<pre><code>&lt;fetchResponse version=""2.0""&gt;
  &lt;type&gt;
    &lt;module&gt;metadata&lt;/module&gt;
    &lt;name&gt;FetchResult&lt;/name&gt;
    &lt;bindings&gt;
      &lt;k&gt;T&lt;/k&gt;
      &lt;v&gt;
        &lt;type&gt;
          &lt;module&gt;typesys&lt;/module&gt;
          &lt;name&gt;ReferenceType&lt;/name&gt;
        &lt;/type&gt;
        &lt;name&gt;OutbreakLocation&lt;/name&gt;
        &lt;mixing&gt;true&lt;/mixing&gt;
      &lt;/v&gt;
    &lt;/bindings&gt;
  &lt;/type&gt;
  &lt;objs&gt;
    &lt;k&gt;0&lt;/k&gt;
    &lt;v&gt;
      &lt;id&gt;AaenHunze_Drenthe_Netherlands&lt;/id&gt;
      &lt;meta&gt;
        &lt;fetchInclude&gt;[id,version,typeIdent]&lt;/fetchInclude&gt;
        &lt;fetchType&gt;OutbreakLocation&lt;/fetchType&gt;
      &lt;/meta&gt;
      &lt;version&gt;262145&lt;/version&gt;
      &lt;typeIdent&gt;EP_LOC&lt;/typeIdent&gt;
    &lt;/v&gt;
  &lt;/objs&gt;
  &lt;count&gt;1&lt;/count&gt;
  &lt;hasMore&gt;true&lt;/hasMore&gt;
&lt;/fetchResponse&gt;
</code></pre>

<p>And I am using the following piece of code to convert the xml to json:</p>

<pre><code>fetch_object = xmltodict.parse(response.text)
</code></pre>
"
60733405,"<p>I am new to web dev so please forgive.</p>

<p>I make simple api call</p>

<pre><code>  const getWorldTotal = async () =&gt; {
  const response = await fetch('https://cors-anywhere.herokuapp.com/https://health-api.com/api/v1/covid-19/total');
  const worldTotal = await response.json();
  alert(worldTotal.total_confirmed)
  document.getElementById('total') = worldTotal.total_confirmed
};
getWorldTotal()
</code></pre>

<p>Here is my html that i am trying to update</p>

<pre><code>&lt;div class=""card text-white bg-secondary mb-3"" id=""total"" style=""max-width: 20rem;""&gt;
&lt;div class=""card-header""&gt;Header&lt;/div&gt;
&lt;div class=""card-body""&gt;
  &lt;h4 class=""card-title"" id=""total""&gt;&lt;/h4&gt;
&lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p>I get the following error</p>

<blockquote>
  <p>index.html:80 Uncaught (in promise) ReferenceError: Invalid left-hand
  side in assignment  at getWorldTotal</p>
</blockquote>

<p>My question is what did i do wrong? Also is this the best way to update HTML when making api calls ? </p>
"
61429456,"<p>So i'm trying to get how many cases of coronavirus are currently confirmed in Colombia for a website. I only need to show the number of cases and i'm using bs4. However, i know basic stuff about programming and i don't know python. here's what i've got</p>

<pre><code>import bs4

import requests

response = requests.get(""https://es.wikipedia.org/wiki/Pandemia_de_enfermedad_por_coronavirus_de_2020_en_Colombia"")

if response is not None:
    html = bs4.BeautifulSoup(response.text, 'html.parser')

    title = html.select("".infobox"")[0].text
    paragraphs = html.select(""tr"")
    #for para in paragraphs:
        #print (para.text)

    mylist = soup.find_all('td')
    print(mylist.text)
</code></pre>
"
60879399,"<p>I completed a bokeh plot which I believe is a bokeh application. I wanted to embed it in my personal git hub page or Medium to make it interactive. I read through the bokeh docs but I still did not understand how things work. In the document it says to use server_document() function and a URL. Where should I get the URL ? 
below is the sample code from Bokeh document. </p>

<pre><code>from bokeh.embed import server_document
script = server_document(""https://demo.bokeh.org/sliders"")
</code></pre>

<p>This is my bokeh plot github repository: <a href=""https://github.com/Lastget/Covid19_Job_risks.git"" rel=""nofollow noreferrer"">https://github.com/Lastget/Covid19_Job_risks.git</a> </p>

<p>This is the website I want to embed the code to <a href=""https://github.com/Lastget/Lastget.github.io.git"" rel=""nofollow noreferrer"">https://github.com/Lastget/Lastget.github.io.git</a> </p>

<p>Sorry I am new to building web pages. I did not know which file to embed my bokeh code to. I built this git page by pre-made template.  I used markdown in _pages folder to make a post. Can I can embed an interactive bokeh plot in markdowns? Or should I embed it in some other HTML in this github page? Thank you so much for answering my question.   </p>
"
60894843,"<p>I'm trying to scrape a website and place it into a structured data format. 
I'd like to end up with a .csv with 6 columns: country, date, general_text, fiscal_text, monetary_text, fx_text. </p>

<p>The mapping is like this:</p>

<pre><code>country &lt;- h3
date &lt;- h6
general_text &lt;- p (h3) (the p tag that follows the h3 header)
fiscal_text  &lt;- p (1st h5 ul li) (the p tag that follows the **first** h5. This tag is inside ul and li blocks)
monetary_text &lt;- p (2nd h5 ul li) (the p tag that follows the **second** h5. This tag is inside ul and li blocks)
fx_text &lt;- p (3rd h5 ul li) (the p tag that follows the **third** h5. This tag is inside ul and li blocks)
</code></pre>

<p>The pattern ends at the next h3 (country) heading.</p>

<p>I'm finding it difficult to get each element in its proper place/column.</p>

<p>The site structure repeats this for each country (see below for the actual tags):</p>

<pre><code>h3
 p
h6
h5
 ul
  li
   p
h5
 ul
  li
   p
h5
 ul
  li
   p
</code></pre>

<p>I have the following code for simple text extraction:</p>

<pre><code>import requests
import io
import csv 
from bs4 import BeautifulSoup
from urllib.request import urlopen
URL = 'https://www.imf.org/en/Topics/imf-and-covid19/Policy-Responses-to-COVID-19'
page = requests.get(URL)
soup = BeautifulSoup(page.content, 'html.parser')

results = soup.find(class_='rr-intro')

with io.open('test.txt', 'w', encoding='utf8') as f:
    for header in results.find_all(['h3', 'h6', 'h5']):
        f.write(header.get_text() + u'\n') 
        for elem in header.next_siblings:
            if elem.name and elem.name.startswith('h'):
                # stop at next header
                break
            if elem.name and elem.find_all('p'):
                f.write(elem.get_text() + u'\n')
</code></pre>

<p>From the comments, I thought it makes sense instead to create lists and somehow zip them. I tried this:</p>

<pre><code>h3 = results.find_all('h3')
h6 = results.find_all('h6')
h5 = results.find_all('h5')
h5f = results.find_all('h5', text='Fiscal')
h5m = results.find_all('h5', text='Monetary and macro-financial')
h5x = results.find_all('h5', text='Exchange rate and balance of payments')
country = [country.get_text() for country in h3]  #list of countries
date = [date.get_text() for date in h6]  #date string

</code></pre>

<p>I'm stuck here. Not sure how to get the contents of the p-tags to go to the right place in a list so it would be zipped, or directly to a csv. </p>

<p>I'm a python rookie, so I made these based on what I found on stackoverflow. Any help would be greatly appreciated.</p>

<p>Edit: To clarify, The structure of what I want looks like this. </p>

<pre><code>&lt;div class=""rr-intro""&gt;

 &lt;h3&gt;
  Country 1
 &lt;/h3&gt;
 &lt;p&gt;
  summary text
 &lt;/p&gt;
 &lt;h6&gt;
  date
 &lt;/h6&gt;
 &lt;h5&gt;
  Fiscal
 &lt;/h5&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    text for fiscal of country 1
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h5&gt;
  Monetary and macro-financial
 &lt;/h5&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    text for monetary of country 1
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h5&gt;
  Exchange rate and balance of payments
 &lt;/h5&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    text for FX of country 1
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
  &lt;h3&gt;
  Country 2
 &lt;/h3&gt;
 &lt;p&gt;
  summary text
 &lt;/p&gt;
 &lt;h6&gt;
  date
 &lt;/h6&gt;
 &lt;h5&gt;
  Fiscal
 &lt;/h5&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    text for fiscal of country 2
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h5&gt;
  Monetary and macro-financial
 &lt;/h5&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    text for monetary of country 2
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
 &lt;h5&gt;
  Exchange rate and balance of payments
 &lt;/h5&gt;
 &lt;ul&gt;
  &lt;li&gt;
   &lt;p&gt;
    text for FX of country 2
   &lt;/p&gt;
  &lt;/li&gt;
 &lt;/ul&gt;
   &lt;h3&gt;
  Country 3
 &lt;/h3&gt; 
</code></pre>

<p>etc...</p>
"
61322060,"<p>When loading a Wikipedia table using HtmlProvider, I get an error message because the last row in the table is empty!</p>

<pre><code>module SOQN = 

    open System
    open FSharp.Data

    let [&lt;Literal&gt;] wikiUrl  = @""https://en.wikipedia.org/wiki/COVID-19_testing#Virus_testing_statistics_by_country""
    type Covid = HtmlProvider&lt;wikiUrl&gt;

    let main() =
        printfn """"
        printfn ""SOQN: Error Loading Table With Empty Last Row Using HtmlProvider?""
        printfn """"
        let feed = Covid.Load(wikiUrl)
        feed.Tables.``Virus testing statistics by country``.Rows
        |&gt; Seq.map (fun r -&gt; r.Date) 
        |&gt; printf ""%A ""
        printfn """"
        0

    [&lt;EntryPoint&gt;]
    main() |&gt; ignore
    printfn ""Fini!""
    printfn """"

// Actual Output: 
// ""Date is missing""
// 
// Expected Output: 
// seq [ ""Albania""; ""19 Apr""; ""5542""; ""562""; ""10.1""; ""1,936""; ""196""; ""[121]"" ]
// ... 
//
</code></pre>

<p>What am I missing?</p>

<p>For instance, can I preset the column types to 'string' similar to using 'schema' with CsvProvider?</p>
"
60694707,"<p>I am trying to experiment with live data from the Coronavirus pandemic (unfortunately and good luck to all of us).</p>

<p>I have developed a small script and I am transitioning into a console application: it uses CSV type providers.</p>

<p>I have the following issue. Suppose we want to filter by region the Italian spread we can use this code into a .fsx file:</p>

<pre><code>open FSharp.Data

let provinceData = CsvProvider&lt; @""https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-province/dpc-covid19-ita-province.csv"" , IgnoreErrors = true&gt;.GetSample()


let filterDataByProvince province = 
    provinceData.Rows
    |&gt; Seq.filter (fun x -&gt; x.Sigla_provincia = province)
</code></pre>

<p>Being sequences lazy, then suppose I force the complier to load in memory the data for the province of Rome, I can add:</p>

<pre><code>let romeProvince = filterDataByProvince ""RM"" |&gt; Seq.toArray
</code></pre>

<p>This works fine, run by FSI, locally.</p>

<p>Now, if I transition this code into a console application using a .fs file; I declare exactly the same functions and using exactly the same type provider loader; but instead of using the last line to gather the data, I put it into a main function:</p>

<pre><code>[&lt;EntryPoint&gt;]
let main _ =
    let romeProvince = filterDataByProvince ""RM"" |&gt; Seq.toArray

    Console.Read() |&gt; ignore
    0
</code></pre>

<p>This results into the following runtime exception:</p>

<pre><code>System.Exception
  HResult=0x80131500
  Message=totale_casi is missing
  Source=FSharp.Data
  StackTrace:
   at &lt;StartupCode$FSharp-Data&gt;.$TextRuntime.GetNonOptionalValue@139-4.Invoke(String message)
   at CoronaSchiatta.Evoluzione.provinceData@10.Invoke(Object parent, String[] row) in C:\Users\glddm\source\repos\CoronaSchiatta\CoronaSchiatta\CoronaEvolution.fs:line 10
   at FSharp.Data.Runtime.CsvHelpers.parseIntoTypedRows@174.GenerateNext(IEnumerable`1&amp; next)
</code></pre>

<p>Can you explain that?</p>

<p>Some rows have an odd format, possibly, but the FSI session is robust to those, whilst the console version is fragile; why? How can I fix that? </p>

<p>I am using VS2019 Community Edition, targeting .NET Framework 4.7.2, F# runtime: 4.7.0.0;
as FSI, I am using the following: FSI Microsoft (R) F# Interactive version 10.7.0.0 for F# 4.7</p>

<p>PS: Please also be aware that if I use CsvFile, instead of type providers, as in:</p>

<pre><code>let test = @""https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-province/dpc-covid19-ita-province.csv"" 
               |&gt; CsvFile.Load |&gt; (fun  x  -&gt; x.Rows )  |&gt; Seq.filter ( fun x-&gt; x.[6 ] = ""RM"")
               |&gt; Seq.iter ( fun x -&gt; x.[9] |&gt; Console.WriteLine )
</code></pre>

<p>Then it works like a charm also in the console application. Of course I would like to use type providers otherwise I have to add type definition, mapping the schema to the columns (and it will be more fragile). The last line was just a quick test.</p>
"
61382551,"<p>I am part of the EUvsVirus hackathon this weekend scraping the web for scientific articles.  COVID-19 in unknown HTML and many require a headless browser. 
What is the minimum software that needs to be installed to do this? I will be distributing as a commandline utility, maybe in Docker. If I use Chrome do I have to install the browser? I will want to distribute the result widely and don't want complex or proprietary installation.</p>

<p>(<a href=""https://github.com/petermr/openVirus"" rel=""nofollow noreferrer"">https://github.com/petermr/openVirus</a>)</p>
"
61441074,"<p>I am trying to parse a json api for Covid19. The link is available in the code . The data I am getting does not match with the original JSON file.(for eg: there is a mismatch in the stats for the district ""Rohtas"" and many more)    </p>

<pre><code> public static void getAllDistrictsInfo()
        {
            ArrayList&lt;StateDetails&gt; states = new ArrayList&lt;StateDetails&gt;();
            try{
            URL url = new URL(""https://api.covid19india.org/state_district_wise.json"");//your url i.e fetch data from .
            HttpURLConnection conn = (HttpURLConnection) url.openConnection();
            conn.setRequestMethod(""GET"");
            conn.setRequestProperty(""Accept"", ""application/json"");
            if (conn.getResponseCode() != 200) {
                throw new RuntimeException(""Failed : HTTP Error code : ""
                        + conn.getResponseCode());
            }
            InputStreamReader in = new InputStreamReader(conn.getInputStream());
            BufferedReader br = new BufferedReader(in);


            Scanner sc = new Scanner(url.openStream());
            String inline = """";
            while(sc.hasNext())
            {
            inline+=sc.nextLine();
            }

            JSONParser parse = new JSONParser();
            JSONObject jobj = (JSONObject)parse.parse(inline);
            ArrayList&lt;String&gt; set = new ArrayList&lt;String&gt;(jobj.keySet());

           for(Iterator iterator = set.iterator(); iterator.hasNext();) 
           {
                String key = (String) iterator.next();
                JSONObject distdata = (JSONObject) jobj.get(key);
                JSONObject dists = (JSONObject) distdata.get(""districtData"");
                System.out.println(key);

                ArrayList&lt;String&gt; set2 = new ArrayList&lt;String&gt;(dists.keySet());
                for(Iterator itr = set2.iterator();itr.hasNext();)
                {
                    String key2 = (String) itr.next();
                    JSONObject district = (JSONObject) dists.get(key2);
                    System.out.println(key2);
                    System.out.println(district);
                }
                System.out.println(""************"");

            }

            conn.disconnect();

        }
        catch (Exception e) {
            System.out.println(""Exception in NetClientGet:- "" + e);
        }


        }
</code></pre>
"
60855507,"<p>I'm trying to web scrape from a website <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a> and turns that data to form an app but the data is not actually printing I don't the reason but whenever I click the button in an android emulator it just crashes instantly !! </p>

<p>I have 3 textView in the app and a button so whenever I click the button it should show up the data in the textView !!</p>

<p>textView have ids of TotalCases / TotalDeaths / TotalRecovered
button has an id of the button</p>

<p>Here is what I have I have done</p>

<pre><code>package com.example.coronaupdate;

import androidx.appcompat.app.AppCompatActivity;

import android.os.Bundle;
import android.view.View;
import android.widget.TextView;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.nodes.Element;
import org.jsoup.select.Elements;
import android.widget.Button;
import java.io.IOException;

public class MainActivity extends AppCompatActivity {

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        Button btn;
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        btn = (Button) findViewById(R.id.button);
        btn.setOnClickListener(new View.OnClickListener(){
            @Override
            public void onClick(View v){
                compare();
            }
        });

    }
    public void compare()
    {
        final TextView totalCases;
        final  TextView totalDeaths;
        final TextView totalRecovered;

        totalCases = (TextView) findViewById(R.id.TotalCases);
        totalDeaths = (TextView) findViewById(R.id.TotalDeaths);
        totalRecovered = (TextView) findViewById(R.id.TotalRecovered);

        try {
            Document doc = Jsoup.connect(""https://www.worldometers.info/coronavirus/"").userAgent(""mozilla/17.0"").get();
            Elements temp = doc.select(""div.maincounter-number"");


            Element totalcase = temp.get(0);
            String cases = totalcase.select(""div.maincounter-number span"").text();
            totalCases.setText(cases);

            Element totaldeaths = temp.get(1);
            String deaths = totaldeaths.select(""div.maincounter-number span"").text();
            totalDeaths.setText(deaths);

            Element totalrecovered = temp.get(2);
            String recovered = totalrecovered.select(""div.maincounter-number span"").text();
            totalRecovered.setText(recovered);

           /* for(Element totalCase:temp)
            {
                String cases = totalCase.select(""div.maincounter-number span"").text();
                System.out.println("""" + cases);
                *//*i++;
                System.out.println(i + """" + totalCase.getElementsByTag(""span""));*//*
            }*/
        }

        catch (IOException e){
            e.printStackTrace();
        }
    }
}
</code></pre>

<p>image of the app view</p>

<p><a href=""https://i.stack.imgur.com/1ptJv.png"" rel=""nofollow noreferrer"">Image of the app view</a></p>
"
60305188,"<p>I would like to seek some opinion or assistance regarding my code for a heatmap based on the number of Wuhan cases each country has, code as shown below.</p>

<p>Currently, I have stored all country coordinates in a hashmap, and I have scraped out data from <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a> where I stored the country name and number of cases in a CSV file. </p>

<p>I am trying to compare the names of the country from the CSV file with the country name (key) in the hashmap, such that if such country exists plot the ""heat area"" on the map. However, currently, when I am trying to do the comparing by using an if-else statement as shown in my codes. However, the issues I am facing is that if the csv file is missing 1 country and it doesn't match with the hashmap, the code will not run. Only when the csv file contain all country name and it matches with the hashmap then the code will display the application as shown below. How do I go about plotting the ""heat area"" when comparing the country names from the csv file and the hashmap ? </p>

<p><strong>CODE</strong></p>

<pre><code> @Override public void init() {

    //Input the coordinates of the country, based on the size of the javafx.
    //Limitation is the current coordinates are not the entire list of country in the world.
    HashMap&lt;String, List&lt;Integer&gt;&gt; countryCoordinates = new HashMap&lt;&gt;();
    Integer[] coordinates = {};
    countryCoordinates.put(""China"", Arrays.asList(700, 180));
    countryCoordinates.put(""Diamond Princess"", Arrays.asList(810, 170));
    countryCoordinates.put(""Singapore"", Arrays.asList(726, 310));
    countryCoordinates.put(""Japan"", Arrays.asList(810, 170));
    countryCoordinates.put(""Hong Kong"", Arrays.asList(755, 225));
    countryCoordinates.put(""Thailand"", Arrays.asList(720, 250));
    countryCoordinates.put(""S. Korea"", Arrays.asList(780, 170));
    countryCoordinates.put(""Taiwan"", Arrays.asList(775, 220));
    countryCoordinates.put(""Malaysia"", Arrays.asList(725, 300));
    countryCoordinates.put(""Germany"", Arrays.asList(440, 115));
    countryCoordinates.put(""Vietnam"", Arrays.asList(740, 260));
    .
    .
    .

    Reader reader;
    try {
        //Retrieving the data from WorldMap CSV
        reader = Files.newBufferedReader(Paths.get(""C:\\Users\\User\\Desktop\\ICT1009_TESTFILE\\WorldMap.csv""));
        CSVReader csvReader = new CSVReader(reader);
        String[] nextRecord;
        while((nextRecord = csvReader.readNext()) != null) {
            String retrieveCountry = nextRecord[0];
            //Comparing the hashmap key with the country name retrieve from CSV file
            //If the names matches, plot the heat area
            List&lt;Integer&gt; coordinatesOfThisCountry = countryCoordinates.get(retrieveCountry);
            if (coordinatesOfThisCountry != null) {
                    events = new Point2D[] {
                            asPoint2D(countryCoordinates.get(retrieveCountry)),
                    };
            }
        }
    } catch (IOException e) {
        // TODO Auto-generated catch block
        e.printStackTrace();
    }
}
</code></pre>

<p><strong>OUTPUT</strong>
<a href=""https://i.stack.imgur.com/TJzPK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/TJzPK.png"" alt=""enter image description here""></a></p>
"
61548994,"<p>I am fetching JSON Array and trying to show it in a list view. I debugged and got that I recieve the array as required but when i run my list view is blank on android screen. When I run no error is shown in syntax or while in emulator. Here is my code:
I have used volley to call the api and fetch json data.</p>

<p>DashBoard.java</p>

<pre><code>public class Dashboard extends AppCompatActivity {

    private RequestQueue queue;
    ListView listView;
    ArrayList&lt;rowitem&gt; arrayList;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_dashboard);
        queue = Volley.newRequestQueue(this);
        listView = (ListView) findViewById(R.id.myListView);
        arrayList = new ArrayList&lt;&gt;();

        String url = ""https://api.rootnet.in/covid19-in/stats/latest"";

        StringRequest stringRequest = new StringRequest(Request.Method.GET, url,
                new Response.Listener&lt;String&gt;() {
                    @Override
                    public void onResponse(String response) {
                        // Display the first 500 characters of the response string.
                        try {
                            JSONObject result = new JSONObject(response).getJSONObject(""data"");
                            JSONArray jsonArray = result.getJSONArray(""regional"");
                            for(int i=0; i&lt;jsonArray.length(); i++)
                            {
                                JSONObject json_data = jsonArray.getJSONObject(i);
                                String location = json_data.getString(""loc"");
                                String totalcase = json_data.getString(""totalConfirmed"");
                                String recovered = json_data.getString(""discharged"");
                                String deaths = json_data.getString(""deaths"");

                                rowitem model = new rowitem();
                                model.setLocation(location);
                                model.setTotalcase(totalcase);
                                model.setRecovered(recovered);
                                model.setDeaths(deaths);
                                arrayList.add(model);
                            }
                        } catch (JSONException e) {
                            Toast.makeText(Dashboard.this, e.getMessage(), Toast.LENGTH_LONG).show();
                        }
                    }
                }, new Response.ErrorListener() {
            @Override
            public void onErrorResponse(VolleyError error) {
                Toast.makeText(Dashboard.this, ""Server is not responding (Covid-19 Tracker)"", Toast.LENGTH_LONG).show();
            }
        });
        // Add the request to the RequestQueue.
        queue.add(stringRequest);
        customlistviewadapter adapter = new customlistviewadapter(this, arrayList);
        listView.setAdapter(adapter);
    }
}
</code></pre>

<p>customlistviewadapter.java</p>

<pre><code>package com.example.maps;

import android.content.Context;
import android.view.LayoutInflater;
import android.view.ViewGroup;
import android.view.View;
import android.widget.BaseAdapter;
import android.widget.TextView;

import java.util.ArrayList;

public class customlistviewadapter extends BaseAdapter {
    Context context;
    ArrayList&lt;rowitem&gt; arrayList;

    public customlistviewadapter(Context context,ArrayList&lt;rowitem&gt; arrayList) {
        this.context = context;
        this.arrayList = arrayList;
    }

    @Override
    public int getCount() {
        return arrayList.size();
    }

    @Override
    public Object getItem(int position) {
        return arrayList.get(position);
    }

    @Override
    public long getItemId(int i) {
        return i;
    }

    @Override
    public  View getView(final int position, View convertView, ViewGroup parent) {
        if (convertView ==  null) {
            convertView = LayoutInflater.from(context).inflate(R.layout.row, parent, false);
        }
        TextView location, totalcase, recovered, deaths;

        location = (TextView) convertView.findViewById(R.id.location);
        totalcase = (TextView) convertView.findViewById(R.id.cases);
        recovered = (TextView) convertView.findViewById(R.id.healthy);
        deaths = (TextView) convertView.findViewById(R.id.deaths);
        location.setText(arrayList.get(position).getLocation());
        totalcase.setText(arrayList.get(position).getTotalcase());
        recovered.setText(arrayList.get(position).getRecovered());
        deaths.setText(arrayList.get(position).getDeaths());

        return convertView;
    }
}
</code></pre>
"
61290621,"<p>I am making a linechart to show the number of cases of coronavirus in the world.</p>

<pre><code>    private void setLinearChart() {
    lineChart.setDragEnabled(true);
    lineChart.setScaleEnabled(false);
    lineChart.getAxisRight().setEnabled(false);
    lineChart.getXAxis().setTextSize(1f);
    lineChart.getXAxis().setPosition(XAxis.XAxisPosition.BOTTOM);
    lineChart.setVisibleXRange(100, 100);

    lineChart.getAxisLeft().setDrawGridLines(false);
    lineChart.getXAxis().setDrawGridLines(false);
    lineChart.setVisibleXRangeMinimum(100);
    lineChart.setVisibleYRangeMinimum(100, 
    lineChart.getAxisLeft().getAxisDependency());


   caseslist = getCasesList(casesMap);


                LineDataSet casesSet = new LineDataSet(caseslist, ""Cases"");
                casesSet.setFillAlpha(110);

                LineData casesLineData = new LineData(casesSet);
                XAxis xAxis = lineChart.getXAxis();
                xAxis.setValueFormatter(new DateValueFormatter());
                lineChart.setData(casesLineData);
                lineChart.invalidate();

}
</code></pre>

<p>and I am getting a line char like this.<a href=""https://i.stack.imgur.com/PXapx.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PXapx.jpg"" alt=""my linechart""></a></p>

<p>I this line to be a continuous curve like in below pic
<a href=""https://i.stack.imgur.com/JTom0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/JTom0.png"" alt=""example image""></a></p>
"
60761351,"<p>I am trying to download a pdf file from the url using onNext() of Rxjava2. After downloading and storing the file in the folder, I have written the code logic in the oncomplete() to open up the pdfview through intents to show up the pdf to the user. But the onComplete() never gets called. Have used breakpoints as well to check but the compiler doesnt never executes the onComplete().</p>

<p>MainActivity:</p>

<pre><code>        home_quarantine_guidelines.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {

                 observable = Observable.just
                        (""https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf"");

                observable.subscribeOn(Schedulers.io())
                        .observeOn(AndroidSchedulers.mainThread())
                        .subscribe(new DisposableObserver&lt;String&gt;() {
                            @Override
                            public void onNext(String s) {
                                //customProgressDialog.show();

                                String extStorageDirectory = Environment.getExternalStorageDirectory().toString();
                                File folder = new File(extStorageDirectory, ""Intelehealth_COVID_PDF"");
                                folder.mkdir();

                                File pdfFile = new File(folder, ""dummy.pdf"");

                                try{
                                    pdfFile.createNewFile();
                                }catch (IOException e){
                                    e.printStackTrace();
                                }

                                FileDownloader.downloadFile(s, pdfFile);

                            }

                            @Override
                            public void onError(Throwable e) {

                            }

                            @Override
                            public void onComplete() {
                                customProgressDialog.dismiss();

                                File pdfFile = new File
                                        (Environment.getExternalStorageDirectory()
                                                + ""/Intelehealth_COVID_PDF/"" + ""dummy.pdf"");

                    Uri path = FileProvider.getUriForFile
                            (context, context.getApplicationContext().getPackageName()
                                    + "".provider"", pdfFile);
                    Intent pdfIntent = new Intent(Intent.ACTION_VIEW);
                    pdfIntent.setDataAndType(path, ""application/pdf"");
                    pdfIntent.addFlags(Intent.FLAG_GRANT_READ_URI_PERMISSION);
                    pdfIntent.addFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP);
                    pdfIntent.addFlags(Intent.FLAG_GRANT_WRITE_URI_PERMISSION);

                    try{
                        startActivity(pdfIntent);
                    }catch(ActivityNotFoundException e){
                        Toast.makeText(HomeActivity.this, ""No Application available to view PDF"", Toast.LENGTH_SHORT).show();
                    }

                            }
                        });

//                File pdfFile_downloaded = new File(Environment.getExternalStorageDirectory() + ""/Intelehealth_COVID_PDF/"" + ""dummy.pdf"");
//
//                if(pdfFile_downloaded.exists())
//                {
//                    File pdfFile = new File(Environment.getExternalStorageDirectory() + ""/Intelehealth_COVID_PDF/"" + ""dummy.pdf"");  // -&gt; filename = maven.pdf
//                    //Uri path = Uri.fromFile(pdfFile);
//                    Uri path = FileProvider.getUriForFile
//                            (context, context.getApplicationContext().getPackageName()
//                                    + "".provider"", pdfFile);
//                    Intent pdfIntent = new Intent(Intent.ACTION_VIEW);
//                    pdfIntent.setDataAndType(path, ""application/pdf"");
//                    pdfIntent.addFlags(Intent.FLAG_GRANT_READ_URI_PERMISSION);
//                    pdfIntent.addFlags(Intent.FLAG_ACTIVITY_CLEAR_TOP);
//                    pdfIntent.addFlags(Intent.FLAG_GRANT_WRITE_URI_PERMISSION);
//
//                    try{
//                        startActivity(pdfIntent);
//                    }catch(ActivityNotFoundException e){
//                        Toast.makeText(HomeActivity.this, ""No Application available to view PDF"", Toast.LENGTH_SHORT).show();
//                    }
//                }
//                else
//                {
//                    customProgressDialog.show();
//                    new DownloadFile().execute(""https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf"", ""dummy.pdf"");
//                }




            }
        });
</code></pre>

<p>FileDownloaded.class:</p>

<pre><code>public class FileDownloader extends FileProvider {
    private static final int  MEGABYTE = 1024 * 1024;

    public static void downloadFile(String fileUrl, File directory){
        try {

            URL url = new URL(fileUrl);
            HttpURLConnection urlConnection = (HttpURLConnection)url.openConnection();
           // urlConnection.setRequestMethod(""GET"");
          //  urlConnection.setDoOutput(true);
            urlConnection.connect();

            InputStream inputStream = urlConnection.getInputStream();
            FileOutputStream fileOutputStream = new FileOutputStream(directory);
            int totalSize = urlConnection.getContentLength();

            byte[] buffer = new byte[MEGABYTE];
            int bufferLength = 0;
            while((bufferLength = inputStream.read(buffer)) &gt; 0){
                fileOutputStream.write(buffer, 0, bufferLength);
            }
            fileOutputStream.close();
        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (MalformedURLException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
</code></pre>

<blockquote>
  <p>EDIT: When I use AsyncTask, the code executes correctly. But why does
  it not execute/work using RxJava2 ?</p>
</blockquote>
"
61442793,"<p>I am building an android app that displays the COVID19 statistics for India, I am getting the stats in JSON format from <a href=""https://api.covid19india.org/data.json"" rel=""nofollow noreferrer"">https://api.covid19india.org/data.json</a> , this API contains data of individual states too,</p>

<p>Below is the snip of Json array(contains json objects representing each state) that i am requesting</p>

<p><a href=""https://i.stack.imgur.com/sA1rZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/sA1rZ.png"" alt=""enter image description here""></a></p>

<p>as of Now i am displaying the entire data ( all states ) at a time on my screen, However i want to give the state name as the input and display the stats of only that state For eg. in the below image in place of sample i want to write a state name and the stats of that state must be displayed on click of the button.</p>

<p><a href=""https://i.stack.imgur.com/q25oY.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/q25oY.jpg"" alt=""enter image description here""></a></p>

<p>Here is the code of mainActivity.java, I am using Volley Library for fetching data from API</p>

<pre><code>public class MainActivity extends AppCompatActivity {
    private TextView result;
    private RequestQueue mq;
    public String value;
    int flag = 0;
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        result = findViewById(R.id.textView4);
        Button parse = findViewById(R.id.button);

        mq = Volley.newRequestQueue(this);
        EditText text = (EditText)findViewById(R.id.state_ip);
        value = text.getText().toString();

        parse.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                jsonParse(value); 
                **//How do i pass 'value' i.e the state name entered by user to jsonParse**
            }
        });
    }

    private void jsonParse(final String value) {

        Log.d(""val_state"",value);
        String url = ""https://api.covid19india.org/data.json"";
        JsonObjectRequest request = new JsonObjectRequest(Request.Method.GET, url, null,
                new Response.Listener&lt;JSONObject&gt;() {
                    @Override
                    public void onResponse(JSONObject response) {
                        try {
                            JSONArray jsonArray = response.getJSONArray(""statewise"");
                            for (int i = 0; i &lt; jsonArray.length(); i++)
                            {
                                JSONObject st = jsonArray.getJSONObject(i);
                                String statename = st.getString(""state"");
                                String active = st.getString(""active"");
                                String confirmed = st.getString(""confirmed"");
                                String deaths = st.getString(""deaths"");
                                String recovered = st.getString(""recovered"");
                                if(statename.equals(value))
                                {
                                    flag= 1;
                                }

                                statename = ""State : "" + statename;
                                active = ""Active Cases : "" + active;
                                confirmed = ""Confirmed Cases : "" + confirmed;
                                deaths = ""Total Deaths : "" + deaths;
                                recovered = ""Total Recovered : "" + recovered;
                                if(flag==1)
                                {
                                    flag=0;
                                     result.append(statename + ""\n"" + String.valueOf(active) + ""\n"" + String.valueOf(confirmed) + ""\n"" + String.valueOf(deaths) + ""\n"" + String.valueOf(recovered) + ""\n\n\n"");
            } 
                            }
                        } catch (JSONException e) {
                            e.printStackTrace();
                        }
                    }
                }, new Response.ErrorListener() {
            @Override
            public void onErrorResponse(VolleyError error) {
                error.printStackTrace();
            }
        });
        mq.add(request);
    }
}
</code></pre>

<p>Here , i want to pass the value of state entered by the user to the method jsonParse() so that i check the state name with the received JSON data and append it to the TextView, but when i do this , and try to log the value inside the jsonParse() method i get nothing, why is this happening , How do i implement the above ?</p>
"
60573532,"<p>I'm trying to get some data from <code>JSON</code> below using <strong>Retrofit</strong>: </p>

<pre><code>[
  {
    ""country"": ""China"",
    ""cases"": 80650,
    ""todayCases"": 98,
    ""deaths"": 3070,
    ""todayDeaths"": 28,
    ""recovered"": 55402,
    ""critical"": 5737
  },
  {
    ""country"": ""S. Korea"",
    ""cases"": 6593,
    ""todayCases"": 309,
    ""deaths"": 43,
    ""todayDeaths"": 1,
    ""recovered"": 135,
    ""critical"": 52
  }
....
]
</code></pre>

<p>I've tried the below code without success : </p>

<p><strong>Interface</strong> :</p>

<pre><code>public interface CoronaInterface {
    @GET(""all"")
    public Call&lt;Resume&gt; getCoronaVirusResumeInformation();

    @GET(""countries"")
    public Call&lt;Complete&gt; getCoronaVirusCompleteInformation();
}
</code></pre>

<p><strong>Models</strong></p>

<pre><code>public class Data {
    @SerializedName(""country"")
    private String country;
    @SerializedName(""recovered"")
    private String recovered;
    @SerializedName(""cases"")
    private String cases;
    @SerializedName(""critical"")
    private String critical;
    @SerializedName(""deaths"")
    private String deaths;
    @SerializedName(""todayCases"")
    private String todayCases;
    @SerializedName(""todayDeaths"")
    private String todayDeaths;

    public String getCountry() {
        return country;
    }

    public String getRecovered() {
        return recovered;
    }

    public String getCases() {
        return cases;
    }

    public String getCritical() {
        return critical;
    }

    public String getDeaths() {
        return deaths;
    }

    public String getTodayCases() {
        return todayCases;
    }

    public String getTodayDeaths() {
        return todayDeaths;
    }

}


public class Complete {
    private Data[] mData;

    public Data[] getData() {
        return mData;
    }

    public void setData(Data[] mData) {
        this.mData = mData;
    }
}
</code></pre>

<p><strong>MainActivity :</strong> </p>

<pre><code>mCallComplete = mCoronaInterface.getCoronaVirusCompleteInformation();
    mCallComplete.enqueue(new Callback&lt;Complete&gt;() {
        @Override
        public void onResponse(@NonNull Call&lt;Complete&gt; call, @NonNull Response&lt;Complete&gt; response) {

        }

        @Override
        public void onFailure(@NonNull Call&lt;Complete&gt; call, @NonNull Throwable t) {
            Toast.makeText(MainActivity.this, ""ops"", Toast.LENGTH_SHORT).show();
        }
    });
</code></pre>

<p><strong>My issue:</strong> I always get <strong>ops</strong> message at runtime.</p>
"
61011655,"<p>Im having problem loading my AppLayout addon UI in production. I don't know what happened but this app has already been deployed to server for several times until this time that I have to test something. previous config wont work anymore, so I tried other config but failed.</p>

<p>This is my application.properties</p>

<pre><code>server.port=3000
# Ensure application is run in Vaadin 14/npm mode
vaadin.productionMode=true
#vaadin.compatibilityMode = false
logging.level.org.atmosphere = warn
</code></pre>

<p>And this is my POM</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;&lt;project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd""&gt;
&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
&lt;groupId&gt;com.main.app&lt;/groupId&gt;
&lt;artifactId&gt;webex-event-management&lt;/artifactId&gt;
&lt;name&gt;webex-event-management&lt;/name&gt;
&lt;version&gt;2.0-SNAPSHOT&lt;/version&gt;
&lt;packaging&gt;jar&lt;/packaging&gt;

&lt;properties&gt;
    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;
    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;
    &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;
    &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;

    &lt;!--&lt;vaadin.version&gt;14.0.15&lt;/vaadin.version&gt;--&gt;
    &lt;vaadin.version&gt;14.1.17&lt;/vaadin.version&gt;

    &lt;drivers.dir&gt;${project.basedir}/drivers&lt;/drivers.dir&gt;
    &lt;drivers.downloader.phase&gt;pre-integration-test&lt;/drivers.downloader.phase&gt;
&lt;/properties&gt;

&lt;parent&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
    &lt;version&gt;2.1.7.RELEASE&lt;/version&gt;
&lt;/parent&gt;

&lt;pluginRepositories&gt;
    &lt;pluginRepository&gt;
        &lt;id&gt;central&lt;/id&gt;
        &lt;url&gt;https://repo1.maven.org/maven2/&lt;/url&gt;
        &lt;snapshots&gt;&lt;enabled&gt;false&lt;/enabled&gt;&lt;/snapshots&gt;
    &lt;/pluginRepository&gt;
&lt;/pluginRepositories&gt;

&lt;repositories&gt;
    &lt;repository&gt;
        &lt;id&gt;central&lt;/id&gt;
        &lt;url&gt;https://repo1.maven.org/maven2/&lt;/url&gt;
        &lt;snapshots&gt;&lt;enabled&gt;false&lt;/enabled&gt;&lt;/snapshots&gt;
    &lt;/repository&gt;
    &lt;!-- Repository used by many Vaadin add-ons --&gt;
    &lt;repository&gt;
        &lt;id&gt;Vaadin Directory&lt;/id&gt;
        &lt;url&gt;https://maven.vaadin.com/vaadin-addons&lt;/url&gt;
        &lt;snapshots&gt;&lt;enabled&gt;false&lt;/enabled&gt;&lt;/snapshots&gt;
    &lt;/repository&gt;
&lt;/repositories&gt;

&lt;dependencyManagement&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
            &lt;artifactId&gt;vaadin-bom&lt;/artifactId&gt;
            &lt;version&gt;${vaadin.version}&lt;/version&gt;
            &lt;type&gt;pom&lt;/type&gt;
            &lt;scope&gt;import&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
&lt;/dependencyManagement&gt;

&lt;dependencies&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
        &lt;!-- Replace artifactId with vaadin-core to use only free components --&gt;
        &lt;artifactId&gt;vaadin&lt;/artifactId&gt;
        &lt;exclusions&gt;
            &lt;!-- Webjars are only needed when running in Vaadin 13 compatibility mode --&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;com.vaadin.webjar&lt;/groupId&gt;
                &lt;artifactId&gt;*&lt;/artifactId&gt;
            &lt;/exclusion&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;org.webjars.bowergithub.insites&lt;/groupId&gt;
                &lt;artifactId&gt;*&lt;/artifactId&gt;
            &lt;/exclusion&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;org.webjars.bowergithub.polymer&lt;/groupId&gt;
                &lt;artifactId&gt;*&lt;/artifactId&gt;
            &lt;/exclusion&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;org.webjars.bowergithub.polymerelements&lt;/groupId&gt;
                &lt;artifactId&gt;*&lt;/artifactId&gt;
            &lt;/exclusion&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;org.webjars.bowergithub.vaadin&lt;/groupId&gt;
                &lt;artifactId&gt;*&lt;/artifactId&gt;
            &lt;/exclusion&gt;
            &lt;exclusion&gt;
                &lt;groupId&gt;org.webjars.bowergithub.webcomponents&lt;/groupId&gt;
                &lt;artifactId&gt;*&lt;/artifactId&gt;
            &lt;/exclusion&gt;
        &lt;/exclusions&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
        &lt;artifactId&gt;vaadin-spring-boot-starter&lt;/artifactId&gt;
        &lt;exclusions&gt;
            &lt;!-- Excluding so that webjars are not included. --&gt;
            &lt;exclusion&gt;&lt;groupId&gt;com.vaadin&lt;/groupId&gt;
                &lt;artifactId&gt;vaadin-core&lt;/artifactId&gt;&lt;/exclusion&gt;
        &lt;/exclusions&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;
        &lt;optional&gt;true&lt;/optional&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;mysql&lt;/groupId&gt;
        &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
        &lt;version&gt;6.0.6&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;
        &lt;artifactId&gt;gson&lt;/artifactId&gt;
        &lt;version&gt;2.8.5&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.googlecode.json-simple&lt;/groupId&gt;
        &lt;artifactId&gt;json-simple&lt;/artifactId&gt;
        &lt;version&gt;1.1.1&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.commons&lt;/groupId&gt;
        &lt;artifactId&gt;commons-email&lt;/artifactId&gt;
        &lt;version&gt;1.4&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.fasterxml.jackson.dataformat&lt;/groupId&gt;
        &lt;artifactId&gt;jackson-dataformat-xml&lt;/artifactId&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt;
        &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;
        &lt;version&gt;2.9.8&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
        &lt;artifactId&gt;vaadin-select-flow&lt;/artifactId&gt;
        &lt;version&gt;1.0.0.beta1&lt;/version&gt;
        &lt;type&gt;jar&lt;/type&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.vaadin.marcus&lt;/groupId&gt;
        &lt;artifactId&gt;shortcut&lt;/artifactId&gt;
        &lt;version&gt;0.3.0&lt;/version&gt;
        &lt;type&gt;jar&lt;/type&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
        &lt;artifactId&gt;vaadin-accordion-flow&lt;/artifactId&gt;
        &lt;version&gt;1.0.3&lt;/version&gt;
        &lt;type&gt;jar&lt;/type&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;exclusions&gt;
            &lt;exclusion&gt;
              &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
              &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt;
            &lt;/exclusion&gt;
        &lt;/exclusions&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.github.appreciated&lt;/groupId&gt;
        &lt;artifactId&gt;apexcharts&lt;/artifactId&gt;
        &lt;version&gt;2.0.0.beta5&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.postgresql&lt;/groupId&gt;
        &lt;artifactId&gt;postgresql&lt;/artifactId&gt;
        &lt;version&gt;42.2.5&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;!-- https://mvnrepository.com/artifact/org.apache.poi/poi --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.poi&lt;/groupId&gt;
        &lt;artifactId&gt;poi&lt;/artifactId&gt;
        &lt;version&gt;4.1.1&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;!-- https://mvnrepository.com/artifact/org.apache.poi/poi-ooxml --&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.apache.poi&lt;/groupId&gt;
        &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt;
        &lt;version&gt;4.1.1&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.github.appreciated&lt;/groupId&gt;
        &lt;artifactId&gt;app-layout-addon&lt;/artifactId&gt;
        &lt;version&gt;4.0.0.rc4&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;org.vaadin.helper&lt;/groupId&gt;
        &lt;artifactId&gt;async-manager&lt;/artifactId&gt;
        &lt;version&gt;1.1.0-alpha1&lt;/version&gt;
    &lt;/dependency&gt;
    &lt;dependency&gt;
        &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
        &lt;artifactId&gt;vaadin-testbench&lt;/artifactId&gt;
        &lt;scope&gt;test&lt;/scope&gt;
    &lt;/dependency&gt;
&lt;/dependencies&gt;

&lt;build&gt;
    &lt;finalName&gt;webex-event&lt;/finalName&gt;
    &lt;defaultGoal&gt;spring-boot:run&lt;/defaultGoal&gt;
    &lt;plugins&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;configuration&gt;
                &lt;executable&gt;true&lt;/executable&gt;
            &lt;/configuration&gt;
        &lt;/plugin&gt;

        &lt;!--
            Take care of synchronizing java dependencies and imports in
            package.json and main.js files.
            It also creates webpack.config.js if not exists yet.
        --&gt;
        &lt;plugin&gt;
            &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
            &lt;artifactId&gt;vaadin-maven-plugin&lt;/artifactId&gt;
            &lt;version&gt;${vaadin.version}&lt;/version&gt;
            &lt;executions&gt;
                &lt;execution&gt;
                    &lt;goals&gt;
                        &lt;goal&gt;prepare-frontend&lt;/goal&gt;
                    &lt;/goals&gt;
                &lt;/execution&gt;
            &lt;/executions&gt;
        &lt;/plugin&gt;
    &lt;/plugins&gt;
&lt;/build&gt;

&lt;profiles&gt;
    &lt;profile&gt;
        &lt;!-- Production mode is activated using -Pproduction --&gt;
        &lt;id&gt;production&lt;/id&gt;
        &lt;properties&gt;
            &lt;vaadin.productionMode&gt;true&lt;/vaadin.productionMode&gt;
        &lt;/properties&gt;

        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
                &lt;artifactId&gt;flow-server-production-mode&lt;/artifactId&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;

        &lt;build&gt;
            &lt;plugins&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                    &lt;configuration&gt;
                        &lt;jvmArguments&gt;-Dvaadin.productionMode&lt;/jvmArguments&gt;
                    &lt;/configuration&gt;
                &lt;/plugin&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;com.vaadin&lt;/groupId&gt;
                    &lt;artifactId&gt;vaadin-maven-plugin&lt;/artifactId&gt;
                    &lt;executions&gt;
                        &lt;execution&gt;
                            &lt;goals&gt;
                                &lt;!--&lt;goal&gt;prepare-frontend&lt;/goal&gt;--&gt;
                                &lt;goal&gt;build-frontend&lt;/goal&gt;
                            &lt;/goals&gt;
                            &lt;phase&gt;compile&lt;/phase&gt;
                        &lt;/execution&gt;
                    &lt;/executions&gt;
                &lt;/plugin&gt;
            &lt;/plugins&gt;
        &lt;/build&gt;
    &lt;/profile&gt;

    &lt;profile&gt;
        &lt;id&gt;integration-tests&lt;/id&gt;
        &lt;build&gt;
            &lt;plugins&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                    &lt;executions&gt;
                        &lt;execution&gt;
                            &lt;id&gt;start-spring-boot&lt;/id&gt;
                            &lt;phase&gt;pre-integration-test&lt;/phase&gt;
                            &lt;goals&gt;
                                &lt;goal&gt;start&lt;/goal&gt;
                            &lt;/goals&gt;
                        &lt;/execution&gt;
                        &lt;execution&gt;
                            &lt;id&gt;stop-spring-boot&lt;/id&gt;
                            &lt;phase&gt;post-integration-test&lt;/phase&gt;
                            &lt;goals&gt;
                                &lt;goal&gt;stop&lt;/goal&gt;
                            &lt;/goals&gt;
                        &lt;/execution&gt;
                    &lt;/executions&gt;
                &lt;/plugin&gt;

                &lt;!-- Runs the integration tests (*IT) after the server is started --&gt;
                &lt;plugin&gt;
                    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
                    &lt;artifactId&gt;maven-failsafe-plugin&lt;/artifactId&gt;
                    &lt;executions&gt;
                        &lt;execution&gt;
                            &lt;goals&gt;
                                &lt;goal&gt;integration-test&lt;/goal&gt;
                                &lt;goal&gt;verify&lt;/goal&gt;
                            &lt;/goals&gt;
                        &lt;/execution&gt;
                    &lt;/executions&gt;
                    &lt;configuration&gt;
                        &lt;trimStackTrace&gt;false&lt;/trimStackTrace&gt;
                        &lt;enableAssertions&gt;true&lt;/enableAssertions&gt;
                        &lt;systemPropertyVariables&gt;
                            &lt;!-- Pass location of downloaded webdrivers to the tests --&gt;
                            &lt;webdriver.chrome.driver&gt;${webdriver.chrome.driver}&lt;/webdriver.chrome.driver&gt;
                        &lt;/systemPropertyVariables&gt;
                    &lt;/configuration&gt;
                &lt;/plugin&gt;

                &lt;plugin&gt;
                    &lt;groupId&gt;com.lazerycode.selenium&lt;/groupId&gt;
                    &lt;artifactId&gt;driver-binary-downloader-maven-plugin&lt;/artifactId&gt;
                    &lt;version&gt;1.0.17&lt;/version&gt;
                    &lt;configuration&gt;
                        &lt;onlyGetDriversForHostOperatingSystem&gt;true
                        &lt;/onlyGetDriversForHostOperatingSystem&gt;
                        &lt;rootStandaloneServerDirectory&gt;
                            ${project.basedir}/drivers/driver
                        &lt;/rootStandaloneServerDirectory&gt;
                        &lt;downloadedZipFileDirectory&gt;
                            ${project.basedir}/drivers/driver_zips
                        &lt;/downloadedZipFileDirectory&gt;
                        &lt;customRepositoryMap&gt;
                            ${project.basedir}/drivers.xml
                        &lt;/customRepositoryMap&gt;
                    &lt;/configuration&gt;
                    &lt;executions&gt;
                        &lt;execution&gt;
                            &lt;!-- use phase ""none"" to skip download step --&gt;
                            &lt;phase&gt;${drivers.downloader.phase}&lt;/phase&gt;
                            &lt;goals&gt;
                                &lt;goal&gt;selenium&lt;/goal&gt;
                            &lt;/goals&gt;
                        &lt;/execution&gt;
                    &lt;/executions&gt;
                &lt;/plugin&gt;
            &lt;/plugins&gt;
        &lt;/build&gt;
    &lt;/profile&gt;

&lt;/profiles&gt;
</code></pre>

<p></p>

<p>already tried running it using</p>

<pre><code>java -jar -Dvaadin.productionMode=true my-jar.jar 
</code></pre>

<p>But still wont work. I already have run out of ideas and currently working for a covid case tracker app with the same problem. Please help guys.</p>

<p><a href=""https://i.stack.imgur.com/60DLX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/60DLX.png"" alt=""enter image description here""></a></p>
"
60810617,"<p>I am writing a GSON (Java) parser for the CORD19 dataset
<a href=""https://pages.semanticscholar.org/coronavirus-research"" rel=""nofollow noreferrer"">https://pages.semanticscholar.org/coronavirus-research</a> of about 40K scientific papers which have been made open for everyone. I want to iterate over the JSON tree using GSON and convert them to HTML. In particular I want to iterate over the entries of the JsonObject elements.</p>

<p>Q1: If anyone has already written an F/OSS CORD19 parser in GSON or other Java parser I'd be delighted.</p>

<p>My specific problem is to iterate over the fields (entries) of a JsonObject.</p>

<p>Data (heavily snipped, but hopefully parsable if snips removed):</p>

<pre><code>{
    ""paper_id"": ""b801b7f92cff2155d98f0e3404229c67b60e2f9f"",
    ""metadata"": {
        ""title"": ""Realtime 2-5A kinetics suggests interferons \u03b2 and \uf06c evade global arrest of translation by RNase L"",
        ""authors"": [
            {
                ""first"": ""Alisha"",
                ""middle"": [],
                ""last"": ""Chitrakar"",
                ""suffix"": """",
                ""affiliation"": {},
                ""email"": """"
            },
            ... SNIPPED
            {
                ""first"": ""Alexei"",
                ""middle"": [],
                ""last"": ""Korennykh"",
                ""suffix"": """",
                ""affiliation"": {},
                ""email"": ""akorenny@princeton.edu""
            }
        ]
    },
    ""abstract"": [
        {
            ""text"": ""Cells of all mammals recognize double-stranded RNA (dsRNA) as a foreign material. ..."",
            ""cite_spans"": [],
            ""ref_spans"": [],
            ""section"": ""Abstract""
        },
... SNIPPED
        {
            ""text"": ""The 2-5A system is also a surveillance pathway for ..."",
            ""cite_spans"": [],
            ""ref_spans"": [],
            ""section"": ""Abstract""
        }
    ],
    ""body_text"": [
        {
            ""text"": ""Interferons IFNs of type I (\uf061 and \u03b2) and type III ..."",
            ""cite_spans"": [],
            ""ref_spans"": [],
            ""section"": ""Introduction""
        },
        {
            ""text"": ""To evaluate how the nuclear envelope ..."",
            ""cite_spans"": [
                {
                    ""start"": 382,
                    ""end"": 384,
                    ""text"": ""50"",
                    ""ref_id"": null
                }
            ],
            ""ref_spans"": [],
            ""section"": ""Diffusion calculations""
        }
    ],
    ""bib_entries"": {
        ""BIBREF0"": {
            ""ref_id"": ""b0"",
            ""title"": ""Higher-order substrate recognition of eIF2alpha by the RNA-dependent protein kinase PKR"",
            ""authors"": [
                {
                    ""first"": ""A"",
                    ""middle"": [
                        ""C""
                    ],
                    ""last"": ""Dar"",
                    ""suffix"": """"
                },
... SNIPPED
                {
                    ""first"": ""F"",
                    ""middle"": [],
                    ""last"": ""Sicheri"",
                    ""suffix"": """"
                }
            ],
            ""year"": 2005,
            ""venue"": ""Cell"",
            ""volume"": ""122"",
            ""issn"": """",
            ""pages"": ""887--900"",
            ""other_ids"": {}
        },
        ""BIBREF1"": {
            ""ref_id"": ""b1"",
            ""title"": ""Increased nuclease activity in cells treated with pppA2'p5'A2'p5' A"",
            ""authors"": [
                {
                    ""first"": ""A"",
                    ""middle"": [
                        ""G""
                    ],
                    ""last"": ""Hovanessian"",
                    ""suffix"": """"
                },
                ... SNIPPED
                {
                    ""first"": ""L"",
                    ""middle"": [],
                    ""last"": ""Montagnier"",
                    ""suffix"": """"
                }
            ],
            ""year"": 1979,
            ""venue"": ""Proc Natl Acad Sci U S A"",
            ""volume"": ""76"",
            ""issn"": """",
            ""pages"": ""3261--3266"",
            ""other_ids"": {}
        },
        ""BIBREF2"": {
            ""ref_id"": ""b2"",
            ""title"": ""Interferon action--sequence specificity of the ppp(A2'p)nA-dependent ribonuclease"",
            ""authors"": [
                {
                    ""first"": ""D"",
                    ""middle"": [
                        ""H""
                    ],
                    ""last"": ""Wreschner"",
                    ""suffix"": """"
                },
                ... SNIPPED
                {
                    ""first"": ""I"",
                    ""middle"": [
                        ""M""
                    ],
                    ""last"": ""Kerr"",
                    ""suffix"": """"
                }
            ],
            ""year"": 1981,
            ""venue"": ""Nature"",
            ""volume"": ""289"",
            ""issn"": """",
            ""pages"": ""414--421"",
            ""other_ids"": {}
        },
        ... SNIPPED
        ""BIBREF47"": {
            ""ref_id"": ""b47"",
            ""title"": ""Size-dependent DNA mobility in cytoplasm and nucleus"",
            ""authors"": [
                {
                    ""first"": ""G"",
                    ""middle"": [
                        ""L""
                    ],
                    ""last"": ""Lukacs"",
                    ""suffix"": """"
                }
            ],
            ""year"": 2000,
            ""venue"": ""J Biol Chem"",
            ""volume"": ""275"",
            ""issn"": """",
            ""pages"": ""1625--1634"",
            ""other_ids"": {}
        },
        ""BIBREF48"": {
            ""ref_id"": ""b48"",
            ""title"": ""Modeling transmembrane transport through cell membrane wounds created by acoustic cavitation"",
            ""authors"": [
                {
                    ""first"": ""V"",
                    ""middle"": [],
                    ""last"": ""Zarnitsyn"",
                    ""suffix"": """"
                },
                ... SNIPPED
                {
                    ""first"": ""M"",
                    ""middle"": [
                        ""R""
                    ],
                    ""last"": ""Prausnitz"",
                    ""suffix"": """"
                }
            ],
            ""year"": 2008,
            ""venue"": ""Biophys J"",
            ""volume"": ""95"",
            ""issn"": """",
            ""pages"": ""4124--4162"",
            ""other_ids"": {}
        }
    },
    ... SNIPPED
    ""back_matter"": [
        {
            ""text"": ""We are grateful to Prof. Bonnie Bassler (Princeton University) for All NS All NS NS ** All ****"",
            ""cite_spans"": [],
            ""ref_spans"": [],
            ""section"": ""Acknowledgments:""
        }
    ]
}
</code></pre>

<p>There is a schema on the CORD-19 site, but entries such as <code>BIBREF1 ... BIBREF48</code> vary in number over each data set.
(Q what is the precise name for a <code>BIBREF</code> object - entry? Child?)</p>

<p>My current code is:</p>

<pre><code>    @Test
    public void testReadJSON() {

        File jsonFile = new File(BIORXIV_MEDRXIV, ""b801b7f92cff2155d98f0e3404229c67b60e2f9f.json"");
        JsonObject oo = null;
        try {
            String resultsJsonString = IOUtils.toString(new FileInputStream(jsonFile), ""UTF-8"");
            JsonParser parser = new JsonParser();
            oo = (JsonObject) parser.parse(resultsJsonString);

        } catch (Exception e) {
            throw new RuntimeException(""Cannot read CORD19 file: ""+jsonFile, e);
        }

        String paperId = oo.get(""paper_id"").getAsString();
        System.out.println(""id: ""+paperId);

        JsonElement metadata = oo.get(""metadata"");
        JsonObject metadataObject = metadata.getAsJsonObject();
        String title = metadataObject.get(""title"").getAsString();
        System.out.println(""title: ""+title);

        JsonElement authorsObject = metadataObject.get(""authors"");
        System.out.println(""Auth: ""+authorsObject);
        JsonArray authors = authorsObject.getAsJsonArray();
        for (int i = 0; i &lt; authors.size(); i++) {
            System.out.println(authors.get(i));
        }

        JsonElement abstrakt = oo.get(""abstract"");
        System.out.println(""abstract: ""+abstrakt);
        JsonArray texts = abstrakt.getAsJsonArray();
        for (int i = 0; i &lt; texts.size(); i++) {
            System.out.println(texts.get(i));
        }

        JsonElement bodyText = oo.get(""body_text"");
        System.out.println(""bodyText: ""+bodyText);
        texts = bodyText.getAsJsonArray();
        for (int i = 0; i &lt; texts.size(); i++) {
            System.out.println(texts.get(i));
        }

        JsonElement bibEntries = oo.get(""bib_entries"");
        System.out.println(""bibEntries: ""+bibEntries.getClass()+bibEntries);
        JsonObject obj = bibEntries.getAsJsonObject();
        // WHAT TO WRITE HERE?

    }

}
</code></pre>

<p>(Additional Q. I am learning Java8 so would appreciate answers in Java8 streams as well as Java7)</p>

<p>(Additional Q.
[I would not normally ""advertise"" on Stack Overflow, but these are not normal times, and think this will help save lives, and provide opportunities for Stack Overflow members to contribute skills]
I have set up volunteer projects to hack this dataset. I have had many years of extracting knowledge from scientific papers and believe that the existing papers may contain valuable pointers to new scientific knowledge.</p>

<ul>
<li>A GitHub project at <a href=""https://github.com/petermr/openVirus"" rel=""nofollow noreferrer"">https://github.com/petermr/openVirus</a></li>
<li>A Wikimedia project at <a href=""https://en.wikiversity.org/wiki/WikiJournal_Preprints/Aggregation_of_scholarly_publications_and_extracted_knowledge_on_COVID19_and_epidemics"" rel=""nofollow noreferrer"">https://en.wikiversity.org/wiki/WikiJournal_Preprints/Aggregation_of_scholarly_publications_and_extracted_knowledge_on_COVID19_and_epidemics</a> using Wikidata to annotate articles.</li>
</ul>

<p>Also - does Stack Overflow have a way of collecting expertise that can be re-used specifically for COVID-19?</p>
"
61381580,"<p>Iam developing an android application where I am trying to show notifications when a particular time is set.</p>

<p>I can see that there is an error coming which says that </p>

<blockquote>
  <p>""Failed to post notification on channel null""</p>
</blockquote>

<p>I have attached the code for reference.
This is WorkReminder.java</p>

<h2>WorkReminder.java</h2>

<pre><code>    public class WorkReminder extends AppCompatActivity implements View.OnClickListener{

    private int notificationId = 1;
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_work_reminder);
        getSupportActionBar().setTitle(""Create reminders"");
        getSupportActionBar().setDisplayHomeAsUpEnabled(true);
        getSupportActionBar().setDisplayShowHomeEnabled(true);

        findViewById(R.id.set_button).setOnClickListener(this);
        findViewById(R.id.cancel_button).setOnClickListener(this);
    }

    @Override
    public void onClick(View v) {
        EditText reminder = findViewById(R.id.reminder_text);
        TimePicker timePicker = findViewById(R.id.timePicker);

        // Set notificationId &amp; text.
        Intent intent = new Intent(WorkReminder.this, AlarmReceiver.class);
        intent.putExtra(""notificationId"", notificationId);
        intent.putExtra(""todo"", reminder.getText().toString());

        // getBroadcast(context, requestCode, intent, flags)
        PendingIntent alarmIntent = PendingIntent.getBroadcast(WorkReminder.this, 0,
                intent, PendingIntent.FLAG_CANCEL_CURRENT);

        AlarmManager alarm = (AlarmManager) getSystemService(ALARM_SERVICE);

        switch (v.getId()) {
            case R.id.set_button:
                int hour = timePicker.getCurrentHour();
                int minute = timePicker.getCurrentMinute();

                // Create time.
                Calendar startTime = Calendar.getInstance();
                startTime.set(Calendar.HOUR_OF_DAY, hour);
                startTime.set(Calendar.MINUTE, minute);
                startTime.set(Calendar.SECOND, 0);
                long alarmStartTime = startTime.getTimeInMillis();

                // Set alarm.
                // set(type, milliseconds, intent)
                alarm.set(AlarmManager.RTC_WAKEUP, alarmStartTime, alarmIntent);

                Toast.makeText(this, ""Done!"", Toast.LENGTH_SHORT).show();
                break;

            case R.id.cancel_button:
                alarm.cancel(alarmIntent);
                Toast.makeText(this, ""Canceled."", Toast.LENGTH_SHORT).show();
                break;
        }
    }
}
</code></pre>

<p>This is the AlarmReceiver.java</p>

<h2>AlarmReceiver.java</h2>

<pre><code>public class AlarmReceiver extends BroadcastReceiver {
    @Override
    public void onReceive(Context context, Intent intent) {
        // Get id &amp; message from intent.
        int notificationId = intent.getIntExtra(""notificationId"", 0);
        String message = intent.getStringExtra(""todo"");

        // When notification is tapped, call MainActivity.
        Intent mainIntent = new Intent(context, MainActivity.class);
        PendingIntent contentIntent = PendingIntent.getActivity(context, 0, mainIntent, 0);

        NotificationManager myNotificationManager =
                (NotificationManager) context.getSystemService(Context.NOTIFICATION_SERVICE);

        // Prepare notification.
        Notification.Builder builder = new Notification.Builder(context);
        builder.setSmallIcon(android.R.drawable.ic_dialog_info)
                .setContentTitle(""Reminder!"")
                .setContentText(message)
                .setWhen(System.currentTimeMillis())
                .setAutoCancel(true)
                .setContentIntent(contentIntent)
                .setPriority(Notification.PRIORITY_MAX)
                .setDefaults(Notification.DEFAULT_ALL);

        // Notify
        myNotificationManager.notify(notificationId, builder.build());
    }
}
</code></pre>

<p>This is the activity_work_reminder.xml</p>

<h1>activity_work_reminder.xml</h1>

<pre><code>    &lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;ScrollView xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    xmlns:tools=""http://schemas.android.com/tools""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    tools:context="".WorkReminder""&gt;

    &lt;androidx.constraintlayout.widget.ConstraintLayout
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""&gt;

        &lt;TextView
            android:id=""@+id/reminder_header""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""4dp""
            android:gravity=""center_horizontal""
            android:lineSpacingExtra=""3dp""
            android:text=""Staying hygiene is more important during COVID - 19. Ensure your safety by creating simple reminders to keep you noted.""
            android:textAlignment=""center""
            android:textColor=""#000""
            android:textSize=""18dp""
            app:layout_constraintEnd_toEndOf=""parent""
            app:layout_constraintHorizontal_bias=""0.0""
            app:layout_constraintStart_toStartOf=""parent""
            app:layout_constraintTop_toTopOf=""parent"" /&gt;

        &lt;EditText
            android:id=""@+id/reminder_text""
            android:layout_width=""300dp""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""28dp""
            android:background=""@drawable/corner_edges""
            android:ems=""10""
            android:hint=""Reminder""
            android:inputType=""textPersonName""
            android:padding=""15dp""
            android:textColor=""#000""
            app:layout_constraintEnd_toEndOf=""parent""
            app:layout_constraintHorizontal_bias=""0.18""
            app:layout_constraintStart_toStartOf=""parent""
            app:layout_constraintTop_toBottomOf=""@+id/reminder_header"" /&gt;

        &lt;TimePicker
            android:id=""@+id/timePicker""
            android:layout_width=""300dp""
            android:layout_height=""400dp""
            android:layout_marginTop=""32dp""
            app:layout_constraintEnd_toEndOf=""parent""
            app:layout_constraintHorizontal_bias=""0.495""
            app:layout_constraintStart_toStartOf=""parent""
            app:layout_constraintTop_toBottomOf=""@+id/reminder_text"" /&gt;

        &lt;Button
            android:id=""@+id/set_button""
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""48dp""
            android:text=""set reminder""
            android:padding=""12dp""
            android:background=""@drawable/corner_edges""
            app:layout_constraintEnd_toStartOf=""@+id/cancel_button""
            app:layout_constraintHorizontal_bias=""0.603""
            app:layout_constraintStart_toStartOf=""parent""
            app:layout_constraintTop_toBottomOf=""@+id/timePicker"" /&gt;

        &lt;Button
            android:id=""@+id/cancel_button""
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""48dp""
            android:layout_marginEnd=""76dp""
            android:layout_marginRight=""76dp""
            android:text=""cancel""
            android:padding=""12dp""
            android:background=""@drawable/corner_edges""
            app:layout_constraintEnd_toEndOf=""parent""
            app:layout_constraintTop_toBottomOf=""@+id/timePicker"" /&gt;
    &lt;/androidx.constraintlayout.widget.ConstraintLayout&gt;
&lt;/ScrollView&gt;
</code></pre>

<p>Suggest me a method to show notifications.</p>
"
61109412,"<p>In order to accede to my JSON data below :</p>

<pre><code>[{""id"":""1"",""code"":""2020-04-05-20:12:12"",""cases"":""313"",""recovered"":""34"",""deaths"":""6"",""datesituation"":""2020-04-08"",""timesituation"":""16:35:00""}]
</code></pre>

<p>I have use thi code below :</p>

<pre><code>private void getGhanaSituation() {

        dataBaseHelper.deleteGhana();
        JsonArrayRequest req = new JsonArrayRequest(""MyURL"",
                new Response.Listener&lt;JSONArray&gt;() {
                    @Override
                    public void onResponse(JSONArray response) {

                        try {

                            for (int i = 0; i &lt; response.length(); i++) {

                                JSONObject ghsituation = (JSONObject) response.get(i);

                                int cases = ghsituation.getInt(""cases"");
                                int recovered = ghsituation.getInt(""recovered"");
                                int deaths = ghsituation.getInt(""deaths"");
                                String datesituation = ghsituation.getString(""datesituation"");
                                String timesituation = ghsituation.getString(""timesituation"");
                            }

                        } catch (JSONException e) {
                            e.printStackTrace();
                            Toast.makeText(getApplicationContext(),
                                    ""Error: "" + e.getMessage(),
                                    Toast.LENGTH_LONG).show();
                        }

                        hidepDialog();

                    }
                }, new Response.ErrorListener() {
            @Override
            public void onErrorResponse(VolleyError error) {
                VolleyLog.d(""TAG"", ""Error: "" + error.getMessage());
                Toast.makeText(getApplicationContext(), ""Error""+error.getMessage(), Toast.LENGTH_SHORT).show();
                hidepDialog();
            }
        });

        VolleySingleton.getInstance(getApplicationContext()).addToRequestQueue(req);
    }
</code></pre>

<p>And now i used an API which give me an other format below :</p>

<pre><code>{""ghana"":{""existing"":""273"",""confirmed"":""313"",""recovered"":""34"",""deaths"":""6"",""date"":""08th April, 2020"",""time"":""16:35""},""global"":{""existing"":""1,066,963"",""confirmed"":""1,468,891"",""recovered"":""316,482"",""deaths"":""85,446"",""date"":""08th April, 2020"",""time"":""16:35""}}
</code></pre>

<p>I changed my code :</p>

<pre><code>private void getGhanaSituation() {

        dataBaseHelper.deleteGhana();
        JsonArrayRequest req = new JsonArrayRequest(""https://mazitekgh.com/covid19/v1/"",
                new Response.Listener&lt;JSONArray&gt;() {
                    @Override
                    public void onResponse(JSONArray response) {

                        try {

                            for (int i = 0; i &lt; response.length(); i++) {

                                JSONObject ghsituation = (JSONObject) response.get(i);

                                int cases = ghsituation.getInt(""confirmed"");
                                int recovered = ghsituation.getInt(""recovered"");
                                int deaths = ghsituation.getInt(""deaths"");
                                String datesituation = ghsituation.getString(""date"");
                                String timesituation = ghsituation.getString(""time"");
                            }

                        } catch (JSONException e) {
                            e.printStackTrace();
                            Toast.makeText(getApplicationContext(),
                                    ""Error: "" + e.getMessage(),
                                    Toast.LENGTH_LONG).show();
                        }

                        hidepDialog();

                    }
                }, new Response.ErrorListener() {
            @Override
            public void onErrorResponse(VolleyError error) {
                VolleyLog.d(""TAG"", ""Error: "" + error.getMessage());
                Toast.makeText(getApplicationContext(), ""Error""+error.getMessage(), Toast.LENGTH_SHORT).show();
                hidepDialog();
            }
        });

        VolleySingleton.getInstance(getApplicationContext()).addToRequestQueue(req);
    }
</code></pre>

<p>When a run the APP i receive an error : </p>

<pre><code>*** Errororg.json.JSONException: Value : {""ghana"":{""existing"":""273"",""confirmed"":""313"",""recovered"":""34"",""deaths"":""6"",""date"":""08th April, 2020"",""time"":""16:35""},""global"":{""existing"":""1,066,963"",""confirmed"":""1,468,891"",""recovered"":""316,482"",""deaths"":""85,446"",""date"":""08th April, 2020"",""time"":""16:35""}} cannot be converted to JSONArray.
</code></pre>
"
61057098,"<p><strong>Caused by:</strong></p>

<blockquote>
  <p>java.lang.NullPointerException: Attempt to invoke virtual method 'boolean java.io.File.isDirectory()' on a null object reference</p>
</blockquote>

<pre class=""lang-java prettyprint-override""><code>LocalOfficeManager officeManager = LocalOfficeManager.install();
try {
  // Start an office process and connect to the started instance (on port 2002).
  officeManager.start();
  File inputFile = new File(""storage/emulated/0/COVID-19/111.pdf"");
  wordtext = String.valueOf(JodConverter.convert(inputFile));
} catch (OfficeException e) {
  e.printStackTrace();
} finally {
  // Stop the office process
  OfficeUtils.stopQuietly(officeManager);
}
</code></pre>

<blockquote>
  <p>E/AndroidRuntime: FATAL EXCEPTION: main Process: handbook_multi_maker.TJ, PID: 17976 java.lang.RuntimeException: Unable to start activity ComponentInfo{handbook_multi_maker.TJ/TJ.SecondActivity}: java.lang.NullPointerException: Attempt to invoke virtual method 'boolean java.io.File.isDirectory()' on a null object reference at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3107) at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3250) at android.app.servertransaction.LaunchActivityItem.execute(LaunchActivityItem.java:78) at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:108) at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:68) at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1947) at android.os.Handler.dispatchMessage(Handler.java:106) at android.os.Looper.loop(Looper.java:214) at android.app.ActivityThread.main(ActivityThread.java:7032) at java.lang.reflect.Method.invoke(Native Method) at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493) at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:964) Caused by: java.lang.NullPointerException: Attempt to invoke virtual method 'boolean java.io.File.isDirectory()' on a null object reference at org.jodconverter.local.office.LocalOfficeUtils.validateOfficeHome(LocalOfficeUtils.java:339) at org.jodconverter.local.office.LocalOfficeManager$Builder.build(LocalOfficeManager.java:169) at org.jodconverter.local.office.LocalOfficeManager.install(LocalOfficeManager.java:78) at TJ.SecondActivity.initWebView(SecondActivity.java:132) at TJ.SecondActivity.onCreate(SecondActivity.java:104) at android.app.Activity.performCreate(Activity.java:7327) at android.app.Activity.performCreate(Activity.java:7318) at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1271) at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3087) at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3250)  at android.app.servertransaction.LaunchActivityItem.execute(LaunchActivityItem.java:78)  at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:108)  at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:68)  at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1947)  at android.os.Handler.dispatchMessage(Handler.java:106)  at android.os.Looper.loop(Looper.java:214)  at android.app.ActivityThread.main(ActivityThread.java:7032)  at java.lang.reflect.Method.invoke(Native Method)  at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:493)  at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:964) </p>
</blockquote>
"
61323669,"<p>I am working on a project with a django restframework backend ,I have done the backend and tested it's working properly but now I want to connect my android application to the APIs but it is at this point that I want to fetch this resposnse<a href=""https://i.stack.imgur.com/lrvWo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lrvWo.png"" alt=""enter image description here""></a> after a successfully registration and get some data to use in the next activity that I'm getting an error although data is saved in the database</p>

<p><strong>Here is my APIClient Interface class</strong></p>

<pre><code>package com.example.covid_19_tracker.data.network;
import com.example.covid_19_tracker.data.network.model.AddLocationResponse;
import com.example.covid_19_tracker.data.network.model.LoginResponse;
import com.example.covid_19_tracker.data.network.model.RegisterDeviceResponse;
import com.example.covid_19_tracker.data.network.model.RegisterUserResponse;

import java.util.HashMap;

import io.reactivex.Observable;
import retrofit2.http.FieldMap;
import retrofit2.http.FormUrlEncoded;
import retrofit2.http.POST;

public interface ApiInterface {

    @FormUrlEncoded
    @POST(""api/locations/"")
    Observable&lt;AddLocationResponse&gt; addLocation(@FieldMap HashMap&lt;String, Object&gt; params);

    @FormUrlEncoded
    @POST(""api/devices/"")
    Observable&lt;RegisterDeviceResponse&gt; registerDevice(@FieldMap HashMap&lt;String, Object&gt;   params);

    @FormUrlEncoded
    @POST(""api/accounts/register/"")
    Observable&lt;RegisterUserResponse&gt; registerUser(@FieldMap HashMap&lt;String, Object&gt; params);

    @FormUrlEncoded
    @POST(""api/accounts/login/"")
    Observable&lt;LoginResponse&gt; loginUser(@FieldMap HashMap&lt;String, Object&gt; params);
}
</code></pre>

<p><strong>And here is my RegisterUserResponse.java model Class</strong></p>

<pre><code>package com.example.covid_19_tracker.data.network.model;

import com.google.gson.annotations.Expose;
import com.google.gson.annotations.SerializedName;

import java.util.ArrayList;

public class RegisterUserResponse {
    @SerializedName(""success"")
    @Expose
    private String success;
    @SerializedName(""status_code"")
    @Expose
    private Integer status_code;
    @SerializedName(""message"")
    @Expose
    private String message;
    @SerializedName(""data"")
    @Expose
    private ArrayList data = new ArrayList();
    @SerializedName(""token"")
    @Expose
    private String token;

    public RegisterUserResponse() {
    }

    public String getSuccess() {
        return success;
    }

    public void setSuccess(String success) {
        this.success = success;
    }

    public Integer getStatus_code() {
        return status_code;
    }

    public void setStatus_code(Integer status_code) {
        this.status_code = status_code;
    }

    public String getMessage() {
        return message;
    }

    public void setMessage(String message) {
        this.message = message;
    }

    public ArrayList getData() {
        return data;
    }

    public void setData(ArrayList data) {
        this.data = data;
    }

    public String getToken() {
        return token;
    }

    public void setToken(String token) {
        this.token = token;
    }
}
</code></pre>

<p>But I'm getting the error <strong>Expected BEGIN_ARRAY but was BEGIN_OBJECT at line 1 column 2 path $</strong>
I'm a beginner in android. Thank you</p>
"
61704917,"<p>I am so tired of my problem. 
I have a JSON, I am trying:<br>
 1. To transform it into POJO using Jackson, and  custom method in Spring Boot app<br>
 2. Save with  H2 Db with Hibernate:
 With JSON below it isn't working.<br>
Without  <strong>""Countries"":</strong> everything working fine.<br>
 Please explain to me, what means ""Countries"" and how to save it to the Db?<br>
Also what means last  ""Date"": ""2020-04-05T06:37:00Z"" after ], and should I save it to DB too?</p>

<p>JSON:</p>

<pre><code> {
      ""Countries"": [
        {
          ""Country"": ""ALA Aland Islands"",
          ""CountryCode"": ""AX"",
          ""Slug"": ""ala-aland-islands"",
          ""NewConfirmed"": 0,
          ""TotalConfirmed"": 0,
          ""NewDeaths"": 0,
          ""TotalDeaths"": 0,
          ""NewRecovered"": 0,
          ""TotalRecovered"": 0,
          ""Date"": ""2020-04-05T06:37:00Z""
        },
        {
          ""Country"": ""Afghanistan"",
          ""CountryCode"": ""AF"",
          ""Slug"": ""afghanistan"",
          ""NewConfirmed"": 18,
          ""TotalConfirmed"": 299,
          ""NewDeaths"": 1,
          ""TotalDeaths"": 7,
          ""NewRecovered"": 0,
          ""TotalRecovered"": 10,
          ""Date"": ""2020-04-05T06:37:00Z""
        }
      ],
""Date"": ""2020-04-05T06:37:00Z""
    }
</code></pre>

<p>My POJO:</p>

<pre><code>@Data
@AllArgsConstructor
@Entity
public class Country {

    @JsonProperty(""Countries"")
    ArrayList &lt;Country&gt; countries = new ArrayList&lt;&gt;();  

    @Id
    @GeneratedValue
    @Column(name = ""id"")
    Long id;  

    @JsonProperty(""Country"")
    private String country;  

    @JsonProperty(""CountryCode"")
    private String countryside;  

    @JsonProperty(""Slug"")
    private String slug;  

    @JsonProperty(""NewConfirmed"")
    private Integer newConfirmed;  

    @JsonProperty(""TotalConfirmed"")
    private Integer totalConfirmed;  

    @JsonProperty(""NewDeaths"")
    private Integer newDeaths;  

    @JsonProperty(""TotalDeaths"")
    private Integer totalDeaths;  

    @JsonProperty(""NewRecovered"")
    private Integer newRecovered;  

    @JsonProperty(""TotalRecovered"")
    private Integer totalRecovered;  

    @JsonProperty(""Date"")
    private String date;

    public Country() {
    }
}
</code></pre>

<p>ERROR:  </p>

<pre><code>2020-05-10 01:07:52.255  INFO 27321 --- [  restartedMain] com.vicchern.Covid19JsonToDb             : Started Covid19JsonToDb in 3.786 seconds (JVM running for 4.595)
**Unable to save users: Cannot deserialize instance of `java.util.ArrayList&lt;com.vicchern.domain.Country&gt;` out of START_OBJECT token**
 at [Source: (BufferedInputStream); line: 2, column: 1]
2020-05-10 01:07:52.632  INFO 27321 --- [on(2)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-05-10 01:07:52.633  INFO 27321 --- [on(2)-127.0.0.1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2020-05-10 01:07:52.642  INFO 27321 --- [on(2)-127.0.0.1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 9 ms
</code></pre>

<p>I want to transform it into POJO with Jackson, with this custom method in Spring Boot app and save with database:</p>

<pre><code>public static void main(String[] args) {
        SpringApplication.run(Covid19JsonToDb.class, args);
    }

    @Bean
    CommandLineRunner runner(UserService userService){
        return args -&gt; {
            // read JSON and load json
            ObjectMapper mapper = new ObjectMapper();
            TypeReference&lt;List&lt;Country&gt;&gt; typeReference = new TypeReference&lt;&gt;(){};
            InputStream inputStream = TypeReference.class.getResourceAsStream(""/json/countries.json"");
            try {
                List&lt;Country&gt; users = mapper.readValue(inputStream,typeReference);
                userService.save(users);
                System.out.println(""Users Saved!"");
            } catch (IOException e){
                System.out.println(""Unable to save users: "" + e.getMessage());
            }
        };
    }
</code></pre>

<p>This is my service:  </p>

<pre><code>@Service
public class CountryService {

    private CountryRepository countryRepository;

    public CountryService(CountryRepository countryRepository) {
        this.countryRepository = countryRepository;
    }

    public Iterable&lt;Country&gt; list() {
        return countryRepository.findAll();
    }

    public Country save(Country country) {
        return countryRepository.save(country);
    }

    public void save(List&lt;Country&gt; countries) {
        countryRepository.saveAll(countries);
    }
}
</code></pre>

<p>Repository implements JpaRepository (no custom input)</p>

<p>I already read a lot of stuff here and on the internet. I have seen answers about ""wrappers"" for Lists. But how to deal with it, please help me with advice.</p>
"
61014650,"<p>I am going to use volley to get data</p>

<pre><code>RequestQueue queue = Volley.newRequestQueue(SummaryPhoneActivity.this);
    String url = ""https://covid19storageservice.table.core.windows.net/COVID19Survey?sv=2019-02-02&amp;ss=bfqt&amp;srt=sco&amp;sp=rwdlacup&amp;se=2020-06-30T18:04:08Z&amp;st=2020-03-30T10:04:08Z&amp;spr=https&amp;sig=Ei3Kcr6xT5e7znK4ebwx6%2FVS09Ia5pbD1lnWRBh6bm4%3D"";
    StringRequest stringRequest = new StringRequest(Request.Method.GET, url, new Response.Listener&lt;String&gt;() {
        @Override
        public void onResponse(String response) {
            Log.d(""response:"", response);
        }
    }, new Response.ErrorListener() {
        @Override
        public void onErrorResponse(VolleyError error) {
            Log.d(""error:"", error.toString());
        }
    }){
        @Override
        public Map&lt;String, String&gt; getHeaders() throws AuthFailureError {
            Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;();
            params.put(""Content-Type"", ""application/json"");
            return params;
        }
    };

    queue.add(stringRequest);
</code></pre>

<p>I can get error: com.android.volley.ClientError.
Above url is working on postman.
How can I use volley for above case. Thanks for your advance.</p>
"
60694921,"<p>I have a JavaFX application and i want to do injection of a prototype scopped bean in a Singleton scopped bean using Lookup method and all my configuration is using javax.inject API</p>

<pre><code>@Named
@Singleton
public abstract class DataModel {

    public ObservableList&lt;Series&lt;Number, Number&gt;&gt; observableList;

    public DataModel() {
        observableList = FXCollections.observableArrayList();
    }

    public void refresh(String[] selectedCountries) {
        observableList.clear();
        SeriesDataAdater seriesDataAdapter = getPopulationFirstCaseRelativeSeriesDataAdapter(selectedCountries);
        observableList.addAll(seriesDataAdapter.getSeriesList());
    }


    @Lookup()
    public abstract FirstCaseDateX_NewCasesPerPopulationY_SeriesDataAdapter getPopulationFirstCaseRelativeSeriesDataAdapter(String[] selectedCountries);
}


@Named
@Scope(""prototype"")
public class FirstCaseDateX_NewCasesPerPopulationY_SeriesDataAdapter extends SeriesDataAdater{

    @Inject
    public FirstCaseDateX_NewCasesPerPopulationY_SeriesDataAdapter(String[] selectedCountries, DataCache cache) {
        super(cache, selectedCountries);
    }

    @Override
    public List&lt;Series&lt;Number, Number&gt;&gt; getSeriesList() {
        ....
    }

    @Override
    public Series&lt;Number, Number&gt; getSeries(String country) {
        ....
    }

}
</code></pre>

<p>i have this exception :</p>

<blockquote>
  <p>Caused by: org.springframework.beans.factory.BeanCreationException:
  Error creating bean with name
  'firstCaseDateX_NewCasesPerPopulationY_SeriesDataAdapter' defined in
  file
  [D:\JAVA\workspaces\covid-19\covid19-unified-start-time-line-chart\target\classes\com\othmen\test\covid19\seriesdatasource\FirstCaseDateX_NewCasesPerPopulationY_SeriesDataAdapter.class]:
  Could not resolve matching constructor (hint: specify index/type/name
  arguments for simple parameters to avoid type ambiguities)</p>
</blockquote>

<p>i think he is not able to inject the argument selectedCountries because it is a simple type (String[]) but i dont know how to give him more informations (name or index) like he want. </p>

<p>i think i can solve this problem by creating a custom class as wrapper for my String[] parameter or by definning a FactoryBean for my String[] which will allow me to give him a Qualifier and the add @Qualifier in the prototype  constrcutor but is there an easier way to give him a Qualifier ?</p>
"
61495505,"<p>I have created WebView Activity and loading <strong><a href=""https://web.doar.zone/coronavirus"" rel=""nofollow noreferrer"">https://web.doar.zone/coronavirus</a></strong></p>

<p>This URL required Camera permission which I had taken Runtime Permission in Android.</p>

<p>Here is the full code of <strong>MainActivity.java</strong>:</p>

<pre><code>public class MainActivity extends AppCompatActivity {

    private static final String TAG = ""MainActivity"";

    Context context;

    ActivityMainBinding binding;

    private String url = ""https://web.doar.zone/coronavirus"";

    @Override
    protected void onResume() {
        super.onResume();
        checkCameraPermission();
    }

    private void checkCameraPermission() {
        int writeExternalStorage = ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA);
        if (writeExternalStorage != PackageManager.PERMISSION_GRANTED) {
            ActivityCompat.requestPermissions(this, new String[]{Manifest.permission.CAMERA}, 1001);
        }
    }

    @Override
    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
        if (requestCode == 1001) {
            if (grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                //Do your stuff
                openWebView();
            } else {
                checkCameraPermission();
            }
        }
    }

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        binding = DataBindingUtil.setContentView(this, R.layout.activity_main);
        context = getApplicationContext();

        openWebView();
    }

    @SuppressLint(""SetJavaScriptEnabled"")
    void openWebView() {

        ConnectivityManager connectivityManager = (ConnectivityManager) context.getSystemService(Context.CONNECTIVITY_SERVICE);

        final NetworkInfo networkInfo;
        if (connectivityManager != null) {
            networkInfo = connectivityManager.getActiveNetworkInfo();
            if (networkInfo != null &amp;&amp; networkInfo.isConnectedOrConnecting()) {
                binding.internetTextView.setVisibility(View.INVISIBLE);
                binding.webView.setVisibility(View.VISIBLE);
                //binding.webView.getSettings().setUserAgentString(""Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3"");
                binding.webView.getSettings().setJavaScriptEnabled(true);
                binding.webView.getSettings().setUseWideViewPort(true);
                binding.webView.getSettings().setDomStorageEnabled(true);
                binding.webView.setInitialScale(1);
                binding.webView.setWebChromeClient(new MyWebChromeClient());
                binding.webView.setWebViewClient(new WebViewClient() {

                    @Override
                    public boolean shouldOverrideUrlLoading(WebView webview, String url) {
                        Uri uri = Uri.parse(url);
                        if (uri.getScheme().contains(""whatsapp"") || uri.getScheme().contains(""tel"")) {
                            try {
                                Intent intent = Intent.parseUri(url, Intent.URI_INTENT_SCHEME);
                                if (intent.resolveActivity(getPackageManager()) != null)
                                    startActivity(intent);
                                return true;
                            } catch (URISyntaxException use) {
                                Log.e(""TAG"", use.getMessage());
                            }
                        } else {
                            webview.loadUrl(url);
                        }

                        return true;
                    }

                    @Override
                    public void onPageFinished(WebView view, String url) {
                        super.onPageFinished(view, url);
                    }
                });
                binding.webView.loadUrl(url);
            } else {

                binding.internetTextView.setVisibility(View.VISIBLE);
                binding.buttonTryAgain.setVisibility(View.VISIBLE);
                binding.webView.setVisibility(View.INVISIBLE);

                Toast.makeText(context, ""Connect to Internet and Refresh Again"", Toast.LENGTH_LONG).show();
            }
        } else {
            binding.internetTextView.setVisibility(View.VISIBLE);
            binding.buttonTryAgain.setVisibility(View.VISIBLE);
            binding.webView.setVisibility(View.INVISIBLE);

            Toast.makeText(context, ""Connect to Internet and Refresh Again"", Toast.LENGTH_LONG).show();
        }
    }


    @Override
    public boolean onKeyDown(int keyCode, KeyEvent event) {
        if (event.getAction() == KeyEvent.ACTION_DOWN) {
            if (keyCode == KeyEvent.KEYCODE_BACK) {
                if (binding.webView.canGoBack()) {
                    binding.webView.goBack();
                } else {
                    finish();
                }
                return true;
            }

        }
        return super.onKeyDown(keyCode, event);
    }

    class MyWebChromeClient extends WebChromeClient {

        MyWebChromeClient() {
            // TODO Auto-generated constructor stub
            binding.pb.setProgress(0);
        }

        @Override
        public void onPermissionRequest(final PermissionRequest request) {
            super.onPermissionRequest(request);
            //request.grant(request.getResources());
        }

        public void onProgressChanged(WebView view, int progress) {
            if (progress &lt; 100  /* &amp;&amp; pBar.getVisibility() == View.VISIBLE*/) {
                binding.pb.setVisibility(View.VISIBLE);
            }
            binding.pb.setProgress(progress);
            if (progress == 100) {
                binding.pb.setVisibility(View.GONE);
            }
        }
    }
}
</code></pre>

<p>Now I am getting error as below When I comment this line:</p>

<pre><code>request.grant(request.getResources());
</code></pre>

<p><a href=""https://i.stack.imgur.com/ie0o0l.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ie0o0l.png"" alt=""enter image description here""></a></p>

<p>And If I uncomment this line then I am getting:</p>

<pre><code> java.lang.IllegalStateException: Either grant() or deny() has been already called.
    at org.chromium.android_webview.permission.AwPermissionRequest.c(PG:3)
    at org.chromium.android_webview.permission.AwPermissionRequest.b(PG:1)
    at Cn.grant(PG:8)
    at com.example.webviewapp.MainActivity$MyWebChromeClient.onPermissionRequest(MainActivity.java:164)
    at org.chromium.android_webview.AwContents.onPermissionRequest(PG:8)
    at android.os.MessageQueue.nativePollOnce(Native Method)
    at android.os.MessageQueue.next(MessageQueue.java:326)
    at android.os.Looper.loop(Looper.java:181)
    at android.app.ActivityThread.main(ActivityThread.java:7078)
2020-04-29 11:52:21.813 4943-4943/com.example.webviewapp W/System.err:     at java.lang.reflect.Method.invoke(Native Method)
    at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:494)
</code></pre>

<p>Any Help?</p>
"
60259973,"<p>I have been building web downloaders over the years (e.g., using Apache HTTPClient and recently JBrowser [1]). These have worked OK till recently when some sites result in certification errors. I do not understand the details, and I cannot find a simple tutorial for people who know relatively little about certificates (e.g., what one looks like and how it obtained or created). This is a request for a default explanation of the simplest case and how to fix it. 
Typical error:</p>

<pre><code>[2020-02-17T09:38:24.249][Instance 1][Port 57129] Warning: Single GUI Threadiong is enabled, FPS should be slower
[2020-02-17T09:38:29.737][Instance 1][Port 57129] Feb 17, 2020 9:38:29 AM com.sun.webkit.network.URLLoader doRun
[2020-02-17T09:38:29.737][Instance 1][Port 57129] WARNING: Unexpected error
[2020-02-17T09:38:29.737][Instance 1][Port 57129] java.io.IOException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target: https://osf.io/search/?q=coronavirus
[2020-02-17T09:38:29.737][Instance 1][Port 57129]   at com.machinepublishers.jbrowserdriver.StreamConnection.exec(StreamConnection.java:369)
[2020-02-17T09:38:29.737][Instance 1][Port 57129]   at com.machinepublishers.jbrowserdriver.StreamConnection.getResponseCode(StreamConnection.java:449)
[2020-02-17T09:38:29.737][Instance 1][Port 57129]   at com.sun.webkit.network.URLLoader.receiveResponse(URLLoader.java:414)
...
</code></pre>

<p>I can access the URL through browsers (Firefox, Chrome) and get HTML which represents what I want, but cannot access this programmatically.</p>

<p>I have read several accounts of how to fix this (e.g. [2]), but they generally refer to ""your Keystore"" or ""trust manager"" as if everyone knows what these are. I am concerned that if I don't know what I am doing, I could break security. I don't know how I add sites to these or whether I even should.</p>

<p>I am on MACOSX and appear to have a binary file</p>

<pre><code>""/Library/Java/JavaVirtualMachines/jdk1.8.0_60.jdk/Contents/Home/JRE/lib/security/cacerts""
</code></pre>

<p>Some of the answers suggest I should have a file called ""truststore.jks"" but don't say where this should be or how it was created.</p>

<p>So I am asking for a simple explanation of the system components and the simplest way to fix it. In some cases, I can avoid it (e.g., by using <code>curl</code> from the command-line), so I don't know how much this is a Java (8) problem. </p>

<p>EDIT:
<a href=""https://stackoverflow.com/questions/6340918/trust-store-vs-key-store-creating-with-keytool?rq=1"">Trust Store vs Key Store - creating with keytool</a> seems to explain the difference between KeyStore and TrustStore, but I still don't have insight into what to do.</p>

<p>[1] <a href=""http://machinepublishers.github.io/jBrowserDriver/com/machinepublishers/jbrowserdriver"" rel=""nofollow noreferrer"">http://machinepublishers.github.io/jBrowserDriver/com/machinepublishers/jbrowserdriver</a>
/JBrowserDriver.html
[2] <a href=""https://stackoverflow.com/questions/24555890/using-a-custom-truststore-in-java-as-well-as-the-default-one"">Using a custom truststore in java as well as the default one</a></p>
"
61103018,"<p>I am trying to  bring this API URL into a pandas DataFrame and getting the values but still needing to add the date as a column like the other values:</p>

<pre><code>import pandas as pd
from pandas.io.json import json_normalize
import ssl

ssl._create_default_https_context = ssl._create_unverified_context

df = pd.read_json(""https://covidapi.info/api/v1/country/DOM"")
df = pd.DataFrame(df['result'].values.tolist())


print (df)
</code></pre>

<p>Getting this output:</p>

<pre><code>    confirmed  deaths  recovered
0           0       0          0
1           0       0          0
2           0       0          0
3           0       0          0
4           0       0          0
..        ...     ...        ...
72       1488      68         16
73       1488      68         16
74       1745      82         17
75       1828      86         33
76       1956      98         36
</code></pre>
"
60812566,"<p>starting from a known public data set which I copied to my own server.</p>

<p>The data set is here: <a href=""https://www.kaggle.com/imdevskp/corona-virus-report/download"" rel=""nofollow noreferrer"">https://www.kaggle.com/imdevskp/corona-virus-report/download</a></p>

<pre><code>import pandas as pd
#df = pd.read_csv(""http://g0mesp1res.dynip.sapo.pt/covid_19_clean_complete.csv"", index_col=4, parse_dates=True)
df = pd.read_csv(""http://g0mesp1res.dynip.sapo.pt/covid_19_clean_complete.csv"")
df=df.drop(labels=None, axis=0, index=None, columns=['Province','Lat','Long'], level=None, inplace=False, errors='raise')
#print(df.head())
df['Date']=pd.to_datetime(df['Date'])
#print(df.head())
list_countries = ['Portugal','Brazil','Spain','Italy','Korea, South','Japan']
df= df[df['Country'].isin(list_countries)]
df_pt = df[df.Country == 'Portugal']
df_es = df[df.Country == 'Spain']
df_it = df[df.Country == 'Italy']
print(df_pt.head())
print(df_pt.tail())
</code></pre>

<p>I get what I expected</p>

<pre><code>       Country       Date  Confirmed  Deaths  Recovered
59    Portugal 2020-01-22          0       0          0
345   Portugal 2020-01-23          0       0          0
631   Portugal 2020-01-24          0       0          0
917   Portugal 2020-01-25          0       0          0
1203  Portugal 2020-01-26          0       0          0
        Country       Date  Confirmed  Deaths  Recovered
15503  Portugal 2020-03-16        331       0          3
15789  Portugal 2020-03-17        448       1          3
16075  Portugal 2020-03-18        448       2          3
16361  Portugal 2020-03-19        785       3          3
16647  Portugal 2020-03-20       1020       6          5
</code></pre>

<p>However, when plotting, it seems that all data is in January!</p>

<pre><code>import plotly.graph_objects as go
fig = go.Figure( go.Scatter(x=df.Date, y=df_pt.Confirmed, name='Portugal'))
fig.show()
</code></pre>

<p>plotly output graph :</p>

<p><a href=""https://i.stack.imgur.com/MdWeI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MdWeI.png"" alt=""enter image description here""></a></p>

<p>What is missing?</p>
"
61233326,"<p>URL: <a href=""https://www.nielsen.com/us/en/insights/related-tag/covid-19/"" rel=""nofollow noreferrer"">https://www.nielsen.com/us/en/insights/related-tag/covid-19/</a></p>

<p>I have the following HTML elements:</p>

<p><a href=""https://i.stack.imgur.com/Oa7M4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Oa7M4.png"" alt=""enter image description here""></a></p>

<p>I want to extract href from this class and the text of title. </p>

<p>I used <code>driver.find_element_by_class_name('h2.entry-title h1&gt;a').get_attribute('href)</code> but returned none.</p>

<p>Any suggestions?</p>
"
61259436,"<p>URL: <a href=""https://www.piie.com/research/economic-issues/coronavirus"" rel=""nofollow noreferrer"">https://www.piie.com/research/economic-issues/coronavirus</a></p>

<p>I am trying to pull hrefs from class ""field field--title"" but my coding is not working</p>

<pre><code>driver.get('https://www.piie.com/research/economic-issues/coronavirus')

for i in driver.find_elements_by_class_name('field field--title'):
    for a in i.find_elements_by_css_selector('a'):
        print(a.get_attribute('href'))
        print(a.text)
</code></pre>

<p>HTML is showing below:</p>

<p><a href=""https://i.stack.imgur.com/zbaNP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zbaNP.png"" alt=""enter image description here""></a></p>

<p>Can anyone help me with the issue? Thanks</p>
"
61278543,"<p>I am trying to parse the hrefs and the titles of all articles from <a href=""https://www.weforum.org/agenda/archive/covid-19"" rel=""nofollow noreferrer"">https://www.weforum.org/agenda/archive/covid-19</a> but I also want to pull information on the next page.</p>

<p>My code can only pull the current page but is not working on click() next page.</p>

<pre><code>driver.get(""https://www.weforum.org/agenda/archive/covid-19"")

links =[]
titles = []

while True:
    for elem in wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.tout__link'))):
        links.append(elem.get_attribute('href'))
        titles.append(elem.text)
    try:
        WebDriverWait(driver,5).until(EC.presence_of_element_located((By.CSS_SELECTOR, "".pagination__nav-text""))).click()
        WebDriverWait(driver,5).until(EC.staleness_of(elem))
    except:
        break
</code></pre>

<p>Can anyone help me with the issue? Thank you!</p>
"
60962756,"<p>My Problem is that these two CSV files have different countries at different rows, so I can't just append the column in question to the other data frame.</p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv</a></p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv</a></p>

<p>I'm trying to think of some way to use a for loop, checking every row, and add the recovered cases to the correct row where the country name is the same in both data frames, but I don't know how to put that idea in to code. Help?</p>
"
61705842,"<p>When I write to the csv file all of my data is printed in only the first column. Using my loop, how do I iterate along the columns to write the data?</p>

<pre><code>import csv
import bs4
import urllib
from urllib.request import  urlopen as uReq
from urllib.request import Request, urlopen
from bs4 import BeautifulSoup as soup

#For sites that can't be opened due to Urllib blocker, use a Mozilla User agent to get access
pageRequest = Request('https://coronavirusbellcurve.com/', headers = {'User-Agent': 'Mozilla/5.0'})
htmlPage = urlopen(pageRequest).read()
page_soup = soup(htmlPage, 'html.parser')
specificDiv = page_soup.find(""div"", {""class"": ""table-responsive-xl""})

TbodyStats = specificDiv.table.tbody.tr.contents
TbodyDates = specificDiv.table.thead.tr.contents


with open('CovidHTML.csv','w', newline= '') as file:
    theWriter = csv.writer(file)             
    theWriter.writerow(['5/4', ' 5/5', ' 5/6',' 5/7',' 5/8',' 5/9'])
    for i in range(3,len(TbodyStats)):
        if i%2 != 0:
            theWriter.writerow([TbodyStats[i].text])
</code></pre>
"
60971787,"<p>I tried scraping the table rows from the <a href=""https://google.com/covid19-map/?hl=en"" rel=""nofollow noreferrer"">website</a> to get the data on corona virus spread. </p>

<p>I wanted to extract the src for all the  tags so as to get the source of the flag's image along with all the data for each country. Could someone help ?</p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
from selenium import webdriver
from selenium.webdriver.firefox.options import Options
options = Options()
options.add_argument('--headless')
driver = webdriver.Firefox(options=options)

driver = webdriver.Firefox(options=options)
driver.get(""https://google.com/covid19-map/?hl=en"")
df = pd.read_html(driver.page_source)[1]

df.to_csv(""Data.csv"", index=False)

driver.quit()
</code></pre>
"
59938187,"<p><a href=""https://i.stack.imgur.com/60vZL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/60vZL.png"" alt=""here is what I&#39;m trying to target with BeautifulSoup""></a></p>

<p>Here is my code so far:</p>

<pre><code>from bs4 import BeautifulSoup
soup = BeautifulSoup(website_url,'lxml')
my_table = soup.find('table',{'class':'wikitable sortable'})

from urllib.request import urlopen as uReq
from bs4 import BeautifulSoup as soup

my_url = 'https://en.wikipedia.org/wiki/2019%E2%80%9320_Wuhan_coronavirus_outbreak'

uClient = uReq(my_url)
page_html = uClient.read()
uClient.close()

page_soup = soup(page_html, ""html.parser"")
page_soup.tbody.tr?
</code></pre>

<p>I'm trying to target this table element, but it is not unique. How can I capture this nested element called ""&lt; td style...&lt; b""?</p>

<p>I could do page_soup.h1 to grab all the h1 tag stuff, but there's many repeated tags here, and I could use some help. I did UTFSE but am still confused. Thank you for your time. </p>
"
61082976,"<p>I have a big datatable, containing metadata such as different drug treatments to samples under different conditions and numeric features of measurements.</p>

<p>Mini dummy dataset:</p>

<pre><code>#I only used one sample here for simplicity. You can image there are multiple sample IDs
#and sometimes the same ID but different timestamp. 
#for each sample, the sample will have 3 levels conditions, 
#for each treatment(here's only 1, R), multiple dosages per condition
#on top of the condition&amp;dose there is next layer to have combo or not.
#from id ~combo they are factors or at least I believe so
#after all these, the real measured variables V1,2.....

set.seed(123)
id &lt;- rep(""S112"",30)  
timestamp &lt;- rep(""T4"",30)
condit &lt;- rep(c(""uns"",""2S"",""3S""), 10)
treatment &lt;- rep(""R"", 30)
dose &lt;- rep(c(""0.1"",""1""),each=15)
combo &lt;-rep(c(""none"",""I10"",""I100""),each=10)
v1 &lt;-rnorm(30,0.5)
v2 &lt;-rnorm(30,0.05)
v3 &lt;-rnorm(30,0.1)
df &lt;- data.frame(id,timestamp,condit,treatment,dose,combo,v1,v2,v3)
</code></pre>

<p>now if I can visualise the one treatment of R, at different condition and different dosages and even combination. </p>

<pre><code>#import libs
library(ggplot2)
library(dplyr)
library(tidyr)
library(wesanderson)  #I have great movie taste I know

# now I look at treatment of interest
R &lt;- df[df$treatment==""R"" &amp; df$combo == ""I10"",]

#table to long
R_long &lt;- gather(R,7:9, key = bin, value = value, -id, -timestamp, -condit )
#plot it
b&lt;- ggplot(R_long, aes(x=bin, y=id,fill=value))
pal &lt;- wes_palette(""Zissou1"", 100, type = ""continuous"")
R_map &lt;- b + 
  geom_tile()+
  scale_fill_gradientn(colors=pal)+
  facet_grid(dose~condit)+
  theme(text = element_text(size = 40,face=""bold"")) +
  theme(legend.text = element_text(size=35, face=""bold""))+
  theme(axis.text.x = element_text(angle=45, hjust=1)) +
  theme(legend.key.size = unit(2, ""cm""))+
  xlab(""Bins"")+
  ylab(""Sample ID"")+
  ggtitle(""Plot of treatment R"")

  ggsave(R_map,file=""R.pdf"",width=30,height=30) 
</code></pre>

<p>This works, but I want to perform the same thing to a group of drugs in the real dataset, instead of just one treatment R. I'm guessing the vectorised R language should allow something like group the treatments I want in a vector c(R1, R2, R3, R4) and apply the above code on this vector. How could I achieve that?</p>

<p>Note: I'm sorry for this poorly worded question. I honestly am too basic in R to even ask the key questions. So feel free to help me edit this (the COVID part is for the good spirit)</p>

<p>Thank you </p>
"
60873984,"<p>currently working on a flutter project with API. I'm quite new to flutter, </p>

<p>My Code:
Results null.
Being working on it for quite some time but couldn't find a solution. First, try on a flutter app therefore I'm quite new to this, would appreciate any solutions or tips/resources.
All variables are resulting in null as you can see I tried printing them couldn't figure out why.</p>

<pre><code>import 'dart:convert';
import 'package:flutter/material.dart';
import 'package:http/http.dart';

void main() =&gt; runApp(MyApp());

Future&lt;Data&gt; getData() async {
    final response = await get(""https://covid-api.com/api/reports?date=2020-03-25&amp;iso=TUR&amp;region_name=Turkey"");

    if(response.statusCode == 200) {
      return Data.fromJson(jsonDecode(response.body));
    } else {
      throw Exception('Not Working');
    }
  }


class Data {
  String date;
  int confirmed;
  int deaths;
  int recovered;
  int confirmedDiff;
  int deathsDiff;
  int recoveredDiff;
  int active;
  int activeDiff;
  double fatalityRate;

  Data({
    this.date,
    this.confirmed,
    this.deaths,
    this.recovered,
    this.confirmedDiff,
    this.deathsDiff,
    this.recoveredDiff,
    this.active,
    this.activeDiff,
    this.fatalityRate,
  });

  factory Data.fromJson(Map&lt;String, dynamic&gt; json) {
    return Data(
    confirmed: json['confirmed'],
    deaths: json['deaths'],
    recovered: json['recovered'],
    confirmedDiff: json['confirmed_diff'],
    deathsDiff: json['deaths_diff'],
    recoveredDiff: json['recovered_diff'],
    active: json['active'],
    activeDiff: json['active_diff'],
    fatalityRate: json['fatality_rate'],
    );
  }

  Map&lt;String, dynamic&gt; toJson() {
    final Map&lt;String, dynamic&gt; data = new Map&lt;String, dynamic&gt;();
    data['date'] = this.date;
    data['confirmed'] = this.confirmed;
    data['deaths'] = this.deaths;
    data['recovered'] = this.recovered;
    data['confirmed_diff'] = this.confirmedDiff;
    data['deaths_diff'] = this.deathsDiff;
    data['recovered_diff'] = this.recoveredDiff;
    data['active'] = this.active;
    data['active_diff'] = this.activeDiff;
    data['fatality_rate'] = this.fatalityRate;
    return data;
  }
}

class MyApp extends StatelessWidget {
  final Future&lt;Data&gt; data = getData();
  @override
  Widget build(BuildContext context) {
    return MaterialApp(

        theme: ThemeData(primaryColor: Colors.red),
        home: Scaffold(
            appBar: AppBar(title: Text('COVID-19 Turkey')),
            body: Center(
              child: FutureBuilder&lt;Data&gt;(
                future: data,
                builder: (context, snapshot) {
                  print(snapshot.data.deaths);
                  print('wtf');
                  print(snapshot.data.deathsDiff);
                  print(snapshot.data.recovered);
                  if(snapshot.hasData){
                    return Text(snapshot.data.confirmed.toString());

                  } else if (snapshot.hasError) {
                    return Text('Error');
                  }

                  return Center(child: CircularProgressIndicator(),);
                },
            ),)

        )
      );
  }
}
</code></pre>
"
60840233,"<p>I'am very new in the programming world and React (using the COVID-19 time to get better...). I'm trying to render a component when the user is clicking a register button. My goal is to display it as a pop-up in the middle of the screen for the user to fill a form. (I'm using Visual studio code and react app generator)</p>

<p>I can't make it happen, if I console.log the result true/false ( depending on a condition) it works correctly so I guess the problem is the way I "" call"" the component.</p>

<p>If anyone could point toward the good direction I would glady appreciate !</p>

<p>The App class where the handler function is calling the supposed popup div</p>

<pre><code>import React from ""react""
import Header from ""./UI/Header"";import RegisterWindow from ""./UI/RegisterWindow""; import Footer from ""./UI/Footer""; import MainSection from ""./UI/MainSection"";
import ""./index.css""


class App extends React.Component{
  constructor(){
    super()
    this.state ={
      registerIsShowed: false
    }
    this.handleRegister = this.handleRegister.bind(this)
  }

  handleRegister(){
   this.setState({
     registerIsShowed: !this.state.registerIsShowed
   })
   const isShowed = this.state.registerIsShowed;
   return isShowed ? &lt;RegisterWindow /&gt; : null
  }

render(){
return (
  &lt;div&gt;
    &lt;Header register={this.handleRegister} /&gt;
    &lt;MainSection /&gt;
  &lt;/div&gt;
)}

}


export default App
</code></pre>

<p>This is the Header code where the button that triggers the opening is located</p>

<pre><code>import React from ""react""

function Header(props) {
  return (
    &lt;header&gt;
      &lt;nav className=""navbar-header""&gt;
        &lt;p className=""header-data""&gt;&lt;/p&gt;
        &lt;ul className=""navbar-menu-header""&gt;
          &lt;li&gt;&lt;button onClick={props.register}&gt;Registrar&lt;/button&gt;&lt;/li&gt;
          &lt;li&gt;&lt;button&gt;Entrar&lt;/button&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/nav&gt;
    &lt;/header&gt;
  )
}

export default Header
</code></pre>

<p>and finally the Component that is supposed to show up</p>

<pre><code>import React from ""react""

class RegisterWindow extends React.Component{
render(){
  return (
    &lt;div className=""register-window""&gt;
      &lt;div&gt;
        &lt;form&gt;
          &lt;input name=""firstName"" placeholder=""First name"" type=""text"" /&gt;First Name
          &lt;input name=""lasttName"" placeholder=""Last name"" type=""text"" /&gt;Last Name
        &lt;/form&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  )
}
}


export default RegisterWindow
</code></pre>

<p>thank you,</p>
"
60877223,"<p>I have a program that creates data visualizations for stock data in Eclipse Nebula. The visualization are built in 2 separate shell windows. I'm looking to take those shells and create a JPG image file using ImageIO and Buffered Readers. I've tried using the built in functions in Graphics2d, but it returns undefined types with the JFrame- based implementation I'm trying on my shells. Here's the code I have for 1 of the shell plots (they are the same minus the source file). The code is a little long, so I have a comment with asterisks where I'm getting the error:</p>

<pre><code>public class CovidPlots {

    public static void main(String[] args) {

    //Data generation code

    //Create shell window
        final Shell shell = new Shell();
        shell.setSize(300, 250);
        shell.open();

        //Define axis for plot- code omitted

        //Create bridge between Lightweight system, SWT, and draw2d
        final LightweightSystem lws = new LightweightSystem(shell);
        XYGraph xyGraph = new XYGraph();
        xyGraph.setTitle(""DJIA PPS During COVID-19 Outbreak"");

        //Set Axis Bounds- code omitted

        //Plot graph
        lws.setContents(xyGraph);

        //Create trace data providers
        CircularBufferDataProvider traceDataProvider = new CircularBufferDataProvider(false);
        CircularBufferDataProvider traceDataProvider2 = new CircularBufferDataProvider(false);
        traceDataProvider.setBufferSize(len);
        traceDataProvider.setCurrentXDataArray(temp);
        traceDataProvider.setCurrentYDataArray(opening);
        traceDataProvider2.setBufferSize(len);
        traceDataProvider2.setCurrentXDataArray(temp);
        traceDataProvider2.setCurrentYDataArray(closing);


        //Build graph
        Trace trace = new Trace(""Opening DJI Values"", xyGraph.primaryXAxis, xyGraph.primaryYAxis, traceDataProvider);
        Trace trace2 = new Trace(""Closing DJI Values"", xyGraph.primaryXAxis, xyGraph.primaryYAxis, traceDataProvider2);
        trace.setPointStyle(PointStyle.CIRCLE);
        trace.setTraceColor(ColorConstants.red);
        trace2.setPointStyle(PointStyle.CIRCLE);
        trace2.setTraceColor(ColorConstants.darkGreen);
        trace2.setLineWidth(0);

        //Draw
        xyGraph.addTrace(trace);
        xyGraph.addTrace(trace2);

        //Keep shell open
        Display display = Display.getDefault();
        while(!shell.isDisposed()) {
            if(!display.readAndDispatch()) {
                display.sleep();
            }
        }

        //Save image as jpeg
        try {
            BufferedImage image = new BufferedImage(300, 250, BufferedImage.TYPE_INT_RGB);
            Graphics2D graphics2d = image.createGraphics(); //**error: createGraphics is undefined for type Buffered image
            shell.getPaint(graphics2d); //**Similar error with type graphics2d
            ImageIO.write(image, ""jpg"", new File(""C:\\Users\\zrr81\\Downloads\\COVID-19_Analysis\\COVID-19_Chart.jpg""));
            }
        catch (Exception e) {
            System.out.println(""Oops"");
        }

    }

</code></pre>
"
61275602,"<p>I am working on some rawString in which i need to remove \n from some places and Some where i need to go in next line if there showing \n.For Example Input:-</p>

<pre> ** As the coronavirus impact weighs, LMT to advance more\nthan $50 mln to small, medium-sized business partners in its\nsupply chain to protect jobs, support economy \n  \n  *New line should start\n\nregular \n  \n \n  \n text.</pre>

<p>I am getting the result Partially using this code </p>

<pre><code> String str = input.replaceAll(""\\n"",""~"").replaceAll(""~\\s+"",System.lineSeparator()+System.lineSeparator()).replaceAll(""~"", "" "");
</code></pre>

<p>Result right now i am getting:</p>

<pre>** As the coronavirus impact weighs, LMT to advance more than $50 mln to small, medium-sized business partners in its supply chain to protect jobs, support economy


*New line should startregular 





text.</pre>

<p>but problem is where i am getting more than one time ""\n"" consecutively  , that all \n replace into one ""\n"", because at this time where i am getting ""\n"" with space its going to next line, e,g so it like ""\n  \n Keyword"" in this case  ""Keyword"" is showing in next line that correct but creating one extra line above that a problem. Can anyone please help on this. </p>

<p>Expected:-</p>

<pre>** As the coronavirus impact weighs, LMT to advance more than $50 mln to small, medium-sized business partners in its supply chain to protect jobs, support economy

*New line should startregular 

text.</pre>

<p><strong>Input Pattern for New line</strong></p>

<p><code>\n  \n    \n  SomeText</code>, <code>\n\n  SomeText\n</code>,<code>\n \n\n  SomeText</code></p>

<p>In all above Pattern <code>someText</code> will start in next line.</p>

<p><strong>Pattern will create space only</strong></p>

<p><code>\nSomeText</code>, <code>\n\n\nSomeText\n\n</code>, <code>\nSomeText</code></p>

<p>in these all cases will create only space <code>"" ""</code>,</p>
"
60852284,"<p>I started to develop an application based on public API which returns not a friendly data type in format <code>text/HTML</code>. A few endpoints return normal data without blurring it, but there is one which is adding additional <code>\</code> to each element in response. </p>

<p>example response below: </p>

<pre><code>""{\""country\"":\""Poland\"",\""stat_by_country\"":[{\""id\"":\""365\"",\""country_name\"":\""Poland\"",\""total_cases\"":\""238\"",\""new_cases\"":\""61\"",\""active_cases\"":\""232\"",\""total_deaths\"":\""5\"",\""new_deaths\"":\""1\"",\""total_recovered\"":\""1\"",\""serious_critical\"":\""3\"",\""region\"":null,\""total_cases_per1m\"":\""6.3\"",\""record_date\"":\""2020-03-17 21:00:05.485\""}]
</code></pre>

<p>My wrapper classes look like below: </p>

<pre><code>@JsonInclude(JsonInclude.Include.NON_NULL)
@JsonIgnoreProperties(ignoreUnknown = true)
@NoArgsConstructor
@AllArgsConstructor
@Builder
@Getter
@Setter
public class CountryCasesHistory {
  private String id;
  private String country_name;
  private String total_cases;
  private String new_cases;
  private String active_cases;
  private String total_deaths;
  private String new_deaths;
  private String total_recovered;
  private String serious_critical;
  private String region;
  private String total_cases_per1m;
  private String record_date;
}
</code></pre>

<p>and</p>

<pre><code>@JsonInclude(JsonInclude.Include.NON_NULL)
@JsonIgnoreProperties(ignoreUnknown = true)
@NoArgsConstructor
@AllArgsConstructor
@Builder
@Getter
@Setter
public class CountryCasesHistoryWrapper {
  @JsonProperty(""country"")
  private String country;
  @JsonProperty(""stat_by_country"")
  private Set&lt;CountryCasesHistory&gt; statsByCountry;
}
</code></pre>

<p>Service and handler looks like: </p>

<pre><code>@Service
public class Covid19APIService {

  @Value(""${rapid-API-URL}"")
  private String covidAPIURL;

  @Value(""${x-rapidapi-host}"")
  private String covidAPI;

  @Value(""${x-rapidapi-key}"")
  private String covidAPIKey;

  public Mono&lt;CountryCasesHistoryWrapper&gt; findCasesHistoryForCountry(String country) {

    return buildWebClient()
        .get()
        .uri(""/cases_by_particular_country.php"")
        .retrieve()
        .onStatus(
            HttpStatus::is4xxClientError,
            response -&gt; error(new InfrastructureException(""Covid19 public API not found"")))
        .onStatus(
            HttpStatus::is4xxClientError,
            response -&gt; error(new InfrastructureException(""Covid19 public API server exception"")))
        .bodyToMono(CountryCasesHistoryWrapper.class);
  }

  private void acceptedCodecs(ClientCodecConfigurer clientCodecConfigurer) {
    clientCodecConfigurer
        .customCodecs()
        .register(new Jackson2JsonEncoder(new ObjectMapper(), TEXT_HTML));
    clientCodecConfigurer
        .customCodecs()
        .register(new Jackson2JsonDecoder(new ObjectMapper(), TEXT_HTML));
  }
}
</code></pre>

<p>Handler.java</p>

<pre><code>@Component
@RequiredArgsConstructor
public class Covid19APIHandler {

  private final Covid19APIService apiService;

  public Mono&lt;ServerResponse&gt; getCasesHistoryForCountry(ServerRequest serverRequest) {
    String country =
        serverRequest
            .queryParam(""country"")
            .orElseThrow(
                () -&gt; new InfrastructureException(""Country parameter is required for this action""));
    final Mono&lt;CountryCasesHistoryWrapper&gt; casesHistoryForCountry =
        apiService.findCasesHistoryForCountry(country);

    return casesHistoryForCountry
        .flatMap(
            gc -&gt;
                ok().contentType(APPLICATION_JSON)
                    .body(fromPublisher(casesHistoryForCountry, CountryCasesHistoryWrapper.class)))
        .switchIfEmpty(noContent().build());
  }
}
</code></pre>

<p>Current solutions lead to backend error:</p>

<pre><code>""message"": ""Invalid JSON input: Unrecognized field \""error\"" (class com.covid.domain.model.CountryCasesHistoryWrapper), not marked as ignorable; nested exception is com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field \""error\"" (class com.covid.domain.model.CountryCasesHistoryWrapper), not marked as ignorable (2 known properties: \""stat_by_country\"", \""country\""])\n at [Source: (io.netty.buffer.ByteBufInputStream); line: 1, column: 11] (through reference chain: com.covid.domain.model.CountryCasesHistoryWrapper[\""error\""])""
</code></pre>

<p>My question is, is it possible to rid-off each single <code>\</code> from the response and receive the normal, not blurred object as a result and hence bypass error. 
I will be grateful for the suggestion on how to reach a goal. </p>

<p>EDIT: 
I can use block on Mono and remap values to another object with method <code>.replaceAll</code> but this is not a desirable solution.
Does anybody have another suggestion? </p>
"
61327789,"<p>Due to the fact that I still did not find out a fully satisfying and reactive solution for my topic: <a href=""https://stackoverflow.com/questions/61254670/getting-could-not-emit-tick-0-due-to-lack-of-requests-interval-doesnt-support"">click</a>, which the main assumption was: </p>

<pre><code>How to run a Web Flux method cyclically in a reactive way?
</code></pre>

<p>I found a walkaround to make it real using the <code>@Scheduled</code> annotation. Implementation below:</p>

<pre><code>@Component
@AllArgsConstructor
public class Covid19APIHandler {

  private Covid19APIService apiService;

  private CountryCasesHistoryRepository repository;

  private CountryCasesWrapperRepository countryCasesWrapperRepository;

  private ServerRequest serverRequest;

  public Mono&lt;Void&gt; getCountryCasesAndSave(ServerRequest serverRequest) {
    return apiService
        .findCasesByCountry()
        .flatMap(
            wrapper -&gt;
                countryCasesWrapperRepository
                    .save(
                        CountryCasesWrapper.builder()
                            .countries_stat(wrapper.getCountries_stat())
                            .statistic_taken_at(wrapper.getStatistic_taken_at())
                            .build())
                    .then(Mono.empty()));
  }

  @Scheduled(fixedDelay = 10000)
  public void casesByCountryScheduled() {
    getCountryCasesAndSave(serverRequest);
  }
}
</code></pre>

<p>The problem is that while code execution I am receiving an error: </p>

<pre><code>Description:

Parameter 3 of constructor in com.covid.application.Covid19APIHandler required a bean of type 'org.springframework.web.reactive.function.server.ServerRequest' that could not be found.

Action:

Consider defining a bean of type 'org.springframework.web.reactive.function.server.ServerRequest' in your configuration.
</code></pre>

<p>I tried <code>final</code> keyword with <code>@RequiredArgsConstructor</code>, generating all args. constructor via <code>IntelliJ</code> but still, my <code>ServerRequest</code> field is not initialized. Here comes the question, how to create my custom bean of <code>ServerRequest</code> and make it initialized properly. I will be grateful for suggestions on how to make it real.  </p>
"
61254670,"<p>I am consuming a public API with reactive WebClient. I want to call API and save the newest data from there in each 1 hour. The problem occurs when I am adding <code>.repeatWhen()</code> method to the <code>Flux</code> stream like below: </p>

<pre><code>@Service
public class Covid19APIService {

  @Value(""${rapid-API-URL}"")
  private String covidAPIURL;

  @Value(""${x-rapidapi-host}"")
  private String covidAPI;

  @Value(""${x-rapidapi-key}"")
  private String covidAPIKey;

  private WebClient buildWebClient() {
    return WebClient.builder()
        .baseUrl(covidAPIURL)
        .exchangeStrategies(ExchangeStrategies.builder().codecs(this::acceptedCodecs).build())
        .defaultHeaders(
            httpHeaders -&gt; {
              httpHeaders.add(""x-rapidapi-host"", covidAPI);
              httpHeaders.add(""x-rapidapi-key"", covidAPIKey);
            })
        .build();
  }

  public Flux&lt;CountryCasesHistoryWrapper&gt; findCasesHistoryForCountryAndDate1(
      String country, String date) {

     return buildWebClient()
        .get()
        .uri(
            builder -&gt;
                builder
                    .path(""/history_by_particular_country_by_date.php"")
                    .queryParam(""country"", country)
                    .queryParam(""date"", date)
                    .build())
        .retrieve()
        .onStatus(
            HttpStatus::is4xxClientError,
            response -&gt; error(new InfrastructureException(""Covid19 public API not found"")))
        .onStatus(
            HttpStatus::is4xxClientError,
            response -&gt; error(new InfrastructureException(""Covid19 public API server exception"")))
        .bodyToMono(CountryCasesHistoryWrapper.class)
             .repeatWhen(interval -&gt; Flux.interval(Duration.ofMinutes(10)))
             .single()
          .repeatWhen(interval -&gt; Flux.interval(Duration.ofSeconds(30))).delayElements(Duration.ofSeconds(10));
  }

  private void acceptedCodecs(ClientCodecConfigurer clientCodecConfigurer) {
    clientCodecConfigurer
        .customCodecs()
        .register(new Jackson2JsonEncoder(new ObjectMapper(), TEXT_HTML));
    clientCodecConfigurer
        .customCodecs()
        .register(new Jackson2JsonDecoder(new ObjectMapper(), TEXT_HTML));
  }
}
</code></pre>

<p>and handler method: </p>

<pre><code>public Mono&lt;ServerResponse&gt; getCasesHistoryForCountryAndDate1(ServerRequest serverRequest) {
    String country =
        serverRequest
            .queryParam(""country"")
            .orElseThrow(
                () -&gt; new InfrastructureException(""Country parameter is required for this action""));

    String date =
        serverRequest
            .queryParam(""date"")
            .orElseThrow(
                () -&gt; new InfrastructureException(""Date parameter is required for this action""));

    final Flux&lt;CountryCasesHistoryWrapper&gt; casesHistoryForCountryAndDate =
        apiService.findCasesHistoryForCountryAndDate1(country, date);

    return casesHistoryForCountryAndDate
        .flatMap(
            countryCasesHistoryWrapper -&gt;
                repository.saveAll(countryCasesHistoryWrapper.getStatsByCountry()))
        .collectList()
        .flatMap(
            countryCasesHistories -&gt;
                ServerResponse.ok()
                    .contentType(MediaType.APPLICATION_JSON)
                    .body(BodyInserters.fromValue(countryCasesHistories)));
}
</code></pre>

<p>Above implementation leads to the exception: </p>

<pre><code>reactor.core.Exceptions$OverflowException: Could not emit tick 0 due to lack of requests (interval doesn't support small downstream requests that replenish slower than the ticks)
    at reactor.core.Exceptions.failWithOverflow(Exceptions.java:231) ~[reactor-core-3.3.3.RELEASE.jar:3.3.3.RELEASE]
</code></pre>

<p>I noticed similar question <a href=""https://stackoverflow.com/questions/48520084/spring-webflux-reactor-error-when-zipwith-could-not-emit-tick-due-to-lack-o"">click</a> but despite adding <code>delayElements()</code> method exception is still occurring. Here comes the question, how to fix the current implementation and reach the desired goal which is calling API in each hour and get the newest data from there. I will be grateful for all suggestions. </p>
"
61560648,"<p>I have a google sheet with coronavirus data. I want to update it using the worldometers site. I don't want to copy the CSS selector for every single of the thousands of cells in my code. </p>

<p>I tried getting the table but it is separated by newlines after each. I got the table with the following code</p>

<pre><code>    import bs4
    import requests

    res = requests.get('https://www.worldometers.info/coronavirus')
    soup = bs4.BeautifulSoup(res.text, 'html.parser')
    print(len(soup.select('table')))
    txt = soup.select('table')[1]
    print(txt.text)
</code></pre>

<p>Is there a way to make what we get from the table int a format that can be put into excel or put the table HTML itself into excel so that will formatted properly.</p>
"
61697570,"<p>Recently, I was trying to do a simple Scala code to analyse COVID - 19 data, I called one API and cast structure of that JSON API call to my Scala case classes. If I do not apply filters code is working as expected, When I try to apply filter it do not work, Little bit confused. Why it is not working. </p>

<pre><code>case class RegionData(region: Option[String], totalInfected: Option[String], recovered: Option[String], deceased: Option[String])

case class Data(activeCases: String, recovered: String, deaths: String, totalCases: String, sourceUrl: String, lastUpdatedAtApify: String, readMe: String, regionData: Option[List[RegionData]])
</code></pre>

<p>These are my case classes for Scala. </p>

<pre><code>import com.fasterxml.jackson.databind.ObjectMapper
import com.fasterxml.jackson.module.scala.DefaultScalaModule

import scala.io.Source

object CovidAnalytics {
  val objectMapper: ObjectMapper = new ObjectMapper()
  objectMapper.registerModule(DefaultScalaModule)

  def main(args: Array[String]): Unit = {
    val getData: String = Source.fromURL(""https://api.apify.com/v2/datasets/58a4VXwBBF0HtxuQa/items?format=json&amp;clean=1"").mkString
    val data: List[Data] = objectMapper.readValue(getData, classOf[List[Data]])
    //This is working
    println(data)

    val filter = data.filter(e =&gt; e.deaths != """")
    //This is not working (Confused!!!)
    println(filter)
  }
}
</code></pre>

<blockquote>
  <p>Exception in thread ""main"" java.lang.ClassCastException:
  scala.collection.immutable.HashMap$HashTrieMap cannot be cast to
  com.example.analytics.Data    at
  com.example.analytics.CovidAnalytics$$anonfun$1.apply(CovidAnalytics.scala:18)
    at
  scala.collection.TraversableLike$$anonfun$filterImpl$1.apply(TraversableLike.scala:248)
    at scala.collection.immutable.List.foreach(List.scala:392)  at
  scala.collection.TraversableLike$class.filterImpl(TraversableLike.scala:247)
    at
  scala.collection.TraversableLike$class.filter(TraversableLike.scala:259)
    at scala.collection.AbstractTraversable.filter(Traversable.scala:104)
    at
  com.example.analytics.CovidAnalytics$.main(CovidAnalytics.scala:18)
    at com.example.analytics.CovidAnalytics.main(CovidAnalytics.scala)</p>
</blockquote>
"
61009374,"<p>I am new to angular and trying to make an COVID 19 app in angular where I have two components, <code>State</code> component and <code>District</code> component.</p>

<p>State component is listing all state in table and when I click on any state It is loading all district list below that state.</p>

<p>Here is my working link: <a href=""https://stackblitz.com/github/mehulk05/COVOID-19"" rel=""nofollow noreferrer"">working link</a>.</p>

<p>Reference of my expectation: <a href=""https://www.covid19india.org/"" rel=""nofollow noreferrer"">expected result link</a></p>

<p>I want to sort (toggle) my district data for particular state in ascending or descending order when I click on District column of table but I am not able to sort data in any way. Once I am able to sort in ascending then I can write same for descending.</p>

<p>I am getting <strong>error</strong>:</p>

<blockquote>
  <p>core.js:6185 ERROR TypeError: districtdata.sort is not a function</p>
</blockquote>

<p>Here is data I am getting as Json response for particular state </p>

<p><strong>data.Json</strong></p>

<pre><code>{
  ""Pune"": {
    ""confirmed"": 63,
    ""lastupdatedtime"": """",
    ""delta"": {
      ""confirmed"": 0
    }
  },
  ""Mumbai"": {
    ""confirmed"": 198,
    ""lastupdatedtime"": """",
    ""delta"": {
      ""confirmed"": 0
    }
  },
  ""Nagpur"": {
    ""confirmed"": 12,
    ""lastupdatedtime"": """",
    ""delta"": {
      ""confirmed"": 0
    }
  },
  ""Thane"": {
    ""confirmed"": 10,
    ""lastupdatedtime"": """",
    ""delta"": {
      ""confirmed"": 0
    }
  },
  ""Ahmadnagar"": {
    ""confirmed"": 19,
    ""lastupdatedtime"": """",
    ""delta"": {
      ""confirmed"": 0
    }
  }
}
</code></pre>

<p><strong>District.component.ts</strong></p>

<pre><code> ngOnInit(): void {
    this.cs.districtdata.subscribe(data=&gt;{
      this.districtdata=data
      console.log(data)
    })

  }

  sortDistrict(districtdata){
    this.isAscendingSort=true;
  const x= districtdata.sort((a, b) =&gt; a.localeCompare(b))
   console.log(x)
  }  
</code></pre>

<p><strong>District.component.html</strong></p>

<pre><code>&lt;div class=""district-heading""&gt;
    &lt;th (click)=""sortDistrict(districtdata)""&gt;
        &lt;div class=""heading-content""&gt;
            &lt;abbr class=""dist"" title=""District""&gt;District&lt;/abbr&gt;
        &lt;/div&gt;
    &lt;/th&gt;
    &lt;th&gt;
        &lt;div class=""heading-content""&gt;
            &lt;abbr class=""confirmed"" title=""Confirmed""&gt;Confirmed&lt;/abbr&gt;
        &lt;/div&gt;
    &lt;/th&gt;
&lt;/div&gt;
</code></pre>
"
61047524,"<p><strong>THE PROBLEM:</strong></p>

<p>In my project, when I select and then unselect a button on mobile, it still remains dark because it's in focus and that's confusing:
<a href=""https://i.stack.imgur.com/qExze.gif"" rel=""nofollow noreferrer"">Screen recording</a></p>

<p>Here's the deployed page: <a href=""https://covid-19-mortality.netlify.com/"" rel=""nofollow noreferrer"">https://covid-19-mortality.netlify.com/</a></p>

<p><strong>WHAT I WANT TO ACHIEVE:</strong></p>

<p>I would like to override the button focused styling so that it is intuitive that the button is in focus and not selected. </p>

<p><strong>WHAT I HAVE TRIED:</strong></p>

<p>I have tried every solution in <a href=""https://stackoverflow.com/questions/23333231/bootstrap-button-shows-blue-outline-when-clicked"">bootstrap button shows blue outline when clicked</a>.</p>
"
61031177,"<p>I have a <code>react</code> app with <code>CSS</code> files working fine.<br/>
I need to start using <code>SCSS</code> so the following changes:</p>

<ol>
<li>Install <code>node-sass</code> and <code>sass-loader</code></li>
<li>Change the imports from <code>.css</code> to <code>.scss</code></li>
<li>Change file extension from <code>.css</code> to <code>.scss</code></li>
</ol>

<p>But my pages are not loading properly:</p>

<p>Current behavior: <img src=""https://i.stack.imgur.com/gJp1G.png"" alt=""enter image description here""></p>

<p>Expected behavior: <img src=""https://i.stack.imgur.com/zTAHv.png"" alt=""enter image description here""></p>

<p>My code:</p>

<p><code>package.json</code></p>

<pre><code>{
  ""name"": ""frontend"",
  ""version"": ""0.1.0"",
  ""private"": true,
  ""dependencies"": {
    ""@coreui/coreui"": ""^3.0.0"",
    ""@stardust-ui/docs-components"": ""^0.40.0"",
    ""axios"": ""^0.19.0"",
    ""bootstrap"": ""^4.4.1"",
    ""compass"": ""^0.1.1"",
    ""css-loader"": ""^3.4.2"",
    ""mdbreact"": ""^4.25.4"",
    ""prettier"": ""^1.6.1"",
    ""prop-types"": ""^15.7.2"",
    ""react"": ""^16.10.2"",
    ""react-bootstrap"": ""^1.0.0-beta.16"",
    ""react-bootstrap-sidebar"": ""0.0.1"",
    ""react-dom"": ""^16.10.2"",
    ""react-fixed-bottom"": ""^1.0.2"",
    ""react-modal"": ""^3.11.1"",
    ""react-rangeslider"": ""^2.2.0"",
    ""react-router-dom"": ""^5.1.2"",
    ""react-scripts"": ""^1.1.5"",
    ""reconnecting-websocket"": ""^4.2.0"",
    ""reconnectingwebsocket"": ""^1.0.0"",
    ""semantic-ui-react"": ""^0.88.2"",
    ""style-loader"": ""^1.1.3"",
    ""styled-components"": ""^4.4.1""
  },
  ""scripts"": {
    ""start"": ""PORT=3000 react-scripts start"",
    ""build"": ""react-scripts build"",
    ""test"": ""react-scripts test --env=jsdom"",
    ""eject"": ""react-scripts eject""
  },
  ""devDependencies"": {
    ""node-sass"": ""^4.13.1"",
    ""sass-loader"": ""^8.0.2""
  }
}
</code></pre>

<p>I injected the code for the loaders in node_modules/react-scripts/config/webpack.config.dev.js like this:</p>

<pre><code>// Process JS with Babel.
          {
            test: /\.(js|jsx|mjs)$/,
            include: paths.appSrc,
            loader: require.resolve('babel-loader'),
            options: {
              // @remove-on-eject-begin
              babelrc: false,
              presets: [require.resolve('babel-preset-react-app')],
              // @remove-on-eject-end
              // This is a feature of `babel-loader` for webpack (not Babel itself).
              // It enables caching results in ./node_modules/.cache/babel-loader/
              // directory for faster rebuilds.
              cacheDirectory: true,
            },
          },
          { 
            test: /\.scss$/, 
            loader: [
              ""css-loader"",
              ""sass-loader""
            ]
          },
</code></pre>

<p>Here is my component:</p>

<pre class=""lang-js prettyprint-override""><code>import React, { Component } from ""react"";
import '../../../general.scss';
import { Warning } from '../../../images/images_svg';

class Terminos extends Component{
  state = { error: false }

  saveAndContinue = () =&gt; {
    if(this.props.values.terminos) {
       this.props.nextStep()      
    }
    else {
       console.log(this.props.values.terminos_error)
       this.props.mandar_error('terminos_error')
    }     
  }

  render() { 
    return (
      &lt;div className=""formulario""&gt;
        &lt;div className=""formulario-seccion-titulo""&gt;
          &lt;div className=""formulario-seccion-barrita""/&gt;
            &lt;div className=""formulario-seccion-content""&gt;
               Presentacion
            &lt;/div&gt;
          &lt;/div&gt;      
          &lt;div className={this.props.values.terminos_error ? ""formulario-seccion"" : ""formulario-seccion-red""}&gt;
             La actual pandemia que afecta al mundo trae consecuencias a nivel sanitario, económico y social. Lo que está ocurriendo con el COVID impacta de lleno, no sólo en la salud física de las personas, sino que también afecta de forma clara y contundente su salud mental.&lt;br/&gt;&lt;br/&gt;
             Ud. puede decidir si contestar o no la encuesta que sigue pero de hacerlo,acepta que los resultados de la misma sean compartidos con su empleador con el único fin de brindarle contención y asistencia. La encuesta debe completarse en las próximas 10 horas.&lt;br/&gt;&lt;br/&gt;
             &lt;input type=""checkbox"" 
               id=""terminos"" 
               className=""formulario-checkbox""
               onChange={() =&gt; this.props.handleTerminos()}
               checked={this.props.values.terminos}
             /&gt;  
             &lt;label className=""formulario-checkbox-label"" htmlFor=""terminos""&gt; 
               Acepto terminos y condiciones.
             &lt;/label&gt;
             {this.props.values.terminos_error===false &amp;&amp;
                &lt;div className=""formulario-seccion-error""&gt;
                  &lt;div className=""formulario-seccion-error-logo"" &gt;
                    &lt;Warning color=""#d93025""/&gt;
                  &lt;/div&gt;
                    Debes aceptar los terminos y condiciones para continuar
                &lt;/div&gt;
              }
           &lt;/div&gt;
           &lt;div className=""formulario-footer""&gt;
             &lt;button className=""formulario-botones"" onClick={this.saveAndContinue}&gt;Siguiente&lt;/button&gt;
           &lt;/div&gt;
         &lt;/div&gt;
       )    
    }
}

export default Terminos;
</code></pre>

<p>If I change the import and the file extension from <code>.scss</code> to <code>.css</code> the page load properly.<br/>I´m using <code>npm start</code> to develop and testing the code. </p>
"
61167275,"<p>I am trying to get <code>Cases</code> list of COVID-19 positive cases from <code>https://www.worldometers.info/</code>, e.g. <a href=""https://www.worldometers.info/coronavirus/country/spain/"" rel=""nofollow noreferrer"">this</a></p>

<p>The sample looks like(~line no: 700) :</p>

<pre><code>&lt;script type=""text/javascript""&gt;
    Highcharts.chart('coronavirus-cases-linear', {
        chart: {
            type: 'line'
        },
        title: {
            text: 'Total Cases'
        },

        subtitle: {
            text: '(Linear Scale)'
        },

        xAxis: {
            categories: [""Feb 15"",""Feb 16"",""Feb 17"",""Feb 18"",""Feb 19"",""Feb 20"",""Feb 21"",""Feb 22"",""Feb 23"",""Feb 24"",""Feb 25"",""Feb 26"",""Feb 27"",""Feb 28"",""Feb 29"",""Mar 01"",""Mar 02"",""Mar 03"",""Mar 04"",""Mar 05"",""Mar 06"",""Mar 07"",""Mar 08"",""Mar 09"",""Mar 10"",""Mar 11"",""Mar 12"",""Mar 13"",""Mar 14"",""Mar 15"",""Mar 16"",""Mar 17"",""Mar 18"",""Mar 19"",""Mar 20"",""Mar 21"",""Mar 22"",""Mar 23"",""Mar 24"",""Mar 25"",""Mar 26"",""Mar 27"",""Mar 28"",""Mar 29"",""Mar 30"",""Mar 31"",""Apr 01"",""Apr 02"",""Apr 03"",""Apr 04"",""Apr 05"",""Apr 06"",""Apr 07"",""Apr 08"",""Apr 09"",""Apr 10"",""Apr 11""]        },

        yAxis: {
            title: {
                text: 'Total Coronavirus Cases'
            }


        },
        legend: {
            layout: 'vertical',
            align: 'right',
            verticalAlign: 'middle'
        },

        credits: {
            enabled: false
        },


        series: [{
            name: 'Cases',
            color: '#33CCFF',
            lineWidth: 5,
            ## I NEED THIS LIST
            data:   [2,2,2,2,2,2,2,2,2,3,9,13,25,33,58,84,120,165,228,282,401,525,674,1231,1695,2277,3146,5232,6391,7988,9942,11826,14769,18077,21571,25496,28768,35136,42058,49515,57786,65719,73235,80110,87956,95923,104118,112065,119199,126168,131646,136675,141942,148220,153222,158273,163027]        }],
        responsive: {
            rules: [{
                condition: {
                    maxWidth: 800
                },
                chartOptions: {
                    legend: {
                        layout: 'horizontal',
                        align: 'center',
                        verticalAlign: 'bottom'
                    }
                }
            }]
        }

    });
</code></pre>

<p>I am using bs4 as:</p>

<pre><code>#!/usr/bin/env python3
import requests as req
from bs4 import BeautifulSoup as bs

resp = req.get(""https://www.worldometers.info/coronavirus/country/spain/"")
soup = bs(resp.text, 'lxml')
scripts = soup.find_all(""script"")
for script in scripts:
  if ""Cases"" in script.series:
    print(script.name)
</code></pre>

<p>which does scrap the file, but after that I am clueless how to get the data. 
The list I am looking for is commented with <code>## I NEED THIS LIST</code>. Kindly help.</p>
"
60780414,"<p>I'm mostly new to nodejs and am making a site that goes through csv data and complies into a table. I am using covid data and the csv file I have has tons of different countries and US states, but I only want the US states. My code right now goes through every row and prints it out in a json format. </p>

<pre><code>const csv = require('csv-parser')
const fs = require('fs')
const results = [];

fs.createReadStream('data.csv')
  .pipe(csv())
  .on('data', (data) =&gt; results.push(data))
  .on('end', () =&gt; {
    console.log(results);
    // [
    //   { 'Province/State': 'North Carolina',
    //     'Country/Region': 'US',
    //     'Last Update': '2020-03-19T23:43:04',
    //      Confirmed: '123',
    //      Deaths: '0',
    //      Recovered: '0',
    //      Latitude: '35.6301',
    //      Longitude: '-79.8064' },
    //      ..... &lt;and so on for every country and every US state.&gt;
    // ]
  });
</code></pre>

<p>The US states are not in a specific order or specific rows so I need to filter them out by looking at the country region. <strong>However</strong>, the  data is only in single quotes and I get errros when I do a JSON.parse <code>SyntaxError: Unexpected token o in JSON at position 1</code>. What is the best way to go through the csv file and be able to parse into json, and parse out only the US states.</p>
"
61674430,"<p>What is the use of <code>SagaIterator</code> in a function generator?</p>

<pre class=""lang-js prettyprint-override""><code>import { SagaIterator } from '@redux-saga/core'

function* getCountry(action: ReturnType&lt;typeof actions.country.request&gt;) : SagaIterator {
    try {       
        const selectedCountry = (state: models.InitialStateTypes) =&gt; state.selectedCountryInitial        
        const data = yield select(selectedCountry)       
        const response: AxiosResponse&lt;models.CountryInitialResponse&gt; = yield call(
            axios.get , 
            'https://covid19.mathdro.id/api/countries/${data}' , 
            { 
                params: action.payload 
            }
        );
        yield put(actions.country.success(response.data))
    } catch (error) {
        yield put(actions.country.failure(error))
    }
}
</code></pre>
"
61547383,"<p>I have an effort to reduce rendering component counts. But I don't know about rendering trigger in ReactJS exactly. I see 2 rendering trigger before useEffect as componentDidMount. And later, there is also 2 rendering triggers whenever state changing. I don't know why component does 2 render for just one state change.</p>

<p>My code in github: <a href=""https://github.com/quangkhaidam93/1653033-covid19-map/blob/master/src/components/covid-map/CovidMap.js"" rel=""nofollow noreferrer"">https://github.com/quangkhaidam93/1653033-covid19-map/blob/master/src/components/covid-map/CovidMap.js</a>
Entire Project: <a href=""https://github.com/quangkhaidam93/1653033-covid19-map"" rel=""nofollow noreferrer"">https://github.com/quangkhaidam93/1653033-covid19-map</a></p>

<p>Image below shows console that have 2 rendering triggers:</p>

<p><a href=""https://i.stack.imgur.com/EdTTr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EdTTr.png"" alt=""enter image description here""></a></p>
"
61036243,"<p>Just looking over a <a href=""https://www.freecodecamp.org/news/how-to-create-a-coronavirus-covid-19-dashboard-map-app-in-react-with-gatsby-and-leaflet/#what-are-we-going-to-build"" rel=""nofollow noreferrer"">cool tutorial</a> and there was a notation that I didn't completely understand and having a hell of a time trying to google it.</p>

<pre><code>async function mapEffect({ leafletElement: map } = {}) {
    let response;

    try {
      response = await axios.get(‘https://corona.lmao.ninja/countries’);
    } catch(e) {
      console.log(`Failed to fetch countries: ${e.message}`, e);
      return;
    }

    // this next line here is the one confusing me:
    const { data = [] } = response;
}
</code></pre>

<p>Reading on, it appears that data is just an array - any reason it is written like this?  Can anyone explain in layman's terms why you would write something this way?  I never stop learning...  Thank you!</p>
"
61591731,"<p>My aim is to move backwards through the array of data, checking that as long as the date/month eg '02' stays the same, I will only take the first case (e.g data.Cases: 1234) I get for that month.</p>

<p>Here I'm stating <strong>(i)</strong> to hold the max length of the array.
<strong>cases</strong> and <strong>date</strong> to carry max number of cases and the month value at position <strong>i</strong>.</p>

<pre><code>    let data = 'https://api.covid19api.com/total/country/south-africa/status/confirmed?from=2020-03-01T00:00:00Z&amp;to=2020-04-01T00:00:00Z';

    let i = (data.length -1);
    let cases = data[i].Cases; // Total sum
    let date = (data[i].Date).slice(6,7);
    let getCase = [];
    let getDate = [];
    let theMonths = [];

    do {
        // Check if the date matches first date.
        // Push that date to getDate array.
        // Push that case to getCase array.
        // Continue loop

        if (date === (data[i].Date).slice(6,7)) {
            i--;
        }
</code></pre>

<p>Then this statement should trigger when the month value changes and change the date variable that the loop had used initially to the new one that triggered this statement. Therefore I can push new values to my array and repeat the whole loop with the next date value.</p>

<pre><code>            // If the date has changed
        if (date !== (data[i].Date).slice(6,7)) {
            // Change to current Date

            //ERROR HERE (Does not update date with new date)

            if (data[i].Date){
                date = (data[i].Date).slice(6,7);
                getDate.push(date);
                getCase.push(data[i].Cases);
            }
        }

        if (date === '1') {
            break;
        }

    }

    while (
        cases &gt;= data[i].Cases
    );
</code></pre>
"
61405018,"<p>API this one <a href=""https://covid19.mathdro.id/api"" rel=""nofollow noreferrer"">https://covid19.mathdro.id/api</a></p>

<p>Sorry for interrupt, but I freaking out with this issue, almost 2 hours im thinking what the problem.
So, for recored and for confirmed it works fine, but for deaths I have this issue:</p>

<p><a href=""https://i.stack.imgur.com/uYdBl.png"" rel=""nofollow noreferrer"">Issue photo</a></p>

<pre><code>import React from 'react';
import {Card, CardContent, Typography, Grid} from '@material-ui/core';
import CountUp from 'react-countup';
import cx from 'classnames';

import styles from './Cards.module.css'

const Cards = ({data: {deaths, confirmed, recovered, lastUpdate } } )  =&gt; {
    if(!confirmed) {
        return 'Loading...'
    };

    return (
        &lt;div className={styles.container}&gt;
            &lt;Grid container spacing={3} justify=""center""&gt;
                &lt;Grid item component={Card} xs={12} md={3} className={cx(styles.card, styles.infected)}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Infected&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;
                            &lt;CountUp
                            start={0}
                            end={confirmed.value}
                            duration={2.5}
                            separator="",""
                            /&gt; 
                        &lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;{new Date(lastUpdate).toDateString()}&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of active cases&lt;/Typography&gt;
                    &lt;/CardContent&gt;
                &lt;/Grid&gt;
                &lt;Grid item component={Card} xs={12} md={3} className={cx(styles.card, styles.recovered)}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Recovered&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;
                            &lt;CountUp
                            start={0}
                            end={recovered.value}
                            duration={2.5}
                            separator="",""
                            /&gt; 
                        &lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;{new Date(lastUpdate).toDateString()}&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of recoveries from COVID-19&lt;/Typography&gt;
                    &lt;/CardContent&gt;
                &lt;/Grid&gt;
                &lt;Grid item component={Card} xs={12} md={3} className={cx(styles.card, styles.deaths)}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Deaths&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;
                            &lt;CountUp
                            start={0}
                            end={deaths.value}
                            duration={2.5}
                            separator="",""
                            /&gt; 
                        &lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;{new Date(lastUpdate).toDateString()}&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of deaths caused by COVID-19&lt;/Typography&gt;
                    &lt;/CardContent&gt;
                &lt;/Grid&gt;
            &lt;/Grid&gt;
        &lt;/div&gt;
    )
}

export default Cards;
</code></pre>

<p>this is my app.js</p>

<pre><code>import React from 'react';


import { Cards, Chart, CountryPicker } from './components';
import styles from './App.module.css';
import { fetchData } from './api';

class App extends React.Component {
    state = {
        data: {},
    }

    async componentDidMount() {
        const fetchedData = await fetchData();

        this.setState({ data: fetchedData });
    }

    render() {
        const {data} = this.state;

        return (
            &lt;div className={styles.container}&gt;
                &lt;Cards data={data}/&gt;
                &lt;Chart /&gt;
                &lt;CountryPicker /&gt;
            &lt;/div&gt;
        )
    }
}

export default App;
</code></pre>

<p>So, I'm try without deaths and it works, but with not.</p>

<p>index.js</p>

<pre><code>import axios from 'axios';

const url = 'https://covid19.mathdro.id/api';

export const fetchData = async () =&gt; {
    try {
        const { data: { confirmed, recovered, death, lastUpdate } } = await axios.get(url);

        return {confirmed, recovered, death, lastUpdate};
    } catch (error) {

    }

}
</code></pre>

<p>Thanks for helping me out!</p>
"
61156445,"<p>In a VueJS component named <strong>GlobeInformation.vue</strong>, I would like to call a getter ""mapData"" which I expect to return a manipulated version of my state's data, however when I display it in my template it shows up as an empty array. I've posted a stripped down relevant version of my code below. Thanks in advance.</p>

<p>PS : I suppose this happens due to the async API call, hence I tried using v-if conditions to check if the data has been received only then render it on the template.</p>

<p><strong>GlobeInformation.vue</strong></p>

<pre class=""lang-js prettyprint-override""><code>&lt;template&gt;
&lt;div class=""information""&gt;
    &lt;div v-if=""mapDataLoaded""&gt;
        {{ mapInformation }}
    &lt;/div&gt;
&lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
export default {
    data: function() { 
        return { 
            mapDataLoaded: false,
            mapInformation: []    
        }
    },
    computed: {
        ...mapGetters(['mapData'])
    },
    methods: {
        ...mapActions(['fetchCondensedDetails'])
    },
    async mounted() {
        await this.fetchCondensedDetails('/')
        this.mapInformation = await this.mapData
        this.mapDataLoaded = true
    }
}
&lt;/script&gt;

</code></pre>

<p><strong>getters.js</strong></p>

<pre class=""lang-js prettyprint-override""><code>export default {
    mapData: state =&gt; {
        let mapData = []
        state.condensed.forEach(country =&gt; {
            mapData[country.alpha_2] = country.confirmed
        })
        return mapData
    }
}
</code></pre>

<p><strong>actions.js</strong></p>

<pre class=""lang-js prettyprint-override""><code>export default {
    async fetchCondensedDetails({ commit }, path) {
        try {
            if (path === '/') {
                const res = await fetch('https://covidapi.info/api/v1/global/latest')
                commit('SET_CONDENSED_DETAILS', await res.json())
            }
        } catch (err) {
            console.log(err)
        }
    }

}
</code></pre>

<p><strong>mutations.js</strong></p>

<pre class=""lang-js prettyprint-override""><code>export default {
    SET_CONDENSED_DETAILS: (state, data) =&gt; {
        data.result.forEach((element, index) =&gt; {
            const key = Object.keys(element)[0]

            let details = countries.find(country =&gt; {
                if (country.alpha_3 === key) return country
            })

            if (details) {
                state.condensed.push({
                    ...data.result[index][key],
                    alpha_3: key,
                    alpha_2: details.alpha_2,
                    name: details.name
                })
            }
        })
    }
}
</code></pre>
"
61195522,"<p>I have added the required build packs. There are also no errors shown in heroku logs. Locally the deployed application works completely fine and scraps the required news but on heroku the page just refreshes and displays nothing</p>

<pre><code>app.post(""/news"",function(req,res){
var pla= req.body.place;
var url='https://www.google.com/search?q=covid+19+'+pla+'&amp;sxsrf=ALeKk02SupK-SO625SAtNAmqA5CHUj5xjg:1586447007701&amp;source=lnms&amp;tbm=nws&amp;sa=X&amp;ved=2ahUKEwikieXS19voAhXAxzgGHV5bCcQQ_AUoAXoECBwQAw&amp;biw=1536&amp;bih=535';

(async () =&gt; {
    const browser = await puppeteer.launch({args: ['--no-sandbox']});
    const page = await browser.newPage();

    await page.goto(url);

    var data = await page.evaluate(() =&gt;
        Array.from(document.querySelectorAll('div.g'))
            .map(compact =&gt; ({
                headline: compact.querySelector('h3').innerText.trim(),
                img: compact.querySelector(""img"") === null ? 'https://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/No_image_3x4.svg/1280px-No_image_3x4.svg.png' : compact.querySelector(""img.th.BbeB2d"").src,
                url: compact.querySelector(""h3.r.dO0Ag&gt;a"").href,
                source: compact.querySelector(""div.gG0TJc&gt;div.dhIWPd&gt;span.xQ82C.e8fRJf"").innerText.trim(),
                time:  compact.querySelector(""div.gG0TJc&gt;div.dhIWPd&gt;span.f.nsa.fwzPFf"").innerText.trim(),
                desc : compact.querySelector(""div.st"").innerText.trim()
            }))
    )

    console.log(data);
    res.render('news.ejs',{data: data});
    await browser.close();
})();
});
</code></pre>
"
61091248,"<p>I want to display data from an API based on the value of an input, but before I even type something in the input box, it reads the value that is inside the box right after I type (in this case its undefined, because I haven't typed anything).</p>

<p>Here's what I tried to do:</p>

<pre class=""lang-js prettyprint-override""><code>fetch(""https://covid-19-coronavirus-statistics.p.rapidapi.com/v1/stats?country="" +
    countryInput.value, {
      ""method"": ""GET"",
      ""headers"": {
        ""x-rapidapi-host"": ""covid-19-coronavirus-statistics.p.rapidapi.com"",
        ""x-rapidapi-key"": ""20438f9eb4mshb2a68ca50196b46p1d55a5jsn2dbdc2b012cd""
      }
    })
  .then(response =&gt; {
    return response.json();
  })
  .then(data =&gt; {

      countryInput = inputElement.value
</code></pre>

<p>(the code keeps on)</p>
"
61444881,"<p>I have a chart that extracts data from an JSON API. I want to display date only from the beginning of the month to the current date.</p>

<p>Start date is the first day of that month and end date is the current date</p>

<p>I tried the following, but it is returning undefined.
I m requesting for assistance with this code.</p>

<p>Thank you.</p>

<p>Below is my code.</p>

<pre><code>        let dates = [];
let confirmed = [];
let recovered = [];
let deaths = [];

var today = new Date();
var TodayDate = today.getFullYear()+'-'+(today.getMonth()+1)+'-'+today.getDate();

var startDate = '01-04-2020'; //YYYY-MM-DD
var endDate = TodayDate; //YYYY-MM-DD

var getDateArray = function(start, end) {
    var arr = new Array();
    var dt = new Date(start);
    while (dt &lt;= end) {
        arr.push(new Date(dt));
        dt.setDate(dt.getDate() + 1);
    }
    return arr;
}

var dateArr = getDateArray(startDate, endDate);


fetch(""https://pomber.github.io/covid19/timeseries.json"")
  .then(response =&gt; response.json())
  .then(data=&gt; {
    data[""South Africa""].forEach(o =&gt; {
      dates.filter(function() {
        o.date==dateArr;
      }).push(o.date);
      confirmed.push(o.confirmed);
      recovered.push(o.recovered);
      deaths.push(o.deaths);
    })
    new Chart(document.getElementById('myChart'), {
      type: 'line',
      data: {
        labels: dates,
        datasets: [{
            label: 'Confirmed',
            borderColor: 'orange',
            backgroundColor: 'orange',
            fill: 'false',
            data: confirmed
          },
          {
            label: 'Recovered',
            borderColor: 'green',
            backgroundColor: 'green',
            fill: 'false',
            data: recovered
          },
          {
            label: 'Deaths',
            borderColor: 'red',
            backgroundColor: 'red',
            fill: 'false',
            data: deaths
          }
        ]
      },
      options: {
        responsive: true,
        maintainAspectRatio: false,
        title: {
          display: true,
          text: 'COVID-19 / Eswatini Time Series'
        }
      }
    });
  });
    &lt;/script&gt;
</code></pre>
"
60508336,"<p>The code below doesn't give any errors but I have a weird bug anyway. I have four streams to aggregate twitter feeds to a discord channel. 3 of those often work. but whenever I run the code there is always a feed not coming through, no line is getting executed in that stream. This often happens with the IntelFeed and/or covid-19feed. When I wait for some time or repeatedly rerun the code it starts working. I think it may be due to the structure of the code (not having enough time to fulfill the conditions) or due to the API. But I can't confirm the latter one.</p>

<pre class=""lang-js prettyprint-override""><code>const Discord = require('discord.js');
const botconfig = require(""./botconfig.json"");
const { Client, RichEmbed } = require('discord.js');
const twitterFeedsModel = require('./models/twitterFeedsModel');
const client = new Discord.Client();

const mongoose = require('mongoose', {useNewUrlParser: true}, { useUnifiedTopology: true });
mongoose.connect('mongodb://localhost/twitterFeedDatabeses');

const Twit = require('twit');

const T = new Twit({
    consumer_key:         botconfig.consumer_key,
    consumer_secret:      botconfig.consumer_key_secret,
    access_token:         botconfig.access_token,
    access_token_secret:  botconfig.access_token_secret,
});


client.on(""ready"", () =&gt; {
    console.log(`Logged in as ${client.user.tag}!`);
    //Newsfeed
    const stream = T.stream(""statuses/filter"", { follow: [""5402612"", ""1652541"", ""831470472"", ""26792275"", ""380648579"", ""426802833"", ""144274618"", ""31696962"", ""1642135962"", ""16561457""]});
    const scr_name = ['BBCbreaking', 'Reuters', 'pewglobal', 'ForeignPolicy', 'AFP', 'AP_Politics', 'economics', 'dw_europe', 'BBCNewsAsia', 'RadioFreeAsia']

    stream.on(""tweet"", function (tweet) {
        if(!scr_name.includes(tweet.user.screen_name)) return;
            client.channels.get(""646745474514026506"").send(`https://twitter.com/${tweet.user.screen_name}/status/${tweet.id_str}`);
    });
    //Covid-19stream
    const secondStream = T.stream(""statuses/filter"", {follow: ""2985479932""});
    const secondScr_name = ""BNODesk""

    secondStream.on(""tweet"", function (tweet){
        console.log(tweet.user.screen_name)
        if(secondScr_name.includes(tweet.user.screen_name)) {
            const tweetContent = tweet.text.split("" "");
            console.log(tweetContent)
            const filteredWords = ['thank', 'Thank', 'you', 'you.', 'you!']
            console.log(""It does include Breakin: "" + tweetContent.includes(""BREAKING:""))
            if(!filteredWords.some(word =&gt; tweet.text.includes(word))){
                if(tweetContent.includes(""BREAKING:"")){
                    console.log(""It does include breaking (after if-statement): "" + tweetContent.includes(""BREAKING:""))
                    client.channels.get(""645733080061181965"").send(`https://twitter.com/${tweet.user.screen_name}/status/${tweet.id_str}`)
                    client.channels.get('645733080061181965').send('I found out this tweet covers important news')
                    } else if(!tweet.text.startsWith(""@"")){
                        client.channels.get(""645733080061181965"").send(`https://twitter.com/${tweet.user.screen_name}/status/${tweet.id_str}`)
                        client.channels.get(""645733080061181965"").send(`Hello &lt;@283206528004259850&gt;, there is a new tweet!`)
                 }
            }
          }
    });
    //GRUNNstream
    const thirdStream = T.stream(""statuses/filter"", { follow: [""14907733"", ""22465767"", ""18549902"", ""451432440"", ""97639259"", ""2343981858""]});
    const thirdScr_name = ['rtvnoord', 'oogtv', 'dvhn_nl', 'P2000Groningen', 'polgroningen', 'Sikkom050']

    thirdStream.on(""tweet"", function (tweet) {
        if(thirdScr_name.includes(tweet.user.screen_name)) {
            client.channels.get(""632705489108729867"").send(`https://twitter.com/${tweet.user.screen_name}/status/${tweet.id_str}`);
        }
    });
    // intelstream
    const fourthStream = T.stream(""statuses/filter"", {follow: ['3331851939', '2407993940', '1140336427550552000', '2790057867', '2315512764', '1517300821', '70529694', '62248461', '146958450', '85904241', '762565517026664400']});
    const fourthScr_name = ['IntelCrab', 'IntelDoge', 'IntelAgencyNGO', 'lummideast', 'bellingcat', 'obretix', 'JanesINTEL', 'BarzanSadiq', 'ragipsoyly', 'leventkemal', 'OmerOzkizilcik']

    fourthStream.on(""tweet"", function (tweet) {
        if(fourthScr_name.includes(tweet.user.screen_name)) {
            client.channels.get(""646745512011235339"").send(`https://twitter.com/${tweet.user.screen_name}/status/${tweet.id_str}`);
        }
    });
});


module.exports.run = client.on('message', message =&gt; {

    if (!message.content.startsWith(botconfig.prefix) || message.author.bot) return;

    const args = message.content.slice(botconfig.prefix.length).split(/ +/);
    const command = args.shift().toLowerCase();

    if (command.length === 0) {
        return message.channel.send(`I ain't gonna fill the command in by myself fam`);
    }

    if (command === 'add_twitter_feed'){
        if (!args.length){ 
            return message.channel.send(""Please enter a valid value!"")};
        var twitterUsername_feed = args;
        T.get('users/show', { screen_name: twitterUsername_feed.join() },  function (err, data, response) {
            console.log(data.id)
        const twitterFeedVar = new twitterFeedsModel({
            _id: mongoose.Types.ObjectId(),
            twitterUsernameAddedToFeed: twitterUsername_feed.join(),
            twitterUsername_idAddedToFeed: data.id,
        })

        twitterFeedVar.save()
        .then(result =&gt; console.log(result))
        .catch(err =&gt; console.log(err))

        twitterFeedVar.find()
        .then(doc =&gt; {
        message.channel.send(doc)
        })
    }) 
    }
    /*if (command === `savelist`) {
        Test.find()
        .then(doc =&gt; {
        message.channel.send(doc)
        })
    }
    */
    if (command === 'twitter_user_id'){
        if (!args.length){ 
            return message.channel.send(""Please enter a valid value!"")};
        var twitterUsername_lookup = args;
        console.log(`${message.member.user.tag} requested the ID of the following user: ` + twitterUsername_lookup.join())
        T.get('users/show', { screen_name: twitterUsername_lookup.join() },  function (err, data, response) {
            console.log(data)
        message.channel.send(`This is the ID of ` + twitterUsername_lookup.join() + `: ` + data.id)
            if (!data.id) {
                return message.channel.send(`Twitter user not found.`)
            }

        })
        message.delete()
    }

    if (command === `hello`){
        return message.channel.send(""Hi there :)"")
    }

    if (command === `feedlist`){
        var scr_name2 = ['BBCbreaking', 'Reuters', 'pewglobal', 'ForeignPolicy', 'AFP', 'AP_Politics', 'economics', 'dw_europe', 'BBCNewsAsia', 'RadioFreeAsia']
        return message.channel.send(scr_name2)
    }

    if (command === `reload`) {
        message.channel.send(`Reloading...`)
        console.clear();
           client.destroy()
           client.login(botconfig.token);
         message.channel.send(`Bot reloaded succesfully!`);
     return;
    }

});

module.exports.help = {
    name: ""testtest""
}


client.login(botconfig.token);
</code></pre>
"
60831555,"<p>I was making a discord bot and I use <code>request.get(url)</code> to get an online CSV file  (one of these 3 <a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">c</a>, <a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">r</a>, <a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv"" rel=""nofollow noreferrer"">d</a>). This was working up to yesterday and without making any changes to my program (as far as I can remember) it suddenly stopped working today.</p>

<pre class=""lang-js prettyprint-override""><code>function getData(source) {
            let rows = [];
            console.log('test');
            request.get(source) 
                .pipe(new StringStream())
                .CSVParse() 
                .consume(object =&gt; rows.push(object)) 
                .then(() =&gt; {
                    console.log('hello');
                    let arr = searchRow(rows, country);
                    let finalArray = formatForGraph(filterCasesDecreasing(filterCasesDupes(filterCasesEmpty(arr)))); // Filters out stuff, configure this as you like
                    generateGraph(finalArray);
                });
        }
</code></pre>

<p>I can this function on one of the 3 urls I mentioned earlier and while the first console.log works the second one doesn't. I am using Plot.ly for plotting but I doubt that has anything to do with my problem since the second console log comes before the graph function. Note that I get no error message from this it just doesnt do anything and the bot keeps working if I send other commands.</p>

<p>Edit: Forgot to mention this but both the url and the country have the intended values inside getData.</p>
"
60881057,"<p>i have tried all possible solve from stackoverflow and github nothing working..its works fine on expo.. but expo build apk size is huge so i want to use react native cli.I have imported All scrren component in app.js they worked problem is in Drawer.js i guess.. I have changed file name exported differently nothing works
This is my Drawer.js code</p>

<pre><code>import React from 'react';
import {View, Button, Text, Image, StyleSheet} from 'react-native';
import {createStackNavigator} from '@react-navigation/stack';
import {
  DrawerItem,
  createDrawerNavigator,
  DrawerContentScrollView,
} from '@react-navigation/drawer';
import Animated from 'react-native-reanimated';
import {
  AntDesign,
  MaterialCommunityIcons,
  FontAwesome5,
} from 'react-native-vector-icons';

import {LinearGradient} from 'react-native-linear-gradient';

// screens
import Dashboard from '../screens/Corona';
import Messages from '../screens/tes';
import Contact from '../screens/Dashboard';
import WHO from '../screens/WHO';

const Stack = createStackNavigator();
const Drawer = createDrawerNavigator();

const Screens = ({navigation, style}) =&gt; {
  return (
    &lt;Animated.View style={StyleSheet.flatten([styles.stack, style])}&gt;
      &lt;Stack.Navigator
        screenOptions={{
          headerTransparent: true,
          headerTitle: null,
          headerLeft: () =&gt; (
            &lt;Button transparent onPress={() =&gt; navigation.openDrawer()}&gt;
              &lt;MaterialCommunityIcons
                name=""menu""
                size={24}
                color=""#ff5c2c""
                style={{paddingHorizontal: 10}}
              /&gt;
            &lt;/Button&gt;
          ),
        }}&gt;
        &lt;Stack.Screen name=""Home""&gt;
          {props =&gt; &lt;Dashboard {...props} /&gt;}
        &lt;/Stack.Screen&gt;
        &lt;Stack.Screen name=""Messages""&gt;
          {props =&gt; &lt;Messages {...props} /&gt;}
        &lt;/Stack.Screen&gt;
        &lt;Stack.Screen name=""Contact""&gt;
          {props =&gt; &lt;Contact {...props} /&gt;}
        &lt;/Stack.Screen&gt;
        &lt;Stack.Screen name=""WHO""&gt;{props =&gt; &lt;WHO {...props} /&gt;}&lt;/Stack.Screen&gt;
      &lt;/Stack.Navigator&gt;
    &lt;/Animated.View&gt;
  );
};

const DrawerContent = props =&gt; {
  return (
    &lt;DrawerContentScrollView
      {...props}
      scrollEnabled={false}
      contentContainerStyle={{flex: 1}}&gt;
      &lt;View&gt;
        &lt;View flex={0.4} margin={20} bottom&gt;
          &lt;Image
            source={{
              uri: 'https://i.ibb.co/6s5NRyh/output-onlinepngtools.png',
              height: 60,
              width: 60,
              scale: 0.5,
            }}
            resizeMode=""center""
            style={styles.avatar}
          /&gt;
          &lt;Text white title&gt;
            Covid-19 CoronaVirus Outbreak
          &lt;/Text&gt;
        &lt;/View&gt;
        &lt;View&gt;
          &lt;DrawerItem
            label=""CORONA UPDATE""
            labelStyle={styles.drawerLabel}
            style={styles.drawerItem}
            onPress={() =&gt; props.navigation.navigate('Home')}
            icon={() =&gt; (
              &lt;MaterialCommunityIcons name=""update"" color=""white"" size={16} /&gt;
            )}
          /&gt;
          &lt;DrawerItem
            label="" DONATE বিদ্যানন্দ - Bidyanondo""
            labelStyle={{color: 'white', marginLeft: -16}}
            style={{alignItems: 'flex-start', marginVertical: 0}}
            onPress={() =&gt; props.navigation.navigate('Messages')}
            icon={() =&gt; &lt;FontAwesome5 name=""donate"" color=""white"" size={16} /&gt;}
          /&gt;
          &lt;DrawerItem
            label=""INFORMATION""
            labelStyle={{color: 'white', marginLeft: -16}}
            style={{alignItems: 'flex-start', marginVertical: 0}}
            onPress={() =&gt; props.navigation.navigate('Contact')}
            icon={() =&gt; (
              &lt;MaterialCommunityIcons
                name=""information""
                color=""white""
                size={16}
              /&gt;
            )}
          /&gt;
          &lt;DrawerItem
            label=""WHO INFORMATION""
            labelStyle={{color: 'white', marginLeft: -16}}
            style={{alignItems: 'flex-start', marginVertical: 0}}
            onPress={() =&gt; props.navigation.navigate('WHO')}
            icon={() =&gt; (
              &lt;MaterialCommunityIcons
                name=""information""
                color=""white""
                size={16}
              /&gt;
            )}
          /&gt;
        &lt;/View&gt;
      &lt;/View&gt;
    &lt;/DrawerContentScrollView&gt;
  );
};

export default () =&gt; {
  const [progress, setProgress] = React.useState(new Animated.Value(0));
  const scale = Animated.interpolate(progress, {
    inputRange: [0, 1],
    outputRange: [1, 0.8],
  });
  const borderRadius = Animated.interpolate(progress, {
    inputRange: [0, 1],
    outputRange: [0, 16],
  });

  const animatedStyle = {borderRadius, transform: [{scale}]};

  return (
    &lt;LinearGradient style={{flex: 1}} colors={['#050505', '#2B2f37']}&gt;
      &lt;Drawer.Navigator
        // hideStatusBar
        drawerType=""slide""
        overlayColor=""transparent""
        drawerStyle={styles.drawerStyles}
        contentContainerStyle={{flex: 1}}
        drawerContentOptions={{
          activeBackgroundColor: 'transparent',
          activeTintColor: 'white',
          inactiveTintColor: 'white',
        }}
        sceneContainerStyle={{backgroundColor: 'transparent'}}
        drawerContent={props =&gt; {
          setProgress(props.progress);
          return &lt;DrawerContent {...props} /&gt;;
        }}&gt;
        &lt;Drawer.Screen name=""Screens""&gt;
          {props =&gt; &lt;Screens {...props} style={animatedStyle} /&gt;}
        &lt;/Drawer.Screen&gt;
      &lt;/Drawer.Navigator&gt;
    &lt;/LinearGradient&gt;
  );
};

const styles = StyleSheet.create({
  stack: {
    flex: 1,
    shadowColor: '#FFF',
    shadowOffset: {
      width: 0,
      height: 8,
    },
    shadowOpacity: 0.44,
    shadowRadius: 10.32,
    elevation: 5,
    // overflow: 'scroll',
    // borderWidth: 1,
  },
  drawerStyles: {flex: 1, width: '50%', backgroundColor: 'transparent'},
  drawerItem: {alignItems: 'flex-start', marginVertical: 0},
  drawerLabel: {color: 'white', marginLeft: -16},
  avatar: {
    borderRadius: 60,
    marginBottom: 16,
    borderColor: 'white',
    borderWidth: StyleSheet.hairlineWidth,
  },
});
</code></pre>

<p>My App.js</p>

<pre><code>import React from 'react';
import {NavigationContainer} from '@react-navigation/native';
import ApolloClient from 'apollo-boost';
import {ApolloProvider} from '@apollo/react-hooks';
import Drawer from './navigation/Drawer';

const client = new ApolloClient({
  uri: 'https://covid19-graphql.now.sh/',
});

export default () =&gt; {
  return (
    &lt;ApolloProvider client={client}&gt;
      &lt;NavigationContainer&gt;
        &lt;Drawer /&gt;
      &lt;/NavigationContainer&gt;
    &lt;/ApolloProvider&gt;
  );
};
</code></pre>
"
61355581,"<p>I'm trying to use Knexjs to handle my database in my application, but I'm not having as much success. He is not able to find the tables to make the inserts with the request and in fact the tables in pgadmin, are very strange ... has anyone been there?</p>

<p><strong><em>knexfile.j</em>s</strong></p>

<pre><code>module.exports = {
  development: {
    client: 'pg',
    connection: {
      host : '127.0.0.1',
      user : 'postgres',
      password : 'admin123',
      database : 'covid',
      charset: 'utf8'
    },
    migrations: {
      directory: './src/database/migrations',
    },
    seeds: {
      directory: './src/database/seeds'
    }
}};
</code></pre>

<p><strong><em>create_casos.js (migrate)</em></strong></p>

<pre><code>exports.up = function(knex) {

    knex.schema.createTable('casos', function(table){   
        table.string('titulo').notNullable()
        table.string('email').notNullable()
    })    
};

exports.down = function(knex) {
    knex.schema.dropTable('casos')
};
</code></pre>

<p><strong><em>CasosController.js</em></strong></p>

<pre><code>module.exports = {

    async create( request, response ){

        try {
            const { titulo, email } = request.body;

            await connection('casos').insert({ titulo, email })

            response.send(request.body)

        } catch (err) {
            return response.status(400).send(err)
        }
    }}
</code></pre>

<p><a href=""https://i.stack.imgur.com/OTdtA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/OTdtA.png"" alt=""Image with the error""></a></p>
"
59927865,"<p>I tried many ways to get value of the attribute isPermaLink using protractor.</p>

<p>I can get the value of any other element fine, but isPermaLink always returns null..</p>

<p><strong>HTML</strong></p>

<pre><code>&lt;guid isPermaLink=""false""&gt;public-anger-grows-over-coronavirus-123829864.html&lt;/guid&gt;
</code></pre>

<p><strong>Code</strong></p>

<pre><code>const isPerma = element(by.xpath('//guid[@isPermaLink]')).
console.log('isPermaLink value ', await isPerma.getAttribute('isPermaLink'));
</code></pre>

<p>If I try other elements like source tag I can get the value</p>

<pre><code>&lt;source url=""http://www.ap.org/""&gt;Associated Press&lt;/source&gt;
</code></pre>

<p><strong>Element located in dev tools</strong>
<a href=""https://i.stack.imgur.com/A2qDP.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/A2qDP.png"" alt=""DevTools Screenshot""></a></p>

<p><strong>Link to Yahoo Rss feed being used:</strong> <a href=""https://news.yahoo.com/rss/"" rel=""nofollow noreferrer"">https://news.yahoo.com/rss/</a></p>
"
61342984,"<p>I am trying to fetch data via API to Google sheets, I am able to get ""NewConfirmed"" and other few fields but not able to get ""Countries"" data. Please help.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>function Covid19() {
  
  // Call the COVID19 API
  var response = UrlFetchApp.fetch(""https://api.covid19api.com/summary"");
  
  // Parse the JSON reply
  var json=response.getContentText();
  var data=JSON.parse(json);
  var sheet = SpreadsheetApp.getActiveSheet();
  var i = 2;

  for each (var info in data)
    {
      sheet.getRange(i,1).setValue([info['NewConfirmed']]);
      sheet.getRange(i,2).setValue([info['Country']]);
     
      i = i + 1;
  }</code></pre>
</div>
</div>
</p>
"
60726608,"<p>I have a problem whit this (file name  <strong><em>jsonRead.js</em></strong>):</p>

<pre><code>var getJSON = require(""get-json"");
'use strict';

module.exports.endpoint = (event, context, callback) =&gt; {
    const response = {
        statusCode: 200,
        body: JSON.stringify(load()),
    };
    callback(null, response);
};
function load(){
        getJSON('https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-json/dpc-covid19-ita-province.json', function(error, response){
            return response
        });
    }
</code></pre>

<p>when I try this and lunch from terminal <code>sls offline</code> my output is empty, but if I console.log the response of getJson I can see the JSON file from the URL.</p>

<p>anyone can help me? I have no idea.</p>

<p>my <strong><em>serverless.yml</em></strong></p>

<pre><code>org: name
app: my-express-application-app
service: my-express-application
provider:
  name: aws
  runtime: nodejs10.x
plugins:
  - serverless-offline
functions:
  loadJson:
    handler: jsonRead.endpoint
    events:
      - http:
          path: readjson
          method: get
</code></pre>
"
61493169,"<p>I’m building a bar chart with d3.js, and for some reason my x axis is ever so slightly misaligned with my bars. I’ve combed through my code and can’t seem to figure out why. I’m sure it’s something simple, but I just can’t put my finger on it. Any chance I could get another pair of eyes to see what I’ve missed?
The JavaScript:</p>

<pre><code>let months = [""January"", ""February"", ""March"", ""April"", ""May"", ""June"", ""July"", ""August"", ""September"", ""October"", ""November"", ""December""];

// function fired when state is selected
document.getElementById(""state-select"").addEventListener(""change"", (e) =&gt; {
//   if there's already a chart, remove it
  let chart = document.getElementById(""chart"");
  if (chart) {
    chart.remove();
  };
  let state = e.target.value;
//   get state data
  fetch(`https://covidtracking.com/api/v1/states/${state}/daily.json`)
    .then((response) =&gt; response.json())
    .then((data) =&gt; {
//     sort data by date, chop off initial null value
      data.sort((a, b) =&gt; a.date - b.date);
      data = data.slice(1);
//     turn data date strings into date objects
      data.forEach(item =&gt; {
        if (item.positiveIncrease &lt; 0){
          item.positiveIncrease = 0
        }
        let dateObject = new Date(item.dateChecked);
        let year = dateObject.getFullYear();
        let month = dateObject.getMonth();
        let day = dateObject.getDate();
        item.dateChecked = new Date(year, month, day);
      });


//     set variables for dimensions and spacing
      const svgWidth = window.innerWidth * .8;
      const svgHeight = window.innerHeight * .8;
      const padding = 40;
      const chartWidth = svgWidth - padding * 2;
      const chartHeight = svgHeight - padding * 2;
      const barSpace = 3;
      const barWidth = chartWidth / data.length - barSpace;

//    build y scale
      const yScale = d3.scaleLinear();
      yScale.domain([
        d3.min(data, (d) =&gt; d.positiveIncrease),
        d3.max(data, (d) =&gt; d.positiveIncrease),
      ]);
      yScale.range([chartHeight, 0]);

//     build y axis
      const yAxis = d3.axisLeft().scale(yScale);

//     build x scale
      const xScale = d3.scaleTime();
      xScale.domain([d3.min(data, d =&gt; d.dateChecked), d3.max(data, d =&gt; d.dateChecked)]);
      xScale.range([0, chartWidth]);

//     build x axis
      const xAxis = d3.axisBottom().scale(xScale);

//     add svg to svg wrapper
      const svg = d3
        .select(""#svg-wrapper"")
        .append(""svg"")
        .attr(""width"", svgWidth)
        .attr(""height"", svgHeight)
        .attr('id', 'chart');

//      add axes
      svg.append('g').attr('transform', `translate(${padding}, ${padding})`).call(yAxis);
      svg.append('g').attr('transform', `translate(${padding}, ${chartHeight + padding })`).call(xAxis);

//     add bars
      let rect = svg
        .selectAll(""rect"")
        .data(data)
        .enter()
        .append(""rect"")
        .attr(""class"", ""bar"")
        .attr(""width"", barWidth)
        .attr(""height"", (d) =&gt; yScale(0) - yScale(d.positiveIncrease))
        .attr(""x"", (d, i) =&gt; i * (barWidth + barSpace) + padding)
        .attr(""y"", (d) =&gt; yScale(d.positiveIncrease) + padding);

//     add title to rects
      rect.append(""title"").text((d) =&gt; {return `${d.positiveIncrease}, ${months[d.dateChecked.getMonth()]} ${d.dateChecked.getDate()}`});

//     add header
      svg
        .append(""text"")
        .attr(""x"", 50)
        .attr(""y"", 50)
        .text(state + "" New Cases Daily"")
        .style(""font-size"", ""1.5rem"")
        .style(""font-weight"", ""bold"");
    });
});
</code></pre>

<p>And <a href=""https://codepen.io/LuosRestil/pen/MWaoyRr"" rel=""nofollow noreferrer"">here's a CodePen</a> of the project.</p>
"
60761444,"<p>I am trying to build a simple website. Simply use vuejs to display data after retrieving. But then I encountered a problem, specifically as follows:</p>

<p>I have retrieved and manipulated data. All data after processing is put into an array. After that, I can still display the result array, but when accessing each element in that array, the result is 'undefined'. I do not know why.</p>

<p><strong>What have I tried</strong></p>

<ul>
<li><p>Manipulation via an intermediate variable. The result is still inaccessible to the elements in both arrays.</p></li>
<li><p>Change the order of console commands.</p></li>
</ul>

<p><strong>My code</strong></p>

<pre><code>&lt;script&gt;
    const axios = require('axios');

    export default {
        data: function() {
            return {
                arr_link: [],
            } 
        },
        created() {
            axios.get('https://api.rss2json.com/v1/api.json?rss_url=https://thanhnien.vn/rss/viet-nam.rss', {
                params: {
                    api_key: 'my_api_key',
                    count: 50
                }
            })
            .then(res=&gt;{
                var result     = res.data.items;
                var char_check = /(Covid|corona|Bệnh nhân số|Phong tỏa|cách ly|bệnh nhân thứ|ncov|Covid-19)/i;

                for (var i = 0; i &lt; result.length; i++) {                         // For loop through the data then 
                    if (char_check.test(result[i].title)) {                       // reate an object to push inside
                        var get_link = result[i].link;                            // arr_link array.
                        var get_text = result[i].title;
                        var link_obj = {id: i, src: get_link, text: get_text}; 
                        this.arr_link.push(link_obj);   
                    }
                }
            })
            .catch(err=&gt;console.log(err));

            console.log(this.arr_link); // Still can show it

            console.log(this.arr_link[0]); // Undefined result, I have also tried with this.arr_link[1] or another index.
        }
    }
&lt;/script&gt;
</code></pre>
"
61603552,"<p>I have a form code that the api is a PUT method, I have a part where I have to send it in the form of a objects, but when I send it it sends it to me as an array, they also tell me that I have to send them if it is true or false</p>

<p><a href=""https://i.stack.imgur.com/HBSrI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HBSrI.png"" alt=""enter image description here""></a></p>

<pre><code>handleSubmit = async (event) =&gt; {
    const {
      state,
      city,
      mild_symptoms = [],
       } = event

    const YES = ""Si""
      console.log(event)

    try {
      const myHeaders = new Headers();
      const url =
        ""XXXXXXXXX"";
      myHeaders.append(
        ""x-api-key"",
        ""XXXXX""
      );

      myHeaders.append(""state"", state);
      myHeaders.append(""city"", city);
      myHeaders.append(
        ""mild_symptoms"",
        `{""flu_syndrome"": ${mild_symptoms.includes(""flu_syndrome"")}, ""conjunctivitis"": ${mild_symptoms.includes(""conjunctivitis"")}, ""muscle_pain"": ${mild_symptoms.includes(""muscle_pain"")}}`
      );
      var requestOptions = {
        method: ""PUT"",
        headers: myHeaders,
        mode: ""cors""
      };
      const response = await fetch(url, requestOptions);
      console.log(""FIRST RESPONSE "", response);
      const result = await response.text();
      console.log(""RESULT"", result);
      Modal.success({
        title: ""Éxito"",
        content: ""Datos enviados correctamente"",
        onOk: ()=&gt;{
          window.location.href = ""https://covid19.gob.sv/orientaciones-tecnicas/""
        }
      })
    } catch (error) {
      console.log(""ERROR"", error);
    }
</code></pre>

<p>I have to send this as a objects and not as an array</p>

<pre><code>""mild_symptoms"",
        `{""flu_syndrome"": ${mild_symptoms.includes(""flu_syndrome"")}, ""conjunctivitis"": ${mild_symptoms.includes(""conjunctivitis"")}, ""muscle_pain"": ${mild_symptoms.includes(""muscle_pain"")}}`
      );
</code></pre>
"
60991142,"<p>I am working in angular app where I am working on COVID 19 app.</p>

<p>Here I have 2 components where component A list of all the states and component B list all the district of the particular state.</p>

<p>Here is my stack blitz link <a href=""https://stackblitz.com/github/mehulk05/COVOID-19"" rel=""nofollow noreferrer"">stack blitz link</a></p>

<p>I want my output like this <a href=""https://www.covid19india.org/"" rel=""nofollow noreferrer"">expected output</a></p>

<p>I got reference here from stack overflow <a href=""https://stackoverflow.com/questions/48127199/angular4-show-hide-content-inside-a-loop"">stack overflow reference</a></p>

<p>Now I have displayed all the data of component in table format and when I click on that state it should load all the data of clicked state and when I click on that state again it should get closed. Also if I click on other state lists of all district fr that state should get displayed</p>

<p>But I don't know where to put my <code>&lt;app-componentB&gt;&lt;/app-componentB&gt;</code> because if put it inside for loop and if I try to display list for one state it displays the same list of district under all states</p>

<p>Here is a piece of my code</p>

<p><strong>componentA.html</strong></p>

<pre><code>  &lt;tbody *ngFor=""let data of statewisedata;let i=index""&gt;
                &lt;span class=""dropdown rotateDownRight""&gt;&lt;svg xmlns=""http://www.w3.org/2000/svg"" width=""24"" height=""24"" viewBox=""0 0 24 24"" fill=""none"" stroke=""currentColor"" stroke-width=""2"" stroke-linecap=""round"" stroke-linejoin=""round""&gt;&lt;polyline points=""6 9 12 15 18 9""&gt;&lt;/polyline&gt;&lt;/svg&gt;&lt;/span&gt;

                &lt;tr class=""state""&gt;
                    &lt;td (click)=""OngetState(data.state)"" style=""font-weight: 600;""&gt;{{data.state}}&lt;/td&gt;



                    &lt;td style=""color: inherit;""&gt;{{data.confirmed}}

                        &lt;span *ngIf='DailystateStatus[i]?.confirmed !==0 || DailystateStatus[i]?.confirmed &lt; 0 ;' class=""deltas"" style=""color: rgb(255, 7, 58);""&gt;&lt;svg xmlns=""http://www.w3.org/2000/svg"" width=""24"" height=""24"" viewBox=""0 0 24 24"" fill=""none"" stroke=""currentColor"" stroke-width=""2"" stroke-linecap=""round"" stroke-linejoin=""round""&gt;&lt;line x1=""12"" y1=""19"" x2=""12"" y2=""5""&gt;&lt;/line&gt;&lt;polyline points=""5 12 12 5 19 12""&gt;&lt;/polyline&gt;
                                &lt;/svg&gt;    {{DailystateStatus[i]?.confirmed}}&lt;/span&gt;

                    &lt;/td&gt;


                    &lt;td style=""color: inherit;""&gt;{{data.active}}&lt;/td&gt;
                    &lt;td style=""color: inherit;""&gt;{{data.recovered}}&lt;/td&gt;
                    &lt;td style=""color: inherit;""&gt;{{data.deaths}}&lt;/td&gt;

                &lt;/tr&gt;


 &lt;app-district *ngIf=""!showDistrict""&gt;&lt;/app-district&gt;

        &lt;/tbody&gt;
</code></pre>

<p><strong>componentA.ts</strong></p>

<pre><code> showDistrict=true
  OngetState(state) {
    this.cs.getState(state)
    this.cs.getDataDistrictWise(state)
    this.showDistrict=!this.showDistrict
  }
</code></pre>
"
60787121,"<p>I am trying to loop through an object that has been parsed from a CSV file of Locations, and Lat/Lng pairs. But when I loop through this object, the first loop returns my object with all the values as undefined. My code is as follows: </p>

<pre><code>import React, { Component, useState, useEffect } from 'react';
import { LatLng } from 'leaflet';
import { Map, TileLayer, CircleMarker, Popup, Marker } from 'react-leaflet';
import CovidCasesClean from './CovidCasesClean.csv';
import Papa from 'papaparse';

export default function PlaceMarker() {
    const latlng = [null];
    const [rows, setRows] = React.useState([])
    const [data, setData] = React.useState({});

    React.useEffect(() =&gt; {
      async function getData() {
        const response = await fetch('/data/CovidCasesClean.csv')
        const reader = response.body.getReader()
        const result = await reader.read() // raw array
        const decoder = new TextDecoder('utf-8')
        const csv = decoder.decode(result.value) // the csv text
        console.log(csv)
        const results = Papa.parse(csv, { header: true, skipEmptyLines: true}) // object with { data, errors, meta }
        console.log(results)
        const rows = results.data
        console.log(rows)
        // array of objects
        setRows(rows)
        rows.map((item, i) =&gt; {
          const rowObj = {item}
          //console.log(rowObj)
          console.log(i)
          setData({
            ...data, key: i, ...data, location: rowObj.item.Location, ...data, latitude: parseFloat(rowObj.item.Latitude), ...data, longitude: parseFloat(rowObj.item.Longitude), ...data, cases: parseFloat(rowObj.item.TotalCases)
          })
        })
      }
      getData()
    }, []) // [] means just do this once, after initial render
    return (
      &lt;div&gt;{console.log(data.key, data.location, data.latitude, data.longitude, data.cases)}&lt;/div&gt; 
    )
  }
</code></pre>

<p>When the console line: <code>&lt;div&gt;{console.log(data.key, data.location, data.latitude, data.longitude, data.cases)}&lt;/div&gt;</code> is ran, the first result returns: </p>

<blockquote>
  <p>undefined undefined undefined undefined undefined</p>
</blockquote>

<p>whereas the second run through returns the correct object like so: </p>

<blockquote>
  <p>0 Barking and Dagenham 53.546299 -1.46786 18 </p>
</blockquote>

<p>This causes my creating a marker object to fail as the first object is not a latlng pair, I have been trying to create markers like so:</p>

<pre class=""lang-html prettyprint-override""><code>&lt;Marker position={(data.longitude, data.latitude)}&gt;
  &lt;Popup&gt;
    &lt;span&gt;
      A pretty CSS3 popup.
      &lt;br /&gt;
      Easily customizable.
    &lt;/span&gt;
  &lt;/Popup&gt;
&lt;/Marker&gt;;
</code></pre>

<p>This is where the error occurs ^ 
Any ideas where I am going wrong, this is my first react project any help appreciated!</p>

<p>CSV file format: </p>

<pre><code>Location,TotalCases,Latitude,Longitude
Barking and Dagenham,18,53.546299,-1.46786
Barnet,28,51.605499,-0.207715
</code></pre>
"
61003105,"<p>So I am using React to pull Covid-19 data from a CSV using papaparse. I then filter this array to only show results from today. I am using a functional react component like so: </p>

<pre><code>import React, { Component, useState, useEffect } from 'react';
import Papa from 'papaparse'
import dataJSON from './data/CovidLocations.json'
import {Tooltip, Circle } from ""react-leaflet"";

const DashBoard = (props) =&gt; {
    const [data, setDataArr] = useState([]);
    const [dailyResults, setDailyResults] = useState([]);


    useEffect(() =&gt; {    
        getData()
    }, [dailyResults]); 

    const getData = () =&gt; {
        Papa.parse(""https://raw.githubusercontent.com/tomwhite/covid-19-uk-data/master/data/covid-19-cases-uk.csv"", {
            download: true,
            header: true,
            complete: (results) =&gt; {
                var data = results.data
                setDataArr(data)
                setData(data)
            }
        });
    }

    const setData = (data) =&gt; {
        let merged = [];
        let result = [];

        for(let i=0; i&lt; data.length; i++) {
            merged.push({
             ...data[i], 
             ...(dataJSON.find((itmInner) =&gt; itmInner.Location === data[i].Area))}
            );  
        }

        result = merged.filter(obj =&gt; {
            return obj.Date === ""2020-04-02""
        });

        let output = result.filter(obj =&gt; Object.keys(obj).includes(""Latitude""));

        setDailyResults(output)
        console.log(dailyResults)

    }


        return(
            &lt;div&gt;
            {dailyResults &amp;&amp;
            dailyResults.map(({Location, Latitude, Longitude, TotalCases}, i) =&gt; (
            &lt;Circle
                key={`markers-${i}`}
                center={[Latitude, Longitude]}
                radius={35 * TotalCases}
                fillColor=""red""
                color=""black""
                weight=""0.5""
            &gt;
                &lt;Tooltip&gt;
                &lt;span&gt;
                    &lt;b&gt;Location&lt;/b&gt;: {Location}
                    &lt;br /&gt;
                    &lt;b&gt;Total Cases&lt;/b&gt;: {TotalCases}
                &lt;/span&gt;
                &lt;/Tooltip&gt;
            &lt;/Circle&gt;
            ))}
            &lt;/div&gt;
        )

}

export default DashBoard;
</code></pre>

<p>At line 46 here <code>console.log(dailyResults)</code> it returns the object correctly, mapped with the other json object, but it then iterates through the object 172 times (the same number of array values). What I need is this code to execute, map the array from the CSV, add the latlngs (all which works fine) but then in the return statement I need the array of 172 to not keep looping so It can be passed into <code>react-leaflet</code> as an object to create map markers. It seems like a simple issue, I just do not know how to implement it.  </p>

<p>dataJSON format: </p>

<pre><code>  {
    ""Location"": ""Barking and Dagenham"",
    ""Latitude"": 53.546299,
    ""Longitude"": -1.46786
  }
</code></pre>
"
61194917,"<p>Im am creating a COVID-19 simulator where every circle in the simulation is a person. When two persons hit each other, i want the direction that they ""bounce"" off each other to be random. Currently i just mirror the current speed, which means the the persons follow a pre defined path, even when bouncing of each other.</p>

<p>This is my ""move"" function</p>

<pre><code> move() {
        if (this.willMove) {
            this.xPos += this.xSpeed;
            this.yPos += this.ySpeed;
        }
    }

</code></pre>

<p>This where i do my collision detection</p>

<pre><code>collision(other) {
        let distance = dist(this.xPos, this.yPos, other.xPos, other.yPos);

        if (distance &lt; this.personRadius + other.personRadius) {
            this.changeDirection();
            return true;
        } else {
            return false;
        }
    }
</code></pre>

<p>The things handeling the changing of direction:</p>

<pre><code>changeDirection() {
        this.mirrorXSpeed();
        this.mirrorYSpeed();
    }

    mirrorXSpeed() {
        this.xSpeed = this.xSpeed * -1;
    }

    mirrorYSpeed() {
        this.ySpeed = this.ySpeed * -1;
    }
</code></pre>

<p>I have tried multiplying the speed by -0.95, but this just decreases the speed.</p>

<p>The full project can be found here: <a href=""https://github.com/perkynades/Simulation-of-COVID19/tree/part1"" rel=""nofollow noreferrer"">https://github.com/perkynades/Simulation-of-COVID19/tree/part1</a></p>
"
61268867,"<p>I have set up a Vue project and initialized firebase functions (using Firebase CLI). Created a function that works fine when deployed from my local machine to the cloud (both with ""firebase Deploy"" and ""firebase deploy --only functions""). The issue arises during cloud build (during CI/CD pipeline). I get a  ""sh: 1: eslint: not found"" error in the build log. The Vue project structure looks like this;</p>

<p><a href=""https://i.stack.imgur.com/Ll06S.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ll06S.png"" alt=""view file structure""></a><a href=""https://i.stack.imgur.com/bhd3x.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bhd3x.png"" alt=""enter image description here""></a></p>

<p>The build is triggered by commits to the master... the build config is as follows;</p>

<pre><code>steps:
# Install
- name: 'gcr.io/cloud-builders/npm'
  args: ['install']
# Build
- name: 'gcr.io/cloud-builders/npm'
  args: ['run', 'build', '--prod']
# Deploy
- name: 'gcr.io/$PROJECT_ID/firebase'
  args: ['deploy']
</code></pre>

<p>The error occurs at the deploy step... the full build log is as follows;</p>

<pre><code>Finished Step #1
Starting Step #2
Step #2: Pulling image: gcr.io/covid-info-bw/firebase
Step #2: Using default tag: latest
Step #2: latest: Pulling from covid-info-bw/firebase
Step #2: c0c53f743a40: Already exists
Step #2: 66997431d390: Already exists 
Step #2: 0ea865e2909f: Already exists 
Step #2: 584bf23912b7: Already exists
Step #2: 3c4c73959f29: Already exists
Step #2: 63e05266fc4b: Already exists
Step #2: 7b37ba8cd979: Already exists
Step #2: 3a18f94fe18a: Already exists
Step #2: a000f3263f8b: Already exists
Step #2: 3a5d0859c8ef: Pulling fs layer
Step #2: 575701571da4: Pulling fs layer
Step #2: 8e3be3979b6a: Pulling fs layer
Step #2: 8e3be3979b6a: Verifying Checksum
Step #2: 8e3be3979b6a: Download complete
Step #2: 575701571da4: Verifying Checksum
Step #2: 575701571da4: Download complete
Step #2: 3a5d0859c8ef: Verifying Checksum
Step #2: 3a5d0859c8ef: Download complete
Step #2: 3a5d0859c8ef: Pull complete
Step #2: 575701571da4: Pull complete
Step #2: 8e3be3979b6a: Pull complete
Step #2: Digest: sha256:35d71d1c92b972de31f223e63fd25f1be6c419f28b24c106187139c9aa3e6cfa
Step #2: Status: Downloaded newer image for gcr.io/covid-info-bw/firebase:latest
Step #2: gcr.io/covid-info-bw/firebase:latest
Step #2: 
Step #2: [1m[37m===[39m Deploying to 'covid-info-bw'...[22m
Step #2: 
Step #2: [1m[36mi [39m[22m deploying [1mfunctions, hosting[22m
Step #2: Running command: npm --prefix ./functions run lint
Step #2: 
Step #2: &gt; functions@ lint /workspace/functions
Step #2: &gt; eslint .
Step #2: 
Step #2: sh: 1: eslint: not found
Step #2: npm ERR! code ELIFECYCLE
Step #2: npm ERR! syscall spawn
Step #2: npm ERR! file sh
Step #2: npm ERR! errno ENOENT 
Step #2: npm ERR! functions@ lint: `eslint .`
Step #2: npm ERR! spawn ENOENT
Step #2: npm ERR! 
Step #2: npm ERR! Failed at the functions@ lint script.
Step #2: npm ERR! This is probably not a problem with npm. There is likely additional logging output 
above.
Step #2: npm WARN Local package.json exists, but node_modules missing, did you mean to install? 
Step #2: 
Step #2: npm ERR! A complete log of this run can be found in:
Step #2: npm ERR!     /builder/home/.npm/_logs/2020-04-16T23_28_19_649Z-debug.log
Step #2: 
Step #2: [1m[31mError:[39m[22m functions predeploy error: Command terminated with non-zero exit 
code1
Finished Step #2
ERROR
ERROR: build step 2 ""gcr.io/covid-info-bw/firebase"" failed: step exited with non-zero status: 1
</code></pre>

<p>Firebase.json snippet is as follows;</p>

<pre><code> ...
 ""functions"": {
  ""predeploy"": [
    ""npm --prefix ./functions run lint""
   ]
 }
 ...
</code></pre>

<p>This is a link to my <a href=""https://github.com/Abel-Moremi/covid-info-bw"" rel=""nofollow noreferrer"">Repo</a> just for reference</p>
"
60864860,"<p>I am trying to remove extra space around my rendered vector map, I am also attaching image, I need to remove the extra area around the map (colored red) from my render. I tried various settings in scale and translate, also changing size of my element / container. But its not working !. My code is as below :
![Map issue Image for reference](<a href=""https://www.covidtrack.in/img/datamaps_issue.png"" rel=""nofollow noreferrer"">https://www.covidtrack.in/img/datamaps_issue.png</a></p>

<pre><code>&lt;div id=""india"" style=""position: relative; width: 900px; height: 900px; background: #cccdc9""&gt;&lt;/div&gt;


    &lt;script&gt;
            var bubble_map = new Datamap({
                element: document.getElementById('india'),
                scope: 'india',
                responsive: true,
                //height: 600,
                //width: 600,
                geographyConfig: {
                    popupOnHover: true,
                    highlightOnHover: true,
                    borderColor: '#444',
                    borderWidth: 0.9,
                    dataUrl: 'js/india.topo.json'
                    //dataJson: topoJsonData
                },
                fills: {
                    'MAJOR': '#306596',
                    'MEDIUM': '#0fa0fa',
                    'MINOR': '#bada55',
                    defaultFill: '#999999'
                },
                data: {
                    'JH': { fillKey: 'MINOR' },
                    'MH': { fillKey: 'MAJOR' }
                },
                setProjection: function (element) {
                    var projection = d3.geo.mercator()
                        //.center([83, 10])
                        .center([78.9629, 23.5937]) // always in [East Latitude, North Longitude]
                        .scale(1000)
                        //.scale(900)
                        .translate([element.offsetWidth / 2, element.offsetHeight / 2]);

                    var path = d3.geo.path().projection(projection);

                    return { path: path, projection: projection };
                }
            });

            let bubbles = [
                {
                    centered: ""MH"",
                    fillKey: ""MAJOR"",
                    radius: 20,
                    state: ""Maharastra""
                },
                {
                    centered: ""AP"",
                    fillKey: ""MAJOR"",
                    radius: 22,
                    state: ""Andhra Pradesh""
                },
                {
                    centered: ""TN"",
                    fillKey: ""MAJOR"",
                    radius: 16,
                    state: ""Tamil Nadu""
                },
                {
                    centered: ""WB"",
                    fillKey: ""MEDIUM"",
                    radius: 15,
                    state: ""West Bengal""
                },
                {
                    centered: ""MP"",
                    fillKey: ""MEDIUM"",
                    radius: 15,
                    state: ""Madhya Pradesh""
                },
                {
                    centered: ""UP"",
                    fillKey: ""MINOR"",
                    radius: 8,
                    state: ""Uttar Pradesh""
                },
                {
                    centered: ""RJ"",
                    fillKey: ""MINOR"",
                    radius: 7,
                    state: ""Rajasthan""
                }

            ]

            console.log(bubble_map);


            setTimeout(() =&gt; { // only start drawing bubbles on the map when map has rendered completely.

                bubble_map.bubbles(bubbles, {
                    popupTemplate: function (geo, data) {
                        return `&lt;div class=""hoverinfo""&gt;city: ${data.state}, Slums: ${data.radius}%&lt;/div&gt;`;
                    }
                });
            }, 1000);
        &lt;/script&gt;


  [1]: https://covidtrack.in/img/datamaps_issue.png
</code></pre>
"
61038397,"<p>I am using <a href=""https://www.chartjs.org/"" rel=""nofollow noreferrer"">Chart.js</a> and this <a href=""https://github.com/pomber/covid19"" rel=""nofollow noreferrer"">API</a> to create a line graph of covid-19 cases in Australia.
However, the API data is not loading in the chart until I do something like inspect an element on the page or resize the window.</p>

<p><strong>Here is my JS file:</strong></p>

<pre><code>window.onload = function() {
   let dates = [];
   let confirmedCases = [];
   let confirmedRecovered = [];
   let confirmedDeaths = [];

   function addArrayFunc(date, confirmed, recovered, deaths) {
      dates.push(date);
      confirmedCases.push(confirmed);
      confirmedRecovered.push(recovered);
      confirmedDeaths.push(deaths);
   }
   fetch(""https://pomber.github.io/covid19/timeseries.json"")
      .then(response =&gt; response.json())
      .then(cases =&gt; {
         cases[""Australia""].forEach(({
               date,
               confirmed,
               recovered,
               deaths
            }) =&gt;
            addArrayFunc(date, confirmed, recovered, deaths)
         )
      })

   const ctx = document.getElementById('myChart').getContext('2d');
   new Chart(ctx, {
      type: 'line',
      data: {
         labels: dates,
         datasets: [{
               label: 'Confirmed',
               borderColor: 'pink',
               backgroundColor: 'pink',
               fill: 'false',
               data: confirmedCases
            },
            {
               label: 'Recovered',
               borderColor: 'blue',
               backgroundColor: 'blue',
               fill: 'false',
               data: confirmedRecovered
            },
            {
               label: 'Deaths',
               borderColor: 'green',
               backgroundColor: 'green',
               fill: 'false',
               data: confirmedDeaths
            }
         ]
      },
      options: {
         responsive: true,
         title: {
            display: true,
            text: 'Covid-19 Cases in Australia'
         },
      }
   });
}
</code></pre>

<p><strong>Here is my html file:</strong> </p>

<pre><code>&lt;html lang=""en""&gt;
   &lt;head&gt;
      &lt;meta charset=""UTF-8""&gt;
      &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
      &lt;title&gt;Confirmed Covid-19 cases in Australia&lt;/title&gt;
      &lt;style&gt;
         canvas {
            -moz-user-select: none;
            -webkit-user-select: none;
            -ms-user-select: none;
            width: 75%;
         }
      &lt;/style&gt;
      &lt;script src=""script.js""&gt;&lt;/script&gt;
      &lt;script src=""https://cdn.jsdelivr.net/npm/chart.js@2.8.0""&gt;&lt;/script&gt;
   &lt;/head&gt;
   &lt;body&gt;
      &lt;canvas id=""myChart""&gt;&lt;/canvas&gt;
   &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>I believe I am creating the chart before the data has arrived from the URL but I have no idea have to rectify that. Is this something <code>async/await</code> or <code>watch</code> could fix? How would I go implementing that?</p>

<p>Any help would be greatly appreciated.</p>
"
61016452,"<p>I'm using a popup window from <a href=""https://codepen.io/pedrobenoit91/pen/aJGzYg"" rel=""nofollow noreferrer"">https://codepen.io/pedrobenoit91/pen/aJGzYg</a> and have been able to tweak it get it to be responsive. Here is my test page: <a href=""https://cismiami.org/index3.html"" rel=""nofollow noreferrer"">Responsive Popup Window Test</a> Here's the tweaked coding I've used:</p>

<p>HTML5 Page</p>

<pre><code>&lt;script type=""text/javascript"" src=""/js/popupwindow.js""&gt;&lt;/script&gt;
&lt;div class='popup'&gt;
&lt;div class='popwin'&gt;
&lt;span style=""font-size:1.50em; color:#2e5c9d;""&gt;CIS Miami Is Here for Our Students &amp;amp; Families&lt;/span&gt;
&lt;p&gt;
&lt;a href=""/covid19.html""&gt;See what we're doing and view resources &amp;#187;&lt;/a&gt;
&lt;br&gt; 
COVID-19 is impacting our students and families in ways that no one could have possibly imagined. Communities In Schools of Miami remains dedicated to ensuring all
of our students and families have the crucial resources they urgently need at this time, but we can't do it without you.
&lt;br&gt;
blah&lt;br&gt;
blah&lt;br&gt;
blah&lt;br&gt;
blah&lt;br&gt;
blah&lt;br&gt;
blah&lt;br&gt;
blah&lt;br&gt;
blah&lt;br&gt;
blah&lt;br&gt;
blah&lt;br&gt;

  &lt;div style=""display:block; padding:0.50em 0;""&gt;
  &lt;div class=""btnOrange""&gt;&lt;a class=""btn"" href=""https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=SDSKUTE5VQXCW&amp;source=url""&gt;&lt;b&gt;DONATE TO CIS MIAMI &lt;i class=""fas fa-angle-double-right""&gt;&lt;/i&gt;&lt;/b&gt;&lt;/a&gt;&lt;/div&gt;
  &lt;/div&gt;
&lt;div class=""right""&gt;&lt;a href='' class='close closepop'&gt;&lt;i class=""fas fa-times""&gt;&lt;/i&gt; CLOSE&lt;/a&gt;&lt;/div&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p>SCRIPT    </p>

<pre><code>$(function(){
var overlay = $('&lt;div id=""overlay""&gt;&lt;/div&gt;');
overlay.show();
overlay.appendTo(document.body);
$('.popup').show();
$('.close').click(function(){
$('.popup').hide();
overlay.appendTo(document.body).remove();
return false;
});

$('.x').click(function(){
$('.popup').hide();
overlay.appendTo(document.body).remove();
return false;
});
});
</code></pre>

<p>STYLESHEET    </p>

<pre><code>#overlay { position:fixed; top:0; left:0; width:100%; height:100%; background-color:#000;
  filter:alpha(opacity=70); -moz-opacity:0.7; -khtml-opacity:0.7; opacity:0.7; z-index:100; display:none; }
.popup { width:100%; margin:0 auto; display:none; position:fixed; top:0; left:0; z-index:101; } /* Added top and left for positioning */
.popwin { min-width:90%; width:90%; min-height:150px; margin:2.0em auto; background:#fff; position:relative; 
  z-index:103; padding:0.5em 1.0em; border-radius:5px; box-shadow:0 2px 5px #000; } /* Changed with to percentages for responsive. Margin determines height from top */
.popwin p { clear:both; color:#555555; /* text-align:justify; */ font-size:1.2em; font-family:sans-serif; }
.popwin a { text-decoration:none; }
.popwin p a { color:#d91900; font-weight:bold; }
.popwin .x { float:right; height:35px; left:0px; position:relative; top:-25px; width:34px; }
.popwin .x:hover { cursor:pointer; }

a.closepop:link, a.closepop:visited, a.closepop:active { text-decoration:none; color:#444; }
a.closepop:hover { color:#444; text-decoration:none; }
</code></pre>

<p>It works, but on smaller devices, like my phone, the popup doesn't scroll so I can't see all of the content or get to the button to close it. I've been trying different things with no luck so far. Any help would be appreciated.</p>
"
61423705,"<p>I have stacked since 3 days in a bug and I don't have any more ideas how to solve. 
I want to put a dynamic <strong>initial</strong> prop value using <strong>react-native-simple-radio-button</strong> library.
Let me show a piece of code:</p>

<pre><code>this.state = {newPTempVal: 1}

componentDidMount(){
    this.getCoachData();
}

getCoachData = () =&gt; {
    let data = { loginCriteria: this.props.fiscalCode }

    fetch(covidQuestionnaireData(), {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Accept': 'application/json',
        },
        body: JSON.stringify(data)
    })
        .then((response) =&gt; {
            this.setState({
                covidQestionnaireStatus: response.status
            })
            return response.json();
        })
        .then((responseJson) =&gt; {
            this.setState({
                lengthRes: Object.keys(responseJson.apiresponse).length
            })
            let newTemp = responseJson.apiresponse.ptemp.reverse()[0];
            [newTemp].map((item) =&gt; {
                this.setState({
                    ptempVal: item.value
                })
                if (this.state.ptempVal === true) {
                    this.setState({
                        newPTempVal: 0
                    })
                } else {
                    this.setState({
                        newPTempVal: 1
                    })
                }
            })
        })
        .catch((error) =&gt; {
            console.log(error);
        })
}
</code></pre>

<p>Here is the response from the POST request:</p>

<pre><code>{
  _id: '5ea2e30d803a741fa4b49be9',
  value: true 
}
</code></pre>

<p>And here is the react-native-simple-radio-button component</p>

<pre><code>&lt;RadioFrom
  initial={this.state.covidQestionnaireStatus === 201 ? this.state.newPTempVal : 1}
  onPress={(value) =&gt; this.changeTemperature(value)}
  formHorizontal={true}
/&gt;
</code></pre>

<p>In any case even if the this.state.covidQestionnaireStatus !== 201 the initial value 1. 
If I delete newPTempVal: 1 from this.state, it will return always value 0.
Does it have any idea how to solve this issue?</p>

<p>Thank you</p>
"
61580002,"<p>I deploy my Angular application to Heroku, with Node.js as the backend. However, when I deploy to Heroku, the static files page works fine. The page that needs data from backend is infinitely loading. 
This is my Github link: <a href=""https://github.com/guohaoyu110/COVID-19_heroku"" rel=""nofollow noreferrer"">https://github.com/guohaoyu110/COVID-19_heroku</a></p>

<p><strong>my</strong> <code>index.js</code> <strong>as the server file like this:</strong></p>

<pre><code>const port = process.env.PORT || 3001;
app.use(express.static(__dirname + '/dist/covid19-tracker'));

app.get('/*', function(req, res){
    res.sendFile(path.join(__dirname + '/dist/covid19-tracker/index.html'));
});

app.set('port',port);

app.listen(port, () =&gt; {
    console.log(`Listening on port:${port}`);
});
</code></pre>

<p><strong>my</strong> <code>package.json</code> <strong>look like this:</strong></p>

<pre><code>{
  ""name"": ""covid19-tracker"",
  ""version"": ""0.0.0"",
  ""scripts"": {
    ""ng"": ""ng"",
    ""start"": ""node index.js"",
    ""build"": ""ng build"",
    ""test"": ""ng test"",
    ""lint"": ""ng lint"",
    ""e2e"": ""ng e2e"",
    ""heroku-postbuild"": ""ng build --prod""

  },
  ""private"": true,
  ""dependencies"": {
    ""@angular/animations"": ""~9.1.0"",
    ""@angular/cli"": ""~9.1.0"",
    ""@angular/common"": ""~9.1.0"",
    ""@angular/compiler"": ""~9.1.0"",
    ""@angular/compiler-cli"": ""~9.1.0"",
    ""@angular/core"": ""~9.1.0"",
    ""@angular/forms"": ""~9.1.0"",
    ""@angular/platform-browser"": ""~9.1.0"",
    ""@angular/platform-browser-dynamic"": ""~9.1.0"",
    ""@angular/router"": ""~9.1.0"",
    ""chart.js"": ""^2.9.3"",
    ""enhanced-resolve"": ""^4.1.1"",
    ""express"": ""^4.17.1"",
    ""leaflet"": ""^1.6.0"",
    ""locutus"": ""^2.0.11"",
    ""mocha"": ""^7.1.2"",
    ""ng2-google-charts"": ""^5.0.0"",
    ""ngx-bootstrap"": ""^5.5.0"",
    ""ngx-spinner"": ""^9.0.2"",
    ""ngx-toastr"": ""^12.0.1"",
    ""rxjs"": ""~6.5.4"",
    ""tslib"": ""^1.10.0"",
    ""typescript"": ""~3.8.3"",
    ""zone.js"": ""~0.10.2"",
    ""cors"": ""^2.8.5"",
    ""cross-fetch"": ""^3.0.4"",
    ""node-fetch"": ""^2.6.0"",
    ""nodemailer"": ""^6.4.6"",
    ""novelcovid"": ""^1.1.4""
  },
  ""devDependencies"": {
    ""@angular-devkit/build-angular"": ""~0.901.0"",
    ""@angular/language-service"": ""~9.1.0"",
    ""@types/jasmine"": ""~3.5.0"",
    ""@types/jasminewd2"": ""~2.0.3"",
    ""@types/node"": ""^12.11.1"",
    ""codelyzer"": ""^5.1.2"",
    ""jasmine-core"": ""~3.5.0"",
    ""jasmine-spec-reporter"": ""~4.2.1"",
    ""karma"": ""^5.0.2"",
    ""karma-chrome-launcher"": ""~3.1.0"",
    ""karma-coverage-istanbul-reporter"": ""~2.1.0"",
    ""karma-jasmine"": ""~3.0.1"",
    ""karma-jasmine-html-reporter"": ""^1.4.2"",
    ""protractor"": ""~5.4.3"",
    ""ts-node"": ""~8.3.0"",
    ""tslint"": ""~6.1.0""
  },
  ""engines"": {
    ""node"": ""12.16.1"",
    ""npm"": ""6.13.4""
  }
}
</code></pre>

<p>and all the build is successful. It just cannot read data from backend. I cannot figure it out, hope anyone could give me some suggestion.</p>
"
61122913,"<p>I'm trying to fetch <a href=""https://rapidapi.com/KishCom/api/covid-19-coronavirus-statistics"" rel=""nofollow noreferrer"">this</a> api into my android app. However, the emulator screen keeps loading. Can somebody please point out the error?</p>

<p><a href=""https://i.stack.imgur.com/mhiZ8.png"" rel=""nofollow noreferrer"">Check code</a></p>
"
61432172,"<p>How I can get the prediction of the model?
I tried to use .dataSync() but it's not returning the prediction</p>

<p>This is my code:</p>

<pre><code>&lt;script src=""https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js""&gt;&lt;/script&gt;

  &lt;script&gt;

  async function start() {

  const model1 = await tf.loadLayersModel('model_xray/model.json');
  const model2 = await tf.loadLayersModel('model_covid/model.json');

   const canvas = document.getElementById(""myCanvas"");
   var ctx = canvas.getContext(""2d"");
   var tmpImage = new Image();
   tmpImage.src = 'radiografie.jpg';
   tmpImage.onload = function(){
   ctx.drawImage(tmpImage,0,0,224,224);
   imageData = ctx.getImageData(null, 0, 64, 64);
   const tensor = tf.browser.fromPixels(imageData);
   const eTensor = tensor.expandDims(0);
   var prediction = model1.predict(eTensor);
   console.log(prediction.dataSync());
   console.log(imageData);
   console.log(tensor);
   console.log(eTensor);
}

}

start();

  &lt;/script&gt;
</code></pre>

<p>This is the console log result:
<a href=""https://i.stack.imgur.com/difmy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/difmy.png"" alt=""this is the console log result""></a></p>
"
61557076,"<p>This is the <a href=""https://www.covid19india.org/deepdive"" rel=""nofollow noreferrer"">page</a> I am trying to make it dynamic by enabling cross-filtering.
So the thing is they are having multiple API.</p>

<p>For the top first two: <code>TOTAL CASES</code> &amp; <code>DAILY CASES</code> 
They are using this <a href=""https://api.covid19india.org/data.json"" rel=""nofollow noreferrer"">API</a> and the third one in the top is based on this <a href=""https://api.covid19india.org/states_daily.json"" rel=""nofollow noreferrer"">API</a>. </p>

<p>The bottom three <code>AGE</code>, <code>GENDER</code>, and <code>NATIONALITY</code> are from this <a href=""https://api.covid19india.org/raw_data.json"" rel=""nofollow noreferrer"">API</a>.</p>

<p>In all the API one thing is common that is a date but there are some API in which some data are missing for few dates like there is a gap( Not available for some of the dates).</p>

<p>So I thought of combining all the JSON API in terms of dates and then allow cross filter because I believe I can enable cross-filtering between them. Correct me If I am wrong. </p>

<p>Like If I click on gender female since it gives info about total cases where the patient was female so only confirmed cases from the Total cases will change not the recovered, deaths as data is not available. SO I guess I should combine the top 3 charts together and gender, age and nationality charts, together. Then Dc js would be able to handle nicely filtering between each segments (cases related to landmark, cases related to person info).</p>

<p><strong>Line 123:</strong></p>

<pre><code>var log = console.log; 

var q = queue()
    .defer(d3.json, ""https://api.covid19india.org/data.json"")
      .defer(d3.json, ""https://api.rootnet.in/covid19-in/unofficial/covid19india.org/statewise/history"");

    q.await(function(error, data1, data2) {
      log(""==========&gt;"");
    log(""data1:"", error,data1);
    log(""data2:"", data2);
});
</code></pre>

<p>This is not working because I can't see <code>console.log()</code> output.</p>

<p><a href=""https://blockbuilder.org/ninjakx/8c48ab6481311aa0452046d66c4d8701"" rel=""nofollow noreferrer"">https://blockbuilder.org/ninjakx/8c48ab6481311aa0452046d66c4d8701</a></p>

<p>So my questions are:</p>

<p>1) Why d3.queue is not working?</p>

<p>2) Suggestion whether combining all the datas together and allowing a filltering is a good idea or not as there is limited data. Should I go for cross filtering between the same api charts. So in this case I will have 2 segments (cases related to landmark, cases related to person info)..
Using DC js I want to make it more interactive and display more info.</p>
"
61471321,"<p>I am working on a simple project that imports COVID data to a Google Sheet on a daily basis. I am running into a problem that since I am using IMPORTHTML the tables are updating every time the table updates on the website I am using. I don't want this, since the goal is to keep tables from each day's stats. My solution was to copy the table that I import and paste it (values only) right on top of itself. Everything is working, including copy and paste, but PASTE_VALUES does not seem to be working. When I do it manually it solves my problem, but not when done with code.  Here is my code.</p>

<pre><code>function getData() { 


  //get yesterdays date for sheet name and title of table
  const today = new Date()
  const yesterday = new Date(today)

  yesterday.setDate(yesterday.getDate() - 1)

  today.toDateString()
  yesterday.toDateString()


  //open up a new spreadsheet with yesterday's date as name
  var activeSpreadsheet = SpreadsheetApp.getActiveSpreadsheet();
  var yourNewSheet = activeSpreadsheet.getSheetByName(yesterday);

  if (yourNewSheet != null) {
    activeSpreadsheet.deleteSheet(yesterday);
  }

  yourNewSheet = activeSpreadsheet.insertSheet();
  yourNewSheet.setName(yesterday);
  yourNewSheet.activate();  


  //import table into new sheet and put yesterday's date as title on top of table
  //var sheetName = SpreadsheetApp.getActiveSpreadsheet().getSheetByName(yesterday); 
  var queryString = Math.random(); 
  var cellFunction = '= IMPORTHTML(""https://www.worldometers.info/coronavirus/country/us/"",""table"", 2)'

  yourNewSheet.getRange('E1').setValue(yesterday);
  yourNewSheet.getRange('A3').setValue(cellFunction); 


  // copy and paste the range to values only so that the importHTML function doesn't download new data when it updates every day
  yourNewSheet.getRange('A3:Z100').copyTo(yourNewSheet.getRange('A3:Z100'), SpreadsheetApp.CopyPasteType.PASTE_VALUES);


}```
</code></pre>
"
61488250,"<p>Relevant stack-trace below - from Heroku:</p>

<pre><code>2020-04-28T17:49:11.997756+00:00 app[web.1]: Your app is listening on port 14385
2020-04-28T17:49:12.491486+00:00 heroku[web.1]: State changed from starting to up
2020-04-28T17:49:41.748150+00:00 heroku[web.1]: State changed from up to crashed
2020-04-28T17:49:41.649885+00:00 app[web.1]: _stream_readable.js:660
2020-04-28T17:49:41.649896+00:00 app[web.1]: dest.on('unpipe', onunpipe);
2020-04-28T17:49:41.649897+00:00 app[web.1]: ^
2020-04-28T17:49:41.649897+00:00 app[web.1]:
2020-04-28T17:49:41.649898+00:00 app[web.1]: TypeError: dest.on is not a function
2020-04-28T17:49:41.649899+00:00 app[web.1]: at ReadStream.Readable.pipe (_stream_readable.js:660:8)
2020-04-28T17:49:41.649900+00:00 app[web.1]: at SendStream.stream (/app/node_modules/send/index.js:798:10)
2020-04-28T17:49:41.649900+00:00 app[web.1]: at SendStream.send (/app/node_modules/send/index.js:707:8)
2020-04-28T17:49:41.649900+00:00 app[web.1]: at /app/node_modules/send/index.js:774:12
2020-04-28T17:49:41.649901+00:00 app[web.1]: at FSReqCallback.oncomplete (fs.js:172:5)
</code></pre>

<p>From AWS (EC2 using a Bitnami instance for NodeJS apps):</p>

<pre><code>Your app is listening on port 8080
_stream_readable.js:666
  dest.on('unpipe', onunpipe);
       ^

TypeError: dest.on is not a function
    at ReadStream.Readable.pipe (_stream_readable.js:666:8)
    at SendStream.stream (/opt/bitnami/apps/demo/htdocs/node_modules/send/index.js:798:10)
    at SendStream.send (/opt/bitnami/apps/demo/htdocs/node_modules/send/index.js:707:8)
    at /opt/bitnami/apps/coronavirus-demo/htdocs/node_modules/send/index.js:774:12
    at FSReqCallback.oncomplete (fs.js:167:5)
error: Forever detected script exited with code: 1
error: Script restart attempt #1
</code></pre>

<p>I see that we seem to be dying on _stream_readable.js:666 where 'dest.on' isn't defined - and I'm way into the weeds of Node at this point - so I'm not sure what I'm looking for, but I find that we're defining this method further down in the file:</p>

<p><a href=""https://github.com/nodejs/node/blob/master/lib/_stream_readable.js:852"" rel=""nofollow noreferrer"">https://github.com/nodejs/node/blob/master/lib/_stream_readable.js:852</a> -</p>

<p>Is this as simple as we're evaluating this _stream_readable file top-down and we haven't defined on() as of line 666 and that's why it's failing?</p>

<p>But why would it work locally?  The app runs fine with Nanoexpress server on a Macbook Pro - same package.json and lock files - no devDependencies that make any difference (the only devDependencies are like Mocha and Sinon and Chai for tests)</p>

<p>I've run the app locally with NODE_ENV=production and NPM_CONFIG_PRODUCTION=true (it's a React &amp; Express [Nanoexpress] app) and it boots and I can get what I need running just fine.</p>

<p>It's only when I push to Heroku / AWS that I'm getting this failure.  Feels like we're trying to use a function before it's defined...</p>
"
60830399,"<p>Hi please I am stuck I have this code but it renders only numbers like the image below. What am I doing wrong. </p>

<pre><code>       import useStats from '../utils/useStats';

export default function CountrySelector() {
    const countries = useStats('https://covid19.mathdro.id/api/countries');
    console.log(countries);
    if (!countries) return &lt;p&gt;Loading...&lt;/p&gt;
    return (
        &lt;div&gt;
            &lt;select&gt;
                {Object.entries(countries.countries).map(([country, code]) =&gt; (
                    &lt;option key={code} value={code}&gt;
                        {country}
                    &lt;/option&gt;
                ))}
            &lt;/select&gt;
        &lt;/div&gt;
    );
}
</code></pre>

<p>This is what it outputs it need to list the country names.</p>

<p><a href=""https://i.stack.imgur.com/1HlV9m.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1HlV9m.png"" alt=""enter image description here""></a></p>
"
61028774,"<p>I have a web app that uploads doc/docx files to an s3 bucket.</p>

<p>I want users to be able to display those files as html without downloading the file. Ultimately, I need to use this with Heroku, so I believe I need to be able to save the file in memory temporarily.</p>

<p>I am attempting to adapt the solution here for xlsx files:</p>

<p><a href=""https://stackoverflow.com/questions/40535757/download-xlsx-from-s3-and-parse-it"">Download xlsx from S3 and parse it</a></p>

<p>here is the current code:</p>

<pre><code>...
const AWS = require('aws-sdk');
const mammoth = require('mammoth');

async function downloadFile(target){
  AWS.config.update({
    accessKeyId: process.env.AWS_ACCESS_KEY_ID,
    secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
  });

  const s3 = new AWS.S3();
  const stream = await s3.getObject(
    { 
      Bucket: process.env.AWS_BUCKET, 
      Key: target.file_url.split(""com/"").reverse()[0]
    }).createReadStream();
  console.log('this is the stream: ',stream)
  return stream;
}

router.put('/:id/download', async (req, res, next) =&gt; {
  console.log('hitting download route')

  var id = req.params.id;
  let upload = await Upload.query().findById( id ).eager('user');

  console.log(""file to download is: "", upload.name)

  var s3FileObject = downloadFile(upload)

  console.log('this is the downloaded file: ', s3FileObject)
  res.send (s3FileObject)

  // mammoth code commented until we successfully download the object
  // mammoth.convertToHtml({ path: '/Users/dariusgoore/Downloads/1585930968750.docx' })
  //   .then(async function(result) {
  //     await Upload.query().findById( id )
  //       .patch({
  //          html: result.value,
  //          conversion_messages: result.messages
  //       })  
  //     res.json(result);
  //   })

    // .done();
});
</code></pre>

<p>the console returns the following:</p>

<pre><code>hitting download route
file to download is:  COVID-19.docx
this is the downloaded file:  Promise { &lt;pending&gt; }
this is the stream:  PassThrough {
  _readableState:
   ReadableState {
     objectMode: false,
     highWaterMark: 16384,
     buffer: BufferList { head: null, tail: null, length: 0 },
     length: 0,
     pipes: null,
     pipesCount: 0,
     flowing: null,
     ended: false,
     endEmitted: false,
     reading: false,
     sync: false,
     needReadable: true,
     emittedReadable: false,
     readableListening: false,
     resumeScheduled: false,
     emitClose: true,
     destroyed: false,
     defaultEncoding: 'utf8',
     awaitDrain: 0,
     readingMore: false,
     decoder: null,
     encoding: null },
  readable: true,
  domain: null,
  _events:
   [Object: null prototype] { prefinish: [Function: prefinish] },
  _eventsCount: 1,
  _maxListeners: undefined,
  _writableState:
   WritableState {
     objectMode: false,
     highWaterMark: 16384,
     finalCalled: false,
     needDrain: false,
     ending: false,
     ended: false,
     finished: false,
     destroyed: false,
     decodeStrings: true,
     defaultEncoding: 'utf8',
     length: 0,
     writing: false,
     corked: 0,
     sync: true,
     bufferProcessing: false,
     onwrite: [Function: bound onwrite],
     writecb: null,
     writelen: 0,
     bufferedRequest: null,
     lastBufferedRequest: null,
     pendingcb: 0,
     prefinished: false,
     errorEmitted: false,
     emitClose: true,
     bufferedRequestCount: 0,
     corkedRequestsFree:
      { next: null,
        entry: null,
        finish: [Function: bound onCorkedFinish] } },
  writable: true,
  allowHalfOpen: true,
  _transformState:
   { afterTransform: [Function: bound afterTransform],
     needTransform: false,
     transforming: false,
     writecb: null,
     writechunk: null,
     writeencoding: null } }
</code></pre>

<p>Where is the file object?</p>
"
61188862,"<p>I am trying to log HTTP requests to a <code>.log</code> file.</p>

<p>i create and write it like so.</p>

<pre><code>const accessLogStream = fs.createWriteStream(path.join(__dirname, 'logger.log'), { flags: 'a' });
</code></pre>

<p>and i write to it via a middleware.</p>

<pre><code>app.use((req, res, next) =&gt; {
  const start = process.hrtime()
  res.on('finish', () =&gt; {            
      const durationInMilliseconds = getDurationInMilliseconds (start);     accessLogStream.write(`${req.method}\t\t${req.originalUrl}\t\t${res.statusCode}\t\t${Math.trunc(durationInMilliseconds).toLocaleString()}ms\n`)
  })
  next()
})
</code></pre>

<p>on hitting <code>/logs</code> endpoint i read the data in file</p>

<pre><code>app.get('/api/v1/on-covid-19/logs?',(req,res) =&gt; {
    fs.readFile('./logger.log', 'utf8', function(err, data) {
        if (err) throw err;
        // line by line
        res.format({
            'text/plain': function () {
              res.send(data)}})
    }) 
});
</code></pre>

<p>The above functionality is able to write to my <code>logger.log</code> file in devt but does not update <code>logger.log</code> file in production on <code>heroku</code>. What am i not doing?</p>

<p>Hitting the <code>/logs</code> endpoint returns an empty <code>data</code> string in production.</p>
"
61015397,"<p>I need to get some data from a webpage for a google sheet project.</p>

<p>the code I use is:</p>

<pre><code>var content = UrlFetchApp.fetch(""https://www.ontario.ca/page/2019-novel-coronavirus#section-0"").getContentText(""UTF-8"");
</code></pre>

<p>However, the content I got from the code is different from what I see on that webpage.</p>

<p><a href=""https://www.ontario.ca/page/2019-novel-coronavirus#section-0"" rel=""nofollow noreferrer"">https://www.ontario.ca/page/2019-novel-coronavirus#section-0</a></p>

<p>I checked the page source. It is different from what I see in Chrome inspect's elements window.   I guess the content is loaded into <code>&lt;div id=""ng-view"" ng-view&gt;&lt;/div&gt;</code> after the page is loaded.</p>

<p>Is there any way, I can get the fully loaded page content? </p>

<p>Thanks</p>
"
60692697,"<p>Currently, I'm trying to get real-time Twitter stream using using their search API. </p>

<p>It works fine with the code below:</p>

<pre><code>var Twit = require('../../../node_modules/twit')

var config = require('../../../config.json')

var T = new Twit({
    consumer_key: config.twitter.consumer_key,
    consumer_secret: config.twitter.consumer_secret,
    access_token: config.twitter.access_token,
    access_token_secret: config.twitter.access_token_secret
})

var stream = T.stream('statuses/filter', { track: ['coronavirus'], filter_level: 'low', language: 'en' })

let iters = 0;

stream.on('tweet', function (tweet) {

    console.log('Tweeeet: ' + tweet.text + '\n' + ' ' + tweet.favorite_count); 

})

</code></pre>

<p>However, what if I want to apply the additional filtering operators as described on <a href=""https://developer.twitter.com/en/docs/tweets/filter-realtime/overview"" rel=""nofollow noreferrer"">https://developer.twitter.com/en/docs/tweets/filter-realtime/overview</a></p>

<p>I should be able to use <code>result_type: 'popular'</code> for example.</p>

<p>However, when I try to add it into my request like this:</p>

<pre><code>var stream = T.stream('statuses/filter', { track: ['coronavirus'], result_type: 'popular', language: 'en' })

</code></pre>

<p>It doesn't have any effect.</p>

<p>Does it mean that you cannot combine the search filtering operators with the real-time stream even though on the Twitter page I provided above it says it works?</p>
"
61561348,"<p>I'm writing small dataviz app, my graph is mostly working, so I went to work on the <code>React</code> part, connecting a store, so I can select the regions to display on my graph. </p>

<p>However, when selecting/unselecting a region the component's previous state isn't destroyed so the new one as little place to be drawn.</p>

<p><a href=""https://i.stack.imgur.com/MnmhA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MnmhA.png"" alt=""component redrawn without removing old state""></a>
Description:</p>

<ol>
<li>Top component is the one appearing when loading the app</li>
<li>Bottom component is the one appearing when state change</li>
</ol>

<p>I was expecting top component to disappear when state is changed.</p>

<hr>

<h3><code>&lt;VisibleEvents /&gt;</code> container component <a href=""https://github.com/edouard-lopez/coronavirus-policies-timeline/blob/6f535321ed/src/Timeline/VisibleEvents.tsx"" rel=""nofollow noreferrer"">(source)</a></h3>

<p>Fetch data and connect <code>&lt;Timeline&gt;</code> component to the Redux store</p>

<pre><code># … import and helpers

const timelineEvents = buildD3Data(data as TimelineEvents)

const getVisibleEvents = (events: TimelineEvents, regions: Regions) =&gt; {
  const visibileEvents = getEvents(
    timelineEvents.sort(sortByRegion),
    regionsWithEvents
  )
  return visibileEvents
}

const mapStateToProps = (state: RootState) =&gt; ({
  regions: getSelectedRegions(state),
  events: getVisibleEvents(timelineEvents, getSelectedRegions(state)),
})
const connector = connect(mapStateToProps, {})

export default connector(Timeline)
</code></pre>

<h3><code>&lt;Timeline /&gt;</code> Component <a href=""https://github.com/edouard-lopez/coronavirus-policies-timeline/blob/6f535321ed/src/Timeline/Timeline.tsx"" rel=""nofollow noreferrer"">(source)</a></h3>

<pre><code>import React, { useEffect, useRef } from 'react'
import { Regions } from '../types/region'
import { TimelineEvents } from '../types/timelineEvent'
import drawGraph from './drawGraph'

interface TimelineProps {
  events: TimelineEvents
  regions: Regions
}

const Timeline = ({ events, regions }: TimelineProps) =&gt; {
  const graph = useRef(null)

  useEffect(() =&gt; drawGraph(graph, regions, events))

  return &lt;div ref={graph} data-testid='chart'&gt;&lt;/div&gt;
}

export default Timeline
</code></pre>

<h3><code>&lt;RegionPicker /&gt;</code> <a href=""https://github.com/edouard-lopez/coronavirus-policies-timeline/blob/6f535321ed/src/Region/RegionPicker.jsx"" rel=""nofollow noreferrer"">(source)</a></h3>

<p>Dispatch event when new region is un/selected:</p>

<pre><code>const mapStateToProps = (state) =&gt; ({
  regions: getSelectedRegions(state),
})
const mapDispatchToProps = (dispatch) =&gt; {
  return {
    selectRegion: (region) =&gt; dispatch(selectRegion(region)),
    unSelectRegion: (region) =&gt; dispatch(unSelectRegion(region)),
  }
}
const connector = connect(mapStateToProps, mapDispatchToProps)

export default connector(RegionPicker)
</code></pre>

<h3>Question</h3>

<p>Why is the old state's component still present? How do I destroy it?</p>

<h3>Related</h3>

<ul>
<li><a href=""https://edouard-lopez.github.io/coronavirus-policies-timeline/"" rel=""nofollow noreferrer"">Live Demo</a> (might be fixed in the future)</li>
<li><a href=""https://github.com/edouard-lopez/coronavirus-policies-timeline/tree/6f535321eda66f14f523e6f2b422089c7aab9a13"" rel=""nofollow noreferrer"">Code repo at commit</a></li>
<li><a href=""https://stackoverflow.com/q/61411864/802365"">D3js: How to update children inside  when using brush selection?</a></li>
</ul>
"
60982453,"<p>I am trying to create multiple markers in Vue using VueMapbox. Currently the map displays correctly but there is only one marker. I think there is something wrong either with my v-for statement or perhaps in the forEach statement. I am trying to place a marker on each location but only the first location is added.</p>

<p>Here is the code for my vue component: </p>

<pre><code>&lt;template&gt;
  &lt;MglMap
    :accessToken=""accessToken""
    :mapStyle.sync=""mapStyle""
  &gt;
    &lt;MglMarker v-for=""coordinate in coordinates"" :key=""coordinate"" :coordinates=""coordinates""&gt;
      &lt;MglPopup&gt;
        &lt;VCard&gt;
          &lt;div&gt;{{ country }}&lt;/div&gt;
          &lt;div&gt;{{ cases }}&lt;/div&gt;
        &lt;/VCard&gt;
      &lt;/MglPopup&gt;
    &lt;/MglMarker&gt;
  &lt;/MglMap&gt;
&lt;/template&gt;

&lt;script&gt;
  import Mapbox from ""mapbox-gl"";
  import { MglMap, MglPopup, MglMarker } from ""vue-mapbox""

  export default {
    name: 'Map',

    components: {
      MglMap,
      MglPopup,
      MglMarker,
    },

    data() {
      return {
        accessToken: 'pk.accesstoken...blahblahblah',
        mapStyle: 'mapbox://styles/mapbox/dark-v10',
        coordinates: [],
        country: '',
        cases: 0,
      }
    },

    created() {
      this.mapbox = Mapbox;
      this.getData();
    },

    methods: {
      getData: function () {
        fetch('https://coronavirus-tracker-api.herokuapp.com/v2/locations')
          .then(response =&gt; response.json())
          .then(data =&gt; {
            const locations = data.locations;

            locations.forEach(stat =&gt; {
              const country = stat.country;
              this.country = country;
              const cases = stat.latest.confirmed;
              this.cases = cases;
              const coordinates = [stat.coordinates.longitude, stat.coordinates.latitude]
              this.coordinates = coordinates;
            })
          })
      }
    }
  }
&lt;/script&gt;
</code></pre>
"
61513147,"<p>I need to split a string of text into its component words, so I'm using a Regex to split it on the empty spaces (in a Typescript file, btw).</p>

<pre><code>splitIntoWords(text: string) : Array&lt;string&gt; {
    const separator = ' ';
    const words = text.split(new RegExp(separator, 'g'));
    return words;
}
</code></pre>

<p>This mostly works, but I've noticed that I regularly get words in the array that still contain spaces. If I copy the text into the Chrome console and split(' ') it I get the correct amount of words, but when I use the variable (even in the console) it invariably fails in some cases. I can't work out what the difference is. This is an example of my text:</p>

<pre><code>""Le coronavirus en France : la décrue se poursuit en réanimation, la reprise économique au cœur des préoccupations. La mise en œuvre du plan de déconfinement élaboré par le gouvernement doit encore faire l’objet, jeudi, d’un « travail de concertation et d’adaptation aux réalités de terrain » avec les responsables et les élus locaux.""
</code></pre>

<p>The regex never manages to split the substring ""économique au"" into two components, for instance. Does anyone know why this is happening?</p>
"
61690199,"<p>I have been trying to start my react app but something happened and now it is giving me the error that it scripts can't be spawned. I would be really thankful if some can help me regarding this</p>

<pre><code>/mnt/d/covid19/client/node_modules/.bin/../node/bin/node: 1: /mnt/d/covid19/client/node_modules/.bin/../node/bin/node: This: not found
npm ERR! code ELIFECYCLE
npm ERR! syscall spawn
npm ERR! file sh
npm ERR! errno ENOENT
npm ERR! n-opinion@0.1.0 start: `react-scripts start`
npm ERR! spawn ENOENT
npm ERR!
npm ERR! Failed at the n-opinion@0.1.0 start script.
</code></pre>
"
61176463,"<p>Basically I am trying to have a firebase function simply output values in a document, I have only achieved this locally... but the function won't deploy to the cloud. Below is the function</p>

<pre><code>const functions = require('firebase-functions');
const firebase = require('firebase/app');
require('firebase/firestore');

const firebaseConfig = {
    projectId: ""covid-info-bw""
};

const db = firebase
.initializeApp(firebaseConfig)
.firestore()

// // Create and Deploy Your First Cloud Functions
// // https://firebase.google.com/docs/functions/write-firebase-functions
//
exports.helloWorld = functions.https.onRequest((request, response) =&gt; {
  response.send(""Hello from Firebase! Dawg I am beast"");
});


exports.getData = functions.https.onRequest((req, res) =&gt; {
const docRef = db.collection('FunctionTest').doc('Cm38kBYShNnyuLVpizcy');
const getDoc = docRef.get()
    .then(doc =&gt; {
    if (!doc.exists) {
        console.log('No such document!');
        return res.send('Not Found')
    } 
        console.log(doc.data());
        return res.send(doc.data());
    })
    .catch(err =&gt; {
    console.log('Error getting document', err);
});
</code></pre>

<p>This is a snippet from the package.json</p>

<pre><code>""dependencies"": {
  ""@firebase/app"": ""^0.6.1"",
  ""@firebase/firestore"": ""^1.14.0"",
  ""@google-cloud/firestore"": ""^3.7.4"",
  ""firebase-admin"": ""^8.10.0"",
 ""firebase-functions"": ""^3.6.0""
},
</code></pre>

<p>This is the error I am getting from running "" firebase deploy --only functions:getData,functions:helloWorld"" </p>

<pre><code>λ firebase deploy --only functions:getData,functions:helloWorld

=== Deploying to 'covid-info-bw'...

i  deploying functions
Running command: npm --prefix ""%RESOURCE_DIR%"" run lint

&gt; functions@ lint M:\VueAdventures\covid-info-bw\functions
&gt; eslint .

+  functions: Finished running predeploy script.
i  functions: ensuring necessary APIs are enabled...
+  functions: all necessary APIs are enabled
i  functions: preparing functions directory for uploading...
i  functions: packaged functions (41.45 KB) for uploading
+  functions: functions folder uploaded successfully
i  functions: current functions in project: getData(us-central1), helloWorld(us-central1)
i  functions: uploading functions in project: helloWorld(us-central1), getData(us-central1)
i  functions: updating Node.js 8 function helloWorld(us-central1)...
i  functions: updating Node.js 8 function getData(us-central1)...
!  functions[getData(us-central1)]: Deployment error.
 Function failed on loading user code. Error message: Code in file index.js can't be loaded. 
 Did you list all required modules in the package.json dependencies?
 Detailed stack trace: Error: Cannot find module 'firebase/app'
    at Function.Module._resolveFilename (module.js:548:15)
    at Function.Module._load (module.js:475:25)
    at Module.require (module.js:597:17)
    at require (internal/module.js:11:18)
    at Object.&lt;anonymous&gt; (/srv/index.js:2:18)
    at Module._compile (module.js:653:30)
    at Object.Module._extensions..js (module.js:664:10)
    at Module.load (module.js:566:32)
    at tryModuleLoad (module.js:506:12)
    at Function.Module._load (module.js:498:3)
    !      functions[helloWorld(us-central1)]: Deployment error.
  Function failed on loading user code. Error message: Code in file index.js can't be loaded.
 Did you list all required modules in the package.json dependencies?
 Detailed stack trace: Error: Cannot find module 'firebase/app'
    at Function.Module._resolveFilename (module.js:548:15)
    at Function.Module._load (module.js:475:25)
    at Module.require (module.js:597:17)
    at require (internal/module.js:11:18)
    at Object.&lt;anonymous&gt; (/srv/index.js:2:18)
    at Module._compile (module.js:653:30)
    at Object.Module._extensions..js (module.js:664:10)
    at Module.load (module.js:566:32)
    at tryModuleLoad (module.js:506:12)
    at Function.Module._load (module.js:498:3)


 Functions deploy had errors with the following functions:
        getData
        helloWorld


 To try redeploying those functions, run:
     firebase deploy --only functions:getData,functions:helloWorld


 To continue deploying other features (such as database), run:
     firebase deploy --except functions

Error: Functions did not deploy properly.
</code></pre>
"
61088533,"<p>I'm working in a Serverless project and I'm having issues to run locally my application with dynamodb. It is not creating a data table thus not executing correctly the seed. What is wrong with my configurations?</p>

<p>start command: <code>$ sls offline start --stage dev</code></p>

<p>error message:</p>

<pre><code>Serverless: Bundling with Webpack...
Serverless: Watching for changes...
Dynamodb Local Started, Visit: http://localhost:8000/shell

  Resource Not Found Exception ---------------------------

  ResourceNotFoundException: Cannot do operations on a non-existent table
      at Request.extractError (/home/mauricio/dev/project/covid-favor-api/node_modules/aws-sdk/lib/protocol/json.js:51:27)
      at Request.callListeners (/home/mauricio/dev/project/covid-favor-api/node_modules/aws-sdk/lib/sequential_executor.js:106:20)
      at Request.emit (/home/mauricio/dev/project/covid-favor-api/node_modules/aws-sdk/lib/sequential_executor.js:78:10)
      at Request.emit (/home/mauricio/dev/project/covid-favor-api/node_modules/aws-sdk/lib/request.js:683:14)
      at endReadableNT (_stream_readable.js:1183:12)
      at processTicksAndRejections (internal/process/task_queues.js:80:21)

     For debugging logs, run again after setting the ""SLS_DEBUG=*"" environment variable.

  Get Support --------------------------------------------
     Docs:          docs.serverless.com
     Bugs:          github.com/serverless/serverless/issues
     Issues:        forum.serverless.com

  Your Environment Information ---------------------------
     Operating System:          linux
     Node Version:              12.13.0
     Framework Version:         1.64.0
     Plugin Version:            3.4.0
     SDK Version:               2.3.0
     Components Core Version:   1.1.2
     Components CLI Version:    1.4.0

</code></pre>

<p>Serverless file:</p>

<pre><code>org: mauriciocoder
app: covid-favor
# We are using JEST for testing: https://jestjs.io/docs/en/getting-started.html - npm test
service: covid-favor-app-api

# Create an optimized package for our functions
package:
  individually: true

# Create our resources with separate CloudFormation templates
resources:
  # API Gateway Handler
  - ${file(resources/api-gateway-handler.yml)}
  # DynamoDb Handler
  - ${file(resources/dynamodb-handler.yml)}

plugins:
  - serverless-bundle # Package our functions with Webpack
  - serverless-dynamodb-local
  - serverless-offline
  - serverless-dotenv-plugin # Load .env as environment variables

custom:
  authorizer:
    dev: 
    prod: aws_iam
  dynamodb:
    stages: dev
    start:
      port: 8000 # always se port 8000, otherwise serverless-dynamodb-client will not find
      migrate: true # creates tables from serverless config
      seed: true # determines which data to onload
    seed:
      domain:
        sources:
          - table: userAccount
            sources: [./resources/migrations/v0.json]

provider:
  name: aws
  runtime: nodejs10.x
  stage: ${opt:stage, 'dev'}
  region: us-east-1

  # These environment variables are made available to our functions
  # under process.env.
  environment:
    helpTableName: help
    userAccountTableName: userAccount

  # 'iamRoleStatements' defines the permission policy for the Lambda function.
  # In this case Lambda functions are granted with permissions to access DynamoDB.
  iamRoleStatements:
    - Effect: Allow
      Action:
        - dynamodb:DescribeTable
        - dynamodb:Query
        - dynamodb:Scan
        - dynamodb:GetItem
        - dynamodb:PutItem
        - dynamodb:UpdateItem
        - dynamodb:DeleteItem
      Resource: ""arn:aws:dynamodb:us-east-1:*:*""

  # These are the usage plan for throttling
  usagePlan:
    throttle:
        burstLimit: 2
        rateLimit: 1

functions: ...
</code></pre>

<p>dynamodb-handler file:</p>

<pre><code>userAccount:
  Type: AWS::DynamoDB::Table
  DeletionPolicy : Retain
  Properties:
    TableName: userAccount
    AttributeDefinitions:
      - AttributeName: userId
        AttributeType: S
    KeySchema:
      - AttributeName: userId
        KeyType: HASH
    ProvisionedThroughput:
      ReadCapacityUnits: 1
      WriteCapacityUnits: 1
</code></pre>

<p>seed file v0.json:</p>

<pre><code>{
    ""Table"": {
        ""TableName"": ""userAccount"",
        ""KeySchema"": [
            {
                ""AttributeName"": ""userId"",
                ""KeyType"": ""S""
            }
        ],
        ""LocalSecondaryIndexes"": [
            {
                ""IndexName"": ""local_index_1"",
                ""KeySchema"": [
                    {
                        ""AttributeName"": ""userId"",
                        ""KeyType"": ""HASH""
                    }
                ]
            }
        ],
        ""ProvisionedThroughput"": {
            ""ReadCapacityUnits"": 1,
            ""WriteCapacityUnits"": 1
        }
    }
}
</code></pre>

<p>package.json</p>

<pre><code>{
  ""name"": ""notes-app-api"",
  ""version"": ""1.1.0"",
  ""description"": ""A Node.js starter for the Serverless Framework with async/await and unit test support"",
  ""main"": ""handler.js"",
  ""scripts"": {
    ""test"": ""serverless-bundle test""
  },
  ""author"": """",
  ""license"": ""MIT"",
  ""repository"": {
    ""type"": ""git"",
    ""url"": ""https://github.com/AnomalyInnovations/serverless-nodejs-starter.git""
  },
  ""devDependencies"": {
    ""aws-sdk"": ""^2.622.0"",
    ""jest"": ""^25.1.0"",
    ""serverless-bundle"": ""^1.2.5"",
    ""serverless-dotenv-plugin"": ""^2.1.1"",
    ""serverless-offline"": ""^5.3.3""
  },
  ""dependencies"": {
    ""serverless-dynamodb-client"": ""0.0.2"",
    ""serverless-dynamodb-local"": ""^0.2.35"",
    ""stripe"": ""^8.20.0"",
    ""uuid"": ""^3.4.0""
  }
}

</code></pre>
"
61601661,"<p>New user here and not versed in code much. Im working on a COVID-19 form for our company and looking for some help with conditional formatting issues. 
SOW: Current we have a google form with simple questions that employees will fill out each day as they arrive, this data is populated on a google sheet.
Each night a google trigger runs that deletes 200 rows of the google sheet for the next days entries, when that script run its messes up my manual conditional formatting, so im trying to run the delete script followed by a script that will apply the conditional formatting to the new sheet each night so everything is ready for the next day. </p>

<p>This is currently what im running that deletes rows each night:</p>

<pre><code>***function deleteResponses() {     
var ss = SpreadsheetApp.openById('Sheet_ID');     
var sheet = ss.getSheets()[0];  
sheet.deleteRows(2, 200);  
 };***
</code></pre>

<p>This is the conditional formatting script ive added to it and trying to run and getting the following error im hoping someone can help me with.</p>

<pre><code>**function deleteResponses() {  
  var ss = SpreadsheetApp.openById('Sheet_ID');  
  var sheet = ss.getSheets()[0];  
  sheet.deleteRows(2, 200);  
};  
var sheet = SpreadsheetApp.openById('Sheet_ID');  
var range = sheet.getRange('C2:C1010');  
var rule = SpreadsheetApp.newConditionalFormatRule()  
   .whenTextContains('No')  
    .setBackground('#FF0000')  
    *.setRanges('C2:C1010')*  
    .build();  
var rules = sheet.getConditionalFormatRules();  
rules.push(rule);  
sheet.setConditionalFormatRules(rules);**
</code></pre>

<p>Im receiving this error.<br>
""Message details
Exception: The parameters (String) don't match the method signature for SpreadsheetApp.ConditionalFormatRuleBuilder.setRanges. (line 12, file ""Code"")""</p>

<p>Anyone that could help me, I would greatly appreciate it!</p>
"
61417657,"<p>I am trying to pass json state from component api to component chart. When I am trying log console it shows the data but in the constructor it does not seems to have them if I try this.state.json instead of this.props.json in console. All I am trying it get the data from this.state.json from api component and pass them to chart component when I am setting json: this.props.json. But the this.state.json inside chart is empty.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>import React, { Component } from 'react';
import axios from 'axios';
import Hlavnicards from './Hlavnicards';
import Datatable from './Datatable';
import Chart from './Chart';
import Countrypicker from './Countrypicker';

 class Api extends Component  {

  constructor(props) {
    super(props);
    this.state = {
      countries: [],
      global: [],
      date: [],
      chartdata: [],
      json: []

    };
}

   
      componentDidMount() {

        axios.get(`https://covid19.mathdro.id/api/daily`)
        .then(response =&gt; response.data)
        .then((data) =&gt; {
            this.setState({ json: data })
             
        })
        
        axios.get(`api/corona2`)
        .then(response =&gt; response.data)
        .then((data) =&gt; {
          this.setState({ countries: data.Countries })
          this.setState({ global: data.Global })
          this.setState({ date: data.Date })
          
         })

         
      }

      render() {
        return (
            &lt;div&gt;
          
          &lt;div class= ""p-col-12""&gt;&lt;Hlavnicards currentDate = {this.state.date} summary = {this.state.global} /&gt;&lt;/div&gt;
          &lt;div class= ""p-col-12""&gt;&lt;Countrypicker /&gt;&lt;/div&gt;
          &lt;div class= ""p-col-12""&gt;&lt;Chart json = {this.state.json} /&gt;&lt;/div&gt;
          &lt;div class= ""p-col-12""&gt;&lt;Datatable summaryCountries = {this.state.countries} /&gt;&lt;/div&gt;
          &lt;/div&gt;
              
       
        );
      }
}

export default Api;</code></pre>
</div>
</div>
</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>import React, { Component } from 'react';
import { Card } from 'primereact/card';
import C3Chart from 'react-c3js';
import 'c3/c3.css';
import axios from 'axios';
class Charts extends Component {

    constructor(props) {
        super(props);

    
        this.state = {
            
            json: this.props.json,


            keys: {
                x: 'reportDate',

                value: ['totalConfirmed', 'deaths.total']
            },
            names: {
                totalConfirmed: 'Infected',
                'deaths.total': 'Deaths'

            },
            types: {
                totalConfirmed: 'area-spline',
                'deaths.total': 'area-spline'
                // 'line', 'spline', 'step', 'area', 'area-step' are also available to stack
            },
            colors: {
                totalConfirmed: 'red',
                'deaths.total': 'black',
                
            },
            zoom: {
                enabled: true
            }

        };

    };


    render() {
        console.log(this.props.json);
        return (
           

            &lt;div class=""p-grid""&gt;

                &lt;div class=""p-col-6"" style={{ textAlign: 'center' }}&gt;

                    &lt;Card&gt;

                        &lt;C3Chart axis={{
                            x: {
                                type: 'timeseries',
                                label: {
                                    text: 'Date',
                                    position: 'outer-center'
                                }
                            },
                            y: {
                                label: {
                                    text: 'Number of people',
                                    position: 'outer-middle'
                                }
                            },

                        }} data={this.state} /&gt;

                    &lt;/Card&gt;

                &lt;/div&gt;

            &lt;/div&gt;


        );
    }
}

export default Charts;</code></pre>
</div>
</div>
</p>
"
61346742,"<p>How are you? I have a couple of doubts! How can I access the inheritance of an object?
I am trying to get the data from NewConfirmed, which has ""Global""</p>

<p>img Console.log:
<a href=""https://i.stack.imgur.com/iJGcH.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/iJGcH.png</a></p>

<p>For now I can only take the data ""Date""</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>stats = () =&gt; {
    const { dataCovid } = this.props;
    if (this.props.loader) {
      return (/**/ );
    }
    return (
      &lt;div className='row'&gt;
        &lt;div className='col-md-4'&gt;
          &lt;div className='card stat-card'&gt;
            &lt;div className='card-body'&gt;
              &lt;h5 className='card-title'&gt;Total de Nuevos    Contagio:&lt;/h5&gt;
              &lt;h2 className='float-right'&gt; {dataCovid.Date}&lt;/h2&gt;
            &lt;/div&gt;
          &lt;/div&gt;</code></pre>
</div>
</div>
</p>

<p>Now if I try to call datacovid.Global, in console I get the following:</p>

<pre><code>Objects are not valid as a React child (found: object with keys {NewConfirmed, TotalConfirmed, NewDeaths, TotalDeaths, NewRecovered, TotalRecovered})
</code></pre>

<p>if you assigned the value of NewConfimed it throws me</p>

<pre><code> TypeError: dataCovid.Global is undefined
</code></pre>
"
61253227,"<p>I was Trying to make a variable array from which i can take data from json but i got error that my array is not defined.</p>

<pre><code>$(document).ready(function(){
    $.getJSON(""https://api.covid19india.org/data.json"", function(data){
        $.each(data.statewise, function(key, value){
            if (value.state === ""Total"") {
             var data2 = [['Covid19', 'Stats'],
                  ['Active cases',value.active],
                  ['Deaths', value.deaths],
                  ['recovered', value.recovered],];  
            }
        });
    });
});

google.charts.load(""current"", {packages:[""corechart""]});
google.charts.setOnLoadCallback(drawChart);
function drawChart() {
var data = google.visualization.arrayToDataTable(data2);

var options = {
width:""350"",
height:""350"",
pieHole: 0.5,
backgroundColor: { fill:""transparent""},
chartArea:{
left:10,
right:10, // !!! works !!!
bottom:20,  // !!! works !!!
top:20,
width:""100%"",
height:""100%""
},
pieSliceTextStyle: {
color: ""white"",
},
legend: {position: ""bottom"", textStyle: {color: ""gray""}},

pieSliceText: ""none"",
};

var chart = new google.visualization.PieChart(document.getElementById(""covid19""));
chart.draw(data, options);
}

</code></pre>

<p>But i got error
Uncaught (in promise) ReferenceError: data2 is not defined
    at drawChart</p>
"
61291296,"<p>I am doing a side project to React, using Axios to fetch <a href=""https://newsapi.org/"" rel=""nofollow noreferrer"">https://newsapi.org/</a> coronavirus related news. Now I can display the news on the screen. My goal is simple, not only display the news but when clicking the image, it will redirect the user to that specific piece of news. I add React-router to the project, but now I cannot display that specific piece of news. </p>

<pre><code>import React, {Component} from 'react';
import './App.css';
import News from './Component/News/News';
import {BrowserRouter} from 'react-router-dom';
import {Route, Switch} from 'react-router-dom';
import FullNews from './Component/FullNews/FullNews';


class App extends Component {
  render() {
    return (
      &lt;BrowserRouter&gt;
        &lt;Switch&gt;
          &lt;Route path='/' exact component={News}/&gt;
          &lt;Route path='/:index' exact component={FullNews}/&gt;
        &lt;/Switch&gt;
      &lt;/BrowserRouter&gt;
    );
  }
}

export default App;
</code></pre>

<p>This is the App.js.</p>

<pre><code>import React from 'react';
import {useState, useEffect} from 'react';
import axios from 'axios';
import NewsList from '../NewsList/NewsList';


const News = (props) =&gt; {
    console.log(props)
    const [news, setNews] = useState([]);
    const [loading, setLoading] = useState(false)

    useEffect(() =&gt; {
        const fetchNews = async() =&gt; {
            setLoading(true)
            const res = await axios.get('http://newsapi.org/v2/top-headlines?country=us&amp;category=health&amp;apiKey=e9f5217c460c42f7826f02144e6c573c')
            setNews(res.data.articles);
            setLoading(false)
        }
        fetchNews();
    }, []) 

    console.log(news)

    const fetchNewsDetail = (index) =&gt; {
        props.history.push('/' + index)
    }
    if(loading) {
        return &lt;div&gt;The page is loading&lt;/div&gt;
    }
    return (
        &lt;React.Fragment&gt;
            &lt;header&gt;
                &lt;h1&gt;Coronavirus News&lt;/h1&gt;
            &lt;/header&gt;
            &lt;main&gt;
                &lt;NewsList news={news} fetchNewsDetail={fetchNewsDetail}/&gt;
            &lt;/main&gt;
        &lt;/React.Fragment&gt;
    )
};

export default News;
</code></pre>

<p>This is the main page that shows the list of the news.</p>

<pre><code>import React from 'react';
import {withRouter, Link, Route} from 'react-router-dom';
import FullNews from '../FullNews/FullNews';

const NewsList = (props) =&gt; {

    console.log(props)
    return (
        &lt;div&gt;
            {props.news.map((item,index) =&gt; {
                    return (
                        &lt;Link to={'/' + index} style={{textDecoration:'none',color: '#333333'}} key={index}&gt;
                            &lt;div&gt;
                                &lt;img
                                    src={item.urlToImage} 
                                    alt=""newsImage"" 
                                    onClick={() =&gt; props.fetchNewsDetail(item.index)}
                                    style = {{width:'90%', height: 'auto'}}
                                /&gt;
                                &lt;h2&gt;{item.title}&lt;/h2&gt;
                                &lt;h6&gt;{item.publishedAt}&lt;/h6&gt;
                            &lt;/div&gt;
                        &lt;/Link&gt;
                    )
            })}
            &lt;Route path={props.match.url + '/:index'} exact component={FullNews}/&gt;
        &lt;/div&gt;
    )
}

export default withRouter(NewsList);
</code></pre>

<p>This is the newslist component, that I want to add an on click event to the image of each piece of news. When the user clicks the image, it will show the full news on a new page. </p>

<pre><code>import React from 'react';
import {useState, useEffect} from 'react';
import axios from 'axios';

const FullNews = (props) =&gt; {
    console.log(props)
    const [loadedNews, setLoadedNews] = useState([]);
    const [loading, setLoading] = useState(false)

    useEffect(() =&gt; {
        const fetchFullNews = async() =&gt; {
            setLoading(true);
            const res = await axios.get('/' + props.match.params.index)
            setLoadedNews(res.data)
            setLoading(false)
        }
        fetchFullNews()
    },[])


    return (
        &lt;div&gt;
            &lt;h2&gt;This is News {props.match.params.index}&lt;/h2&gt;
        &lt;/div&gt;
    )
}


export default FullNews; 
</code></pre>

<p>This is the full news page which I am struggling with, I can not use axios.get to fetch that piece of news. <code>axios.get('/' + props.match.params.index)</code> It doesn't work and always show xhr.js:178 GET <a href=""http://localhost:3000/1"" rel=""nofollow noreferrer"">http://localhost:3000/1</a> 404 (Not Found)</p>

<p>After fetching the newsapi, I already got a collection of articles that can be used for me. But now I have no idea how to pass them to the fullnews. </p>
"
61012833,"<p>I am trying to use AWS-Lambda to post data throught AWS-api gateway onto a client-side web-page but I am stuck on the above error message. When run the function run the database is displayed but then gets stuck on the error message. The three sets of code pasted bellow is what I'm using. If you can help let me know also if you need more info let me know</p>

<pre><code>
database.js[
let AWS = require(""aws-sdk"");

//Create new DocumentClient
let docClient = new AWS.DynamoDB.DocumentClient();

//Returns all of the connection IDs
module.exports.getConnectionIds = async() =&gt; {
    let params = {
        TableName: ""WebSocketClients""
    };
    return docClient.scan(params).promise();
};


module.exports.getCNYData = async() =&gt; {
    let params = {
        TableName: ""Currency"",
        Limit: 100,
        ScanIndexForward: true,
        IndexName: ""Currency_Name-Date-index"",
        KeyConditionExpression: ""Currency_Name = :Currency"",

        ExpressionAttributeValues: {
            "":Currency"": ""CNY"",
        }

    };
    return docClient.query(params).promise();
};

module.exports.getGBXData = async() =&gt; {
    let params = {
        TableName: ""Currency"",
        Limit: 100,
        ScanIndexForward: false,
        IndexName: ""Currency_Name-Date-index"",
        KeyConditionExpression: ""Currency_Name = :Currency"",
        ExpressionAttributeValues: {
            "":Currency"": ""GBX"",
        }
    };
    return docClient.query(params).promise();
};

module.exports.getSARData = async() =&gt; {
    let params = {
        TableName: ""Currency"",
        Limit: 100,
        ScanIndexForward: false,
        IndexName: ""Currency_Name-Date-index"",
        KeyConditionExpression: ""Currency_Name = :Currency"",
        ExpressionAttributeValues: {
            "":Currency"": ""SAR"",
        }
    };
    return docClient.query(params).promise();
};

module.exports.getUSDData = async() =&gt; {
    let params = {
        TableName: ""Currency"",
        Limit: 100,
        ScanIndexForward: false,
        IndexName: ""Currency_Name-Date-index"",
        KeyConditionExpression: ""Currency_Name = :Currency"",
        ExpressionAttributeValues: {
            "":Currency"": ""USD"",
        }
    };
    return docClient.query(params).promise();
};

module.exports.getPositiveSentimentData = async() =&gt; {
    let params = {
        TableName: ""Sentiment"",
        Limit: 100,
        ScanIndexForward: false,
        IndexName: ""Sentiment-Id-index"",
        KeyConditionExpression: ""Sentiment = :sentiment"",
        ExpressionAttributeValues: {
            "":sentiment"": ""POSITIVE"",
        }
    };
    return docClient.query(params).promise();
};

module.exports.getNegativeSentimentData = async() =&gt; {
    let params = {
        TableName: ""Sentiment"",
        Limit: 100,
        ScanIndexForward: false,
        IndexName: ""Sentiment-Id-index"",
        KeyConditionExpression: ""Sentiment = :sentiment"",
        ExpressionAttributeValues: {
                    "":sentiment"": ""NEGATIVE"",
        }
    };
    return docClient.query(params).promise();
};

module.exports.getData = async() =&gt; {
    let pSentiment = await module.exports.getPositiveSentimentData();
    let nSentiment = await module.exports.getNegativeSentimentData();
    let SAR = await module.exports.getSARData();
    let CNY = await module.exports.getCNYData();
    let USD = await module.exports.getUSDData();
    let GBX = await module.exports.getGBXData();
    let data = {
        positive: pSentiment,
        negative: nSentiment,
        CNY: CNY,
        GBX: GBX,
        SAR: SAR,
        USD: USD,
    };
    return data;
};

//Deletes the specified connection ID
module.exports.deleteConnectionId = async(connectionId) =&gt; {
    console.log(""Deleting connection Id: "" + connectionId);

    let params = {
        TableName: ""WebSocketClients"",
        Key: {
            ConnectionId: connectionId
        }
    };
    return docClient.delete(params).promise();
};
]

websocket.js[
let AWS = require(""aws-sdk"");

// Add ApiGatewayManagementApi to the AWS namespace
require('aws-sdk/clients/apigatewaymanagementapi');

//Import functions for database
let db = require('database');

module.exports.getSendMessagePromises = async(message, domainName, stage) =&gt; {
    //Get connection IDs of clients 
    let clientIdArray = (await db.getConnectionIds()).Items;
    console.log(""\nClient IDs:\n"" + JSON.stringify(clientIdArray));

    //Create API Gateway management class.
    const apigwManagementApi = new AWS.ApiGatewayManagementApi({
        apiVersion: '2018-11-29',
        endpoint: domainName + '/' + stage
    });

    //Try to send message to connected clients
    let msgPromiseArray = clientIdArray.map(async item =&gt; {
        try {

            console.log(""Sending message '"" + message + ""' to: "" + item.ConnectionId);



            //Create parameters for API Gateway

            let apiMsg = {

                ConnectionId: item.ConnectionId,

                Data: JSON.stringify(await db.getData)

            };



            //Wait for API Gateway to execute and log result

            await apigwManagementApi.postToConnection(apiMsg).promise();

            console.log(""Message '"" + message + ""' sent to: "" + item.ConnectionId);

        }

        catch (err) {

            console.log(""Failed to send message to: "" + item.ConnectionId);



            //Delete connection ID from database

            if (err.statusCode == 410) {

                try {

                    await db.deleteConnectionId(item.ConnectionId);

                }

                catch (err) {

                    console.log(""ERROR deleting connectionId: "" + JSON.stringify(err));

                    throw err;

                }

            }

            else {

                console.log(""UNKNOWN ERROR: "" + JSON.stringify(err));

                throw err;

            }

        }

    });
    return msgPromiseArray;
};

]


index.js[
//Import external library with websocket functions
let ws = require(""websocket"");
let db = require(""database"");

//Hard coded domain name and stage - use when pushing messages from server to client
let domainName = ""*********"";
let stage = ""dev"";

exports.handler = async (event) =&gt; {
    try {
        //Get Message from event
        const msg = JSON.stringify(await db.getData(), function(key, value){
            if (typeof value === ""bigint"") {
                return value.toString();
            } else {
                return value;
            }
        });


        //Allocate domain name and stage dynamically
        //domainName = event.requestContext.domainName;
        //stage = event.requestContext.stage;
        console.log(""Domain: "" + domainName + "" stage: "" + stage);

        //Get promises message to connected clients
        let sendMsgPromises = await ws.getSendMessagePromises(msg, domainName, stage); 

        //Execute promises
        await Promise.all(sendMsgPromises);
    }
    catch(err){
        return { statusCode: 500, body: ""Error: "" + (err)};
    }

    //Success
    return { statusCode: 200, body: ""Data sent successfully."" };
};
]
</code></pre>

<p>Edit:
For the two Dynamodb tables:
Name:Currency
Primary Partition Key: Date(String),
Primary Sort Key: Currency_Name(String),
Field: Price(BigInt),
Index: Currency_Name-Date-index.</p>

<p>Second table:
Name: Sentiment
Primary Partition Key: Id(Number),
Primary Sort Key: Text(String),
Field: Sentiment(string),
Index: Sentiment-Id-index.</p>

<p>Error Message:</p>

<pre><code>Response:
{
  ""statusCode"": 500,
  ""body"": ""Error: MissingRequiredParameter: Missing required key 'Data' in params""
}

Request ID:
""e2fee9cd-4af1-489e-8aac-98e16139dd4d""

Function Logs:
019-10-23""},{""Currency_Name"":""USD"",""Price"":""48.50"",""Date"":""2019-10-22""},{""Currency_Name"":""USD"",""Price"":""47.32"",""Date"":""2019-10-21""},{""Currency_Name"":""USD"",""Price"":""47.48"",""Date"":""2019-10-18""},{""Currency_Name"":""USD"",""Price"":""48.69"",""Date"":""2019-10-17""},{""Currency_Name"":""USD"",""Price"":""48.25"",""Date"":""2019-10-16""},{""Currency_Name"":""USD"",""Price"":""47.00"",""Date"":""2019-10-15""},{""Currency_Name"":""USD"",""Price"":""46.49"",""Date"":""2019-10-14""},{""Currency_Name"":""USD"",""Price"":""46.10"",""Date"":""2019-10-11""},{""Currency_Name"":""USD"",""Price"":""43.81"",""Date"":""2019-10-10""},{""Currency_Name"":""USD"",""Price"":""43.65"",""Date"":""2019-10-09""},{""Currency_Name"":""USD"",""Price"":""44.10"",""Date"":""2019-10-08""},{""Currency_Name"":""USD"",""Price"":""45.66"",""Date"":""2019-10-07""},{""Currency_Name"":""USD"",""Price"":""44.91"",""Date"":""2019-10-04""},{""Currency_Name"":""USD"",""Price"":""42.70"",""Date"":""2019-10-03""},{""Currency_Name"":""USD"",""Price"":""43.50"",""Date"":""2019-10-02""},{""Currency_Name"":""USD"",""Price"":""45.50"",""Date"":""2019-10-01""},{""Currency_Name"":""USD"",""Price"":""44.62"",""Date"":""2019-09-30""},{""Currency_Name"":""USD"",""Price"":""45.67"",""Date"":""2019-09-27""},{""Currency_Name"":""USD"",""Price"":""46.22"",""Date"":""2019-09-26""},{""Currency_Name"":""USD"",""Price"":""44.42"",""Date"":""2019-09-25""},{""Currency_Name"":""USD"",""Price"":""47.33"",""Date"":""2019-09-24""},{""Currency_Name"":""USD"",""Price"":""45.83"",""Date"":""2019-09-23""},{""Currency_Name"":""USD"",""Price"":""47.89"",""Date"":""2019-09-20""},{""Currency_Name"":""USD"",""Price"":""48.23"",""Date"":""2019-09-19""},{""Currency_Name"":""USD"",""Price"":""48.04"",""Date"":""2019-09-18""},{""Currency_Name"":""USD"",""Price"":""47.77"",""Date"":""2019-09-17""},{""Currency_Name"":""USD"",""Price"":""47.53"",""Date"":""2019-09-16""},{""Currency_Name"":""USD"",""Price"":""49.21"",""Date"":""2019-09-13""},{""Currency_Name"":""USD"",""Price"":""49.50"",""Date"":""2019-09-12""},{""Currency_Name"":""USD"",""Price"":""47.74"",""Date"":""2019-09-11""},{""Currency_Name"":""USD"",""Price"":""46.75"",""Date"":""2019-09-10""},{""Currency_Name"":""USD"",""Price"":""47.19"",""Date"":""2019-09-09""},{""Currency_Name"":""USD"",""Price"":""46.65"",""Date"":""2019-09-06""},{""Currency_Name"":""USD"",""Price"":""45.39"",""Date"":""2019-09-05""},{""Currency_Name"":""USD"",""Price"":""42.48"",""Date"":""2019-09-04""},{""Currency_Name"":""USD"",""Price"":""41.79"",""Date"":""2019-09-03""},{""Currency_Name"":""USD"",""Price"":""42.87"",""Date"":""2019-08-30""},{""Currency_Name"":""USD"",""Price"":""41.63"",""Date"":""2019-08-29""},{""Currency_Name"":""USD"",""Price"":""39.61"",""Date"":""2019-08-28""},{""Currency_Name"":""USD"",""Price"":""40.72"",""Date"":""2019-08-27""},{""Currency_Name"":""USD"",""Price"":""40.47"",""Date"":""2019-08-26""},{""Currency_Name"":""USD"",""Price"":""42.07"",""Date"":""2019-08-23""},{""Currency_Name"":""USD"",""Price"":""43.45"",""Date"":""2019-08-22""},{""Currency_Name"":""USD"",""Price"":""43.25"",""Date"":""2019-08-21""},{""Currency_Name"":""USD"",""Price"":""42.95"",""Date"":""2019-08-20""},{""Currency_Name"":""USD"",""Price"":""43.53"",""Date"":""2019-08-19""},{""Currency_Name"":""USD"",""Price"":""40.19"",""Date"":""2019-08-16""},{""Currency_Name"":""USD"",""Price"":""39.77"",""Date"":""2019-08-15""},{""Currency_Name"":""USD"",""Price"":""40.90"",""Date"":""2019-08-14""},{""Currency_Name"":""USD"",""Price"":""39.55"",""Date"":""2019-08-13""},{""Currency_Name"":""USD"",""Price"":""39.85"",""Date"":""2019-08-12""},{""Currency_Name"":""USD"",""Price"":""41.25"",""Date"":""2019-08-09""}],""Count"":100,""ScannedCount"":100,""LastEvaluatedKey"":{""Currency_Name"":""USD"",""Date"":""2019-08-09""}}}' to: KYSQycomoAMCJdA=
2020-04-03T14:09:16.092Z    e2fee9cd-4af1-489e-8aac-98e16139dd4d    INFO    Sending message '{""positive"":{""Items"":[{""Sentiment"":""POSITIVE"",""Id"":""1238393433607131100n"",""Text"":""\""Nice, didn’t get boated 🤗 *********""""}],""Count"":1,""ScannedCount"":1},""negative"":{""Items"":[{""Sentiment"":""NEGATIVE"",""Id"":""1238395098741825500n"",""Text"":""\""RT @keira_churchill: GBP plummets against the Euro because coronavirus. GBP plummets against the USD because coronavirus. GBP plummets agai…\""""},{""Sentiment"":""NEGATIVE"",""Id"":""1238392914813816800n"",""Text"":""\""@keira_churchill GBP was already weakened by Brexit uncertainty/risks. Add CoronavEND RequestId: e2fee9cd-4af1-489e-8aac-98e16139dd4d
</code></pre>
"
61502528,"<p>I'm using d3</p>

<p>I keep getting the error message</p>

<pre><code>Error: &lt;path&gt; attribute d: Expected number, ""M1588291200000,NaNL158880960000…"".
</code></pre>

<p>The code block where the bug is coming from is </p>

<pre><code>let line = d3.line()
    .y(data =&gt; data[""covidCases""])
    .x(data =&gt; data[""dates""])

    svg.append(""path"")
      .datum(covidLine)
      .attr(""fill"", ""none"")
      .attr(""stroke"", ""steelblue"")
      .attr(""stroke-width"", 1.5)
      .attr(""d"", line)
</code></pre>

<p>A date is being passed to the x co-ordinate.</p>

<p>An example of the data = <code>Fri May 01 2020 01:00:00 GMT+0100 (British Summer Time)</code></p>
"
61507105,"<p>Why is my line not appearing on my linechart ?</p>

<p>I am trying to use d3 to create a line chart, with two y-axis and one x-axis.
However when i try and append a line to my graph i get the error message.</p>

<p><code>d3.v5.min.js:2 Error: &lt;path&gt; attribute d: Expected moveto path command ('M' or 'm'), ""function a(a){va…"".</code></p>

<p>which I assume is the <code>d3.line()</code> not returning a valid ""M"" command. </p>

<p>Below is:</p>

<p>My js fiddle :
<a href=""https://jsfiddle.net/ryboh1/z5xvj7ou/2/"" rel=""nofollow noreferrer"">https://jsfiddle.net/ryboh1/z5xvj7ou/2/</a></p>

<p>Where I think the bug is happening</p>

<pre><code> svg.append(""path"")
      .datum(covidLine)
      .attr(""fill"", ""none"")
      .attr(""stroke"", ""steelblue"")
      .attr(""stroke-width"", 1.5)
      .attr(""d"", (d,i) =&gt;{

        let lines = createLine.y(d =&gt; yScaleCovid(d[1][i]))
        .x(d =&gt; xScaleDates( d[0][i] ))

        return lines
      }
      )
</code></pre>
"
61372394,"<p>I am getting error ""SyntaxError: Unterminated string literal (line 8, file ""Code"" while using google apps script, its working fine with another API but I don't know whats wrong with this.</p>

<pre><code>new code is :
`function Covid19_all() {

  // Call the COVID19 API
  var response = UrlFetchApp.fetch(""https://api.covid19api.com/all"");

  // Parse the JSON reply
  var json=response.getContentText();
  var data=JSON.parse(json);
  var sheet = SpreadsheetApp.getActiveSheet();

  for(var i=0;i&lt;data.length;i++)
  { 
    sheet.getRange(i+2,1).setValue([data[i]['Country']]);
    sheet.getRange(i+2,2).setValue([data[i]['CountryCode']]);
    sheet.getRange(i+2,3).setValue([data[i]['Province']]);
    sheet.getRange(i+2,4).setValue([data[i]['City']]);
    sheet.getRange(i+2,5).setValue([data[i]['Lat']]);
    sheet.getRange(i+2,6).setValue([data[i]['Lon']]);
    sheet.getRange(i+2,7).setValue([data[i]['Confirmed']]);
    sheet.getRange(i+2,8).setValue([data[i]['Deaths']]);
    sheet.getRange(i+2,9).setValue([data[i]['Recovered']]);
    sheet.getRange(i+2,10).setValue([data[i]['Active']]);
    sheet.getRange(i+2,11).setValue([data[i]['Date']]);
  }

</code></pre>

<p>and error is:
'SyntaxError: Unexpected end of JSON input (line 8, file ""Code"")'</p>
"
61568681,"<p>I'm trying to get the data from the api to display on the component.html on Angular. But i'm stuck at this problem</p>

<p>So it supposed to show the totalDeaths from the API which is ""238569"".</p>

<p>ERROR Error: Error trying to diff '238569'. Only arrays and iterables are allowed</p>

<p>component.html</p>

<pre><code>&lt;li *ngFor=""let deaths of tDeaths""
  [value]=""deaths""&gt;
  {{ deaths }}
&lt;/li&gt;
</code></pre>

<p>component.ts</p>

<pre><code>import { Component, OnInit } from '@angular/core';
import { CoronaService } from '../corona.service';
import { Observable } from 'rxjs';

@Component({
  selector: 'app-covid',
  templateUrl: './covid.component.html',
  styleUrls: ['./covid.component.css']
})
export class CovidComponent implements OnInit {
  public tDeaths:any = [];
  constructor(private coronaService : CoronaService) {}

  ngOnInit(): void {
      this.coronaService.getJSON().subscribe(data =&gt; {
        console.log(data);

        this.tDeaths = data.Global.TotalDeaths;
      });
  }  
}
</code></pre>

<p>service.ts</p>

<pre><code>import { Injectable } from '@angular/core';
import { HttpClient } from '@angular/common/http';
import { Observable } from 'rxjs';



@Injectable({
  providedIn: 'root'
})
export class CoronaService {

  constructor(private http: HttpClient) {
    this.getJSON().subscribe(data =&gt; {
    });
}

public getJSON(): Observable&lt;any&gt; {
    return this.http.get(""https://api.covid19api.com/summary"");
}
}
</code></pre>
"
61189778,"<p>I am working an Express web application that runs JavaScript scraping code whenever the page is first loaded. </p>

<p>Here is the node web scraping code (scrape.js): </p>

<pre><code>const request = require('request-promise');
const cheerio = require('cheerio');
const fs = require('fs');
const data = require('../public/state_data.json');
const cases_data = require('../public/cases_data.json');

// retrieve wikipeida page
request('https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_the_United_States', (error, response, html) =&gt; {
if(!error &amp;&amp; response.statusCode == 200) {
    // create cheerio scraper 
    const $ = cheerio.load(html);

    // find, and loop through all the rows in the table
    var rows = $('.wikitable').find('tr');
    for(var i = 3; i &lt; 59; i++) {
        // scrape state name and cases from table
        var state = $(rows[i]).children('th:nth-child(2)').text().split(""\n"");
        var cases = parseInt($(rows[i]).children('td').html().replace("","", """"));

        // update state_data.json file w/ proper cases and per capita
        for(var j = 0; j &lt; data.length; j++) {
            if(data[j].state === state[0]) {
                // push new data to cases_data.json
                cases_data.push({
                    state: state[0],
                    latitude: data[j].latitude,
                    longitude: data[j].longitude,
                    cases: cases,
                    percapita: (cases / data[j].population)
                });

                // write to new cases_data.json file w/ state name, cases and calculated per capita 
                fs.writeFile('../public/cases_data.json', JSON.stringify(cases_data, null, 2), function(err) {
                        if (err) throw err;
                });
            }
        }
    }
} else {
    console.log('request error')
}
});
</code></pre>

<p>And here is the express app (app.js):</p>

<pre><code>const express = require('express');
const app = express();
const port = 3000;
const scrape = require('./scrape.js');

app.get('/', (req, res) =&gt; {
    scrape();
    res.render('index');
})

app.listen(port, () =&gt; console.log(`Example app listening at http://localhost:${port}`))
</code></pre>

<p>Right now when I run 'node app.js' I get this as an error: </p>

<blockquote>
  <p>TypeError: scrape is not a function</p>
</blockquote>

<p>I've tried wrapping scrape.js in a function to no avail. Any ideas? </p>
"
61639953,"<p>Im trying to upload my app to heroku</p>

<p>i got the error below, cant figure it out.</p>

<p>now, when im trying to push to heruko  - </p>

<p>'git push --set-upstream staging master' 
the remote is 'staging <a href=""https://git.heroku.com/blabla.git"" rel=""nofollow noreferrer"">https://git.heroku.com/blabla.git</a> (fetch)'</p>

<p>i get this error msg : </p>

<pre><code>[remote rejected]     master -&gt; master (pre-receive hook declined)
error: failed to push some refs to 'https://git.heroku.com/blabla.git'
</code></pre>

<hr>

<p>if it helps: </p>

<p>when I load the app in visual studio, Im opening 2 terminals - </p>

<p>1 for the frontend - cd frontend - npm start</p>

<p>1 for the back end - cd backend - node run server.js</p>

<hr>

<p>what am i doing wrong?</p>

<hr>

<p>PACKAGE JSON IN THE FRONT END FOLDER: </p>

<pre><code>  ""scripts"": {
    ""start"": ""react-scripts start"",
    ""build"": ""react-scripts build"",
    ""test"": ""react-scripts test"",
    ""eject"": ""react-scripts eject"",
  },
}
</code></pre>

<p>PACKAGE JSON IN THE BACKEND END FOLDER: </p>

<pre><code>{
    ""main"": ""server.js"",
    ""scripts"": {
      ""test"": ""echo \""Error: no test specified\"" &amp;&amp; exit 1"",
      ""start"": ""node server.js""
    },
  }

</code></pre>

<p>ERROR CODE</p>

<pre><code>2020-05-06T14:27:33.065460+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=np-covid-19-tracker.herokuapp.com request_id=451b134b-f71b-45a2-b80d-6ff484af8923 fwd=""77.124.82.234"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-06T14:29:19.115585+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=np-covid-19-tracker.herokuapp.com request_id=82c472cf-e91d-49c4-bbc2-5e0fde4b2232 fwd=""77.124.82.234"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-06T14:29:19.425304+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=np-covid-19-tracker.herokuapp.com request_id=be89f9f5-330b-41ee-a8be-f0eb303076d5 fwd=""77.124.82.234"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-06T14:29:21.520127+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=np-covid-19-tracker.herokuapp.com request_id=3f8ee4cf-8850-4ce2-adc9-4ba9d7efb9a9 fwd=""77.124.82.234"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-06T14:29:21.793845+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=np-covid-19-tracker.herokuapp.com request_id=c4594f42-6589-422e-b21e-7d06e6444974 fwd=""77.124.82.234"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-06T14:30:44.796612+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=np-covid-19-tracker.herokuapp.com request_id=cc013e92-b29e-48b8-b6a3-56812324a38b fwd=""77.124.82.234"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-06T14:30:45.090537+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=np-covid-19-tracker.herokuapp.com request_id=e4b3caa2-5257-471e-b0f2-207ffe2e6fe8 fwd=""77.124.82.234"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-06T14:30:50.000000+00:00 app[api]: Build started by user EMAIL@EMAIL.COM
2020-05-06T14:31:03.932757+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=np-covid-19-tracker.herokuapp.com request_id=6585cd91-8750-48ad-9a9d-c75a8f82b61a fwd=""77.124.82.234"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-06T14:31:04.230008+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=np-covid-19-tracker.herokuapp.com request_id=c09152d1-2454-450e-8fa7-312238ada727 fwd=""77.124.82.234"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-06T14:31:30.951225+00:00 app[api]: Release v4 created by user EMAIL@EMAIL.COM
2020-05-06T14:31:30.951225+00:00 app[api]: Deploy 1659eafe by user EMAIL@EMAIL.COM
2020-05-06T14:31:31.000000+00:00 app[api]: Build succeeded
2020-05-06T14:31:32.061500+00:00 heroku[web.1]: State changed from crashed to starting
2020-05-06T14:31:52.069529+00:00 heroku[web.1]: State changed from starting to crashed
2020-05-06T14:31:51.907510+00:00 app[web.1]: npm ERR! missing script: start
2020-05-06T14:31:51.934435+00:00 app[web.1]: 
2020-05-06T14:31:51.935177+00:00 app[web.1]: npm ERR! A complete log of this run can be found in:
</code></pre>
"
60905773,"<p>My app is working fine when i use localhost:3000, my api routes are proxying through localhost:8080. After i deployed and try to visit /news (this is where my api is being hit) it's giving me this error message: apiFuncs.js:10 Uncaught (in promise) TypeError: e.data.map is not a function.</p>

<p>this is my server config</p>

<pre><code>const express = require(""express"");
const morgan = require(""morgan"");
const path = require(""path"");
const app = express();
const port = process.env.PORT || 8080;

require(""dotenv"").config();

// logging middleware
app.use(morgan());

// body parsing
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// serves static files - react
if (process.env.NODE_ENV === ""production"") {
  app.use(express.static(path.join(__dirname, ""../build"")));
}

// redirection /api
app.use(""/api"", require(""./api""));

app.get(""*"", (req, res) =&gt; {
  res.sendFile(path.join(__dirname, ""../build"", ""index.html""));
});

function notFound(req, res, next) {
  res.status(404);
  const error = new Error(""Not Found"");
  next(error);
}

function errorHandler(error, req, res, next) {
  res.status(res.statusCode || 500);
  res.json({
    message: error.message
  });
}

app.use(notFound);
app.use(errorHandler);

app.listen(port, () =&gt; {
  console.log(""Listening on port "", port);
});

module.exports = app;
</code></pre>

<p>this is my /api</p>

<pre><code>const router = require(""express"").Router();
const fetch = require(""node-fetch"");

const baseUrl = ""https://newsapi.org/v2/top-headlines?"";

router.get(""/topHeadlines/:country/:category"", (req, res, next) =&gt; {
  let endPoint = `${baseUrl}apiKey=${process.env.NEWS_API_KEY}&amp;q=coronavirus&amp;pageSize=100`;
  const { country, category } = req.params;
  endPoint += `&amp;country=${country}&amp;category=${category}`;
  try {
    return fetch(endPoint)
      .then(response =&gt; response.json())
      .then(({ articles }) =&gt; res.json(articles));
  } catch (error) {
    next(error);
  }
});

router.get(""/topHeadlines/:filter"", (req, res, next) =&gt; {
  let endPoint = `${baseUrl}apiKey=${process.env.NEWS_API_KEY}&amp;q=coronavirus&amp;pageSize=100`;
  if (req.params.filter.length === 2) endPoint += `&amp;country=${req.params.filter}`;
  else endPoint += `&amp;category=${req.params.filter}`;
  return fetch(endPoint)
    .then(response =&gt; response.json())
    .then(({ articles }) =&gt; res.json(articles));
});

router.get(""/topHeadlines"", (req, res) =&gt; {
  let endPoint = `${baseUrl}apiKey=${process.env.NEWS_API_KEY}&amp;q=coronavirus&amp;pageSize=100`;
  return fetch(endPoint)
    .then(response =&gt; response.json())
    .then(({ articles }) =&gt; res.json(articles));
});

module.exports = router;
</code></pre>

<p>this is the function that i'm calling in the front-end which is hitting the route.
the error message is in .then(({data}))</p>

<pre><code>export const getTopHeadlines = async (country, category) =&gt; {
  let baseRoute = `api/topHeadlines`;
  if (country) baseRoute += `/${country}`;
  if (category) baseRoute += `/${category}`;
  return await axios
    .get(baseRoute)
    .then(({ data }) =&gt; data.map(article =&gt; selectFields(article)))
    .then(articles =&gt; filterArticles(articles));
};

</code></pre>

<p>i tried console logging the response and got</p>

<pre><code>{data: """", status: 200, statusText: ""OK"", headers: {…}, config: {…}, …}
data: """"
status: 200
statusText: ""OK""
headers: {connection: ""keep-alive"", content-length: ""0"", content-type: ""application/json; charset=utf-8"", date: ""Sat, 28 Mar 2020 19:15:11 GMT"", server: ""Cowboy"", …}
config: {url: ""api/topHeadlines"", method: ""get"", headers: {…}, transformRequest: Array(1), transformResponse: Array(1), …}
request: XMLHttpRequest {readyState: 4, timeout: 0, withCredentials: false, upload: XMLHttpRequestUpload, onreadystatechange: ƒ, …}
__proto__: Object
</code></pre>

<p>this is my package.json</p>

<pre><code>{
  ""name"": ""calamity-monitor"",
  ""version"": ""1.0.0"",
  ""main"": ""src/index.js"",
  ""private"": true,
  ""dependencies"": {
    ""@google-cloud/storage"": ""^4.6.0"",
    ""@material-ui/core"": ""^4.9.7"",
    ""@material-ui/icons"": ""^4.9.1"",
    ""@material-ui/styles"": ""^4.9.6"",
    ""@testing-library/jest-dom"": ""^4.2.4"",
    ""@testing-library/react"": ""^9.5.0"",
    ""@testing-library/user-event"": ""^7.2.1"",
    ""axios"": ""^0.19.2"",
    ""calcite-react"": ""^0.49.0"",
    ""child-process-promise"": ""^2.2.1"",
    ""cors"": ""^2.8.5"",
    ""dotenv"": ""^8.2.0"",
    ""esri-loader"": ""^2.13.0"",
    ""express"": ""^4.17.1"",
    ""firebase"": ""^7.11.0"",
    ""firebase-functions"": ""^3.5.0"",
    ""firebase-tools"": ""^7.15.1"",
    ""framer-motion"": ""^1.10.2"",
    ""local-storage-fallback"": ""^4.1.1"",
    ""material-ui"": ""^0.20.2"",
    ""morgan"": ""^1.10.0"",
    ""newsapi"": ""^2.4.0"",
    ""node-fetch"": ""^2.6.0"",
    ""nodemon"": ""^2.0.2"",
    ""os"": ""^0.1.1"",
    ""react"": ""^16.13.0"",
    ""react-dom"": ""^16.13.0"",
    ""react-infinite-scroll-component"": ""^5.0.4"",
    ""react-router-dom"": ""^5.1.2"",
    ""react-scripts"": ""3.4.0"",
    ""react-slick"": ""^0.25.2"",
    ""reselect"": ""^4.0.0"",
    ""styled-components"": ""^5.0.1"",
    ""styled-theming"": ""^2.2.0"",
    ""use-dark-mode"": ""^2.3.1""
  },
  ""scripts"": {
    ""start"": ""react-scripts start &amp; nodemon server/server.js"",
    ""build"": ""react-scripts build"",
    ""test"": ""react-scripts test"",
    ""eject"": ""react-scripts eject""
  },
  ""eslintConfig"": {
    ""extends"": ""react-app""
  },
  ""proxy"": ""http://localhost:8080"",
  ""browserslist"": {
    ""production"": [
      ""&gt;0.2%"",
      ""not dead"",
      ""not op_mini all""
    ],
    ""development"": [
      ""last 1 chrome version"",
      ""last 1 firefox version"",
      ""last 1 safari version""
    ]
  },
  ""devDependencies"": {
    ""node-sass"": ""^4.13.1"",
    ""sass"": ""^1.26.3"",
    ""typescript"": ""^3.8.3""
  }
}

</code></pre>

<p>website: <a href=""https://calamity-monitor.herokuapp.com/news"" rel=""nofollow noreferrer"">https://calamity-monitor.herokuapp.com/news</a></p>
"
60891500,"<p>I'm trying to add the data of my api to my other file, it's related to covid-19 virus and want to add three different sections, confirmed, recovered an deaths.</p>

<p>My code  file with data(api)</p>

<pre class=""lang-js prettyprint-override""><code>import React, { Component } from 'react';

const API = 'https://covid19.mathdro.id/api';

class MyData extends React.Component {
  constructor(props) {
    super(props);
    this.state = {
      confirmed: 0,
      recovered: 0,
      deaths: 0
    };
  }

  componentDidMount() {
    fetch(API)
      .then(response =&gt; response.json())
      .then(data =&gt; this.setState({
        confirmed: data.confirmed.value,
        deaths: data.deaths.value,
        recovered: data.recovered.value }));
  }

  render() {
    return(
      &lt;worldInfo data={this.state.confirmed} /&gt;,
      &lt;worldInfo data={this.state.recovered} /&gt;,
      &lt;worldInfo data={this.state.deaths} /&gt;
    )
  }
}

export default MyData;
</code></pre>

<p>The other file where I'm trying to use the data.</p>

<pre class=""lang-js prettyprint-override""><code>const data = [
  {
    name: 'Confirmed',  female: confirmed, male: 2290,
  },
  {
    name: 'Recovered', female: 125000, male: 2000,
  },
  {
    name: 'Deaths ', female: 25000, male: 0,
  },
];
</code></pre>

<p>The error I get is <strong>'confirmed' is not defined  no-undef</strong></p>
"
61601167,"<p>I want to edit the label property but when I try to do it with this <em>this.setState({chartData.datasets[0].label: 'Test'})</em> it throws me this error:
 P<em>arsing error: Unexpected token, expected "",""</em></p>

<pre><code>state = {
    chartData: {
      labels: ['monday', 'tuesday', 'wednesday'],
      datasets: [
        {
          label: '',
          data: [40, 32, 70],
          backgroundColor: [
            'rgba(75, 192, 192, 0.6)'
          ],
          borderWidth: 4
        }
      ]
    }
  }

  async componentDidMount() {
    this.getDataSet();
  }

  getDataSet = async () =&gt; {
    const res = await axios.get(""https://covid.ourworldindata.org/data/ecdc/total_cases.csv"");
    const dataSet = res.data;

    this.setState({chartData.datasets[0].label: 'Test'})
  }
</code></pre>
"
61451229,"<p>i wont to make class to handle fetch data from api, please help my trouble:</p>

<pre><code>class Api{
    static getAll(){
        fetch(""https://covid-193.p.rapidapi.com/statistics"", {
        ""method"": ""GET"",
        ""headers"": {
        ""x-rapidapi-host"": ""covid-193.p.rapidapi.com"",
        ""x-rapidapi-key"": ""c44a47562cmsh6ff0d107514bccfp146d00jsn876b11317ac5""
        }
        })
        .then(function(response) {
            return response.json()
        })
        .catch(function(err) {
            console.log(err)
        })
    }
}

export default Api;
</code></pre>

<p>when i call <strong>Api.getAll()</strong> in <strong>app.js</strong> like this:</p>

<pre><code>import Api from ""./api.js""
console.log(Api.getAll())
</code></pre>

<p>its not console anything , just console undefine.
but if i console inside <strong>.then()</strong> like this </p>

<pre><code>.then(function(response) {
            console.log(response.json())
</code></pre>

<p>the result in console is </p>

<pre><code>undefine
result json
</code></pre>

<p>and if i change the key to get eror, the <strong>.catch()</strong> not work also.</p>

<p>thanks,</p>
"
61615986,"<p>I have tried to include this code in my file for having a toggled dark mode for my react-website. But unfortunately, this code isn't working.I've tried to put the code inside the render function but it still shows this error. Can anybody please suggest a better way to put this code.  <a href=""https://i.stack.imgur.com/b5hUq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/b5hUq.png"" alt=""enter image description here""></a></p>

<pre><code>import React ,{useState} from 'react';

import styles  from './App.module.css';

import titleImage from './images/image.png'; 
import { Paper ,Switch  } from '@material-ui/core';
import {ThemeProvider, createMuiTheme } from '@material-ui/core/styles';

class App extends React.Component{
    const [darkMode, lightMode] = useState (false);
    const theme = createMuiTheme ({
        palette:{
            type: darkMode ? ""dark"" : ""light"",
        },
    });
    render(){
        const { data ,country } = this.state;
        return(
            &lt;ThemeProvider theme = {theme}&gt;
                &lt;Paper&gt;
                    &lt;div className={styles.container}  &gt;
                        &lt;img className={styles.image} src={titleImage} alt=""COVID-19"" /&gt;
                          &lt;Switch checked ={darkMode} onChange = {() =&gt; setDarkMode(!darMode) }


                    &lt;/div&gt;
                &lt;/Paper&gt;
            &lt;/ThemeProvider&gt; 
       )
    }
}

export default App;
</code></pre>

<p>{P.S. -  I can't change the code which includes the render function as this is only the portion of the entire code. }</p>
"
61156517,"<p>This is my component:</p>

<pre><code>import React, { useState, useEffect } from ""react"";

export default function App() {
  const [countriesArray, setCountriesArray] = useState([]);

  useEffect(() =&gt; {
    getCountriesArray();
  }, []);

  const getCountriesArray = async () =&gt; {
    try {
      let response = await fetch(
        ""https://coronavirus-19-api.herokuapp.com/countries""
      );
      if (response.status === 200) {
        const newCountriesArray = [...countriesArray];
        const data = await response.json();
        await data.forEach(item =&gt; newCountriesArray.push(item.country));
        setCountriesArray(newCountriesArray);
      } else {
        setErrorStatus(true);
        console.error(""Error status"");
      }
    } catch (err) {
      console.error(err);
    }
  };

  const optionItems = countriesArray.map((item) =&gt;
        &lt;option key={item}&gt;{item}&lt;/option&gt;
    )

  return (
    &lt;div className=""App""&gt;
      &lt;select&gt;{optionItems}&lt;/select&gt;
    &lt;/div&gt;
  );
}
</code></pre>

<p>In the select I get the names of the countries when mounting the component but in the console I have a loop error message:</p>

<pre><code>Warning: Encountered two children with the same key, `Total:`. Keys should be unique so that components maintain their identity across updates. Non-unique keys may cause children to be duplicated and/or omitted — the behavior is unsupported and could change in a future version.
    in select (at App.js:36)
    in div (at App.js:35)
    in App
    in StrictMode (at src/index.js:8)
</code></pre>

<p>However I use the empty array as a second parameter of the useEffect to execute it only when mounting the component</p>
"
60832376,"<p>I have a problem, probably stupid one, with slack slash command.</p>

<p>I config a /command that simple ask some data about covid infection that will be fetch at request, the answer work well but after some second (3000 ms for timeout) i have a message of error ""failed with the error ""operation_timeout"". </p>

<p>Reading Slack documentation i must send a post message of confirmation and this i think is done by sending Post response with message, right? or i must send an answer before send the message?</p>

<p>This is the code:</p>

<pre><code>app.post('/covid', async (req, res) =&gt; {
console.log(req.body)
const respUrl = req.body.response_url
slackBody = {
    ""text"": ""Test""
}

await axios.post(respUrl, JSON.stringify(slackBody), {
    headers: {
        'Content-Type': 'application/json',
    }
})
            .then(function (response) {
                console.log(response.data);
                console.log(response.status);
                console.log(response.statusText);
                console.log(response.headers);
                console.log(response.config);
            })
            .catch((e) =&gt; console.log(e))
})
</code></pre>

<p><a href=""https://i.stack.imgur.com/LPK1x.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LPK1x.png"" alt=""This is the result""></a></p>

<p>And this is the Axios response. </p>

<pre><code>{
  url: 'https://hooks.slack.com/commands/TU7AFJ1RU/1022360678069/tTuQ4NJhgmnb58FNPeubZUR5',
  method: 'post',
  data: '{""text"":""Test""}',
  headers: {
  Accept: 'application/json, text/plain, */*',
  'Content-Type': 'application/json',
  'User-Agent': 'axios/0.19.2',
 'Content-Length': 15
},
transformRequest: [ [Function: transformRequest] ],
transformResponse: [ [Function: transformResponse] ],
timeout: 0,
adapter: [Function: httpAdapter],
xsrfCookieName: 'XSRF-TOKEN',
xsrfHeaderName: 'X-XSRF-TOKEN',
maxContentLength: -1,
validateStatus: [Function: validateStatus]
}
</code></pre>

<p>I'm breaking my head from 8hour for this tricky issue. Thanks for your help :)</p>

<hr>

<p>UPDATE</p>

<p>Dear community i resolve this issue with simple </p>

<pre><code>res.send(slackBody)
</code></pre>

<p>deleting all axios config, now i have plain message, also if i send object Block the slack visualize Array and not the message... </p>
"
60796850,"<p>I am trying to access endpoint data of country &amp; cases from this API: <a href=""https://corona.lmao.ninja/countries"" rel=""nofollow noreferrer"">https://corona.lmao.ninja/countries</a></p>

<p>After the fetch request I have an array of objects. How can I access the endpoints? </p>

<p>Thanks for your help</p>

<p>These are my relevant code snippets: 
console.log(stats) in the CasesByCountry function prints an array of objects. 
When I call map on stats the Error is 'TypeError: Cannot read property 'map' of undefined'</p>

<pre><code>export default function useStats(url) {
  const [stats, setStats] = useState();
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState();
  useEffect(() =&gt; {
    async function fetchData() {
      setLoading(true);
      setError();
      const data = await fetch(url)
        .then(res =&gt; res.json())
        .catch(err =&gt; {
          setError(err);
        });
        console.log('data', url, data)
      setStats(data);
      setLoading(false);
    }
    fetchData();
  }, [url]);
  return {
    stats,
    loading,
    error,
  };
}

export default function CasesByCountry() {
  const { stats, loading, error } = useStats('https://coronavirus-19-api.herokuapp.com/countries');
  console.log(stats)
  stats.map(stat =&gt; {
    console.log(stat.country)
  })
  return (
    &lt;div&gt;
      &lt;h2&gt;....&lt;/h2&gt;
    &lt;/div&gt;
  )
}
</code></pre>
"
60878541,"<p>I've been having an annoying time trying to debug why heroku kept crashing my app, and I got to the point where I decided to npx create-react-app a clean, stock project and push it to github and see if it would fail. It did! In fact, the errors where identical. Does anyone have any idea as to why? I'll paste the error log below: </p>

<pre><code>2020-03-27T00:54:56.850925+00:00 app[web.1]: 

2020-03-27T00:54:56.850937+00:00 app[web.1]: &gt; test@0.1.0 start /app

2020-03-27T00:54:56.850941+00:00 app[web.1]: &gt; react-scripts start

2020-03-27T00:54:56.850941+00:00 app[web.1]: 

2020-03-27T00:54:57.000000+00:00 app[api]: Build succeeded

2020-03-27T00:54:58.704186+00:00 app[web.1]: [34mℹ[39m [90m｢wds｣[39m: Project is running at http://172.18.128.138/

2020-03-27T00:54:58.704582+00:00 app[web.1]: [34mℹ[39m [90m｢wds｣[39m: webpack output is served from 

2020-03-27T00:54:58.704672+00:00 app[web.1]: [34mℹ[39m [90m｢wds｣[39m: Content not from webpack is served from /app/public

2020-03-27T00:54:58.704763+00:00 app[web.1]: [34mℹ[39m [90m｢wds｣[39m: 404s will fallback to /

2020-03-27T00:54:58.704945+00:00 app[web.1]: Starting the development server...

2020-03-27T00:54:58.704946+00:00 app[web.1]: 

2020-03-27T00:54:58.806112+00:00 heroku[web.1]: State changed from crashed to starting

2020-03-27T00:54:58.801584+00:00 heroku[web.1]: State changed from starting to crashed

2020-03-27T00:55:06.517253+00:00 heroku[web.1]: Starting process with command `npm start`

2020-03-27T00:55:08.823558+00:00 app[web.1]: 

2020-03-27T00:55:08.823600+00:00 app[web.1]: &gt; test@0.1.0 start /app

2020-03-27T00:55:08.823601+00:00 app[web.1]: &gt; react-scripts start

2020-03-27T00:55:08.823601+00:00 app[web.1]: 

2020-03-27T00:55:10.648454+00:00 app[web.1]: [34mℹ[39m [90m｢wds｣[39m: Project is running at http://172.17.12.190/

2020-03-27T00:55:10.649058+00:00 app[web.1]: [34mℹ[39m [90m｢wds｣[39m: webpack output is served from 

2020-03-27T00:55:10.649175+00:00 app[web.1]: [34mℹ[39m [90m｢wds｣[39m: Content not from webpack is served from /app/public

2020-03-27T00:55:10.649256+00:00 app[web.1]: [34mℹ[39m [90m｢wds｣[39m: 404s will fallback to /

2020-03-27T00:55:10.649462+00:00 app[web.1]: Starting the development server...

2020-03-27T00:55:10.649463+00:00 app[web.1]: 

2020-03-27T00:55:10.768321+00:00 heroku[web.1]: State changed from starting to crashed

2020-03-27T00:55:10.743454+00:00 heroku[web.1]: Process exited with status 0

2020-03-27T00:57:37.184021+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covidvisualizer.herokuapp.com request_id=bb939d90-ca76-4e9b-a1c5-98fd32894599 fwd=""68.101.72.92"" dyno= connect= service= status=503 bytes= protocol=https

2020-03-27T00:57:37.409787+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=covidvisualizer.herokuapp.com request_id=69af616c-8fc9-4234-90de-78972030846a fwd=""68.101.72.92"" dyno= connect= service= status=503 bytes= protocol=https
</code></pre>

<p>I've tried looking up the error code itself but I really haven't found anything. Any help is appreciated!</p>
"
61018374,"<p>I am trying to push my Node.js app which uses puppeteer2.1.1 into Github so I can then host on Azure. After trying to push I get these errors.</p>

<p><img src=""https://i.stack.imgur.com/IVf9c.png"" alt=""error message after trying to push to git""></p>

<p>I tried using <code>git lfs</code> followed all the commands by tracking the files, which I believe needs to be <code>/.local-chromium</code> according to the error message. After trying to push again still failed.</p>

<p>Has anybody used puppeteer and uploading to GitHub ever run into the same problem? I am also confused as to why it is even going to the node_modules folder. I thought that was automatically ignored when pushing to git. Here is my code below.</p>

<p>index.js </p>

<pre><code>const puppeteer = require(""puppeteer"");
require('dotenv').config();
const accountSid = process.env.TWILIO_ACCOUNT_SID;
const authToken = process.env.TWILIO_AUTH_TOKEN;
const client = require('twilio')(accountSid, authToken);
var schedule = require('node-schedule');

function coronaInfoSearch(){

    puppeteer.launch({  
        headless:true
    }).then(async browser =&gt;{


        //open new tab and go to specified url
        const page = await browser.newPage();

        await page.goto('https://www.worldometers.info/coronavirus/country/us/');

        //select elements wanted 
        page.waitForSelector('td')
            .then(async function(){

                //var self explanatory 
                const njRowTotalCases =await page.$eval('table .even .sorting_1', element =&gt; element.innerHTML);
                const njRowName = await page.$eval('table .even td', element =&gt; element.innerHTML);
                const njRowActiveCases = await page.$eval('#usa_table_countries_today &gt; tbody:nth-child(2) &gt; tr:nth-child(2) &gt; td:nth-child(6)', element =&gt; element.innerHTML);
                const njRowDeaths = await page.$eval('#usa_table_countries_today &gt; tbody:nth-child(2) &gt; tr:nth-child(2) &gt; td:nth-child(4)' , element =&gt; element.innerHTML);

                var coronainfoOutput = ""Total Cases:\n""+njRowTotalCases+""\n\n""+""Active Cases:""+njRowActiveCases+""\n\n""+""Total Deaths:""+njRowDeaths;
                //atring to be sent for outputting 
                var coronainfoOutputHeading=""NJ COVID-19 Update\n----------------\n"";

                //sent text message 
                client.messages
                  .create({
                     body: coronainfoOutputHeading + coronainfoOutput,
                     from: process.env.TWILIO_PHONE_NUMBER,
                     to: process.env.ANT_NUMBER
                   })
                  .then(message =&gt; console.log(message.sid));
            })
    });
};

schedule.scheduleJob(""55 13 * * 0-6"", function(){
    coronaInfoSearch();
});
</code></pre>

<p>package.json</p>

<pre><code>{
  ""name"": ""coronawebscrap"",
  ""version"": ""1.0.0"",
  ""description"": """",
  ""main"": ""index.js"",
  ""scripts"": {
    ""start"": ""node index.js"",
    ""test"": ""echo \""Error: no test specified\"" &amp;&amp; exit 1""
  },
  ""keywords"": [],
  ""author"": """",
  ""license"": ""ISC"",
  ""dependencies"": {
    ""dotenv"": ""^8.2.0"",
    ""express"": ""^4.17.1"",
    ""puppeteer"":  ""^2.1.1"",
    ""node-schedule"": ""^1.3.2"",
    ""twilio"": ""^3.41.1""
  }
}
</code></pre>

<p>.gitattributes</p>

<pre><code>.local-chromium filter=lfs diff=lfs merge=lfs -text
node_modules/puppeteer/.local-chromium filter=lfs diff=lfs merge=lfs -text
</code></pre>

<h2>Edit</h2>

<p>After putting node_modules/ under the .gitignore file, then adding to git repo, then committing, then pushing, I am still having same error.</p>

<p><strong>.gitignore</strong> </p>

<pre><code>.env
node_modules/
</code></pre>

<p>Git actions and errors:</p>

<p><img src=""https://i.stack.imgur.com/IVf9c.png"" alt=""**git actions and errors**""></p>
"
61630163,"<pre><code>app.get(""/dashboard"", function(req, res) {
  const country = ""Singapore"";

  // I used a constant in desperation

  const url =
    ""https://api.covid19api.com/live/country/"" + country;
  https.get(url, function(response) {
    response.on(""data"", function(data) {
      const caseData = JSON.parse(data);

      // Error stems from here

      res.render(""cases"", { caseData: caseData });
    });
  });
});
</code></pre>
"
61452397,"<p>I created new heroku app and pushed my react application first gives no error but while trying to load on heroku it crashes.</p>

<p><strong>package.json</strong> file:</p>

<pre><code>    {
      ""name"": ""covid-react"",
      ""version"": ""0.1.0"",
      ""private"": true,
      ""engines"": {
        ""node"": ""12.14.0"",
        ""npm"": ""6.13.4""
      },
      ""dependencies"": {
        ""@fortawesome/fontawesome"": ""^1.1.8"",
        ""@fortawesome/fontawesome-svg-core"": ""^1.2.28"",
        ""@fortawesome/free-solid-svg-icons"": ""^5.13.0"",
        ""@fortawesome/react-fontawesome"": ""^0.1.9"",
        ""@material-ui/core"": ""^4.9.11"",
        ""@testing-library/jest-dom"": ""^4.2.4"",
        ""@testing-library/react"": ""^9.5.0"",
        ""@testing-library/user-event"": ""^7.2.1"",
        ""axios"": ""^0.19.2"",
        ""chart.js"": ""^2.9.3"",
        ""classnames"": ""^2.2.6"",
        ""react"": ""^16.13.1"",
        ""react-chartjs-2"": ""^2.9.0"",
        ""react-countup"": ""^4.3.3"",
        ""react-dom"": ""^16.13.1"",
        ""react-scripts"": ""3.4.1"",
        ""serve"": ""11.3.0""
      },
      ""scripts"": {
        ""predeploy"": ""npm run build"",
        ""deploy"": ""serve -s build"",
        ""postdeploy"": ""now alias -A ./build/now.json"",
        ""start"": ""react-scripts start"",
        ""build"": ""react-scripts build"",
        ""test"": ""react-scripts test --env=jsdom"",
        ""eject"": ""react-scripts eject""    
      },
      ""eslintConfig"": {
        ""extends"": ""react-app""
      },
      ""browserslist"": {
        ""production"": [
          ""&gt;0.2%"",
          ""not dead"",
          ""not ie &lt;= 11"",
          ""not op_mini all""
        ],
        ""development"": [
          ""last 1 chrome version"",
          ""last 1 firefox version"",
          ""last 1 safari version""
        ]
      }
    }
</code></pre>

<p><strong>Procfile</strong></p>

<p>web: npm run deploy</p>

<p><strong>Heroku logs</strong>:</p>

<pre><code>2020-04-27T06:24:23.689579+00:00 heroku[web.1]: State changed from starting to crashed
2020-04-27T06:24:23.608647+00:00 app[web.1]: npm ERR! missing script: deploy
2020-04-27T06:24:23.617094+00:00 app[web.1]: 
2020-04-27T06:24:23.617388+00:00 app[web.1]: npm ERR! A complete log of this run can be found in:
2020-04-27T06:24:23.617531+00:00 app[web.1]: npm ERR!     /app/.npm/_logs/2020-04-27T06_24_23_609Z-debug.log
2020-04-27T06:24:24.000000+00:00 app[api]: Build succeeded
2020-04-27T06:24:29.460961+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covid19tracker-sid.herokuapp.com request_id=3f536ce1-d49b-4f04-990d-4fb1ef5ef39e fwd=""142.117.23.250"" dyno= connect= service= status=503 bytes= protocol=https
2020-04-27T06:24:29.843959+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=covid19tracker-sid.herokuapp.com request_id=97a80763-71d6-4dbf-9aa1-e4ecbc87a7d5 fwd=""142.117.23.250"" dyno= connect= service= status=503 bytes= protocol=https
</code></pre>

<p>Heroku logs application state as crashed. I tried changing package.json react-script start and adding Procfile with deploy command but app still doesn't show up. Heroku app runs for a while than show in logs that it crashed. </p>

<p><strong>UPDATE:</strong> I did it some how by adding this</p>

<pre><code>""scripts"": {
    ""dev"": ""react-scripts start"",
    ""deploy"": ""serve -s build"",
    ""start"": ""react-scripts start"",
    ""build"": ""react-scripts build"",
    ""test"": ""react-scripts test --env=jsdom"",
    ""eject"": ""react-scripts eject"",
    ""heroku-postbuild"": ""npm run build""    
  },
</code></pre>
"
60784136,"<p>So on my friend's mac computer, using the exact same src files and the same package.json file, this code runs perfectly. I tried npm ls react and it shows I indeed have two references, but npm deduped one of them. I'm also quite certain my call is legal. </p>

<pre><code>const IndexPage = () =&gt; {
    const { data, loading, error } = useQuery(CORONAVIRUS_QUERY)
    if (loading) return &lt;span&gt;loading...&lt;/span&gt;
    if (error) return &lt;p&gt;{error.message}&lt;/p&gt;

    return (
        &lt;Layout&gt;
            &lt;SEO title='Home' /&gt;
            &lt;h2&gt;I've got the high ground, and now so do you&lt;/h2&gt;
            &lt;DataTable regionData={data} /&gt;
            &lt;Link to='/about/'&gt;About&lt;/Link&gt;
        &lt;/Layout&gt;
    )
}

export default IndexPage
</code></pre>

<p>package.json</p>

<pre><code>{
    ""name"": ""gatsby-starter-default"",
    ""private"": true,
    ""description"": ""A simple starter to get up and developing quickly with Gatsby"",
    ""version"": ""0.1.0"",
    ""author"": ""null pointer studios"",
    ""dependencies"": {
        ""@apollo/react-hooks"": ""^3.1.3"",
        ""apollo-boost"": ""^0.4.7"",
        ""es6-promise"": ""^4.2.8"",
        ""gatsby"": ""^2.19.45"",
        ""gatsby-image"": ""^2.2.44"",
        ""gatsby-plugin-manifest"": ""^2.2.48"",
        ""gatsby-plugin-offline"": ""^3.0.41"",
        ""gatsby-plugin-react-helmet"": ""^3.1.24"",
        ""gatsby-plugin-sharp"": ""^2.4.13"",
        ""gatsby-source-filesystem"": ""^2.1.56"",
        ""gatsby-transformer-sharp"": ""^2.3.19"",
        ""graphql"": ""^14.6.0"",
        ""isomorphic-fetch"": ""^2.2.1"",
        ""nivo"": ""^0.31.0"",
        ""prop-types"": ""^15.7.2"",
        ""react"": ""^16.12.0"",
        ""react-dom"": ""^16.12.0"",
        ""react-helmet"": ""^5.2.1"",
        ""react-materialize"": ""^3.5.9"",
        ""reactable"": ""^1.1.0""
    },
    ""devDependencies"": {
        ""prettier"": ""^1.19.1""
    },
    ""keywords"": [
        ""gatsby""
    ],
    ""license"": ""MIT"",
    ""scripts"": {
        ""build"": ""gatsby build"",
        ""develop"": ""gatsby develop"",
        ""format"": ""prettier --write \""**/*.{js,jsx,json,md}\"""",
        ""start"": ""npm run develop"",
        ""serve"": ""gatsby serve"",
        ""clean"": ""gatsby clean"",
        ""test"": ""echo \""Write tests! -&gt; https://gatsby.dev/unit-testing\"" &amp;&amp; exit 1""
    },
    ""repository"": {
        ""type"": ""git"",
        ""url"": ""https://github.com/gatsbyjs/gatsby-starter-default""
    },
    ""bugs"": {
        ""url"": ""https://github.com/gatsbyjs/gatsby/issues""
    },
    ""prettier"": {
        ""singleQuote"": true,
        ""semi"": false,
        ""jsxSingleQuote"": true,
        ""bracketSpacing"": true,
        ""useTabs"": true
    }
}
</code></pre>

<p>Full Error Message as Requested
<a href=""https://i.stack.imgur.com/L5WVm.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/L5WVm.png</a></p>

<p>EDIT: 
const [something, setsomething] = useState(0)
doesn't work either, so maybe it IS my code?</p>
"
61255211,"<p>Would anyone be able to help me with this error? I am trying to create a drop down picker for country names, pulling from the following API path: <a href=""https://api.covid19api.com/countries"" rel=""nofollow noreferrer"">https://api.covid19api.com/countries</a></p>

<pre><code>TypeError: Country.map is not a function
at fetchCountries (index.js:29)
at async fetchAPI (CountryPicker.jsx:13)
</code></pre>

<p>Here are the two code sections I am working in:</p>

<p>CountryPicker.jsx</p>

<pre><code>import React, { useState, useEffect } from 'react';
import { NativeSelect, FormControl } from '@material-ui/core';

import styles from './CountryPicker.module.css';

import { fetchCountries } from '../../api';

const CountryPicker = () =&gt; {
  const [fetchedCountries, setFetchedCountries] = useState([]);

  useEffect(() =&gt; {
    const fetchAPI = async () =&gt; {
      setFetchedCountries(await fetchCountries());
    };

    fetchAPI();
  }, [setFetchedCountries]);
  console.log(fetchedCountries);


  return (
    &lt;FormControl className={styles.formControl}&gt;
      &lt;NativeSelect &gt;
        &lt;option value=""""&gt;Global&lt;/option&gt;
      &lt;/NativeSelect&gt;
    &lt;/FormControl&gt;
  );
};

export default CountryPicker;
</code></pre>

<p>index.js</p>

<pre><code>import axios from 'axios';

const summary = 'https://api.covid19api.com/summary';
const countriesURL = 'https://api.covid19api.com/countries';

export const fetchData = async () =&gt; {
    try {
        const { data: { Global: { NewConfirmed, TotalConfirmed, NewDeaths, TotalDeaths, NewRecovered, TotalRecovered, }, Date } } = await axios.get(summary);



        return {  NewConfirmed, TotalConfirmed, NewDeaths, TotalDeaths, NewRecovered, TotalRecovered, Date };

    } catch (error) {
        console.log(error);

    }
}

//TODO
//Fetch Daily Data for charts using axios

export const fetchCountries = async () =&gt; {
    try {
      const { data: [ {Country} ] } = await axios.get(countriesURL);



     return Country.map((Country) =&gt; Country);
    } catch (error) {
      console.log(error);

    }
  };
</code></pre>

<p>I tried to look up why the error may be happening and I found that .map() will not work on a variable that is not an array, but I'm unsure with the current implementation, how to fix this</p>

<p>The data from the API looks like this:</p>

<pre><code>[
    {""Country"":""Micronesia, Federated States of"",""Slug"":""micronesia"",""ISO2"":""FM""},
    {""Country"":""Bangladesh"",""Slug"":""bangladesh"",""ISO2"":""BD""},
    {""Country"":""Bouvet Island"",""Slug"":""bouvet-island"",""ISO2"":""BV""},
    // ...and so on...
]
</code></pre>
"
60882707,"<p>Facing this issue after running yarn, trying to run my repo, this is my repo structure</p>

<p><a href=""https://i.stack.imgur.com/S4yBq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/S4yBq.png"" alt=""enter image description here""></a></p>

<p>I run command yarn and this happens</p>

<p>yarn
yarn install v1.17.3
[1/4] Resolving packages...
[2/4] Fetching packages...
info fsevents@1.2.12: The platform ""win32"" is incompatible with this module.
info ""fsevents@1.2.12"" is an optional dependency and failed compatibility check. Excluding it from installation.
info fsevents@2.0.7: The platform ""win32"" is incompatible with this module.
info ""fsevents@2.0.7"" is an optional dependency and failed compatibility check. Excluding it from installation.
[3/4] Linking dependencies...
warning ""antd > rc-picker@1.1.5"" has unmet peer dependency ""dayjs@^1.8.18"".
warning ""react-scripts-rewired > @typescript-eslint/eslint-plugin@1.13.0"" has incorrect peer dependency ""eslint@^5.0.0"".
warning ""react-scripts-rewired > @typescript-eslint/parser@1.13.0"" has incorrect peer dependency ""eslint@^5.0.0"".
warning ""react-scripts-rewired > eslint-config-react-app@5.2.1"" has incorrect peer dependency ""@typescript-eslint/eslint-plugin@2.x"".
warning ""react-scripts-rewired > eslint-config-react-app@5.2.1"" has incorrect peer dependency ""@typescript-eslint/parser@2.x"".
warning ""react-scripts-rewired > @typescript-eslint/eslint-plugin > tsutils@3.17.1"" has unmet peer dependency ""typescript@>=2.8.0 || >= 3.2.0-dev || >= 3.3.0-dev || >= 3.4.0-dev || >= 3.5.0-dev || >= 3.6.0-dev 
|| >= 3.6.0-beta || >= 3.7.0-dev || >= 3.7.0-beta"".
warning "" > eslint-config-airbnb@18.1.0"" has unmet peer dependency ""eslint@^5.16.0 || ^6.8.0"".
warning "" > eslint-config-airbnb@18.1.0"" has unmet peer dependency ""eslint-plugin-react@^7.19.0"".<br>
warning "" > eslint-config-airbnb@18.1.0"" has unmet peer dependency ""eslint-plugin-react-hooks@^2.5.0 || ^1.7.0"".
warning ""eslint-config-airbnb > eslint-config-airbnb-base@14.1.0"" has unmet peer dependency ""eslint@^5.16.0 || ^6.8.0"".
warning "" > eslint-plugin-import@2.20.1"" has unmet peer dependency ""eslint@2.x - 6.x"".
[4/4] Building fresh packages...
success Saved lockfile.
Done in 166.99s.
PS D:\Repos\pth\telehealth-frontend> yarn start
yarn run v1.17.3
$ npm run build-css &amp;&amp; react-scripts start</p>

<blockquote>
  <p>Covid19-Tele-Health@0.1.0 build-css D:\Repos\pth\telehealth-frontend
  node-sass-chokidar src/styles/App.scss -o src/styles</p>
</blockquote>

<p>Rendering Complete, saving .css file...
Wrote CSS to D:\Repos\pth\telehealth-frontend\src\styles\App.css</p>

<p>There might be a problem with the project dependency tree.
It is likely not a bug in Create React App, but something you need to fix locally.</p>

<p>The react-scripts-rewired package provided by Create React App requires a dependency:</p>

<p>""babel-eslint"": ""10.0.2""</p>

<p>Don't try to install it manually: your package manager does it automatically.
However, a different version of babel-eslint was detected higher up in the tree:</p>

<p>D:\node_modules\babel-eslint (version: 9.0.0)</p>

<p>Manually installing incompatible versions is known to cause hard-to-debug issues.</p>

<p>If you would prefer to ignore this check, add SKIP_PREFLIGHT_CHECK=true to an .env file in your project. 
That will permanently disable this message but you might encounter other issues.</p>

<p>To fix the dependency tree, try following the steps below in the exact order:</p>

<ol>
<li>Delete package-lock.json (not package.json!) and/or yarn.lock in your project folder.</li>
<li>Delete node_modules in your project folder.</li>
<li>Remove ""babel-eslint"" from dependencies and/or devDependencies in the package.json file in your project folder.</li>
<li>Run npm install or yarn, depending on the package manager you use.</li>
</ol>

<p>In most cases, this should be enough to fix the problem.
If this has not helped, there are a few other things you can try:</p>

<ol start=""5"">
<li><p>If you used npm, install yarn (<a href=""http://yarnpkg.com/"" rel=""nofollow noreferrer"">http://yarnpkg.com/</a>) and repeat the above steps with it instead.<br>
 This may help because npm has known issues with package hoisting which may get resolved in future versions.</p></li>
<li><p>Check if D:\node_modules\babel-eslint is outside your project directory.
 For example, you might have accidentally installed something in your home folder.</p></li>
<li><p>Try running npm ls babel-eslint in your project folder.
 This will tell you which other package (apart from the expected react-scripts-rewired) installed babel-eslint.</p></li>
</ol>

<p>If nothing else helps, add SKIP_PREFLIGHT_CHECK=true to an .env file in your project.
That would permanently disable this preflight check in case you want to proceed anyway.</p>

<p>P.S. We know this message is long but please read the steps above :-) We hope you find them helpful!     </p>

<p>error Command failed with exit code 1.
info Visit <a href=""https://yarnpkg.com/en/docs/cli/run"" rel=""nofollow noreferrer"">https://yarnpkg.com/en/docs/cli/run</a> for documentation about this command.</p>

<p>Any help is appreciated </p>
"
61172402,"<p>I have two JSON requests for Covid-19 API's and two chart components.
The first works fine, the second, because it has a slightly different data structure, it does not. </p>

<p>Here's a working sandbox for the first component
<a href=""https://codesandbox.io/s/loving-tdd-t6m9z?file=/src/components/Request2.vue"" rel=""nofollow noreferrer"">https://codesandbox.io/s/loving-tdd-t6m9z?file=/src/components/Request2.vue</a></p>

<pre><code>[Vue warn]: Invalid prop: type check failed for prop ""countrydata"". Expected Object, got String with value ""American Samoa"".
</code></pre>

<p>When selecting the country in the select option for Request2, only the passes String to Chart2. Please look at the Vue Devtools bellow:</p>

<p><a href=""https://i.stack.imgur.com/xsXlA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xsXlA.png"" alt=""full object successfully passed to chart""></a></p>

<p>The issue is Request2 should pass Object with the country string:
<a href=""https://i.stack.imgur.com/96hiS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/96hiS.png"" alt=""only country string is passed from selected option""></a></p>

<p>Here is the one that doesn't work:</p>

<p>Request.vue</p>

<pre><code>&lt;template&gt;
  &lt;div&gt;
    &lt;select v-model=""country"" class=""option""&gt;
      &lt;option :value=""null""&gt;-- Select Country --&lt;/option&gt;
      &lt;option v-for=""value in info"" :key=""value.code""&gt;
        {{ value.name }}
      &lt;/option&gt;
    &lt;/select&gt;
    &lt;div v-if=""country""&gt;
      &lt;Chart2 :countrydata=""country"" /&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import axios from ""axios"";
import Chart2 from ""./WHOChart.vue"";

export default {
  data() {
    return { info: null, loading: true, errored: false, country: [] };
  },
  name: ""Request2"",
  components: {
    Chart2
  },
  mounted() {
    axios
      .get(""https://corona-api.com/countries"")
      .then(response =&gt; {
        this.info = response.data.data;
        console.log(""Request 2 type of response"", typeof this.info);
        // console.log(this.info);
        return this.info;
      })
      .catch(error =&gt; {
        this.errored = true;
      })
      .finally(() =&gt; (this.loading = false));
  }
};
&lt;/script&gt;
</code></pre>

<p>WHOChart.vue</p>

<pre><code>&lt;script&gt;
import { Line } from ""vue-chartjs"";

export default {
  extends: Line,
  props: {
    countrydata: {
      type: Object,
      default: null
    },
    options: {
      type: Object,
      default: null
    }
  },
  mounted() {
    this.renderChart(this.countrydata, this.options)
  }
};
&lt;/script&gt;
</code></pre>

<p>If someone could help out passing the whole object to the second file I would appreciate it. Stay safe!</p>
"
61121960,"<p>I'm working on a Geocharts map that imports some data with PapaParse. The issue I'm having is a ReferenceError on line <code>temp = CovidData.data.find(element[1] === countries[c]);</code>.</p>

<p>I'm using the PapaParse library to parse a csv file I grabbed off of GitHub.</p>

<pre><code>      google.charts.load('current', {
        'packages':['geochart'],
      });
      google.charts.setOnLoadCallback(drawRegionsMap);

    function drawRegionsMap() {
    Papa.parse('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv',{    download: true,
    complete: function(results) {var CovidData=results;}});

    countries = [""France"",""Germany"", ""United Kingdom"", ""US"", ""Italy""];
    var mapData = [{label: 'Country', type: 'string'}, 'Density',{label: 'Infected', type: 'number'}];

    for(c in countries) {
      var temp = CovidData.data.find(element =&gt; element[0] === """" &amp;&amp; element[1] === countries[c]);
      mapData.push([countries[c],1,temp[temp.length-1]);
    }

        var data = google.visualization.arrayToDataTable(mapData);
        var options = {
                    colorAxis: {colors: ['green','blue', 'red','black'], maxValue: 1},
                    datalessRegionColor: 'grey',
                    defaultColor: '#f5f5f5',
                    callback: drawRegionsMap,
          };

        var chart = new google.visualization.GeoChart(document.getElementById('regions_div'));
        chart.draw(data);
      }

</code></pre>
"
61157302,"<p>I'm using a React Hook to fetching data from a JSON object by using the native fetch method.</p>

<pre><code>const COVID_API_URL = ""https://api.covid19api.com/summary"";
const [infected, setInfected] = useState([]);

async function fetchData() {
  const response = await fetch(COVID_API_URL);

  response.json().then(response =&gt; setInfected(response));
}

useEffect(() =&gt; {
  fetchData();
}, []);

console.log(infected.Global.TotalConfirmed);
</code></pre>

<p>When I console.log the value from TotalConfirmed, I get the correct result, but when I refresh the browser, I keep getting:</p>

<pre><code>TypeError: Cannot read property 'TotalConfirmed' of undefined
</code></pre>

<p>Anyone know why this is happening? I'm using Gatsby.js default starter, does this have anything to do with this?</p>
"
60806805,"<p>I am trying to get a site to deploy to Firebase using TravisCI. I keep running into an issue when the functions deploy and try to run lint. eslint doesn't seem to be there, even though I added a command to <code>cd</code> and <code>npm install</code>. I'm sure this is some kind of no-brainer. What am I missing? </p>

<p>Here's my .travis.yml:</p>

<pre><code>language: node_js
node_js:
  - 12
deploy:
  provider: firebase
  project: ""*****""
  message: ""Deployed from Github by TravisCI""
  token:
    secure: 
       *******
env:
  global:
    secure: 
       *****
branches:
  only:
    - master
before_deploy:
  - npm install -g gatsby-cli
  - rm -rf node_modules/*/.git/
  - npm install
  - gatsby build
  - cd functions &amp;&amp; npm install --dev &amp;&amp; cd ..
</code></pre>

<p>Here's the error in the Travis log:</p>

<pre><code>Installing deploy dependencies
dpl.2
Preparing deploy
dpl.3
Deploying application
=== Deploying to 'covid19-reports'...
i  deploying storage, firestore, functions, hosting
Running command: npm --prefix ""$RESOURCE_DIR"" run lint
&gt; functions@ lint /home/travis/build/amygroshek/covid19reports/functions
&gt; eslint .
sh: 1: eslint: not found
npm ERR! code ELIFECYCLE
npm ERR! syscall spawn
npm ERR! file sh
npm ERR! errno ENOENT
npm ERR! functions@ lint: `eslint .`
npm ERR! spawn ENOENT
npm ERR! 
npm ERR! Failed at the functions@ lint script.
npm ERR! This is probably not a problem with npm. There is likely additional logging output above.
npm WARN Local package.json exists, but node_modules missing, did you mean to install?
npm ERR! A complete log of this run can be found in:
npm ERR!     /home/travis/.npm/_logs/2020-03-23T00_34_17_951Z-debug.log
Error: functions predeploy error: Command terminated with non-zero exit code1

</code></pre>
"
61143794,"<p>I am trying to change de legend order of each interaction so we can better understand the country rank of COVD-19 deaths. Is that possible with ggplot2 or we must do this by for loop plots? Anyone can help? Thanks!</p>

<pre><code>library(utils)
library(httr)

GET(""https://opendata.ecdc.europa.eu/covid19/casedistribution/csv"", authenticate("":"", "":"", type=""ntlm""), write_disk(tf &lt;- tempfile(fileext = "".csv"")))
data &lt;- read.csv(tf)
data$dateRep&lt;- as.Date(data$dateRep,""%d/%m/%Y"")
seq_datas&lt;- sort(unique(data$dateRep))
seq_paises&lt;- as.vector(unique(data$countriesAndTerritories))
df_final&lt;- data.frame(dateRep = NA, countriesAndTerritories =NA,
                      deaths = NA, acumdeath=NA,cases = NA, dias_diazero=NA )
for(j in seq_paises){
  acum&lt;- subset(data, countriesAndTerritories == j,
                select= c(dateRep,countriesAndTerritories, deaths, cases))
  acum &lt;- acum[order(acum$dateRep, decreasing = FALSE),]
  acum$acumdeath&lt;- cumsum(acum$deaths)
  dia_zero&lt;- acum$dateRep[min(which(acum$cases&gt;0))]
  acum$dias_diazero&lt;- acum$dateRep-dia_zero
  df_final&lt;- rbind(df_final,acum)
}
df_final$dateRep&lt;- as.Date(df_final$dateRep, origin='1970-01-01')
df_final&lt;- df_final[complete.cases(df_final), ]
bra&lt;- subset(df_final, countriesAndTerritories == ""Brazil"")

require('ggplot2')
require('gganimate')

newdata &lt;- df_final[order(df_final$acumdeath, decreasing = TRUE),]
newdata&lt;- subset(newdata, dateRep == max(df_final$dateRep))
newdata &lt;- newdata[order(newdata$acumdeath, decreasing = TRUE),]
países&lt;- newdata[1:10,2]
newdata&lt;- data.frame()
dados&lt;- data.frame()
for(j in países){
  newdata&lt;- subset(df_final, countriesAndTerritories == j)
  dados&lt;- rbind(newdata,dados)
}
names(bra)&lt;- c(""dateRep"", ""Países"", ""deaths"", ""acumdeath"", ""cases"", ""dias_diazero"")
names(dados)&lt;- c(""dateRep"", ""Países"", ""deaths"", ""acumdeath"", ""cases"", ""dias_diazero"")
dados&lt;- rbind(dados, bra)
grafico &lt;- ggplot(dados, aes(x = dias_diazero, y=acumdeath,
                                colour = Países, label= Países)) +
  geom_point(show.legend = TRUE, alpha = 3) +
  xlim(0, max(dados$dias_diazero)) +
  labs(x = ""Dias a partir do primeiro caso confirmado"", y = ""Mortes Acumuladas COVID 19"") +
  scale_size(range = c(10, 12))
scale_color_discrete(breaks = sort(as.numeric(rownames(allEst))))

grafico +  transition_time(as.numeric(dateRep)) +
  shadow_mark(alpha = 0.3, size = 0.5)
</code></pre>

<p><img src=""https://i.stack.imgur.com/xg4uN.gif"" alt=""Result as gif image""></p>
"
60254870,"<p>I have seen several SO questions about inflection point calculation. I am still not sure if I have done it right. Based on lab confirmed cumulative case data in the epicenter of the current epidemic, we have tried to identify the inflection point. I used the <code>inflection</code> package and calculated the inflection point as ""08 Feb 2020"". I have also tried to calculate the first and second directives as estimated increase each and changing rate. I have little math understanding about it, but just following examples from different SO posts. My question: are those results from the following graphs consistent? If not how to improve my code. </p>



<pre class=""lang-r prettyprint-override""><code>df&lt;-structure(list(date = structure(c(18277, 18278, 18279, 18280, 
18281, 18282, 18283, 18284, 18285, 18286, 18287, 18288, 18289, 
18290, 18291, 18292, 18293, 18294, 18295, 18296, 18297, 18298, 
18299, 18300, 18301, 18302, 18303, 18304, 18305, 18306, 18307), 
class = ""Date""), 
cases = c(45, 62, 121, 198, 258, 363, 425, 
        495, 572, 618, 698, 1590, 1905, 2261, 2639, 3125, 4109, 5142, 
        6384, 8351, 10117, 11618, 13603, 14982, 16903, 18454, 19558, 
       20630, 21960, 22961, 23621)), 
class = ""data.frame"", row.names = c(NA, -31L))
xlb_0&lt;- structure(c(18281, 18285, 18289, 18293, 
                    18297, 18301, 18305,   
                    18309), class = ""Date"")
library(tidyverse)
# Smooth cumulative cases over time 
df$x = as.numeric(df$date)
fit_1&lt;- loess(cases ~ x, span = 1/3, data = df) 
df$case_sm &lt;-fit_1$fitted 

# use inflection to obtain inflection point
library(inflection)
guai_0 &lt;- check_curve(df$x, df$case_sm)
check_curve(df$x, df$cases)
#&gt; $ctype
#&gt; [1] ""convex_concave""
#&gt; 
#&gt; $index
#&gt; [1] 0
guai_1 &lt;- bese(df$x, df$cases, guai_0$index)
structure(guai_1$iplast, class = ""Date"")
#&gt; [1] ""2020-02-08""

# Plot cumulativew numbers of cases 
df %&gt;% 
  ggplot(aes(x = date, y = cases ))+
  geom_line(aes(y = case_sm), color = ""red"") +
  geom_point() + 
  geom_vline(xintercept = guai_1$iplast) + 
  labs(y = ""Cumulative lab confirmed infections"")
</code></pre>

<p><img src=""https://i.imgur.com/7JN0ufQ.png"" alt=""""></p>

<pre class=""lang-r prettyprint-override""><code># Daily new cases (first derivative) and changing rate (second derivative)
df$dt1 = c(0, diff(df$case_sm)/diff(df$x))
fit_2&lt;- loess(dt1 ~ x, span = 1/3, data = df) 
df$change_sm &lt;-fit_2$fitted 
df$dt2 &lt;- c(NA, diff(df$change_sm)/diff(df$x)) 

df %&gt;%  
  ggplot(aes(x = date, y = dt1))+
  geom_line(aes(y = dt1, 
                color = ""Estimated number of new cases"")) + 
  geom_point(aes(y = dt2*2, color = ""Changing rate"")) +
  geom_line(aes(y = dt2*2, color = ""Changing rate""))+
  geom_vline(xintercept = guai_1$iplast) + 
  labs(y = ""Estimatede number of new cases"") +
  scale_x_date(breaks = xlb_0, 
               date_labels = ""%b%d"") + 
  theme(legend.title = element_blank())
#&gt; Warning: Removed 1 rows containing missing values (geom_point).
#&gt; Warning: Removed 1 row(s) containing missing values (geom_path).
</code></pre>

<p><img src=""https://i.imgur.com/nYd1KdC.png"" alt=""""></p>

<p><sup>Created on 2020-02-17 by the <a href=""https://reprex.tidyverse.org"" rel=""nofollow noreferrer"">reprex package</a> (v0.3.0)</sup></p>
"
60842901,"<p>I am trying to reproduce this graphic below on the COVID19 (first plot) using <code>facet_wrap()</code> but I cannot make the other background series visible in gray (second plot).</p>

<p><a href=""https://i.stack.imgur.com/WeMyW.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WeMyW.jpg"" alt=""enter image description here""></a></p>

<p><strong>Second plot</strong></p>

<pre><code>library(dplyr)
library(httr)
library(readxl)
library(ggplot2)
library(ggrepel)
library(scales)
library(forcats)

url &lt;- paste(""https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide-"",format(Sys.time(), ""%Y-%m-%d""), "".xlsx"", sep = """")
GET(url, authenticate("":"", "":"", type=""ntlm""), write_disk(tf &lt;- tempfile(fileext = "".xlsx"")))
data &lt;- read_excel(tf)
data$`Countries and territories` = fct_recode( data$`Countries and territories`, ""Canada"" =""CANADA"")

days100 = data %&gt;%
  rename(country = `Countries and territories`) %&gt;%
  select(-Day, -Month, -Year) %&gt;%
  arrange(country, DateRep) %&gt;%  
  group_by(country) %&gt;%  
  mutate(test = if_else(Cases &gt;= 1, 
                        cumsum(Cases),0),
         logtest = if_else(test &gt; 0, 
                           log10(test),0),
         dummy100 = if_else(test &gt;= 100, 
                            1,0),
         num100 = if_else(dummy100 == 1, 
                          cumsum(dummy100),0),
         selec_count = if_else(country == ""Ecuador"",
                               1,
                               if_else(country == ""Italy"",
                                       2,
                                       if_else(country == ""US"",
                                               3,
                                               if_else(country == ""China"",
                                                       4,
                                                       0))))) %&gt;%
  filter(country != 'Cases_on_an_international_conveyance_Japan',
         test &gt;=100)

days100 = days100 %&gt;% 
  mutate(fil_count = if_else(GeoId == ""CL"" | GeoId == ""IT"" | GeoId == ""CN"" | GeoId == ""FR"", 1, 0))

ggplot(data = days100, aes(x = num100, 
                           y = test, 
                           color = selec_count,
                           group = country)) +
  geom_line() +
  guides(color = F) +
  #scale_color_manual(values = c(""1""=""#5aae61"", ""2""=""#7b3294"", ""3"" = ""red"", ""4"" = ""blue"", ""0""= ""black"")) +
  facet_wrap(~ country) +
  scale_x_continuous(expand = c(0, -1)) + 
  scale_y_continuous(trans=""log10"", 
                     labels = scales::comma,
                     limits = c(100, NA),
                     expand = expand_scale(mult = c(0, 0.05))) +  
  theme_bw() +
  ggrepel::geom_text_repel(data = days100 %&gt;%
                             filter(fil_count==1 &amp;
                                      DateRep == last(DateRep)),
                           aes(label = country))
</code></pre>

<p><a href=""https://i.stack.imgur.com/ROcdX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ROcdX.png"" alt=""enter image description here""></a></p>

<p>Also I want to add manual colors for <code>selec_count</code> category so that each series can be better visualized using <code>scale_color_manual()</code>.</p>

<p><strong>Without <code>facet_wrap()</code></strong></p>

<p><a href=""https://i.stack.imgur.com/KS63t.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KS63t.png"" alt=""enter image description here""></a></p>
"
60623127,"<p>I've been trying to use <code>tabulizer</code> to avoid hardcoding parsing that could possibly change with the next report. I was wondering if you all might have better ideas.</p>

<pre><code>library(tabulizer)
library(tidyverse)

who &lt;- ""https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200309-sitrep-49-covid-19.pdf""

page1 &lt;- tabulizer::extract_tables(who, pages = 4, output = ""data.frame"") %&gt;% 
  as.data.frame() %&gt;% 
  slice(5:n()) %&gt;% 
  select(-`X.1`)

page2 &lt;- tabulizer::extract_tables(who, pages = 5, output = ""data.frame"") %&gt;% 
  as.data.frame() %&gt;% 
  rbind(colnames(.))

page3 &lt;- tabulizer::extract_tables(who, pages = 6, output = ""data.frame"") %&gt;% 
  as.data.frame() %&gt;% 
  rbind(colnames(.))

colnames(page2) &lt;- colnames(page1)
colnames(page3) &lt;- colnames(page1)

dat &lt;- page1 %&gt;% rbind(page2) %&gt;% rbind(page3)
</code></pre>

<p>If you run this you'll notice the region and totals need to be removed but the page split and tall rows are where I'm having trouble.</p>
"
61019376,"<p>I'm having trouble understanding how to add tags to data series as I do <code>SELECT INTO</code> queries. I have an Influxdb of the <a href=""https://github.com/nytimes/covid-19-data"" rel=""nofollow noreferrer"">NYTimes COVID dataset</a> where I've used the <code>cases</code> and <code>deaths</code> fields as <code>fields</code> and the <code>state</code> and <code>county</code> information as tags. </p>

<p>I can aggregate data from neighboring counties in a query like this:</p>

<pre><code>SELECT sum(""cases"") AS ""cases"" FROM ""ny_covid"".""autogen"".""value"" WHERE (""state""='Pennsylvania') AND (""county""='Philadelphia' OR ""county""='Delaware') GROUP BY time(1d) FILL(null)
</code></pre>

<p>This works perfectly. But I want to save this aggregated data into a new database for doing other queries. Which I can do like this:</p>

<pre><code>SELECT sum(""cases"") AS ""cases"" INTO ""new_covid"".""autogen"".""value"" FROM ""ny_covid"".""autogen"".""value"" WHERE (""state""='Pennsylvania') AND (""county""='Philadelphia' OR ""county""='Delaware') GROUP BY time(1d) FILL(null)
</code></pre>

<p>My question is, how do I add a tag like <code>location=Philly</code> to the data I've just inserted into the <code>new_covid</code> database? Because, I'd like to do a few other location level aggregations and it seems like the <code>tag</code> is the way to keep these values distinct.</p>

<pre><code>SELECT sum(""cases"") AS ""cases"" INTO ""new_covid"".""autogen"".""value"" FROM ""ny_covid"".""autogen"".""value"" WHERE (""state""='Pennsylvania') AND (""county""='Dauphin' OR ""county""='Lancaster') GROUP BY time(1d) FILL(null)
</code></pre>

<p>All of the searching I've done has just been about using the tags in queries or preserving them when copying across databases. But I haven't been able to find anything about attaching tags in <code>SELECT INTO</code> type statements. </p>
"
60747741,"<p>I am writing a script to go to the NYT website on Corona, get the US data, extract numbers (total, death), and to send me a notification. I am close, but when I extract numbers and display them, they are put together (ie 700021 instead of 7000,21). My question is:</p>

<p>How do I extract the numbers so that they are delineated? </p>

<p>Here is the code:</p>

<pre><code>set theURL to ""https://www.nytimes.com/interactive/2020/world/coronavirus-maps.html?action=click&amp;pgtype=Article&amp;state=default&amp;module=styln-coronavirus&amp;variant=show&amp;region=TOP_BANNER&amp;context=storyline_menu""

tell application ""Safari"" to make new document with properties {URL:theURL}

tell application ""System Events""
    repeat until exists (UI elements of groups of toolbar 1 of window 1 of application process ""Safari"" whose name = ""Reload this page"")
        delay 0.5
    end repeat
end tell

to getInputByClass(theClass, num)
    tell application ""Safari""
        set input to do JavaScript ""
document.getElementsByClassName('"" &amp; theClass &amp; ""')["" &amp; num &amp; ""].innerText;"" in document 1
    end tell
    return input
end getInputByClass

set myVar to getInputByClass(""g-body "", 5)

on returnNumbersInString(inputString)
    set s to quoted form of inputString
    do shell script ""sed s/[a-zA-Z\\']//g &lt;&lt;&lt; "" &amp; s
    set dx to the result
    set numlist to {}
    repeat with i from 1 to count of words in dx
        set this_item to word i of dx
        try
            set this_item to this_item as number
            set the end of numlist to this_item
        end try
    end repeat
    return numlist
end returnNumbersInString

set theNums to returnNumbersInString(myVar) as text

display notification ""COVID-19 UPDATE"" subtitle theNums sound name ""glass""

tell application ""Safari""
    close its front window
end tell
</code></pre>
"
61132822,"<p><strong>SOLVED -- at end!</strong></p>

<p>How do I use Applescript to select a specific file in the Project Pane of a BBEdit window?</p>

<p>When I open BBEdit, without AppleScript, my Project opens up, with the Project file list in the left Pane just like it should.</p>

<p><strong>With AppleScript</strong>, I wish to</p>

<ol>
<li>select a specific file in this Pane and then</li>
<li>select ""Preview in BBEdit"" under its ""Markup"" Menu.</li>
</ol>

<p>The challenge right now is to use AppleScript for #1. I have tried the following and it doesn't work.</p>

<pre><code>tell application ""BBEdit""
    activate

    set theFile to ""compiled_corona_virus.html""

    select theFile
end tell
</code></pre>

<p>I get this error:</p>

<pre><code>error ""BBEdit got an error: \""compiled_corona_virus.html\"" doesn’t understand the “select” message."" number -1708 from ""compiled_corona_virus.html""
</code></pre>

<p>I have definitely looked at BBEdit's AppleScript Dictionary which reads:</p>

<pre><code>select v : Select the specified object
select [specifier] : the object to select
</code></pre>

<p>For what it's worth, I have tried this Script within Apple's Script Editor:</p>

<pre><code>tell application ""BBEdit""
    activate

    tell application ""Finder"" to set theFile to ""Macintosh HD:Users:johnlove:Sites:www.lovetoteach.dev:Web_Site_Storage:lovesongforever.com:coronavirus:compiled_corona_virus.html""

    select theFile
end tell
</code></pre>

<p>Identical select error?</p>

<p>I did also try to use</p>

<pre><code>open theFile
</code></pre>

<p>and BBEdit did open it and show the opened theFile in the right-most Pane, but <strong>without</strong> selecting this file in the left-most Project Pane.</p>

<p><strong>SOLVED by Rich Siegel at barebones.com</strong></p>

<p>Rich is the author of the Pearl of Wisdom ""Someday I will look back on all of this and laugh .. until they sedate me!""</p>

<pre><code>on setAutoRevealSelectedDocumentInProjectList()

    tell application ""Terminal""
        activate

        tell application ""System Events""
            keystroke ""defaults write com.barebones.bbedit AutoRevealSelectedDocumentInProjectList -bool YES ""
            keystroke return
        end tell
    end tell

end setAutoRevealSelectedDocumentInProjectList
</code></pre>

<p>Rich patiently teaches us that the leftmost Pane of BBEdit's window, consists of two separate parts:</p>

<pre><code>1) the Project's files on top
2) Currently Open Documents at the bottom
</code></pre>

<p>If you develop an AppleScript that opens a file via the open(name) command, BBEdit will open it and show it highlighted at the bottom under ""Currently Open Documents"".</p>

<p>HOWEVER, this does not change the Project file selected on top.</p>

<p>SO, to do that, the programmer must invoke Terminal with:</p>

<pre><code>setAutoRevealSelectedDocumentInProjectList()
</code></pre>

<p>THANK YOU, Rich!!</p>
"
61227392,"<p>I used a converter but the result was wrong...<br>
Am trying to develop application about Covid-19 using flutter and am kinda stuck on this format of result.I need to converted to dart to keep working on the app so any help will be appreciate and thanks in advance :) </p>

<h3>This is the result of the request from the api:</h3>

<pre><code>[  
  {  
    ""country"": ""Afghanistan"",  
    ""province"": null,  
    ""timeline"": {  
      ""cases"": {  
        ""3/16/20"": 21,  
        ""3/17/20"": 22,  
        ""3/18/20"": 22,  
        ""3/19/20"": 22,  
        ""3/20/20"": 24,  
        ""3/21/20"": 24,  
        ""3/22/20"": 40,  
        ""3/23/20"": 40,  
        ""3/24/20"": 74,  
        ""3/25/20"": 84,  
        ""3/26/20"": 94,  
        ""3/27/20"": 110,  
        ""3/28/20"": 110,  
        ""3/29/20"": 120,  
        ""3/30/20"": 170,  
        ""3/31/20"": 174,  
        ""4/1/20"": 237,  
        ""4/2/20"": 273,  
        ""4/3/20"": 281,  
        ""4/4/20"": 299,  
        ""4/5/20"": 349,  
        ""4/6/20"": 367,  
        ""4/7/20"": 423,  
        ""4/8/20"": 444,  
        ""4/9/20"": 484,  
        ""4/10/20"": 521,  
        ""4/11/20"": 555,  
        ""4/12/20"": 607,  
        ""4/13/20"": 665,  
        ""4/14/20"": 714  
      },  
      ""deaths"": {  
        ""3/16/20"": 0,  
        ""3/17/20"": 0,  
        ""3/18/20"": 0,  
        ""3/19/20"": 0,  
        ""3/20/20"": 0,  
        ""3/21/20"": 0,  
        ""3/22/20"": 1,  
        ""3/23/20"": 1,  
        ""3/24/20"": 1,  
        ""3/25/20"": 2,  
        ""3/26/20"": 4,  
        ""3/27/20"": 4,  
        ""3/28/20"": 4,  
        ""3/29/20"": 4,  
        ""3/30/20"": 4,  
        ""3/31/20"": 4,  
        ""4/1/20"": 4,  
        ""4/2/20"": 6,  
        ""4/3/20"": 6,  
        ""4/4/20"": 7,  
        ""4/5/20"": 7,  
        ""4/6/20"": 11,  
        ""4/7/20"": 14,  
        ""4/8/20"": 14,  
        ""4/9/20"": 15,  
        ""4/10/20"": 15,  
        ""4/11/20"": 18,  
        ""4/12/20"": 18,  
        ""4/13/20"": 21,  
        ""4/14/20"": 23  
      },  
      ""recovered"": {  
        ""3/16/20"": 1,  
        ""3/17/20"": 1,  
        ""3/18/20"": 1,  
        ""3/19/20"": 1,  
        ""3/20/20"": 1,  
        ""3/21/20"": 1,  
        ""3/22/20"": 1,  
        ""3/23/20"": 1,  
        ""3/24/20"": 1,  
        ""3/25/20"": 2,  
        ""3/26/20"": 2,  
        ""3/27/20"": 2,  
        ""3/28/20"": 2,  
        ""3/29/20"": 2,  
        ""3/30/20"": 2,  
        ""3/31/20"": 5,  
        ""4/1/20"": 5,  
        ""4/2/20"": 10,  
        ""4/3/20"": 10,  
        ""4/4/20"": 10,  
        ""4/5/20"": 15,  
        ""4/6/20"": 18,  
        ""4/7/20"": 18,  
        ""4/8/20"": 29,  
        ""4/9/20"": 32,  
        ""4/10/20"": 32,  
        ""4/11/20"": 32,  
        ""4/12/20"": 32,  
        ""4/13/20"": 32,  
        ""4/14/20"": 40  
      }  
    }  
  },  
...  
]  
</code></pre>

<h3>And this the result from converter:</h3>

<pre><code>class Historic {
  String country;
  Null province;
  Timeline timeline;

  Historic({this.country, this.province, this.timeline});

  Historic.fromJson(Map&lt;String, dynamic&gt; json) {
    country = json['country'];
    province = json['province'];
    timeline = json['timeline'] != null
        ? new Timeline.fromJson(json['timeline'])
        : null;
  }

  Map&lt;String, dynamic&gt; toJson() {
    final Map&lt;String, dynamic&gt; data = new Map&lt;String, dynamic&gt;();
    data['country'] = this.country;
    data['province'] = this.province;
    if (this.timeline != null) {
      data['timeline'] = this.timeline.toJson();
    }
    return data;
  }
}

class Timeline {
  Cases cases;
  Cases deaths;
  Cases recovered;

  Timeline({this.cases, this.deaths, this.recovered});

  Timeline.fromJson(Map&lt;String, dynamic&gt; json) {
    cases = json['cases'] != null ? new Cases.fromJson(json['cases']) : null;
    deaths = json['deaths'] != null ? new Cases.fromJson(json['deaths']) : null;
    recovered = json['recovered'] != null
        ? new Cases.fromJson(json['recovered'])
        : null;
  }

  Map&lt;String, dynamic&gt; toJson() {
    final Map&lt;String, dynamic&gt; data = new Map&lt;String, dynamic&gt;();
    if (this.cases != null) {
      data['cases'] = this.cases.toJson();
    }
    if (this.deaths != null) {
      data['deaths'] = this.deaths.toJson();
    }
    if (this.recovered != null) {
      data['recovered'] = this.recovered.toJson();
    }
    return data;
  }
}

class Cases {
  int i31620;
  int i31720;
  int i31820;
  int i31920;
  int i32020;
  int i32120;
  int i32220;
  int i32320;
  int i32420;
  int i32520;
  int i32620;
  int i32720;
  int i32820;
  int i32920;
  int i33020;
  int i33120;
  int i4120;
  int i4220;
  int i4320;
  int i4420;
  int i4520;
  int i4620;
  int i4720;
  int i4820;
  int i4920;
  int i41020;
  int i41120;
  int i41220;
  int i41320;
  int i41420;

  Cases(
      {this.i31620,
      this.i31720,
      this.i31820,
      this.i31920,
      this.i32020,
      this.i32120,
      this.i32220,
      this.i32320,
      this.i32420,
      this.i32520,
      this.i32620,
      this.i32720,
      this.i32820,
      this.i32920,
      this.i33020,
      this.i33120,
      this.i4120,
      this.i4220,
      this.i4320,
      this.i4420,
      this.i4520,
      this.i4620,
      this.i4720,
      this.i4820,
      this.i4920,
      this.i41020,
      this.i41120,
      this.i41220,
      this.i41320,
      this.i41420});

  Cases.fromJson(Map&lt;String, dynamic&gt; json) {
    i31620 = json['3/16/20'];
    i31720 = json['3/17/20'];
    i31820 = json['3/18/20'];
    i31920 = json['3/19/20'];
    i32020 = json['3/20/20'];
    i32120 = json['3/21/20'];
    i32220 = json['3/22/20'];
    i32320 = json['3/23/20'];
    i32420 = json['3/24/20'];
    i32520 = json['3/25/20'];
    i32620 = json['3/26/20'];
    i32720 = json['3/27/20'];
    i32820 = json['3/28/20'];
    i32920 = json['3/29/20'];
    i33020 = json['3/30/20'];
    i33120 = json['3/31/20'];
    i4120 = json['4/1/20'];
    i4220 = json['4/2/20'];
    i4320 = json['4/3/20'];
    i4420 = json['4/4/20'];
    i4520 = json['4/5/20'];
    i4620 = json['4/6/20'];
    i4720 = json['4/7/20'];
    i4820 = json['4/8/20'];
    i4920 = json['4/9/20'];
    i41020 = json['4/10/20'];
    i41120 = json['4/11/20'];
    i41220 = json['4/12/20'];
    i41320 = json['4/13/20'];
    i41420 = json['4/14/20'];
  }

  Map&lt;String, dynamic&gt; toJson() {
    final Map&lt;String, dynamic&gt; data = new Map&lt;String, dynamic&gt;();
    data['3/16/20'] = this.i31620;
    data['3/17/20'] = this.i31720;
    data['3/18/20'] = this.i31820;
    data['3/19/20'] = this.i31920;
    data['3/20/20'] = this.i32020;
    data['3/21/20'] = this.i32120;
    data['3/22/20'] = this.i32220;
    data['3/23/20'] = this.i32320;
    data['3/24/20'] = this.i32420;
    data['3/25/20'] = this.i32520;
    data['3/26/20'] = this.i32620;
    data['3/27/20'] = this.i32720;
    data['3/28/20'] = this.i32820;
    data['3/29/20'] = this.i32920;
    data['3/30/20'] = this.i33020;
    data['3/31/20'] = this.i33120;
    data['4/1/20'] = this.i4120;
    data['4/2/20'] = this.i4220;
    data['4/3/20'] = this.i4320;
    data['4/4/20'] = this.i4420;
    data['4/5/20'] = this.i4520;
    data['4/6/20'] = this.i4620;
    data['4/7/20'] = this.i4720;
    data['4/8/20'] = this.i4820;
    data['4/9/20'] = this.i4920;
    data['4/10/20'] = this.i41020;
    data['4/11/20'] = this.i41120;
    data['4/12/20'] = this.i41220;
    data['4/13/20'] = this.i41320;
    data['4/14/20'] = this.i41420;
    return data;
  }
}
</code></pre>
"
61579646,"<p>Hello all I wants to update data from Google spreadsheet to flutter android application by using real time data updated in JSON file accessible like one 'api.covid19india.org/data.json' mansioned.</p>

<p>Can anyone suggest me how to do this..
Has seen many of using PostMaster API..</p>

<p>Would be glad if anyone can tell me how to build the similar json service, if possible limiting Google environment.</p>
"
61420661,"<p>I don't know all that much about coding or anything similar. I need help with creating a  google sheet that automatically updates using data from <a href=""https://coronavirus.maryland.gov/datasets/master-casetracker-2/geoservice?orderBy=FID&amp;orderByAsc=false&amp;selectedAttribute=MONT&amp;where=ReportDate%20%3E%3D%20TIMESTAMP%20%272020-04-23%2000%3A00%3A00%27%20AND%20ReportDate%20%3C%3D%20TIMESTAMP%20%272020-05-31%2023%3A59%3A59%27"" rel=""nofollow noreferrer"">this source.</a></p>

<p>I managed to get the data onto my spreadsheet by using =ImportJSON("""") but it looked very messy. From what I could tell, the way I did it made it so that new data gets recorded on a new rows of the spreadsheet.</p>

<p>What I'm trying to do is to extract only the most recent numbers and sort in separate tables so that I could create bar graphs but I don't know how to do that.
<a href=""https://i.stack.imgur.com/CcCFP.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
"
61264149,"<p>I am working on an <code>android</code> app to display <code>Coronavirus</code> <code>JSON</code> Data using a <code>RecyclerView</code>. Initially i was successful in displaying the JSON Data in my <code>RecyclerView</code> but it displayed a list of all the countries exactly how i parsed the JSON Data. Now I want to add a search filter, so that the user can search for a specific country. I tried to achieve this by implementing <code>Filterable</code> in my RecyclerView Adapter class. Here are the steps i took.
I started by creating a custom Country object class with <code>getter</code> and <code>setter</code> methods.
Then, I stored the result I got from the network request after parsing the <code>JSON</code> data in an <code>Arraylist</code> called countries. Please see the code below</p>

<pre><code>public final class CovidJSON_Utils {

    public static String[] getSimpleStringFromJson(Context context, String codivJsonString)
    throws JSONException {
    final String COV_COUNTRY = ""Countries"";
    final String COV_CONFIRMED = ""confirmed"";
    final String COV_DEATHS = ""deaths"";
    final String COV_MESSAGE_CODE = ""code"";

        String[] parsedCovidData = null;
        ArrayList&lt;Country&gt; countries = new ArrayList&lt;&gt;();
        JSONObject covidJsonObject = new JSONObject(codivJsonString);

        if (covidJsonObject.has(COV_MESSAGE_CODE)) {
                int errorCode = covidJsonObject.getInt(COV_MESSAGE_CODE);
                switch (errorCode) {
                    case HttpURLConnection.HTTP_OK:
                        break;
                    case HttpURLConnection.HTTP_NOT_FOUND:
                        return null;
                    default:
                        return null;
                }

            }

            JSONArray countryCovidArray = covidJsonObject.getJSONArray(COV_COUNTRY);


            parsedCovidData = new String[countryCovidArray.length()];
            for (int i = 0; i &lt; countryCovidArray.length(); i++) {

                Country tempCountry = new Country();

                JSONObject countryJSONObject = countryCovidArray.getJSONObject(i);
                String Country = countryJSONObject.getString(""Country"");
                String Confirmed = String.valueOf(countryJSONObject.getInt(""TotalConfirmed""));
                String Deaths = String.valueOf(countryJSONObject.getInt(""TotalDeaths""));

                parsedCovidData[i] = Country + ""- Cases "" + Confirmed + ""- Deaths "" + Deaths;
                tempCountry.setCountryName(Country);
                tempCountry.setTotalConfirmed(Confirmed);
                tempCountry.setTotalDeaths(Deaths);
                countries.add(tempCountry);
                countries.clear();

            }
            return parsedCovidData;


        }


    } 
</code></pre>

<p>After that, in the <code>RecyclerView Adapter class</code> I added the <code>getFilter()</code> method to get a filtered <code>ArrayList</code>. I modified the <code>Corona_Stats_Adapter</code> constructor to pass in a <code>List&lt;Country&gt;</code>. But, from my Main activity when I call the <code>Corona_Stats_Adapter</code> constructor, How do I pass the correct <code>ArrayList</code> which I created by parsing the <code>JSON</code> Data in the <code>CovidJSON_Utils</code> class. </p>

<pre><code>public class Corona_Stats_Adapter extends RecyclerView.Adapter&lt;Corona_Stats_Adapter.Corona_Stats_AdapterViewHolder&gt;
 implements Filterable {

    private Context context;
    private List&lt;Country&gt; countryList;
    private List&lt;Country&gt; countryListFiltered;
    private String[] mCoronaData;
    public Corona_Stats_Adapter(Context context, List&lt;Country&gt; countryList){
            this.context = context;
            this.countryList = countryList;
            this.countryListFiltered = countryList;
    }

    @NonNull
    @Override
    public Corona_Stats_AdapterViewHolder onCreateViewHolder(@NonNull ViewGroup viewGroup, int viewType) {
        Context context = viewGroup.getContext();
        int LayoutIdForListItem =R.layout.corona_stats_list_item;
        LayoutInflater inflater =LayoutInflater.from(context);
        boolean ShouldAttachToParentImmediately = false;

        View view = inflater.inflate(LayoutIdForListItem,viewGroup,ShouldAttachToParentImmediately);
        return new Corona_Stats_AdapterViewHolder(view);
    }

    @Override
    public void onBindViewHolder(@NonNull Corona_Stats_AdapterViewHolder corona_stats_adapterViewHolder, int position) {
        final Country country = countryListFiltered.get(position);
        corona_stats_adapterViewHolder.mCoronaTextView.setText(country.getCountryName());

        String coronaStats = mCoronaData[position];
        corona_stats_adapterViewHolder.mCoronaTextView.setText(coronaStats);
    }

    @Override
    public int getItemCount() {
        if(null == mCoronaData) return 0;
        //return mCoronaData.length;
        return countryListFiltered.size();
    }

    @Override
    public Filter getFilter() {
        return new Filter() {
            @Override
            protected FilterResults performFiltering(CharSequence charSequence) {
                String charString = charSequence.toString();
                if(charString.isEmpty()){
                    countryListFiltered = countryList;
                } else {
                    List&lt;Country&gt; filteredList = new ArrayList&lt;&gt;();
                    for(Country row : countryList){
                        if(row.getCountryName().toLowerCase().contains(charString.toLowerCase()) ){
                            filteredList.add(row);
                        }
                    }
                    countryListFiltered = filteredList;
                }
                FilterResults filterResults = new FilterResults();
                filterResults.values = countryListFiltered;
                return filterResults;
            }

            @Override
            protected void publishResults(CharSequence charSequence, FilterResults filterResults) {
                countryListFiltered = (ArrayList&lt;Country&gt;) filterResults.values;
                notifyDataSetChanged();
            }
        };
    }

    public class Corona_Stats_AdapterViewHolder extends RecyclerView.ViewHolder {

        public final TextView mCoronaTextView;

        public Corona_Stats_AdapterViewHolder(@NonNull View view) {
            super(view);
            mCoronaTextView = (TextView) view.findViewById(R.id.tv_corona_data);
        }
    }

        public void setCoronaData(String[] coronaData){
            mCoronaData = coronaData;
            notifyDataSetChanged();
        }

}
</code></pre>

<p>Country class code </p>

<pre><code>
public class Country {
        String CountryName;
        String TotalConfirmed;
        String TotalDeaths;

        public Country(){
        }

        public String getCountryName(){return CountryName;}
        public String getTotalConfirmed(){return TotalConfirmed;}
        public String getTotalDeaths(){return TotalDeaths;}

    public void setCountryName(String countryName) {
        CountryName = countryName;
    }

    public void setTotalConfirmed(String totalConfirmed) {
        TotalConfirmed = totalConfirmed;
    }

    public void setTotalDeaths(String totalDeaths) {
        TotalDeaths = totalDeaths;
    }
}
</code></pre>

<p>Main Activity Code..</p>

<pre><code>public class MainActivity extends AppCompatActivity {
    private RecyclerView mRecyclerView;
    private Corona_Stats_Adapter mCorona_Stats_Adapter;
    private TextView mErrorDisplay;
    private ProgressBar mProgressBar;

    //ArrayList&lt;Country&gt; countries = new ArrayList&lt;Country&gt;();

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.corona_stats);

        mRecyclerView = (RecyclerView)findViewById(R.id.Corona_stats_recycler);
        mErrorDisplay = (TextView) findViewById(R.id.tv_error_message_display);

        LinearLayoutManager layoutManager = new LinearLayoutManager(this, LinearLayoutManager.VERTICAL, false);
        mRecyclerView.setLayoutManager(layoutManager);
        mRecyclerView.setHasFixedSize(true);
        mCorona_Stats_Adapter = new Corona_Stats_Adapter();
        mRecyclerView.setAdapter(mCorona_Stats_Adapter);
        mProgressBar = (ProgressBar)findViewById(R.id.pb_loading_indicator) ;



        loadCoronaData();

    }

        private void loadCoronaData(){
            showCoronaDataView();
            //String Country = String.valueOf(mSearchQuery.getText());
            new Fetch_data().execute();

        }
        private void showCoronaDataView(){
        mErrorDisplay.setVisibility(View.INVISIBLE);
        mRecyclerView.setVisibility(View.VISIBLE);
        }

        private void showErrorMessage(){
        mRecyclerView.setVisibility(View.INVISIBLE);
        mErrorDisplay.setVisibility(View.VISIBLE);
        }

    public class Fetch_data extends AsyncTask&lt;Void,Void,String[]&gt; {
        @Override
        protected void onPreExecute() {
            super.onPreExecute();
            mProgressBar.setVisibility(View.VISIBLE);
        }



        @Override
        protected String[] doInBackground(Void... voids) {

            URL covidRequestURL = NetworkUtils.buildUrl();


            try {
                String JSONCovidResponse = NetworkUtils.getResponseFromHttpUrl(covidRequestURL);
                String[] simpleJsonCovidData = CovidJSON_Utils.getSimpleStringFromJson(MainActivity.this, JSONCovidResponse);
                return simpleJsonCovidData;
            } catch (IOException | JSONException e) {
                e.printStackTrace();
                return null;
            }



        }

        @Override
        protected void onPostExecute(String[] coronaData) {
            mProgressBar.setVisibility(View.INVISIBLE);
            if(coronaData !=null){
                showCoronaDataView();
                mCorona_Stats_Adapter.setCoronaData(coronaData);
            } else{
                showErrorMessage();
            }

        }
    }

    @Override
    public boolean onCreateOptionsMenu(Menu menu) {
        getMenuInflater().inflate(R.menu.main, menu);
        return true;
    }

    @Override
    public boolean onOptionsItemSelected(@NonNull MenuItem item) {
        int menuItemThatWasSelected = item.getItemId();
        if(menuItemThatWasSelected == R.id.action_search){
            Toast.makeText(MainActivity.this, ""Search clicked"", Toast.LENGTH_LONG).show();
        }
        return super.onOptionsItemSelected(item);
    } 

}

</code></pre>
"
61611054,"<p><strong>JSON api file:</strong></p>

<pre><code>  {
    ""state"": ""Jammu and Kashmir"",
    ""statecode"": ""JK"",
    ""districtData"": [
      {
        ""district"": ""Anantnag"",
        ""notes"": """",
        ""active"": 107,
        ""confirmed"": 109,
        ""deceased"": 1,
        ""recovered"": 1,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      {
        ""district"": ""Budgam"",
        ""notes"": """",
        ""active"": 18,
        ""confirmed"": 30,
        ""deceased"": 0,
        ""recovered"": 12,
        ""delta"": {
          ""confirmed"": 4,
          ""deceased"": 0,
          ""recovered"": 0
        }
      }
    ]
  }
</code></pre>

<p><strong>Java Code:</strong></p>

<pre><code>        StringRequest stringRequest = new StringRequest(Request.Method.GET,
                ""https://api.covid19india.org/v2/state_district_wise.json"",
                new Response.Listener&lt;String&gt;() {
                    @Override
                    public void onResponse(String response) {
                        try {
                            JSONObject jsonObject = new JSONObject(response);
                            JSONArray jsonArray = jsonObject.getJSONArray(""districtData"");
                            for (int i = 0; i &lt; jsonArray.length(); i++) {
                                JSONObject object = jsonArray.getJSONObject(i);
                                // Need to get data here !!!
                            }
                            progressDialog.cancel();
                        } catch (Exception e) {
                        }
                    }
                }, new Response.ErrorListener() {
            @Override
            public void onErrorResponse(VolleyError error) {
            }
        });
        RequestQueue requestQueue = Volley.newRequestQueue(this);
        requestQueue.add(stringRequest);
</code></pre>

<p><strong>Logcat (debug):</strong> Down below is the logcat which I am getting when trying to run my app.</p>

<pre><code>2020-05-05 16:21:49.663 8813-8813/? I/owais.wabah202: Late-enabling -Xcheck:jni
2020-05-05 16:21:50.013 8813-8813/com.johnowais.wabah2020 I/Perf: Connecting to perf service.
2020-05-05 16:21:50.160 8813-8813/com.johnowais.wabah2020 W/owais.wabah202: Accessing hidden method Landroid/graphics/drawable/Drawable;-&gt;getOpticalInsets()Landroid/graphics/Insets; (light greylist, linking)
2020-05-05 16:21:50.160 8813-8813/com.johnowais.wabah2020 W/owais.wabah202: Accessing hidden field Landroid/graphics/Insets;-&gt;left:I (light greylist, linking)
2020-05-05 16:21:50.160 8813-8813/com.johnowais.wabah2020 W/owais.wabah202: Accessing hidden field Landroid/graphics/Insets;-&gt;right:I (light greylist, linking)
2020-05-05 16:21:50.160 8813-8813/com.johnowais.wabah2020 W/owais.wabah202: Accessing hidden field Landroid/graphics/Insets;-&gt;top:I (light greylist, linking)
2020-05-05 16:21:50.160 8813-8813/com.johnowais.wabah2020 W/owais.wabah202: Accessing hidden field Landroid/graphics/Insets;-&gt;bottom:I (light greylist, linking)
2020-05-05 16:21:50.235 8813-8813/com.johnowais.wabah2020 W/owais.wabah202: Accessing hidden method Landroid/view/View;-&gt;computeFitSystemWindows(Landroid/graphics/Rect;Landroid/graphics/Rect;)Z (light greylist, reflection)
2020-05-05 16:21:50.239 8813-8813/com.johnowais.wabah2020 W/owais.wabah202: Accessing hidden method Landroid/view/ViewGroup;-&gt;makeOptionalFitsSystemWindows()V (light greylist, reflection)
2020-05-05 16:21:50.289 8813-8813/com.johnowais.wabah2020 W/owais.wabah202: Accessing hidden method Landroid/widget/TextView;-&gt;getTextDirectionHeuristic()Landroid/text/TextDirectionHeuristic; (light greylist, linking)
2020-05-05 16:21:50.389 8813-8813/com.johnowais.wabah2020 D/OpenGLRenderer: Skia GL Pipeline
2020-05-05 16:21:50.495 8813-8856/com.johnowais.wabah2020 I/Adreno: QUALCOMM build                   : 2df12b3, I07da2d9908
    Build Date                       : 10/04/18
    OpenGL ES Shader Compiler Version: EV031.25.03.01
    Local Branch                     : 
    Remote Branch                    : 
    Remote Branch                    : 
    Reconstruct Branch               : 
2020-05-05 16:21:50.495 8813-8856/com.johnowais.wabah2020 I/Adreno: Build Config                     : S L 6.0.7 AArch64
2020-05-05 16:21:50.495 8813-8856/com.johnowais.wabah2020 D/vndksupport: Loading /vendor/lib64/hw/gralloc.msm8953.so from current namespace instead of sphal namespace.
2020-05-05 16:21:50.502 8813-8856/com.johnowais.wabah2020 I/Adreno: PFP: 0x005ff087, ME: 0x005ff063
2020-05-05 16:21:50.509 8813-8856/com.johnowais.wabah2020 I/ConfigStore: android::hardware::configstore::V1_0::ISurfaceFlingerConfigs::hasWideColorDisplay retrieved: 0
2020-05-05 16:21:50.509 8813-8856/com.johnowais.wabah2020 I/ConfigStore: android::hardware::configstore::V1_0::ISurfaceFlingerConfigs::hasHDRDisplay retrieved: 0
2020-05-05 16:21:50.511 8813-8856/com.johnowais.wabah2020 I/OpenGLRenderer: Initialized EGL, version 1.4
2020-05-05 16:21:50.511 8813-8856/com.johnowais.wabah2020 D/OpenGLRenderer: Swap behavior 2
2020-05-05 16:21:50.513 8813-8858/com.johnowais.wabah2020 D/NetworkSecurityConfig: No Network Security Config specified, using platform default
2020-05-05 16:21:50.515 8813-8858/com.johnowais.wabah2020 I/DpmTcmClient: RegisterTcmMonitor from: com.android.okhttp.TcmIdleTimerMonitor
2020-05-05 16:21:50.565 8813-8856/com.johnowais.wabah2020 D/vndksupport: Loading /vendor/lib64/hw/android.hardware.graphics.mapper@2.0-impl.so from current namespace instead of sphal namespace.
2020-05-05 16:21:50.566 8813-8856/com.johnowais.wabah2020 D/vndksupport: Loading /vendor/lib64/hw/gralloc.msm8953.so from current namespace instead of sphal namespace.
</code></pre>

<p>I am not able to fetch data as it is not in proper format. I want to use where clause also which will give me data of each district of a state which I want.</p>

<p><strong>API link:</strong> <a href=""https://api.covid19india.org/v2/state_district_wise.json"" rel=""nofollow noreferrer"">https://api.covid19india.org/v2/state_district_wise.json</a></p>
"
61474945,"<p>When vuetify datatable height is greater than the window height, when we scroll the page, I want the header row sticky till the datatable scroll is over</p>

<p>The behaviour should be similar to this
<a href=""https://output.jsbin.com/zuzuqe/1/"" rel=""nofollow noreferrer"">https://output.jsbin.com/zuzuqe/1/</a></p>

<p>also like the datatable they used <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a></p>

<p>I've also tried </p>

<pre><code>th {
    position:sticky;  
    top: 0;
    background-color: white;
}
</code></pre>

<p>The position sticky is relative to the datatable and not to the window</p>

<p>Can anyone suggest me some idea or codepen on how to implement the same using Vuetify datatable</p>
"
61390482,"<p>This is the api I am using <a href=""https://covid19.mathdro.id/api"" rel=""nofollow noreferrer"">https://covid19.mathdro.id/api</a></p>

<p>I need to take the {recovered.value} and divide it by {confirmed.value} and then multiply the result by 100 to get the recovery percentage.
But these values are coming as string and not number//</p>

<p>this is the file</p>

<pre><code>import React from ""react"";
import { Card, CardContent, Typography, Grid } from ""@material-ui/core"";
import CountUp from ""react-countup"";
import cx from ""classnames"";

import styles from ""./Cards.module.css"";

const Info = ({ data: { confirmed, recovered, deaths, lastUpdate } }) =&gt; {
  if (!confirmed) {
    return ""Loading..."";
  }

  return (
    &lt;div className={styles.container}&gt;
      &lt;Grid container spacing={3} justify=""center""&gt;
        &lt;Grid
          item
          xs={12}
          md={3}
          component={Card}
          className={cx(styles.card, styles.infected)}
        &gt;
          &lt;CardContent&gt;
            &lt;Typography color=""textSecondary"" gutterBottom&gt;
              Infected
            &lt;/Typography&gt;
            &lt;Typography variant=""h5"" component=""h2""&gt;
              &lt;CountUp
                start={0}
                end={confirmed.value}
                duration={2.75}
                separator="",""
              /&gt;
              &lt;div&gt;
                {recovered.value}/{confirmed.value}
              &lt;/div&gt;
            &lt;/Typography&gt;
            &lt;Typography color=""textSecondary""&gt;
              {new Date(lastUpdate).toDateString()}
            &lt;/Typography&gt;
            &lt;Typography variant=""body2"" component=""p""&gt;
              Number of active cases of COVID-19.
            &lt;/Typography&gt;
          &lt;/CardContent&gt;
        &lt;/Grid&gt;
        &lt;Grid
          item
          xs={12}
          md={3}
          component={Card}
          className={cx(styles.card, styles.recovered)}
        &gt;
          &lt;CardContent&gt;
            &lt;Typography color=""textSecondary"" gutterBottom&gt;
              Recovered
            &lt;/Typography&gt;
            &lt;Typography variant=""h5"" component=""h2""&gt;
              &lt;CountUp
                start={0}
                end={recovered.value}
                duration={2.75}
                separator="",""
              /&gt;
            &lt;/Typography&gt;
            &lt;Typography color=""textSecondary""&gt;
              {new Date(lastUpdate).toDateString()}
            &lt;/Typography&gt;
            &lt;Typography variant=""body2"" component=""p""&gt;
              Number of recoveries from COVID-19.
            &lt;/Typography&gt;
          &lt;/CardContent&gt;
        &lt;/Grid&gt;
        &lt;Grid
          item
          xs={12}
          md={3}
          component={Card}
          className={cx(styles.card, styles.deaths)}
        &gt;
          &lt;CardContent&gt;
            &lt;Typography color=""textSecondary"" gutterBottom&gt;
              Deaths
            &lt;/Typography&gt;
            &lt;Typography variant=""h5"" component=""h2""&gt;
              &lt;CountUp
                start={0}
                end={deaths.value}
                duration={2.75}
                separator="",""
              /&gt;
            &lt;/Typography&gt;
            &lt;Typography color=""textSecondary""&gt;
              {new Date(lastUpdate).toDateString()}
            &lt;/Typography&gt;
            &lt;Typography variant=""body2"" component=""p""&gt;
              Number of deaths caused by COVID-19.
            &lt;/Typography&gt;
          &lt;/CardContent&gt;
        &lt;/Grid&gt;
      &lt;/Grid&gt;
    &lt;/div&gt;
  );
};
export default Info;
</code></pre>

<p>and I have tried parseInt, in this part of code,for confirmed, but it does not woke</p>

<pre><code>const Info = ({ data: { parseInt(confirmed), recovered, deaths, 
  lastUpdate } }) =&gt; {
  if (!confirmed) {
    return ""Loading..."";
  }
....
</code></pre>

<p>this is my app.js</p>

<pre><code>import React from ""react"";

import { Cards, CountryPicker, Chart } from ""./components"";
import { fetchData } from ""./api/"";
import styles from ""./App.module.css"";

class App extends React.Component {
  state = {
    data: {},
    country: """",
  };

  componentWillUpdate() {
    console.log(""hello"");
  }
  async componentDidMount() {
    const data = await fetchData();
    this.setState({ data });
    console.log(""data"");
  }

  handleCountryChange = async (country) =&gt; {
    const data = await fetchData(country);
    this.setState({ data, country: country });
    console.log(""data"");
  };

  render() {
    const { data, country } = this.state;

    return (
      &lt;div className={styles.container}&gt;
        &lt;Cards data={data} /&gt;
        &lt;CountryPicker handleCountryChange={this.handleCountryChange} /&gt;
        &lt;Chart data={data} country={country} /&gt;
      &lt;/div&gt;
    );
  }
}

export default App;
</code></pre>
"
60905093,"<p>Im digging into the world of OpenStreetMap, leaflet and map tiles !<br>
First thing i want is a pretty map for data visualization. Prior experiense with google maps i could style the map client side, but when i search for OpenStreetMap styling it just dont seem possible, and it must be done server side.</p>

<p>How does a side like <a href=""https://coronavirus.app/map"" rel=""nofollow noreferrer"">coranavirus.app</a> do it then ? When i inspect their site i can see they pull the normal OSM png tiles. How does that turn into the light/dark map ?</p>

<p><a href=""https://i.stack.imgur.com/Md97o.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Md97o.png"" alt=""Network inspect of dark map ""></a></p>

<p><br><br>Any hints would be much appreciated !</p>
"
60907198,"<p>So this is the situation: I'm trying to get specific data from a Promise. The Promise shows data from an API: <a href=""https://api.covid19api.com/country/netherlands/status/confirmed"" rel=""nofollow noreferrer"">https://api.covid19api.com/country/netherlands/status/confirmed</a></p>

<p>The Promise consists of three values (0, 1 and 2) and each value consists of an array which hold multiple variables. I want to get the data from the last variable in the array from the Promise names '0' (do you understand?).</p>

<p>This is what the Promise looks like:
<a href=""https://i.stack.imgur.com/FnN8B.png"" rel=""nofollow noreferrer"">Here you can see it consists of the values 0, 1 and 2</a></p>

<p>After clicking on it: <a href=""https://i.stack.imgur.com/A9WqV.png"" rel=""nofollow noreferrer"">I try to get the data from the array (PromiseValue I believe it is called?)</a></p>

<p>So this is the data I want: the data from the last variable in the array. From this variable I want the data from 'Cases', so '8603'. <a href=""https://i.stack.imgur.com/j3a00.png"" rel=""nofollow noreferrer"">This is the data I try to get</a></p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>function getAPIdata() {

  var url = 'https://api.covid19api.com/country';
  var country = document.getElementById('country').value;
  var requestConfirmed = url + '/' + country + '/' + 'status' + '/' + 'confirmed';
  var requestRecovered = url + '/' + country + '/' + 'status' + '/' + 'recovered';
  var requestDeaths = url + '/' + country + '/' + 'status' + '/' + 'deaths';


  var requestOptions = {
    method: 'GET',
    redirect: 'follow'
  };

  Promise.all([
    fetch(requestConfirmed, requestOptions),
    fetch(requestRecovered, requestOptions),
    fetch(requestDeaths, requestOptions)
  ])

    .then(function (responses) {
      return responses.map(function (response){
        if(!response.ok) throw Error(response.statusText);
        return response.json();
      });

    }) .then(function(result){
        onAPISucces(result);
        // console.log(result);

    }) .catch(function (error){
        onAPIError(error);
    });

  }

  function onAPISucces(result) {

    var type = result;
    var landenLijst = result;
    console.log(landenLijst);
    var country = document.getElementById('country').value;
    // console.log(landenLijst[landenLijst.length - 1].Cases);
    for(var i=0; i &lt; landenLijst.length; i++);
    // console.log(landenLijst[i].TotalConfirmed);

    var totaalAantalBesmettingen = landenLijst[0].PromiseValue[PromiseValue.length - 1];

    var totaleBesmettingen = document.getElementById('confirmedInformation');
    totaleBesmettingen.innerHTML = totaalAantalBesmettingen;

  }

  function onAPIError(error) {
    console.error('Oeps, foutje!', error);
    var totaleBesmettingen = document.getElementById('confirmedInformation');
    totaleBesmettingen.innerHTML = 'Please try again. Did you enter a country?';
  }

  document.getElementById('zoek').onclick = function(){
    getAPIdata();
  };</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;body&gt;

      &lt;form&gt;
  			&lt;fieldset&gt;
  				&lt;legend&gt;Choose a country:&lt;/legend&gt;
  				&lt;label for=""country""&gt;Country:&lt;/label&gt;
  				&lt;input type=""text"" name=""country"" id=""country"" placeholder=""For example: Belgium""/&gt;
  				&lt;input type=""button"" id=""zoek"" value=""Search"" /&gt;
  			&lt;/fieldset&gt;
  		&lt;/form&gt;
      &lt;p id=""confirmedInformation""&gt;&lt;/p&gt;
      &lt;p id=""recoveredInformation""&gt;&lt;/p&gt;
      &lt;p id=""deathsInformation""&gt;&lt;/p&gt;

      &lt;p id=""test""&gt;&lt;/p&gt;

  	&lt;/body&gt;</code></pre>
</div>
</div>
</p>

<p>I'm stuck at my code below (which you can find in my JavaScript code). I don't know how to get the specific data from the array. Do you know what I'm doing wrong?</p>

<pre><code>var totaalAantalBesmettingen = landenLijst[0].PromiseValue[PromiseValue.length - 1];
</code></pre>
"
60798979,"<p>I'm making a table with the latest number cases of coronavirus in JavaScript, and I am at a point where I want to create a column that shows how many days it took for the number of confirmCases to double. Here is an example:</p>

<pre><code>{
  ""message"": ""Success"",
  ""source"": ""JHU CSSE"",
  ""sourceURL"": ""https://github.com/CSSEGISandData/2019-nCoV"",
  ""updateDate"": ""2020-03-22T11:08:41.651Z"",
  ""data"": {
    ""3/15/20"": {
      ""Afghanistan"": 16,
      ""Albania"": 42,
      ""Algeria"": 48,
      ""Andorra"": 1,
      ""Angola"": 0,
      ""Antigua and Barbuda"": 1,
      ""Argentina"": 45,
      ""Armenia"": 26,
      ""Australia"": 297,
      ""Austria"": 860,
      ""Azerbaijan"": 23,
      ""Bahamas, The"": 0,
      ""Bahrain"": 214,
      ""Bangladesh"": 5,
      ""Barbados"": 0,
      ""Belarus"": 27,
      ""Belgium"": 886,
      ""Benin"": 0,
      ""Bhutan"": 1,
      ""Bolivia"": 10,
      ""Bosnia and Herzegovina"": 24,
      ""Brazil"": 162,
      ""Brunei"": 50,
      ""Bulgaria"": 51,
      ""Burkina Faso"": 3,
      ""Cabo Verde"": 0,
      ""Cambodia"": 7,
      ""Cameroon"": 2,
      ""Canada"": 252,
      ""Cape Verde"": 0,
      ""Central African Republic"": 1,
      ""Chad"": 0,
      ""Chile"": 74,
      ""China"": 81003,
      ""Colombia"": 34,
      ""Congo (Brazzaville)"": 1,
      ""Congo (Kinshasa)"": 2,
      ""Costa Rica"": 27,
      ""Cote d'Ivoire"": 1,
      ""Croatia"": 49,
      ""Cruise Ship"": 696,
      ""Cuba"": 4,
      ""Cyprus"": 26,
      ""Czechia"": 253,
      ""Denmark"": 875,
      ""Djibouti"": 0,
      ""Dominican Republic"": 11,
      ""East Timor"": 0,
      ""Ecuador"": 28,
      ""Egypt"": 110,
      ""El Salvador"": 0,
      ""Equatorial Guinea"": 1,
      ""Eritrea"": 0,
      ""Estonia"": 171,
      ""Eswatini"": 1,
      ""Ethiopia"": 1,
      ""Fiji"": 0,
      ""Finland"": 244,
      ""France"": 4523,
      ""Gabon"": 1,
      ""Gambia, The"": 0,
      ""Georgia"": 33,
      ""Germany"": 5795,
      ""Ghana"": 6,
      ""Greece"": 331,
      ""Guatemala"": 1,
      ""Guinea"": 1,
      ""Guyana"": 4,
      ""Haiti"": 0,
      ""Holy See"": 1,
      ""Honduras"": 3,
      ""Hungary"": 32,
      ""Iceland"": 171,
      ""India"": 113,
      ""Indonesia"": 117,
      ""Iran"": 13938,
      ""Iraq"": 116,
      ""Ireland"": 129,
      ""Israel"": 251,
      ""Italy"": 24747,
      ""Jamaica"": 10,
      ""Japan"": 839,
      ""Jordan"": 8,
      ""Kazakhstan"": 9,
      ""Kenya"": 3,
      ""Korea, South"": 8162,
      ""Kosovo"": 2,
      ""Kuwait"": 112,
      ""Kyrgyzstan"": 0,
      ""Latvia"": 30,
      ""Lebanon"": 110,
      ""Liberia"": 0,
      ""Liechtenstein"": 4,
      ""Lithuania"": 12,
      ""Luxembourg"": 59,
      ""Madagascar"": 0,
      ""Malaysia"": 428,
      ""Maldives"": 13,
      ""Malta"": 21,
      ""Martinique"": 9,
      ""Mauritania"": 1,
      ""Mauritius"": 0,
      ""Mexico"": 41,
      ""Moldova"": 23,
      ""Monaco"": 2,
      ""Mongolia"": 1,
      ""Montenegro"": 0,
      ""Morocco"": 28,
      ""Namibia"": 2,
      ""Nepal"": 1,
      ""Netherlands"": 1138,
      ""New Zealand"": 8,
      ""Nicaragua"": 0,
      ""Niger"": 0,
      ""Nigeria"": 2,
      ""North Macedonia"": 14,
      ""Norway"": 1221,
      ""Oman"": 22,
      ""Pakistan"": 53,
      ""Panama"": 43,
      ""Papua New Guinea"": 0,
      ""Paraguay"": 6,
      ""Peru"": 43,
      ""Philippines"": 140,
      ""Poland"": 119,
      ""Portugal"": 245,
      ""Qatar"": 401,
      ""Romania"": 131,
      ""Russia"": 63,
      ""Rwanda"": 1,
      ""Saint Lucia"": 2,
      ""Saint Vincent and the Grenadines"": 1,
      ""San Marino"": 101,
      ""Saudi Arabia"": 103,
      ""Senegal"": 24,
      ""Serbia"": 48,
      ""Seychelles"": 2,
      ""Singapore"": 226,
      ""Slovakia"": 54,
      ""Slovenia"": 219,
      ""Somalia"": 0,
      ""South Africa"": 51,
      ""Spain"": 7798,
      ""Sri Lanka"": 18,
      ""Sudan"": 1,
      ""Suriname"": 1,
      ""Sweden"": 1022,
      ""Switzerland"": 2200,
      ""Taiwan*"": 59,
      ""Tanzania"": 0,
      ""Thailand"": 114,
      ""Togo"": 1,
      ""Trinidad and Tobago"": 2,
      ""Tunisia"": 18,
      ""Turkey"": 6,
      ""US"": 3499,
      ""Uganda"": 0,
      ""Ukraine"": 3,
      ""United Arab Emirates"": 98,
      ""United Kingdom"": 1145,
      ""Uruguay"": 4,
      ""Uzbekistan"": 1,
      ""Venezuela"": 10,
      ""Vietnam"": 56,
      ""Zambia"": 0,
      ""Zimbabwe"": 0
    },
    ""3/16/20"": {
      ""Afghanistan"": 21,
      ""Albania"": 51,
      ""Algeria"": 54,
      ""Andorra"": 2,
      ""Angola"": 0,
      ""Antigua and Barbuda"": 1,
      ""Argentina"": 56,
      ""Armenia"": 52,
      ""Australia"": 377,
      ""Austria"": 1018,
      ""Azerbaijan"": 15,
      ""Bahamas, The"": 1,
      ""Bahrain"": 214,
      ""Bangladesh"": 8,
      ""Barbados"": 0,
      ""Belarus"": 36,
      ""Belgium"": 1058,
      ""Benin"": 1,
      ""Bhutan"": 1,
      ""Bolivia"": 11,
      ""Bosnia and Herzegovina"": 25,
      ""Brazil"": 200,
      ""Brunei"": 54,
      ""Bulgaria"": 52,
      ""Burkina Faso"": 15,
      ""Cabo Verde"": 0,
      ""Cambodia"": 7,
      ""Cameroon"": 4,
      ""Canada"": 415,
      ""Cape Verde"": 0,
      ""Central African Republic"": 1,
      ""Chad"": 0,
      ""Chile"": 155,
      ""China"": 81033,
      ""Colombia"": 54,
      ""Congo (Brazzaville)"": 1,
      ""Congo (Kinshasa)"": 2,
      ""Costa Rica"": 35,
      ""Cote d'Ivoire"": 1,
      ""Croatia"": 57,
      ""Cruise Ship"": 696,
      ""Cuba"": 4,
      ""Cyprus"": 33,
      ""Czechia"": 298,
      ""Denmark"": 933,
      ""Djibouti"": 0,
      ""Dominican Republic"": 11,
      ""East Timor"": 0,
      ""Ecuador"": 37,
      ""Egypt"": 150,
      ""El Salvador"": 0,
      ""Equatorial Guinea"": 1,
      ""Eritrea"": 0,
      ""Estonia"": 205,
      ""Eswatini"": 1,
      ""Ethiopia"": 5,
      ""Fiji"": 0,
      ""Finland"": 277,
      ""France"": 6668,
      ""Gabon"": 1,
      ""Gambia, The"": 0,
      ""Georgia"": 33,
      ""Germany"": 7272,
      ""Ghana"": 6,
      ""Greece"": 331,
      ""Guatemala"": 2,
      ""Guinea"": 1,
      ""Guyana"": 4,
      ""Haiti"": 0,
      ""Holy See"": 1,
      ""Honduras"": 6,
      ""Hungary"": 39,
      ""Iceland"": 180,
      ""India"": 119,
      ""Indonesia"": 134,
      ""Iran"": 14991,
      ""Iraq"": 124,
      ""Ireland"": 169,
      ""Israel"": 255,
      ""Italy"": 27980,
      ""Jamaica"": 10,
      ""Japan"": 825,
      ""Jordan"": 17,
      ""Kazakhstan"": 10,
      ""Kenya"": 3,
      ""Korea, South"": 8236,
      ""Kosovo"": 2,
      ""Kuwait"": 123,
      ""Kyrgyzstan"": 0,
      ""Latvia"": 34,
      ""Lebanon"": 99,
      ""Liberia"": 1,
      ""Liechtenstein"": 4,
      ""Lithuania"": 17,
      ""Luxembourg"": 77,
      ""Madagascar"": 0,
      ""Malaysia"": 566,
      ""Maldives"": 13,
      ""Malta"": 30,
      ""Martinique"": 15,
      ""Mauritania"": 1,
      ""Mauritius"": 0,
      ""Mexico"": 53,
      ""Moldova"": 23,
      ""Monaco"": 7,
      ""Mongolia"": 1,
      ""Montenegro"": 0,
      ""Morocco"": 29,
      ""Namibia"": 2,
      ""Nepal"": 1,
      ""Netherlands"": 1416,
      ""New Zealand"": 8,
      ""Nicaragua"": 0,
      ""Niger"": 0,
      ""Nigeria"": 2,
      ""North Macedonia"": 18,
      ""Norway"": 1333,
      ""Oman"": 22,
      ""Pakistan"": 136,
      ""Panama"": 55,
      ""Papua New Guinea"": 0,
      ""Paraguay"": 8,
      ""Peru"": 86,
      ""Philippines"": 142,
      ""Poland"": 177,
      ""Portugal"": 331,
      ""Qatar"": 439,
      ""Romania"": 158,
      ""Russia"": 90,
      ""Rwanda"": 5,
      ""Saint Lucia"": 2,
      ""Saint Vincent and the Grenadines"": 1,
      ""San Marino"": 109,
      ""Saudi Arabia"": 118,
      ""Senegal"": 24,
      ""Serbia"": 55,
      ""Seychelles"": 3,
      ""Singapore"": 243,
      ""Slovakia"": 63,
      ""Slovenia"": 253,
      ""Somalia"": 1,
      ""South Africa"": 62,
      ""Spain"": 9942,
      ""Sri Lanka"": 28,
      ""Sudan"": 1,
      ""Suriname"": 1,
      ""Sweden"": 1103,
      ""Switzerland"": 2200,
      ""Taiwan*"": 67,
      ""Tanzania"": 1,
      ""Thailand"": 147,
      ""Togo"": 1,
      ""Trinidad and Tobago"": 4,
      ""Tunisia"": 20,
      ""Turkey"": 18,
      ""US"": 4632,
      ""Uganda"": 0,
      ""Ukraine"": 7,
      ""United Arab Emirates"": 98,
      ""United Kingdom"": 1551,
      ""Uruguay"": 8,
      ""Uzbekistan"": 6,
      ""Venezuela"": 17,
      ""Vietnam"": 61,
      ""Zambia"": 0,
      ""Zimbabwe"": 0
    },
    ""3/17/20"": {
      ""Afghanistan"": 22,
      ""Albania"": 55,
      ""Algeria"": 60,
      ""Andorra"": 39,
      ""Angola"": 0,
      ""Antigua and Barbuda"": 1,
      ""Argentina"": 68,
      ""Armenia"": 78,
      ""Australia"": 452,
      ""Austria"": 1332,
      ""Azerbaijan"": 28,
      ""Bahamas, The"": 1,
      ""Bahrain"": 228,
      ""Bangladesh"": 10,
      ""Barbados"": 2,
      ""Belarus"": 36,
      ""Belgium"": 1243,
      ""Benin"": 1,
      ""Bhutan"": 1,
      ""Bolivia"": 11,
      ""Bosnia and Herzegovina"": 26,
      ""Brazil"": 321,
      ""Brunei"": 56,
      ""Bulgaria"": 67,
      ""Burkina Faso"": 15,
      ""Cabo Verde"": 0,
      ""Cambodia"": 33,
      ""Cameroon"": 10,
      ""Canada"": 478,
      ""Cape Verde"": 0,
      ""Central African Republic"": 1,
      ""Chad"": 0,
      ""Chile"": 201,
      ""China"": 81058,
      ""Colombia"": 65,
      ""Congo (Brazzaville)"": 1,
      ""Congo (Kinshasa)"": 3,
      ""Costa Rica"": 41,
      ""Cote d'Ivoire"": 5,
      ""Croatia"": 65,
      ""Cruise Ship"": 696,
      ""Cuba"": 5,
      ""Cyprus"": 46,
      ""Czechia"": 396,
      ""Denmark"": 1025,
      ""Djibouti"": 0,
      ""Dominican Republic"": 21,
      ""East Timor"": 0,
      ""Ecuador"": 58,
      ""Egypt"": 196,
      ""El Salvador"": 0,
      ""Equatorial Guinea"": 1,
      ""Eritrea"": 0,
      ""Estonia"": 225,
      ""Eswatini"": 1,
      ""Ethiopia"": 5,
      ""Fiji"": 0,
      ""Finland"": 321,
      ""France"": 7699,
      ""Gabon"": 1,
      ""Gambia, The"": 1,
      ""Georgia"": 34,
      ""Germany"": 9257,
      ""Ghana"": 7,
      ""Greece"": 387,
      ""Guatemala"": 6,
      ""Guinea"": 1,
      ""Guyana"": 7,
      ""Haiti"": 0,
      ""Holy See"": 1,
      ""Honduras"": 8,
      ""Hungary"": 50,
      ""Iceland"": 220,
      ""India"": 142,
      ""Indonesia"": 172,
      ""Iran"": 16169,
      ""Iraq"": 154,
      ""Ireland"": 223,
      ""Israel"": 337,
      ""Italy"": 31506,
      ""Jamaica"": 12,
      ""Japan"": 878,
      ""Jordan"": 34,
      ""Kazakhstan"": 33,
      ""Kenya"": 3,
      ""Korea, South"": 8320,
      ""Kosovo"": 2,
      ""Kuwait"": 130,
      ""Kyrgyzstan"": 0,
      ""Latvia"": 49,
      ""Lebanon"": 120,
      ""Liberia"": 1,
      ""Liechtenstein"": 7,
      ""Lithuania"": 25,
      ""Luxembourg"": 140,
      ""Madagascar"": 0,
      ""Malaysia"": 673,
      ""Maldives"": 13,
      ""Malta"": 38,
      ""Martinique"": 16,
      ""Mauritania"": 1,
      ""Mauritius"": 0,
      ""Mexico"": 82,
      ""Moldova"": 30,
      ""Monaco"": 7,
      ""Mongolia"": 5,
      ""Montenegro"": 2,
      ""Morocco"": 38,
      ""Namibia"": 2,
      ""Nepal"": 1,
      ""Netherlands"": 1711,
      ""New Zealand"": 12,
      ""Nicaragua"": 0,
      ""Niger"": 0,
      ""Nigeria"": 3,
      ""North Macedonia"": 26,
      ""Norway"": 1463,
      ""Oman"": 24,
      ""Pakistan"": 236,
      ""Panama"": 69,
      ""Papua New Guinea"": 0,
      ""Paraguay"": 9,
      ""Peru"": 117,
      ""Philippines"": 187,
      ""Poland"": 238,
      ""Portugal"": 448,
      ""Qatar"": 439,
      ""Romania"": 184,
      ""Russia"": 114,
      ""Rwanda"": 7,
      ""Saint Lucia"": 2,
      ""Saint Vincent and the Grenadines"": 1,
      ""San Marino"": 109,
      ""Saudi Arabia"": 171,
      ""Senegal"": 26,
      ""Serbia"": 65,
      ""Seychelles"": 4,
      ""Singapore"": 266,
      ""Slovakia"": 72,
      ""Slovenia"": 275,
      ""Somalia"": 1,
      ""South Africa"": 62,
      ""Spain"": 11748,
      ""Sri Lanka"": 44,
      ""Sudan"": 1,
      ""Suriname"": 1,
      ""Sweden"": 1190,
      ""Switzerland"": 2700,
      ""Taiwan*"": 77,
      ""Tanzania"": 1,
      ""Thailand"": 177,
      ""Togo"": 1,
      ""Trinidad and Tobago"": 5,
      ""Tunisia"": 24,
      ""Turkey"": 47,
      ""US"": 6421,
      ""Uganda"": 0,
      ""Ukraine"": 14,
      ""United Arab Emirates"": 98,
      ""United Kingdom"": 1960,
      ""Uruguay"": 29,
      ""Uzbekistan"": 10,
      ""Venezuela"": 33,
      ""Vietnam"": 66,
      ""Zambia"": 0,
      ""Zimbabwe"": 0
    },
    ""3/18/20"": {
      ""Afghanistan"": 22,
      ""Albania"": 59,
      ""Algeria"": 74,
      ""Andorra"": 39,
      ""Angola"": 0,
      ""Antigua and Barbuda"": 1,
      ""Argentina"": 79,
      ""Armenia"": 84,
      ""Australia"": 568,
      ""Austria"": 1646,
      ""Azerbaijan"": 28,
      ""Bahamas, The"": 1,
      ""Bahrain"": 256,
      ""Bangladesh"": 14,
      ""Barbados"": 2,
      ""Belarus"": 51,
      ""Belgium"": 1486,
      ""Benin"": 2,
      ""Bhutan"": 1,
      ""Bolivia"": 12,
      ""Bosnia and Herzegovina"": 38,
      ""Brazil"": 372,
      ""Brunei"": 68,
      ""Bulgaria"": 92,
      ""Burkina Faso"": 20,
      ""Cabo Verde"": 0,
      ""Cambodia"": 35,
      ""Cameroon"": 10,
      ""Canada"": 657,
      ""Cape Verde"": 0,
      ""Central African Republic"": 1,
      ""Chad"": 0,
      ""Chile"": 238,
      ""China"": 81102,
      ""Colombia"": 93,
      ""Congo (Brazzaville)"": 1,
      ""Congo (Kinshasa)"": 4,
      ""Costa Rica"": 50,
      ""Cote d'Ivoire"": 6,
      ""Croatia"": 81,
      ""Cruise Ship"": 712,
      ""Cuba"": 7,
      ""Cyprus"": 49,
      ""Czechia"": 464,
      ""Denmark"": 1116,
      ""Djibouti"": 1,
      ""Dominican Republic"": 21,
      ""East Timor"": 0,
      ""Ecuador"": 111,
      ""Egypt"": 196,
      ""El Salvador"": 0,
      ""Equatorial Guinea"": 4,
      ""Eritrea"": 0,
      ""Estonia"": 258,
      ""Eswatini"": 1,
      ""Ethiopia"": 6,
      ""Fiji"": 0,
      ""Finland"": 336,
      ""France"": 9105,
      ""Gabon"": 1,
      ""Gambia, The"": 1,
      ""Georgia"": 38,
      ""Germany"": 12327,
      ""Ghana"": 7,
      ""Greece"": 418,
      ""Guatemala"": 6,
      ""Guinea"": 1,
      ""Guyana"": 7,
      ""Haiti"": 0,
      ""Holy See"": 1,
      ""Honduras"": 9,
      ""Hungary"": 58,
      ""Iceland"": 250,
      ""India"": 156,
      ""Indonesia"": 227,
      ""Iran"": 17361,
      ""Iraq"": 164,
      ""Ireland"": 292,
      ""Israel"": 433,
      ""Italy"": 35713,
      ""Jamaica"": 13,
      ""Japan"": 889,
      ""Jordan"": 52,
      ""Kazakhstan"": 35,
      ""Kenya"": 3,
      ""Korea, South"": 8413,
      ""Kosovo"": 2,
      ""Kuwait"": 142,
      ""Kyrgyzstan"": 3,
      ""Latvia"": 71,
      ""Lebanon"": 133,
      ""Liberia"": 2,
      ""Liechtenstein"": 28,
      ""Lithuania"": 27,
      ""Luxembourg"": 203,
      ""Madagascar"": 0,
      ""Malaysia"": 790,
      ""Maldives"": 13,
      ""Malta"": 38,
      ""Martinique"": 19,
      ""Mauritania"": 1,
      ""Mauritius"": 3,
      ""Mexico"": 93,
      ""Moldova"": 30,
      ""Monaco"": 7,
      ""Mongolia"": 6,
      ""Montenegro"": 1,
      ""Morocco"": 49,
      ""Namibia"": 2,
      ""Nepal"": 1,
      ""Netherlands"": 2058,
      ""New Zealand"": 20,
      ""Nicaragua"": 0,
      ""Niger"": 0,
      ""Nigeria"": 8,
      ""North Macedonia"": 35,
      ""Norway"": 1550,
      ""Oman"": 39,
      ""Pakistan"": 299,
      ""Panama"": 86,
      ""Papua New Guinea"": 0,
      ""Paraguay"": 11,
      ""Peru"": 145,
      ""Philippines"": 202,
      ""Poland"": 251,
      ""Portugal"": 448,
      ""Qatar"": 452,
      ""Romania"": 260,
      ""Russia"": 147,
      ""Rwanda"": 8,
      ""Saint Lucia"": 2,
      ""Saint Vincent and the Grenadines"": 1,
      ""San Marino"": 119,
      ""Saudi Arabia"": 171,
      ""Senegal"": 31,
      ""Serbia"": 83,
      ""Seychelles"": 4,
      ""Singapore"": 313,
      ""Slovakia"": 105,
      ""Slovenia"": 275,
      ""Somalia"": 1,
      ""South Africa"": 116,
      ""Spain"": 13910,
      ""Sri Lanka"": 51,
      ""Sudan"": 2,
      ""Suriname"": 1,
      ""Sweden"": 1279,
      ""Switzerland"": 3028,
      ""Taiwan*"": 100,
      ""Tanzania"": 3,
      ""Thailand"": 212,
      ""Togo"": 1,
      ""Trinidad and Tobago"": 7,
      ""Tunisia"": 29,
      ""Turkey"": 98,
      ""US"": 7783,
      ""Uganda"": 0,
      ""Ukraine"": 14,
      ""United Arab Emirates"": 113,
      ""United Kingdom"": 2642,
      ""Uruguay"": 50,
      ""Uzbekistan"": 15,
      ""Venezuela"": 36,
      ""Vietnam"": 75,
      ""Zambia"": 2,
      ""Zimbabwe"": 0
    },
    ""3/19/20"": {
      ""Afghanistan"": 22,
      ""Albania"": 64,
      ""Algeria"": 87,
      ""Andorra"": 53,
      ""Angola"": 0,
      ""Antigua and Barbuda"": 1,
      ""Argentina"": 97,
      ""Armenia"": 115,
      ""Australia"": 681,
      ""Austria"": 2013,
      ""Azerbaijan"": 44,
      ""Bahamas, The"": 3,
      ""Bahrain"": 278,
      ""Bangladesh"": 17,
      ""Barbados"": 5,
      ""Belarus"": 51,
      ""Belgium"": 1795,
      ""Benin"": 2,
      ""Bhutan"": 1,
      ""Bolivia"": 12,
      ""Bosnia and Herzegovina"": 63,
      ""Brazil"": 621,
      ""Brunei"": 75,
      ""Bulgaria"": 94,
      ""Burkina Faso"": 33,
      ""Cabo Verde"": 0,
      ""Cambodia"": 37,
      ""Cameroon"": 13,
      ""Canada"": 800,
      ""Cape Verde"": 0,
      ""Central African Republic"": 1,
      ""Chad"": 1,
      ""Chile"": 238,
      ""China"": 81156,
      ""Colombia"": 102,
      ""Congo (Brazzaville)"": 3,
      ""Congo (Kinshasa)"": 14,
      ""Costa Rica"": 69,
      ""Cote d'Ivoire"": 9,
      ""Croatia"": 105,
      ""Cruise Ship"": 712,
      ""Cuba"": 11,
      ""Cyprus"": 67,
      ""Czechia"": 694,
      ""Denmark"": 1225,
      ""Djibouti"": 1,
      ""Dominican Republic"": 34,
      ""East Timor"": 0,
      ""Ecuador"": 199,
      ""Egypt"": 256,
      ""El Salvador"": 1,
      ""Equatorial Guinea"": 6,
      ""Eritrea"": 0,
      ""Estonia"": 267,
      ""Eswatini"": 1,
      ""Ethiopia"": 6,
      ""Fiji"": 1,
      ""Finland"": 400,
      ""France"": 10947,
      ""Gabon"": 1,
      ""Gambia, The"": 1,
      ""Georgia"": 40,
      ""Germany"": 15320,
      ""Ghana"": 11,
      ""Greece"": 418,
      ""Guatemala"": 9,
      ""Guinea"": 1,
      ""Guyana"": 7,
      ""Haiti"": 0,
      ""Holy See"": 1,
      ""Honduras"": 12,
      ""Hungary"": 73,
      ""Iceland"": 330,
      ""India"": 194,
      ""Indonesia"": 311,
      ""Iran"": 18407,
      ""Iraq"": 192,
      ""Ireland"": 557,
      ""Israel"": 677,
      ""Italy"": 41035,
      ""Jamaica"": 15,
      ""Japan"": 924,
      ""Jordan"": 69,
      ""Kazakhstan"": 44,
      ""Kenya"": 7,
      ""Korea, South"": 8565,
      ""Kosovo"": 2,
      ""Kuwait"": 148,
      ""Kyrgyzstan"": 3,
      ""Latvia"": 86,
      ""Lebanon"": 157,
      ""Liberia"": 2,
      ""Liechtenstein"": 28,
      ""Lithuania"": 36,
      ""Luxembourg"": 335,
      ""Madagascar"": 0,
      ""Malaysia"": 900,
      ""Maldives"": 13,
      ""Malta"": 53,
      ""Martinique"": 23,
      ""Mauritania"": 2,
      ""Mauritius"": 3,
      ""Mexico"": 118,
      ""Moldova"": 49,
      ""Monaco"": 7,
      ""Mongolia"": 6,
      ""Montenegro"": 3,
      ""Morocco"": 63,
      ""Namibia"": 3,
      ""Nepal"": 1,
      ""Netherlands"": 2467,
      ""New Zealand"": 28,
      ""Nicaragua"": 1,
      ""Niger"": 0,
      ""Nigeria"": 8,
      ""North Macedonia"": 48,
      ""Norway"": 1746,
      ""Oman"": 48,
      ""Pakistan"": 454,
      ""Panama"": 109,
      ""Papua New Guinea"": 0,
      ""Paraguay"": 11,
      ""Peru"": 234,
      ""Philippines"": 217,
      ""Poland"": 355,
      ""Portugal"": 785,
      ""Qatar"": 460,
      ""Romania"": 277,
      ""Russia"": 199,
      ""Rwanda"": 8,
      ""Saint Lucia"": 2,
      ""Saint Vincent and the Grenadines"": 1,
      ""San Marino"": 119,
      ""Saudi Arabia"": 274,
      ""Senegal"": 31,
      ""Serbia"": 103,
      ""Seychelles"": 6,
      ""Singapore"": 345,
      ""Slovakia"": 123,
      ""Slovenia"": 286,
      ""Somalia"": 1,
      ""South Africa"": 150,
      ""Spain"": 17963,
      ""Sri Lanka"": 60,
      ""Sudan"": 2,
      ""Suriname"": 1,
      ""Sweden"": 1439,
      ""Switzerland"": 4075,
      ""Taiwan*"": 108,
      ""Tanzania"": 6,
      ""Thailand"": 272,
      ""Togo"": 1,
      ""Trinidad and Tobago"": 9,
      ""Tunisia"": 39,
      ""Turkey"": 192,
      ""US"": 13677,
      ""Uganda"": 0,
      ""Ukraine"": 16,
      ""United Arab Emirates"": 140,
      ""United Kingdom"": 2716,
      ""Uruguay"": 79,
      ""Uzbekistan"": 23,
      ""Venezuela"": 42,
      ""Vietnam"": 85,
      ""Zambia"": 2,
      ""Zimbabwe"": 0
    },
    ""3/20/20"": {
      ""Afghanistan"": 24,
      ""Albania"": 70,
      ""Algeria"": 90,
      ""Andorra"": 75,
      ""Angola"": 1,
      ""Antigua and Barbuda"": 1,
      ""Argentina"": 128,
      ""Armenia"": 136,
      ""Australia"": 791,
      ""Austria"": 2388,
      ""Azerbaijan"": 44,
      ""Bahamas, The"": 3,
      ""Bahrain"": 285,
      ""Bangladesh"": 20,
      ""Barbados"": 5,
      ""Belarus"": 69,
      ""Belgium"": 2257,
      ""Benin"": 2,
      ""Bhutan"": 2,
      ""Bolivia"": 15,
      ""Bosnia and Herzegovina"": 89,
      ""Brazil"": 793,
      ""Brunei"": 78,
      ""Bulgaria"": 127,
      ""Burkina Faso"": 40,
      ""Cabo Verde"": 1,
      ""Cambodia"": 51,
      ""Cameroon"": 20,
      ""Canada"": 943,
      ""Cape Verde"": 0,
      ""Central African Republic"": 3,
      ""Chad"": 1,
      ""Chile"": 434,
      ""China"": 81250,
      ""Colombia"": 128,
      ""Congo (Brazzaville)"": 3,
      ""Congo (Kinshasa)"": 18,
      ""Costa Rica"": 89,
      ""Cote d'Ivoire"": 9,
      ""Croatia"": 128,
      ""Cruise Ship"": 712,
      ""Cuba"": 16,
      ""Cyprus"": 67,
      ""Czechia"": 833,
      ""Denmark"": 1337,
      ""Djibouti"": 1,
      ""Dominican Republic"": 72,
      ""East Timor"": 0,
      ""Ecuador"": 367,
      ""Egypt"": 285,
      ""El Salvador"": 1,
      ""Equatorial Guinea"": 6,
      ""Eritrea"": 0,
      ""Estonia"": 283,
      ""Eswatini"": 1,
      ""Ethiopia"": 9,
      ""Fiji"": 1,
      ""Finland"": 450,
      ""France"": 12726,
      ""Gabon"": 3,
      ""Gambia, The"": 1,
      ""Georgia"": 43,
      ""Germany"": 19848,
      ""Ghana"": 16,
      ""Greece"": 495,
      ""Guatemala"": 12,
      ""Guinea"": 1,
      ""Guyana"": 7,
      ""Haiti"": 2,
      ""Holy See"": 1,
      ""Honduras"": 24,
      ""Hungary"": 85,
      ""Iceland"": 409,
      ""India"": 244,
      ""Indonesia"": 369,
      ""Iran"": 19644,
      ""Iraq"": 208,
      ""Ireland"": 683,
      ""Israel"": 705,
      ""Italy"": 47021,
      ""Jamaica"": 16,
      ""Japan"": 963,
      ""Jordan"": 85,
      ""Kazakhstan"": 49,
      ""Kenya"": 7,
      ""Korea, South"": 8652,
      ""Kosovo"": 2,
      ""Kuwait"": 159,
      ""Kyrgyzstan"": 6,
      ""Latvia"": 111,
      ""Lebanon"": 163,
      ""Liberia"": 2,
      ""Liechtenstein"": 28,
      ""Lithuania"": 49,
      ""Luxembourg"": 484,
      ""Madagascar"": 3,
      ""Malaysia"": 1030,
      ""Maldives"": 13,
      ""Malta"": 64,
      ""Martinique"": 32,
      ""Mauritania"": 2,
      ""Mauritius"": 12,
      ""Mexico"": 164,
      ""Moldova"": 66,
      ""Monaco"": 11,
      ""Mongolia"": 6,
      ""Montenegro"": 14,
      ""Morocco"": 77,
      ""Namibia"": 3,
      ""Nepal"": 1,
      ""Netherlands"": 3003,
      ""New Zealand"": 39,
      ""Nicaragua"": 1,
      ""Niger"": 1,
      ""Nigeria"": 12,
      ""North Macedonia"": 67,
      ""Norway"": 1914,
      ""Oman"": 48,
      ""Pakistan"": 501,
      ""Panama"": 137,
      ""Papua New Guinea"": 1,
      ""Paraguay"": 13,
      ""Peru"": 234,
      ""Philippines"": 230,
      ""Poland"": 425,
      ""Portugal"": 1020,
      ""Qatar"": 470,
      ""Romania"": 308,
      ""Russia"": 253,
      ""Rwanda"": 17,
      ""Saint Lucia"": 2,
      ""Saint Vincent and the Grenadines"": 1,
      ""San Marino"": 144,
      ""Saudi Arabia"": 344,
      ""Senegal"": 38,
      ""Serbia"": 135,
      ""Seychelles"": 7,
      ""Singapore"": 385,
      ""Slovakia"": 137,
      ""Slovenia"": 341,
      ""Somalia"": 1,
      ""South Africa"": 202,
      ""Spain"": 20410,
      ""Sri Lanka"": 73,
      ""Sudan"": 2,
      ""Suriname"": 4,
      ""Sweden"": 1639,
      ""Switzerland"": 5294,
      ""Taiwan*"": 135,
      ""Tanzania"": 6,
      ""Thailand"": 322,
      ""Togo"": 9,
      ""Trinidad and Tobago"": 9,
      ""Tunisia"": 54,
      ""Turkey"": 359,
      ""US"": 19100,
      ""Uganda"": 0,
      ""Ukraine"": 29,
      ""United Arab Emirates"": 140,
      ""United Kingdom"": 4014,
      ""Uruguay"": 94,
      ""Uzbekistan"": 33,
      ""Venezuela"": 42,
      ""Vietnam"": 91,
      ""Zambia"": 2,
      ""Zimbabwe"": 1
    },
    ""3/21/20"": {
      ""Afghanistan"": 24,
      ""Albania"": 76,
      ""Algeria"": 139,
      ""Andorra"": 88,
      ""Angola"": 2,
      ""Antigua and Barbuda"": 1,
      ""Argentina"": 158,
      ""Armenia"": 160,
      ""Australia"": 1071,
      ""Austria"": 2814,
      ""Azerbaijan"": 53,
      ""Bahamas, The"": 4,
      ""Bahrain"": 305,
      ""Bangladesh"": 25,
      ""Barbados"": 6,
      ""Belarus"": 76,
      ""Belgium"": 2815,
      ""Benin"": 2,
      ""Bhutan"": 2,
      ""Bolivia"": 19,
      ""Bosnia and Herzegovina"": 93,
      ""Brazil"": 1021,
      ""Brunei"": 83,
      ""Bulgaria"": 163,
      ""Burkina Faso"": 64,
      ""Cabo Verde"": 3,
      ""Cambodia"": 53,
      ""Cameroon"": 27,
      ""Canada"": 1278,
      ""Cape Verde"": 1,
      ""Central African Republic"": 3,
      ""Chad"": 1,
      ""Chile"": 537,
      ""China"": 81305,
      ""Colombia"": 196,
      ""Congo (Brazzaville)"": 3,
      ""Congo (Kinshasa)"": 23,
      ""Costa Rica"": 117,
      ""Cote d'Ivoire"": 14,
      ""Croatia"": 206,
      ""Cruise Ship"": 712,
      ""Cuba"": 21,
      ""Cyprus"": 84,
      ""Czechia"": 995,
      ""Denmark"": 1420,
      ""Djibouti"": 1,
      ""Dominican Republic"": 112,
      ""East Timor"": 1,
      ""Ecuador"": 506,
      ""Egypt"": 294,
      ""El Salvador"": 3,
      ""Equatorial Guinea"": 6,
      ""Eritrea"": 1,
      ""Estonia"": 306,
      ""Eswatini"": 1,
      ""Ethiopia"": 9,
      ""Fiji"": 1,
      ""Finland"": 523,
      ""France"": 14431,
      ""Gabon"": 4,
      ""Gambia, The"": 1,
      ""Georgia"": 49,
      ""Germany"": 22213,
      ""Ghana"": 19,
      ""Greece"": 530,
      ""Guatemala"": 17,
      ""Guinea"": 2,
      ""Guyana"": 7,
      ""Haiti"": 2,
      ""Holy See"": 1,
      ""Honduras"": 24,
      ""Hungary"": 103,
      ""Iceland"": 473,
      ""India"": 330,
      ""Indonesia"": 450,
      ""Iran"": 20610,
      ""Iraq"": 214,
      ""Ireland"": 785,
      ""Israel"": 883,
      ""Italy"": 53578,
      ""Jamaica"": 16,
      ""Japan"": 1007,
      ""Jordan"": 85,
      ""Kazakhstan"": 53,
      ""Kenya"": 7,
      ""Korea, South"": 8799,
      ""Kosovo"": 2,
      ""Kuwait"": 176,
      ""Kyrgyzstan"": 14,
      ""Latvia"": 124,
      ""Lebanon"": 187,
      ""Liberia"": 3,
      ""Liechtenstein"": 37,
      ""Lithuania"": 83,
      ""Luxembourg"": 670,
      ""Madagascar"": 3,
      ""Malaysia"": 1183,
      ""Maldives"": 13,
      ""Malta"": 73,
      ""Martinique"": 32,
      ""Mauritania"": 2,
      ""Mauritius"": 14,
      ""Mexico"": 203,
      ""Moldova"": 80,
      ""Monaco"": 11,
      ""Mongolia"": 10,
      ""Montenegro"": 14,
      ""Morocco"": 96,
      ""Namibia"": 3,
      ""Nepal"": 1,
      ""Netherlands"": 3640,
      ""New Zealand"": 52,
      ""Nicaragua"": 2,
      ""Niger"": 1,
      ""Nigeria"": 22,
      ""North Macedonia"": 85,
      ""Norway"": 2118,
      ""Oman"": 52,
      ""Pakistan"": 730,
      ""Panama"": 200,
      ""Papua New Guinea"": 1,
      ""Paraguay"": 18,
      ""Peru"": 318,
      ""Philippines"": 307,
      ""Poland"": 536,
      ""Portugal"": 1280,
      ""Qatar"": 481,
      ""Romania"": 367,
      ""Russia"": 306,
      ""Rwanda"": 17,
      ""Saint Lucia"": 2,
      ""Saint Vincent and the Grenadines"": 1,
      ""San Marino"": 144,
      ""Saudi Arabia"": 392,
      ""Senegal"": 47,
      ""Serbia"": 171,
      ""Seychelles"": 7,
      ""Singapore"": 432,
      ""Slovakia"": 178,
      ""Slovenia"": 383,
      ""Somalia"": 1,
      ""South Africa"": 240,
      ""Spain"": 25374,
      ""Sri Lanka"": 77,
      ""Sudan"": 2,
      ""Suriname"": 4,
      ""Sweden"": 1763,
      ""Switzerland"": 6575,
      ""Taiwan*"": 153,
      ""Tanzania"": 6,
      ""Thailand"": 411,
      ""Togo"": 16,
      ""Trinidad and Tobago"": 49,
      ""Tunisia"": 60,
      ""Turkey"": 670,
      ""US"": 25489,
      ""Uganda"": 1,
      ""Ukraine"": 47,
      ""United Arab Emirates"": 153,
      ""United Kingdom"": 5067,
      ""Uruguay"": 110,
      ""Uzbekistan"": 43,
      ""Venezuela"": 70,
      ""Vietnam"": 94,
      ""Zambia"": 2,
      ""Zimbabwe"": 3
    }
  }
}
</code></pre>

<p>Is it possible for it to return an object where it shows how many days it took for the number of cases in each country to <strong>double</strong> ?</p>
"
61560554,"<p>I am trying to extract nested objects inside a JSON file. The JSON file contains information about Indian <strong>states</strong> and <strong>districts</strong> and looks something like this:-
<a href=""https://api.covid19india.org/state_district_wise.json"" rel=""nofollow noreferrer"">https://api.covid19india.org/state_district_wise.json</a></p>

<pre><code>{
""Haryana"": {
    ""districtData"": {

      ""Ambala"": {
        ""notes"": """",
        ""active"": 2,
        ""confirmed"": 14,
        ""deceased"": 1,
        ""recovered"": 11,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Bhiwani"": {
        ""notes"": """",
        ""active"": 1,
        ""confirmed"": 3,
        ""deceased"": 0,
        ""recovered"": 2,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Charkhi Dadri"": {
        ""notes"": """",
        ""active"": 0,
        ""confirmed"": 1,
        ""deceased"": 0,
        ""recovered"": 1,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Faridabad"": {
        ""notes"": """",
        ""active"": 18,
        ""confirmed"": 61,
        ""deceased"": 1,
        ""recovered"": 42,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Fatehabad"": {
        ""notes"": """",
        ""active"": 0,
        ""confirmed"": 1,
        ""deceased"": 0,
        ""recovered"": 1,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Gurugram"": {
        ""notes"": """",
        ""active"": 19,
        ""confirmed"": 57,
        ""deceased"": 0,
        ""recovered"": 38,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      }
    }

""Maharashtra"": {
    ""districtData"": {
      ""Other States"": {
        ""notes"": ""Cases from other States/UTs"",
        ""active"": 24,
        ""confirmed"": 27,
        ""deceased"": 3,
        ""recovered"": 0,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Ahmednagar"": {
        ""notes"": """",
        ""active"": 17,
        ""confirmed"": 42,
        ""deceased"": 2,
        ""recovered"": 23,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Akola"": {
        ""notes"": """",
        ""active"": 30,
        ""confirmed"": 39,
        ""deceased"": 1,
        ""recovered"": 8,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Amravati"": {
        ""notes"": """",
        ""active"": 17,
        ""confirmed"": 28,
        ""deceased"": 7,
        ""recovered"": 4,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Aurangabad"": {
        ""notes"": """",
        ""active"": 131,
        ""confirmed"": 161,
        ""deceased"": 8,
        ""recovered"": 22,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Bhandara"": {
        ""notes"": """",
        ""active"": 1,
        ""confirmed"": 1,
        ""deceased"": 0,
        ""recovered"": 0,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Beed"": {
        ""notes"": """",
        ""active"": 0,
        ""confirmed"": 1,
        ""deceased"": 0,
        ""recovered"": 1,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Buldhana"": {
        ""notes"": ""Reconciled as per MH bulleting 24/04"",
        ""active"": 1,
        ""confirmed"": 21,
        ""deceased"": 1,
        ""recovered"": 19,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      ""Chandrapur"": {
        ""notes"": """",
        ""active"": 1,
        ""confirmed"": 3,
        ""deceased"": 0,
        ""recovered"": 2,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      }
   }
}
</code></pre>

<p>The above information represents district data objects nested inside state objects(Here district is equivalent of a city). For example, <strong>Haryana</strong> is the state and <strong>Ambala</strong> is a district in Haryana. So there are multiple states and inside each state there are multiple districts. I want to access the <strong>active</strong> and <strong>deceased</strong> objects inside the districts and create an array of all district objects in India which contains information about all the districts which looks like this:-</p>

<pre><code>[
  {
   ""active"":
   ""deceased"":
   ""recovered"":
   ""districtname"":""District-A""
   ""statename"":
  },
  {
   ""active"":
   ""deceased"":
   ""recovered"":
   ""districtname"":""District-B""
   ""statename"":
  },
  {
   ""active"":
   ""deceased"":
   ""recovered"":
   ""districtname"":""District-C""
   ""statename"":
  },
  {
   ""active"":
   ""deceased"":
   ""recovered"":
   ""districtname"":""District-D""
   ""statename"":
  }
]
</code></pre>

<p>I have tried the <code>for...in</code> approach and also tried to convert the inner objects into array but was not able to loop inside properly. Can anyone suggest how to do it?</p>
"
61644376,"<p>I would like to make an onClick event that when I click on a bar it makes a console log, how can I do it? </p>

<pre><code>state = {
    chartData: {
      labels: [],
      datasets: [
        {
          label: 'Covid-19',
          data: [],
          backgroundColor:'red',
          borderColor: 'red',
          hoverBackgroundColor: 'green',
          hoverBorderColor: 'green',
          borderWidth: 4,
          responsive: true,
        }
      ],
    }
  }



&lt;div className=""container""&gt;
    &lt;Bar  data={this.state.chartData}}/&gt;
  &lt;/div&gt;
</code></pre>

<p><a href=""https://i.stack.imgur.com/o7nHE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/o7nHE.png"" alt=""This is my chart built with react-chartjs-2 ""></a></p>
"
60155345,"<p>Every day a new CSV file is added to a GitHub repository. Is there a way to update a google sheets file with the most recent data as soon as the new file is published?</p>

<p>This is what I have tried so far:</p>

<p>in a cell in my google sheets:</p>

<pre><code>=ImportData(""https://raw.githubusercontent.com/CSSEGISandData/2019-nCoV/master/daily_case_updates/02-10-2020_1030.csv"")
</code></pre>

<p>This works as expected, quite perfectly actually, however it only gets data from the specific file in the url. As mentioned, I need to get the most recent one, and changing the url each day is not feasible. </p>
"
60840181,"<p>I am developing a simple Vue application to act as a repository for all things corona-virus in my country. I want to show a map using <a href=""https://vue2-leaflet.netlify.com/"" rel=""nofollow noreferrer"">Vue2-leaflet</a> but i want only my country to appear such as this <a href=""http://aparshin.github.io/leaflet-boundary-canvas/examples/canvas-boundary-providers.html"" rel=""nofollow noreferrer"">example</a>, its exactly what I want but its built using vanilla <a href=""https://leafletjs.com/"" rel=""nofollow noreferrer"">leaflet</a> using <a href=""https://github.com/aparshin/leaflet-boundary-canvas"" rel=""nofollow noreferrer"">leaflet-boundary-canvas</a> which is a leaflet plugin.</p>

<p>I want to basically replicate this <a href=""http://aparshin.github.io/leaflet-boundary-canvas/examples/canvas-boundary-providers.html"" rel=""nofollow noreferrer"">example</a> but built using <a href=""https://vue2-leaflet.netlify.com/"" rel=""nofollow noreferrer"">vue2-leaflet</a></p>

<p>this is my <a href=""https://github.com/Abel-Moremi/covid-info-bw"" rel=""nofollow noreferrer"">repo</a></p>
"
61597165,"<p>I'm really having trouble with D3 and need some help changing my existing barchart to be a grouped barchart The barchart is being used within a tooltip and currently looks like:
<a href=""https://i.stack.imgur.com/r0UZr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/r0UZr.png"" alt=""enter image description here""></a></p>

<p>Each colour represents a sector of industry (pink = retail, teal = groceries...etc).
I need to change the bar chart so that it compares the percentage change in each industry with the world average percentage change in this industry.</p>

<p>At the moment the bar chart is being created from an array of data. I also have an array with the world percentage values.</p>

<p>So imagine:</p>

<p>countryData = [10,-20,-30,-63,-23,20],
worldData = [23,-40,-23,-42,-23,40]</p>

<p>Where index 0 = retail sector, index 1 = grocery sector, etc.</p>

<p>I need to plot a grouped barchart comparing each sector to the world average (show the world average in red). This is a bit tricky to explain so I drew it for you (...excuse the shoddy drawing).</p>

<p><a href=""https://i.stack.imgur.com/XJuBA.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XJuBA.jpg"" alt=""enter image description here""></a></p>

<p>Please can someone help me change my existing tooltip?
Here's the current code. If you want to simulate the data values changing.
If you want to scrap my existing code that's fine.</p>

<pre><code> .on('mouseover', ({ properties }) =&gt; {
        // get county data
        const mobilityData = covid.data[properties[key]] || {};


      const {
        retailAverage,
        groceryAverage,
        parksAverage,
        transitAverage,
        workplaceAverage,
        residentialAverage,
      } = getAverage(covid1);



      let avgArray = [retailAverage, groceryAverage, parksAverage, transitAverage, workplaceAverage, retailAverage];
      let categoriesNames = [""Retail"", ""Grocery"", ""Parks"", ""Transit"", ""Workplaces"", ""Residential""];




        // create tooltip
        div = d3.select('body')
          .append('div')
          .attr('class', 'tooltip')
          .style('opacity', 0);

        div.html(properties[key]);

        div.transition()
          .duration(200)
          .style('opacity', 0.9);

        // calculate bar graph data for tooltip
        const barData = [];

        Object.keys(mobilityData).forEach((industry) =&gt; {
          const stringMinusPercentage = mobilityData[industry].slice(0, -1);
          barData.push(+stringMinusPercentage); // changing it to an integer value, from string
        });

        //combine the two lists for the combined bar graph
        var combinedList = [];
        for(var i = 0; i &lt; barData.length; i++) {
          const stringMinusPercentage2 = +(avgArray[i].slice(0, -1));
          const object = {category: categoriesNames[i], country: barData[i], world: stringMinusPercentage2}
          combinedList.push(object); //Push object into list
        }
        console.log(combinedList);

        // barData = barData.sort(function (a, b) {  return a - b;  });
        // sort into ascending ^ keeping this in case we need it later
        const height2 = 220;
        const width2 = 250;
        const margin = {
          left: 50, right: 10, top: 20, bottom: 15,
        };

        // create bar chart svg
        const svgA = div.append('svg')
          .attr('height', height2)
          .attr('width', width2)
          .style('border', '1px solid')
          .append('g')
        // apply the margins:
          .attr('transform', `translate(${[`${margin.left},${margin.top}`]})`);

        const barWidth = 30; // Width of the bars

        // plot area is height - vertical margins.
        const chartHeight = height2 - margin.top - margin.left;

        // set the scale:
        const yScale = d3.scaleLinear()
          .domain([-100, 100])
          .range([chartHeight, 0]);

        // draw some rectangles:
        svgA
          .selectAll('rect')
          .data(barData)
          .enter()
          .append('rect')
          .attr('x', (d, i) =&gt; i * barWidth)
          .attr('y', (d) =&gt; {
            if (d &lt; 0) {
              return yScale(0); // if the value is under zero, the top of the bar is at yScale(0);
            }

            return yScale(d); // otherwise the rectangle top is above yScale(0) at yScale(d);
          })
          .attr('height', (d) =&gt; Math.abs(yScale(0) - yScale(d))) // the height of the rectangle is the difference between the scale value and yScale(0);
          .attr('width', barWidth)
          .style('fill', (d, i) =&gt; colours[i % 6]) // colour the bars depending on index
          .style('stroke', 'black')
          .style('stroke-width', '1px');

        // Labelling the Y axis
        const yAxis = d3.axisLeft(yScale);
        svgA.append('text')
          .attr('class', 'y label')
          .attr('text-anchor', 'end')
          .attr('x', -15)
          .attr('y', -25)
          .attr('dy', '-.75em')
          .attr('transform', 'rotate(-90)')
          .text('Percentage Change (%)');

        svgA.append('g')
          .call(yAxis);
      })
      .on('mouseout', () =&gt; {
        div.style('opacity', 0);
        div.remove();
      })
      .on('mousemove', () =&gt; div
        .style('top', `${d3.event.pageY - 140}px`)
        .style('left', `${d3.event.pageX + 15}px`));

    svg.append('g')
      .attr('transform', 'translate(25,25)')
      .call(colorLegend, {
        colorScale,
        circleRadius: 10,
        spacing: 30,
        textOffset: 20,
      });

  };

  drawMap(svg1, geoJson1, geoPath1, covid1, key1, 'impact1');
  drawMap(svg2, geoJson2, geoPath2, covid2, key2, 'impact2');
};
</code></pre>
"
61449048,"<p>I would like to make two api call's at once to a ReST API in my vue component. I have done research online and am using this logic:</p>

<pre class=""lang-js prettyprint-override""><code>// Multiple fetches
      Promise.all([
        fetch(
          `https://api.covid19api.com/live/country/${this.selected}/status/confirmed/date/${this.yesterday}`
        ),
        fetch(
          `https://api.covid19api.com/live/country/south-africa/status/confirmed/date/2020-03-21T13:13:30Z`
        )
      ])
        .then(responses =&gt; {
          // Get a JSON object from each of the responses
          return responses.map(response =&gt; {
            return response.json();
          });
        })
        .then(data =&gt; {
          // Log the data to the console
          // You would do something with both sets of data here

          this.coronaVirusStats1 = data[0];
          console.log(this.coronaVirusStats1);
        })
        .catch(function(error) {
          // if there's an error, log it
          console.log(error);
        });
    }
</code></pre>

<p>The consoled value is a promise which I understand but when I look in the Vue devTools under my component I see that coronaVirusStats1 has a value of ""Promise"", not the array of objects I expect back. When I do a single fetch and consume the data variable there is no problem. However I am perplexed as to how one accesses the returned data from fetch calls to multiple endpoints. I tried all the solutions here <a href=""https://stackoverflow.com/questions/54896470/how-to-return-the-promise-all-fetch-api-json-data"">fetching api's</a> ,but none worked. If someone can elucidate on the proper way to access the data from the fetches I would be most appreciative.</p>
"
61191696,"<p>I'm using Google Visualization to plot two charts, one with the central information, and another that I'm using as an overview. The <code>ControlWrapper</code> is used to control the range in the main chart.</p>

<p><a href=""https://i.stack.imgur.com/RFDwH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RFDwH.png"" alt=""enter image description here""></a></p>

<pre><code>function renderChart(data) {

    data = _data_as_array(data['history']);
    data = google.visualization.arrayToDataTable(
        $.merge([['Date', 'Infected', '1st Degree', '2nd Degree']], data),
    );

    var options = {
        hAxis: {textPosition: 'none', gridlines: { color: 'transparent' }, baselineColor: 'transparent'},
        vAxis: {textPosition: 'none', gridlines: { color: 'transparent' }, baselineColor: 'transparent'},
        legend: {position: 'none'},
        backgroundColor: 'transparent',
        series: {
            0: { color: '#6958E5' },
            1: { color: '#747171' },
            2: { color: '#EF8131' }
        },
    };

    var chart = new google.visualization.ChartWrapper({
        chartType: 'AreaChart',
        containerId: 'covidoff-chart',
        options: $.extend({
            chartArea: {
                width: '98%',
                height: '100%'
            }
        }, options)
    });

    var control = new google.visualization.ControlWrapper({
        controlType: 'ChartRangeFilter',
        containerId: 'covidoff-chart-control',
        dataTable: data,
        options: {
            filterColumnIndex: 0, // filter on dates
            ui: {
                chartOptions: {
                    chartArea: {
                        width: '98%',
                        height: '20'
                    }
                },
            },
        },
    });

    var dashboard = new google.visualization.Dashboard(document.getElementById('covidoff-chart-container'));
    dashboard.bind([control], [chart]);
    dashboard.draw(data);
}
</code></pre>

<p>This is the relevant HTML:</p>

<pre><code>&lt;div id=""covidoff-chart-container"" class=""d-none""&gt;
    &lt;div id=""covidoff-chart""&gt;&lt;/div&gt;
    &lt;div id=""covidoff-chart-control""&gt;&lt;/div&gt;
    &lt;div&gt;a&lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p>You can see in the picture above that there's a huge whitespace below the control. That space would be the default height for the control, and setting <code>options.ui.chartOptions.chartArea.height</code> seems to shrink the chart but not the area.</p>

<p>Inspecting the HTML, I see that the tool is injecting this style inline, and giving it a height to <code>200px</code>. </p>

<p><a href=""https://i.stack.imgur.com/XFLAF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/XFLAF.png"" alt=""enter image description here""></a></p>

<p>I'd assume it's reasonable to use CSS to change this, but since I'm not the one managing the elements I'm also thinking it break something, or not always work.</p>

<p>What's the correct way to properly set the height?</p>
"
60583604,"<p>The following</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>$.ajax({
    url: ""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"",
    success: function(csv) {
        const output = Papa.parse(csv, {
          header: true, // Convert rows to Objects using headers as properties
        });
        if (output.data) {
          console.log(output.data);
        } else {
          console.log(output.errors);
        }
    },
    error: function(jqXHR, textStatus, errorThrow){
        console.log(textStatus);
    }
});</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js""&gt;&lt;/script&gt;
&lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.1.0/papaparse.min.js""&gt;&lt;/script&gt;</code></pre>
</div>
</div>
</p>

<p>Gives</p>

<pre><code>[
  {
    ""Province/State"": ""Anhui"",
    ""Country/Region"": ""Mainland China"",
    ""Lat"": ""31.8257"",
    ""Long"": ""117.2264"",
    ""1/22/20"": ""1"",
    ""1/23/20"": ""9"",
    ""1/24/20"": ""15"",
    ""1/25/20"": ""39"",
    ""1/26/20"": ""60"",
    ""1/27/20"": ""70"",
    ""1/28/20"": ""106"",
    ""1/29/20"": ""152"",
    ""1/30/20"": ""200"",
    ""1/31/20"": ""237"",
    ""2/1/20"": ""297"",
    ""2/2/20"": ""340"",
    ""2/3/20"": ""408"",
    ""2/4/20"": ""480"",
    ""2/5/20"": ""530""
  },
  {
    ""Province/State"": ""Beijing"",
    ""Country/Region"": ""Mainland China"",
    ""Lat"": ""40.1824"",
    ""Long"": ""116.4142"",
    ""1/22/20"": ""14"",
    ""1/23/20"": ""22"",
    ""1/24/20"": ""36"",
    ""1/25/20"": ""41"",
    ""1/26/20"": ""68"",
    ""1/27/20"": ""80"",
    ""1/28/20"": ""91"",
</code></pre>

<p>But the dates are single objects that I need and the number next to it too, so I'd need something like</p>

<pre><code>{
  ""Province/State"": ""Beijing"",
  ""Country/Region"": ""Mainland China"",
   ""Lat"": ""40.1824"",
   ""Long"": ""116.4142"",
   ""cases"": [
    {
      ""date"": ""1/28/20"",
       ""people"": ""91"",
      ],
      ""date"": ""1/29/20"",
       ""people"": ""99"",
      ],
      ""date"": ""1/30/20"",
       ""people"": ""101"",
      ],
    },
</code></pre>

<p>Literally I'm looking for a properly formatted json with single objects</p>
"
60584393,"<p>I have an <code>array</code></p>

<pre><code>coords = [];
</code></pre>

<p>Then I run this function</p>

<pre><code>    getVirusData();

    function getVirusData() {
      getAvailableDatasets()
      .then(combineDatasets)
      .then(data =&gt; { // It's asynchronous
        coords.push.apply(coords, data.map(item =&gt; item.Lat +"","" + item.Long));
      });
    }

    function getAvailableDatasets() {
      return $.getJSON('https://api.github.com/repos/CSSEGISandData/COVID-19/contents/csse_covid_19_data/csse_covid_19_time_series')
        .then((files) =&gt; {
          return Promise.all(
            files.filter(file =&gt; /^time_series_19-covid-.+\.csv$/.test(file.name))
            .map(file =&gt; getDataset(file.download_url))
          );
        })
        .catch(function(err) {
          console.log(err);
        })
    }

    function getDataset(url) {
      return $.ajax(url)
        .then(csv =&gt; {
          const output = Papa.parse(csv, {
            header: true, // Convert rows to Objects using headers as properties
            dynamicTyping: true, // Convert some fields to Numbers automatically
          });
          if (output.data) {
            const labelMatches = url.match(/time_series_19-covid-(.+)\.csv$/);
            const label = labelMatches ? labelMatches[1] : ""Untitled"";

            const formatted = output.data.map(area =&gt; {
              const obj = {};

              Object.keys(area).forEach(key =&gt; {
                if (/^\d+\/\d+\/\d+$/.test(key)) {
                  obj[key] = { date: key, [label]: area[key] };
                } else {
                  obj[key] = area[key];
                }
              });

              return obj;
            });



            return formatted;
          } else {
            console.log(output.errors);
          }
        });
    }

    function combineDatasets(datasets) {
      if (datasets.length) {
        const combined = datasets.reduce((result, dataset, i) =&gt; {
          if (i === 0) { return result; }
          dataset.forEach(area =&gt; {
            // Look for area with same coordinates
            let existingArea = result.find(a =&gt; a.Lat === area.Lat &amp;&amp; a.Long === area.Long);
            if (!existingArea) {
              result.push(area);
            } else {
              const dates = Object.keys(area).filter(key =&gt; /^\d+\/\d+\/\d+$/.test(key));
              dates.forEach(date =&gt; existingArea[date] = Object.assign(area[date], existingArea[date]));
            }
          });
          return result;
        }, datasets[0]);

        return combined.map(area =&gt; {
          const obj = { data: [] };

          Object.keys(area).forEach(key =&gt; {
            if (/^\d+\/\d+\/\d+$/.test(key)) {
              obj.data.push(area[key]);
            } else {
              obj[key] = area[key];
            }
          });

          return obj;
        });
      } else {
        throw ""No datasets were found"";
      }
    }
</code></pre>

<p>Then after I have pushed all the values into the array, I need to run this</p>

<pre><code>    drawMarkers();

    function drawMarkers() {
      for (var a = 0; a &lt; coords.length; ++a) {
          var pin = coords[a].split(',');
          var latLng = new google.maps.LatLng(pin[0], pin[1]);
          var marker = new google.maps.Marker({
            position: latLng
          });
       }
      }
</code></pre>

<p>At the moment as I run <code>drawMarkers();</code> I get no markers and if I <code>console.log(pin)</code> after the <code>for loop</code> I get nothing, therefore there must be an <code>asynchronous</code> issue</p>

<p><strong>UPDATE FULL CODE</strong></p>

<pre><code>      (function($) {

        var markers = [],
          circle,
          latitude = [],
          longitude = [],
          datesExternal = [],
          links = [],
          years = [],
          type = [],
          coords = [],
          oggetti = [],
          scuole = [],
          privati = [],
          markerCluster,
          ids = [],
          currentSite = [],
          author = [],
          site = [],
          titles = [];

        var map = new google.maps.Map(document.getElementById('map'), {
          center: {lat: 40.600486, lng: 9.261252},
          zoomControl: true,
          zoom: 2,
          minZoom: 2,
          maxZoom: 18,
          noClear: true,
          zoomControlOptions: {
            position: google.maps.ControlPosition.LEFT_CENTER
          },
          styles: [
                    {
                        ""featureType"": ""administrative"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""simplified""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative"",
                        ""elementType"": ""geometry.fill"",
                        ""stylers"": [
                            {
                                ""visibility"": ""off""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative"",
                        ""elementType"": ""geometry.stroke"",
                        ""stylers"": [
                            {
                                ""weight"": ""1.00""
                            },
                            {
                                ""color"": ""#ffffff""
                            },
                            {
                                ""visibility"": ""off""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative"",
                        ""elementType"": ""labels.text.fill"",
                        ""stylers"": [
                            {
                                ""color"": ""#484848""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative.country"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""simplified""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative.country"",
                        ""elementType"": ""geometry.stroke"",
                        ""stylers"": [
                            {
                                ""visibility"": ""on""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative.country"",
                        ""elementType"": ""labels.text.fill"",
                        ""stylers"": [
                            {
                                ""color"": ""#484848""
                            },
                            {
                                ""visibility"": ""simplified""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative.province"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""simplified""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative.province"",
                        ""elementType"": ""labels.text.fill"",
                        ""stylers"": [
                            {
                                ""color"": ""#484848""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative.locality"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""simplified""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative.neighborhood"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""off""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative.neighborhood"",
                        ""elementType"": ""labels.text.fill"",
                        ""stylers"": [
                            {
                                ""visibility"": ""simplified""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""administrative.land_parcel"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""off""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""landscape"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""color"": ""#e2e2e2""
                            },
                            {
                                ""visibility"": ""simplified""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""landscape"",
                        ""elementType"": ""labels"",
                        ""stylers"": [
                            {
                                ""color"": ""#484848""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""landscape.natural"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""simplified""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""landscape.natural"",
                        ""elementType"": ""labels.text.fill"",
                        ""stylers"": [
                            {
                                ""color"": ""#484848""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""poi"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""off""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""road"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""off""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""road.local"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""simplified""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""transit"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""visibility"": ""off""
                            }
                        ]
                    },
                    {
                        ""featureType"": ""water"",
                        ""elementType"": ""all"",
                        ""stylers"": [
                            {
                                ""color"": ""#ededed""
                            }
                        ]
                    }
                ],
          draggable: true,
          clickable: true,
          streetViewControl: false,
          rotateControl: false,
          fullscreenControl: false,
          scrollwheel: false,
          animatedZoom: false,
          navigationControl: false,
          mapTypeControl: false,
          scaleControl: false
        });


getVirusData();

function getVirusData() {
  getAvailableDatasets()
    .then(combineDatasets)
    .then(data =&gt; { // It's asynchronous
      coords.push.apply(coords, data.map(item =&gt; item.Lat + "","" + item.Long));
    }).then(function(entry) {
      for (var a = 0; a &lt; coords.length; a++) {
        var pin = coords[a].split(',');
        console.log(pin);
        var latLng = new google.maps.LatLng(pin[0], pin[1]);
        var marker = new google.maps.Marker({
          position: latLng
        });
      }
    });
}

function getAvailableDatasets() {
  return $.getJSON('https://api.github.com/repos/CSSEGISandData/COVID-19/contents/csse_covid_19_data/csse_covid_19_time_series')
    .then((files) =&gt; {
      return Promise.all(
        files.filter(file =&gt; /^time_series_19-covid-.+\.csv$/.test(file.name))
        .map(file =&gt; getDataset(file.download_url))
      );
    })
    .catch(function(err) {
      console.log(err);
    })
}

function getDataset(url) {
  return $.ajax(url)
    .then(csv =&gt; {
      const output = Papa.parse(csv, {
        header: true, // Convert rows to Objects using headers as properties
        dynamicTyping: true, // Convert some fields to Numbers automatically
      });
      if (output.data) {
        const labelMatches = url.match(/time_series_19-covid-(.+)\.csv$/);
        const label = labelMatches ? labelMatches[1] : ""Untitled"";

        const formatted = output.data.map(area =&gt; {
          const obj = {};

          Object.keys(area).forEach(key =&gt; {
            if (/^\d+\/\d+\/\d+$/.test(key)) {
              obj[key] = {
                date: key,
                [label]: area[key]
              };
            } else {
              obj[key] = area[key];
            }
          });

          return obj;
        });



        return formatted;
      } else {
        console.log(output.errors);
      }
    });
}

function combineDatasets(datasets) {
  if (datasets.length) {
    const combined = datasets.reduce((result, dataset, i) =&gt; {
      if (i === 0) {
        return result;
      }
      dataset.forEach(area =&gt; {
        // Look for area with same coordinates
        let existingArea = result.find(a =&gt; a.Lat === area.Lat &amp;&amp; a.Long === area.Long);
        if (!existingArea) {
          result.push(area);
        } else {
          const dates = Object.keys(area).filter(key =&gt; /^\d+\/\d+\/\d+$/.test(key));
          dates.forEach(date =&gt; existingArea[date] = Object.assign(area[date], existingArea[date]));
        }
      });
      return result;
    }, datasets[0]);

    return combined.map(area =&gt; {
      const obj = {
        data: []
      };

      Object.keys(area).forEach(key =&gt; {
        if (/^\d+\/\d+\/\d+$/.test(key)) {
          obj.data.push(area[key]);
        } else {
          obj[key] = area[key];
        }
      });

      return obj;
    });
  } else {
    throw ""No datasets were found"";
  }
}
</code></pre>
"
60998210,"<p>I am trying to plot a line chart where the X axes are the dates (see <a href=""https://dudnic.com/covid-19"" rel=""nofollow noreferrer"">this link</a>).</p>

<pre class=""lang-js prettyprint-override""><code>var totalChartOptions = {
    chart : {title : 'Total cases'},
    curveType : 'function',
    legend : {position : 'none'},
    axes : {x : {0 : {side : 'top'}}},
    hAxis : {title : '', format : ""dd/MM""},
    colors : [ 'orange', 'green', 'red' ],
    pointSize : 20,
    pointShape : 'diamond',
}

totalData.addColumn(""date"", ""Date"");
totalData.addColumn(""number"", ""Confirmed"");
totalData.addColumn(""number"", ""Recovered"");
totalData.addColumn(""number"", ""Deaths"");
... foreach (...)
        totalData.addRow([ date, confirmed, recovered, deaths, null ]);
... var chart = new google.charts.Line(totalElement);
chart.draw(totalData, google.charts.Line.convertOptions(vm.totalChartOptions));

</code></pre>

<p>For ""today"", I would like to add a colored area in order to show the data is not yet final.</p>

<p><a href=""https://i.stack.imgur.com/DBiVK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DBiVK.png"" alt=""enter image description here""></a>.</p>

<p>However, I don't want the area be user-interactive(add another chart), just a specific background to the existing one. How do I do that?</p>
"
61411864,"<p>I'm trying to modify a dataviz layout in order to group a <code>rect</code> and a <code>a</code> below a <code>g</code> element. Display works, but when I updated my brush selection everything go to hell as event that should be remove from the canvas are not...</p>

<h3>Layout</h3>

<pre><code>&lt;g class=""zoomed-event"" transform=""translate(276,0)""&gt;
    &lt;rect width=""110"" height=""42""&gt;
    &lt;/rect&gt;
    &lt;a xlink:href=""…"" target=""_blank"" transform=""translate(0, 0)""&gt;
        &lt;text transform=""translate(2,12)"" class=""event-label"" text-anchor=""start""&gt;…&lt;/text&gt;
    &lt;/a&gt;
&lt;/g&gt;
</code></pre>

<h3>Preview</h3>

<p><a href=""https://i.stack.imgur.com/zloM7.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zloM7.gif"" alt=""update and removal fail""></a></p>

<h3>Zoom events code</h3>

<p>The core of the <code>drawZoomedEvents</code> minor helper methods:</p>

<pre><code>  const zoomedEvents = zoomArea
    .selectAll('.zoomed-event')
    .data(visibleEvents, (d) =&gt; d)
    .attr('transform', (d) =&gt; `translate(${xEvent(d)},${y(d)})`)
    .enter()
    .append('g')
    .attr('class', 'zoomed-event')
    .attr('transform', (d) =&gt; `translate(${xEvent(d)},${y(d)})`)

  // eslint-disable-next-line no-unused-vars
  const rects = zoomedEvents
    .insert('rect')
    .attr('width', (d) =&gt; width(d))
    .attr('height', (d) =&gt; yStartPoint(1))
    .attr('style', (d) =&gt; colorize(d.lane))

  // eslint-disable-next-line no-unused-vars
  const links = zoomedEvents
    .insert('a')
    .attr('xlink:href', (d) =&gt; d.url)
    .attr('target', '_blank')
    .attr('transform', (d) =&gt; `translate(${xLink(d)}, 0)`)
    .append('text')
    .text((d) =&gt; title(d))
    .attr('transform', 'translate(2,12)')
    .attr('class', 'event-label')
    .attr('text-anchor', 'start')

  zoomedEvents.exit().remove()

  return zoomedEvents
}
</code></pre>

<h3>Brush</h3>

<p>Not sure that's needed but, I call <code>drawZoomedEvents</code> like this:</p>

<pre><code>const drawBrush = (data, { x, xStartPoint, yStartPoint }, zoomArea) =&gt; {
  const selection = d3.event &amp;&amp; d3.event.selection
  if (!selection) return
  let [selectionStart, selectionEnd] = selection.map(x.invert)
  let visibleEvents = data.filter(
    (event) =&gt; event.end &gt; selectionStart &amp;&amp; event.start &lt; selectionEnd
  )

  xStartPoint.domain([selectionStart, selectionEnd])

  drawZoomedEvents(zoomArea, visibleEvents, {
    xStartPoint,
    yStartPoint,
    selectionStart,
  })
}
</code></pre>

<h3>Code</h3>

<p>Repo is open-source: <a href=""https://github.com/edouard-lopez/coronavirus-policies-timeline/commit/fa61afd631d0848564458f47671acd391ad28513"" rel=""nofollow noreferrer"">coronavirus-policies-timeline</a>, see <a href=""https://github.com/edouard-lopez/coronavirus-policies-timeline/blob/fa61afd631d0848564458f47671acd391ad28513/src/Timeline/ZoomedEvents.js"" rel=""nofollow noreferrer"">ZoomedEvents.js</a> file.</p>
"
61468861,"<p>I have this api I am working from, I would like to make the country (i.e value.slug == china) to be a search item by the user no as I manually type them in the code to get the result of each country. </p>

<p>I want to be able to connect the api with my html form input tag for a user to search for the country themselves. </p>

<p>Here is the code</p>

<pre><code>fetch('https://api.covid19api.com/summary')
        .then(function (response) {
            return response.json();
        })
        .then(function (data) {
            let country = data.Countries.filter((value) =&gt; value.Slug == 'china')
            appendData(country);

        })
        .catch(function (err) {
            console.log(err);
        });
</code></pre>
"
61405842,"<p>I wonder if I could access the data from this table:</p>

<p><a href=""https://public.tableau.com/profile/hans.kristian.o.lorenzana?fbclid=IwAR1NyNmuyihay_-T7qajexzmTHdG2uG38qOsmaqKIu1qRM2UECKItr1os7w#!/vizhome/BianCityCovid19Dashboard_15873861726130/Dashboard1?publish=yes"" rel=""nofollow noreferrer"">https://public.tableau.com/profile/hans.kristian.o.lorenzana?fbclid=IwAR1NyNmuyihay_-T7qajexzmTHdG2uG38qOsmaqKIu1qRM2UECKItr1os7w#!/vizhome/BianCityCovid19Dashboard_15873861726130/Dashboard1?publish=yes</a></p>

<p>and automatically load it on my website using Javascript. How can I retrieve it without going to this website and manually change the data?</p>

<p>Assume that all I need is the data in the table in the far right (the one with ""Barangay"" ""Suspect"" ""Probable"" ""Confirmed"" ""Recovered"" and ""Deceased"").</p>

<p>Here's my javascript:</p>

<pre><code>var langkiwaCases = {
    postiveCase: 0,
    suspect: 0,
    probable: 0,
    recovered: 0,
    deceased: 0
};

  .
  . //name of every variable is the ""barangay""
  .
</code></pre>

<p>How can I access it? Thank you in advance.</p>
"
61143871,"<p>Here is the link for the api - <em><a href=""https://api.rootnet.in/covid19-in/unofficial/covid19india.org/statewise"" rel=""nofollow noreferrer"">https://api.rootnet.in/covid19-in/unofficial/covid19india.org/statewise</a></em></p>

<p>I tried using this Jquery code. I want to retrieve the data of each individual state, for my project but I am unable to access them from the code given below.</p>

<pre><code>$.getJSON('https://api.rootnet.in/covid19-in/unofficial/covid19india.org/statewise', function(data) 
{
    var total_cases = data.total.cases
    var deaths = data.total.deaths
    var recovered = data.total.recovered
    var new_cases = data.total.active
    $("".total_cases"").html(total_cases);
    $("".deaths"").html(deaths);
    $("".recovered"").html(recovered);
    $("".new_cases"").html(new_cases);
});
</code></pre>

<p>My question is about</p>
"
61093806,"<p>I have this json data URL and i want to select only France data to display in html but i don't know how to do. please help me to do that </p>

<p><a href=""https://coronavirus-19-api.herokuapp.com/countries"" rel=""nofollow noreferrer"">https://coronavirus-19-api.herokuapp.com/countries</a></p>

<p>This is my JAVASCRIPT</p>

<pre><code>// API Fetch Call
 const api_url = './src/india.json';
 async function getCcount() {
     const response = await fetch(api_url);
     const data = await response.json();
     const {
         cases,
         active,
         deaths,
         recovered
     } = data;

     document.getElementById('t-count').textContent = cases;
     document.getElementById('a-count').textContent = active;
     document.getElementById('d-count').textContent = deaths;
     document.getElementById('r-count').textContent = recovered;
 }

 getCcount();
</code></pre>

<p>How can i select only France data to display in HTML. Using the fetch function.</p>
"
61337464,"<p>I want to get data from an API only once in a while(say, once every hour) and store it locally and use that data on my website without having to call that api again and again everytime the person refreshes the browser. How can we achieve this. Can we use localStorage for that purpose. If yes then how?</p>

<p>I am using this:</p>

<pre><code>fetch(""https://coronavirus-tracker-api.herokuapp.com/deaths"")
.then(res=&gt;{
  return res.json();
})
.then(data=&gt;{
  localStorage.setItem(""data"",JSON.stringify(data));
  console.log(localStorage.getItem(""data""))
})
</code></pre>

<p>but this would call the api everytime the page reloads. But instead of calling to the api again and again I want to store data in the localstorage and get data to view on the page from there.</p>
"
60883507,"<p>When I try to output this on HTML, it doesn't show the whole output, but one by one country.</p>

<p>I have tried to output it using <code>document.write</code> but it overwrites the whole HTML. How to print all data without replacing all my HTML code? I have also tried other ways to output it using <code>getElementById</code>, <code>innerHTML</code>. None of these worked.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;

&lt;head&gt;
  &lt;link rel=""stylesheet"" href=""https://unpkg.com/onsenui/css/onsenui.css""&gt;
  &lt;link rel=""stylesheet"" href=""https://unpkg.com/onsenui/css/onsen-css-components.min.css""&gt;

  &lt;script src=""https://unpkg.com/onsenui/js/onsenui.min.js""&gt;&lt;/script&gt;
  &lt;script src=""https://code.jquery.com/jquery-3.2.1.min.js""&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body style=""color:silver;""&gt;

  &lt;ons-page&gt;
    &lt;ons-toolbar&gt;
      &lt;div class=""center"" style=""color:#fff; text-shadow: 1px 1px silver; background-color:#E20000;""&gt;CORONA VIRUS TRACKER&lt;/div&gt;
    &lt;/ons-toolbar&gt;

    &lt;ons-tabbar swipeable position=""auto""&gt;
      &lt;ons-tab page=""tab1.html"" label=""Global"" icon=""globe, material:md-home"" active&gt;
      &lt;/ons-tab&gt;
    &lt;/ons-tabbar&gt;
  &lt;/ons-page&gt;

  &lt;template id=""tab1.html""&gt;
  &lt;ons-page id=""Tab1""&gt;
   &lt;div class=""allcountry""&gt;&lt;/div&gt;
  &lt;/ons-page&gt;
&lt;/template&gt;

  &lt;script&gt;
    for (var i = 0; i &lt; 199; i++) {
      (function(i) {
        $.getJSON('https://coronavirus-19-api.herokuapp.com/countries', function(data3) {
          var txt = `&lt;table style=""border-collapse: collapse; font-family: Andale Mono, monospace; border: silver;"" width=""100%"" border=""1""&gt;
        &lt;tr&gt;&lt;td&gt;&lt;div style=""background-color: #EB0D0D; text-transform: uppercase; text-align:center; color:#fff;""&gt;${data3[i].country}&lt;br&gt;&lt;/div&gt;&lt;/td&gt;&lt;/tr&gt;
		
	
	
	
        
                    &lt;tr&gt;&lt;td&gt;&lt;img src=""https://via.placeholder.com/150"" height=""90"" width=""90"" style=""float: left; padding-right: 5px;""&gt;&lt;h5&gt;CONFIRMED CASES&lt;/h5&gt; &lt;h3&gt;${data3[i].cases}&lt;/h3&gt;&lt;/td&gt;&lt;/tr&gt;
                    
                    &lt;tr&gt;&lt;td&gt;&lt;img src=""https://via.placeholder.com/150"" height=""90"" width=""90"" style=""float: left; padding-right: 5px;""&gt;&lt;h5&gt;NEW CASES&lt;/h5&gt; &lt;h3&gt;${data3[i].todayCases}&lt;/h3&gt;&lt;/td&gt;&lt;/tr&gt;
                    
                    &lt;tr&gt;&lt;td&gt;&lt;img src=""https://via.placeholder.com/150"" height=""90"" width=""90"" style=""float: left; padding-right: 5px;""&gt;&lt;h5&gt;DECEASED&lt;/h5&gt; &lt;h3&gt;${data3[i].deaths}&lt;/h3&gt;&lt;/td&gt;&lt;/tr&gt;
                    
                   &lt;tr&gt;&lt;td&gt;&lt;img src=""images/todaydeath.jpg"" height=""90"" width=""90"" style=""float: left; padding-right: 5px;""&gt;&lt;h5&gt;DEATHS TODAY&lt;/h5&gt; &lt;h3&gt;${data3[i].todayDeaths}&lt;/h3&gt;&lt;/td&gt;&lt;/tr&gt;
                   
                   &lt;tr&gt;&lt;td&gt;&lt;img src=""images/recovered.jpg"" height=""90"" width=""90"" style=""float: left; padding-right: 5px;""&gt;&lt;h5&gt;RECOVERED &lt;/h5&gt; &lt;h3&gt;${data3[i].recovered}&lt;/h3&gt;&lt;/td&gt;&lt;/tr&gt;
                   
                   &lt;tr&gt;&lt;td&gt;&lt;img src=""images/active.jpg"" height=""90"" width=""90"" style=""float: left; padding-right: 5px;""&gt;&lt;h5&gt;ACTIVE CASES&lt;/h5&gt; &lt;h3&gt;${data3[i].active}&lt;/h3&gt;&lt;/td&gt;&lt;/tr&gt;
                   
                   &lt;tr&gt;&lt;td&gt;&lt;img src=""images/critical.jpg"" height=""90"" width=""90"" style=""float: left; padding-right: 5px;""&gt;&lt;h5&gt;CRITICAL CONDITION&lt;/h5&gt; &lt;h3&gt;${data3[i].critical}&lt;/h3&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;`

          $("".allcountry"").html(txt);
        })
      })(i);
    }
  &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
</div>
</p>
"
61552369,"<p>I have an HTML website with many subpages, and when I want to update the navigation, I have to copy and paste the <code>&lt;nav&gt;</code> tag 50+ times to different documents. Is there a way I can create ONE html file that holds my nav, and whenever I update that document, it will update the nav on all my pages?</p>

<p>EDIT:</p>

<p>I tried some PHP and couldn't get it to work. What's wrong??</p>

<p>nav.php</p>

<pre><code>&lt;!doctype html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta charset=""utf-8""&gt;
&lt;title&gt;Untitled Document&lt;/title&gt;
&lt;/head&gt;

&lt;body&gt;
    &lt;?php echo ""&lt;img id=""logo"" src=""logo.png"" alt=""logo"" height=""100"" width=""100""&gt;
&lt;a href=""index.html""&gt;&lt;button class=""navbutton""&gt;Home&lt;/button&gt;&lt;/a&gt;
&lt;a href=""about.html""&gt;&lt;button class=""navbutton""&gt;About Me&lt;/button&gt;&lt;/a&gt;
&lt;button onclick=""sixthGrade()"" class=""navbutton""&gt;6th Grade&lt;/button&gt;
&lt;div class=""dropdown""&gt;
    &lt;button class=""dropbtn""&gt;7th Grade&lt;/button&gt;
    &lt;div class=""dropdown-content""&gt;
        &lt;a href=""english7.html""&gt;ELA&lt;/a&gt;
        &lt;a href=""geography.html""&gt;World Geography&lt;/a&gt;
        &lt;a href=""science7.html""&gt;Science&lt;/a&gt;
        &lt;a href=""multimedia.html""&gt;Multimedia&lt;/a&gt;
        &lt;a href=""woods.html""&gt;Woodshop&lt;/a&gt;
        &lt;a href=""algebra1.html""&gt;Algebra 1&lt;/a&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=""dropdown""&gt;
    &lt;button class=""dropbtn""&gt;8th Grade&lt;/button&gt;
    &lt;div class=""dropdown-content""&gt;
        &lt;a href=""multimedia2.html""&gt;Multimedia&lt;/a&gt;
        &lt;a href=""woods2.html""&gt;Woodshop&lt;/a&gt;
        &lt;a href=""amerhistory.html""&gt;American History&lt;/a&gt;
        &lt;a href=""geometry.html""&gt;Geometry&lt;/a&gt;
        &lt;a href=""english8.html""&gt;ELA&lt;/a&gt;
        &lt;a href=""science8.html""&gt;Science&lt;/a&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=""dropdown""&gt;
    &lt;button class=""dropbtn""&gt;9th Grade&lt;/button&gt;
    &lt;div class=""dropdown-content""&gt;
        &lt;a href=""algebra2.html""&gt;Honors Algebra 2&lt;/a&gt;
        &lt;a href=""english9.html""&gt;English 9&lt;/a&gt;
        &lt;a href=""vidprod.html""&gt;Video Production&lt;/a&gt;
        &lt;a href=""webdesign.html""&gt;Web Design&lt;/a&gt;
        &lt;a href=""biology.html""&gt;Biology&lt;/a&gt;
        &lt;a href=""worldhistory.html""&gt;World History&lt;/a&gt;
        &lt;a href=""pltwied.html""&gt;PLTW IED&lt;/a&gt;
        &lt;a href=""photography.html""&gt;Photography&lt;/a&gt;
        &lt;a href=""pe.html""&gt;PE&lt;/a&gt;
        &lt;a href=""hchem.html""&gt;Honors Chemistry&lt;/a&gt;
        &lt;a href=""covid.html""&gt;COVID-19 Blog&lt;/a&gt;
    &lt;/div&gt;
&lt;/div&gt;
&lt;div class=""dropdown""&gt;
    &lt;button class=""dropbtn""&gt;Social&lt;/button&gt;
    &lt;div class=""dropdown-content""&gt;
        &lt;a onclick=""instagram()""&gt;&lt;img class=""social"" src=""instagram.png"" alt=""Instagram logo""&gt;&lt;/a&gt;
        &lt;a onclick=""twitter()""&gt;&lt;img class=""social"" src=""twitter.png"" alt=""Twitter logo""&gt;&lt;/a&gt;
        &lt;a onclick=""youtube()""&gt;&lt;img class=""social"" src=""youtube.png"" alt=""YouTube logo""&gt;&lt;/a&gt;
        &lt;a onclick=""vimeo()""&gt;&lt;img class=""social"" src=""vimeo.png"" alt=""Vimeo logo""&gt;&lt;/a&gt;
    &lt;/div&gt;
  &lt;/div&gt;"";&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>index.php</p>

<pre><code>&lt;!doctype html&gt;
&lt;html&gt;
    &lt;head&gt;
        &lt;meta charset=""utf-8""&gt;
        &lt;link rel=""stylesheet"" href=""alex.css""&gt;
        &lt;title&gt;Alex's Website || Home&lt;/title&gt;
        &lt;link rel=""icon"" href=""favicon.ico"" type=""image/x-icon""&gt;
        &lt;link rel=""shortcut icon"" href=""favicon.ico"" type=""image/x-icon""&gt;
        &lt;meta property=""og:title"" content=""Alex's Website"" /&gt;
        &lt;meta property=""og:image"" content=""splash.jpg"" /&gt;
        &lt;script&gt;
            if (screen.width &lt;= 800) {
                window.location = ""http://m.amgutowski.com"";
            }
        &lt;/script&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;div id=""wrapper""&gt;
            &lt;div id=""content""&gt;
                &lt;nav&gt;
                    &lt;?php include 'nav.php';?&gt;
                &lt;/nav&gt;
                &lt;h2&gt;Welcome To My Website!&lt;/h2&gt;
                &lt;br&gt;
                &lt;p&gt;Welcome to my website. This took me about 3 days to create originally, and I'm still adding to it.
                Feel free to look around, and have fun!&lt;/p&gt;
                &lt;br&gt;
                &lt;footer&gt;
                    Copyright &amp;copy; 2020 Alex Gutowski &lt;br&gt;
                    &lt;a href=""mailto:alexgutowski@gmail.com""&gt;alexgutowski@gmail.com&lt;/a&gt; &lt;br&gt;
                    All Rights Reserved
                &lt;/footer&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/body&gt;
&lt;/html&gt;
</code></pre>
"
60757401,"<p>I'm using matlab to read in <a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">COVID-19 data</a> provided by Johns Hopkins as a <a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">.csv-file</a> using <code>urlread</code>, but I'm not sure how to use <code>textscan</code> in the next step in order to convert the string into a table. The first two columns of the .csv-file are strings specifying the region, followed by a large number of columns containing the registered number of infections by date. </p>

<p>Currently, I just save the string returned by <code>urlread</code> locally and open this file with <code>importdata</code> afterwards, but surely there should be a more elegant solution.</p>
"
60745188,"<p>I want to bulk update list of entries with graphQL  mutation in faunaDB.
The input data is list of coronavirus cases from external source. It will be updated frequently. The mutation should update existing entries if the entry name is present in collectio and create new ones if not present.</p>

<p>Current GRAPHQL MUTATION</p>

<pre><code>mutation UpdateList($data: ListInput!) {
  updateList(id: ""260351229231628818"", data: $data) {
    title
    cities {
      data {
        name
        infected
      }
    }
  }
}
</code></pre>

<p>GRAPHQL VARIABLES</p>

<pre><code>{
  ""data"": {
    ""title"": ""COVID-19"",
    ""cities"": {
      ""create"": [
        {
          ""id"": 22,
          ""name"": ""Warsaw"",
          ""location"": {
            ""create"": {
              ""lat"": 52.229832,
              ""lng"": 21.011689
            }
          },
          ""deaths"": 0,
          ""cured"": 0,
          ""infected"": 37,
          ""type"": ""ACTIVE"",
          ""created_timestamp"": 1583671445,
          ""last_modified_timestamp"": 1584389018
        }
      ]
    }
  }
}
</code></pre>

<p>SCHEMA</p>

<pre><code>type cityEntry {
  id: Int!
  name: String!
  deaths: Int!
  cured: Int!
  infected: Int!
  type: String!
  created_timestamp: Int!
  last_modified_timestamp: Int!
  location: LatLng!
  list: List
}

type LatLng {
  lat: Float!
  lng: Float!
}

type List {
  title: String!
  cities: [cityEntry] @relation
}

type Query {
  items: [cityEntry!]
  allCities: [cityEntry!]
  cityEntriesByDeathFlag(deaths: Int!): [cityEntry!]
  cityEntriesByCuredFlag(cured: Int!): [cityEntry!]
  allLists: [List!]
}
</code></pre>

<p>Everytime the mutation runs it creates new duplicates.
What is the best way to update the list within single mutation?</p>
"
61349428,"<p>I am attempting to unpivot COVID-19 data in Knime with the Unpivoting Node. 
The data available from Johns Hopkins at
<a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19</a>
is wide format where each new day of data is added as a new column.</p>

<p>I can <em>manually</em> make the columns with daily data be rows with the <a href=""https://nodepit.com/node/org.knime.base.node.preproc.unpivot2.Unpivot2NodeFactory"" rel=""nofollow noreferrer"">Unpivoting</a> Node. However, each day I must reconfigure the node to account for the new column. There are 5 unpivoting nodes in my workflow where this must be done.</p>

<p>The Unpivoting Node has an option to use <em>Regex</em> to detect the columns to include or exclude but I am unable to make it work.</p>

<p>The available columns to include/exclude are a handful of field names such as Province/State, Country/Region, Lat, Long, plus the long list of date columns of the format <code>m/d/yy</code> (or <code>m/dd/yy</code> if later in the month). The Johns Hopkins data for the US is similar format but with additional columns for counties, iso codes, etc.</p>

<p>All of the date columns are this year (i.e. 2020). </p>

<ul>
<li>For the top part of the Unpivoting node where Value Columns are
specified, I can do what I need by using the Wildcard setting and the
pattern  <code>*/*/20</code></li>
<li>For the bottom part of the Unpivoting node, I need a wildcard or Regex
expression to specify all the other columns. </li>
</ul>

<p>All the other columns include alphabet characters. None are of the format m/d/yy.
Therefore, some sort of Regex that includes any column with alphabetical column names, or specifies NOT <code>m/d/yy</code> should do the trick.</p>

<p>I tried using <a href=""https://regexr.com/3f4vo"" rel=""nofollow noreferrer""><code>[\s\S]+</code></a> for help writing the Regex but nothing seems to work. I appreciate any help.</p>

<p><a href=""https://i.stack.imgur.com/RUITq.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RUITq.jpg"" alt=""Image is screenshot of unpivot configuration window""></a></p>
"
61161450,"<p>I want to use Apple and Google's new APIs to support Covid contact tracing as desribedin this <a href=""https://covid19-static.cdn-apple.com/applications/covid19/current/static/contact-tracing/pdf/ContactTracing-FrameworkDocumentation.pdf"" rel=""nofollow noreferrer"">API document</a>.  But when I try to use these APIs in XCode, the classes are not found:</p>

<pre><code>let request = CTSelfTracingInfoRequest()
</code></pre>

<p>How do I enable these APIs?</p>
"
71418,"<p>The Covid-19 death data for different countries should reflect how fast the infection spreads through the population and how susceptible the population is.
The total number of deaths after some longer time will depend on the population size but the initial infection rate less so.</p>

<p>For example if the infection starts with one person, then the speed at which it spreads will not depend on population size per se (it will depend on density and connected-ness). </p>

<p>However, in a larger population it is more likely there will be more then one patient zero.
Also after some time the number of new infections slows down because there are fewer not-infected individuals left in a network. In a larger population this mitigating effect will be smaller because there are more networks to infect.</p>

<p>Taking the above into consideration, how should the numbers on covid-19 deaths be corrected for population size?</p>
"
60157685,"<p>Is there a method to get the RAW link to the latest file uploaded in a folder within a GitHub repository?</p>

<p>For example, here is a link (to a specific file):</p>

<pre><code>https://raw.githubusercontent.com/CSSEGISandData/2019-nCoV/master/daily_case_updates/02-10-2020_1030.csv
</code></pre>

<p>Is there a method to get the link to most recent one?</p>
"
61239644,"<p><strong>EDIT:</strong> I added additional information and context <a href=""https://stackoverflow.com/questions/61258211/how-does-one-redistribute-a-calculated-total-across-a-range-of-dates-in-power-bi"">in a new post here</a>.</p>

<p>I am trying to figure out what life after pandemic looks like for my firm.  </p>

<p>We are currently operating at about 20% capacity for shipping orders. It is expected that those orders will return after the pandemic subsides.  </p>

<p>I have a measure that calculates 80% of our backlogged orders. How to add it to the remaining dates of the year in my model? I assume I need to somehow strip the date context and then parse the total out amongst the remaining days...but I don't have the slightest idea how to begin doing that.</p>

<p>I'd like my total to be spread evenly over the next 4 months. Spearing it evenly by an upper limit works, too.  </p>

<p>Any ideas?</p>
"
61427653,"<p>I need to <strong>connect the api ""<a href=""https://coronavirus-19-api.herokuapp.com/countries"" rel=""nofollow noreferrer"">https://coronavirus-19-api.herokuapp.com/countries</a>""</strong> <strong>to google sheets</strong> and want to <strong>update it hourly or as soon as the api page refreshes</strong>. Went through various tutorials but need help in parsing and executing it as a first timer. </p>

<p>Please try and implement by using the above mentioned api link. Thanks in advance!</p>
"
60876169,"<p>How to extract the last update info from this webpage: <a href=""https://coronavirus.health.ny.gov/county-county-breakdown-positive-cases"" rel=""nofollow noreferrer"">https://coronavirus.health.ny.gov/county-county-breakdown-positive-cases</a></p>

<p>I tried </p>

<pre><code>=IMPORTXML(""https://coronavirus.health.ny.gov/county-county-breakdown-positive-cases"",""//div[@class=’wysiwyg--field-webny-wysiwyg-title’]"")
</code></pre>

<p>It didn't work. </p>

<p>Thank you in advance!</p>
"
71639,"<p>Was reading a Washington Post article <a href=""https://www.washingtonpost.com/graphics/2020/world/corona-simulator/?itid=hp_no-name_hp-in-the-news%3Apage%2Fin-the-news"" rel=""nofollow noreferrer"">""Why outbreaks like coronavirus
spread exponentially, and how to flatten the curve”</a> and it looked like they were using Brownian Motion.</p>

<p><em>(Can't directly link the graphic, but it's the third graphic in the article, showing particles bouncing around, but I've included a screenshot:)</em></p>

<p><a href=""https://i.stack.imgur.com/cBFUM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/cBFUM.png"" alt=""enter image description here""></a></p>

<p>If this is the case, how do particles in a fluid medium resemble interactions in a human population?</p>
"
61267380,"<p>I was looking to extract comments made by editors on the Wikipedia talk page along woth editor name and timestamp (e.g., <a href=""https://en.wikipedia.org/wiki/Talk:Coronavirus"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/Talk:Coronavirus</a>). Is there any meaningful way to do this at all? Can the comments be extracted while preserving the tree structure - i.e., whether a comment was in response to another comment.</p>

<p>Thank you!</p>
"
61384403,"<p>I am developing a Whatsapp Bot in Twilio to collect survey data Covid-19 related. However, i want to add complex logic in my program task. For example, i only want to display a question asking if the user is pregnant or not if the user has selected female as her gender. Plus i want to add a range of the questions asking weight and height.</p>

<p>Below is the sample code for my task</p>

<pre><code>    ""actions"": [
        {
            ""say"": ""Thank you for making the time for this survey. Your answers help us improve the service!""
        },
        {
            ""collect"": {
                ""name"": ""csat_answers"",
                ""questions"": [

                    {
                        ""question"": ""Have you completed this survey before??"",
                        ""name"": ""first_time"",
                        ""type"": ""Twilio.YES_NO""
                    },
                    {
                        ""question"": ""Please enter your username"",
                        ""name"": ""usernmae""
                    },
                    {
                        ""question"": ""How old are you?"",
                        ""name"": ""age"",
                        ""type"": ""Twilio.NUMBER""
                    },
                        {
                        ""question"": ""What Gender are you"",
                        ""name"": ""Gender""
                    },
                    {
                        ""question"": ""Are you pregnant?"",
                        ""name"": ""pregnant"",
                        ""type"": ""Twilio.YES_NO""
                    },
                    {
                        ""question"": ""What is your height (cm)?"",
                        ""name"": ""height"",
                        ""type"": ""Twilio.NUMBER""
                    },
                    {
                        ""question"": ""What is your weight (kg)?"",
                        ""name"": ""weight"",
                        ""type"": ""Twilio.NUMBER""
                    }
                ],
                ""on_complete"": {
                    ""redirect"": {
                        ""method"": ""POST"",
                        ""uri"": ""task://complete_survey""
                    }
                }
            }
        }
    ]
}```
</code></pre>
"
61506460,"<p>I'm running API calls to the C3.ai COVID-19 Data Lake in Postman. I'm using Fetch on the Subsequence type, and want to get the isolationSource for the BiologicalAsset that is related to the Subsequence. But I can't figure out how to access this field properly. I'm running POST on <code>https://api.c3.ai/covid/api/1/subsequence/fetch</code>. Here's the request body:</p>

<pre><code>{
    spec: {
        include: ""startIndex, endIndex, sequence, sequence.isolationSource"",
        limit: 10
    }
}
</code></pre>

<p>But then each object in the resulting XML looks like this:</p>

<pre><code>&lt;k&gt;0&lt;/k&gt;
&lt;v&gt;
    &lt;startIndex&gt;1&lt;/startIndex&gt;
    &lt;endIndex&gt;182&lt;/endIndex&gt;
    &lt;id&gt;LC522350_1-182&lt;/id&gt;
    &lt;meta&gt;
        &lt;fetchInclude&gt;[startIndex,endIndex,sequence,id,version]&lt;/fetchInclude&gt;
        &lt;fetchType&gt;Subsequence&lt;/fetchType&gt;
    &lt;/meta&gt;
    &lt;version&gt;1&lt;/version&gt;
&lt;/v&gt;
</code></pre>

<p>This doesn't properly show the sequence or isolation source. How do I find these?</p>
"
61160237,"<p>I have the following data for 1 country for covid-19 data:</p>

<pre><code>{
  ""count"": 29,
  ""result"": [
    // removed for brevity
    {
      ""confirmed"": 6443,
      ""date"": ""2020-04-04"",
      ""deaths"": 373,
      ""recovered"": 205
    },
    {
      ""confirmed"": 6830,
      ""date"": ""2020-04-05"",
      ""deaths"": 401,
      ""recovered"": 205
    },
    {
      ""confirmed"": 7206,
      ""date"": ""2020-04-06"",
      ""deaths"": 477,
      ""recovered"": 205
    },
    {
      ""confirmed"": 7693,
      ""date"": ""2020-04-07"",
      ""deaths"": 591,
      ""recovered"": 205
    },
    {
      ""confirmed"": 8419,
      ""date"": ""2020-04-08"",
      ""deaths"": 687,
      ""recovered"": 205
    },
    {
      ""confirmed"": 9141,
      ""date"": ""2020-04-09"",
      ""deaths"": 793,
      ""recovered"": 205
    },
    {
      ""confirmed"": 9685,
      ""date"": ""2020-04-10"",
      ""deaths"": 870,
      ""recovered"": 381
    }
  ]
}
</code></pre>

<p>I am  plotting a graph for several countries</p>

<p>As each country has different populations, how would I normalise the data to plot a better graph to better compare the rates in different countries.</p>
"
61185661,"<p>What I need is to count the total number of cases on: <code>parent cities</code>, <code>districts</code>, and <code>regions</code></p>

<p><strong>So let me please tell you what the situation is and what I have done so far</strong></p>

<hr>

<p>I have two tables <code>[cities]</code> &amp; <code>[covid19cities]</code></p>

<hr>

<p><strong><em>The [cities] table:</em></strong> 
<em>reference table</em></p>

<p><strong>Structure is:</strong></p>

<pre><code>------------------------------
| id | parent_id | city_name |
------------------------------
</code></pre>

<p><strong>Cities levels is:</strong></p>

<pre><code> - Region          //[its parent_id = 0]
 -- District       //[its parent_id = the region id]
 ---- Parent-city  //[its parent_id = the district id]
 ------ Child-city //[its parent_id = the parent-city id]
</code></pre>

<hr>

<p><strong><em>The [covid19cities] table:</em></strong></p>

<p><strong>Structure is:</strong></p>

<pre><code>-----------------------------------------------------
| id | city_id | date | n_cases | r_cases | d_cases |
-----------------------------------------------------
</code></pre>

<p>So each day we fill <code>[covid19cities]</code> with the different cases in different cities:</p>

<p><code>n_cases</code> = new covid-19 cases; <code>r_cases</code> = recovered cases; <code>d_cases</code> = deceased cases</p>

<hr>

<p><strong>Up to this point:</strong></p>

<ol>
<li><p>I am able to get the sum of cases (e.g. new cases) in each city using query like this:</p>

<pre><code>SELECT  sum(`n_cases`) AS city_n_cases, cities.name AS city_name,
        cities.id AS city_id,
    FROM  covid19cities
    INNER JOIN  cities  ON cities.id = covid19cities.city_id
    WHERE  covid19cities.city_id = '#'
</code></pre>

<ol start=""2"">
<li>I am able to get sum of all cases (e.g. new cases) in all cities:</li>
</ol></li>
</ol>

<pre>
SELECT 
sum(`n_cases`) AS total_n_cases, 
FROM 
covid19cities 
</pre>

<hr>

<p><strong>Now,</strong> what I need is to count the total number of cases on:</p>

<ul>
<li>parent cities</li>
<li>districts</li>
<li>regions</li>
</ul>

<p>So, how can I accomplish that? What I thought about is</p>

<ol>
<li>to find all regions</li>
<li>within the fetch assoc while-loop I search for the districts of the this region</li>
<li>within the fetch assoc while-loop of the districts I search for the parent-cities</li>
<li>within the fetch assoc while-loop of parent cities I search for the children cities</li>
<li>count the sum and then added back-wards to the parent cities and from there to districts and then to regions!</li>
</ol>

<p><strong>BUT</strong> I believe this is not how it should be done.  However, I do not know how to keep tracking parent-children cities in such case.</p>

<p>I appreciate your advice and help.</p>

<p>Thanks</p>

<pre><code>p.s. sorry for my English :/
</code></pre>
"
61535998,"<p>I need to run a custom cron job using a wp function. I tried to follow <a href=""https://wordpress.stackexchange.com/a/216121/26593"">this answer</a> but the piece below is not running.</p>

<p>I need t run <code>wp_remote_get</code> every 5 minutes.</p>

<p>In function.php I do:</p>

<pre><code>$args = array(false);
function schedule_my_cron(){
    wp_schedule_event(time(), '5min', 'my_schedule_hook', $args);
}
if(!wp_next_scheduled('my_schedule_hook',$args)){
    add_action('init', 'schedule_my_cron');
}

function my_schedule_hook() {
  wp_remote_get('https://example.com/wp-content/themes/JikuHealth/scripts/covid-19_global_data.php');
}
</code></pre>

<p><a href=""https://developer.wordpress.org/reference/functions/wp_schedule_event/"" rel=""nofollow noreferrer"">wp docs here</a> but I still don't understand how to.</p>
"
61553229,"<p>Let's say I have this dataframe containing the difference in number of active cases from previous value in each country:</p>

<pre><code>[in]
import pandas as pd
import numpy as np
active_cases = {'Day(s) since outbreak':['0', '1', '2', '3', '4', '5'], 'Australia':[np.NaN, 10, 10, -10, -20, -20], 'Albania':[np.NaN, 20, 0, 15, 0, -20], 'Algeria':[np.NaN, 25, 10, -10, 20, -20]}
df = pd.DataFrame(active_cases)
df

[out]
    Day(s) since outbreak   Australia   Albania     Algeria
0             0                   NaN       NaN         NaN
1             1                  10.0      20.0        25.0
2             2                  10.0       0.0        10.0
3             3                 -10.0      15.0       -10.0
4             4                 -20.0       0.0        20.0
5             5                 -20.0     -20.0       -20.0
</code></pre>

<p>I need to find the average length of days for a local outbreak to peak in this COVID-19 dataframe.</p>

<p>My solution is to find the nth row with the first negative value in each column (e.g., nth row of first negative value in 'Australia': 3, nth row of first negative value in 'Albania': 5) and average it.</p>

<p>However, I have no idea how to do this in Panda/Python.</p>

<p>Are there any ways to perform this task with simple lines of Python/Panda code?</p>
"
61341032,"<p>My dataframe look like this:</p>

<pre><code>times = pd.to_datetime(pd.Series(['2020-08-05','2020-08-12', '2020-08-16', '2020-08-22', '2020-08-30', '2020-09-11', '2020-09-20']))
event = [100, 90, 77, 62, 39, 30, 30]
df = pd.DataFrame({'Active_Covid_Cases': event}, index=times)
</code></pre>

<p>I want to analyse how trend changes week over week.</p>

<p>My expected output should look like: (WW: Work Week)</p>

<pre><code>WW   Active_Case   times
0    100         2020-08-05
1     90         2020-08-12
2     ..         2020-08-19
3     ..         2020-08-26
</code></pre>

<p>WW0 corresponds to the first date (2020-08-05) and thus, WW1 would be 2020-08-12 and so on...</p>

<p>I am doing resampling using:  <code>df2 = df.resample('W')</code>  But, what more to add to get into Work week format???</p>
"
61335097,"<p>I was looking at <a href=""https://www.apple.com/covid19/mobility"" rel=""nofollow noreferrer"">Apple Mobility Trends Reports</a> and I have a question on how to put all the dates in one column called ""Dates"", where each date is a value in the column ""Dates"". My plan is to set this column as the index for the DataFrame.</p>

<p>Thank you for the help!</p>
"
61266186,"<p>I am building a google dialogflow chatbot for COVID-19 data. I have created a intent which will call a webhook service. This service is a python flask app which is gathering data &amp; processing the data. My use case is the user will ask for details of a locality. I am creating an image (.png file) in my flask app. But how can I return it back to dialogflow?. Till now, it accepts images that have a public URL. But in my case, I don't have a public URL. each image is dynamic in nature based on user input. Can anyone help how I can achieve this? Any help appreciated. Let me know any details.</p>
"
61199044,"<p>I am making some fetch API calls to the C3.ai COVID-19 datalake. How best can I convert that to a csv for easier reading? For reference, I am running the sample code below:</p>

<pre><code>import requests, json

url = ""https://api.c3.ai/covid/api/1/outbreaklocation/fetch/""

request_data = {
    ""spec"": {
        ""include"": ""id,name,population2018"",
        ""limit"": 500
    }
}
headers = {
    ""Accept"": ""application/json"",
    ""Content-Type"": ""application/json""
}

response = requests.post(url=url, json=request_data, headers=headers)

fetch_object = json.loads(response.text)
</code></pre>

<p><code>fetch_object</code> is now a python <code>dict</code>. But I would like to convert it to a csv. How do I do that generically? I could fetch one or more fields, as specified in the <code>include</code> field in the <code>spec</code> argument.</p>
"
60976869,"<p>This is my file text:</p>

<pre><code>Covid-19 Data
Country / Number of infections / Number of Death
USA  124.356  2.236
Netherlands  10.866  771
Georgia  90  NA
Germany  58.247  455
</code></pre>

<p>I created a function to calculate the ratio of deaths compared to the infections, however it does not work, because some of the values aren't floats. </p>

<pre><code>f=open(""myfile.txt"",""w+"")

x=""USA"" + "" "" + "" "" + ""124.356"" + "" "" + "" "" + ""2.236""
y=""Netherlands"" + "" "" + "" "" + ""10.866"" + "" "" + "" "" + ""771""
z=""Georgia"" + "" "" + "" "" + ""90"" + "" "" + "" "" + ""NA""
w=""Germany"" + "" "" + "" "" + ""58.247"" + "" "" + "" "" + ""455""

f.write(""Covid-19 Data"" + ""\n"" + ""Country"" + "" "" + ""/"" + "" "" + ""Number of infections"" + "" ""  + ""/"" + "" "" + ""Number of Death"" + ""\n"")
f.write(x + ""\n"")
f.write(y + ""\n"")
f.write(z + ""\n"")
f.write(w)

f.close()

with open(""myfile.txt"", ""r"") as file:


        try:
            for i in file:
                t = i.split()
                    result=float(t[-1])/float(t[-2])
                    print(results)
        except:
            print(""fail"")
        file.close()
</code></pre>

<p>Does someone have an idea how to solve this problem ? </p>
"
60917038,"<p>I would like filter two or more countries in this dataframe, but I don't know how. </p>

<p><a href=""https://i.stack.imgur.com/fEEXp.png"" rel=""nofollow noreferrer"">image</a></p>

<pre><code>covid.filter(items = [ 'Country', 'Confirmed', 'Deaths'] ).where(covid.Country == 'Canada').groupby('Country').max()
</code></pre>
"
60908301,"<p>Let me try to explain to the best of my ability as I am not a Python wizard. I have read with PyPDF2 a PDF table of data regarding covid-19 in Mexico and tokenize it—long story, I tried doing it with tabula but did not get the format I was expecting and I was going to spend more time reformatting the CSV document I have gotten back than analyzing it—and have gotten a list of strings back with len of 16792 which is fine. </p>

<p>Now, the problem I am facing is that I need to format it in the appropriate way by concatenating some (not all) of those strings together so I can create a list of lists with the same length which is 9 columns. </p>

<p>This is an example of how it looks right now, the columns are Case number, State, Locality, Gender, Age, Date when symptoms started, Status, Type of contagion, Date of arrival to Mexico:</p>

<pre><code>['1', 'PUEBLA', 'PUEBLA', 'M', '49', '15/03/2020', 'Sospechoso', 'Contacto', 'NA', '2', 'GUERRERO', 'ZONA', 'NORTE', 'M', '29', '15/03/2020', 'Sospechoso', 'Contacto', 'NA', '3', 'BAJA', 'CALIFORNIA', 'TIJUANA', 'F', '34', '14/03/2020', 'Sospechoso', 'Estados', 'Unidos', '08/03/2020', '4', 'CIUDAD', 'DE', 'MÉXICO', 'TLALPAN', 'F', '69', '25/02/2020', 'Sospechoso', 'Italia', '03/03/2020', '5', 'JALISCO', 'CENTRO', 'GUADALAJARA', 'M', '19', '18/03/2020', 'Sospechoso', 'España', '17/03/2020'
</code></pre>

<p>What I would want is to get certain strings like 'ZONA', 'NORTE' as 'ZONA NORTE' or 'CIUDAD', 'DE', 'MEXICO' as 'CIUDAD DE MEXICO' or 'ESTADOS', 'UNIDOS' as 'ESTADOS UNIDOS'... </p>

<p>I seriously do not know how to tackle this. I have tried, split(), replace(), trying to find the index of each frequency, read all questions about manipulating lists, tried almost all the responses provided... and haven't been able to do it. </p>

<p>Any guidance, will be greatly appreciated. Sorry if this is a very basic question, but I know there has to be a way, I just don't know it. </p>
"
61133792,"<p>I created a coronavirus simulation and I wanted to refresh everything to the beginning each time I click the screen. I would greatly appreciate your help if you could help me. Thank you!</p>

<p>My code:</p>

<pre><code>x= [ ]
y= [ ]
h= [False, True] #False=&gt; infected
infected=1
healthy=24
runs=0

def setup():
    size(500,500)

    #Setting up the ... random coordinates
    for i in range(25):
        x.append(random(0,500))
        y.append(random(0,500))
        h.append(True) #All healthy, h is health
    textSize(12);

def distance(x1, x2, y1, y2):
    a=(x1-x2)
    b=(y1-y2)        
    c= sqrt(a**2 + b**2)
    return c



def draw():
    global x, y, infected, healthy
    background(255)


      #Drawing the individuals
    for individuals in range(len(x)):
        strokeWeight(2)
        if h[individuals] == True:
            fill(255)  #healthy
        else:
            fill(255,0,0)  #infected

        circle(x[individuals], y[individuals], 40)
        #calulate the distance to each neighbors
        for neighbors in range(len(x)):
            if neighbors == individuals:
                continue
            d = distance(x[individuals], x[neighbors], y[individuals], y[neighbors])
            if d &lt; 40 and (h[neighbors] == False or h[individuals]==False) and (h[individuals] == True or h[neighbors] == True):
                #infection happens
                h[individuals] = False
                h[neighbors] = False
                infected = infected + 1
                healthy = healthy -1
                if healthy &lt;0:
                    healthy=0
                if infected &gt;25:
                    infected=25   #Need to put infected, healthy stuff in another if statement







    for m in range(len(x)):
        x[m]= x[m] + random(-10,10)
        y[m]= y[m] + random(-10,10)    
        if x[m] &gt; 500:
                x[m] = 500

        if y[m] &gt; 500:
                    y[m] = 500
        if x[m] &lt; 0:
                    x[m] = 0
        if y[m] &lt; 0:
                    y[m] = 0
    barGraph()        
    delay(100)


def barGraph():
    global infected, healthy, runs
    strokeWeight(1)
    fill(255,0,0)
    rect(60, 10, infected, 10) #(x coordinate, y coordinate, width, height)
    fill(3,3,3)
    text('Infected', 10,20)
    text(infected, 180,20)
    strokeWeight(1)
    fill(255)
    rect(60, 30, healthy, 10)
    fill(3,3,3)
    text('Healthy', 10,40)
    text(healthy, 180, 35)
    text('Click screen to run the simulation again', 10, 60)
    text('Iteration # :', 10,80 )
    text(runs, 120,80)
</code></pre>

<p>P/s. This is what I had been trying so far for the code to refresh:</p>

<pre><code>def mouseClicked():
    global infected, healthy, x
    infected=1
    healthy=24
    for individuals in range(len(x)-1):
        strokeWeight(2)
        if h[individuals] == True:
            fill(255)  #healthy
            circle(x[individuals], y[individuals], 40)
    for individuals in range(1):
        strokeWeight(2)
        fill(255,0,0)  #infected
        circle(x[individuals], y[individuals], 40)
</code></pre>

<p>However, it only refresh the bar graphs, not the circles. It should refresh so that in the beginning, there will be 1 red infected circle, the other 24 circles are white and healthy.</p>
"
60799906,"<p>This is my first question on Stack overflow and I have been searching extensively for similar Q&amp;A without success yet.</p>

<p>I am working with the <a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">Covid dataset</a> and try to produce a chart without date timeline but with a count of days since the 100th case, <a href=""https://i.stack.imgur.com/BzWUu.jpg"" rel=""nofollow noreferrer"">similar to this one</a></p>

<p>To do so I am looking for a code allowing me to shift the row content over the column(s) with 0 for each row:
<a href=""https://i.stack.imgur.com/R2ONn.jpg"" rel=""nofollow noreferrer"">illustration</a></p>

<p><strong>Problem:</strong> I thought of using DropNa here but it would delete columns where other rows would have an actual number... Any suggestions ?</p>

<p>Many thanks in advance</p>
"
60860946,"<p>this is the code to extract the html data from the class where my data is located. but how do i extract the required data(<strong>the state wise data</strong>) as it is not given in order
<a href=""https://www.mohfw.gov.in/"" rel=""nofollow noreferrer"">website</a></p>

<pre><code>import requests
import cloudscraper
from bs4 import BeautifulSoup
import re
import pandas as pd
import time
import datetime
scraper = cloudscraper.create_scraper()
html = scraper.get(""https://www.mohfw.gov.in/"").text
data = BeautifulSoup(html, 'html.parser')
li=data.find_all(class_='table-responsive')
li
</code></pre>
"
61084070,"<p>Protect Shield seems to be a anti-DDoS service that is preventing me accessing the page I need to extract information from.  Is there anyway to get past this? I really can't find any information on how to get through.  The page is perfectly fine to view on a web browser and is a public free source of information.</p>

<pre><code>import requests
from bs4 import BeautifulSoup as BS4
# Latest news info 
headers = {'User-Agent': 'Mozilla/5.0'}
url = 'https://www.thelocal.it/20200308/should-you-be-concerned-about-the-coronavirus-in-italy'
page = requests.get(url, headers=headers)
print(page.text)

soup = BS4(page.text, 'html.parser')
print(soup.prettify())
</code></pre>

<p>This is the html part of the output where is mentions only the Project Shield.  When I open it up in a browser it automatically forwards from this part to the page that I need.  But when I try and access the same url with a script I get stuck here and I'm not sure how I can proceed.</p>

<pre><code>&lt;html&gt;
 &lt;body&gt;
  &lt;div style=""position:absolute;top:100px;text-align:center;margin-left:auto;margin-right:auto;left:0;right:0;width:500px;font-family:Roboto,sans-serif;""&gt;
   &lt;img alt=""Project Shield Logo"" height=""50px"" src=""https://storage.googleapis.com/ddos-shield.appspot.com/shield-logo-mono-darktext.svg"" width=""250px""/&gt;
   &lt;p style=""font-size:18px;""&gt;
    You will be connected to
    &lt;b&gt;
     www.thelocal.it
    &lt;/b&gt;
    in just a moment...
   &lt;/p&gt;
   &lt;p&gt;
    &lt;a href=""https://g.co/shield""&gt;
     Learn about Project Shield
    &lt;/a&gt;
   &lt;/p&gt;
  &lt;/div&gt;
  &lt;script src=""https://storage.googleapis.com/ddos-shield.appspot.com/aes.js"" type=""text/javascript""&gt;
  &lt;/script&gt;
  &lt;script&gt;
   function toNumbers(d){var e=[];d.replace(/(..)/g,function(d){e.push(parseInt(d,16))});return e;}function toHex(){for(var d=[],d=1==arguments.length&amp;&amp;arguments[0].constructor==Array?arguments[0]:arguments,e="""",f=0;f&lt;d.length;f++)e+=(16&gt;d[f]?""0"":"""")+d[f].toString(16);return e.toLowerCase()}var a=toNumbers(""7dd3398871bb335e2cfcbae515405ebc""),b=toNumbers(""254cce1703f77e225de62ca842f05921""),c=toNumbers(""60ae5ab2c50fe6711bb47ab811836a49"");document.cookie=""STC=""+toHex(slowAES.decrypt(c,2,a,b))+""; expires=Thu, 31-Dec-37 23:55:55 GMT; domain=.thelocal.it; path=/"";location.href=""https://www.thelocal.it/20200308/should-you-be-concerned-about-the-coronavirus-in-italy?sckattempt=1"".replace(new RegExp(""sckattempt=[0-9]\&amp;""), """").replace(new RegExp(""[?&amp;]sckattempt=[0-9]""), """");
  &lt;/script&gt;
 &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>Any help or advice would be appreciated.  Thank you.</p>
"
61583856,"<p>I am trying to build a synonym token filter with ElasticSearch-dsl in python that for example when I try to search ""tiny"" or ""little"", it will also return the articles including ""small"".
Here is my code:</p>

<pre><code>from elasticsearch_dsl import token_filter

# Connect to local host server
connections.create_connection(hosts=['127.0.0.1'])

spelling_tokenfilter = token_filter(
    'my_tokenfilter', # Name for the filter
    'synonym', # Synonym filter type
    synonyms_path = ""analysis/wn_s.pl""
    )

# Create elasticsearch object
es = Elasticsearch()

text_analyzer = analyzer('my_tokenfilter',
                         type='custom',
                         tokenizer='standard',
                         filter=['lowercase', 'stop', spelling_tokenfilter])
</code></pre>

<p>I created a folder in es-7.6.2/config named 'analysis' and downloaded the Wordnet prolog database and copy and paste 'wn_s.pl' into it. But when I run the program, there's an error:</p>

<pre><code>Traceback (most recent call last):
  File ""index.py"", line 161, in &lt;module&gt;
    main()
  File ""index.py"", line 156, in main
    buildIndex()
  File ""index.py"", line 74, in buildIndex
    covid_index.create()
  File ""C:\Anaconda\lib\site-packages\elasticsearch_dsl\index.py"", line 259, in create
    return self._get_connection(using).indices.create(index=self._name, body=self.to_dict(), **kwargs)
  File ""C:\Anaconda\lib\site-packages\elasticsearch\client\utils.py"", line 92, in _wrapped
    return func(*args, params=params, headers=headers, **kwargs)
  File ""C:\Anaconda\lib\site-packages\elasticsearch\client\indices.py"", line 104, in create
    ""PUT"", _make_path(index), params=params, headers=headers, body=body
  File ""C:\Anaconda\lib\site-packages\elasticsearch\transport.py"", line 362, in perform_request
    timeout=timeout,
  File ""C:\Anaconda\lib\site-packages\elasticsearch\connection\http_urllib3.py"", line 248, in perform_request
    self._raise_error(response.status, raw_data)
  File ""C:\Anaconda\lib\site-packages\elasticsearch\connection\base.py"", line 244, in _raise_error
    status_code, error_message, additional_info
elasticsearch.exceptions.RequestError: RequestError(400, 'illegal_argument_exception', 'failed to build synonyms')
</code></pre>

<p>Anybody knows how to fix it?
Thanks!</p>
"
61152242,"<p>I am trying to obtain the COVID-19 data present in different worksheets of the following google sheet. The g-sheet being open for public usage, the URL only returns the first worksheet only.I want to scrape all the worksheets.Can any one help. Here's the google sheet link:</p>

<p><a href=""https://docs.google.com/spreadsheets/d/e/2PACX-1vSc_2y5N0I67wDU38DjDh35IZSIS30rQf7_NYZhtYYGU1jJYT6_kDx4YpF-qw0LSlGsBYP8pqM_a1Pd/pubhtml"" rel=""nofollow noreferrer"">https://docs.google.com/spreadsheets/d/e/2PACX-1vSc_2y5N0I67wDU38DjDh35IZSIS30rQf7_NYZhtYYGU1jJYT6_kDx4YpF-qw0LSlGsBYP8pqM_a1Pd/pubhtml</a></p>
"
61215372,"<p>I'm trying to pull the href and the data-promoname from the </p>

<blockquote>
  <p>URL: 
  <a href=""https://www2.deloitte.com/global/en/pages/about-deloitte/topics/combating-covid-19-with-resilience.html?icid=covid-19_article-nav"" rel=""nofollow noreferrer"">https://www2.deloitte.com/global/en/pages/about-deloitte/topics/combating-covid-19-with-resilience.html?icid=covid-19_article-nav</a></p>
</blockquote>

<p><a href=""https://i.stack.imgur.com/DwVek.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DwVek.png"" alt=""enter image description here""></a></p>

<p>I tried the code below but can only extract href under the class ""promo-focus"", but I also want to get the <code>COVID-19 Economic cases: Scenarios for business leaders</code> from <code>data-promoname</code></p>

<pre><code>driver = webdriver.Chrome(executable_path=r'C:\chromedriver.exe')
url = ""https://www2.deloitte.com/global/en/pages/about-deloitte/topics/combating-covid-19-with-resilience.html?icid=covid-19_article-nav""
driver.get(url)

for i in driver.find_elements_by_class_name('promo-focus'):
    print(i.get_attribute('href'))
</code></pre>

<p>Can anyone tell me how to do that using Python?</p>
"
61235160,"<p>Web URL: <a href=""https://www.ipsos.com/en-us/knowledge/society/covid19-research-in-uncertain-times"" rel=""nofollow noreferrer"">https://www.ipsos.com/en-us/knowledge/society/covid19-research-in-uncertain-times</a></p>

<p>Hi folks, I want to parse the HTML as below:</p>

<p><a href=""https://i.stack.imgur.com/5lcFR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5lcFR.png"" alt=""enter image description here""></a></p>

<p>I want to get all hrefs within the &lt; li > elements and the highlighted text. I tried the code </p>

<pre><code>elementList = driver.find_element_by_class_name('block-wysiwyg').find_elements_by_tag_name(""li"")
for i in range(len(elementList)):
    driver.find_element_by_class_name('blcokwysiwyg').find_elements_by_tag_name(""li"").get_attribute(""href"")
</code></pre>

<p>But the block returned none.</p>

<p>Can anyone please help me with the above code? Thank you for the help!</p>
"
61125123,"<p>I have prepared a time series model using FB Prophet for making forecasts. The model forecasts for the coming 30 days and my data ranges from Jan 2019 until Mar 2020 both months inclusive with all the dates filled in. The model has been built specifically for the UK market</p>

<p>I have already taken care of the following:</p>

<ol>
<li>Seasonality</li>
<li>Holidaying Effect</li>
</ol>

<p>My question is, that how do I take care of the current COVID-19 situation into the same model? The cases that I am trying to forecast are also dependent on the previous data at least from Jan 2020. So in order to forecast I need to take into account the current coronavirus situation as well that would impact my forecasts apart from seasonality and holidaying effect.</p>

<p>How should I achieve this?</p>
"
60576809,"<p>I was attempting to create a quiz and one of the criteria is to limit the time available to solve for each question in the quiz. I looked up certain tutorials but some require an input of x seconds for the timer to go off while others looked more like a stopwatch...</p>

<p>I was wondering how do I do like a background timer that ticks down as soon as the question is printed out and skips to the next question if, for example the 30-second period has ended? I'm clueless in the timer function and was having problems to even try to implement them onto my codes. Could someone give out a few pointers so I can sorta progress further in implementing a working timer?</p>

<p>Thank you!</p>

<p>EDITED section below:
The timer that I want to implement onto my coding:</p>

<pre><code>import time
import threading

def atimer():
    print(""Time's up."")

a_timer = threading.Timer(10.0, atimer)
a_timer.start()
print("""")
</code></pre>

<p>This is the whole coding that I tried to implement the timer into.
I noticed that when I tried to define <strong>qtimer</strong> to just print 1 or 2 lines of statements the timer works but I want the timer to stop and go to second question or stop and give the user another attempt to retry the question, so I tried to attach a bunch of codes after the definition and it didn't work. I know I'm most probably doing something wrong here since I'm not quite familiar with time or threading functions. Is there a workaround?</p>

<pre><code>def qtimer():
    print(""I'm sorry but your time is up for this question."")
    print(""You may have another attempt if you wish to, with reduced marks allocated."")
    response1 = input(""Type 'Yes' for another attempt, anything else to skip: "")
    if response1 == ""Yes"":
        Answ = input(""Which option would you go for this time?: "")
        Answ = int(Answ)
        if possible[Answ - 1] == qaItem.corrAnsw:
            print(""Your answer was correct."")
            corr += 1
            marks += 0.5 * qaItem.diff
        else:
            print(""Your answer was wrong."")
            print(""Correct answer was: "" + qaItem.corrAnsw)
            print(""Explanation: "" + qaItem.expl)
            print("""")
    else:
        print(""Correct answer was: "" + qaItem.corrAnsw)
        print(""Explanation: "" + qaItem.expl)
        print("""")

class A:
  def __init__(self, question, correctAnswer, otherAnswers, difficulty, explanation):
    self.question = question
    self.corrAnsw = correctAnswer
    self.otherAnsw = otherAnswers
    self.diff = difficulty
    self.expl = explanation

qaList = [A(""What is COVID-19?"", ""Coronavirus Disease 2019"", [""Wuhan virus"", ""I don't understand..."", ""Coronavirus Disease v19""], 1, ""Explanation 1""),
A(""What describes COVID-19?"", ""A disease"", [""A virus"", ""A parasite"", ""A bacteriophage""], 1, ""Explanation 2""),
A(""What causes COVID-19?"", ""SARS-CoV-2"", [""Coronavirus"", ""Mimivirus"", ""Rubeola Virus""], 1, ""Explanation 3""),
A(""Which of the following is used in COVID-19 treatment?"", ""Lopinavir / Ritonavir "", [""Midazolam / Triazolam"", ""Amiodarone"", ""Phenytoin""], 2, ""Explanation 4""),
A(""Which of the following receptors is used by COVID-19 to infect human cells?"", ""ACE-2 Receptors"", [""ApoE4 Receptors"", ""TCR Receptors"", ""CD28 Receptors""], 3, ""Explanation 5"")]

corr = 0
marks = 0
random.shuffle(qaList)
for qaItem in qaList:
    q_timer = threading.Timer(5.0, qtimer)
    q_timer.start()
    print(qaItem.question)
    print(""Possible answers are:"")
    possible = qaItem.otherAnsw + [qaItem.corrAnsw]
    random.shuffle(possible)
    count = 0
    while count &lt; len(possible):
        print(str(count+1) + "": "" + possible[count])
        count += 1
    print(""Please enter the number of your answer:"")
    Answ = input()
    Answ = str(Answ)
    while not Answ.isdigit():
        print(""That was not a number. Please enter the number of your answer:"")
        Answ = input()
        Answ = int(Answ)
    Answ = int(Answ)
    while Answ &gt; 4 or Answ &lt; 1:
        print(""That number doesn't correspond to any answer. Please enter the number of your answer:"")
        Answ = input()
        Answ = int(Answ)
    if possible[Answ-1] == qaItem.corrAnsw:
        print(""Your answer was correct."")
        corr += 1
        marks += 1 * qaItem.diff
    else:
        print(""Your answer was wrong."")
        response = input(""Would you want to try again? If so, input 'Yes' to attempt it again, if not just input whatever!"")
        if response == ""Yes"":
            Answ = input(""Which option would you go for this time?: "")
            Answ = int(Answ)
            if possible[Answ - 1] == qaItem.corrAnsw:
                print(""Your answer was correct."")
                corr += 1
                marks += 0.5 * qaItem.diff
            else:
                print(""Your answer was wrong."")
                print(""Correct answer was: "" + qaItem.corrAnsw)
                print(""Explanation: "" + qaItem.expl)
                print("""")
        else:
            print(""Correct answer was: "" + qaItem.corrAnsw)
            print(""Explanation: "" + qaItem.expl)
            print("""")

print(""You answered "" + str(corr) + "" of "" + str(len(qaList)) + "" questions correctly."")
print(""You have achieved a total score of "" + str(marks) + ""."")
</code></pre>
"
60868176,"<p>I'm looking at the John Hopkins Dataset.</p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv</a></p>

<p>I have transformed it to the form (dummy data).</p>

<pre><code>Country/Region  | Province/State |   Date     |   Type   | Cases | 
     US               Arizona      2020/03/14   Confirmed  100 
Country/Region  | Province/State |   Date     |   Type   | Cases | 
     US               Arizona      2020/03/15   Confirmed  120 
</code></pre>

<p>What I want is to calculate the difference between date n and date n-1 for each country,region and case type.</p>

<p>Something like</p>

<pre><code>df['Difference'] = df.groupby(['Country/Region','Province/State','Type']).apply(...)
</code></pre>

<p>But I am not sure how to write the apply function.</p>

<p>I want the output table to look like this.</p>

<pre><code>Country/Region  | Province/State |   Date     |   Type   | Cases |  Difference
     US               Arizona      2020/03/14   Confirmed  100         ...
Country/Region  | Province/State |   Date     |   Type   | Cases | 
     US               Arizona      2020/03/15   Confirmed  120         20
</code></pre>

<p>How is this achieved?</p>
"
61478332,"<p>I am trying to read the text from an image using openCV and Pytesseract but it seems that I am unable to read everything that is written there in that image either as a plain text or something over logo.</p>

<p>I have done something like this:-</p>

<pre><code>img = cv2.imread(image_path)
bw_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
cv2.imshow('B/W Image', bw_img)
cv2.waitKey(0)
print(pytesseract.image_to_string(bw_img, lang='eng'))
cv2.destroyAllWindows()
</code></pre>

<p>and what I am getting in return as output:-</p>

<p>Support Local Business &amp; Donate to the
‘COVID-19 CRISIS RESPONSE FUND
frie GREATER EVANSVILLE REGION</p>

<p>SUPPORT</p>

<p>LOCAL</p>

<p>I have attached the images which I am trying to read text from and as you can see the text ""ORDER HERE"" inside a rectangle shaped button logo is unable to read/extract by openCV.</p>

<p><a href=""https://i.stack.imgur.com/pUQNU.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pUQNU.jpg"" alt=""enter image description here""></a></p>

<p>On the below images, both Cloud Vision API and Pytesseract are not able to extract proper text out of it. for Image first, I am getting ""off club price"" and for second "" "".
<a href=""https://i.stack.imgur.com/meNIZ.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/meNIZ.jpg"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/ffEMZ.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ffEMZ.jpg"" alt=""enter image description here""></a></p>

<p>If there is any other way to read text in python which is way better or easy than this one, kindly share.</p>
"
60839910,"<p>I am trying to understand how to get a list of URLs to scrape from a search box in Cyrillic website.
This is the results page, and the search term is ""коронавирус"" (it's 'windows-1251'):
<a href=""https://www.dnes.bg/search.php?q=%EA%EE%F0%EE%ED%E0%E2%E8%F0%F3%F1"" rel=""nofollow noreferrer"">https://www.dnes.bg/search.php?q=%EA%EE%F0%EE%ED%E0%E2%E8%F0%F3%F1</a></p>

<p>I am trying to get the URLs only under a tag like this one: </p>

<pre><code>&lt;div class=""ttl mb0""&gt;&lt;a href=""/notifikacii/2020/03/24/greta-tunberg-veroiatno-bila-bolna-ot-covid-19.443414""&gt;Грета Тунберг ""вероятно"" била болна от COVID-19&lt;/a&gt;&lt;/div&gt;
</code></pre>

<p>but it's a nested structure.
The xpath is:</p>

<pre><code>//*[@id=""c1""]/div[4]/div[1]/a
</code></pre>

<p>With BeautifulSoup's find_all('a') I find all the links, and I don't need everything, just the search results.</p>

<p>A full-code answer would be most helpful!</p>
"
61067293,"<p>I'm having issues to sum the values by the key for each country. The json data includes all the countries and each country has all the dates and each date has case numbers. The data looks like the following: </p>

<pre><code>{
  ""Afghanistan"": [
    {
      ""date"": ""2020-1-22"",
      ""confirmed"": 0,
      ""deaths"": 0,
      ""recovered"": 0
    },
    {
      ""date"": ""2020-1-23"",
      ""confirmed"": 0,
      ""deaths"": 0,
      ""recovered"": 0
    },
   ...
   ...
  ""Albania"":
   ...
   ...
}
</code></pre>

<p>I'm trying to show it as something like below (country and total confirmed cases for the country):</p>

<p>Afghanistan
###</p>

<p>Albania
###</p>

<p>Below are the codes that I've tried, but the results doesn't seem to be correct. </p>

<pre><code>     contents = requests.get('https://pomber.github.io/covid19/timeseries.json').json()
        for country in contents:
            print(country)
            data = contents[country]

            idx = 0
            confirmed_total = 0
            for each_day in data:
                confirmed_total += data[idx]['confirmed']
                idx += 1
            print(confirmed_total)


</code></pre>

<p>Any help would be appreciated.</p>
"
60726797,"<p>I am attempting to pull a data table from a NYT open-access web article on the number of COVID-19 cases, which can be found <a href=""https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html"" rel=""nofollow noreferrer"">here</a>. The table shows the top 10 states with highest number of cases, and expands to all 50 states and U.S. territories upon clicking the ""Show more"" button.</p>

<p><a href=""https://i.stack.imgur.com/I9ilX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/I9ilX.png"" alt=""enter image description here""></a></p>

<p>The HTML portion of the table is as follows:</p>

<p><a href=""https://i.stack.imgur.com/2xy5Z.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2xy5Z.png"" alt=""enter image description here""></a></p>

<p>Using <a href=""https://medium.com/ymedialabs-innovation/web-scraping-using-beautiful-soup-and-selenium-for-dynamic-page-2f8ad15efe25"" rel=""nofollow noreferrer"">this</a> tutorial, I have written the following code utilizing Selenium to try clicking this button, and pass this page off to BeautifulSoup to begin synthesizing for use in Pandas. My initial code looks as follows:</p>

<pre><code>from bs4 import BeautifulSoup
import selenium
import time
from selenium import webdriver

options = webdriver.ChromeOptions()
options.add_argument('--ignore-certificate-errors')
options.add_argument('--incognito')
options.add_argument('--headless')
driver = webdriver.Chrome(""/usr/bin/chromedriver"", chrome_options=options)
driver.get(""https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html"")
</code></pre>

<p>At this juncture, I am not sure how to execute clicking the button (found in the HTML snippet: <code>&lt;button class=""svelte-1tjczrs""&gt;Show more&lt;/button&gt;</code>), and stage it for BeautifulSoup.</p>

<p>Any help is greatly appreciated!</p>
"
61079652,"<p>I want to plot graph to compare cases each countries where I input by string. I import data from <a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">here</a></p>

<p>Here's an example of what I'm expecting:</p>

<p><a href=""https://i.stack.imgur.com/AsaUk.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AsaUk.jpg"" alt=""plot""></a></p>

<p>From that pic. I input N = 3 for range of countries to input. And I input name of each countries step by step. From now. If I want to plot the graph by which countries I was input to compare number of cases in one graph how can I do?</p>

<p>Here is my code:</p>

<pre><code>import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#read file
dfi = pd.read_csv('time_series_covid19_confirmed_global.csv', sep=',')
df = dfi.drop(['Province/State','Lat','Long'], axis=1)
df

#sum all the cases of each province/State to 1 row.
df_gr = df.groupby('Country/Region').sum()

time = df_gr.columns.tolist()
df_gr.columns = pd.to_datetime(time)
df_gr.reset_index(inplace = True)

countriesx = df_gr['Country/Region'].unique() #keep each country into list.
countries_list = [x for x in countriesx] #clean the data.

df = df_gr.T
new_header = df.iloc[0]
df = df[1:]
df.columns = new_header

#input the number of countries to compare.
while True:
   N = int(input('The number of countries to compare: '))
   if N &lt; 1 or N &gt; 185:
      print('The value must between1 and 185. Try again.\n')
      continue
   else:
      print('Correct inout.\n')
      break

#input name of countries to compare.
cnt = len(countries_list)
choose = [] #For the name of each countries.

for i in range(N):
   print(f'Country {i+1} of {N}')
      while True:
         my_countries = input('Enter the full country name: ')
         my_countries = my_countries.capitalize()
         countries_list.append(my_countries)

         set_checker = set(countries_list)

      if len(set_checker) == cnt:
         print(f'Country {i+1} confirmed as \'{my_countries}\'.\n')
         choose.append(my_countries)
         break
      else:
         print(f'There is no country named \'{my_countries}\'. Try again\n')
         countries_list.remove(my_countries)
         continue
</code></pre>

<p>This that I tried.</p>
"
60997790,"<p>I dunno if somebody here can help me easily, and be sure i don't want you to lost your time.
I am realy a newbie in programmation (only studied HTLM at the end of 90's ^^), but i was always interested in. Unfortunetely, don't have a lot of time between my job, children, the ""metro boulot dodo"" as we say in France.</p>

<p>But with the covid virus, situation changed. I need to developp a cartography tool for my job, to help artisan who can be open during the confinement to be find by proximity users. 
We have a few time to do it (until next monday). That's the moment for me to jump in the code... if i can !</p>

<p>So, what i want to do is simple : i have a list of artisan, geolocalisated, that i want to place on a map. I can do it with a lot of tools i master on the internet. Not so hard.
But where it's more complicated, that's i want to have two slides menu for helping users to accurate their reschearch : one for selected the region, and another to selected the categorie of artisans (food, building worker, proximity services, etc).</p>

<p>Here an image of what it will be looked like : <a href=""https://i.stack.imgur.com/LdUVs.jpg"" rel=""nofollow noreferrer"">clic here</a></p>

<p>I found Leaflet on the internet, and i tried to understand in the tutorial how i can do it. 
But i am a newbie... and french ! So, that's a little hard for me to find the good way.</p>

<p>So, can i do my project, even if i am a newbie ?</p>

<p>And if that's possible, what tutorial need i to follow to learn to do it ?</p>

<p>Thank you so much.</p>

<p>Julien</p>
"
61545243,"<p>I am extremely new to D3 so please bear with me. I've tried to consult lots of tutorials but think I just need a bit of help to get my head around this.
So I am trying to visualise the impact of COVID on sectors in geographical areas. The information is found in a JSON file which is mapped to a variable `covid'. You can select the county you wish to visualise by doing 'covid.data.____', so to select Aberdeen I have done</p>

<pre><code>const aberdeen = covid.data.Aberdeenshire;
</code></pre>

<p>The data (from console.log(aberdeen) looks like:</p>

<p><a href=""https://i.stack.imgur.com/5TMin.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5TMin.png"" alt=""enter image description here""></a></p>

<p>As you can see there are both positive and negative values for the sectors. I want to plot a bar chart which looks something like this, but obviously modified so that the axes only go from +100% to -100%  (image from <a href=""https://bl.ocks.org/gurjeet/83189e2931d053187eab52887a870c5e"" rel=""nofollow noreferrer"">https://bl.ocks.org/gurjeet/83189e2931d053187eab52887a870c5e</a>):
<a href=""https://i.stack.imgur.com/nOCdm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nOCdm.png"" alt=""enter image description here""></a></p>

<p>The issue is that the example code is using a JSON file, but I want to be able to plot the data from the JSON object as shown. Please can someone help? I've been going round in circles with this one :( Thank you in advance</p>
"
60982058,"<p>Apologies for the vague question, I'm not too sure how to completely phrase what I'm wanting to do, which hasn't helped my searching for solutions at all! I'm pretty new to javascript and vega-lite but am trying to upskill. As such I'm working on COVID19 data made available by the New Zealand Ministry of Health, and looking at how I can visualise the data. If interested here is my rough site thus far: <a href=""https://sirselim.github.io/covid_analysis/"" rel=""nofollow noreferrer"">https://sirselim.github.io/covid_analysis/</a></p>

<p>I'm trying to define all days that have been in lockdown here in NZ, since the 26th March 2020, and display these in a different colour, see below for my current solution which is I believe 95% of the way there:</p>

<p><br>
<a href=""https://i.stack.imgur.com/W4QID.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/W4QID.png"" alt=""enter image description here""></a></p>

<p>So I have essentially what I want being displayed, however I am manually defining the dates in the <code>scale</code> element, which doesn't seem like the correct way to do things. I would have thought I should be able to define a date range and it would apply the formatting to dates that fall in the defined range. The other, smaller, tweak I would like to make is not listing the dates in the legend but just have [blue] no lockdown and [orange] lockdown.</p>

<p>Here's the code:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Embedding Vega-Lite&lt;/title&gt;
    &lt;script src=""https://cdn.jsdelivr.net/npm/vega@5.10.1""&gt;&lt;/script&gt;
    &lt;script src=""https://cdn.jsdelivr.net/npm/vega-lite@4.9.0""&gt;&lt;/script&gt;
    &lt;script src=""https://cdn.jsdelivr.net/npm/vega-embed@6.5.2""&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div id=""vis""&gt;&lt;/div&gt;

    &lt;script type=""text/javascript""&gt;
      var yourVlSpec = {
  ""$schema"": ""https://vega.github.io/schema/vega-lite/v4.json"",
  ""width"": 580,
  ""height"": 200,
  ""padding"": 5,
  ""description"": ""simple vega-lite chart with linked data"",
  ""title"": ""Confirmed COVID cases in NZ DHBs"",
  ""data"": {
      ""url"": ""https://raw.githubusercontent.com/sirselim/covid_analysis/master/data//NZCOVID_confirmed_formatted.json""
    },
  ""transform"": [{
    ""sort"": [{""field"": ""Date of report""}],
    ""window"": [{""op"": ""count"", ""field"": ""count"", ""as"": ""cumulative_count""}],
    ""frame"": [null, 0]
  }],
  ""mark"": {
    ""type"": ""bar"",
    ""tooltip"": true
  },
  ""encoding"": {
    ""x"": {
      ""field"": ""Date of report"",
      ""type"": ""nominal""
    },
    ""y"": {
      ""field"": ""cumulative_count"",
      ""type"": ""quantitative""
    },
            ""color"": {
              ""value"": ""steelblue"",
              ""condition"": {
                ""test"": {
                  ""field"": ""Date of report"",
                  ""range"": [
                    ""2020-03-26"",
                    ""2020-04-30""
                  ]
                },
                ""field"": ""Date of report"",
                ""title"": ""Days in lockdown"",
                ""type"": ""nominal"",
                ""scale"": {
                  ""domain"": [
                    ""2020-03-26"",
                    ""2020-03-27"",
                    ""2020-03-28"",
                    ""2020-03-29"",
                    ""2020-03-30"",
                    ""2020-03-31"",
                    ""2020-04-01""
                  ],
                  ""range"": [
                    ""#FFA500"",
                    ""#FFA500""
                  ]
                }
              }
            }
  }
};
      vegaEmbed('#vis', yourVlSpec);
    &lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
</div>
</p>

<p>Thank you in advance to anyone with some insight!</p>
"
60918374,"<p>I am trying to create a simple with vue-cli and the router that fetches Covid-19 cases by Country from a JSON object of arrays. This is my first Vue app. However, I keep getting an error about ""Declaring Reactive Properties"". I searched dozens of similar errors on many different forums and seemed to do the trick.</p>

<p>Most of the <a href=""https://vuejs.org/v2/cookbook/using-axios-to-consume-apis.html#Alternative-Patterns"" rel=""nofollow noreferrer"">code is from vue.org</a>, except for the JSON link.</p>

<p>Api.js:</p>

<pre><code>import axios from ""axios"";
import Vue from ""vue"";

new Vue({
  el: ""#app"",
  data() {
    return {
      info: null,
      loading: true,
      errored: false
    };
  },
  template: ""&lt;div&gt;{{ output.info }}&lt;/div&gt;"",
  mounted() {
    axios
      .get(""https://pomber.github.io/covid19/timeseries.json"")
      .then(response =&gt; {
        this.info = response.data;
        console.log(this.info);
      })
      .catch(error =&gt; {
        console.log(error);
        this.errored = true;
      })
      .finally(() =&gt; (this.loading = false));
  }
});

export default {
  name: ""About"",
  props: {
    loading: String,
    errored: String,
    info: String
  }
};
</code></pre>

<p>About.js</p>

<pre><code>&lt;template&gt;
</code></pre>

<p></p>

<pre><code>&lt;h1&gt;Covid-19 cases by Country&lt;/h1&gt;

&lt;section v-if=""errored""&gt;
  &lt;p&gt;
    We're sorry, we're not able to retrieve this information at the moment,
    please try back later
  &lt;/p&gt;
&lt;/section&gt;

&lt;section v-else&gt;
  &lt;div v-if=""loading""&gt;Loading...&lt;/div&gt;

  &lt;div v-else v-for=""data in info"" :key=""data"" class=""currency""&gt;
    &lt;h1&gt;{{ data.Portugal[0].deaths }}&lt;/h1&gt;
  &lt;/div&gt;
&lt;/section&gt;
</code></pre>

<p>
</p>

<p>Error: </p>

<blockquote>
  <p>[Vue warn]: Property or method ""errored"" is not defined on the
  instance but referenced during render. Make sure that this property is
  reactive, either in the data option, or for class-based components, by
  initializing the property</p>
</blockquote>

<p>I can see the warning 3 times, for each of the props errored, loading and info, the most important one.</p>
"
60803008,"<p>I am a real beginner in flutter and dart, i am trying to implement some web page (specifically pandemic.events) functionality with in a really simple android app..</p>

<p>my first thought is just to copy the web page with all of its' javascript inside the app and manipulate a little bit some parts that i find lacking.</p>

<p>i am struggling with using javascript inside my flutter app (writing import package:js... in main.dart).</p>

<p>Is there even a possibility to use javascript inside a flutter android app ?</p>
"
61060364,"<p>Like stated in the title, how do I add a countup animation to the following items:
Tested positive
Population
Deaths
Percentage of deaths of positive tested people
Last date updated</p>

<p>The numbers are dynamic and not static, that's where I am getting lost.</p>

<p>Thank you for your help. I'm sorry, but I am new to coding with Javascript, Json and using API's.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>window.addEventListener(""load"", function() {
  document.getElementById(""countrySel"").addEventListener(""change"", getCovidStats);
  document.getElementById(""countrySel"").value = ""169"";
  getCovidStats()
})

function getCovidStats() {
  const cc = document.getElementById(""countrySel"").value;
  if (cc === """") return;

  fetch('https://coronavirus-tracker-api.herokuapp.com/v2/locations/' + cc)
    .then(function(resp) {
      return resp.json()
    })
    .then(function(data) {
      let population = data.location.country_population;
      let update = data.location.last_updated;
      let confirmedCases = data.location.latest.confirmed;
      let deaths = data.location.latest.deaths;

      document.getElementById('inwoners').innerHTML = population.toLocaleString('en');
      document.getElementById('update').innerHTML = update.substr(0, 10);
      document.getElementById('patienten').innerHTML = confirmedCases.toLocaleString('en');
      document.getElementById('doden').innerHTML = deaths.toLocaleString('en');
      document.getElementById('procent').innerHTML = ((Number(deaths) / Number(confirmedCases)) * 100).toLocaleString(""en"", {
        minimumFractionDigits: 2,
        maximumFractionDigits: 2
      }) + ""%"";
    })
    .catch(function() {
      console.log(""error"");
    })
  setInterval(getCovidStats, 43200000) // update every 12 hours
}</code></pre>
<pre class=""snippet-code-css lang-css prettyprint-override""><code>* {
  margin: 0;
  padding: 0;
}

html {
  height: 100%;
  width: 100%;
}

h1,
h2 {
  font-family: 'Roboto', sans-serif;
  font-weight: 300;
  text-align: center;
  padding-bottom: 20px;
  font-size: 250%;
}

.subtitle,
.over {
  padding: 20px;
  font-size: 150%;
}

body {
  background-color: #FFDC56;
}

div {
  padding: 20px;
}


/* Add a black background color to the top navigation */

.topnav {
  background-color: #005A9C;
  overflow: hidden;
  font-family: 'Roboto', sans-serif;
  font-size: 75%;
}

.logo {
  float: left;
}


/* Style the links inside the navigation bar */

.topnav a {
  float: right;
  color: #f2f2f2;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 17px;
}


/* Change the color of links on hover */

.topnav a:hover {
  background-color: #FFDC56;
  color: black;
}


/* Add a color to the active/current link */

.topnav a.active {
  background-color: #4CAF50;
  color: white;
}

.stats-container {
  text-align: center;
  float: right;
  display: inline-block;
}

.location-container {
  display: inline-block;
}

.data-container {
  border: 2px solid #005A9C;
  margin-right: 30%;
  margin-left: 30%;
}

h4,
{
  font-size: 85%;
  color: gray;
  font-family: 'Roboto', sans-serif;
  font-weight: 300;
  text-align: center;
  padding-top: 20px;
  padding-left: 20px;
  padding-right: 20px;
  padding-bottom: 5px;
}

.over {
  font-family: 'Roboto', sans-serif;
  font-size: 100%;
  text-align: center;
}

.footer {
  font-family: 'Roboto', sans-serif;
  bottom: 0;
  font-size: 75%;
  padding: 5px;
}

.maatregelen {
  width: 35%;
  display: block;
  margin-left: auto;
  margin-right: auto;
  text-align: center;
}

.maatregelen-caption {
  text-align: center;
  font-family: 'Roboto', sans-serif;
  font-size: 80%;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;

&lt;head&gt;
  &lt;title&gt;Coronavirus Statistieken&lt;/title&gt;
  &lt;meta charset=""UTF-8""&gt;
  &lt;link rel=""shortcut icon"" href=""masker-emoji.png""&gt;
  &lt;link href=""https://fonts.googleapis.com/css?family=Roboto:100,300,400&amp;display=swap"" rel=""stylesheet""&gt;
  &lt;link rel=""stylesheet"" type=""text/css"" href=""styles.css""&gt;
  &lt;script type=""text/javascript"" src=""app.js""&gt;&lt;/script&gt;
  &lt;script type=""text/javascript"" src=""loader.js""&gt;&lt;/script&gt;

&lt;/head&gt;

&lt;body&gt;
  &lt;div class=""topnav""&gt;
    &lt;h1 class=""logo""&gt;Coronavirus&lt;/h1&gt;
    &lt;a href=""over.html""&gt;about&lt;/a&gt;
    &lt;a class=""active"" href=""index.html""&gt;stats&lt;/a&gt;
  &lt;/div&gt;

  &lt;h2 class=""subtitle""&gt;Title&lt;/h2&gt;
  &lt;div class=""data-container""&gt;
    &lt;div class=""stats-container""&gt;
      &lt;h4&gt;Tested positive&lt;/h4&gt;
      &lt;h1 id=""patienten""&gt;&lt;/h1&gt;
      &lt;h4&gt;Deaths&lt;/h4&gt;
      &lt;h1 id=""doden""&gt;&lt;/h1&gt;
      &lt;h4&gt;Percentage of deaths of positive tested people&lt;/h4&gt;
      &lt;h1 id=""procent""&gt;&lt;/h1&gt;
    &lt;/div&gt;
    &lt;div class=""location-container""&gt;
      &lt;h4&gt;country&lt;/h4&gt;
      &lt;h1 id=""country""&gt;&lt;label for=""countrySel""&gt;Country:&lt;/label&gt;
        &lt;select id=""countrySel""&gt;
          &lt;option value=""169""&gt;🇳🇱 &lt;/option&gt;
          &lt;option value=""120""&gt;🇩🇪 &lt;/option&gt;
          &lt;option value=""116""&gt;🇫🇷 &lt;/option&gt;
          &lt;option value=""201""&gt;🇪🇸 &lt;/option&gt;
          &lt;option value=""137""&gt;🇮🇹 &lt;/option&gt;
          &lt;option value=""187""&gt;🇷🇺 &lt;/option&gt;
          &lt;option value=""143""&gt;🇰🇷 &lt;/option&gt;
          &lt;option value=""225""&gt;🇺🇸 &lt;/option&gt;
        &lt;/select&gt;
      &lt;/h1&gt;
      &lt;h4&gt;population&lt;/h4&gt;
      &lt;h1 id=""inwoners""&gt;&lt;/h1&gt;
      &lt;h4&gt;updated on&lt;/h4&gt;
      &lt;h1 id=""update""&gt;&lt;/h1&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;h1 class=""footer""&gt;Footer&lt;/h1&gt;
&lt;/body&gt;

&lt;/html&gt;</code></pre>
</div>
</div>
</p>
"
60659215,"<p>I'm having trouble incorporating John Hopkins coronavirus data into a D3 choropleth, I'm quite new so there's likely a fundamental thing that's missing. The code is largely swiped for various sources I've found on the internet but this is largely a learning project to teach myself D3 so well annotated answers would be greatly appreciated.</p>

<p>R code to get data:</p>

<pre><code>library(tidyverse)
library(tools)

dat &lt;- read.csv(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"")

states &lt;- dat %&gt;% 
  filter(Country.Region == ""US"", 
         !grepl("","",Province.State),
         !grepl(""Princess"",Province.State),
         Province.State != ""District of Columbia"") %&gt;% 
  pivot_longer(5:ncol(.), names_to = ""Date"", values_to = ""Cases"") %&gt;% 
  mutate(Date = str_remove(Date,""X""),
         Date = as.Date(Date, ""%m.%d.%y"")) %&gt;% 
  filter(Date == max(Date)) %&gt;% 
  select(state = Province.State,
         cases = Cases)

counties &lt;-  dat %&gt;% 
  filter(Country.Region == ""US"", 
         grepl("","",Province.State),
         !grepl(""Princess"",Province.State),
         Province.State != ""Washington, D.C."") %&gt;% 
  separate(Province.State, c(""county"", ""state""), "", "") %&gt;% 
  mutate(county = str_remove(county, "" County"")) %&gt;% 
  pivot_longer(6:ncol(.), names_to = ""Date"", values_to = ""Cases"") %&gt;% 
  mutate(Date = str_remove(Date,""X""),
         Date = as.Date(Date, ""%m.%d.%y"")) %&gt;% 
  filter(Date == max(Date)) %&gt;% 
  select(county = county,
         state,
         cases = Cases)

#write.csv(states, ""state_cases.csv"",row.names=FALSE)
#write.csv(counties, ""county_cases.csv"",row.names=FALSE)

#FIPS=====================================================================+++++

#county_fips &lt;- read.csv(""https://raw.githubusercontent.com/kjhealy/fips-codes/master/state_and_county_fips_master.csv"") %&gt;% 
#  select(id = fips,
#         name,
#         state) %&gt;% 
#  mutate(id = str_pad(as.character(id), 5, pad = ""0""),
#         name = str_remove(name, "" County""),
#         name = toTitleCase(tolower(as.character(name))),
#         id = case_when(grepl(""000"", id) ~ str_sub(id, end=-4),
#         TRUE ~ id))
#
#write.csv(county_fips, ""county_fips.csv"",row.names=FALSE)

county_fips &lt;- read.csv(""county_fips.csv"")

cases &lt;- county_fips %&gt;% filter(is.na(state)) %&gt;% 
  left_join(states, by= c(""name"" = ""state"")) %&gt;% 
  select(-state) %&gt;% 
  rbind(
    county_fips %&gt;% filter(!is.na(state)) %&gt;% 
      left_join(counties, by= c(""name"" = ""county"",""state"" = ""state"")) %&gt;% 
      select(-state)
  )

write.csv(cases, ""cases.csv"",row.names=FALSE)

</code></pre>

<p>HTML:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1""&gt;
    &lt;title&gt;Coronavirus Cases&lt;/title&gt;
    &lt;style&gt;
        .background {
            fill: none;
            pointer-events: all;
        }

        #states {
            fill: none;
        }

        #states .active {
            display:none;
        }

        #state-borders {
            fill: none;
            stroke: #fff;
            stroke-width: 1px;
            stroke-linejoin: round;
            stroke-linecap: round;
            pointer-events: none;
        }

        .county-boundary {
            fill: 'grey';
            stroke: #fff;
            stroke-width: .5px;
        }

        .county-boundary:hover, .state:hover {
            fill: rgba(121, 121, 121, 0.2);
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;

&lt;script src=""https://d3js.org/d3.v5.min.js""&gt;&lt;/script&gt;
&lt;script src=""https://d3js.org/d3-scale-chromatic.v1.min.js""&gt;&lt;/script&gt;
&lt;script src=""https://d3js.org/topojson.v2.min.js""&gt;&lt;/script&gt;

    &lt;div class=""viz""&gt;&lt;/div&gt;
    &lt;script type=""text/javascript""&gt;

        var x = d3.scaleLinear()
            .domain([1, 10])
            .rangeRound([600, 860]);

        var color = d3.scaleThreshold()
            .domain(d3.range(0, 9))
            .range(d3.schemeBlues[9]);

        var margin = {
            top: 10,
            bottom: 10,
            left: 10,
            right:10
        }, width = parseInt(d3.select('.viz').style('width'))
            , width = width - margin.left - margin.right
            , mapRatio = 0.5
            , height = width * mapRatio
            , active = d3.select(null);

        var svg = d3.select('.viz').append('svg')
            .attr('height', height + margin.top + margin.bottom)
            .attr('width', width + margin.left + margin.right);

        svg.append('rect')
            .attr('class', 'background center-container')
            .attr('height', height + margin.top + margin.bottom)
            .attr('width', width + margin.left + margin.right)
            .on('click', clicked);

        var promises = [
            d3.json(""us-10m.v1.json""),
            d3.csv(""cases.csv"", function(d) { 
                cases.set(d.id, +d.name +d.cases); 
            })
        ]

        Promise.all(promises).then(ready)

        var projection = d3.geoAlbersUsa()
            .translate([width /2 , height / 2])
            .scale(width);

        var path = d3.geoPath()
            .projection(projection);

        var g = svg.append(""g"")
            .attr('class', 'center-container center-items us-state')
            .attr('transform', 'translate('+margin.left+','+margin.top+')')
            .attr('width', width + margin.left + margin.right)
            .attr('height', height + margin.top + margin.bottom)

        function ready(us) {

            g.append(""g"")
                .attr(""id"", ""counties"")
                .selectAll(""path"")
                .data(topojson.feature(us, us.objects.counties).features)
                .enter().append(""path"")
                .attr(""d"", path)
                .attr(""fill"", function(d) { 
                var sn = CountyNames.get(d.id)
                d.rate = cases.get(countyNames.get(d.id)) || 0
                var col =  color(d.rate); 
                if (col) {
                    return col
                } else {
                    return '#ffffff'
                }
            })
                .attr(""class"", ""county-boundary"")
                .on(""click"", reset);

            g.append(""g"")
                .attr(""id"", ""states"")
                .selectAll(""path"")
                .data(topojson.feature(us, us.objects.states).features)
                .enter().append(""path"")
                .attr(""d"", path)
                .attr(""fill"", function(d) { 
                var sn = StateNames.get(d.id)
                d.rate = cases.get(stateNames.get(d.id)) || 0
                var col =  color(d.rate); 
                if (col) {
                    return col
                } else {
                    return '#ffffff'
                }
            })
                .attr(""class"", ""state"")
                .on(""click"", clicked);


            g.append(""path"")
                .datum(topojson.mesh(us, us.objects.states, function(a, b) { return a !== b; }))
                .attr(""id"", ""state-borders"")
                .attr(""d"", path);

        }

        function clicked(d) {
            if (d3.select('.background').node() === this) return reset();

            if (active.node() === this) return reset();

            active.classed(""active"", false);
            active = d3.select(this).classed(""active"", true);

            var bounds = path.bounds(d),
                dx = bounds[1][0] - bounds[0][0],
                dy = bounds[1][1] - bounds[0][1],
                x = (bounds[0][0] + bounds[1][0]) / 2,
                y = (bounds[0][1] + bounds[1][1]) / 2,
                scale = .9 / Math.max(dx / width, dy / height),
                translate = [width / 2 - scale * x, height / 2 - scale * y];

            g.transition()
                .duration(750)
                .style(""stroke-width"", 1.5 / scale + ""px"")
                .attr(""transform"", ""translate("" + translate + "")scale("" + scale + "")"");
        }


        function reset() {
            active.classed(""active"", false);
            active = d3.select(null);

            g.transition()
                .delay(100)
                .duration(750)
                .style(""stroke-width"", ""1.5px"")
                .attr('transform', 'translate('+margin.left+','+margin.top+')');

        }
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
</div>
</p>

<p>I'm just getting this: <a href=""https://i.stack.imgur.com/KAwFj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KAwFj.png"" alt=""enter image description here""></a></p>

<p>When I should be seeing something along these lines: <a href=""http://bl.ocks.org/ElefHead/ebff082d41ef8b9658059c408096f782"" rel=""nofollow noreferrer"">http://bl.ocks.org/ElefHead/ebff082d41ef8b9658059c408096f782</a></p>
"
61685568,"<p>I'm new in Python, I would like to get the content and the titles of all the news articles from this page: <a href=""https://www.nytimes.com/search?query=china+COVID-19"" rel=""nofollow noreferrer"">https://www.nytimes.com/search?query=china+COVID-19</a></p>

<p>However, the output of my current codes stored all the paragraphs from 10 articles into 1 list. I wonder how could I store each paragraph into a dict, which is the article it belongs to, and save all the dict into 1 list?</p>

<p>Any helps would be greatly appreciated!</p>

<pre><code>import requests
from bs4 import BeautifulSoup
import json

response=requests.get('https://www.nytimes.com/search?query=china+COVID-19')
response.encoding='utf-8'
soupe=BeautifulSoup(response.text,'html.parser')

links = soupe.find_all('div', class_='css-1i8vfl5')

pagelinks = []
for link in links:
    url = link.contents[0].find_all('a')[0] 
 pagelinks.append('https://www.nytimes.com'+url.get('href')) 


articles=[]  

for i in pagelinks:
    response=requests.get(i)
    response.encoding='utf-8'
    soupe=BeautifulSoup(response.text,'html.parser') 
    for p in soupe.select('section.meteredContent.css-1r7ky0e div.css-53u6y8'):
        articles.append(p.text.strip())
print('\n'.join(articles))
</code></pre>
"
61184056,"<p>I want to plot two bar graphs side by side using matplotlib/seaborn for two countries Covid-19 confirmed cases: Italy and India for comparison. However after trying many methods I couldn't achieve the problem. Confirmed cases of both countries are coming from two different data frames.  </p>

<p><a href=""https://raw.githubusercontent.com/datasets/covid-19/master/data/countries-aggregated.csv"" rel=""nofollow noreferrer"">Data source</a>  </p>

<p>I want to plot 'Dates' column on x-axis and 'Confirmed cases count' on y-axis.<br>
Attaching images of my code for reference.<br>
P.S: I am new to data visualization and pandas too.      </p>

<pre><code> import pandas as pd
 import numpy as np
 import matplotlib.pyplot as plt
 import seaborn as sns
 df = pd.read_csv('https://raw.githubusercontent.com/datasets/covid- 
 19/master/data/countries-aggregated.csv', parse_dates = ['Date'])
 df.head(5)

 ind_cnfd = df[['Date', 'Country', 'Confirmed']]
 ind_cnfd = ind_cnfd[ind_cnfd['Country']=='India']
 italy_cnfd = df[['Date', 'Country', 'Confirmed']]
 italy_cnfd = italy_cnfd[italy_cnfd['Country'] == 'Italy']
</code></pre>

<p>Expected output kind of this: 
With dates on x-axis and confirmed cases on y-axis
<a href=""https://i.stack.imgur.com/fFRay.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/fFRay.png"" alt=""image""></a></p>
"
60893358,"<p>I created a new column in my dataset called deaths_to_cases (this is a dataframe about COVID-19 cases in the United States). For some reason, anything I want to try and do, like get the median of this new column, isn't being recognized in Pandas - I'm using Google Colab. </p>

<p>The code is below, and I even tested an existing column that was in the dataframe I uploaded as the CSV file (existing column='positive'), and it worked. The problem is the df.loc[:,'deaths_to_cases'].median(). I'm newer to Python/pandas so I'm sure it's an obvious fix and I'm just too new to know. Any help much appreciated!</p>

<pre><code>df.assign(deaths_to_cases = df.death/df.positive)
df.info()
df.loc[:,'positive'].median()
df.loc[:,'deaths_to_cases'].median()
</code></pre>
"
60841745,"<p>I'm having trouble selecting specific values of a row with pandas.
I have a CSV file with confirmed cases of Coronavirus in each country each day. So obviously some countries started having cases in different days and progressed in different ways.</p>

<p>Dataframe of countries I'm trying to plot:
<a href=""https://i.stack.imgur.com/SpRnv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/SpRnv.png"" alt=""enter image description here""></a></p>

<p>I would like to filter each row since de 50th confirmed case, which occurs on different days for each country.
I tried to use the command <code>df[df['column']&gt;50]</code>, but this works for a single column and I want to do for all columns.</p>

<p>All my life I worked just with procedural programming in python without libraries but this week I decided to start using some of them, so my library understanding is very limited and I don't know how to insert a for loop on a library function, which I think is the case here. This is also my first question on stack overflow, so if I am doing something wrong please tell me. Thank you!</p>
"
61633719,"<p>I am building a small program to chart some API data. I have set it up to pull the data and then create a local json which I then create a dataframe from.</p>

<p>Is there a way to skip the local file and pull the data straight into the dataframe?</p>

<p>As you can see the example I am working with is Ireland, but I would like to end up with something that can reference any country, and would hope to avoid creating a file.</p>

<pre><code># Import the libraries
import requests
import json
from datetime import datetime

import matplotlib.pyplot as plt

import pandas as pd
import numpy as np
from pandas import Series, DataFrame

# Save the current API call as a JSON file
# countryStatusdDayOne

# 1. Make an API call and store the response.
url = 'https://api.covid19api.com/total/dayone/country/ireland'
data = requests.get(url)

# Store the API response in a variable.
available_data = data.json()

filename = 'data/covid_call__ireland_day_one_workable.json'
with open(filename, 'w') as f:
    json.dump(available_data, f, indent=4)

# read the json
ireland = pd.read_json('data/covid_call__ireland_day_one_workable.json')

# create a dataframe 
df_ire = pd.DataFrame(ireland)

</code></pre>

<p>This is all very new to me so any advice on how to format or improve my code is also very welcome!</p>
"
60680186,"<p>I'm so new to this I don't have the vocabulary to properly frame the question.  Nor do I know how to include the output very well.  </p>

<p>I'm trying to slice a multi indexed dataframe of COVID19 data.  I want to select data from countries other than China.  I know how to slice using a multiindex based on countries I want to see, I just don't know how to look at everything but a country or set of countries.</p>

<pre><code>                     1/22/20   1/23/20   1/24/20...
Country   Province  
China      Hubei       28        28         28
Italy       NaN         0         0          0
...
</code></pre>

<p>Obviously the dataframe is much bigger.  All I want to do is slice by excluding rather than explicitly including.</p>

<p><code>df.loc['China']</code></p>

<p>Gives me all rows with China.  How do I slice to exclude?  Below doesn't work, but it gives the idea:</p>

<p><code>df.loc[!='China']</code></p>

<p>Any hints?</p>

<p>Thanks!</p>
"
60987445,"<p>I'm trying to create a Python programme which will show the following data about Covid-19, all from a CSV file:</p>

<ul>
<li>cases per day</li>
<li>total cases</li>
<li>deaths per day</li>
<li>total deaths</li>
</ul>

<p>I'm reading the data from a file and populating 4 arrays with the info. I can iterate over the arrays and print out the data - it all looks OK.</p>

<p>The issue is when I look at the graph produced - the data seems to be OK for the first 25 entries and then rises with all lines in parallel. The scale on the y-axis is wrong too - it seems to restart the scale for each of the 4 data sets.</p>

<p><a href=""https://i.stack.imgur.com/Mavvt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Mavvt.png"" alt=""Output Graph""></a></p>

<p>Here's the code:</p>

<pre><code>import csv
import matplotlib.pyplot as plt
from datetime import datetime

#create the arrays to hold virus data

caseDate, cases, casesCum, deaths, deathsCum = [], [], [], [], []
leg1 = ""Cases""
leg2 = ""Cases - Cum""
leg3 = ""Deaths""
leg4 = ""Deaths - Cum""

#open virus data file
filename = 'Virus Data.csv'
with open(filename) as f:
    reader = csv.reader(f)
    header_row = next(reader)

    #record data in arrays
    for row in reader:
        current_date = datetime.strptime(row[0], ""%d/%m/%Y"")
        caseDate.append(current_date)
        cases.append(row[1])
        casesCum.append(row[2])
        deaths.append(row[3])
        deathsCum.append(row[4])

for i in range (len(cases)):
    print(""Entry "", i, "": Cases: "", cases[i],""; Cum Cases: "", casesCum[i],""; Deaths: "", deaths[i],""; Cum Deaths: "", deathsCum[i])

#data now recorded
#plot data in chart
fig = plt.figure(dpi = 128, figsize=(12,6))
plt.plot(caseDate, cases, c=""red"", alpha=0.5)
plt.plot(caseDate, casesCum, c=""blue"", alpha=0.5)
plt.plot(caseDate, deaths, c=""green"", alpha = 0.5)
plt.plot(caseDate, deathsCum, c=""black"", alpha = 0.5)

#format plot
title = ""Covid-19 Statistics""
plt.title(title, fontsize = 20)
plt.xlabel("""", fontsize = 16)
fig.autofmt_xdate()
plt.ylabel(""Cases / Cum Cases / Deaths / Cum Deaths"", fontsize = 12)
plt.tick_params(axis='both', which='major', labelsize=16)

plt.show()
</code></pre>

<p>It's almost there, but not quite. When I create the chart in Excel, it looks like I expect:</p>

<p><a href=""https://i.stack.imgur.com/kUleB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kUleB.png"" alt=""Excel Graph""></a></p>

<p>I'd like it to work in Python.....</p>
"
61383352,"<p>I am new to Python and I am trying to scrape some article links from a website. I managed to scrape the info needed from the first page but I don't know how to do the same for all the next pages. I know that there are quite a few posts regarding this issue but I wasn't able to figure it out in my case. The code that I am using is this one:</p>

<pre><code>from bs4 import BeautifulSoup
import requests
import csv

csv_file = open('cms_scrape.csv', 'w', newline='')
csv_writer = csv.writer(csv_file)
csv_writer.writerow(['date', 'link'])

base_url = 'https://www.khaleejtimes.com'
search_url = 'https://www.khaleejtimes.com/search&amp;text=&amp;content=articles&amp;datefilter=24hours&amp;sort=oldest&amp;facet.filter=TaxonomyLeaf:Coronavirus%20outbreak'

def get_info(article):
    date = article.find('div', class_= 'author_date').text
    print(date)
    link = base_url + article.find('a')['href']
    print(link)

source = requests.get(search_url).text

soup = BeautifulSoup(source, 'lxml')

results = soup.find(class_= 'search_listing')

for article in results.find_all('li'):
    get_info(article)

    print()

    csv_writer.writerow([date, link])

csv_file.close()
</code></pre>

<p>Any help would be much appreciated.</p>
"
60793000,"<p>First time I created a very light python/flask application that is fully written in one file.
I tried to create a light API and make it accessible from the terminal (curl, etc.) and got the following error after I deployed it and tried to retrieve the data:</p>

<pre><code>    desc=""No web processes running"" .....
</code></pre>

<p>The app folder structure:</p>

<p>FolderName:</p>

<p><code>app.py</code>
<code>Procfile</code>
<code>requirements.txt</code></p>

<p>Now what each of them contains:</p>

<p><strong>app.py</strong></p>

<pre><code>    import flask
    import datetime
    import requests
    import json


    app = flask.Flask(__name__)


    @app.route('/covidData', methods=('GET', 'POST'))
    def get_data():

        country_input = flask.request.args.get('country')
        date_input = flask.request.args.get('date')
        date_split = date_input.split(""-"")
        date = datetime.datetime(int(date_split[2]),  int(date_split[0]), int(date_split[1])).strftime('%m-%d-%Y')

        data = requests.get('https://covid19.mathdro.id/api/daily/' + date)
        processed_data = data.json()

        for country in processed_data:
            if country['countryRegion'] == country_input:
                target_country = country

        requested_data = {""Country"": target_country['countryRegion'], ""Cases"": target_country[""confirmed""], ""Recovered"": target_country[""recovered""]}

        return flask.jsonify(requested_data)


    if __name__ == '__main__':
        app.run(port=5000)
</code></pre>

<p><strong>Procfile:</strong></p>

<pre><code>    gunicorn wsgi:app
</code></pre>

<p><strong>requirements:</strong></p>

<pre><code>    requests==2.22.0
    Flask==1.1.1
</code></pre>

<p>How I deployed:
1. git init
2. heroku login
3. created a Procfile
4. heroku apps:create 
5. git add .
6. git commit -m ""heroku deployment""
7. git push heroku master</p>

<p>Then, I try to retrieve the data from my local terminal:</p>

<pre><code>    curl -X POST ""https://covid-19-2020-api.herokuapp.com/covidData?country=Israel&amp;date=03-20-2020""
</code></pre>

<p>And get the following Error:</p>

<pre><code>    heroku[router]: at=error code=H14 desc=""No web processes running"" method=POST path=""/covidData?country=Israel&amp;date=03-20-2020"" host=covid-19-2020-api.herokuapp.com request_id=8b56257e-4c4f-46df-b8d9-ee487a4a5480 fwd=""185.175.33.226"" dyno= connect= service= status=503 bytes= protocol=https
</code></pre>

<p>What might be the problem, any advice, directions will be highly appreciated! I am newby in building APIs</p>

<p>Thank you!</p>
"
61665880,"<p>I am trying to scrape the table of research studies in the below link</p>

<p><a href=""https://clinicaltrials.gov/ct2/results?cond=COVID&amp;term=&amp;cntry=&amp;state=&amp;city=&amp;dist="" rel=""nofollow noreferrer"">https://clinicaltrials.gov/ct2/results?cond=COVID&amp;term=&amp;cntry=&amp;state=&amp;city=&amp;dist=</a></p>

<p>The table has dynamically created content using Javascript.
I tried using selenium, but intermittently getting StaleElementException.
Please help me with the same.</p>

<p>I want to retrieve all rows in the table and store them in a local database.
Here is what I have tried in selenium</p>

<pre><code> import selenium.webdriver as webdriver
 url = 'https://clinicaltrials.gov/ct2/results?cond=COVID&amp;term=&amp;cntry=&amp;state=&amp;city=&amp;dist='
 driver=webdriver.Firefox()
 #driver.implicitly_wait(30)
 driver.get(url)
 data = []
 for tr in driver.find_elements_by_xpath('//table[@id=""theDataTable""]//tbody//tr'):
  tds = tr.find_elements_by_tag_name('td')
   if tds:
    for td in tds:
     print(td.text)
     if td.text not in data:
      data.append(td.text)          
 driver.quit()
 print('*********************************************************************')
 print(data)
</code></pre>

<p>Further the data from the 'data' variable I'll store in DB.</p>

<p>I am new to selenium and Web Scraping and further, I want to click on each link in the 'Study Title' column and extract data from that page for each study.</p>

<p>I want suggestions to avoid/handle a stale element exception or an alternative for Selenium webdriver.
Thanks in Advance!</p>
"
61151457,"<p>I'm trying to create a single figure that plot my <code>y_train</code> and <code>y_pred</code> with date as x-axis. I have never created the one like this before so i'm kind of confused. How could i create it like the example of figure below? So far i'm only able to create similar figure but the line does not connected, how to make it connected?</p>

<p><a href=""https://i.stack.imgur.com/ChhCk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ChhCk.png"" alt=""this image""></a></p>

<pre><code>X = np.array(covid.drop(['acc_deceased'],1))
y = np.array(covid['acc_deceased'])

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,
                                                 shuffle = False)

lr = LinearRegression()

lr.fit(X_train,y_train)

y_pred = lr.predict(X_test)

pred = pd.DataFrame(y_pred, columns = ['y_pred'])
train = pd.DataFrame(y_train,columns = ['y_train'])
final = pd.concat([train,pred],ignore_index=True,sort=False)
final = final.set_index(covid.index)
plt.figure(figsize=(10,5))
sns.lineplot(x=final.index, y=final['y_train'])
sns.lineplot(x=final.index, y=final['y_pred'])
plt.legend(['y_train','y_pred','y_test'],
            loc='upper left')
plt.ylabel('y')
</code></pre>

<p>This is my figure</p>

<p><a href=""https://i.stack.imgur.com/73W9b.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/73W9b.png"" alt=""my figure""></a></p>
"
61347803,"<p>I'm learning about data scraping in python using tweepy and I ran on a syntax error with my code. I think I'm missing something, but it looks fine to me? Any help is appreciated. Thank you</p>

<pre><code>twitterStream = Stream(auth, MyStreamListener('COVID', 'COVID-19', 'COVID19', 'NCR', 'Manila', 'Metro Manila', 'Coronavirus', 'Cases'))

twitterStream.filter(track=['COVID', 'COVID-19', 'COVID19', 'NCR', 'Manila', 'Metro Manila', 'Coronavirus', 'Cases'], async=True)
</code></pre>

<p>The last line of the code is where I'm getting the error. </p>

<p>Here's a link to view the whole code: <a href=""https://paste.ofcode.org/?edit=bvg8wTJsTymfJhLgaytktD"" rel=""nofollow noreferrer"">https://paste.ofcode.org/?edit=bvg8wTJsTymfJhLgaytktD</a></p>
"
60922750,"<p>I new to python, selenium, pycharm and such.</p>

<p>I'm trying to print the value of a  on a website ( at the moment of writing this the value is <strong>6320</strong> ).The code is not giving errors but it's printing nothing.</p>

<p>As you can see in the screenshot, when i'm debugging and hovering over the variable, it's displaying <strong>6320</strong>, which is the value i'm looking for.</p>

<p>What am I doing wrong?</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support.expected_conditions import presence_of_element_located

# This example requires Selenium WebDriver 3.13 or newer
with webdriver.Chrome() as driver:
    wait = WebDriverWait(driver, 10)
    driver.get(""https://ici.radio-canada.ca/info/2020/coronavirus-covid-19-pandemie-cas-carte-maladie-symptomes-propagation/"")

    driver.implicitly_wait(5)

    items = driver.find_element_by_xpath('//*[@id=""app""]/div[2]/div[3]/div[3]/div[1]/table/tbody/tr[2]/td[1]/span[2]').text


    print(items)
    print(""hello"")
</code></pre>

<p><a href=""https://i.stack.imgur.com/joYNf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/joYNf.png"" alt=""enter image description here""></a></p>

<p>Thanks a lot for your help!</p>
"
60815772,"<p>I would need to extract some numbers from following table:</p>

<p><a href=""https://datahub.io/core/covid-19/r/1.html"" rel=""nofollow noreferrer"">COVID-19 table</a></p>

<p>I need to display it as a supporting table in Tableau. I know I can download it as an .csv, import it in SQL/Tableau and then display it in Tableau but that is too much effort for what I need. Ideally I would like to display/filter directly from Tableau as an iframe or something. Is it possible to filter the data somehow by adding some attributes to the URL address?</p>

<p>Is this somehow possible, I don't know anything about R?</p>

<p>The whole purpose is to not download manually a csv file to have the workbook updated. This would be the easiest way. Do you have any other idea how to get this table to Tableau easily?</p>

<p>Thank you!</p>
"
61024608,"<p>I am trying to develop a Shinyapp for modeling the COVID-19 illness, but I can't find the error when I try to publish it. In R, the code is running OK and everything is correctly shown, but when I try to publish, an error is shown in the part where the plot should be: ""An error has occurred. Check your logs or contact the app author for clarification."" 
I'm trying to use Prophet package. I'm new with this package and this is my first app, so I will appreciate your help...</p>

<p>The logs:</p>

<pre><code>2020-04-04T06:19:59.741057+00:00 shinyapps[2055422]: Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.
2020-04-04T06:19:59.794156+00:00 shinyapps[2055422]: Compiling model (this will take a few minutes...)
2020-04-04T06:19:59.794607+00:00 shinyapps[2055422]: If this is the first time fitting a model since package install, this is normal. You should not see this message more than once after install.
2020-04-04T06:19:59.795419+00:00 shinyapps[2055422]: Writing model to: /opt/R/3.6.3/lib/R/library/prophet/libs
2020-04-04T06:19:59.795868+00:00 shinyapps[2055422]: Compiling using binary: /opt/R/3.6.3/lib/R/bin
2020-04-04T06:20:26.545815+00:00 shinyapps[2055422]: Warning in system(cmd, intern = !verbose) :
2020-04-04T06:20:26.545817+00:00 shinyapps[2055422]:   comando ejecutado '/opt/R/3.6.3/lib/R/bin/R CMD SHLIB file10a8c62e87.cpp 2&gt; file10a8c62e87.cpp.err.txt' tiene estatus 1
2020-04-04T06:20:26.602133+00:00 shinyapps[2055422]: Warning: Error in sink: conexión inválida
2020-04-04T06:20:26.610392+00:00 shinyapps[2055422]:   185: sink
2020-04-04T06:20:26.610394+00:00 shinyapps[2055422]:   184: cxxfunctionplus
2020-04-04T06:20:26.610395+00:00 shinyapps[2055422]:   182: compile_stan_model
2020-04-04T06:20:26.610394+00:00 shinyapps[2055422]:   183: rstan::stan_model
2020-04-04T06:20:26.610395+00:00 shinyapps[2055422]:   181: fit.prophet
2020-04-04T06:20:26.610396+00:00 shinyapps[2055422]:   179: renderPlot [/srv/connect/apps/COVID19-Mexico/app.R#131]
2020-04-04T06:20:26.610396+00:00 shinyapps[2055422]:   177: fund
2020-04-04T06:20:26.610419+00:00 shinyapps[2055422]:   137: drawPlot
2020-04-04T06:20:26.610420+00:00 shinyapps[2055422]:   123: &lt;reactive:plotObj&gt;
2020-04-04T06:20:26.610420+00:00 shinyapps[2055422]:   107: drawReactive
2020-04-04T06:20:26.610421+00:00 shinyapps[2055422]:    94: origRenderFunc
2020-04-04T06:20:26.610421+00:00 shinyapps[2055422]:    93: output$timeplot
2020-04-04T06:20:26.610421+00:00 shinyapps[2055422]:    13: runApp
2020-04-04T06:20:26.610422+00:00 shinyapps[2055422]:     6: eval
2020-04-04T06:20:26.610422+00:00 shinyapps[2055422]:    12: fn
2020-04-04T06:20:26.610423+00:00 shinyapps[2055422]:     5: eval
2020-04-04T06:20:26.771701+00:00 shinyapps[2055422]: Disabling yearly seasonality. Run prophet with yearly.seasonality=TRUE to override this.
2020-04-04T06:20:26.610395+00:00 shinyapps[2055422]:   180: prophet
2020-04-04T06:20:26.610422+00:00 shinyapps[2055422]:     7: connect$retry
2020-04-04T06:20:26.772159+00:00 shinyapps[2055422]: Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this.
2020-04-04T06:20:26.883191+00:00 shinyapps[2055422]: Compiling model (this will take a few minutes...)
2020-04-04T06:20:26.883501+00:00 shinyapps[2055422]: If this is the first time fitting a model since package install, this is normal. You should not see this message more than once after install.
2020-04-04T06:20:26.884052+00:00 shinyapps[2055422]: Writing model to: /opt/R/3.6.3/lib/R/library/prophet/libs
2020-04-04T06:20:26.884384+00:00 shinyapps[2055422]: Compiling using binary: /opt/R/3.6.3/lib/R/bin
2020-04-04T06:20:56.818503+00:00 shinyapps[2055422]: Warning in system(cmd, intern = !verbose) :
2020-04-04T06:20:56.818505+00:00 shinyapps[2055422]:   comando ejecutado '/opt/R/3.6.3/lib/R/bin/R CMD SHLIB file10a4e80f688.cpp 2&gt; file10a4e80f688.cpp.err.txt' tiene estatus 1
2020-04-04T06:20:56.867650+00:00 shinyapps[2055422]: Warning: Error in sink: conexión inválida
2020-04-04T06:20:56.872694+00:00 shinyapps[2055422]:   115: sink
2020-04-04T06:20:56.872694+00:00 shinyapps[2055422]:   114: cxxfunctionplus
2020-04-04T06:20:56.872695+00:00 shinyapps[2055422]:   113: rstan::stan_model
2020-04-04T06:20:56.872695+00:00 shinyapps[2055422]:   112: compile_stan_model
2020-04-04T06:20:56.872695+00:00 shinyapps[2055422]:   111: fit.prophet
2020-04-04T06:20:56.872696+00:00 shinyapps[2055422]:   110: prophet
2020-04-04T06:20:56.872696+00:00 shinyapps[2055422]:   109: compute_data [/srv/connect/apps/COVID19-Mexico/app.R#221]
2020-04-04T06:20:56.872697+00:00 shinyapps[2055422]:   108: renderTable [/srv/connect/apps/COVID19-    Mexico/app.R#272]
2020-04-04T06:20:56.872707+00:00 shinyapps[2055422]:   107: fund
2020-04-04T06:20:56.872707+00:00 shinyapps[2055422]:    94: origRenderFunc
2020-04-04T06:20:56.872707+00:00 shinyapps[2055422]:    93: output$table
2020-04-04T06:20:56.872708+00:00 shinyapps[2055422]:    13: runApp
2020-04-04T06:20:56.872708+00:00 shinyapps[2055422]:    12: fn
2020-04-04T06:20:56.872709+00:00 shinyapps[2055422]:     7: connect$retry
2020-04-04T06:20:56.872709+00:00 shinyapps[2055422]:     6: eval
2020-04-04T06:20:56.872709+00:00 shinyapps[2055422]:     5: eval
</code></pre>

<p>Any advice or another way to publish this app? Thanks
download the <a href=""https://mega.nz/file/jkhU0KZZ#QzgxKDVArc9uIdTk9Usfzl5RLrzpULDqC441ci9RF0I"" rel=""nofollow noreferrer"">script</a> </p>

<blockquote>
  <p>Blockquote</p>
</blockquote>
"
60790039,"<p>To allow sales people to meet clients in the COVID19 era without travelling, busienss wants to create a virtual meeting room .
The clients will get Oculus Quest as Hololens is hard to procure right now where as business wants to use Hololens on their end. </p>

<p>Will an application /experience created for Hololens using Unity work as is on Oculus Quest or does it make sense to have the same device on both end?</p>

<p>I am new to this area, so not sure if this question makes sense, but is it something like developing 2 versions of code, one for iOS and one or Android and using something like Xamarin to make the process easy ?</p>

<p>Does Unity have features to make applications compatible between Hololens and Oculus Quest ?</p>
"
60609262,"<p>I am trying to build an app to implement the 'Sign in With Apple' feature on a flutter application. It says Xcode has found an error but there is no error text. I have tried to run 'flutter clean' and 'flutter build ios' nothing is helping and I cannot find my question elsewhere. The firebase auth has been downgraded to an older version because the most updated and recent versions do not work at all. I am quite new at this so I am all ears on doing what I can to help fix this error.</p>

<pre><code>import 'dart:io';
import 'package:device_info/device_info.dart';
import 'package:firebase_auth/firebase_auth.dart';
import 'package:flutter/material.dart';
import 'package:apple_sign_in/apple_sign_in.dart';
import 'package:cloud_firestore/cloud_firestore.dart';


void main() =&gt; runApp(MyApp());

class MyApp extends StatefulWidget {
 @override
 _MyAppState createState() =&gt; _MyAppState();
}

class _MyAppState extends State&lt;MyApp&gt; {
 @override
 Widget build(BuildContext context) {
   return MaterialApp(
     debugShowCheckedModeBanner: false,
     home: DiningHalls(),
   );
 }
}

class DiningHalls extends StatefulWidget {
 @override
 _DiningHallsState createState() =&gt; _DiningHallsState();
}

class _DiningHallsState extends State&lt;DiningHalls&gt; {
 @override

 bool supportsAppleSignIn = false;

 void initState() {
   // TODO: implement initState

   Firestore.instance.collection('FitTracker').document();

   super.initState();
   checkDevice();

}

checkDevice()async{
 if (Platform.isIOS) {
 var iosInfo = await DeviceInfoPlugin().iosInfo;
 var version = iosInfo.systemVersion;

 if (version.contains('13') == true) {
   supportsAppleSignIn = true;
 }
}
}



 @override
 Widget build(BuildContext context) {
   return Scaffold(
     body: Center(child: Column(
       children: &lt;Widget&gt;[
         Text(""COVID-19""),
         Container(
 height: 300 / 15,
 width: 300 / 1.5,
 child: AppleSignInButton(
   style: ButtonStyle.black,
   type: ButtonType.continueButton,
   onPressed: () {
     initiateSignInWithApple();
         },
       ),
     )
             ],
           )),
         );
       }
     }

     void initiateSignInWithApple() async{
       final AuthorizationResult result = await AppleSignIn.performRequests([
 AppleIdRequest(requestedScopes: [Scope.email, Scope.fullName])
]);

       switch (result.status) {
 case AuthorizationStatus.authorized:

  // here we're going to sign in the user within firebase
  break;
 case AuthorizationStatus.error:
   // do something
   break;

 case AuthorizationStatus.cancelled:
   print('User cancelled');
   break;
}
      print(""successfull sign in"");
final AppleIdCredential appleIdCredential = result.credential;

OAuthProvider oAuthProvider =
   new OAuthProvider(providerId: ""apple.com"");
final AuthCredential credential = oAuthProvider.getCredential(
 idToken:
     String.fromCharCodes(appleIdCredential.identityToken),
 accessToken:
     String.fromCharCodes(appleIdCredential.authorizationCode),
);

final AuthResult res = await FirebaseAuth.instance
   .signInWithCredential(credential);

FirebaseAuth.instance.currentUser().then((val) async {
 UserUpdateInfo updateUser = UserUpdateInfo();
 updateUser.displayName =
     ""${appleIdCredential.fullName.givenName} ${appleIdCredential.fullName.familyName}"";
 updateUser.photoUrl =
     ""define a photo url here""; 
 await val.updateProfile(updateUser);
});
}
</code></pre>
"
61711600,"<p>I am learning flutter and trying to parse a JSON just like in this <a href=""https://medium.com/@vipinvijayan23/easily-parse-complex-json-create-json-model-classes-show-in-listview-e087ecdee988"" rel=""nofollow noreferrer"">article</a>, but getting this error.</p>

<blockquote>
  <p>lib/service/apiservice.dart:11:33: Error: A value of type 'Data' can't
  be assigned to a variable of type 'List'.
   - 'Data' is from 'package:gocorona/models/totals.dart' ('lib/models/totals.dart').
   - 'List' is from 'dart:core'.
          final List data = dataFromJson(response.body);</p>
</blockquote>

<p><strong>lib/service/apiservice.dart</strong></p>

<pre><code>import 'package:http/http.dart' as http;
import 'package:gocorona/models/totals.dart';

class ApiServices {

  static const String url = 'https://api.rootnet.in/covid19-in/stats/latest';
static Future&lt;List&lt;Data&gt;&gt; getDataFromAPI() async {
    try {
      final response = await http.get(url);
      if (200 == response.statusCode) {
        final List&lt;Data&gt; data = dataFromJson(response.body);
        return data;
      } else {
        return List&lt;Data&gt;();
      }
    } catch (e) {
      return List&lt;Data&gt;();
    }
  }
}
</code></pre>

<p><strong>lib/models/totals.dart</strong></p>

<pre><code>import 'dart:convert';

Data dataFromJson(String str) =&gt; Data.fromJson(json.decode(str));

String dataToJson(Data data) =&gt; json.encode(data.toJson());

class Data {
    bool success;
    DataClass data;
    DateTime lastRefreshed;
    DateTime lastOriginUpdate;

    Data({
        this.success,
        this.data,
        this.lastRefreshed,
        this.lastOriginUpdate,
    });

    factory Data.fromJson(Map&lt;String, dynamic&gt; json) =&gt; Data(
        success: json[""success""],
        data: DataClass.fromJson(json[""data""]),
        lastRefreshed: DateTime.parse(json[""lastRefreshed""]),
        lastOriginUpdate: DateTime.parse(json[""lastOriginUpdate""]),
    );

    Map&lt;String, dynamic&gt; toJson() =&gt; {
        ""success"": success,
        ""data"": data.toJson(),
        ""lastRefreshed"": lastRefreshed.toIso8601String(),
        ""lastOriginUpdate"": lastOriginUpdate.toIso8601String(),
    };
}

class DataClass {
    Summary summary;
    List&lt;UnofficialSummary&gt; unofficialSummary;
    List&lt;Regional&gt; regional;

    DataClass({
        this.summary,
        this.unofficialSummary,
        this.regional,
    });

    factory DataClass.fromJson(Map&lt;String, dynamic&gt; json) =&gt; DataClass(
        summary: Summary.fromJson(json[""summary""]),
        unofficialSummary: List&lt;UnofficialSummary&gt;.from(json[""unofficial-summary""].map((x) =&gt; UnofficialSummary.fromJson(x))),
        regional: List&lt;Regional&gt;.from(json[""regional""].map((x) =&gt; Regional.fromJson(x))),
    );

    Map&lt;String, dynamic&gt; toJson() =&gt; {
        ""summary"": summary.toJson(),
        ""unofficial-summary"": List&lt;dynamic&gt;.from(unofficialSummary.map((x) =&gt; x.toJson())),
        ""regional"": List&lt;dynamic&gt;.from(regional.map((x) =&gt; x.toJson())),
    };
}

class Regional {
    String loc;
    int confirmedCasesIndian;
    int discharged;
    int deaths;
    int confirmedCasesForeign;
    int totalConfirmed;

    Regional({
        this.loc,
        this.confirmedCasesIndian,
        this.discharged,
        this.deaths,
        this.confirmedCasesForeign,
        this.totalConfirmed,
    });

    factory Regional.fromJson(Map&lt;String, dynamic&gt; json) =&gt; Regional(
        loc: json[""loc""],
        confirmedCasesIndian: json[""confirmedCasesIndian""],
        discharged: json[""discharged""],
        deaths: json[""deaths""],
        confirmedCasesForeign: json[""confirmedCasesForeign""],
        totalConfirmed: json[""totalConfirmed""],
    );

    Map&lt;String, dynamic&gt; toJson() =&gt; {
        ""loc"": loc,
        ""confirmedCasesIndian"": confirmedCasesIndian,
        ""discharged"": discharged,
        ""deaths"": deaths,
        ""confirmedCasesForeign"": confirmedCasesForeign,
        ""totalConfirmed"": totalConfirmed,
    };
}

class Summary {
    int total;
    int confirmedCasesIndian;
    int confirmedCasesForeign;
    int discharged;
    int deaths;
    int confirmedButLocationUnidentified;

    Summary({
        this.total,
        this.confirmedCasesIndian,
        this.confirmedCasesForeign,
        this.discharged,
        this.deaths,
        this.confirmedButLocationUnidentified,
    });

    factory Summary.fromJson(Map&lt;String, dynamic&gt; json) =&gt; Summary(
        total: json[""total""],
        confirmedCasesIndian: json[""confirmedCasesIndian""],
        confirmedCasesForeign: json[""confirmedCasesForeign""],
        discharged: json[""discharged""],
        deaths: json[""deaths""],
        confirmedButLocationUnidentified: json[""confirmedButLocationUnidentified""],
    );

    Map&lt;String, dynamic&gt; toJson() =&gt; {
        ""total"": total,
        ""confirmedCasesIndian"": confirmedCasesIndian,
        ""confirmedCasesForeign"": confirmedCasesForeign,
        ""discharged"": discharged,
        ""deaths"": deaths,
        ""confirmedButLocationUnidentified"": confirmedButLocationUnidentified,
    };
}

class UnofficialSummary {
    String source;
    int total;
    int recovered;
    int deaths;
    int active;

    UnofficialSummary({
        this.source,
        this.total,
        this.recovered,
        this.deaths,
        this.active,
    });

    factory UnofficialSummary.fromJson(Map&lt;String, dynamic&gt; json) =&gt; UnofficialSummary(
        source: json[""source""],
        total: json[""total""],
        recovered: json[""recovered""],
        deaths: json[""deaths""],
        active: json[""active""],
    );

    Map&lt;String, dynamic&gt; toJson() =&gt; {
        ""source"": source,
        ""total"": total,
        ""recovered"": recovered,
        ""deaths"": deaths,
        ""active"": active,
    };
}
</code></pre>

<p><strong>lib/screens/states.dart</strong></p>

<pre><code>import 'package:flutter/material.dart';
import 'package:gocorona/models/totals.dart';
import 'package:gocorona/service/apiservice.dart';

class Statewise extends StatefulWidget {
  @override
  _StatewiseState createState() =&gt; _StatewiseState();
}

class _StatewiseState extends State&lt;Statewise&gt; {
  List&lt;Data&gt; _datafromApi;
  bool _isloading;

  @override
  void initState() {
    super.initState();

    _isloading = true;
    ApiServices.getDataFromAPI().then((data) {
      setState(() {
        _datafromApi = data;
        _isloading = false;
      });
    });
  }

  @override
  Widget build(BuildContext context) {
    if (_isloading) {
      return Container(
        child: Center(
          child: CircularProgressIndicator(),
        ),
      );
    } else {
      return Scaffold(
        body: ListView.builder(
            itemCount: _datafromApi == null ? 0 : _datafromApi.length,
            itemBuilder: (context, index) {
              Data datas = _datafromApi[index];
              print(datas?.toString() ?? ""Empty"");
              return ListTile(
                  title: Text(
                datas.data.regional[0].loc.toString(),
                style: TextStyle(color: Colors.black),
              ));
            }),
      );
    }
  }
}

</code></pre>

<p><strong>Compiler message:</strong></p>

<pre><code>lib/service/apiservice.dart:11:33: Error: A value of type 'Data' can't be assigned to a variable of type 'List&lt;Data&gt;'.
 - 'Data' is from 'package:gocorona/models/totals.dart' ('lib/models/totals.dart').
 - 'List' is from 'dart:core'.
        final List&lt;Data&gt; data = dataFromJson(response.body);
                                ^
</code></pre>

<p><strong>flutter doctor</strong></p>

<pre><code>Doctor summary (to see all details, run flutter doctor -v):
[√] Flutter (Channel stable, v1.17.0, on Microsoft Windows [Version 10.0.18362.778], locale en-IN)

[√] Android toolchain - develop for Android devices (Android SDK version 29.0.3)
[√] Android Studio (version 3.6)
[√] VS Code (version 1.45.0)
[√] Connected device (1 available)

• No issues found!

</code></pre>
"
60992586,"<p>I am trying to get data from an API <a href=""https://rapidapi.com/KishCom/api/covid-19-coronavirus-statistics/endpoints"" rel=""nofollow noreferrer"">here</a>. The sample data in the endpoint looks like: </p>

<pre><code>`{4 items
""error"":false
""statusCode"":200
""message"":""OK""
""data"":{2 items
""lastChecked"":""2020-04-02T11:49:38.233Z""
""covid19Stats"":[15 items
0:{8 items
""city"":""""
""province"":""Alberta""
""country"":""Canada""
""lastUpdate"":""2020-04-01 22:04:44""
""keyId"":""Alberta, Canada""
""confirmed"":754
""deaths"":9
""recovered"":0
}
1:{...}8 items
2:{...}8 items
3:{...}8 items
4:{...}8 items
5:{...}8 items
6:{...}8 items
7:{...}8 items
8:{...}8 items
9:{...}8 items
10:{...}8 items
11:{...}8 items
12:{...}8 items
13:{...}8 items
14:{...}8 items
]
}
}`
</code></pre>

<p>I am trying to map this data to the <code>CovidData</code> class in the following code:</p>

<pre><code>import 'dart:convert';

import 'package:flutter/material.dart';
import 'package:http/http.dart' as http;

class StatusPage extends StatefulWidget{
  @override
  State&lt;StatefulWidget&gt; createState() {
    return StatusPageState();
  }
}

class StatusPageState extends State&lt;StatusPage&gt;{
  @override
  void initState() {
    super.initState();
    fetch();
  }
  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: Center(
          child: Text(
            ""COVID-19 Stats"",
            style: TextStyle(
                color: Colors.white,
                fontFamily: 'Montserrat',
                fontWeight: FontWeight.bold),
          ),
        ),
      ),
      body: Container(
        child: FlatButton(onPressed: () =&gt; show(), child: Text(""Fetch"")),
      ),
  );
  } 

fetch(){
  API.getStats().then(
    (response) =&gt; {
      lists = json.decode(response.body),
      countries = lists.map((model) =&gt; CovidData.fromJson(model)).toList(), 
      // print(json.decode(response.body)['data']['covid19Stats'][0])
    }
  );
  setState(() {

  });
}
}

class CovidData{
  String city = """";
  String province = """";
  String country = """";
  String lastUpdate = """";
  String keyId = """";
  int confirmed = 0;
  int deaths = 0;
  int recovered = 0;

  CovidData(String city, String province, String country, String lastUpdate, String keyId, int confirmed, int deaths, int recovered){
    this.city = city;
    this.province = province;
    this.country = country;
    this.lastUpdate = lastUpdate;
    this.keyId = keyId;
    this.confirmed = confirmed;
    this.deaths = deaths;
    this.recovered = recovered;
  }

  CovidData.fromJson(Map json)
  : city = json['city'],
    province = json['province'],
    country = json['country'],
    lastUpdate = json['lastUpdate'],
    keyId = json['keyId'],
    confirmed = json['confirmed'],
    deaths = json['deaths'],
    recovered = json['recovered'];

  Iterable toJson(){
    return [
      {'city': city},
      {'province': province},
      {'country': country},
      {'lastUpdate': lastUpdate},
      {'keyId': keyId},
      {'confirmed': confirmed},
      {'deaths': deaths},
      {'recovered': recovered},
    ];
  }
}

List&lt;CovidData&gt; countries = [];
Iterable lists;

show(){
  print(countries);
}


const baseUrl = ""https://covid-19-coronavirus-statistics.p.rapidapi.com/v1/stats"";

class API {
  static Future getStats(){
    return http.get(baseUrl, headers: {
      ""x-rapidapi-host"": ""covid-19-coronavirus-statistics.p.rapidapi.com"",
      ""x-rapidapi-key"": ""8ca140a965mshe408a2e58737ba5p14b104jsn19a57561ec85""
    });
  }
}
</code></pre>

<p>When I navigate to this page I get the following exception:</p>

<pre><code>[ERROR:flutter/lib/ui/ui_dart_state.cc(157)] Unhandled Exception: type '_InternalLinkedHashMap&lt;String, dynamic&gt;' is not a subtype of type 'Iterable&lt;dynamic&gt;
</code></pre>

<p>I am new with APIs so I don't know how to solve this problem. Any help would be appreciate. Thanks.</p>
"
60646627,"<p>I am trying to get the image link from <a href=""https://www.wired.com/feed/"" rel=""nofollow noreferrer"">https://www.wired.com/feed/</a>.
I am looking for something like that:</p>

<pre><code>NodeList mNodeList = mDocument.getElementsByTagName(""item"");

for(int i = 0; i &lt; mNodeList.getLength(); i++){
    Element element = (Element) mNodeList.item(i);

    NodeList nodeListCreator = element.getElementsByTagName(""dc:creator"");
    NodeList nodeListMedia = element.getElementsByTagName(""media:thumbnail"");

    String creator = nodeListCreator.item(0).getFirstChild().getNodeValue();
    String media = nodeListMedia.item(0).getFirstChild().getNodeValue();
}
</code></pre>

<p>media is causing a NullPointerException. I couldn't find a quick way to solve my problem. I have tried something like:</p>

<pre><code>Element elementMedia = (Element) nodeListMedia.item(i); 
String media = elementMedia.getAttribute(""url"");
</code></pre>

<p>Codes above also don't work.</p>

<p>Here is one item from the address above:</p>

<pre><code>&lt;item&gt;
&lt;title&gt;
Is It Ethically OK to Order Delivery During a Pandemic?
&lt;/title&gt;
&lt;link&gt;
https://www.wired.com/story/coronavirus-food-delivery-gig-economy
&lt;/link&gt;
&lt;guid isPermaLink=""false""&gt;5e66714857f1520008d314fb&lt;/guid&gt;
&lt;pubDate&gt;Wed, 11 Mar 2020 19:56:04 +0000&lt;/pubDate&gt;
&lt;media:content/&gt;
&lt;description&gt;
People are being encouraged to stay home to avoid exposure to the coronavirus. Should they ask others to bring them food?
&lt;/description&gt;
&lt;category&gt;Culture&lt;/category&gt;
&lt;category&gt;Culture / Digital Culture&lt;/category&gt;
&lt;media:keywords&gt;coronavirus, gig economy, COVID-19&lt;/media:keywords&gt;
&lt;dc:creator&gt;Arielle Pardes&lt;/dc:creator&gt;
&lt;dc:modified&gt;Wed, 11 Mar 2020 22:36:50 +0000&lt;/dc:modified&gt;
&lt;dc:publisher&gt;Condé Nast&lt;/dc:publisher&gt;
&lt;media:thumbnail url=""https://media.wired.com/photos/5e66824d7ae91d000803583f/master/pass/Cul-fooddelivery-1190668088.jpg"" width=""2400"" height=""1600""/&gt;
&lt;/item&gt;
</code></pre>

<p>How to get this: ""<a href=""https://media.wired.com/photos/5e66824d7ae91d000803583f/master/pass/Cul-fooddelivery-1190668088.jpg"" rel=""nofollow noreferrer"">https://media.wired.com/photos/5e66824d7ae91d000803583f/master/pass/Cul-fooddelivery-1190668088.jpg</a>""</p>

<p>I am not familiar with xml services. 
I hope you help.    </p>
"
61549004,"<p>I don't understand clearly why Row component rendered 8 times. Should I use custom comparing function in React Memo for this component? I'm using the <a href=""https://www.npmjs.com/package/react-window"" rel=""nofollow noreferrer"">react-window</a> package. Please explain how it works for me. Thanks a lot.</p>

<p>Parent component of ListView: <a href=""https://github.com/quangkhaidam93/1653033-covid19-map/blob/master/src/components/covid-map/CovidMap.js"" rel=""nofollow noreferrer"">CovidMap Component</a></p>

<p>My entire project: <a href=""https://github.com/quangkhaidam93/1653033-covid19-map"" rel=""nofollow noreferrer"">Github</a></p>

<p>This is my code:</p>

<pre><code>import React, { useRef, memo, useEffect } from 'react';
import { FixedSizeList as FixedList, areEqual } from 'react-window';
import './ListView.scss';

const ListView = (props) =&gt; {
  const listRef = useRef();

  const Row = memo((props) =&gt; {
    console.log('Row rendering...');
    const { data, index, style } = props;
    const className =
      data.itemIndex === index
        ? 'PatienIndicator Highlight'
        : 'PatientIndicator';
    return (
      &lt;button
        key={index}
        className={className}
        onClick={() =&gt; data.onClickPatient(data.patients[index])}
        style={style}
      &gt;
        {data.patients[index].name}
      &lt;/button&gt;
    );
  }, areEqual);

  const patientsLength = props.patients
    ? Object.keys(props.patients).length
    : 0;

  const data = Object.assign(
    {},
    { patients: props.patients },
    { onClickPatient: props.onClickPatient },
    { itemIndex: props.itemIndex }
  );

  console.log('List View rendering...');

  useEffect(() =&gt; {
    if (props.itemIndex) {
      listRef.current.scrollToItem(props.itemIndex, 'smarter');
    }
  });

  return (
    &lt;FixedList
      className=""List""
      height={300}
      itemCount={patientsLength}
      itemSize={50}
      width={'100%'}
      ref={listRef}
      itemData={data}
    &gt;
      {Row}
    &lt;/FixedList&gt;
  );
};

export default memo(ListView);
</code></pre>
"
61504017,"<p>I have a nested json like this:</p>

<pre><code>(47) [{…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}, {…}]
0:
day: ""2020-03-14""
total:
confirmed: 81
recovered: 9
deaths: 2
active: 70
__proto__: Object
statewise: Array(37)
0:
state: ""Andaman and Nicobar Islands""
confirmed: 0
recovered: 0
deaths: 0
active: 0
__proto__: Object
1: {state: ""Andhra Pradesh"", confirmed: 1, recovered: 0, deaths: 0, active: 1}
.......
</code></pre>

<p><a href=""https://i.stack.imgur.com/n9tER.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/n9tER.png"" alt=""enter image description here""></a></p>

<p>Structure is like this:</p>

<pre><code>&lt;array consiting daywise data&gt;
    day
    total
     -confirmed
     -recovered
     -deaths
     -active
    statewise
       &lt;array defining states having below items&gt;
           - state
           - confirmed
           - recovered
           - deaths
</code></pre>

<p>Thing is, I want to make a line graph showing total cases(confirmed) trend with dates for states like this:</p>

<p><a href=""https://i.stack.imgur.com/AdzTr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AdzTr.png"" alt=""enter image description here""></a></p>

<p><strong>code:</strong></p>

<pre><code>  &lt;script src=""https://d3js.org/d3.v5.min.js""&gt;&lt;/script&gt;
    &lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/crossfilter/1.3.7/crossfilter.js""&gt;&lt;/script&gt;
    &lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js""&gt;&lt;/script&gt;
    &lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/dc/3.2.1/dc.js""&gt;&lt;/script&gt;
    &lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/reductio/1.0.0/reductio.js""&gt;&lt;/script&gt;

 &lt;script&gt;

  const cases_chart = dc.lineChart(""#line-chart"");
  var log = console.log; 
  d3.json('https://api.rootnet.in/covid19-in/unofficial/covid19india.org/statewise/history').then(function(json_data) {
  var data = json_data.data.history;
  log(""=====&gt;"", data);

    cf = crossfilter(data); // Main crossfilter objects
    var cases_bar_d = cf.dimension(function(d) { 
      console.log('----------------------&gt;',new Date(d.day));
      return d.day});

    var cases_bar_g = cases_bar_d.group().reduceSum(function(d){ 
      log(""statewise:"", d.statewise);

      return d.statewise});
   });
&lt;/script&gt;
</code></pre>

<p>Actually there are 37 items in state and I know how to solve this solution. I have to create a composite chart. But creating 37 groups and then feed them to composite chart will be a lengthy process. Is there any other way of solving this?  I can create groups individually by returning <code>d.statewise[0].confirmed,.....d.statewise[36].confirmed</code></p>

<p>I want to make this <code>cases_bar_g</code> to be like this:</p>

<pre><code>{key: &lt;date&gt;, &lt;state_name1&gt;: &lt;confirmed1&gt;, .....&lt;state_name36&gt;: &lt;confirmed36&gt; }
</code></pre>

<p>Then It will be easier to create a chart.</p>

<h1>Edit1:</h1>

<p>Seems like I found a <a href=""https://stackoverflow.com/questions/48649766/dc-js-flatten-data-vs-array-of-objects-and-filtering"">similar</a> question with the same nested pattern. But having hard time to implement it as a line chart.</p>

<h1>Edit2:</h1>

<p>I managed to flatten the array using for state confirmed cases. </p>

<pre><code>    data.forEach(function(d,i){

      log(""!!!!"", i);

      for (var j=0; j&lt;d.statewise.length;j++)
      {
          log(""@@@:"",map_state[d.statewise[j].state],d.statewise[j].state , d.statewise[j].confirmed);

         d[map_state[d.statewise[j].state]] = d.statewise[j].confirmed;
     }
   });
</code></pre>

<p>It look like this now:
<a href=""https://i.stack.imgur.com/GSOYr.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GSOYr.png"" alt=""enter image description here""></a></p>

<p>Although now I can access the element directly to plot it. But I think this is not a good approach. I should have done it via dimension and group concept.</p>
"
61210890,"<p>I am relatively new to react and wanted to know how I could rewrite this code in order for it to be dry. as you can see the cardcontent and typography is pretty much the same, but the only difference is the <code>&lt;Typography color=""textSecondary"" gutterBottom&gt;</code> and <code>&lt;Typography variant=""body2"" component=""p""&gt;</code></p>

<pre><code>  &lt;div className={styles.container}&gt;
      &lt;Grid container spacing={3} justify=""center""&gt;
        &lt;Grid item component={Card} xs={12} md={3} className={cx(styles.card, styles.infected)}&gt;
          &lt;CardContent&gt;
            &lt;Typography color=""textSecondary"" gutterBottom&gt;
              Infected
            &lt;/Typography&gt;
            &lt;Typography variant=""h5"" component=""h2""&gt;
              &lt;CountUp
                start={0}
                end={confirmed.value}
                duration={2.5}
                separator="",""
              /&gt;
            &lt;/Typography&gt;
            &lt;Typography color=""textSecondary""&gt;
              {new Date(lastUpdate).toDateString()}
            &lt;/Typography&gt;
            &lt;Typography variant=""body2"" component=""p""&gt;
              Number of active cases of COVID-19
            &lt;/Typography&gt;
          &lt;/CardContent&gt;
        &lt;/Grid&gt;
        &lt;Grid item component={Card} xs={12} md={3} className={cx(styles.card, styles.recovered)}&gt;
          &lt;CardContent&gt;
            &lt;Typography color=""textSecondary"" gutterBottom&gt;
              Recovered
            &lt;/Typography&gt;
            &lt;Typography variant=""h5"" component=""h2""&gt;
              &lt;CountUp
                start={0}
                end={recovered.value}
                duration={2.75}
                separator="",""
              /&gt;
            &lt;/Typography&gt;
            &lt;Typography color=""textSecondary""&gt;
              {new Date(lastUpdate).toDateString()}
            &lt;/Typography&gt;
            &lt;Typography variant=""body2""&gt;
              Number of recoveries from COVID-19
            &lt;/Typography&gt;
          &lt;/CardContent&gt;
        &lt;/Grid&gt;
        &lt;Grid item component={Card} xs={12} md={3} className={cx(styles.card, styles.deaths)}&gt;
          &lt;CardContent&gt;
            &lt;Typography color=""textSecondary"" gutterBottom&gt;
              Deaths
            &lt;/Typography&gt;
            &lt;Typography variant=""h5"" component=""h2""&gt;
              &lt;CountUp
                start={0}
                end={deaths.value}
                duration={2.75}
                separator="",""
              /&gt;
            &lt;/Typography&gt;
            &lt;Typography color=""textSecondary""&gt;
              {new Date(lastUpdate).toDateString()}
            &lt;/Typography&gt;
            &lt;Typography variant=""body2""&gt;
              Number of deaths caused by COVID-19
            &lt;/Typography&gt;
          &lt;/CardContent&gt;
        &lt;/Grid&gt;
      &lt;/Grid&gt;
    &lt;/div&gt;
</code></pre>
"
61215821,"<p>I implemented an accordion on this page: <a href=""https://www.oct.ca/public/media/announcements/covid-19-news-and-resources"" rel=""nofollow noreferrer"">https://www.oct.ca/public/media/announcements/covid-19-news-and-resources</a></p>

<p>After about 3 seconds of clicking on the accordion item the title disappears.</p>

<p>It looks like something is adding ""opacity: 0"" to the button element.</p>
"
61088015,"<p>I'm trying to create a custom map using Flutter Web that would be capable of displaying custom statistics for a place for COVID-19.</p>

<p>First we'll have a interface that display statistics for our entire planet:
<a href=""https://google.com/covid19-map/?hl=en"" rel=""nofollow noreferrer"">https://google.com/covid19-map/?hl=en</a> (Just like htisw)</p>

<p>Then the user can click on any country to zoom-in with probably an ease-in transition to see the number of cases in each state or province of that country. Assuming that I am able to fetch the exact co-ordinates of the epicenter in that country, I would like to deepen the shade in those parts in such a way that it lightens out as we move towards areas which have a lower number of cases.</p>

<p>Is it possible in Flutter Web?</p>

<p>I came across this plugin (thanks to this thread on SO <a href=""https://stackoverflow.com/questions/51842695/openstreetmap-in-flutter"">Openstreetmap in Flutter?</a>) </p>

<p><a href=""https://pub.dev/packages/flutter_map"" rel=""nofollow noreferrer"">https://pub.dev/packages/flutter_map</a></p>

<p>but it doesn't explicitly say that it supports Flutter Web.</p>

<p>I tried fetching the tiles from OSM(Open Street Map) and displaying the maps on Flutter Web with the help of the example given in the above site <a href=""https://pub.dev/packages/flutter_map#open-street-map-provider"" rel=""nofollow noreferrer"">https://pub.dev/packages/flutter_map#open-street-map-provider</a></p>

<p>But it didn't really display anything, maybe because a certain widget or function didn't work as expected.</p>

<p>According to your experience, which is the best way to achieve what I am looking for? </p>

<p>If possible, please describe the answer in such a way as if you were me and trying to do what I am doing.</p>
"
61284970,"<p>I am developing an android app which shows a list of countries affected by Coronavirus , the total number of confirmed cases and total Deaths. I am using a <code>JSON</code> API to get the data and displaying it using a <code>RecyclerView</code> . The app works fine , and i get a list of all the countries with their respective case counts. I want to add a search option so that the users can filter the list and find a specific country. How do i do that? I am new to programming , if someone could help with this that would be awesome.
Here is the code snippet </p>

<p>MainActivity.java</p>

<pre><code>    private RecyclerView mRecyclerView;
    private Corona_Stats_Adapter mCorona_Stats_Adapter;
    private TextView mErrorDisplay;
    private ProgressBar mProgressBar;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.corona_stats);

        mRecyclerView = (RecyclerView)findViewById(R.id.Corona_stats_recycler);
        mErrorDisplay = (TextView) findViewById(R.id.tv_error_message_display);

        LinearLayoutManager layoutManager = new LinearLayoutManager(this, LinearLayoutManager.VERTICAL, false);
        mRecyclerView.setLayoutManager(layoutManager);
        mRecyclerView.setHasFixedSize(true);
        mCorona_Stats_Adapter = new Corona_Stats_Adapter();
        mRecyclerView.setAdapter(mCorona_Stats_Adapter);
        mProgressBar = (ProgressBar)findViewById(R.id.pb_loading_indicator) ;



        loadCoronaData();

    }

        private void loadCoronaData(){
            showCoronaDataView();
            //String Country = String.valueOf(mSearchQuery.getText());
            new Fetch_data().execute();

        }
        private void showCoronaDataView(){
        mErrorDisplay.setVisibility(View.INVISIBLE);
        mRecyclerView.setVisibility(View.VISIBLE);
        }

        private void showErrorMessage(){
        mRecyclerView.setVisibility(View.INVISIBLE);
        mErrorDisplay.setVisibility(View.VISIBLE);
        }

    public class Fetch_data extends AsyncTask&lt;Void,Void,String[]&gt; {
        @Override
        protected void onPreExecute() {
            super.onPreExecute();
            mProgressBar.setVisibility(View.VISIBLE);
        }



        @Override
        protected String[] doInBackground(Void... voids) {

            URL covidRequestURL = NetworkUtils.buildUrl();


            try {
                String JSONCovidResponse = NetworkUtils.getResponseFromHttpUrl(covidRequestURL);
                String[] simpleJsonCovidData = CovidJSON_Utils.getSimpleStringFromJson(MainActivity.this, JSONCovidResponse);
                return simpleJsonCovidData;
            } catch (IOException | JSONException e) {
                e.printStackTrace();
                return null;
            }



        }

        @Override
        protected void onPostExecute(String[] coronaData) {
            mProgressBar.setVisibility(View.INVISIBLE);
            if(coronaData !=null){
                showCoronaDataView();
                mCorona_Stats_Adapter.setCoronaData(coronaData);
            } else{
                showErrorMessage();
            }

        }
    }
}

</code></pre>

<p>RecyclerView Adapter class Corona_stats_Adapter.java</p>

<pre><code>public class Corona_Stats_Adapter extends RecyclerView.Adapter&lt;Corona_Stats_Adapter.Corona_Stats_AdapterViewHolder&gt;
  {

    private Context context;
   // private List&lt;Country&gt; countryList;
   // private List&lt;Country&gt; countryListFiltered;
    private String[] mCoronaData;
    public Corona_Stats_Adapter(){
    }

    @NonNull
    @Override
    public Corona_Stats_AdapterViewHolder onCreateViewHolder(@NonNull ViewGroup viewGroup, int viewType) {
        Context context = viewGroup.getContext();
        int LayoutIdForListItem =R.layout.corona_stats_list_item;
        LayoutInflater inflater =LayoutInflater.from(context);
        boolean ShouldAttachToParentImmediately = false;

        View view = inflater.inflate(LayoutIdForListItem,viewGroup,ShouldAttachToParentImmediately);
        return new Corona_Stats_AdapterViewHolder(view);
    }

    @Override
    public void onBindViewHolder(@NonNull Corona_Stats_AdapterViewHolder corona_stats_adapterViewHolder, int position) {

        String coronaStats = mCoronaData[position];
        corona_stats_adapterViewHolder.mCoronaTextView.setText(coronaStats);
    }

    @Override
    public int getItemCount() {
        if(null == mCoronaData) return 0;
        return mCoronaData.length;
       // return countryListFiltered.size();
    }

    public class Corona_Stats_AdapterViewHolder extends RecyclerView.ViewHolder {

        public final TextView mCoronaTextView;

        public Corona_Stats_AdapterViewHolder(@NonNull View view) {
            super(view);
            mCoronaTextView = (TextView) view.findViewById(R.id.tv_corona_data);
        }
    }

        public void setCoronaData(String[] coronaData){
            mCoronaData = coronaData;
            notifyDataSetChanged();
        }

}
</code></pre>

<p>Parsing the JSON data in CovidJSON_Utils.java</p>

<pre><code>public final class CovidJSON_Utils {

    public static String[] getSimpleStringFromJson(Context context, String codivJsonString)
    throws JSONException {
    final String COV_COUNTRY = ""Countries"";
    final String COV_CONFIRMED = ""confirmed"";
    final String COV_DEATHS = ""deaths"";
    final String COV_MESSAGE_CODE = ""code"";

        String[] parsedCovidData = null;
        JSONObject covidJsonObject = new JSONObject(codivJsonString);

        if (covidJsonObject.has(COV_MESSAGE_CODE)) {
                int errorCode = covidJsonObject.getInt(COV_MESSAGE_CODE);
                switch (errorCode) {
                    case HttpURLConnection.HTTP_OK:
                        break;
                    case HttpURLConnection.HTTP_NOT_FOUND:
                        return null;
                    default:
                        return null;
                }

            }

            JSONArray countryCovidArray = covidJsonObject.getJSONArray(COV_COUNTRY);


            parsedCovidData = new String[countryCovidArray.length()];
            for (int i = 0; i &lt; countryCovidArray.length(); i++) {

                JSONObject countryJSONObject = countryCovidArray.getJSONObject(i);
                String Country = countryJSONObject.getString(""Country"");
                String Confirmed = String.valueOf(countryJSONObject.getInt(""TotalConfirmed""));
                String Deaths = String.valueOf(countryJSONObject.getInt(""TotalDeaths""));

                parsedCovidData[i] = Country + ""- Cases "" + Confirmed + ""- Deaths "" + Deaths;

            }
            return parsedCovidData;


        }


    }
</code></pre>
"
60867035,"<p>I am importing data from two different websites - <a href=""https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/"" rel=""nofollow noreferrer"">Quebec.ca</a> and <a href=""https://www.ontario.ca/page/2019-novel-coronavirus"" rel=""nofollow noreferrer"">Ontario.ca</a></p>

<p>For Quebec's website, I used the following code to import Quebec's cities' data:</p>

<pre><code>=IMPORTHTML(""https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/"",""table"",1)
</code></pre>

<p><a href=""https://i.stack.imgur.com/HCWT0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HCWT0.png"" alt=""Quebec.ca Result""></a></p>

<p>However, if I do the same with Ontario's website, I get <strong>#N'A</strong> with message ""Imported Content is Empty""</p>

<p>I tried finding out what seems to be the issue by using the following code:</p>

<pre><code>=IMPORTXML(""https://www.ontario.ca/page/2019-novel-coronavirus"", ""//body"")
</code></pre>

<p>and following result came back.</p>

<p><a href=""https://i.stack.imgur.com/WuwtJ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WuwtJ.png"" alt=""Ontario.ca Result""></a></p>

<p>It looks like due to Javascript issue, spreadsheet is unable to import using IMPORTXML and IMPORTHTML. Plus this site is also blocking iframe.</p>

<p>Can anyone provide any alternative approach or solution? Thanks!</p>
"
61562230,"<p>I have the following node.js code when doing a password hash.</p>

<blockquote>
  <p>body.password = covid@19</p>
</blockquote>

<pre><code>salt = ""hello@world""
body.passwordhex = crypto.createHmac('sha256', salt).update(body.password).digest('hex');
</code></pre>

<p>It's giving the following result:</p>

<blockquote>
  <p>5fbbff7f6b4db4df6308c6ad7e8fd5afcea513bb70ca12073c7bec618c6b4959</p>
</blockquote>

<hr>

<p>Now, I am trying to convert this to it's go-lang equivalent and my code is</p>

<blockquote>
  <p>body_password := ""covid@19""</p>
</blockquote>

<pre><code>salt := ""hello@world""

// Create a new HMAC by defining the hash type and the key (as byte array)
h := hmac.New(sha256.New, []byte(key))

// Write Data to it
h.Write([]byte(salt))

// Get result and encode as hexadecimal string
hash := hex.EncodeToString(h.Sum(nil))
</code></pre>

<p>And the go-lang result is</p>

<blockquote>
  <p>9b0cb661fcea1bbfe1fa38912e8610f8c0e4707739021988006368c1ba8da8b7</p>
</blockquote>

<p>What could be wrong on my go-lang code? Was it the digest?</p>
"
61258305,"<p>I am using the following code to to draw a piechart. problem is it is always showing a full circle.I can't able fix it. I am using Data from getJSON and making it array.</p>

<pre><code>google.charts.load(""current"", {packages:[""corechart""]});
google.charts.setOnLoadCallback(drawChart);
function drawChart() {
            $.getJSON(""https://api.covid19india.org/data.json"", function(data){
                $.each(data.statewise, function(key, value){
                    if (value.state == ""Total"") {
                     var data2 = [['Covid19', 'Stats'],
                          ['Active cases',value.active],
                          ['Deaths', value.deaths],
                          ['recovered', value.recovered],];
                          innerDrawChart(data2);  
                    }
                });
            });
    function innerDrawChart(data2) {
      var data = google.visualization.arrayToDataTable(data2);

      var options = {
        width:""350"",
        height:""350"",
        pieHole: 0.5,
        backgroundColor: { fill:""transparent""},
        chartArea:{
        left:10,
        right:10, // !!! works !!!
        bottom:20,  // !!! works !!!
        top:20,
        width:""100%"",
        height:""100%""
        },
        pieSliceTextStyle: {
        color: ""white"",
        },
        legend: {position: ""bottom"", textStyle: {color: ""gray""}},

        pieSliceText: ""none"",
        };

      var chart = new google.visualization.PieChart(document.getElementById('covid19'));
      chart.draw(data, options);
    }
}
</code></pre>

<p>Please any Fix for this or any other way?</p>
"
61684072,"<p>Here is what i am trying to do -</p>

<ol>
<li><p>Send a GET request to the this API <a href=""https://api.covid19india.org/data.json"" rel=""nofollow noreferrer"">https://api.covid19india.org/data.json</a> which returns JSON data</p></li>
<li><p>On my UI of chrome extension i have a button and a div</p></li>
<li><p>Display the JSON data received in div on click of the button</p></li>
</ol>

<p>Code -</p>

<p>manifest.json</p>

<pre><code>{
    ""manifest_version"": 2,

   ""name"": ""Custom Google Homepage"",
    ""description"": ""This extension shows a Google Image search result for the current page"",
    ""version"": ""1.0"",
    ""browser_action"": {
        ""default_popup"": ""popup.html"",
        ""default_title"": ""Click here!""
        },
    ""permissions"":[
        ""tabs"",
        ""https://ajax.googleapis.com/"",
        ""https://api.covid19india.org/*""
    ],
    ""content_scripts"":[
        {
            ""matches"":[
                ""&lt;all_urls&gt;""
            ],
            ""js"":[""content.js""]
        }
    ]
}
</code></pre>

<p>popup.html</p>

<pre><code>&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
&lt;head&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
    &lt;title&gt;Hello&lt;/title&gt;

    &lt;style&gt;
        #link
        {
            width: 70px;
            height: 25px;
        }
        #textt
        {
            width: 450px;
            height: 200px;
        }
    &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;button id=""link""&gt;Extract !&lt;/button&gt;
    &lt;div id=""textt"" style=""color: red; font-family: 'Courier New', Courier, monospace;""&gt;&lt;/div&gt;
&lt;/body&gt;
&lt;script src=""content.js""&gt;&lt;/script&gt;
&lt;/html&gt;
</code></pre>

<p>content.js</p>

<pre><code>fetch('https://api.covid19india.org/data.json').then(r =&gt; r.text()).then(result =&gt; {
    // Result now contains the response text, do what you want...
    result = JSON.parse(result)
    console.log(result[""statewise""])
    //alert(JSON.stringify(result[""statewise""][0]))
    })

    document.addEventListener('DOMContentLoaded', function () {
        var div = document.getElementById('textt');
        var btn = document.getElementById('link');


        btn.addEventListener('click', function() {
            chrome.tabs.getSelected(null, function(tab){
                alert(JSON.stringify(result['statewise'][0]));
            });

            div.innerHTML += JSON.stringify(result['statewise'][0]);
        });
      });

</code></pre>

<p>I am able to console.log data received from JSON, but nothing is displayed when i click the button, where am i going wrong, please help !</p>
"
60800697,"<p>I am creating multiple graphs on the same canvas but I am unable to successfully use the destroy() API to clean up the previous data.</p>

<p><strong>HERE IS MY JS CODE FOR CREATING A CHART</strong></p>

<pre><code>const getCountryDataByMonth = async (country) =&gt; {
document.getElementById('casesGraphHeader').innerHTML = ""Loading...."";
const response = await fetch ('https://cors-anywhere.herokuapp.com/https://pomber.github.io/covid19/timeseries.json');
const data = await response.json();

const reports = await data[country];
var i;
var dateList = [];
var caseByDay = [];
var deathsByDay = [];

for(i = 0; i &lt; reports.length; i++){
  dateList.push(reports[i].date);
  caseByDay.push(reports[i].confirmed);
  deathsByDay.push(reports[i].deaths);
}
//GRAPH FOR TOTAL CASES
var casesOptions = {
  type: 'bar',
  data: {
    labels: dateList,
    datasets: [
        {
          label: 'Total Cases',
          data: caseByDay,
        backgroundColor: '#f49d12',
        borderColor: '#f49d12',
        fill: false,
        borderWidth: 2
        }
        ]
  },
  options: {
    legend: {
         labels: {
             fontSize: 15
         }
     },
    scales: {
        yAxes: [{
        ticks: {
                    reverse: false,
          fontSize: 15
        }
      }],
      xAxes: [{
        ticks: {
          fontSize: 15
        }
      }],
    }
  }
}

var totalCasesChart = document.getElementById('totalCasesContainer').getContext('2d');
new Chart(totalCasesChart, casesOptions);
document.getElementById('casesGraphHeader').innerHTML = ""Total Cases for ""+country;


//GRAPH FOR TOTAL Deaths
var deathOptions = {
  type: 'bar',
  data: {
    labels: dateList,
    datasets: [
        {
          label: 'Total Deaths',
          data: deathsByDay,
        backgroundColor: '#e84c3d',
        borderColor: '#e84c3d',
        fill: false,
        borderWidth: 2
        }
        ]
  },
  options: {
    legend: {
         labels: {
             fontSize: 15
         }
     },
    scales: {
        yAxes: [{
        ticks: {
                    reverse: false,
          fontSize: 15
        }
      }],
      xAxes: [{
        ticks: {
          fontSize: 15
        }
      }],
    }
  }
}


var totalCasesChart = document.getElementById('totalDeathsContainer').getContext('2d');
new Chart(totalDeathsContainer, deathOptions);
document.getElementById('deathsGraphHeader').innerHTML = ""Total Deaths for ""+country;

};

function renderChart(){
  getCountryDataByMonth(document.getElementById('myInput').value);
}


function defaultChart() {
    getCountryDataByMonth('US');
}
window.onload = defaultChart;
</code></pre>

<p>This is what I tried. I basically did</p>

<pre><code>if(caseBar){
 caseBar.destroy();
}
</code></pre>

<p>However, this does not work. In my <a href=""https://jsfiddle.net/x3tpjcf2/2/"" rel=""nofollow noreferrer"">FIDDLE</a> you can try to type China first click to create the graph and then type Italy. Then HOVER over the Italy graph and you will see the stats from china appear on the graph.</p>
"
60839686,"<p>You can find the Google GeoChart code example and docs here <a href=""https://developers.google.com/chart/interactive/docs/gallery/geochart"" rel=""nofollow noreferrer"">https://developers.google.com/chart/interactive/docs/gallery/geochart</a></p>

<p>I know that if I copy and paste this two script files </p>

<pre><code>&lt;script type=""text/javascript"" src=""https://www.gstatic.com/charts/loader.js""&gt;&lt;/script&gt;
    &lt;script type=""text/javascript""&gt;
      google.charts.load('current', {
        'packages':['geochart'],
        // Note: you will need to get a mapsApiKey for your project.
        // See: https://developers.google.com/chart/interactive/docs/basic_load_libs#load-settings
        'mapsApiKey': 'MY_API_KEY'
      });
      google.charts.setOnLoadCallback(drawRegionsMap);

      function drawRegionsMap() {
        var data = google.visualization.arrayToDataTable([
          ['Country', 'Popularity'],
          ['Germany', 200],
          ['United States', 300],
          ['Brazil', 400],
          ['Canada', 500],
          ['France', 600],
          ['RU', 700]
        ]);

        var options = {};

        var chart = new google.visualization.GeoChart(document.getElementById('regions_div'));

        chart.draw(data, options);
      }
    &lt;/script&gt;
</code></pre>

<p>within my <code>&lt;head&gt;</code> tag in the main <code>index.html</code> (where the <code>&lt;app-root&gt;</code> lives) I'll get the expected output... The map with all that dummy data</p>

<p><a href=""https://i.stack.imgur.com/Cp3pm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Cp3pm.png"" alt=""enter image description here""></a></p>

<p>Instead all that dummy data, I want to inject some other countries and values, but as soon as I place all that code and methods in another JS file, the GeoMap doesnt show up anymore on the screen</p>

<p>Current <code>index.html</code> file</p>

<pre><code>&lt;!doctype html&gt;
&lt;html lang=""en""&gt;

&lt;head&gt;
  &lt;meta charset=""utf-8""&gt;
  &lt;title&gt;Covid19&lt;/title&gt;
  &lt;base href=""/""&gt;
  &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1""&gt;
  &lt;link rel=""icon"" type=""image/x-icon"" href=""favicon.ico""&gt;
  &lt;link rel=""stylesheet"" href=""https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css""
    integrity=""sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh"" crossorigin=""anonymous""&gt;

  &lt;!-- Google Geomaps --&gt;
  &lt;script type=""text/javascript"" src=""https://www.gstatic.com/charts/loader.js""&gt;&lt;/script&gt;
  &lt;script type=""text/javascript"" src=""./geomaps.js""&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;
  &lt;app-root&gt;&lt;/app-root&gt;
&lt;/body&gt;

&lt;/html&gt;
</code></pre>

<p>Current <code>geomaps.js</code> file:</p>

<pre><code>google.charts.load('current', {
      'packages': ['geochart'],
      // Google Api Key
      'mapsApiKey': ''
      // MY_API_KEY
    });
    google.charts.setOnLoadCallback(drawRegionsMap);

    function drawRegionsMap() {
      var data = google.visualization.arrayToDataTable([
        ['Country', 'Popularity'],
        ['Germany', 200],
        ['United States', 300],
        ['Brazil', 400],
        ['Canada', 500],
        ['France', 600],
        ['RU', 700]
      ]);

      var options = {};

      var chart = new google.visualization.GeoChart(document.getElementById('regions_div'));

      chart.draw(data, options);
</code></pre>

<p>Output on the screen: Nothing</p>

<p>Output on the chrome dev tools console:
<a href=""https://i.stack.imgur.com/VYqv0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VYqv0.png"" alt=""enter image description here""></a></p>
"
61045370,"<p>Trying to make a simulator for COVID-19, after some time after a person in my simulation gets infected, i want them to recover, and this to be shown by changing the color of the person to change to pink.</p>

<p>This is what i am trying to do so far:</p>

<pre><code>setRecoveredTimer() {
        setTimeout(function () {
            let newColor = '#d176d6';
            this.isRecovered = true;
            this.color = color(newColor);
        }, 5000);
}
</code></pre>

<p>Whenever the 5 seconds has passed, i get this error:</p>

<p><a href=""https://i.stack.imgur.com/JFFdo.png"" rel=""nofollow noreferrer"">TypeError: color is not a function</a></p>

<p>I am able to change color other places is my code, like here:</p>

<pre><code>changeColor() {
        if (this.isInfected == true) {
            this.color = color('#ed2d2d');
        }
    }
</code></pre>

<p>If it is any help, the rest of my project is here: <a href=""https://github.com/perkynades/Simulation-of-COVID19/tree/part1"" rel=""nofollow noreferrer"">https://github.com/perkynades/Simulation-of-COVID19/tree/part1</a></p>

<p>Been stuck on this issue for a day now, so any help will be appriciated :)</p>
"
61349063,"<p>So basically my web application I am working on is HTMl/CSS/Javascript all in file for ease right now.  It reads data from CSV regarding cases, deaths, days regarding covid-19 and displays them on chart.js graphs.  I have a state drop down select and when the button is pressed, reveals stat graphs for the state in question.  My state functionality is not working correctly.  It works on load for the first time, but does not work when you hit on Display State data button.  When I click the button, the first total cases for the state doesnt load and the side panel containining cumulative stats does not load.  I had this functionality working earlier but it broke.  Please take a look at my code. Here is my github where you can download the standalone HTML for ease with all the css and javasript inside.  <a href=""https://github.com/PjBanj/CoronaVirusStatistics/"" rel=""nofollow noreferrer"">https://github.com/PjBanj/CoronaVirusStatistics/</a>.  Grab the index.html and run it in chrome.  Look for intended functionality when you select state and hit the display state button. Error I get when I press the button is 
""ncaught TypeError: Object.defineProperty called on non-object in my chart.min.js
    at Function.defineProperty ()""</p>

<p>HTML:</p>

<pre><code>&lt;div class=""col-xs-12"" style=""display: flex; flex-direction: row; justify-content: center; align-items: center""&gt;
            &lt;label for=""state""&gt;State&lt;/label&gt;
            &lt;select id=""state"" name=""state""&gt;&lt;option value=""Alabama""&gt;Alabama&lt;/option&gt;&lt;option value=""Alaska""&gt;Alaska&lt;/option&gt;&lt;option value=""Arizona""&gt;Arizona&lt;/option&gt;&lt;option value=""Arkansas""&gt;Arkansas&lt;/option&gt;&lt;option value=""California""&gt;California&lt;/option&gt;&lt;option value=""Colorado""&gt;Colorado&lt;/option&gt;&lt;option value=""Connecticut""&gt;Connecticut&lt;/option&gt;&lt;option value=""Delaware""&gt;Delaware&lt;/option&gt;&lt;option value=""District of Columbia""&gt;District of Columbia&lt;/option&gt;&lt;option value=""Florida""&gt;Florida&lt;/option&gt;&lt;option value=""Georgia""&gt;Georgia&lt;/option&gt;&lt;option value=""Guam""&gt;Guam&lt;/option&gt;&lt;option value=""Hawaii""&gt;Hawaii&lt;/option&gt;&lt;option value=""Idaho""&gt;Idaho&lt;/option&gt;&lt;option value=""Illinois""&gt;Illinois&lt;/option&gt;&lt;option value=""Indiana""&gt;Indiana&lt;/option&gt;&lt;option value=""Iowa""&gt;Iowa&lt;/option&gt;&lt;option value=""Kansas""&gt;Kansas&lt;/option&gt;&lt;option value=""Kentucky""&gt;Kentucky&lt;/option&gt;&lt;option value=""Louisiana""&gt;Louisiana&lt;/option&gt;&lt;option value=""Maine""&gt;Maine&lt;/option&gt;&lt;option value=""Maryland""&gt;Maryland&lt;/option&gt;&lt;option value=""Massachusetts""&gt;Massachusetts&lt;/option&gt;&lt;option value=""Michigan""&gt;Michigan&lt;/option&gt;&lt;option value=""Minnesota""&gt;Minnesota&lt;/option&gt;&lt;option value=""Mississippi""&gt;Mississippi&lt;/option&gt;&lt;option value=""Missouri""&gt;Missouri&lt;/option&gt;&lt;option value=""Montana""&gt;Montana&lt;/option&gt;&lt;option value=""Nebraska""&gt;Nebraska&lt;/option&gt;&lt;option value=""Nevada""&gt;Nevada&lt;/option&gt;&lt;option value=""New Hampshire""&gt;New Hampshire&lt;/option&gt;&lt;option value=""New Jersey""&gt;New Jersey&lt;/option&gt;&lt;option value=""New Mexico""&gt;New Mexico&lt;/option&gt;&lt;option value=""New York""&gt;New York&lt;/option&gt;&lt;option value=""North Carolina""&gt;North Carolina&lt;/option&gt;&lt;option value=""North Dakota""&gt;North Dakota&lt;/option&gt;&lt;option value=""Northern Marianas Islands""&gt;Northern Marianas Islands&lt;/option&gt;&lt;option value=""Ohio""&gt;Ohio&lt;/option&gt;&lt;option value=""Oklahoma""&gt;Oklahoma&lt;/option&gt;&lt;option value=""Oregon""&gt;Oregon&lt;/option&gt;&lt;option value=""Pennsylvania""&gt;Pennsylvania&lt;/option&gt;&lt;option value=""Puerto Rico""&gt;Puerto Rico&lt;/option&gt;&lt;option value=""Rhode Island""&gt;Rhode Island&lt;/option&gt;&lt;option value=""South Carolina""&gt;South Carolina&lt;/option&gt;&lt;option value=""South Dakota""&gt;South Dakota&lt;/option&gt;&lt;option value=""Tennessee""&gt;Tennessee&lt;/option&gt;&lt;option value=""Texas""&gt;Texas&lt;/option&gt;&lt;option value=""Utah""&gt;Utah&lt;/option&gt;&lt;option value=""Vermont""&gt;Vermont&lt;/option&gt;&lt;option value=""Virginia""&gt;Virginia&lt;/option&gt;&lt;option value=""Virgin Islands""&gt;Virgin Islands&lt;/option&gt;&lt;option value=""Washington""&gt;Washington&lt;/option&gt;&lt;option value=""West Virginia""&gt;West Virginia&lt;/option&gt;&lt;option value=""Wisconsin""&gt;Wisconsin&lt;/option&gt;&lt;option value=""Wyoming""&gt;Wyoming&lt;/option&gt;&lt;/select&gt;
            &lt;button class=""button"" align=""center"" style=""margin: 20px; padding: 5px"" onclick=""chartStateCases(document.getElementById('state').value)""&gt;Display State Data&lt;/button&gt;
        &lt;/div&gt;

        &lt;div class=""col-xs-12"" &gt;
            &lt;h5 class=""text-center""&gt;Total Cases and Deaths Per Day in &lt;span class='newState'&gt;Alabama&lt;/span&gt;&lt;/h5&gt;
            &lt;div style=""height: 300px; width: 45%;display:inline-block;""&gt;&lt;/&gt; 
                &lt;canvas id=""CoronaChartStateCases""&gt; &lt;/canvas&gt; 
            &lt;/div&gt;
            &lt;div style=""height: 300px; width: 45%;display:inline-block;""&gt; 
                &lt;canvas id=""CoronaChartStateDeaths"" &gt;&lt;/canvas&gt;
            &lt;/div&gt;
        &lt;/div&gt; 

        &lt;div class=""col-xs-12"" &gt;
            &lt;h5 class=""text-center""&gt;New Cases and Deaths Per Day in &lt;span class='newState'&gt;Alabama&lt;/span&gt;&lt;/h5&gt;
            &lt;div style=""height: 300px; width: 45%;display:inline-block;""&gt;&lt;/&gt; 
                &lt;canvas id=""CoronaChartNewStateCases""&gt; &lt;/canvas&gt; 
            &lt;/div&gt;
            &lt;div style=""height: 300px; width: 45%;display:inline-block;""&gt; 
                &lt;canvas id=""CoronaChartNewStateDeaths"" &gt;&lt;/canvas&gt;
            &lt;/div&gt;
        &lt;/div&gt; 
    &lt;/main&gt;
</code></pre>

<p>Javascript: </p>

<pre><code>&lt;script&gt;
    var cases = [];
    var deaths = [];
    var newCases=[];
    var newDeaths=[];
    var days = [];
    var nationDays=[];
    var nationCases=[];
    var newNationCases=[];
    var nationDeaths=[];
    var newNationDeaths=[];
    var state = ""New York"";
    var caseUSChart = null;
    var newCaseUSChart = null;
    var deathUSChart = null;
    var newDeathUSChart = null;
    var caseStateChart = null;
    var deathStateChart = null;
    var newCaseStateChart = null;
    var newDeathStateChart = null;

    window.onload = function () {
        displayCountryData();   
        getDisplayStateData(state);
    }

    function loadSidePanel(newState){
        var casestate = cases[cases.length-1];
        var deathstate = deaths[deaths.length-1]; 
        document.getElementsByClassName(""newState"")[0].innerHTML = newState; 
        document.getElementsByClassName(""newState"")[1].innerHTML = newState; 
        document.getElementsByClassName(""newState"")[2].innerHTML = newState;
        document.getElementsByClassName(""newState"")[3].innerHTML = newState; 
    }

    function chartStateCases(state) {
        getDisplayStateData(state); 
    }

function chartStateCases(cases, days) {
        if(caseStateChart!=null){
            caseStateChart.destroy();
        }
        var ctx = document.getElementById('CoronaChartStateCases').getContext('2d');
            caseStateChart = new Chart(ctx, {
            type: 'bar',
            data: {
                labels: days,
                datasets: [{
                  label: 'Cases',
                  data: cases,
                  backgroundColor: ""rgb(207,181,59)""
                }]
            },
            options: {
                title: {
                    display: true,
                    text: 'Total CoronaVirus Cases in the State'
                },
                maintainAspectRatio: false,
                responsive: true,
                  scales: {
                    xAxes: [ {
                    ticks: {
                        autoSkip: true,
                        maxTicksLimit: 12
                    },
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'Days since first case in the State'
                      },
                    } ],
                    yAxes: [ {
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'Total Cases in the state'
                      }
                            } ]
                }
            }
        });

        caseStateChart.render();
    }

    function chartStateDeaths(deaths, days) {
        if(deathStateChart!=null){
            deathStateChart.destroy();
        }
        var ctx = document.getElementById('CoronaChartStateDeaths').getContext('2d');
        deathStateChart = new Chart(ctx, {
            type: 'bar',
            data: {
            labels: days,
            datasets: [{
              label: 'Deaths',
              data: deaths,
              backgroundColor: ""rgb(0,0,139)""
            }]
          },
          options: {
                title: {
                    display: true,
                    text: 'Total CoronaVirus Deaths in the State'
                },
                responsive: true,
                maintainAspectRatio: false,
                  scales: {
                    xAxes: [ {
                    ticks: {
                        autoSkip: true,
                        maxTicksLimit: 12
                    },
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'Days since first case in the State'
                      },
                    } ],
                    yAxes: [ {
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'Total Deaths in the state'
                      }
                            } ]
                        }
            }
        });

        deathStateChart.render();
    }

    function chartNewStateCases(nCases, dayaxis) {
        if(newCaseStateChart!=null){
            newCaseStateChart.destroy();
        }
        var ctx = document.getElementById('CoronaChartNewStateCases').getContext('2d');
        newCaseStateChart = new Chart(ctx, {
            type: 'bar',
            data: {
                labels: dayaxis,
                datasets: [{
                  label: 'New Cases per Day',
                  data: nCases,
                  backgroundColor: ""rgb(207,181,59)""
                }]
            },
            options: {
                title: {
                    display: true,
                    text: 'New CoronaVirus cases per Day in the State'
                },
                maintainAspectRatio: false,
                responsive: true,
                  scales: {
                    xAxes: [ {
                    ticks: {
                        autoSkip: true,
                        maxTicksLimit: 12
                    },
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'Days since first case in the State'
                      },
                    } ],
                    yAxes: [ {
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'New Cases per Day'
                        }

                        } ]
                    }
            }
        });
        newCaseStateChart.render();
    }

    function chartNewStateDeaths(nDeaths, dayaxis) {
        if(newDeathStateChart!=null){
            newDeathStateChart.destroy();
        }
        var ctx = document.getElementById('CoronaChartNewStateDeaths').getContext('2d');
        newDeathStateChart = new Chart(ctx, {
            type: 'bar',
            data: {
                labels: dayaxis,
                datasets: [{
                  label: 'New Deaths per day',
                  data: nDeaths,
                  backgroundColor: ""rgb(0,0,139)""
                }]
            },
            options: {
                title: {
                    display: true,
                    text: 'New CoronaVirus Deaths in the State'
                },
                maintainAspectRatio: false,
                responsive: true,
                  scales: {
                    xAxes: [ {
                    ticks: {
                        autoSkip: true,
                        maxTicksLimit: 12
                    },
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'Days since first case in the State'
                      },
                    } ],
                    yAxes: [ {
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'New Deaths per Day'
                        }

                        } ]
                    }
            }
        });
        newDeathStateChart.render();
    }

    function getDisplayStateData(state) { 
        cases = [];
        deaths = [];
        newStateCases=[];
        newStateDeaths=[];
        days = [];
        fetch('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')
        .then((response) =&gt; {
            return response.text(); 
        })
        .then((data) =&gt; {
            const table = data.split('\n').slice(1);
            curDay = 0;
            table.forEach((row) =&gt; { 
                const columns = row.split(','); 
                if(columns[1]==state) {
                    cases.push(columns[3]);
                    deaths.push(columns[4]);
                    days.push(curDay++);
                }   
            });

            chartStateCases(cases, days);
            chartStateDeaths(deaths, days);
            loadSidePanel(state);
            populateNewStateStats(cases, deaths);
            chartNewStateCases(newStateCases, days);
            chartNewStateDeaths(newStateDeaths, days);

        })
    }

    function csvToArray(csvString) {

        // The array we're going to build
        var csvArray = [];
        // Break it into rows to start
        var csvRows = csvString.split(/\n/);

        // Take off the first line to get the headers, then split that into an array
        var csvHeaders = csvRows.shift().split(',');

        // Loop through remaining rows
        for (var rowIndex = 0; rowIndex &lt; csvRows.length; ++rowIndex) {
            var rowArray = csvRows[rowIndex].split(',');

            // Create a new row object to store our data.
            var rowObject = csvArray[rowIndex] = {};

            // Then iterate through the remaining properties and use the headers as keys
            for (var propIndex = 0; propIndex &lt; rowArray.length; ++propIndex) {
                // Grab the value from the row array we're looping through...
                var propValue = rowArray[propIndex];
                // ...also grab the relevant header (the RegExp in both of these removes quotes)
                var propLabel = csvHeaders[propIndex];

                rowObject[propLabel] = propValue;
            }
        }

        return csvArray;
    }

    function displayCountryData() {  

        fetch('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')
        .then((response) =&gt; {
            return response.text(); 
        })
        .then((data) =&gt; {
            var csvData = csvToArray(data);
            const res = Object.values(csvData).reduce((acc, {date, cases, deaths}) =&gt; {
                if (acc[date] !== undefined) {
                    acc[date].totalCases += (+cases);
                    acc[date].totalDeaths += (+deaths);
                    } 
                else{
                    acc[date] = {date, totalCases: (+cases), totalDeaths: (+deaths)};
                    }

                return acc;
            }, {});

            var i = 0;

            for (var key in res) 
            {
                nationDays.push(i);
                nationCases.push(res[key].totalCases);
                nationDeaths.push(res[key].totalDeaths);
                i++;
            }
            chartCountryCases();
            chartCountryDeaths();
            populateNewNationStats();
            chartNewCountryCases();
            chartNewCountryDeaths();
            var caseus = nationCases[nationCases.length-1];
            var deathus = nationDeaths[nationDeaths.length-1];
            document.getElementById('caseus').innerHTML = caseus;
            document.getElementById('deathus').innerHTML = deathus;
        })
    }

    function populateNewNationStats()
    {
        var idx = 0;

        for(var x in nationCases)
        {
            if(idx==0)
            {
                newNationCases.push(0);
                newNationDeaths.push(0);
            }
            else
            {
                newNationCases.push(nationCases[idx] - nationCases[idx-1]);
                newNationDeaths.push(nationDeaths[idx] - nationDeaths[idx-1]);
            }

            idx++;
        }

        console.log(newNationCases);
        console.log(newNationDeaths);
    }

    function populateNewStateStats(stateCases, stateDeaths)
    {
        var idx = 0;

        for(var x in stateCases)
        {
            if(idx==0)
                {
                    newStateCases.push(0);
                    newStateDeaths.push(0);
                }
                else
                {
                    newStateCases.push(stateCases[idx] - stateCases[idx-1]);
                    newStateDeaths.push(stateDeaths[idx] - stateDeaths[idx-1]);
                }
            idx++;
        }

    }

&lt;/script&gt;
</code></pre>
"
60895213,"<p>I'm looking at the following three datasets from JHU</p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv</a></p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv</a></p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv</a></p>

<p>Which are on the form </p>

<pre><code> 'Province/State   'Country/Region    'Lat'    'Long'   '1/22/20'    '1/23/20' ...
       NaN               Italy          x        y          0            0
</code></pre>

<p>I want to calculate the number of active cases per province,country and day based on formula <code>active = confirmed - (recovered+deahts)</code></p>

<p>Before the datasets had the same shape, so I could do the following</p>

<pre><code>df_active = df_confirmed.copy()
df_active.loc[4:] = df_confirmed.loc[4:]-(df_recovered.loc[4:]+df_deaths.loc[4:])
</code></pre>

<p>Now they do not contain data on the same countries, and do not always have the same amount of date columns. </p>

<p>So I need to do the following</p>

<p>1) Determine what date columns all 3 DF have in common,</p>

<p>2) Where the province and country column match, do <code>active = confirmed - (recovered+deahts)</code></p>

<p>For point 1) I can do the following</p>

<pre><code>## append all shape[1] to list
df_shape_list.append(df_confirmed.shape[1])
...  
min_common_columns = min(df_shape_list)
</code></pre>

<p>So I need to subtract columns <code>4:min_common_columns</code>, but how do I do that where province and country column match on all 3 DF's?</p>
"
61036457,"<p>I have a script that uses bs4 to scrape a webpage and grab a string named, ""Last Updated 4/3/2020, 8:28 p.m."". I then assign this string to a variable and send it in an email. The script is scheduled to run once a day. However, the date and time on the website change every other day. So, instead of emailing every time I run the script I'd like to set up a trigger so that it sends only when the date is different. How do I configure the script to detect that change?</p>

<p>String in HTML:</p>

<pre>
<h1>COVID-19 News Updates</h1>


<br>Last Updated 4/3/2020, 12:08 p.m.
</pre>

<pre><code>'''Checks municipal websites for changes in meal assistance during C19 pandemic'''

# Import requests (to download the page)
import requests
# Import BeautifulSoup (to parse what we download)
from bs4 import BeautifulSoup
import re

#list of urls
urls = ['http://www.vofil.com/covid19_updates']

#set the headers as a browser
headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}

#download the homepage
response = requests.get(urls[0], headers=headers)
#parse the downloaded homepage and grab all text
soup = BeautifulSoup(response.text, ""lxml"")
#Find string
last_update_fra = soup.findAll(string=re.compile(""Last Updated""))
print(last_update_fra)

#Put something here (if else..?) to trigger an email.

#I left off email block...
</code></pre>

<p>The closet answer I found was this, but it's referring to the tags, not a string.
<a href=""https://stackoverflow.com/questions/17415796/parsing-changing-tags-beautifulsoup"">Parsing changing tags BeautifulSoup</a></p>
"
60977985,"<p>I have a use case where I access Covid-19 data via a GoogleSheet URL. When the file is fully loaded the gid appears. in this instance it's: 1576906596. After a day or two, the gid id changes, making the URL to break, unless you visit the site with the part of URL without edit#<strong>gid=1576906596</strong>
Currently, I am manually reading the gid after loading the file, but I am looking for a way to extract that and tag it automatically with the main part of the URL
<a href=""https://docs.google.com/spreadsheets/d/14quQPFErG-hlpsrNgYcX85vW7JMMK5X2vNZrafRcH8c/edit#"" rel=""nofollow noreferrer"">https://docs.google.com/spreadsheets/d/14quQPFErG-hlpsrNgYcX85vW7JMMK5X2vNZrafRcH8c/edit#</a><strong>gid=1576906596</strong></p>

<pre><code>gid = ""1576906596""    # need to extract automatically
baseURL = ""https://docs.google.com/spreadsheets/d/14quQPFErG-hlpsrNgYcX85vW7JMMK5X2vNZrafRcH8c/""
fullURL = baseURL + gid
</code></pre>
"
61402079,"<p>I am trying to get the line to display over the bar. It seems that whatever trace has <code>secondary_y=True</code> will be drawn on top of the one where <code>secondary_y=False</code>.</p>

<p>That's fine, but for this particular data set, the bar axis should be on the right, because otherwise this graph is confusing. The line is the one that is in the 1-3 range, and the bar is the one that is in the 0-35k range. </p>

<p>In other words, it should look just like this, but with y-axes switched. Is there some way to switch the axes, or control the order in which it draws the traces, so that I can force the line to be on top of the bars?</p>

<p><a href=""https://i.stack.imgur.com/mTgVa.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mTgVa.png"" alt=""enter image description here""></a></p>

<pre><code>import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from plotly.offline import init_notebook_mode,  plot
init_notebook_mode()

rdf = pd.read_csv('us_covid_data_latest.csv', dtype={'fips':str})
incidence = pd.pivot_table(rdf, values='cases', index = 'date', aggfunc=np.sum)
incidence['actual_inc'] = incidence['cases'].diff()

def tail_plot_plotly(tail):

    fig = make_subplots(specs=[[{""secondary_y"": True}]])

    fig.add_trace(
        go.Bar(
            x= incidence['date'].tail(tail),
            y= incidence['actual_inc'].tail(tail)
            ),
        secondary_y = False
        ) 


    fig.add_trace(
        go.Scatter(
            x= incidence['date'].tail(tail),
            y= incidence['R_t'].tail(tail)
            ),
        secondary_y = True
        )

    plot(fig)

tail_plot_plotly(50)
</code></pre>
"
61354755,"<p>Doing:</p>

<pre><code># extract data
df = pd.read_csv('https://covid.ourworldindata.org/data/ecdc/total_cases.csv')
df.set_index('date', inplace=True)
#transpose columns to rows
df = df.T
# swap all NAN with 0.0
df = df.fillna(0.0)
</code></pre>

<p>I have:</p>

<pre><code>date         2020-04-20  2020-04-21  
World        2355853.0   2431890.0  
Afghanistan  996.0      1031.0  
Albania      562.0       584.0  
Algeria      2629.0      2718.0
</code></pre>

<p>Now I wish to drop the first column create an index, ending up with:</p>

<pre><code>    2020-04-20  2020-04-21  
0   2355853.0   2431890.0  
1   996.0       1031.0  
2   562.0       584.0  
3   2629.0      2718.0
</code></pre>

<p>How?</p>

<p>Edit:</p>

<pre><code>date  2019-12-31  2020-01-01  2020-01-02  2020-01-03  2020-01-04  2020-01-05  \
0           27.0        27.0        27.0        44.0        44.0        59.0   
1            0.0         0.0         0.0         0.0         0.0         0.0   
2            0.0         0.0         0.0         0.0         0.0         0.0 
</code></pre>
"
60896703,"<p>As an exercise, I’m trying to plot the excellent <a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">COVID-19 data provided by Johns Hopkins CSSE</a>.
I’m confused because the time series is organized in columns (each day is put to the side of the other... see below in the figure). Preferentially I’d like to avoid transposing the columns to lines and vice-versa. My intention is to plot the COVID-19 evolution as lines for all countries, day by day (yes, it is going to get messy).</p>

<p>I was thinking that I could use a for loop iterating through the columns to populate a list and use this as my y-axis but do we have a more “direct” way to get this plot? Recently I'm using Plotly more, but I'm OK with matplotlib or seaborn too.</p>

<p><a href=""https://i.stack.imgur.com/QDLP6.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QDLP6.png"" alt=""enter image description here""></a></p>
"
61706334,"<p>As part of our <a href=""https://poolkeh.github.io/"" rel=""nofollow noreferrer"">Poolkeh</a> paper, we wanted to use <a href=""https://github.com/facebookresearch/nevergrad"" rel=""nofollow noreferrer"">nevergrad</a>. However, sadly it doesn't always return the same result, nor the most optimal one. </p>

<p>We tried <code>DiscreteOnePlusOne</code> as an optimizer, but it didn't find the optimal results. <code>OnePlusOne</code> worked ok, but didn't give the best solution and it needed some hints like this one:</p>

<pre><code>if s1 &lt; s2*(1+r0):
    return np.Inf
</code></pre>

<p>We explored the case of <a href=""https://markd87.github.io/2020/05/08/Fake-coins-and-infectious-diseases.html"" rel=""nofollow noreferrer"">pooling COVID-19 tests</a> with two steps, here is the complete code:</p>

<pre><code>!pip install nevergrad
import numpy as np
def optimal(r0: float, s1:int, s2:int):
  r0 = r0/100
  if s1 &lt; s2*(1+r0):
    return np.Inf

  p1=1-np.power(1-r0,s1)
  r1=r0/p1
  p2=1-np.power(1-r1,s2)
  return 1/s1 + p1/s2 + p1*p2

import nevergrad as ng

def findBestStategy(r0: float):
  '''
  r0 is in %
  '''
  parametrization = ng.p.Instrumentation(
      r0 = r0, 
      s1=ng.p.Scalar(lower=1, upper=100).set_integer_casting(),
      s2=ng.p.Scalar(lower=1, upper=100).set_integer_casting(),
  )
  optimizer = ng.optimizers.OnePlusOne(parametrization=parametrization, budget=2000, num_workers=1)
  recommendation = optimizer.minimize(optimal)
  return recommendation.kwargs
findBestStategy(1)
{'r0': 1, 's1': 23, 's2': 5}
</code></pre>

<p>This is not the optimal, but really close:</p>

<pre><code>optimal(1, 23,5)
0.13013924406458133
optimal(1, 24,5) 
0.13007783167425113
</code></pre>

<ol>
<li>How can we make nevergrad be more robust? </li>
<li>Which optimizer should we use?</li>
</ol>
"
61060003,"<p>How to read the table into a pandas dataframe. (Corona Patient Database)</p>

<p>Here is the URL Source: <a href=""https://docs.google.com/spreadsheets/d/e/2PACX-1vSc_2y5N0I67wDU38DjDh35IZSIS30rQf7_NYZhtYYGU1jJYT6_kDx4YpF-qw0LSlGsBYP8pqM_a1Pd/pubhtml"" rel=""nofollow noreferrer"">https://docs.google.com/spreadsheets/d/e/2PACX-1vSc_2y5N0I67wDU38DjDh35IZSIS30rQf7_NYZhtYYGU1jJYT6_kDx4YpF-qw0LSlGsBYP8pqM_a1Pd/pubhtml</a></p>

<p><a href=""https://i.stack.imgur.com/LiBcI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/LiBcI.png"" alt=""enter image description here""></a></p>

<p>I want to get this data into a dataframe with minimal effort using pandas for further analysis. What is the best way to do it. The HTML is nested with multiple sheets. This is what I have tried so far.</p>

<pre><code>url = r'https://docs.google.com/spreadsheets/d/e/2PACX-1vSc_2y5N0I67wDU38DjDh35IZSIS30rQf7_NYZhtYYGU1jJYT6_kDx4YpF-qw0LSlGsBYP8pqM_a1Pd/pubhtml'
import pandas as pd
import requests

rtext = requests.get(url).text
</code></pre>

<p>rtext has all the html with the data. Now I tried Beautiful Soup, but it is very confusing.</p>

<p>Hoping to get a clean solution.</p>

<p>Part of the HTML Table look like this:</p>

<pre><code>&lt;table class=""waffle"" cellspacing=""0"" cellpadding=""0""&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th class=""row-header freezebar-vertical-handle header-shim row-header-shim""&gt;&lt;/th&gt;&lt;th id=""0C0"" style=""width:54px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C1"" style=""width:60px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C2"" style=""width:72px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C4"" style=""width:50px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C5"" style=""width:48px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C6"" style=""width:111px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C7"" style=""width:130px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C8"" style=""width:201px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C9"" style=""width:69px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C10"" style=""width:124px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C11"" style=""width:190px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C12"" style=""width:96px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C13"" style=""width:99px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C14"" style=""width:99px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C15"" style=""width:99px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C16"" style=""width:258px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C17"" style=""width:96px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C18"" style=""width:96px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C19"" style=""width:100px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C20"" style=""width:100px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C21"" style=""width:100px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C22"" style=""width:100px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C23"" style=""width:100px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C24"" style=""width:100px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C25"" style=""width:100px"" class=""header-shim""&gt;&lt;/th&gt;&lt;th id=""0C26"" style=""width:100px"" class=""header-shim""&gt;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
&lt;tr style=""height:46px;""&gt;&lt;th id=""0R0"" style=""height: 46px;"" class=""row-headers-background row-header-shim""&gt;&lt;div class=""row-header-wrapper"" style=""line-height: 46px;""&gt;1&lt;/div&gt;&lt;/th&gt;
&lt;td class=""s0"" dir=""ltr""&gt;Patient Number&lt;/td&gt;&lt;td class=""s1"" dir=""ltr""&gt;State Patient Number&lt;/td&gt;&lt;td class=""s2""&gt;Date Announced&lt;/td&gt;&lt;td class=""s2""&gt;Age Bracket&lt;/td&gt;&lt;td class=""s0""&gt;Gender&lt;/td&gt;&lt;td class=""s0""&gt;Detected City&lt;/td&gt;&lt;td class=""s0"" dir=""ltr""&gt;Detected District&lt;/td&gt;&lt;td class=""s2"" dir=""ltr""&gt;Detected State&lt;/td&gt;&lt;td class=""s0"" dir=""ltr""&gt;State code&lt;/td&gt;&lt;td class=""s0"" dir=""ltr""&gt;Current Status&lt;/td&gt;&lt;td class=""s3"" dir=""ltr""&gt;Notes&lt;/td&gt;&lt;td class=""s1"" dir=""ltr""&gt;Contracted from which Patient (Suspected)&lt;/td&gt;&lt;td class=""s2"" dir=""ltr""&gt;Nationality&lt;/td&gt;&lt;td class=""s2"" dir=""ltr""&gt;Type of transmission&lt;/td&gt;&lt;td class=""s2""&gt;Status Change Date&lt;/td&gt;&lt;td class=""s3"" dir=""ltr""&gt;Source_1&lt;/td&gt;&lt;td class=""s3"" dir=""ltr""&gt;Source_2&lt;/td&gt;&lt;td class=""s3"" dir=""ltr""&gt;Source_3&lt;/td&gt;&lt;td class=""s1"" dir=""ltr""&gt;Backup Notes&lt;/td&gt;&lt;td class=""s4""&gt;&lt;/td&gt;&lt;td class=""s4""&gt;&lt;/td&gt;&lt;td class=""s4""&gt;&lt;/td&gt;&lt;td class=""s4""&gt;&lt;/td&gt;&lt;td class=""s4""&gt;&lt;/td&gt;&lt;td class=""s4""&gt;&lt;/td&gt;&lt;td class=""s4""&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th style=""height:3px"" class=""freezebar-cell freezebar-horizontal-handle row-header-shim""&gt;&lt;/th&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;td class=""freezebar-cell""&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr style=""height:20px;""&gt;&lt;th id=""0R1"" style=""height: 20px;"" class=""row-headers-background row-header-shim""&gt;&lt;div class=""row-header-wrapper"" style=""line-height: 20px;""&gt;2&lt;/div&gt;&lt;/th&gt;&lt;td class=""s5"" dir=""ltr""&gt;1&lt;/td&gt;&lt;td class=""s6"" dir=""ltr""&gt;KL-TS-P1&lt;/td&gt;&lt;td class=""s5"" dir=""ltr""&gt;30/01/2020&lt;/td&gt;&lt;td class=""s5"" dir=""ltr""&gt;20&lt;/td&gt;&lt;td class=""s6"" dir=""ltr""&gt;F&lt;/td&gt;&lt;td class=""s6"" dir=""ltr""&gt;Thrissur&lt;/td&gt;&lt;td class=""s6"" dir=""ltr""&gt;Thrissur&lt;/td&gt;&lt;td class=""s6"" dir=""ltr""&gt;Kerala&lt;/td&gt;&lt;td class=""s6""&gt;KL&lt;/td&gt;&lt;td class=""s6"" dir=""ltr""&gt;Recovered&lt;/td&gt;&lt;td class=""s7"" dir=""ltr""&gt;Travelled from Wuhan&lt;/td&gt;&lt;td class=""s8""&gt;&lt;/td&gt;&lt;td class=""s5"" dir=""ltr""&gt;India&lt;/td&gt;&lt;td class=""s5"" dir=""ltr""&gt;Imported&lt;/td&gt;&lt;td class=""s9"" dir=""ltr""&gt;14/02/2020&lt;/td&gt;&lt;td class=""s10"" dir=""ltr""&gt;&lt;a target=""_blank"" rel=""noreferrer"" href=""https://www.google.com/url?q=https://twitter.com/vijayanpinarayi/status/1222819465143832577&amp;amp;sa=D&amp;amp;ust=1586180154769000&amp;amp;usg=AFQjCNEwtlOETa2v9D30Pjoe-fJxrVA9PA""&gt;https://twitter.com/vijayanpinarayi/status/1222819465143832577&lt;/a&gt;&lt;/td&gt;&lt;td class=""s11"" dir=""ltr"" colspan=""2""&gt;&lt;a target=""_blank"" rel=""noreferrer"" href=""https://www.google.com/url?q=https://weather.com/en-IN/india/news/news/2020-02-14-kerala-defeats-coronavirus-indias-three-covid-19-patients-successfully&amp;amp;sa=D&amp;amp;ust=1586180154769000&amp;amp;usg=AFQjCNGWVTymYTvejeSjCqq583NMJ3jbTA""&gt;https://weather.com/en-IN/india/news/news/2020-02-14-kerala-defeats-coronavirus-indias-three-covid-19-patients-successfully&lt;/a&gt;&lt;/td&gt;&lt;td class=""s12 softmerge"" dir=""ltr""&gt;&lt;div class=""softmerge-inner"" style=""width: 198px; left: -1px;""&gt;Student from Wuhan&lt;/div&gt;&lt;/td&gt;&lt;td class=""s13""&gt;&lt;/td&gt;&lt;td class=""s13""&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
</code></pre>
"
61457049,"<p><a href=""https://github.com/meezanmalek/coronavirus_data/blob/master/corona_virus.py"" rel=""nofollow noreferrer"">Here is my code in github</a></p>

<p><a href=""https://i.stack.imgur.com/FoVXC.png"" rel=""nofollow noreferrer"">Here is my output in excel file from that dataframe</a></p>

<hr>

<p><strong>How i can remove those  tags ???</strong></p>
"
60733564,"<p>i need to <strong>get values</strong> only for <strong>Czechia</strong> country from this website list ""<a href=""https://coronavirus-19-api.herokuapp.com/countries"" rel=""nofollow noreferrer"">https://coronavirus-19-api.herokuapp.com/countries</a>""<a href=""https://coronavirus-19-api.herokuapp.com/countries"" rel=""nofollow noreferrer""></a> and store like a <strong>variable dictionary</strong> in ptyhon.</p>

<p>Like this:</p>

<pre><code>Czechia = {""cases"":434,""todayCases"":0,""deaths"":0,""todayDeaths"":0,""recovered"":3,""active"":431,""critical"":2}
</code></pre>
"
60682977,"<p>I have thymeleaf html page with below content:</p>

<pre><code>&lt;table&gt;
    &lt;tr&gt;
        &lt;th&gt;State&lt;/th&gt;
        &lt;th&gt;Country&lt;/th&gt;
        &lt;th&gt;Total case reported&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr th:each=""locationStat : ${locationStats}""&gt;
        &lt;td th:text=""${locationStat.state}""&gt;&lt;/td&gt;
        &lt;td th:text=""${locationStat.country}""&gt;&lt;/td&gt;
        &lt;td th:text=""${locationStat.latestTotalCases}""&gt;&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;
</code></pre>

<p>My spring boot model looks like this</p>

<pre><code>public class LocationStats {

    private String state;
    private String country;
    private Integer latestTotalCases;

    public String getState() {
        return state;
    }

    public void setState(String state) {
        this.state = state;
    }

    public String getCountry() {
        return country;
    }

    public void setCountry(String country) {
        this.country = country;
    }

    public Integer getLatestTotalCases(int i) {
        return latestTotalCases;
    }

    public void setLatestTotalCases(Integer latestTotalCases) {
        this.latestTotalCases = latestTotalCases;
    }

    @Override
    public String toString() {
        return ""locationStats{"" +
                ""state='"" + state + '\'' +
                "", country='"" + country + '\'' +
                "", latestTotalCases="" + latestTotalCases +
                '}';
    }
}
</code></pre>

<p>On my service layer reading the CSV and writing to object.</p>

<pre><code>@Service
public class CoronavirusDataService {

    private static String DATA_URL = ""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"";

    private List&lt;LocationStats&gt; allStats = new ArrayList&lt;&gt;();

    public List&lt;LocationStats&gt; getAllStats() {
        return allStats;
    }


    @PostConstruct
    @Scheduled(cron = ""* 1 * * * *"")
    public void fetchVirusData() throws IOException, InterruptedException {

        List&lt;LocationStats&gt; newStats = new ArrayList&lt;&gt;();

        HttpClient client = HttpClient.newHttpClient();

        HttpRequest request = HttpRequest.newBuilder()
                .uri(URI.create(DATA_URL)).build();

        HttpResponse&lt;String&gt; httpResponse = client.send(request, HttpResponse.BodyHandlers.ofString());


        StringReader csvReader = new StringReader(httpResponse.body());

        Iterable&lt;CSVRecord&gt; records = CSVFormat.DEFAULT.withFirstRecordAsHeader().parse(csvReader);


        for (CSVRecord record : records) {

            LocationStats locationStats = new LocationStats();

            locationStats.setState(record.get(""Province/State""));
            locationStats.setCountry(record.get(""Country/Region""));

            Integer totalCases = Integer.parseInt(record.get(record.size() - 1));

            locationStats.setLatestTotalCases(totalCases);

            System.out.println(locationStats);

            newStats.add(locationStats);
        }
        this.allStats = newStats;
    }
}
</code></pre>

<p>Having this code in place, when I start my spring boot app it starts normally but when I hit locahost:8080 it throws the following exception.</p>

<pre><code>2020-03-14 18:20:11.696  INFO 15100 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 33 ms 2020-03-14 18:20:13.027 ERROR 15100 --- [nio-8080-exec-1] org.thymeleaf.TemplateEngine             : [THYMELEAF][http-nio-8080-exec-1] Exception processing template ""home"": An error happened during template parsing (template: ""class path resource [templates/home.html]"")

org.thymeleaf.exceptions.TemplateInputException: An error happened during template parsing (template: ""class path resource [templates/home.html]"")  at org.thymeleaf.templateparser.markup.AbstractMarkupTemplateParser.parse(AbstractMarkupTemplateParser.java:241) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     at org.thymeleaf.templateparser.markup.AbstractMarkupTemplateParser.parseStandalone(AbstractMarkupTemplateParser.java:100) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:666) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1098) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1072) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.spring5.view.ThymeleafView.renderFragment(ThymeleafView.java:362) ~[thymeleaf-spring5-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.spring5.view.ThymeleafView.render(ThymeleafView.java:189) ~[thymeleaf-spring5-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1373) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1118) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1057) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]     at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]     at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) ~[tomcat-embed-core-9.0.31.jar:9.0.31]  at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]     at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) ~[tomcat-embed-core-9.0.31.jar:9.0.31]  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.31.jar:9.0.31]   at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.31.jar:9.0.31]   at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) ~[tomcat-embed-core-9.0.31.jar:9.0.31]    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) ~[tomcat-embed-core-9.0.31.jar:9.0.31]    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) ~[tomcat-embed-core-9.0.31.jar:9.0.31]  at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) ~[tomcat-embed-core-9.0.31.jar:9.0.31]  at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) ~[tomcat-embed-core-9.0.31.jar:9.0.31]   at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:367) ~[tomcat-embed-core-9.0.31.jar:9.0.31]    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) ~[tomcat-embed-core-9.0.31.jar:9.0.31]  at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) ~[tomcat-embed-core-9.0.31.jar:9.0.31]   at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1639) ~[tomcat-embed-core-9.0.31.jar:9.0.31]   at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) ~[tomcat-embed-core-9.0.31.jar:9.0.31]   at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[na:na]   at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[na:na]   at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) ~[tomcat-embed-core-9.0.31.jar:9.0.31]    at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na] Caused by: org.attoparser.ParseException: Exception evaluating SpringEL expression: ""locationStat.latestTotalCases"" (template: ""home"" - line 23, col 13)    at org.attoparser.MarkupParser.parseDocument(MarkupParser.java:393) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]   at org.attoparser.MarkupParser.parse(MarkupParser.java:257) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]   at org.thymeleaf.templateparser.markup.AbstractMarkupTemplateParser.parse(AbstractMarkupTemplateParser.java:230) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     ... 48 common frames omitted Caused by: org.thymeleaf.exceptions.TemplateProcessingException: Exception evaluating SpringEL expression: ""locationStat.latestTotalCases"" (template: ""home"" - line 23, col 13)    at org.thymeleaf.spring5.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:290) ~[thymeleaf-spring5-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.engine.Model.process(Model.java:282) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.engine.Model.process(Model.java:290) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.engine.IteratedGatheringModelProcessable.processIterationModel(IteratedGatheringModelProcessable.java:367) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.engine.IteratedGatheringModelProcessable.process(IteratedGatheringModelProcessable.java:221) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.engine.ProcessorTemplateHandler.handleCloseElement(ProcessorTemplateHandler.java:1640) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.engine.TemplateHandlerAdapterMarkupHandler.handleCloseElementEnd(TemplateHandlerAdapterMarkupHandler.java:388) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.templateparser.markup.InlinedOutputExpressionMarkupHandler$InlineMarkupAdapterPreProcessorHandler.handleCloseElementEnd(InlinedOutputExpressionMarkupHandler.java:322) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.standard.inline.OutputExpressionInlinePreProcessorHandler.handleCloseElementEnd(OutputExpressionInlinePreProcessorHandler.java:220) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     at org.thymeleaf.templateparser.markup.InlinedOutputExpressionMarkupHandler.handleCloseElementEnd(InlinedOutputExpressionMarkupHandler.java:164) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     at org.attoparser.HtmlElement.handleCloseElementEnd(HtmlElement.java:169) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]     at org.attoparser.HtmlMarkupHandler.handleCloseElementEnd(HtmlMarkupHandler.java:412) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]     at org.attoparser.MarkupEventProcessorHandler.handleCloseElementEnd(MarkupEventProcessorHandler.java:473) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]     at org.attoparser.ParsingElementMarkupUtil.parseCloseElement(ParsingElementMarkupUtil.java:201) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]   at org.attoparser.MarkupParser.parseBuffer(MarkupParser.java:725) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]     at org.attoparser.MarkupParser.parseDocument(MarkupParser.java:301) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]   ... 50 common frames omitted Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1008E: Property or field 'latestTotalCases' cannot be found on object of type 'com.gour.modules.LocationStats' - maybe not public or not valid?  at org.springframework.expression.spel.ast.PropertyOrFieldReference.readProperty(PropertyOrFieldReference.java:217) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:104) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.springframework.expression.spel.ast.PropertyOrFieldReference.access$000(PropertyOrFieldReference.java:51) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at org.springframework.expression.spel.ast.PropertyOrFieldReference$AccessorLValue.getValue(PropertyOrFieldReference.java:406) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]     at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:92) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]     at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:112) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:337) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at org.thymeleaf.spring5.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:263) ~[thymeleaf-spring5-3.0.11.RELEASE.jar:3.0.11.RELEASE]   ... 75 common frames omitted

2020-03-14 18:20:13.031 ERROR 15100 --- [nio-8080-exec-1] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: An error happened during template parsing (template: ""class path resource [templates/home.html]"")] with root cause

org.springframework.expression.spel.SpelEvaluationException: EL1008E: Property or field 'latestTotalCases' cannot be found on object of type 'com.gour.modules.LocationStats' - maybe not public or not valid?  at org.springframework.expression.spel.ast.PropertyOrFieldReference.readProperty(PropertyOrFieldReference.java:217) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:104) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.springframework.expression.spel.ast.PropertyOrFieldReference.access$000(PropertyOrFieldReference.java:51) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at org.springframework.expression.spel.ast.PropertyOrFieldReference$AccessorLValue.getValue(PropertyOrFieldReference.java:406) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]     at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:92) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]     at org.springframework.expression.spel.ast.SpelNodeImpl.getValue(SpelNodeImpl.java:112) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:337) ~[spring-expression-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at org.thymeleaf.spring5.expression.SPELVariableExpressionEvaluator.evaluate(SPELVariableExpressionEvaluator.java:263) ~[thymeleaf-spring5-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.standard.expression.VariableExpression.executeVariableExpression(VariableExpression.java:166) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.standard.expression.SimpleExpression.executeSimple(SimpleExpression.java:66) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.standard.expression.Expression.execute(Expression.java:109) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     at org.thymeleaf.standard.expression.Expression.execute(Expression.java:138) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     at org.thymeleaf.standard.processor.AbstractStandardExpressionAttributeTagProcessor.doProcess(AbstractStandardExpressionAttributeTagProcessor.java:144) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.processor.element.AbstractAttributeTagProcessor.doProcess(AbstractAttributeTagProcessor.java:74) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.processor.element.AbstractElementTagProcessor.process(AbstractElementTagProcessor.java:95) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.util.ProcessorConfigurationUtils$ElementTagProcessorWrapper.process(ProcessorConfigurationUtils.java:633) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.engine.ProcessorTemplateHandler.handleOpenElement(ProcessorTemplateHandler.java:1314) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.engine.OpenElementTag.beHandled(OpenElementTag.java:205) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.engine.Model.process(Model.java:282) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.engine.Model.process(Model.java:290) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.engine.IteratedGatheringModelProcessable.processIterationModel(IteratedGatheringModelProcessable.java:367) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.engine.IteratedGatheringModelProcessable.process(IteratedGatheringModelProcessable.java:221) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.engine.ProcessorTemplateHandler.handleCloseElement(ProcessorTemplateHandler.java:1640) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.engine.TemplateHandlerAdapterMarkupHandler.handleCloseElementEnd(TemplateHandlerAdapterMarkupHandler.java:388) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.templateparser.markup.InlinedOutputExpressionMarkupHandler$InlineMarkupAdapterPreProcessorHandler.handleCloseElementEnd(InlinedOutputExpressionMarkupHandler.java:322) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]  at org.thymeleaf.standard.inline.OutputExpressionInlinePreProcessorHandler.handleCloseElementEnd(OutputExpressionInlinePreProcessorHandler.java:220) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     at org.thymeleaf.templateparser.markup.InlinedOutputExpressionMarkupHandler.handleCloseElementEnd(InlinedOutputExpressionMarkupHandler.java:164) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     at org.attoparser.HtmlElement.handleCloseElementEnd(HtmlElement.java:169) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]     at org.attoparser.HtmlMarkupHandler.handleCloseElementEnd(HtmlMarkupHandler.java:412) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]     at org.attoparser.MarkupEventProcessorHandler.handleCloseElementEnd(MarkupEventProcessorHandler.java:473) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]     at org.attoparser.ParsingElementMarkupUtil.parseCloseElement(ParsingElementMarkupUtil.java:201) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]   at org.attoparser.MarkupParser.parseBuffer(MarkupParser.java:725) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]     at org.attoparser.MarkupParser.parseDocument(MarkupParser.java:301) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]   at org.attoparser.MarkupParser.parse(MarkupParser.java:257) ~[attoparser-2.0.5.RELEASE.jar:2.0.5.RELEASE]   at org.thymeleaf.templateparser.markup.AbstractMarkupTemplateParser.parse(AbstractMarkupTemplateParser.java:230) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]     at org.thymeleaf.templateparser.markup.AbstractMarkupTemplateParser.parseStandalone(AbstractMarkupTemplateParser.java:100) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:666) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1098) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1072) ~[thymeleaf-3.0.11.RELEASE.jar:3.0.11.RELEASE]    at org.thymeleaf.spring5.view.ThymeleafView.renderFragment(ThymeleafView.java:362) ~[thymeleaf-spring5-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.thymeleaf.spring5.view.ThymeleafView.render(ThymeleafView.java:189) ~[thymeleaf-spring5-3.0.11.RELEASE.jar:3.0.11.RELEASE]   at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1373) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1118) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1057) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]     at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]     at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at javax.servlet.http.HttpServlet.service(HttpServlet.java:634) ~[tomcat-embed-core-9.0.31.jar:9.0.31]  at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.2.4.RELEASE.jar:5.2.4.RELEASE]     at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) ~[tomcat-embed-core-9.0.31.jar:9.0.31]  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.31.jar:9.0.31]   at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]   at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]  at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.4.RELEASE.jar:5.2.4.RELEASE]    at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.31.jar:9.0.31]   at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) ~[tomcat-embed-core-9.0.31.jar:9.0.31]    at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) ~[tomcat-embed-core-9.0.31.jar:9.0.31]    at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) ~[tomcat-embed-core-9.0.31.jar:9.0.31]     at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) ~[tomcat-embed-core-9.0.31.jar:9.0.31]  at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) ~[tomcat-embed-core-9.0.31.jar:9.0.31]  at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) ~[tomcat-embed-core-9.0.31.jar:9.0.31]   at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:367) ~[tomcat-embed-core-9.0.31.jar:9.0.31]    at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) ~[tomcat-embed-core-9.0.31.jar:9.0.31]  at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) ~[tomcat-embed-core-9.0.31.jar:9.0.31]   at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1639) ~[tomcat-embed-core-9.0.31.jar:9.0.31]   at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) ~[tomcat-embed-core-9.0.31.jar:9.0.31]   at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) ~[na:na]   at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) ~[na:na]   at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) ~[tomcat-embed-core-9.0.31.jar:9.0.31]    at java.base/java.lang.Thread.run(Thread.java:834) ~[na:na]
</code></pre>

<p>Error says that latestTotalCases not found on object com.gour.modules.LocationStats but if you see my model class it is there.</p>

<p>Not sure what i am missing , need your help. I am new to this so please bear with me with my queries.</p>
"
60732193,"<p>I'm currently new to the Spring Boot Java framework and I'm building a simple application. When my service starts, I want to be able to read a raw file from a URL, parse that data, and upload it into my mongodb database of atlas. So far this is what I have:</p>

<pre><code>@Service
public class CoronaVirusDataService {
  private List&lt;LocationStats&gt; allConfirmedStats = new ArrayList&lt;&gt;();
  MongoOperations mongoOperations;

  @PostConstruct // run this method as soon as the application runs
  @Scheduled(cron = ""* * 1 * * *"") // execute this method every day
  public void fetchVirusData() {
    List&lt;LocationStats&gt; newStats = new ArrayList&lt;&gt;(); // to hold the stats of each state
    HttpClient client = HttpClient.newHttpClient();
    // creating a new http request
    HttpRequest request = HttpRequest.newBuilder()
        .uri(URI.create(ConstantsUtil.VIRUS_CONFIRMED_DATA_URL))
        .build();

    // get a response by having the client send the request
    try {
      HttpResponse&lt;String&gt; httpResponse = client.send(request, HttpResponse.BodyHandlers.ofString());
      // parse the body of the request from csv format to readable format
      StringReader csvBodyReader = new StringReader(httpResponse.body());
      Iterable&lt;CSVRecord&gt; records = CSVFormat.DEFAULT.withFirstRecordAsHeader().parse(csvBodyReader);
      for (CSVRecord record: records) {
        // create a model with the parsed data
        LocationStats stats = new LocationStats();
        stats.setState(record.get(""Province/State""));
        stats.setCountry(record.get(""Country/Region""));
        // the latest day
        int latestCases = Integer.parseInt(record.get(record.size() - 1));
        int prevDayCases = Integer.parseInt(record.get(record.size() - 2));
        stats.setLatestTotalCases(latestCases);
        stats.setDiffFromPreviousDay(prevDayCases);

        mongoOperations.save(LocationStats);

        // add to new stats
        newStats.add(stats);
      }
      // assign to class array -&gt; we use this array to display the data
      this.allConfirmedStats = newStats;

    } catch (IOException | InterruptedException e) {
      e.printStackTrace();
    }
  }

}
</code></pre>

<p>So the main issue with this is the data is not saving to the mongoDB once I call mongoOperations.save(). Also, I've learned that it is bad practice to maintain some type of state in a Service. What is the best practice for this? Will inserting the data into MongoDB take care of that since we are not managing state. </p>

<p>Here is my model class that I want to save to mongodb</p>

<pre><code>@Document(collection = ""LocationStats"")
public class LocationStats {
  /** Location model to show corona virus statistics in each state*/
  @Id
  private String state;
  private String country;
  private int latestTotalCases;
  private int diffFromPreviousDay;

  public String getState() {
    return state;
  }

  public void setState(String state) {
    this.state = state;
  }

  public String getCountry() {
    return country;
  }

  public void setCountry(String country) {
    this.country = country;
  }

  public int getLatestTotalCases() {
    return latestTotalCases;
  }

  public void setLatestTotalCases(int latestTotalCases) {
    this.latestTotalCases = latestTotalCases;
  }

  public int getDiffFromPreviousDay() {
    return diffFromPreviousDay;
  }

  public void setDiffFromPreviousDay(int diffFromPreviousDay) {
    this.diffFromPreviousDay = diffFromPreviousDay;
  }

  @Override
  public String toString() {
    return ""LocationStats{"" +
        ""state='"" + state + '\'' +
        "", country='"" + country + '\'' +
        "", latestTotalCases="" + latestTotalCases +
        '}';
  }
}
</code></pre>

<p>once I have my models saved into mongoDB, I want to read from the database and get all the data from each collection and display it on the webpage. I'm thinking I'd fetch that data within the controller class and pass it to the frontend, is this good practice? here is my controller class.</p>

<pre><code>@Controller
public class HomeController {
  /** Controller class to generate/render the html UI */
  @Autowired
  CoronaVirusDataService coronaVirusDataService;

  @Autowired
  MongoOperations mongoOperations;

  @GetMapping(""/"") // map this to the root template
  public String home(Model model) {
    List&lt;LocationStats&gt; allStats = coronaVirusDataService.getAllConfirmedStats();

    // instead of above getter method, have a method call that fetches all data from mongoDB and return it as a List&lt;LocationStats&gt;

    // get the total confirmed cases
    int totalConfirmedCases = allStats.stream().mapToInt(LocationStats::getLatestTotalCases).sum();
    int totalNewCases = allStats.stream().mapToInt(LocationStats::getDiffFromPreviousDay).sum();


    // send the models to the view
    model.addAttribute(""locationStats"", allStats);
    model.addAttribute(""totalReportedCases"", totalConfirmedCases);
    model.addAttribute(""totalNewCases"", totalNewCases);

    return ""home"";
  }
}
</code></pre>
"
61245799,"<p>I am learning React and have encountered the following problem. Img and p elements are styled but h1 element is ignored for some reason. Why is that? </p>

<pre><code>import ""./Body.css"" 

img { // inside Body.css
height: 150px }
h1 {
font-size: 15px;
color: red
}
p {
font-size: 15px;
color: red
} // inside Body.css


function Body(){
const imgStyle = {
    marginTop: 45
}


return (
&lt;div style={{paddingTop: 100}} className=""container""&gt;
    &lt;div style={{paddingTop: 20}} className=""row""&gt;
        &lt;h1&gt;Overview&lt;/h1&gt;
    &lt;/div&gt;
    &lt;div className=""row""&gt;
        &lt;div className=""col-md""&gt;
        &lt;p&gt;Coronavirus disease (COVID-19) is an infectious disease caused by a new virus.
            The disease causes respiratory illness (like the flu) with symptoms such as a
            cough, fever, and in more severe cases, difficulty breathing. You can protect
            yourself by washing your hands frequently, avoiding touching your face, and 
            avoiding close contact (1 meter or 3 feet) with people who are unwell.&lt;/p&gt;
        &lt;/div&gt;
        &lt;div className=""col-md""&gt;
            &lt;img&gt;&lt;/img&gt;
        &lt;/div&gt;
    &lt;/div&gt;
</code></pre>

<p>
<a href=""https://i.stack.imgur.com/0bbNB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0bbNB.png"" alt=""Rendered elements""></a></p>
"
61634265,"<p>im still new on using react native and i have the problem like this:
im trying to get the data from this api which is <a href=""https://covid19.mathdro.id/api"" rel=""nofollow noreferrer"">https://covid19.mathdro.id/api</a>
just to get the values for the death patients but i got nothing in the app it doesn't show the value of the deaths but in the console it show both the value and details
here are the code that i use:</p>

<pre><code>class Deaths extends React.Component{
constructor(){
    super();
    this.state = {
        Dead: [
        ],
        refreshing: false
    }

}

}
renderItem = ({item}) =&gt; (
    &lt;View&gt;
        &lt;Text&gt;{item.value}&lt;/Text&gt;
        &lt;Text&gt;{item.detail}&lt;/Text&gt;&lt;/View&gt;

)


onRefresh = () =&gt; {
    this.getDataApi();

}

componentDidMount = () =&gt; {
    this.getDataApi();
}

getDataApi = async () =&gt;{
    this.setState({ refreshing: true})
    const response = await fetch('https://covid19.mathdro.id/api/')
    const json = await response.json();
    this.setState({Dead: json.deaths, refreshing: false})
}

render(){
    console.log(this.state.Dead)
    return(
        &lt;View&gt;
            &lt;FlatList
                data={this.state.Dead}
                keyExtractor={item =&gt; item.deaths.toString()}
                renderItem={this.renderItem}
                refreshing = {this.state.refreshing}
                onRefresh={this.onRefresh}
            /&gt;
        &lt;/View&gt;
    )
}
</code></pre>
"
61608071,"<p>I was trying to make a Bar Chart using D3 by calling the data from the JSON API, I was able to make a single bar visible but not able to make other bars visible. I hope there is some issue placing of the bars.</p>

<p>Different rectangles are visible in the developer tool, but all are coming up in a same place.</p>

<p>Any help would be much appreciated.</p>

<pre><code>// javascript

const svg = d3.select('svg');
const width = +svg.attr('width');
const height = +svg.attr('height');

// Get the data from the JSON api 
d3.json(""https://api.covid19india.org/data.json"")
    .then( data =&gt; {

        // Store the data in two variales
        var stateNames = [];
        var confirmedCases = [];
        for (let i=1; i &lt;= 10; i++){ //i &lt;= (data.statewise.length) - 1
                stateNames.push(data.statewise[i].state);
                confirmedCases.push(+(data.statewise[i].confirmed));
            }
        //console.log(stateNames);
        //console.log(confirmedCases);
        // Max number of cases
        let sortedData = [...confirmedCases];
        let sortedCases = sortedData.sort(function(a,b){
            return a-b;
        })

        // Measurement of the SVG Element
        const margin = { top: 20, right: 20, bottom: 20, left: 100};
        const innerWidth = width - margin.left - margin.right; 
        const innerHeight = height - margin.top - margin.bottom;


// Horizontal Visualization of Bar Graph
        // X scale
        const xScale = d3.scaleLinear()
                         .domain([0, sortedCases[sortedCases.length-1]])
                         .range([0, innerWidth]);

        //console.log(xScale.domain()); 
        //console.log(xScale.range());

        const yScale = d3.scaleBand()
                     .domain(stateNames)
                     .range([0, innerHeight])
                     .padding(0.2);

        //console.log(yScale.domain());

        const yAxis = d3.axisLeft(yScale); 

        const g = svg.append('g')
                 .attr('transform', `translate(${margin.left},${margin.top})`);

        g.append('g').call(d3.axisLeft(yScale));
        g.append('g').call(d3.axisBottom(xScale))
                .attr('transform', `translate(0,${innerHeight})`);

        g.selectAll('rect').data(confirmedCases).enter()
            .append('rect')
            .attr('width', xScale)
            .attr('height', 30)



})
</code></pre>

<p>Reference to the codepen link, where I have tried</p>

<p><a href=""https://codepen.io/Jagat_Nayan/pen/mdepwgZ"" rel=""nofollow noreferrer"">https://codepen.io/Jagat_Nayan/pen/mdepwgZ</a></p>
"
61214973,"<p>I am reading data in from a <code>.csv</code> file and inputting the data into a <code>chart.js</code> graph to render.  Please took a look at my code.  It only renders when I inspect element after I hit display state the button. 
Also, can I modify my <code>getdata</code> function to update the data for the graphs and re-render it? </p>

<p>JavaScript below:</p>

<pre><code>window.onload = function () {
    chartItCountryCases();
    chartItCountryDeaths();
    getData(state);

}


function chartItCTCases(cases, days) {
        var ctx = document.getElementById('CoronaChartCTCases').getContext('2d');
        var myChart = new Chart(ctx, {
            type: 'bar',
            data: {
                labels: days,
                datasets: [{
                  label: 'Cases',
                  data: cases,
                  backgroundColor: ""rgb(207,181,59)""
                }]
            },
            options: {
                title: {
                    display: true,
                    text: 'Total CoronaVirus Cases in the State'
                },
                maintainAspectRatio: false,
                responsive: true,
                  scales: {
                    xAxes: [ {
                    ticks: {
                        autoSkip: true,
                        maxTicksLimit: 12
                    },
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'Days since first case in the State'
                      },
                    } ],
                    yAxes: [ {
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'Total Cases in the state'
                      }
                            } ]
                        }
            }
        });

        myChart.render();
    }

    function chartItCTDeaths(deaths, days) {
        var ctx = document.getElementById('CoronaChartCTDeaths').getContext('2d');
        var myChart = new Chart(ctx, {
            type: 'bar',
            data: {
            labels: days,
            datasets: [{
              label: 'Deaths',
              data: deaths,
              backgroundColor: ""rgb(207,181,59)""
            }]
          },
          options: {
                title: {
                    display: true,
                    text: 'Total CoronaVirus Deaths in the State'
                },
                responsive: true,
                maintainAspectRatio: false,
                  scales: {
                    xAxes: [ {
                    ticks: {
                        autoSkip: true,
                        maxTicksLimit: 12
                    },
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'Days since first case in the State'
                      },
                    } ],
                    yAxes: [ {
                      display: true,
                      scaleLabel: {
                        display: true,
                        labelString: 'Total Deaths in the state'
                      }
                            } ]
                        }
            }
        });

        myChart.render();
    }


function getData(state) { 
        cases = [];
        deaths = [];
        days = [];
        fetch('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv')
        .then((response) =&gt; {
            return response.text(); 
        })
        .then((data) =&gt; {
            const table = data.split('\n').slice(1);
            curDay = 0;
            table.forEach((row) =&gt; { 
                const columns = row.split(','); 
                if(columns[1]==state) {
                    cases.push(columns[3]);
                    deaths.push(columns[4]);
                    days.push(curDay++);
                }   
            });
        })
        chartItCTCases(cases, days);
        chartItCTDeaths(deaths, days);
    }
</code></pre>

<p>HTML below:</p>

<pre><code>&lt;div class=""col-xs-12"" &gt;
                &lt;div style=""height: 300px; width: 45%;display:inline-block;""&gt;&lt;/&gt; 
                    &lt;canvas id=""CoronaChartCTCases""&gt; &lt;/canvas&gt; 
                &lt;/div&gt;
                &lt;div style=""height: 300px; width: 45%;display:inline-block;""&gt; 
                    &lt;canvas id=""CoronaChartCTDeaths"" &gt;&lt;/canvas&gt;
                &lt;/div&gt;
            &lt;/div&gt; 
</code></pre>
"
60787056,"<p>I'm currently developing a medical application that deals with artificial respiration ( important project for COVID-19 especially ), the application works fine but I have a problem based on design selection.</p>

<p>In medical application world, you can find a ton of brands of artificial respiration machines, and I'd like my application to be able to simulate the look that each machines have.</p>

<p>For example : </p>

<p>Here's an artifical repirator UI => <a href=""https://www.swissinfo.ch/image/45620400/3x2/640/426/99f9e3cd33cb41fcaabfb8d48daffa69/Ky/hamilton.jpg"" rel=""nofollow noreferrer"">https://www.swissinfo.ch/image/45620400/3x2/640/426/99f9e3cd33cb41fcaabfb8d48daffa69/Ky/hamilton.jpg</a></p>

<p>And here's another one =><a href=""https://afiris.si/wp-content/uploads/2017/11/SV-300-3-1-e1522149651805.jpg"" rel=""nofollow noreferrer"">https://afiris.si/wp-content/uploads/2017/11/SV-300-3-1-e1522149651805.jpg</a></p>

<p>They both have the same functions and buttons but not the same design, hence I'd like to know if there is a way to make the user be able to select the UI of the website with a dropdown list ( it can be a plugin, a code, HTML, CSS, JS, anything ! )</p>

<p>Thank you for your reponses ! =)</p>
"
60987082,"<p>I am working on an Angular app where I am showing data in table. Now when I click on any column of data it is sorting data in ascending and descending order.</p>

<p>Now what I want is when I initially load class it should not set any class but when I click on column (td) I want to display a down arrow (for descending order) up arrow(for ascending order). Also when I click on other column current column should remove class which I had set.</p>

<p>But when I load by default down arrow is there on all columns where I only want to set classes on particular td when I click on it and it should get removed if i click on some other class.</p>

<p>Reference link of how actually it should work here <a href=""https://www.covid19india.org/"" rel=""nofollow noreferrer"">reference demo link</a></p>

<p>Here is my code</p>

<p><strong>data.html</strong></p>

<pre><code>&lt;tr&gt;
   &lt;th (click)=""sortAscending(sortedData)""  
   [ngClass]=""status ? 'down-arrow' : 'up-arrow'""&gt;    State   &lt;/th&gt;
   &lt;th (click)=""sortAscendingActive(sortedData)"" 
   [ngClass]=""status ? 'down-arrow' : 'up-arrow'""&gt;   Active Cases  &lt;/th&gt;
   &lt;th (click)=""sortAscendingConfirmed(sortedData)"" 
   [ngClass]=""status ? 'down-arrow' : 'up-arrow'""&gt; Confirmed Cases  &lt;/th&gt;
   &lt;th (click)=""sortAscendingDeath(sortedData)""
   [ngClass]=""status ? 'down-arrow' : 'up-arrow'""&gt;   Death  &lt;/th&gt;
&lt;/tr&gt;
</code></pre>

<p><strong>data.ts</strong></p>

<pre><code>status =false

  sortByMaxCases(sortedDataBasedOnDate) {
    this.isAscendingSort = !this.isAscendingSort;
   this.status=true

    sortedDataBasedOnDate.forEach(item =&gt; item.statewise.sort(function (a, b) {
      if (b.confirmed &lt; a.confirmed) {
        return -1;
      }
      if (b.confirmed &gt; a.confirmed) {
        return 1;
      }
      return 0;
    }))
    this.calculateDiff(this.sortedDataBasedOnDate)

    if (!this.isAscendingSort) {
     this.status=!this.status
      sortedDataBasedOnDate.forEach(item =&gt; item.statewise.sort(function (a, b) {
        if (a.confirmed &lt; b.confirmed) {
          return -1;
        }
        if (a.confirmed &gt; b.confirmed) {
          return 1;
        }
        return 0;
      }))

      this.calculateDiff(this.sortedDataBasedOnDate)
    }
  }


</code></pre>

<p>Any help will be great.</p>
"
61668019,"<p>The COVID-19 tracking project (api described <a href=""https://covidtracking.com/api"" rel=""nofollow noreferrer"">here</a>) provides data on many aspects of the pandemic. Each row of the JSON is one day's data for one state. As many people know, the pandemic is hitting different states differently -- New York and its neighbors hardest first, with other states being hit later. Here is a subset of the data:</p>

<pre><code>date,state,positive,negative
20200505,AK,371,22321
20200505,CA,56212,723690
20200505,NY,321192,707707
20200505,WY,596,10319
20200504,AK,370,21353
20200504,CA,54937,692937
20200504,NY,318953,688357
20200504,WY,586,9868
20200503,AK,368,21210
20200503,CA,53616,662135
20200503,NY,316415,669496
20200503,WY,579,9640
20200502,AK,365,21034
20200502,CA,52197,634606
20200502,NY,312977,646094
20200502,WY,566,9463
</code></pre>

<p>To get the entire data set I am doing this:</p>

<pre><code>import pandas as pd
all_states = pd.read_json(""https://covidtracking.com/api/v1/states/daily.json"")
</code></pre>

<p>I would like to be able to summarize the data by adding up the values for one column, but only for certain states; and then adding up the same column, for the states not included before. I was able to do this, for instance:</p>

<pre><code>not_NY = all_states[all_states['state'] != 'NY'].groupby(['date'], as_index = False).hospitalizedCurrently.sum()
</code></pre>

<p>This creates a new dataframe from all_states, grouped by date, and summing for all the states that are not ""NY"". What I want to do, though, is exclude <em>multiple</em> states with something like a ""not in"" function (this doesn't work):</p>

<pre><code>not_tristate = all_states[all_states['state'] not in ['NY','NJ','CT']].groupby(['date'], as_index = False).hospitalizedCurrently.sum()
</code></pre>

<p>Is there a way to do that? An alternate approach I tried is to create a new dataframe as a pivot table, with one row per date, one column per state, like this:</p>

<pre><code>pivot_states = all_states.pivot_table(index = 'gooddate', columns = 'state', values = 'hospitalizedCurrently', aggfunc='sum')
</code></pre>

<p>but this still leaves me with creating new columns from summing only some columns. In SQL, I would solve the problem like this:</p>

<pre><code>SELECT all_states.Date AS [Date], Sum(IIf([all_states]![state] In (""NY"",""NJ"",""CT""),[all_states]![hospitalizedCurrently],0)) AS tristate, Sum(IIf([all_states]![state] Not In (""NY"",""NJ"",""CT""),[all_states]![hospitalizedCurrently],0)) AS not_tristate
FROM all_states
GROUP BY all_states.Date
ORDER BY all_states.Date;
</code></pre>

<p>The end result I am looking for is like this (using the sample data above and summing on the 'positive' column, with 'NY' standing in for 'tristate'):</p>

<pre><code>date,not_tristate,tristate
20200502,53128,312977,366105
20200503,54563,316415,370978
20200504,55893,318953,374846
20200505,57179,321192,378371
</code></pre>

<p>Any help would be welcome.</p>
"
61580746,"<p>I am doing a basic visualisation for Covid-19 and in one of the tabs I have a table. I can't seem to get the writing above and below the table in another colour. I've included an image that highlights the writing that I need changed. </p>

<p><img src=""https://i.stack.imgur.com/KeQVP.png"" alt=""https://i.stack.imgur.com/qbcke.png""></p>

<p>I would also like to build a light and dark mode but I can't find any code that would work in the form I have the app now. My code with these issues is currently as follows</p>

<pre><code>library(dplyr)
library(shiny)
library(shinythemes)

####################### READ CSV #############################
ncov &lt;- read.csv(""https://raw.githubusercontent.com/datasets/covid-19/master/data/time-series-19-covid-combined.csv"")
ncov = ncov %&gt;% rename(Country = Country.Region)
###########################################################

ui &lt;- fluidPage(
  theme = shinytheme(""slate""),
  tags$head(
    tags$style(
      ""
@import url('https://fonts.googleapis.com/css?family=Pacifico&amp;display=swap');

h2 {
    font-family: 'Pacifico', cursive;
    font-size: 48px;
    margin-bottom: 25px;
}
ul.nav li a {
    background-color: lightgrey;
}

    #To change text and background color of the `Select` box 
    .dataTables_length select {
      color: #0E334A;
        background-color: #0E334A
    }

  ##To change text and background color of the `Search` box 
  .dataTables_filter input {
    color: #0E334A;
      background-color: #0E334A
  }

  thead {
    color: #ffffff;
  }

  tbody {
    color: #000000;
  }


""
    )
  ),
    mainPanel(
      tabsetPanel(type = ""tabs"",

                  tabPanel(title = ""Table"", icon = icon(""table""),
                           tags$br(),
                           dataTableOutput(""table""))
               )
             )
             )

server &lt;- function(input, output) {

  output$table &lt;- DT::renderDT({
   ncov %&gt;%
      group_by(Country) %&gt;%
      arrange(Country) %&gt;%
      slice(1) %&gt;%
      ungroup() %&gt;%
      arrange(Country)  
  })

}

shinyApp(ui = ui, server = server)
</code></pre>
"
61535415,"<p>I´m trying to access the Corona Virus CSV file hosted on <a href=""http://covid.saude.gov.br"" rel=""nofollow noreferrer"">http://covid.saude.gov.br</a>, but there is no HTML content to parse with rvest package. The page is generated by firebase application. Here is the source code of the page.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;

&lt;head&gt;
    &lt;meta charset=""utf-8""/&gt;
    &lt;title&gt;Coronavírus Brasil&lt;/title&gt;

    &lt;base href=""/""/&gt;

    &lt;meta name=""viewport""
          content=""viewport-fit=cover, width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no""/&gt;
    &lt;meta name=""format-detection"" content=""telephone=no""/&gt;
    &lt;meta name=""msapplication-tap-highlight"" content=""no""/&gt;
    &lt;link rel=""stylesheet"" href=""https://unpkg.com/leaflet@1.5.1/dist/leaflet.css""
          integrity=""sha512-xwE/Az9zrjBIphAcBb3F6JVqxf46+CDLwfLMHloNu6KEQCAWi6HcDUbeOfBIptF7tcCzusKFjFw2yuvEpDL9wQ==""
          crossorigin=""""/&gt;

    &lt;link rel=""icon"" type=""image/png"" href=""assets/imgs/Favicon.png""/&gt;

    &lt;!-- add to homescreen for ios --&gt;
    &lt;meta name=""apple-mobile-web-app-capable"" content=""yes""/&gt;
    &lt;meta name=""apple-mobile-web-app-status-bar-style"" content=""black""/&gt;
    &lt;!-- The core Firebase JS SDK is always required and must be listed first --&gt;
      &lt;script src=""https://www.gstatic.com/firebasejs/7.12.0/firebase-app.js""&gt;&lt;/script&gt;

      &lt;!-- TODO: Add SDKs for Firebase products that you want to use
      https://firebase.google.com/docs/web/setup#available-libraries --&gt;
      &lt;script src=""https://www.gstatic.com/firebasejs/7.12.0/firebase-analytics.js""&gt;&lt;/script&gt;

      &lt;script&gt;
            // Your web app's Firebase configuration
            var firebaseConfig = {
            apiKey: ""AIzaSyDoHC6J1pxoKZtLNqNX4UpVWEaGdjy5ATE"",
            authDomain: ""covid-saude.firebaseapp.com"",
            databaseURL: ""https://covid-saude.firebaseio.com"",
            projectId: ""covid-saude"",
            storageBucket: ""covid-saude.appspot.com"",
            messagingSenderId: ""1097006543403"",
            appId: ""1:1097006543403:web:a308f2e4e006a72592706e"",
            measurementId: ""G-VE7NTSSB9X""
            };
            // Initialize Firebase
            firebase.initializeApp(firebaseConfig);
            firebase.analytics();
      &lt;/script&gt;
&lt;link rel=""stylesheet"" href=""styles.f19219a3da5ded85f5db.css""&gt;&lt;/head&gt;

&lt;body&gt;
&lt;app-root&gt;&lt;/app-root&gt;
&lt;script src=""runtime-es2015.6a60e601fd1c50dddd74.js"" type=""module""&gt;&lt;/script&gt;&lt;script src=""runtime-es5.6a60e601fd1c50dddd74.js"" nomodule defer&gt;&lt;/script&gt;&lt;script src=""polyfills-es5.3f81798dab399e8c607f.js"" nomodule defer&gt;&lt;/script&gt;&lt;script src=""polyfills-es2015.c1f142d23713235da53a.js"" type=""module""&gt;&lt;/script&gt;&lt;script src=""scripts.3e3259fea52df4adcf5b.js"" defer&gt;&lt;/script&gt;&lt;script src=""main-es2015.e24b034b00be1f140463.js"" type=""module""&gt;&lt;/script&gt;&lt;script src=""main-es5.e24b034b00be1f140463.js"" nomodule defer&gt;&lt;/script&gt;&lt;/body&gt;

&lt;script type=""text/javascript""&gt;
      (function(){(function(){function a(){if(void 0===b.dialogArguments)return navigator.cookieEnabled;document.cookie=""__dTCookie=1"";var a=-1!==document.cookie.indexOf(""__dTCookie"");document.cookie=""__dTCookie=1; expires=Thu, 01-Jan-1970 00:00:01 GMT"";return a}if(window.dT_)window.console&amp;&amp;window.console.log(""Duplicate agent injection detected, turning off redundant initConfig."");else{var b=""undefined""!==typeof window?window:self;a()&amp;&amp;(window.dT_||(window.dT_={cfg:""app=dfe0c9b2171df634|cors=1|featureHash=A2SVfqru|reportUrl=https://bf51981tgr.bf.dynatrace.com/bf|rdnt=1|uxrgce=1|bp=2|cuc=46s458bt|srms=1,1,,,|uxrgcm=100,25,300,3;100,25,300,3|dpvc=1|lastModification=1585265376157|dtVersion=10187200323152418|tp=500,50,0,1|uxdcw=1500|featureHash=A2SVfqru|agentUri=https://js-cdn.dynatrace.com/jstag/17052aca8bb/ruxitagent_A2SVfqru_10187200323152418.js|auto=|domain=|rid=RID_|rpid=|app=dfe0c9b2171df634"",
      iCE:a}))}})();}).call(this);
      (function(){(function(){function Ob(){return ta?new ta:ua?new ua(""MSXML2.XMLHTTP.3.0""):d.XMLHttpRequest?new d.XMLHttpRequest:new d.ActiveXObject(""MSXML2.XMLHTTP.3.0"")}function Pb(){ua=ta=void 0}function u(){var a=0;try{a=d.performance.timing.navigationStart+Math.floor(d.performance.now())}catch(b){}return 0&gt;=a||isNaN(a)||!isFinite(a)?(new Date).getTime():a}function R(a,b){function c(){delete la[g];a.apply(this,arguments)}for(var e=[],J=2;J&lt;arguments.length;J++)e[J-2]=arguments[J];var g;""apply""in va?g=va.apply(d,
      [c,b].concat(e)):g=va(c,b);la[g]=!0;return g}function $a(a){delete la[a];""apply""in ca?ca.call(d,a):ca(a)}function k(a){for(var b=[],c=1;c&lt;arguments.length;c++)b[c-1]=arguments[c];a.push.apply(a,b)}function ab(a){k(da,a)}function Qb(a){for(var b=da.length;b--;)if(da[b]===a){da.splice(b,1);break}}function Rb(){return da}function Sb(a,b){return bb(a,b)}function Tb(a,b){a=new Ub([a],{type:b});return Vb(a)}function Wb(a,b){return cb?new cb(a,b):void 0}function Xb(a){""function""===typeof a&amp;&amp;k(db,a)}function Yb(){return db}
      function Zb(){return Da}function eb(a){return function(){for(var b=[],c=0;c&lt;arguments.length;c++)b[c]=arguments[c];if(""number""!==typeof b[0]||!la[b[0]])try{return a.apply(this,b)}catch(e){return a(b[0])}}}function $b(){ma&amp;&amp;(d.clearTimeout=ca,d.clearInterval=Ea,ma=!1)}function ea(a,b){return isNaN(a)||isNaN(b)?0:Math.floor(Math.random()*(b-a+1))+a}function v(a,b){return parseInt(a,b||10)}function p(a,b,c){void 0===c&amp;&amp;(c=0);var e=-1;b&amp;&amp;a&amp;&amp;a.indexOf&amp;&amp;(e=a.indexOf(b,c));return e}function fb(a){return document.getElementsByTagName(a)}
      function gb(a){var b=a.length;if(""number""===typeof b)a=b;else{for(var b=0,c=2048;a[c-1];)b=c,c+=c;for(var e=7;1&lt;c-b;)e=(c+b)/2,a[e-1]?b=e:c=e;a=a[e]?c:b}return a}function ac(a){a=encodeURIComponent(a);var b=[];if(a)for(var c=0;c&lt;a.length;c++){var e=a.charAt(c);k(b,bc[e]||e)}return b.join("""")}function S(a){if(!a)return"""";var b=d.crypto||d.msCrypto;if(b){var c=new Int8Array(a);b.getRandomValues(c)}else for(c=[],b=0;b&lt;a;b++)c.push(ea(0,32));a=[];for(b=0;b&lt;c.length;b++){var e=Math.abs(c[b]%32);a.push(String.fromCharCode(e+
      (9&gt;=e?48:55)))}return a.join("""")}function hb(){return!(!d.console||!d.console.log)}function cc(){try{dc.apply(d.parent,arguments)}catch(a){}}function ec(){try{fc.apply(d.top,arguments)}catch(a){}}function gc(a){var b=Array.prototype.slice.call(arguments,1);try{hc.apply(a,b)}catch(c){}}function ic(a){var b=Array.prototype.slice.call(arguments,1);try{jc.apply(a,b)}catch(c){}}function K(){return d.dT_}function kc(){return B}function lc(){return ib}function mc(){return jb}function nc(){return wa}function kb(){return""dtAdk""}
      function oc(){return fa}function lb(a){-1&lt;d.dT_.io(a,""^"")&amp;&amp;(a=a.split(""^^"").join(""^""),a=a.split(""^dq"").join('""'),a=a.split(""^rb"").join(""&gt;""),a=a.split(""^lb"").join(""&lt;""),a=a.split(""^p"").join(""|""),a=a.split(""^e"").join(""=""),a=a.split(""^s"").join("";""),a=a.split(""^c"").join("",""),a=a.split(""^bs"").join(""\\""));return a}function pc(){return T}function qc(a){T=a}function mb(a){var b=d.dT_,c=b.scv(""rid""),b=b.scv(""rpid"");c&amp;&amp;(a.rid=c);b&amp;&amp;(a.rpid=b)}function nb(a){if(a.xb){a=lb(a.xb);try{T=new RegExp(a)}catch(b){}}}
      function ob(a){var b={};a=a.split(""|"");for(var c=0;c&lt;a.length;c++){var e=a[c].split(""="");2===e.length&amp;&amp;(b[e[0]]=decodeURIComponent(e[1].replace(/\+/g,"" "")))}return b}function Fa(){var a=n(""csu"");return(a.indexOf(""dbg"")===a.length-3?a.substr(0,a.length-3):a)+""_""+n(""app"")+""_Store""}function xa(a,b,c){b=b||{};a=a.split(""|"");for(var e=0;e&lt;a.length;e++){var d=a[e],g=p(a[e],""="");-1===g?b[d]=""1"":(d=a[e].substring(0,g),b[d]=a[e].substring(g+1,a[e].length))}!c&amp;&amp;(c=b,a=c.spc)&amp;&amp;(e=document.createElement(""textarea""),
      e.innerHTML=a,c.spc=e.value);return b}function U(a){return a in f?f[a]:ya[a]}function l(a){a=U(a);return""false""===a||""0""===a?!1:!!a}function L(a){var b=v(U(a));isNaN(b)&amp;&amp;(b=ya[a]);return b}function n(a){return String(U(a)||"""")}function rc(a,b){f[a]=b}function pb(a){return f=a}function qb(a){var b=location.hostname;return b&amp;&amp;a?b===a||-1!==b.indexOf("".""+a,b.length-("".""+a).length):!0}function Ga(a){f[a]=0&gt;p(f[a],""#""+a.toUpperCase())?f[a]:""""}function Ha(a){var b=a.agentUri;b&amp;&amp;-1&lt;p(b,""_"")&amp;&amp;(b=/([a-zA-Z]*)[0-9]{0,4}_([a-zA-Z_0-9]*)_[0-9]+/g.exec(b))&amp;&amp;
      b.length&amp;&amp;2&lt;b.length&amp;&amp;(a.csu=b[1],a.featureHash=b[2])}function Ia(a,b){qb(f.domain||"""")||(f.domainOverride=location.hostname+"",""+f.domain,delete f.domain);f.pVO&amp;&amp;(a.pVO=f.pVO);b||(a.bp=a.bp||ya.bp,1===h&amp;&amp;a.bp1&amp;&amp;(a.bp=1),a.bp2&amp;&amp;(a.bp=2),4!==a.bp||d.JSON||(a.bp=1))}function sc(){return f}function C(a,b){try{var c=na;c&amp;&amp;c.setItem(a,b)}catch(e){}}function oa(a){try{var b=na;if(b)return b.getItem(a)}catch(c){}return null}function M(a){try{var b=na;b&amp;&amp;b.removeItem(a)}catch(c){}}function za(a,b){if(V()&amp;&amp;
      (!K().A||rb))return a.apply(this,b||[])}function V(){return!l(""coo"")||l(""cooO"")||rb}function m(a){document.cookie=a+'="""";path=/'+(n(""domain"")?"";domain=""+n(""domain""):"""")+""; expires=Thu, 01 Jan 1970 00:00:01 GMT;""}function sb(a,b,c){var e=1,d=0;do document.cookie=a+'=""""'+(b?"";domain=""+b:"""")+"";path=""+c.substr(0,e)+""; expires=Thu, 01 Jan 1970 00:00:01 GMT;"",e=c.indexOf(""/"",e),d++;while(-1!==e&amp;&amp;5&gt;d)}function N(a){var b=document.cookie;if(!b)return"""";var c=a+""="";a=p(b,c);if(0&gt;a)return"""";for(;0&lt;=a;)if(a&amp;&amp;
      "" ""!==b.charAt(a-1)&amp;&amp;"";""!==b.charAt(a-1))a=p(b,c,a+c.length);else return c=a+c.length,a=p(b,"";"",a),0&lt;=a?b.substring(c,a):b.substr(c);return""""}function tc(a,b,c,e){b||0===b?(b=(""""+b).replace(/[;\n\r]/g,""_""),a=a+""=""+b+"";path=/""+(n(""domain"")?"";domain=""+n(""domain""):""""),c&amp;&amp;(a+="";expires=""+c.toUTCString()),e&amp;&amp;(a+="";Secure""),document.cookie=a):m(a)}function D(a,b,c,e){za(tc,[a,b,c,e])}function pa(a){var b=/^[0-9A-Za-z_=:\$\+\/\.\-\*%\|]*$/.test(a);return a&amp;&amp;2&lt;a.split(""$"").length?!1:b}function tb(){var a=
      N(B);a||((a=oa(B))&amp;&amp;pa(a)?W(a):a="""");return pa(a)?a:""""}function W(a){D(B,a,void 0,l(""ssc""))}function qa(a){return 32===a.length||12&gt;=a.length?a:""""}function ub(a){if(!isNaN(Number(a))){var b=v(a);if(-99&lt;=b&amp;&amp;99&gt;=b)return a}return""""}function vb(a){var b={sessionId:"""",b:""""},c=p(a,""|""),e=a;-1!==c&amp;&amp;(e=a.substring(0,c));c=p(e,""$"");-1!==c?(b.sessionId=qa(e.substring(c+1)),b.b=ub(e.substring(0,c))):b.sessionId=qa(e);return b}function wb(a){var b={sessionId:"""",b:""""};a=a.split(""v""===a.charAt(0)?""_"":""="");if(2&lt;
      a.length&amp;&amp;!(a.length%2)){var c=Number(a[1]);if(isNaN(c)||3&gt;c)return b;for(var c={},e=2;e&lt;a.length;e++)c[a[e]]=a[e+1],e++;c.sn?b.sessionId=qa(c.sn):b.sessionId=""hybrid"";c.srv&amp;&amp;(b.b=ub(c.srv));a=K();""1""!==c.ol||0&lt;=p(navigator.userAgent,""RuxitSynthetic"")||(C(""dtDisabled"",""true""),a.disabled=!0,a.A=!0)}return b}function Ja(){return!l(""dpvc"")&amp;&amp;!l(""pVO"")}function ga(a){var b=document.cookie?document.cookie.split(a+""="").length-1:0;if(1&lt;b){var c=n(""domain"")||d.location.hostname,e=d.location.hostname,J=d.location.pathname,
      g=0,f=0;w.push(a);do{var h=e.substr(g);if(h!==c||""/""!==J){sb(a,h===c?"""":h,J);var k=document.cookie?document.cookie.split(a+""="").length-1:0;k&lt;b&amp;&amp;(w.push(h),b=k)}g=e.indexOf(""."",g)+1;f++}while(g&amp;&amp;10&gt;f&amp;&amp;1&lt;b);n(""domain"")&amp;&amp;1&lt;b&amp;&amp;sb(a,"""",J)}}function uc(){ga(fa);ga(B);ga(wa);ga(""rxvt"");ab(function(a,b,c,e){0&lt;w.length&amp;&amp;!b&amp;&amp;(a.av(e,0,""dCN"",function(){return w.join("","")}),a.av(e,4,""duplicateCookieNames"",function(){return w.slice()}),w=[])})}function vc(){return ha}function Aa(a,b,c,e,d){var g=document.createElement(""script"");
      g.setAttribute(""src"",a);b&amp;&amp;g.setAttribute(""defer"",""true"");c&amp;&amp;(g.onload=c);e&amp;&amp;(g.onerror=e);d&amp;&amp;g.setAttribute(""id"",d);g.setAttribute(""crossorigin"",""anonymous"");a=document.getElementsByTagName(""script"")[0];a.parentElement.insertBefore(g,a)}function Ka(a,b){return La+""/""+(b||X)+""_""+a+""_""+(L(""buildNumber"")||K().version)+"".js""}function Ma(a,b){try{d.localStorage&amp;&amp;d.localStorage.setItem(a,b)}catch(c){}}function Na(a){try{if(d.localStorage)return d.localStorage.getItem(a)}catch(b){}return null}function E(a){try{d.localStorage&amp;&amp;
      d.localStorage.removeItem(a)}catch(b){}}function xb(a){if(a=a||tb()){var b=a.charAt(0);return""v""===b||""=""===b?wb(a):vb(a)}return{sessionId:"""",b:""""}}function ia(a){return xb(a).b}function ja(a){return xb(a).sessionId}function yb(a,b){b=r(b);for(var c=!1,e=0;e&lt;b.length;e++)b[e].frameId===ha&amp;&amp;(b[e].g=a,c=!0);c||k(b,{frameId:ha,g:a});Y(b)}function Y(a,b,c){if(a){var e=0===h;var d=[];for(var g=0;g&lt;a.length;g++)if(""-""!==a[g].g){0&lt;g&amp;&amp;0&lt;d.length&amp;&amp;k(d,""p"");var f=x;f&amp;&amp;(k(d,f),k(d,""$""));k(d,a[g].frameId);k(d,
      ""h"");k(d,a[g].g)}e&amp;&amp;!d.length&amp;&amp;(Oa&amp;&amp;(O(0,!0,""a""),Pa(!1)),x=ia()||"""",k(d,x),k(d,""$""),k(d,ha),k(d,""h-""));a=e?b||Qa():F();if(e||a)k(d,""v""),k(d,a),e=""undefined""!==typeof c?c:t(),0&lt;=e&amp;&amp;(k(d,""e""),k(d,e));d=d.join("""")}else d="""";d||0!==h||(Oa&amp;&amp;(O(0,!0,""a""),Pa(!1)),x=ia()||"""",c=""undefined""!==typeof c?c:t(),d=x+""$""+ha+""h-v""+(b||Qa()+(0&lt;=c?""e""+c:"""")));D(fa,d||""-"",void 0,l(""ssc""))}function r(a){var b=N(fa),c=[];if(b&amp;&amp;""-""!==b){for(var b=b.split(""p""),d="""",f=null,g=0;g&lt;b.length;g++){var h=b[g],n=p(h,""h""),l=p(h,
      ""v""),m=p(h,""e""),y=h.substring(p(h,""$"")+1,n),n=-1!==l?h.substring(n+1,l):h.substring(n+1),d=d||-1!==l?-1!==m?h.substring(l+1,m):h.substring(l+1):"""",f=f||-1!==m?h.substring(m+1):null;(h=a)||(h=v(y.split(""_"")[0]),l=u()%Ra,l&lt;h&amp;&amp;(l+=Ra),h=h+9E5&gt;l);h&amp;&amp;k(c,{frameId:y,g:""-""===n?""-"":v(n)})}for(g=0;g&lt;c.length;g++)c[g].visitId=d||"""",c[g].j=null!==f?v(f):-1}return c}function Qa(){return F()||O(0,!0,""c"")}function F(){var a=r(!0);return Z()&lt;=u()?"""":(ka(!1),1&lt;=a.length?-1!==t()&amp;&amp;2&lt;=L(Sa)&amp;&amp;a[0].j&gt;=L(wc)?O(0,!0,""e""+
      a[0].j,!0):a[0].visitId||"""":P(G)||"""")}function ka(a){var b=u(),c=zb().m;a&amp;&amp;(c=b);Ab(b+Bb+""|""+c);Cb()}function Db(a,b,c){if(c&amp;&amp;(c=r(!0),(c=1&lt;=c.length?c[0].visitId||"""":P(G)||"""")&amp;&amp;(c=/([A-Z]+)-([0-9]+)/g.exec(c))&amp;&amp;3===c.length&amp;&amp;isFinite(Number(c[2]))))return a=c[1]+""-""+(Number(c[2])+1),Eb(a,b),a;a||(a=ea(1,1E6));c=ja()||"""";c||(c=(0===h?-1*ea(Fb,Gb)+""$"":"""")+S(32),W(c),c=ja(c)||"""");a=""""+a;for(var d=a.length,f=[],g=0;g&lt;c.length;g++)f[g]=String.fromCharCode(65+Math.abs((c.charCodeAt(g)^a.charCodeAt(g%d))%
      26));f.push(""-0"");a=f.join("""");Eb(a,b);return a}function Ta(a){var b=r(!1),c=2&lt;=L(Sa)?0:-1;Y(b,a,c);Q(G,a);Q(aa,String(c));ka(!0)}function O(a,b,c,d){b&amp;&amp;(ba=!0);a=Db(u(),c,d);Ta(a);return a}function Eb(a,b){for(var c=0;c&lt;Ua.length;c++)Ua[c](a,ba,b)}function xc(a){Ua.push(a)}function Cb(){Va&amp;&amp;$a(Va);Va=R(Hb,Z()-u())}function Hb(){if(Z()&lt;=u()&amp;&amp;V()){var a=u(),a=Db(a,""t""+(a-Z()));Ta(a);return!0}Ba(Cb);return!1}function Ab(a){D(""rxvt"",a,void 0,l(""ssc""));Q(""rxvt"",a)}function Q(a,b){Ja()?(Ma(a,b),M(a)):
      (C(a,b),E(a))}function Ib(){var a=N(""rxvt"");a||(a=P(""rxvt"")||"""");return a}function Jb(){var a=F()||"""";Q(G,a);a=Ib();Ab(a)}function zb(){var a={v:0,m:0},b=Ib();if(b)try{var c=b.split(""|"");2===c.length&amp;&amp;(a.v=parseInt(c[0],10),a.m=parseInt(c[1],10))}catch(e){}return a}function Z(){var a=zb();return Math.min(a.v,a.m+Kb)}function yc(a){Bb=a}function Pa(a){void 0===a&amp;&amp;(a=!0);Oa=a}function zc(){var a=ba;ba=!1;return a}function Ac(){Hb()||ka(!1)}function Bc(){if(0===h&amp;&amp;-1!==t()&amp;&amp;2&lt;=L(Sa)){var a=r(!1),b=t()+
      1;Y(a,"""",b);Q(aa,String(b))}}function P(a){var b=Na(a);b||(b=oa(a));return b}function t(){var a=r(!0);if(1&lt;=a.length&amp;&amp;!isNaN(a[0].j))return a[0].j;a=P(aa)||""-1"";a=v(a);return isNaN(a)?-1:a}function Ba(a){V()?a():(q||(q=[]),k(q,a))}function Cc(a){return za(a)}function Dc(){for(var a=0;a&lt;q.length;a++)R(q[a],0);q=[];f.cooO=!0}function Ec(){f.cooO=!1;m(B);m(fa);m(wa);m(""dtSa"");m(kb());0===h&amp;&amp;(m(""rxVisitor""),m(""rxvt""));try{Ja()?(E(aa),E(G)):(M(aa),M(G));var a=na;a&amp;&amp;(0===h&amp;&amp;a.removeItem(""rxVisitor""),a.removeItem(B),
      a.removeItem(""rxvt""));(a=Wa)&amp;&amp;a.removeItem(Fa())}catch(b){}}function Fc(){return x}function Gc(){Ba(function(){ja()||W((0===h?-1*ea(Fb,Gb)+""$"":"""")+S(32));x=ia()||""""})}function Xa(){var a=N(""rxVisitor"");if(!a||a.length&amp;&amp;a.length!==Ya)a=Na(""rxVisitor"")||oa(""rxVisitor""),a&amp;&amp;a.length===Ya||(Lb=!0,a=u()+"""",a+=S(Ya-a.length));var b=a;if(Ja()){var c=new Date;c.setFullYear(c.getFullYear()+2);Ma(""rxVisitor"",b)}else C(""rxVisitor"",b);D(""rxVisitor"",b,c,l(""ssc""));return a}function Hc(){return Lb}function Ic(a){var b=
      N(""rxVisitor"");m(""rxVisitor"");M(""rxVisitor"");E(""rxVisitor"");D(""rxVisitor"",b);f.pVO=!0;a&amp;&amp;Ma(Za,""1"");Jb()}function Jc(){E(Za);l(""pVO"")&amp;&amp;(f.pVO=!1,Xa());Jb()}function Kc(){var a=0;try{a=Math.floor(d.performance.now())}catch(b){}return 0&gt;=a||isNaN(a)||!isFinite(a)?(new Date).getTime()-Mb():a}function Mb(){var a=0;try{a=Math.floor(d.performance.B)}catch(c){}if(0&gt;=a||isNaN(a)||!isFinite(a)){var a=d.dT_,b=0;try{b=d.performance.timing.navigationStart}catch(c){}a=0&gt;=b||isNaN(b)||!isFinite(b)?a.gAST():b}return a}
      function Lc(){var a=d.dT_;d.dT_={version:""10187200323152418"",cfg:a?a.cfg:"""",iCE:a?a.iCE:function(){return navigator.cookieEnabled},ica:1,disabled:!1,A:!1,gx:Ob,cx:Pb,mp:cc,mtp:ec,mi:gc,mw:ic,gAST:Zb,ww:Wb,stu:Tb,nw:u,apush:k,st:R,si:Sb,aBPSL:ab,rBPSL:Qb,gBPSL:Rb,aBPSCC:Xb,gBPSCC:Yb,buildType:0===h?""dynatrace"":""appmon"",gSSV:oa,sSSV:C,rSSV:M,rvl:E,pn:v,iVSC:pa,p3SC:wb,pLSC:vb,io:p,dC:m,sC:D,esc:ac,gSId:ia,gDtc:ja,gSC:tb,sSC:W,gC:N,cRN:ea,cRS:S,gEL:gb,gEBTN:fb,gSCN:kc,gPCHN:lc,gRHN:mc,gPCCN:oc,gLCN:nc,
      gMSIDCN:kb,cfgO:sc,pCfg:ob,pCSAA:xa,cFHFAU:Ha,sCD:Ia,bcv:l,ncv:L,scv:n,stcv:rc,rplC:pb,cLSCK:Fa,gFId:vc,gBAU:Ka,iS:Aa,eWE:Ba,oEIE:Cc,oEIEWA:za,eA:Dc,dA:Ec,gcSId:Fc,iNV:Hc,gVID:Xa,dPV:Ic,ePV:Jc,sVIdUP:Pa,sVTT:yc,sVID:Ta,rVID:F,gVI:Qa,gNVId:O,gARnVF:zc,cAUV:Ac,uVT:ka,aNVL:xc,gPC:r,cPC:yb,sPC:Y,clB:$b,ct:$a,aRI:mb,iXB:nb,gXBR:pc,sXBR:qc,de:lb,cCL:hb,gEC:t,iEC:Bc,rnw:Kc,gto:Mb}}var H=window;if(!H.dT_||!H.dT_.cfg||""string""!=typeof H.dT_.cfg||H.dT_.initialized)H.console&amp;&amp;H.console.log(""Initconfig not found or agent already initialized! This is an injection issue."");
      else if(!(navigator.userAgent&amp;&amp;0&lt;=navigator.userAgent.indexOf(""RuxitSynthetic""))){var d=""undefined""!==typeof window?window:self,ta,ua,da,db=[],Da,Wa,na,la={},bc=new (function(){return function(){this[""!""]=""%21"";this[""~""]=""%7E"";this[""*""]=""%2A"";this[""(""]=""%28"";this["")""]=""%29"";this[""'""]=""%27"";this.$=""%24"";this["";""]=""%3B"";this["",""]=""%2C""}}()),va,bb,hc=d.postMessage,cb=d.Worker,Ub=d.Blob,Vb=d.URL&amp;&amp;d.URL.createObjectURL,jc=d.Worker&amp;&amp;d.Worker.prototype.postMessage,dc=d.parent.postMessage,fc=d.top.postMessage,
      ca,Ea,ma=!1,h,ya,fa=""dtPC"",B=""dtCookie"",ib=""x-dtpc"",jb=""x-dtreferer"",wa=""dtLatC"",T,f={},rb=!!navigator.userAgent&amp;&amp;0&lt;=navigator.userAgent.indexOf(""RuxitSynthetic""),w=[],ha,Ra=6E8,Nb,La,X,Mc={childList:!0,subtree:!0,attributes:!0,attributeOldValue:!0},Nc=[""_DT_RENDERING_""],wc=""mel"",Sa=""vs"",aa=""rxec"",G=""rxvisitid"",Va,Bb=18E5,Kb=216E5,ba=!1,Ua=[],Oa=!1,q=[],Fb=2,Gb=21,x,Za=""dt-pVO"",Ya=45,Lb=!1;if(!function(a){try{h=a;var b=d.dT_;ta=d.XMLHttpRequest;ua=d.ActiveXObject;va=d.setTimeout;bb=d.setInterval;
      ma||(ca=d.clearTimeout,Ea=d.clearInterval);if(!((b.iCE?b.iCE():navigator.cookieEnabled)&amp;&amp;(""complete""!==document.readyState||d.performance&amp;&amp;d.performance.timing)))return!1;Lc();try{Wa=d.localStorage,na=d.sessionStorage}catch(Ca){}Da=u();da=[];la={};ma||(d.clearTimeout=eb(ca),d.clearInterval=eb(Ea),ma=!0);ha=Da%Ra+""_""+v(ea(0,1E3)+"""");ya={ade:"""",aew:!0,agentLocation:"""",agentname:"""",agentUri:"""",uana:""data-dtname,data-dtName"",app:"""",async:!1,auto:!1,bandwidth:""300"",bp1:!1,bp2:!1,bp:0===h?1:2,bs:!1,buildNumber:0,
      coo:!1,cooO:!1,cors:!1,csu:"""",cuc:"""",cux:!1,dataDtConfig:"""",debugName:"""",dASXH:0!==h,disableCookieManager:!1,disableLogging:!1,dmo:!1,dpvc:!1,disableXhrFailures:!1,domain:"""",domainOverride:"""",doNotDetect:"""",ds:!0,dsndb:!1,dsss:!1,eni:!1,euf:!1,evl:"""",extblacklist:"""",exteventsoff:!1,fa:!1,fau:!0,featureHash:"""",ffi:!1,hvt:216E5,lastModification:0,imm:!1,initializedModules:"""",ign:"""",instr:"""",iub:"""",lab:!1,legacy:!1,lmut:!0,lzwd:!1,lzwe:!1,mb:"""",md:"""",mdp:"""",mdl:"""",mdn:5E3,mel:200,mepp:10,moa:30,mrt:3,
      mpl:0===h?1024:100,mmds:2E4,msl:3E4,mhl:4E3,name:"""",ncw:!1,ntd:!1,oat:180,ote:!1,perfbv:1,prfSmpl:0,pt:!0,pui:!1,pVO:!1,raxeh:!0,rdnt:0,reportUrl:""dynaTraceMonitor"",restoreTimeline:!1,rid:"""",ridPath:"""",rpid:"""",rt:0===h?1E4:0,rtl:0===h?0:100,rtp:0===h?2:1,rtt:1E3,rtu:200,rx_visitID:"""",sl:100,sosi:!1,spc:"""",srbbv:1,srbw:!0,srad:!0,srmr:100,srms:""1,1,,,"",srsr:1E5,srtbv:3,srtd:1,srtr:500,srvr:"""",srwo:!1,ssc:!1,st:3E3,svNB:!1,syntheticConfig:!1,tal:0,tp:""500,50,3"",tt:100,tvc:3E3,uam:!1,useNewCookies:!1,
      uxdce:!1,uxdcw:1500,uxrgce:!0,uxrgcm:""100,25,300,3;100,25,300,3"",vcfi:0===h,vcit:1E3,vct:50,vcv:1,vcx:50,vs:1,WST:!1,xb:"""",xmut:!0,xt:0};a:{var c=K().cfg;f={reportUrl:""dynaTraceMonitor"",initializedModules:"""",csu:""dtagent"",dataDtConfig:""string""===typeof c?c:""""};K().cfg=f;0===h&amp;&amp;(f.csu=""ruxitagentjs"");var e=f.dataDtConfig;e&amp;&amp;-1===p(e,""#CONFIGSTRING"")&amp;&amp;(xa(e,f),Ga(""domain""),Ga(""auto""),Ga(""app""),Ha(f));var k=fb(""script""),g=gb(k),m=-1===p(f.dataDtConfig||"""",""#CONFIGSTRING"")?f:null;if(0&lt;g)for(a=0;a&lt;g;a++)b:{var b=
      void 0,r=k[a],c=m;if(r.attributes){var x=f.csu+""_bootstrap.js"",e=/.*\/jstag\/.*\/.*\/(.*)_bs(_dbg)?.js$/,D=c,y=r.src,w=y&amp;&amp;y.indexOf(x),E=r.attributes.getNamedItem(""data-dtconfig"");if(E){var t=y,G=E.value,z={};f.legacy=!0;if(t){var q=/([a-zA-Z]*)[0-9]{0,4}_([a-zA-Z_0-9]*)_([0-9]+)/g.exec(t);q&amp;&amp;q.length&amp;&amp;(z.csu=q[1],z.featureHash=q[2],0===h&amp;&amp;(z.agentLocation=t.substr(0,p(t,q[1])-1),z.buildNumber=q[3]))}G&amp;&amp;xa(G,z,!0);qb(z.domain)||(z.domainOverride=location.hostname+"",""+z.domain,delete z.domain);b=z;
      if(!c)D=b;else if(!b.syntheticConfig){m=b;break b}}b||(b=f);if(w&amp;&amp;0&lt;=w){var H=w+x.length+5;b.app=y.length&gt;H?y.substr(H):""Default%20Application""}else if(y){var M=e.exec(y);M&amp;&amp;(b.app=M[1])}m=D}else m=c}if(m)for(var O in m)m.hasOwnProperty(O)&amp;&amp;(k=O,f[k]=m[k]);if(f.rx_visitID){var Q=f.rx_visitID;Q&amp;&amp;(K().rx_visitID=Q)}var aa=Fa();try{var S=(m=Wa)&amp;&amp;m.getItem(aa);if(S){var ra=ob(S),A=xa(ra.config||""""),C=f.lastModification||""0"",W=v((A.lastModification||ra.lastModification||""0"").substr(0,13)),ga=""string""===
      typeof C?v(C.substr(0,13)):C;if(!C||W&gt;=ga)if(A.agentname=ra.name,A.agentUri?Ha(A):(A.csu=ra.name,A.featureHash=ra.featureHash),Ia(A,!0),nb(A),mb(A),W&gt;(f.lastModification||0)){var ia=l(""auto""),ja=l(""legacy"");f=pb(A);f.auto=ia;f.legacy=ja}}}catch(Ca){}Ia(f);try{var Y=f.ign;if(Y&amp;&amp;(new RegExp(Y)).test(d.location.href)){document.dT_=d.dT_=void 0;var sa=!1;break a}}catch(Ca){}f.useNewCookies&amp;&amp;0===h&amp;&amp;(fa=""rxpc"",B=""rxsession"",wa=""rxlatency"",ib=""x-rxpc"",jb=""x-rxreferer"");sa=!0}if(!sa)return!1;uc();try{Nb=
      K().disabled||!!oa(""dtDisabled"")}catch(Ca){}var F;if(!(F=n(""agentLocation"")))a:{var Z=n(""agentUri"");if(Z||document.currentScript){var I=Z||document.currentScript.src;if(I){var ka=-1===p(I,""_bs"")&amp;&amp;-1===p(I,""_bootstrap"")&amp;&amp;-1===p(I,""_complete"")?1:2,P=I.lastIndexOf(""/"");for(sa=0;sa&lt;ka&amp;&amp;-1!==P;sa++)I=I.substr(0,P),P=I.lastIndexOf(""/"");F=I;break a}}var ba=location.pathname;F=ba.substr(0,ba.lastIndexOf(""/""))}La=F;X=n(""agentname"")||n(""csu"")||(0===h?""ruxitagentjs"":""dtagent"");""true""===N(""dtUseDebugAgent"")?
      0&gt;X.indexOf(""dbg"")&amp;&amp;(X=n(""debugName"")||X+""dbg""):X=n(""name"")||X;if(!l(""auto"")&amp;&amp;!l(""legacy"")&amp;&amp;!Nb){var R=n(""agentUri"")||Ka(n(""featureHash"")),T;if(!(T=l(""async"")||""complete""===document.readyState)){var U=d.navigator.userAgent,V=U.indexOf(""MSIE "");T=0&lt;V?9&gt;=parseInt(U.substring(V+5,U.indexOf(""."",V)),10):!1}T?Aa(R,l(""async""),void 0,void 0,""dtjsagent""):(document.write('&lt;script id=""dtjsagentdw"" type=""text/javascript"" src=""'+R+'""&gt;\x3c/script&gt;'),document.getElementById(""dtjsagentdw"")||Aa(R,l(""async""),void 0,
      void 0,""dtjsagent""))}var pa=d.location.href;0===h&amp;&amp;-1!==p(pa,""_DT_RENDERING_"")&amp;&amp;(K().RMOD={conf:Mc,ignore:Nc,ID:""_DT_RENDERING_""},La&amp;&amp;Aa(Ka(""R""),!0,void 0,void 0,""dtjsagent""));N(B)&amp;&amp;(f.cooO=!0);Gc();if(0===h){var qa=!!Na(Za);f.pVO=qa;Ba(Xa)}0===h&amp;&amp;L(""hvt"")&amp;&amp;(Kb=L(""hvt""));za(yb,[1])}catch(Ca){return!1}return!0}(0)){try{delete d.dT_}catch(a){d.dT_=void 0}hb()&amp;&amp;d.console.log(""JsAgent initCode initialization failed!"")}}})();}).call(this);
  &lt;/script&gt;
&lt;/html&gt;</code></pre>
</div>
</div>
</p>

<p>How can I access the CSV file related to the highlighted link shown ? </p>

<p><a href=""https://i.stack.imgur.com/iyfiX.png"" rel=""nofollow noreferrer"">corona.saude.gov.br site</a></p>
"
61220346,"<p>I'm trying to scrape the date and policy type for COVID related announcements from this url: <a href=""https://covid19.healthdata.org/united-states-of-america/alabama"" rel=""nofollow noreferrer"">https://covid19.healthdata.org/united-states-of-america/alabama</a></p>

<p>The first date I'm trying to pull is the ""April 4th, 2020"" date for Alabama's Stay at Home Order.</p>

<p>As far as I can tell (as I am new to this), it has the xpath:</p>

<pre><code> ""//[@id=""root""]/div/main/div[3]/div[1]/div[2]/div[1]/div[1]/div/div/span""
</code></pre>

<p>I've been using the following lines to try to retrieve it - </p>

<pre><code>data &lt;- read_html(url) %&gt;% 
  html_nodes(""span.ant-statistic-content-value"")

data &lt;- read_html(url) %&gt;%
  html_nodes(xpath = ""//*[@id='root']/div/main/div[3]/div[1]/div[2]/div[1]/div[1]/div/div/span"")
</code></pre>

<p>Neither are able to pull the information I'm looking for. Any help would be appreciated!</p>
"
61461933,"<p>I have node.js to charge credit card via stripe I am beginner in node.js , the whole code is working perfectly on development front but I'm getting an error on production side where I have to change credits on credit card payment i.e 5 credits for 5 dollars but credit is not updating only in production its working fine in development 
<a href=""https://i.stack.imgur.com/z3x5g.png"" rel=""nofollow noreferrer"">error on google developer site</a></p>

<p>along with that I'm getting
here is my github site: <a href=""https://github.com/kishanshetty1991/Covid--19-Feedback-app"" rel=""nofollow noreferrer"">https://github.com/kishanshetty1991/Covid--19-Feedback-app</a>
even though i don't think the error is in code but I'm not sure.
Thanks.</p>
"
61005026,"<p>I am learning React js and this might sound like a newbie question. I am trying to implement a paginate function in react js from an API data. I am not sure how to implement the logic though. I have passed on props like the page size, current page and the data that needs to be rendered. Here is my code:</p>

<p>App.js</p>

<pre><code>import React, { Component } from 'react'
import Result from './Result';
import Form from 'react-bootstrap/Form';
import Button from 'react-bootstrap/Button';
import Navbar from 'react-bootstrap/Navbar'
import Card from './Card';
import Loading from './Loading'
import Paginate from './Paginate';


export default class App extends Component {
  constructor(){
    super();
    this.state = {
      data: [],
      totalData:[],
      searchText:'',
      searchResult:[],
      isSearch:false,
      isLoading:true,
      pageSize:15,
      currentPage:1
    }
    this.onSearchChange=this.onSearchChange.bind(this);
    this.handlePageChange=this.handlePageChange.bind(this);
  }

  onSearchChange= (e) =&gt;{
    console.log(""search change ""+this.state.searchText)
    this.setState({
      searchText:e.target.value,
      isSearch:true
    })
    console.log(""api data""+this.state.data[0])
  }

  /* fetchSearchResult= () =&gt;{
    console.log(this.state.searchText)
    console.log(""inside fetch"")
   let store= this.state.data.map(item=&gt;{
      let {country}=item
      return(country)
    })
    console.log(store)
    var areEqual = store.includes(this.state.searchText);
     console.log(this.state.areEqual)
     return (areEqual)? 
      store:'not matched'
  //  return store;

  } */

  componentDidMount() {
    const url =
    'https://corona.lmao.ninja/countries?sort=country'
    fetch(url)
      .then(result =&gt; result.json())
      .then(result =&gt; {
        this.setState({
          data: result.reverse(),
          isLoading:false
        })
      })
      const totalUrl =
      'https://corona.lmao.ninja/all'
      fetch(totalUrl)
        .then(result =&gt; result.json())
        .then(result =&gt; {
          //let store=result;
          //console.log(""store data""+store)
          this.setState({
            totalData: result
          })
          console.log(""2nd fetched data""+this.state.totalData)
        })   
  }

  handlePageChange= (page) =&gt;{
    this.setState({
      currentPage:page
    })

  }
  render() {
    return (

       this.state.isLoading?&lt;Loading/&gt;:
       &lt;div id=""main""&gt;
       &lt;Navbar bg=""dark"" variant=""dark""&gt;
    &lt;Navbar.Brand href=""#home""&gt;
    &lt;Button id=""live_text""
    &gt;Live&lt;/Button&gt;
      &lt;img
        alt=""""
        src=""/logo.svg""
        width=""100""
        height=""30""
        className=""d-inline-block align-top""
      /&gt;{' '}
     Covid-19 dashboard
     {this.state.curTime}
    &lt;/Navbar.Brand&gt;
  &lt;/Navbar&gt;

      &lt;Form.Group&gt;
       &lt;Form.Label&gt;Search&lt;/Form.Label&gt;
        &lt;Form.Control value={this.state.searchText}onChange={this.onSearchChange} type=""text"" placeholder=""Enter country"" /&gt;
      &lt;/Form.Group&gt;
        &lt;Card totalData={this.state.totalData}/&gt;
      &lt;Paginate 
        dataCount={this.state.data.length} 
        pageSize={this.state.pageSize}
        onPageChange={this.handlePageChange}
        currentPage={this.state.currentPage}/&gt;

        &lt;Result data={this.state.data} 
        toSearch={this.state.searchText} 
        searchCheck={this.state.isSearch}
        searchValue={this.state.searchText}/&gt;

    &lt;/div&gt;

    )
  }
}
</code></pre>

<p>Paginate.js</p>

<pre><code>import React from 'react'
import _ from 'lodash'

export default function Paginate(props) {
    const {pageSize, dataCount, onPageChange, currentPage}=props;
    console.log(""current page""+currentPage)
    const pagesCount=Math.ceil(dataCount/pageSize);
    const pages=_.range(1,pagesCount+1);
    return (
        &lt;div&gt;
            &lt;nav aria-label=""...""&gt;
  &lt;ul class=""pagination""&gt;
      {pages.map((page)=&gt;{
          return(
        &lt;li key={page}class={(page===currentPage)?""page-item active"":""page-item""}&gt;
        &lt;a class=""page-link"" href=""#"" onClick={()=&gt;onPageChange(page)}&gt;{page}&lt;/a&gt;
        &lt;/li&gt;
          )
      })}


  &lt;/ul&gt;
&lt;/nav&gt;
        &lt;/div&gt;
    )
}
</code></pre>

<p>Result.js</p>

<pre><code>import React  from 'react'
import Table from 'react-bootstrap/Table';

const Result = (props) =&gt; {
    console.log('props value is:'+props.data)
    let {searchCheck, searchValue}=props;


   let update=props.data.map((item)=&gt;{

    const { countryInfo, country, cases, deaths, recovered, active, casesPerOneMillion} = item;
    return(
    (searchCheck)?country.toUpperCase().includes(searchValue.toUpperCase())?
        &lt;tbody&gt;
        &lt;tr key={countryInfo._id}&gt;
          &lt;td&gt;&lt;img style={{height:'25px',width:'50px'}}src={countryInfo.flag}/&gt;&lt;/td&gt;
         &lt;td&gt;{country}&lt;/td&gt;
          &lt;td&gt;{cases}&lt;/td&gt;
          &lt;td&gt;{active}&lt;/td&gt;
          &lt;td&gt;{recovered}&lt;/td&gt;
          &lt;th&gt;{casesPerOneMillion}&lt;/th&gt;
          &lt;td&gt;{deaths}&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;:
      '':
      &lt;tbody&gt;
        &lt;tr key={countryInfo._id}&gt;
          &lt;td&gt;&lt;img style={{height:'25px',width:'50px'}}src={countryInfo.flag}/&gt;&lt;/td&gt;
         &lt;td&gt;{country}&lt;/td&gt;
          &lt;td&gt;{cases}&lt;/td&gt;
          &lt;td&gt;{active}&lt;/td&gt;
          &lt;td&gt;{recovered}&lt;/td&gt;
          &lt;th&gt;{casesPerOneMillion}&lt;/th&gt;
          &lt;td&gt;{deaths}&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    )  
    })
    return (
      &lt;div&gt;
          &lt;Table striped bordered hover variant=""dark""&gt;
          &lt;thead&gt;
        &lt;tr&gt;

          &lt;th&gt;Flag&lt;/th&gt;
          &lt;th&gt;Country&lt;/th&gt;
          &lt;th&gt;Cases&lt;/th&gt;
          &lt;th&gt;Active&lt;/th&gt;
          &lt;th&gt;Recovered&lt;/th&gt;
          &lt;th&gt;Cases per one Million&lt;/th&gt;
          &lt;th&gt;Deaths&lt;/th&gt;


        &lt;/tr&gt;
      &lt;/thead&gt;
          {update}
          &lt;/Table&gt;
      &lt;/div&gt;
    )
  }
export default Result;
</code></pre>

<p><a href=""https://codesandbox.io/s/vigilant-yalow-4xpdn"" rel=""nofollow noreferrer"">Codesandbox live</a></p>
"
61216943,"<p>I have the following form with few boolean fields: </p>

<pre class=""lang-py prettyprint-override""><code>class RegistrationForm(UserCreationForm):

    guardianSource = forms.BooleanField(widget=forms.CheckboxInput(attrs={'id':'guardianSource'}),required=False)
    bbcSource = forms.BooleanField(required=False)
    independentSource = forms.BooleanField(required=False)

    categoryCoronaVirus = forms.BooleanField(required=False)
    categoryPolitics = forms.BooleanField(required=False)
    categorySport = forms.BooleanField(required=False)

    #Telling the registration form what kind of data we are going to be modelling/ what the form needs to look like
    class Meta:
        model = Account
        fields = (""username"", ""password1"", ""password2"", ""guardianSource"", ""bbcSource"", ""independentSource"", ""categoryCoronaVirus"", ""categoryPolitics"", ""categorySport"")

</code></pre>

<p>The register template looks as following: </p>

<pre class=""lang-html prettyprint-override""><code>&lt;form class=""form-signin"" method=""POST""&gt;{% csrf_token %}

  &lt;h1 class=""h3 mb-3 font-weight-normal""&gt;Register&lt;/h1&gt;



  &lt;label for=""username"" class=""sr-only""&gt;Username&lt;/label&gt;
  &lt;input type=""text"" name=""username"" id=""username"" class=""form-control"" placeholder=""User name"" required autofocus&gt;

  &lt;label for=""inputPassword1"" class=""sr-only""&gt;Password&lt;/label&gt;
  &lt;input type=""password"" name=""password1"" id=""inputPassword1"" class=""form-control"" placeholder=""Password"" required&gt;

  &lt;label for=""inputPassword2"" class=""sr-only""&gt;Password&lt;/label&gt;
  &lt;input type=""password"" name=""password2"" id=""inputPassword2"" class=""form-control"" placeholder=""Confirm Password"" required&gt;
    &lt;br&gt;
  &lt;div  class=""form-control""&gt;
    &lt;p&gt;&lt;b&gt;Please choose news sources!&lt;/b&gt;&lt;/p&gt;

    &lt;label for=""guardianSource"" &gt;The Guardian&lt;/label&gt;
    &lt;input type=""checkbox"" name=""source"" id=""guardianSource""&gt;
    &lt;br&gt;
    &lt;label for=""bbcSource"" &gt;BBC News&lt;/label&gt;
    &lt;input type=""checkbox"" name=""source"" id=""bbcSource""&gt;
    &lt;br&gt;
    &lt;label for=""independentSource"" &gt;The Independent&lt;/label&gt;
    &lt;input type=""checkbox"" name=""source"" id=""independentSource""&gt;
   &lt;/div&gt;
   &lt;br&gt;
   &lt;div  class=""form-control""&gt;
    &lt;p&gt;&lt;b&gt;Please choose news category!&lt;/b&gt;&lt;/p&gt;

    &lt;label for=""categoryCoronaVirus"" &gt;Corona Virus&lt;/label&gt;
    &lt;input type=""checkbox"" name=""category"" id=""categoryCoronaVirus""&gt;
    &lt;br&gt;
    &lt;label for=""categoryPolitics"" &gt;Politics&lt;/label&gt;
    &lt;input type=""checkbox"" name=""category"" id=""categoryPolitics""&gt;
    &lt;br&gt;
    &lt;label for=""categorySport"" &gt;Sport&lt;/label&gt;
    &lt;input type=""checkbox"" name=""category"" id=""categorySport""&gt;
   &lt;/div&gt;

    {% for field in registration_form %}
        &lt;p&gt;
            {% for error in field.errors %}
                &lt;p class=""alert alert-danger card-header text-center flashit""&gt; {{ error }}&lt;/p&gt;
            {% endfor %}
        &lt;/p&gt;
    {% endfor %}
    {% if registration_form.non_field_errors %}
        &lt;div style=""color:red;""&gt;
                &lt;p&gt;{{registration_form.non_field_errors}}&lt;/p&gt;
        &lt;/div&gt;
    {% endif %}
  &lt;h6 class=""text-muted""&gt;
     NOTE: You &lt;b&gt;MUST&lt;/b&gt; select at least 1 choice for each!!!
  &lt;/h6&gt;
    &lt;div  id=""error_message""&gt; &lt;/div&gt;

  &lt;button class=""btn btn-lg btn-primary btn-block"" type=""submit"" onclick=""valthisform()""&gt;Register&lt;/button&gt;

&lt;/form&gt;
</code></pre>

<p>There is a JavaScript function that checks if at least 1 checkbox for category and 1 for source is selected before submitting the form:</p>

<pre><code>function valthisform(){

                var guardianSource = document.getElementById(""guardianSource"").checked;
                var bbcSource = document.getElementById(""bbcSource"").checked;
                var independentSource = document.getElementById(""independentSource"").checked;
                var checkedSource = false;

                var categoryCoronaVirus = document.getElementById(""categoryCoronaVirus"").checked;
                var categoryPolitics = document.getElementById(""categoryPolitics"").checked;
                var categorySport = document.getElementById(""categorySport"").checked;
                var checkedCategory = false;



                if(guardianSource ===true || bbcSource===true || independentSource===true){
                    checkedSource = true;
                }
                if(categoryCoronaVirus===true || categoryPolitics===true || categorySport===true){
                    checkedCategory = true;
                }

                if(checkedSource ===false &amp;&amp; checkedCategory===false){
                    document.getElementById('error_message').innerHTML = '&lt;div class=""alert alert-danger card-header text-center flashit""&gt;&lt;strong&gt;Warning!&lt;/strong&gt; No source and category selected!&lt;/div&gt;';
                    event.preventDefault();
                }
                else if(checkedSource ===false ){
                    document.getElementById('error_message').innerHTML = '&lt;div class=""alert alert-danger card-header text-center flashit""&gt;&lt;strong&gt;Warning!&lt;/strong&gt; No source selected!&lt;/div&gt;';
                    event.preventDefault();
                }
                else if(checkedCategory===false){
                    document.getElementById('error_message').innerHTML = '&lt;div class=""alert alert-danger card-header text-center flashit""&gt;&lt;strong&gt;Warning!&lt;/strong&gt; No  category selected!&lt;/div&gt;';
                    event.preventDefault();
                }

        }
</code></pre>

<p>The problem is: when I don't check any checkbox when registering the JavaScript function works as it is supposed to - it prevents saving the data into the database and prints whatever it supposed to. After printing the warning message, I check few boxes and submit the form. Form submits and redirects to home page, however, once I look into the database the checked boolean values are not saved - they are all False. 
My django view for register is: </p>

<pre class=""lang-py prettyprint-override""><code>def registration(request):
    context = {}

    if request.user.is_authenticated: # If user is logged in, redirect to home screen, they cannot register again!
        return redirect('home')
    if request.POST:
        form = RegistrationForm(request.POST)
        if form.is_valid():
            form.save()
            username = form.cleaned_data.get('username')
            raw_password = form.cleaned_data.get('password1')
            account = authenticate(username=username, password=raw_password)
            login(request, account)
            return redirect('home')
        else:
            context['registration_form'] = form
    else: # GET request
        form = RegistrationForm()
        context['registration_form'] = form
    return render(request, 'accounts/register.html', context)
</code></pre>

<p>EDIT: 
I finally found the bug after going through the commits on git and comparing files to earliest commits.
Basically the code from the register template: </p>

<pre class=""lang-py prettyprint-override""><code>&lt;label for=""guardianSource"" &gt;The Guardian&lt;/label&gt;
    &lt;input type=""checkbox"" name=""source"" id=""guardianSource""&gt;
    &lt;br&gt;
    &lt;label for=""bbcSource"" &gt;BBC News&lt;/label&gt;
    &lt;input type=""checkbox"" name=""source"" id=""bbcSource""&gt;
    &lt;br&gt;
    &lt;label for=""independentSource"" &gt;The Independent&lt;/label&gt;
    &lt;input type=""checkbox"" name=""source"" id=""independentSource""&gt;
   &lt;/div&gt;
   &lt;br&gt;
   &lt;div  class=""form-control""&gt;
    &lt;p&gt;&lt;b&gt;Please choose news category!&lt;/b&gt;&lt;/p&gt;

    &lt;label for=""categoryCoronaVirus"" &gt;Corona Virus&lt;/label&gt;
    &lt;input type=""checkbox"" name=""category"" id=""categoryCoronaVirus""&gt;
    &lt;br&gt;
    &lt;label for=""categoryPolitics"" &gt;Politics&lt;/label&gt;
    &lt;input type=""checkbox"" name=""category"" id=""categoryPolitics""&gt;
    &lt;br&gt;
    &lt;label for=""categorySport"" &gt;Sport&lt;/label&gt;
    &lt;input type=""checkbox"" name=""category"" id=""categorySport""&gt;
   &lt;/div&gt;
</code></pre>

<p>I have renamed for some reason the name attribute of each checkbox. 
After changing the values to: </p>

<pre class=""lang-py prettyprint-override""><code>&lt;label for=""guardianSource"" &gt;The Guardian&lt;/label&gt;
    &lt;input type=""checkbox"" name=""guardianSource"" id=""guardianSource""&gt;
    &lt;br&gt;
    &lt;label for=""bbcSource"" &gt;BBC News&lt;/label&gt;
    &lt;input type=""checkbox"" name=""bbcSource"" id=""bbcSource""&gt;
    &lt;br&gt;
    &lt;label for=""independentSource"" &gt;The Independent&lt;/label&gt;
    &lt;input type=""checkbox"" name=""independentSource"" id=""independentSource""&gt;
   &lt;/div&gt;
   &lt;br&gt;
   &lt;div  class=""form-control""&gt;
    &lt;p&gt;&lt;b&gt;Please choose news category!&lt;/b&gt;&lt;/p&gt;

    &lt;label for=""categoryCoronaVirus"" &gt;Corona Virus&lt;/label&gt;
    &lt;input type=""checkbox"" name=""categoryCoronaVirus"" id=""categoryCoronaVirus""&gt;
    &lt;br&gt;
    &lt;label for=""categoryPolitics"" &gt;Politics&lt;/label&gt;
    &lt;input type=""checkbox"" name=""categoryPolitics"" id=""categoryPolitics""&gt;
    &lt;br&gt;
    &lt;label for=""categorySport"" &gt;Sport&lt;/label&gt;
    &lt;input type=""checkbox"" name=""categorySport"" id=""categorySport""&gt;
   &lt;/div&gt;
</code></pre>

<p>It works. </p>
"
60891200,"<p>I have just knocked up a simple site to support the NHS in the current corona virus pandemic and I'm getting reports from iPhone users that the buttons (Yes and No on the main page) are not clickable. </p>

<p>I have tried forcing <code>cursor: pointer</code> on the element as well as detecting if <code>touchstart</code> or <code>click</code> is available bu to no avail. Unfortunately I dont have an iPhone myself to test it on. </p>

<p>Any help would be great - all code (there really isnt a lot!) can be found at <a href=""https://stayhomeforthenhs.co.uk/"" rel=""nofollow noreferrer"">https://stayhomeforthenhs.co.uk</a> </p>
"
61466484,"<p>Below is a snippet of data I am working with.</p>

<p>Flu<br>
Day Positive Total<br>
1 2 2<br>
2 1 3<br>
3 2 5<br>
4 0 5<br>
5 3 8<br>
6 4 12<br>
7 7 19<br>
8 8 27<br>
9 9 36<br>
10 15 41   </p>

<p>I am trying to write a loop with an if/else statement to determine if the one value in the Positive column is either ""Higher"" or ""Lower"" than the previous value. Doing so would then create a new column named ""Trend"" and would populate the row accordingly with ""Higher"" or Lower""</p>

<pre><code> {
if(Flu$Positive[i+1]&gt;Covid$Positive[i]))
   Trend = ""Higher""
else
   Trend = ""Lower""
   }
</code></pre>
"
61498654,"<p>I am trying to update a map based on the slider value but when I run the code no plot is created. My code is shown below:</p>

<pre><code>
# Creating the Slider

slider = Slider(title = 'Day', 
                start = np.min(covidmap['day_of_year']), end = np.max(covidmap['day_of_year']), 
                step = 1, value = np.min(covidmap['day_of_year']))
# This callback triggers the filter when the slider changes
callback = CustomJS(args = dict(source=geosource), 
                    code = """"""source.change.emit();"""""")
slider.js_on_change('value', callback)
# Creates custom filter that selects the rows of the month based on the value in the slider
custom_filter = CustomJSFilter(args = dict(slider = slider, 
                                           source = geosource), 
                               code = """"""
var data = source.data;
                var f = slider.value;
                var indices = [];
                x = data['day_of_year']
                cumsum = data['cumsum']
for (var i = 0; i &lt; source.get_length(); i++){
 if (x[i] == f){
 indices.push(true);
 } else {
 indices.push(false);
 }
}
return indices;
"""""")
# Uses custom_filter to determine which set of sites are visible
view1 = CDSView(source = geosource, filters = [custom_filter])



#Define a sequential multi-hue color palette.
palette = brewer['YlGnBu'][8]
#Reverse color order so that dark blue is highest obesity.
palette = palette[::-1]
#Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors. Input nan_color.
color_mapper = LogColorMapper(palette = palette, low = 0, high = 100000, nan_color = '#d9d9d9')
#Create color bar. 
color_bar = ColorBar(color_mapper=color_mapper, label_standoff=8,width = 500, height = 20,
                     border_line_color=None,location = (0,0), orientation = 'horizontal')
#Create figure object.
p = figure(plot_height = 600 , 
           plot_width = 950, 
          x_range=(2000000,5500000), y_range=(2500000,5500000))
p.xgrid.grid_line_color = None
p.ygrid.grid_line_color = None

# Adding map tile
p.add_tile(tile_provider)

#Add patch renderer to figure. 
p.patches('xs','ys', source = geosource,fill_color = {'field' :'cumsum', 'transform' : color_mapper},
          line_color = 'black', line_width = 0.25, fill_alpha = 1, view=view1)
#Specify layout
p.add_layout(color_bar, 'below')

# Make a column layout of widgetbox(slider) and plot, and add it to the current document
layout = column(p,slider)
#Display plot inline in Jupyter notebook
output_notebook()
#Display plot
show(layout)

</code></pre>

<p>FYI. Before running the above code I merged the shape dataset with the dataset the contains the information and now the dataset looks as shown below.</p>

<p>cases   deaths   cumsum   num_days  CNTRY_NAME  geometry    day_of_year</p>

<p>0   2.0 0.0 2.0 1   Albania POLYGON ((2314546.339 4928852.306, 2314022.746...   69</p>

<p>1   4.0 0.0 6.0 2   Albania POLYGON ((2314546.339 4928852.306, 2314022.746...   70</p>

<p>2   4.0 0.0 10.0    3   Albania POLYGON ((2314546.339 4928852.306, 2314022.746...   71</p>

<p>3   1.0 1.0 11.0    4   Albania POLYGON ((2314546.339 4928852.306, 2314022.746...   72</p>

<p>After that I used the below code to convert it to GeoJSONDataSource which is what I used to plot the map</p>

<pre><code>#Read data to json.
merged_json = json.loads(covidmap.to_json())
#Convert to String like object.
json_data = json.dumps(merged_json)

#Input GeoJSON source that contains features for plotting.
geosource = GeoJSONDataSource(geojson = json_data)

</code></pre>
"
60874095,"<p>I am making a one page flask web application which purpose is to display a bar chart about total covid19 cases and deaths per country. </p>

<p>The single page consists of a title, a form containing two date fields (start date and end date) and a submit button, and the bar chart. When the user clicks the button, it sends the dates using a POST method to the view function 'index' defined below :</p>

<pre><code>from flask import render_template, redirect
from app import app
from app.forms import DateForm
from .data_processing.dataset_preparation import process_data


@app.route('/', methods=[""GET"", ""POST""])
def index():
    form = DateForm()
    if form.validate_on_submit():
        process_data(form.startDate.data, form.endDate.data)
        return redirect('/')

    return render_template('base.html', title='Home', form=form)

</code></pre>

<p>The process_data function works fine because i can see that the .csv has been processed, however, my bar chart doesn't change at all. I am using d3js to render the bar chart and i have included the code in my html template like so :</p>

<p><code>&lt;script type=""text/javascript"" src=""{{url_for('static', filename='script.js')}}""&gt;&lt;/script&gt;</code></p>

<p>where 'script.js' is the file containing the d3js code which goes like this :</p>

<pre><code>const render =(data) =&gt; {
#some code to render the data as a bar chart
  };


d3.csv(""/static/data/processed/processed_covid19.csv"").then(function(data) {
    render(data);
    });

</code></pre>

<p>When i refresh the page after clicking the submit button, i can see that the bar chart refreshes accordingly. However, only clicking on the submit button does refresh the page without changing the bar chart at all. I am wondering why ? </p>

<p>When i click the submit button, the redirect method in the view function  'index' calls the same view function using a GET method after processing the data, so it renders the single page's html template which should then trigger the script.js and execute this line of code</p>

<p><code>d3.csv(""/static/data/processed/processed_covid19.csv"").then(function(data) {
    render(data);
    });</code></p>

<p>which, to my understanding, should read the data (which has been updated) and therefore render the chart again using this new data ?</p>

<p>I tried using d3.select(""svg"").remove() before re-rendering my chart and also put all my code inside $(document).ready(function(){}) but to no avail.</p>

<p>Thank you for your help (-: !</p>
"
60746151,"<p>I want to scrape the State level information table, related to COVID-19, from the CDC website (<a href=""https://www.cdc.gov/coronavirus/2019-ncov/index.html"" rel=""nofollow noreferrer"">https://www.cdc.gov/coronavirus/2019-ncov/index.html</a>). When using BeautifulSoup I hit an error when I begin to try an extract any information from the table. Any help would be much appreciated!</p>

<pre><code>import pandas as pd
import requests
from bs4 import BeautifulSoup
from lxml import html 

url = 'https://www.cdc.gov/coronavirus/2019-ncov/index.html'
html_content = requests.get(url).text
soup = BeautifulSoup(html_content, ""lxml"")

gdp_table = soup.find(""table"", attrs={""class"": ""ReactTable""})
gdp_table_data = gdp_table.tbody.find_all(""div"")  # contains 2 rows

# Get all the headings of Lists
headings = []
for td in gdp_table_data[0].find_all(""td""):
    # remove any newlines and extra spaces from left and right
    headings.append(td.b.text.replace('\n', ' ').strip())

print(headings)

</code></pre>

<p>If you are having difficulty finding the table I am referencing, it is half way down the web page, under the map of the US. Where the header reads 'States' hit the '+' next to it.</p>
"
61201053,"<p>I am learning React and trying to get my hands around React router. I have an API that displays the data into a table component and I would like to use the item names as URL parameters. For ex, if the country name is USA, then I would like to show the data using localhost:3000/USA. I tried to implement this routing but it's giving an error. here is my code:</p>

<p>Index.js</p>

<pre><code>import React from 'react';
import ReactDOM from 'react-dom';
import './index.css';
import App from './App';
import { BrowserRouter } from ""react-router-dom"";



ReactDOM.render(
  &lt;BrowserRouter&gt;
    &lt;App /&gt;
  &lt;/BrowserRouter&gt;
  ,
  document.getElementById('root')
);
</code></pre>

<p>App.js</p>

<pre><code>import React, { Component } from 'react';
import Button from 'react-bootstrap/Button';
import Form from 'react-bootstrap/Form';
import Navbar from 'react-bootstrap/Navbar';
import Card from './Card';
import Loading from './Loading';
import Paginate from './Paginate';
import Result from './Result';
import {Switch, Route , Router} from 'react-router-dom'



export default class App extends Component {
  constructor() {
    super();
    this.state = {
      data: [],
      totalData: [],
      searchText: '',
      searchResult: [],
      isSearch: false,
      isLoading: true,
      pageSize: 8,
      currentPage: 1,
      showPaginate: true,

    }
    this.onSearchChange = this.onSearchChange.bind(this);
    this.handlePageChange = this.handlePageChange.bind(this);
  }

  //for displaying the data of all the countries
  componentDidMount() {
    const url =
      'https://corona.lmao.ninja/countries?sort=country'
    fetch(url)
      .then(result =&gt; result.json())
      .then(result =&gt; {
        //sorting by highest case
        var sortedData = result.sort((a, b) =&gt; b.cases - a.cases)
        this.setState({
          data: sortedData,
          isLoading: false
        })
      })

    //for displaying data in the card component
    const totalUrl =
      'https://corona.lmao.ninja/all'
    fetch(totalUrl)
      .then(result =&gt; result.json())
      .then(result =&gt; {
        //let store=result;
        //console.log(""store data""+store)
        this.setState({

          totalData: result
        })
        console.log(""2nd fetched data"" + this.state.totalData)
      })
  }

  onSearchChange = (e) =&gt; {
    console.log(""search change "" + this.state.searchText)
    this.setState({
      searchText: e.target.value,
      isSearch: true,
      showPaginate: false,
    })
    console.log(""api data"" + this.state.data[0])
  }

  handlePageChange = (page) =&gt; {
    this.setState({
      currentPage: page
    })

  }
  render() {

    const indexOfLastItem = this.state.currentPage * this.state.pageSize;
    console.log(""indexOfLastItem"" + indexOfLastItem)
    const indexOfFirstItem = indexOfLastItem - this.state.pageSize;
    console.log(""indexOfFirstItem"" + indexOfFirstItem)
    const currentData = this.state.data.slice(indexOfFirstItem, indexOfLastItem);
    console.log(""current data"" + currentData)
    return (

      this.state.isLoading ? &lt;Loading /&gt; :
        &lt;div id=""main""&gt;
          &lt;Router&gt;
      &lt;Switch&gt;
          &lt;Navbar bg=""dark"" variant=""dark""&gt;
            &lt;Navbar.Brand href=""#home""&gt;
              &lt;Button id=""live_text""
              &gt;Live&lt;/Button&gt;
              &lt;img
                alt=""""
                src=""/logo.svg""
                width=""100""
                height=""30""
                className=""d-inline-block align-top""
              /&gt;{' '}
     Covid-19 dashboard

    &lt;/Navbar.Brand&gt;
          &lt;/Navbar&gt;


          &lt;Card totalData={this.state.totalData} /&gt;

          &lt;Form.Group&gt;
            &lt;Form.Control id=""search_bar"" value={this.state.searchText} onChange={this.onSearchChange} type=""text"" placeholder=""Enter country"" /&gt;
          &lt;/Form.Group&gt;





          &lt;Paginate
            dataCount={this.state.data.length}
            pageSize={this.state.pageSize}
            onPageChange={this.handlePageChange}
            currentPage={this.state.currentPage} /&gt;


          &lt;Route path=""/:id""&gt;
          &lt;Result data={this.state.isSearch?this.state.data:currentData}
            searchCheck={this.state.isSearch}
            searchValue={this.state.searchText} /&gt;
          &lt;/Route&gt;
        &lt;/Switch&gt;
      &lt;/Router&gt;

        &lt;/div&gt;

    )
  }
}
</code></pre>

<p>Result.js</p>

<pre><code>import React from 'react'
import Table from 'react-bootstrap/Table';
import {Switch, Route , Router, Link} from 'react-router-dom'

const Result = (props) =&gt; {
  console.log('props value is:' + props.data)
  let { searchCheck, searchValue } = props;

  let update = props.data.map((item) =&gt; {

    const { countryInfo, country, cases, deaths, recovered, active, casesPerOneMillion } = item;
    let findMortality=Math.ceil((deaths/cases)*100);
    return (
      &lt;Router&gt;
      (searchCheck) ? country.toUpperCase().includes(searchValue.toUpperCase()) ?
        &lt;tbody&gt;
          &lt;tr key={countryInfo._id}&gt;
            &lt;td&gt;&lt;img style={{ height: '25px', width: '50px' }} src={countryInfo.flag} /&gt;&lt;/td&gt;

            &lt;Link to={`${props.match.params.url}/${country}`}&gt;{country}&lt;/Link&gt;
            &lt;td&gt;{cases}&lt;/td&gt;
            &lt;td&gt;{active}&lt;/td&gt;
            &lt;td&gt;{recovered}&lt;/td&gt;
            &lt;th&gt;{findMortality}%&lt;/th&gt;
            &lt;td&gt;{deaths}&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt; :
        '' :
        &lt;tbody&gt;
          &lt;tr key={countryInfo._id}&gt;
            &lt;td&gt;&lt;img style={{ height: '25px', width: '50px' }} src={countryInfo.flag} /&gt;&lt;/td&gt;
            &lt;Link to={`${props.match.params.url}/${country}`}&gt;{country}&lt;/Link&gt;
            &lt;td&gt;{cases}&lt;/td&gt;
            &lt;td&gt;{active}&lt;/td&gt;
            &lt;td&gt;{recovered}&lt;/td&gt;
            &lt;th&gt;{findMortality}%&lt;/th&gt;
            &lt;td&gt;{deaths}&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/tbody&gt;
        &lt;Switch&gt;

        &lt;Route path={`${props.match.params.url.path}/:country`}&gt;
          &lt;Country /&gt;
        &lt;/Route&gt;
      &lt;/Switch&gt;
     &lt;/Router&gt;
    )
  })
  return (
    &lt;div&gt;
      &lt;Table striped bordered hover variant=""dark""&gt;
        &lt;thead&gt;
          &lt;tr&gt;

            &lt;th&gt;Flag&lt;/th&gt;
            &lt;th&gt;Country&lt;/th&gt;
            &lt;th&gt;Cases&lt;/th&gt;
            &lt;th&gt;Active&lt;/th&gt;
            &lt;th&gt;Recovered&lt;/th&gt;
            &lt;th&gt;Mortality&lt;/th&gt;
            &lt;th&gt;Deaths&lt;/th&gt;


          &lt;/tr&gt;
        &lt;/thead&gt;
        {update}
      &lt;/Table&gt;
    &lt;/div&gt;
  )
}

function Country(props) {
  // The &lt;Route&gt; that rendered this component has a
  // path of `/topics/:topicId`. The `:topicId` portion
  // of the URL indicates a placeholder that we can
  // get from `useParams()`.
  //let { topicId } = useParams();

  return (
    &lt;div&gt;
      &lt;h3&gt;{props.match.params.country}&lt;/h3&gt;
    &lt;/div&gt;
  );
}

export default Result;
</code></pre>
"
61031157,"<p>So, I'm trying to pass some data to a chart (using chartjs and django) and I can print my data in my webpage, but can't pass it as arguments to the chart. Also, if I put data hardcoded in the chart it works, but with my own data from an array I can't see anything...</p>

<p>I've tried {{data | safe}} and {{labels | safe}} but I get an error, so I'm not getting what I'm doing wrong. Can anyone help me?</p>

<p>To explain better:</p>

<p><strong>views.py</strong></p>

<pre><code>import csv

def home(request):
    csvFilePath = ""../data/raw_datasets/covid_confirmed.csv""
    data = []
    labels = []
    with open(csvFilePath, ""r"") as csvfile:
        csv_reader = csv.reader(csvfile, delimiter=',')
        next(csv_reader)
        for row in csv_reader:
            data.append(row[1])
            labels.append(row[73])

    return render(request, 'home.html',
                  {
                      'data': data,
                      'labels': labels
                  }) 
</code></pre>

<p><strong>home.html</strong></p>

<pre><code>&lt;!DOCTYPE html&gt;

&lt;html lang=""en""&gt;
    &lt;head&gt;
        &lt;meta charset=""UTF-8""&gt;
        &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
        &lt;meta http-equiv=""X-UA-Compatible"" content=""ie=edge""&gt;
        &lt;script src=""https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js""&gt;&lt;/script&gt;
        &lt;title&gt;Crypto Covid&lt;/title&gt;
    &lt;/head&gt;

    &lt;body&gt;
        &lt;h4&gt;{{data | safe}}&lt;/h4&gt;
        &lt;p&gt;--------------&lt;/p&gt;
        &lt;h4&gt;{{labels|safe}}&lt;/h4&gt;
        &lt;div class=""container""&gt;
            &lt;canvas id=""chart""&gt;

            &lt;/canvas&gt;
        &lt;/div&gt;

    &lt;/body&gt;

    &lt;script src=""https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js""&gt;&lt;/script&gt;
    &lt;script&gt; src=""https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.3/Chart.js""&lt;/script&gt;
  &lt;script&gt;

    var config = {
      type: 'pie',
      data: {
        datasets: [{
          data: {data} ,
          backgroundColor: [
            '#696969', '#808080', '#A9A9A9', '#C0C0C0', '#D3D3D3'
          ],
          label: 'Population'
        }],
        labels: {labels}
      },
      options: {
        responsive: true
      }
    };

    window.onload = function() {
      var ctx = document.getElementById('chart').getContext('2d');
      window.myPie = new Chart(ctx, config);
    };
&lt;/script&gt;
&lt;/html&gt;
</code></pre>

<p>The result in my page:</p>

<p><a href=""https://i.stack.imgur.com/EPsgp.png"" rel=""nofollow noreferrer"">my result page</a></p>
"
61377486,"<p>I'm currently working with the New York Times Coronavirus dataset by US county. </p>

<p>It is formatted by date, in a way that only counties with >1 cases were entered on any given date. So for date (1/21) there's only one row for the first county with one case. </p>

<p>eg:</p>

<pre><code>     date         county       state    fips cases deaths
1   2020-01-21  Snohomish   Washington  53061   1   0     #Snomish data starts 1/21
2   2020-01-22  Snohomish   Washington  53061   1   0
3   2020-01-23  Snohomish   Washington  53061   1   0
4   2020-01-24  Cook        Illinois    17031   1   0     #Cook data starts 1/24
8   2020-01-25  Snohomish   Washington  53061   1   0
7   2020-01-25  Cook        Illinois    17031   1   0
6   2020-01-25  Orange      California  6059    1   0     #Orange data starts 1/25
</code></pre>

<p>......</p>

<p>How do I fill the missing dates for each county?</p>

<p>For example here, I'd like to enter data for Cook and Orange counties for the previous days, with 0 0 for cases and deaths but preserving state, fips, and the other info. I'd do it manually, but by now he have thousands of counties.</p>
"
60941262,"<p>I am a 14-year-old new to coding, so please be patient.  I am learning as quick as I can.
*</p>

<p>The website is a wix website.</p>

<p>I need a Search that takes a text input element and then filters multiple columns of a Wix dataset. </p>

<hr>

<p>[EDIT:</p>

<p>I already have a search that I set up, but the search results are not very accurate because when a user types in a multiple word phrase (example: ""clinical study"" the search looks for all of the words in the same order and in the same column. </p>

<p>I would like it to search each row of data for both the words “clinical” AND “study”.  </p>

<p>For a positive result, the words “clinical” AND “study” must appear in the same row -- they could be in different columns but would have to be on the same row.</p>

<p>**</p>

<p>The code looks like this.</p>

<pre class=""lang-js prettyprint-override""><code>
      import wixData from 'wix-data';


    export function SearchBox_keyPress(event, $w) {

        $w(""#dataset1"").setFilter(wixData.filter()
        )


    const filterValue = $w(""#SearchBox"").value
    const byTitle = wixData.filter().contains(""title"", filterValue)
    const byTag1 = wixData.filter().contains(""tag1"", filterValue)
    const byTag2 = wixData.filter().contains(""tag2"", filterValue)
    $w(""#dataset1"").setFilter(byTitle.or(byTag1.or(byTag2)))

    }
</code></pre>

<p>**</p>

<p>I am a volunteer helping with the data management of a COVID-19 research library.   It is put together by doctors who don’t know anything about coding so I am helping with that.  You can see what I’ve done so far here: <a href=""https://www.pandemicity.org/epidemiological-research"" rel=""nofollow noreferrer"">https://www.pandemicity.org/epidemiological-research</a></p>

<p>I have had some help from forums but if anyone has better ideas of how I can get questions answered or pointed in the right direction, I would appreciate it.<br>
Are there better forums or pages? Or a reference book?  I just need a bit of coaching as I work these things out.  </p>

<p>Thank you very much. </p>
"
60749022,"<p>I can't grab <a href=""https://www.ontario.ca/page/2019-novel-coronavirus"" rel=""nofollow noreferrer"">Ontario Coronavirus's</a> HTML from a page that's served using JavaScript.  I'm using Nokogiri in Ruby.</p>

<p>The site Ruby retrieves is more of a warning/explanation page that says my browser needs JavaScript.</p>

<pre><code>&lt;h1&gt;JavaScript is required to view this site&lt;/h1&gt; &lt;p&gt;Ontario.ca needs JavaScript to function properly and provide you with a fast,
stable experience. Please enable JavaScript or check your browser's settings.&lt;/p&gt;...Outdated browsers lack safety features that keep your information secure
</code></pre>

<p>I tried parsing the page using JSON with the same result.  The page comes back as a <code>stringIO</code> object, and that <code>.string</code> also has the same result.  </p>

<p>How can I grab this page and any others that get served this way?  I'm thinking this is a recurring issue with JavaScript served sites.  </p>
"
61312169,"<p>I am working on a project dealing with Covid-19 Data. I have data that is updated daily from <em><a href=""https://ourworldindata.org/coronavirus"" rel=""nofollow noreferrer"">Our World in Data</a></em>. The csv file is here: <a href=""https://raw.githubusercontent.com/owid/covid-19-data/9ee33ac73942b2e37eb04014bf2a7a17a83998cf/public/data/owid-covid-data.csv"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/owid/covid-19-data/9ee33ac73942b2e37eb04014bf2a7a17a83998cf/public/data/owid-covid-data.csv</a></p>

<p>The data has several columns country, date, cases, etc.</p>

<p>What I am interested in is saving only the most recent row for each country and removing everything else. What would be the best way to go about this? </p>

<p>Currently, my code looks like this. I have recently made the transition to R from another program, so guidance is helpful even if this is a dumb question! </p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>world.data &lt; -read.csv(""https://raw.githubusercontent.com/owid/covid-19-data/9ee33ac73942b2e37eb04014bf2a7a17a83998cf/public/data/owid-covid-data.csv"")
world.data$iso_code &lt; -NULL# Remove Country ISO Code
world.data$date &lt; -as.Date(world.data$date, ""%Y-%m-%d"")

library(ggplot2)</code></pre>
</div>
</div>
</p>
"
60634651,"<p>Hej people</p>

<p>I try to create some fullstack app (base on one tutorial) and I have some problem with understand how backed part work. Teoreticlly, then I did this tutorial first time, everything was working. But now, then I try to something new base on it, I see how many things I don't understand. Basically, why it won't work.</p>

<p>I generate express app. My app.js looks that:</p>

<pre><code>var express = require('express');
var path = require('path');
var cookieParser = require('cookie-parser');
var logger = require('morgan');
var mongoose = require('mongoose');
var cors = require('cors');

mongoose.connect('mongodb://localhost/covid', {
  useNewUrlParser: true,
  useUnifiedTopology: true,
  useCreateIndex: true
}).then(() =&gt;  console.log('connection successful'))
  .catch((err) =&gt; console.error(err));

var indexRouter = require('./routes/index');
var usersRouter = require('./routes/users');
var casesRouter = require('./routes/cases');

var app = express();

app.use(cors());
app.use(logger('dev'));
app.use(express.json());
app.use(express.urlencoded({ extended: false }));
app.use(cookieParser());
app.use(express.static(path.join(__dirname, 'public')));

app.use('/', indexRouter);
app.use('/users', usersRouter);
app.use('/api', casesRouter);

module.exports = app;
</code></pre>

<p>routers/cases.js:</p>

<pre><code>var express = require('express');
var router = express.Router();
var app = express();
var server = require('http').createServer(app);
var io = require('socket.io')(server);
var Cases = require('../models/Cases.js');

server.listen(4000)

// socket io
io.on('connection', function (socket) {
    socket.on('newdata', function (data) {
        io.emit('new-data', { data: data });
    });
    socket.on('updatedata', function (data) {
      io.emit('update-data', { data: data });
    });
});

// list data
router.get('/', function(req, res) {
    Cases.find(function (err, cases) {
        if (err) return next(err);
        res.json(cases);
    });
})

module.exports = router;
</code></pre>

<p>and schema:</p>

<pre><code>var mongoose = require('mongoose');

var CasesSchema = new mongoose.Schema({
  id: String,
  name: String,
  location: String,
  state: String,
});

module.exports = mongoose.model('Cases', CasesSchema);
</code></pre>

<p>ok, it's all.</p>

<p>So now I run it from my console by nodemon. In console everything looks ok. No error, and message that everything is ok. But app is not working:</p>

<p>1) I expect that this part:</p>

<pre><code>mongoose.connect('mongodb://localhost/covid', {
  useNewUrlParser: true,
  useUnifiedTopology: true,
  useCreateIndex: true
}).then(() =&gt;  console.log('connection successful'))
  .catch((err) =&gt; console.error(err));
</code></pre>

<p>should created me now new schema ""covid"" with object Cases with keys id, name, location, state. It didn't happen. I installed Compass to easiest examination my mongodb and I can see, that I don't have something like covid. ok, I created it manually, But, as I understand, it should be done automaticlly after I run nodemon.</p>

<p>2) I expect that I can examination my backend via postman. <a href=""https://localhost:3000/api/"" rel=""nofollow noreferrer"">https://localhost:3000/api/</a> (3000 - nodemon default port), but I </p>

<blockquote>
  <p>Could not get any response There was an error connecting to
  <a href=""https://localhost:3000/api/"" rel=""nofollow noreferrer"">https://localhost:3000/api/</a>.</p>
</blockquote>

<p>and it's everything. I can't see this error neither in console nor postman.</p>

<p>Maybe I don't understand something with ports in express app, or I don't understand something with mongoDB. But google didn't help me. It did only bigger mess in my head. So maybe someone of you can explain me how it should work and why? </p>
"
60722286,"<p>Hi I'm new on this technology, and I need to know how it is possible to read a JSON from GitHub URL in serverless and have and endpoint whit this JSON file.</p>

<p>I have this URL: <a href=""https://github.com/pcm-dpc/COVID-19/blob/master/dati-json/dpc-covid19-ita-province.json"" rel=""nofollow noreferrer"">https://github.com/pcm-dpc/COVID-19/blob/master/dati-json/dpc-covid19-ita-province.json</a></p>

<p>I'm really sorry for the little info but I don't know, at the moment, to explain myself better.</p>

<p>i made something like this:</p>

<pre><code>var request = require(""request"");
'use strict';

module.exports.endpoint = (event, context, callback) =&gt; {
    const response = {
        statusCode: 200,
        body: JSON.stringify(load()),
    };
    function load(){
        var url = 'https://myurl.com/file.json';
        var jsonObject;
        request(url, function (error, response, body) {
        if (!error &amp;&amp; response.statusCode == 200) {
            jsonObject = JSON.parse(body);
            return jsonObject;
        }
        });
    }

    callback(null, response);
};
</code></pre>
"
61194923,"<p>I'm trying to access the data array that has the information from the request, but I cannot seem to figure it out.</p>

<p>When I try to display it in my view, I get an undefined cannot read property of length;</p>

<pre><code>const getData = () =&gt; {
    axios.get(""https://www.worldometers.info/coronavirus/"")
        .then(res =&gt; {
            const data = [];
            const $ = cheerio.load(res.data);
            $('.maincounter-number').each((index, element) =&gt; {
                const numberData = $(element).text();
                data[0] = {numberData: numberData};
            });
        }).catch(err =&gt; {
        console.log(""Error fetching and parsing data: "", err);
    });

}


app.get(""/"", (req, res) =&gt; {
    const data = getData();;
    res.render('index', {title: 'Home', data: data});

});
</code></pre>

<p>Pug View</p>

<pre><code>p #{data.dataNumbers}
</code></pre>

<p>I've also tried this function as well but I get the same issue</p>

<pre><code>async function scrapeWorldOMeter(){
   try{
       const worldOMeterResponse = await axios.get(""https://www.worldometers.info/coronavirus/"");
       const data = [];
       const $ = cheerio.load(worldOMeterResponse.data);
       $('.maincounter-number').each((index, element) =&gt; {
       const numberData = $(element).text();
       data[0] = {numberData: numberData};
       return data[0];
   });

   }
   catch(err){
       throw new Error(`Can't scrape WorldOMeter ${err}`)
   }
}


app.get(""/"", async(req, res) =&gt; {
const data = await scrapeWorldOMeter()
res.render('index', {title: 'Home', data});
});
</code></pre>
"
61702945,"<p>would anyone be able to help me with a wall I have hit in a React practice project I am working on. This is a live tracker for Covid-19 that displays a series of cards and one of two charts based on the selection from the country picker in the middle. On a choice of Global, it should display a line chart and the card values will correspond to the global values. On a choice of an actual specific country, it should display a bar chart for each country and the values in the cards should update to reflect just that country's individual numbers. I seem to have hit a wall with passing the specific country data to the cards and the charts.</p>

<p>I also have a secondary issue where the API returns specific country data when a country is picked in the country picker component, but global values are returned when I try to console log those values. The name of the country, however, is correct. </p>

<p>Would anyone be able to help me correct these issues? I am providing relevant code below:</p>

<p>index.js</p>

<pre><code>import axios from 'axios';

const url = 'https://corona.lmao.ninja/v2';
const lastDays = '?lastdays=90';

export const fetchData = async () =&gt; {


    try {
        const { data: { updated, cases, deaths, recovered }} = await axios.get(`${url}/all`);



        return {  updated, cases, deaths, recovered };

    } catch (error) {
        console.log(error);

    }
}


export const fetchDailyData = async () =&gt; {



  try {
      const { data } = await axios.get(`${url}/historical/all${lastDays}`);

      const labels = Object.keys(data.cases);
      const cases = labels.map((name) =&gt; data.cases[name]);
      const deaths = labels.map((name) =&gt; data.deaths[name]);
      const recovered = labels.map((name) =&gt; data.recovered[name]);

      return {labels, cases, deaths, recovered};





  } catch (error) {
    return error;

  }
}

export const fetchCountries = async () =&gt; {




  try {

    const {data} = await axios.get(`${url}/countries`);

    const modifiedData = data.map((data) =&gt; data.country);

    return modifiedData;


  } catch (error) {
    console.log(error);


  }

}


export const fetchSpecificCountries = async (country) =&gt; {

  try {
    const { data } = await axios.get(`${url}/countries/${country}`);
    console.log(data);



  } catch (error) {

  }
}
</code></pre>

<p>App.js</p>

<pre><code>import React from 'react';

import { Cards, Chart, CountryPicker} from './components';
import styles from './App.module.css';
import {fetchData} from './api';

class App extends React.Component {

    state ={
        data: {},
        country: '',
    }

    async componentDidMount() {
        const fetchedData = await fetchData();

        this.setState({data: fetchedData});

    }

    handleCountryChange = async (country) =&gt; {
        const fetchedData = await fetchData(country);

        this.setState({data: fetchedData, country: country});

        console.log(fetchedData);

        console.log(country);

        //fetch the data
        //set the state
    }



    render() {
        const { data } = this.state;

        return(
                &lt;div className={styles.container}&gt;
                    &lt;Cards data = {data} /&gt;
                    &lt;CountryPicker handleCountryChange={this.handleCountryChange} /&gt;
                    &lt;Chart data={data}  /&gt;
                &lt;/div&gt;
        );
    }
}

export default App;
</code></pre>

<p>Cards.jsx</p>

<pre><code>import React from 'react';
import {Card, CardContent, Typography, Grid} from '@material-ui/core';
import CountUp from 'react-countup';
import Moment from 'react-moment';
import styles from './Cards.module.css';
import cx from 'classnames';

const Cards = ({ data: { updated, cases, deaths, recovered }} ) =&gt; {    


if (!cases){
    return 'Loading...';
} 
    return(
        &lt;div className = {styles.container}&gt;
            &lt;Grid container spacing={3} justify=""center""&gt;


                &lt;Grid item component={Card} xs={12} md={3} className={cx(styles.card, styles.infected)}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography  color=""textSecondary"" gutterBottom&gt;Total Confirmed&lt;/Typography&gt;
                        &lt;Typography  variant=""h5""&gt;
                            &lt;CountUp start={0} end={cases} duration={2.5} separator="","" /&gt;
                        &lt;/Typography&gt;
                        &lt;Typography  color=""textSecondary""&gt;
                            &lt;Moment fromNow&gt;{updated}&lt;/Moment&gt;
                        &lt;/Typography&gt;
                        &lt;Typography variant=""body2"" component=""p""&gt; Number of active cases of COVID-19. &lt;/Typography&gt;
                    &lt;/CardContent&gt;
                &lt;/Grid&gt;



                &lt;Grid item component={Card} xs={12} md={3} className={cx(styles.card, styles.deaths)}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Total Deaths&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;
                            &lt;CountUp start={0} end={deaths} duration={2.5} separator="",""/&gt;
                        &lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;
                            &lt;Moment fromNow&gt;{updated}&lt;/Moment&gt;
                        &lt;/Typography&gt;
                        &lt;Typography variant=""body2"" component=""p""&gt; Number of deaths cases of COVID-19. &lt;/Typography&gt;

                    &lt;/CardContent&gt;
                &lt;/Grid&gt;



                &lt;Grid item component={Card} xs={12} md={3} className={cx(styles.card, styles.recovered)}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Total Recovered&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;
                        &lt;CountUp start={0} end={recovered} duration={2.5} separator="","" /&gt;
                        &lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;
                            &lt;Moment fromNow&gt;{updated}&lt;/Moment&gt;
                        &lt;/Typography&gt;
                        &lt;Typography variant=""body2"" component=""p""&gt; Number of recovered cases of COVID-19. &lt;/Typography&gt;

                    &lt;/CardContent&gt;
                &lt;/Grid&gt;
            &lt;/Grid&gt;
        &lt;/div&gt;
    )

}

export default Cards;
</code></pre>

<p>Chart.jsx</p>

<pre><code>import React, { useState, useEffect } from 'react';
import { Line, Bar } from 'react-chartjs-2';
import { fetchDailyData } from '../../api';

import styles from './Chart.module.css';



const Chart = () =&gt; {
    const [dailyData, setDailyData] = useState([]);

    useEffect(() =&gt; {
        const fetchAPI = async () =&gt; {
            setDailyData(await fetchDailyData());
        }

        fetchAPI();
    }, []);





    const lineChart = (

        &lt;Line data = {
            {
                labels: dailyData.labels,
                datasets: [{
                        data:dailyData.cases,
                        label: 'Infected',
                        borderColor: '#3333ff',
                        fill: true,

                    }, {
                        data: dailyData.deaths,
                        label: 'Deaths',
                        borderColor: 'red',
                        backgroundColor: 'rgba(255, 0, 0, 0.5)',
                        fill: true,
                    },
                    {
                        data: dailyData.recovered,
                        label: 'Recovered',
                        borderColor: 'green',
                        backgroundColor: 'rgba(0, 255, 0, 0.5)',
                        fill: true,
                    }],
            }
        }



        /&gt;
    );

    return ( 
        &lt;div className = { styles.container }&gt; 
            {lineChart}
        &lt;/div&gt;
    );
};

export default Chart;
</code></pre>
"
61416574,"<p>I am trying to get the json to display in cards or list after search. The search part seems to be working since I can see the call to the API with the text written in the search box in the console. but nothing is displaying and I get this error TypeError: Cannot read property 'data' of undefined. I don't think I am getting the json path correct.</p>

<p>app.vue</p>

<pre><code>  &lt;template&gt;
  &lt;div id=""app""&gt;
    &lt;Header/&gt;
    &lt;SearchForm v-on:search=""search""/&gt;
    &lt;SearchResults
      v-if=""results.length &gt; 0""
      v-bind:results=""results""
      v-bind:reformattedSearchString=""reformattedSearchString""
    /&gt;
    &lt;Pagination
      v-if=""results.length &gt; 0""
      v-bind:prevPageToken=""api.prevPageToken""
      v-bind:nextPageToken=""api.nextPageToken""
      v-on:prev-page=""prevPage""
      v-on:next-page=""nextPage""
    /&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import Header from './components/layout/Header';
import SearchForm from './components/SearchForm';
import SearchResults from './components/SearchResults';
import Pagination from './components/Pagination';
import axios from 'axios';

export default {
  name: 'app',
  components: {
    Header,
    SearchForm,
    SearchResults,
    Pagination
  },

   data() {
    return {
      results: [],
      reformattedSearchString: '',
      api: {
        baseUrl: 'https://geodeepdive.org/api/v1/articles?',
        max: 10,
        q: '',
        prevPageToken: '',
        nextPageToken: ''
      }
    };
  },


   methods: {
    search(searchParams) {
      this.reformattedSearchString = searchParams.join(' ');
      this.api.q = searchParams.join('+');
      const { baseUrl, q, max} = this.api;
      const apiUrl = `${baseUrl}&amp;term=${q}&amp;title=${q}&amp;max=${max}`;
      this.getData(apiUrl);

    },

    prevPage() {
      const { baseUrl, q, max, prevPageToken } = this.api;
      const apiUrl = `${baseUrl}&amp;term=${q}&amp;title=${q}&amp;max=${max}&amp;pageToken=${prevPageToken}`;
      this.getData(apiUrl);
    },

    nextPage() {
      const { baseUrl, q, max,nextPageToken } = this.api;
      const apiUrl = `${baseUrl}&amp;term=${q}&amp;title=${q}&amp;max=${max}&amp;pageToken=${nextPageToken}`;
      this.getData(apiUrl);
    },

    getData(apiUrl) {
      axios
        .get(apiUrl)

        .then(res =&gt; {
          this.results = res.success.data;
          this.api.prevPageToken = res.success.data.prevPageToken;
          this.api.nextPageToken = res.success.data.nextPageToken;
        })
        .catch(error =&gt; console.log(error))
    }

  }
};
&lt;/script&gt;
</code></pre>

<p>searchresults</p>

<pre><code>&lt;template&gt;
  &lt;div class=""container mb-3""&gt;
    &lt;div class=""d-flex mb-3""&gt;
      &lt;div class=""mr-auto""&gt;
        &lt;h3&gt;Search Results for ""{{ reformattedSearchString }}""&lt;/h3&gt;
      &lt;/div&gt;
      &lt;div class=""btn-group ml-auto"" role=""group""&gt;
        &lt;button
          @click=""changeDisplayMode('grid')""
          type=""button""
          class=""btn btn-outline-secondary""
          v-bind:class=""{ active: displayMode === 'grid' }""
        &gt;
          &lt;i class=""fas fa-th""&gt;&lt;/i&gt;
        &lt;/button&gt;
        &lt;button
          @click=""changeDisplayMode('list')""
          type=""button""
          class=""btn btn-outline-secondary""
          v-bind:class=""{ active: displayMode === 'list' }""
        &gt;
          &lt;i class=""fas fa-list""&gt;&lt;/i&gt;
        &lt;/button&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=""card-columns"" v-if=""displayMode === 'grid'""&gt;
      &lt;div class=""card"" v-bind:key=""result.link.url"" v-for=""result in results""&gt;
        &lt;ArticleGridItem v-bind:result=""result""/&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;div v-else&gt;
      &lt;div class=""card mb-2"" v-bind:key=""result.link.url"" v-for=""result in results""&gt;
        &lt;ArticleListItem v-bind:result=""result""/&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import ArticleListItem from './ArticleListItem';
import ArticleGridItem from './ArticleGridItem';

export default {
  name: 'SearchResults',
  components: {
    ArticleListItem,
    ArticleGridItem
  },
  data() {
    return {
      title: 'Search Results',
      displayMode: 'grid'
    };
  },
  methods: {
    changeDisplayMode(displayMode) {
      this.displayMode = displayMode;
    }
  },
  props: ['results', 'reformattedSearchString']
};
&lt;/script&gt;
</code></pre>

<p>json </p>

<pre><code>{
success: {
    v: 1,
    data: [
       {
         type: ""article"",
         _gddid: ""5ea0b2b3998e17af826b7f42"",
         title: ""The current COVID-19 wave will likely be mitigated in the second-line European countries"",
         volume: """",
         journal: ""Cold Spring Harbor Laboratory Press"",
         link: [
            {
               url: ""https://www.medrxiv.org/content/10.1101/2020.04.17.20069179v1"",
               type: ""publisher""
             }
         ],
         publisher: ""bioRxiv"",
         author: [
            {
               name: ""Samuel Soubeyrand""
             }

         ],
        pages: """",
        number: """",
        identifier: [
          {
              type: ""doi"",
              id: ""10.1101/2020.04.17.20069179""
           }
        ],
       year: ""2020""
      }
    ]
 }
</code></pre>

<p>}</p>
"
61214227,"<p>I am building a tracker application in React using an open source API. I am using Axios for HTTP requests. When I pass the objects retrieved from the GET function in index.js, I get an error that reads: </p>

<p><strong>TypeError: Cannot read property 'NewConfirmed' of undefined</strong></p>

<p>Does anyone know why this may be happening based on the code below and why the parameters are coming back undefined? I tried to change my de-structuring of the parameters to reflect the way the API structures it, but it did not work.</p>

<p>index.js</p>

<pre><code>import axios from 'axios';

const url = 'https://api.covid19api.com/summary';

export const fetchData = async () =&gt; {
    try {
        const { data: { Global: { NewConfirmed, TotalConfirmed, NewDeaths, TotalDeaths, NewRecovered, TotalRecovered, } } } = await axios.get(url);


        return { NewConfirmed, TotalConfirmed, NewDeaths, TotalDeaths, NewRecovered, TotalRecovered,  } ;
    } catch (error) {
        console.log(error);

    }
}
</code></pre>

<p>App.js</p>

<pre><code>import React from 'react';

import {Cards, Chart, CountryPicker} from './components';
import styles from './App.module.css';
import {fetchData} from './api';

class App extends React.Component {

    state ={
        data: {},
    }

    async componentDidMount() {
        const fetchedData = await fetchData();

        this.setState({data: fetchedData});

    }

    render() {

        const { data } = this.state;
        return(
            &lt;div className={styles.container}&gt;
                &lt;Cards data = {data} /&gt;
                &lt;CountryPicker /&gt;
                &lt;Chart /&gt;
            &lt;/div&gt;
        );
    }
}

export default App;
</code></pre>

<p>Cards.jsx</p>

<pre><code>import React from 'react';
import {Card, CardContent, Typography, Grid} from '@material-ui/core';
import styles from './Cards.module.css';

const Cards = ({data: { Global: { NewConfirmed, TotalConfirmed, NewDeaths, TotalDeaths, NewRecovered, TotalRecovered } } }) =&gt; {    


    return(
        &lt;div className = {styles.container}&gt;
            &lt;Grid container spacing={3} justify=""center""&gt;
                &lt;Grid item component={Card}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;New Confirmed&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;{NewConfirmed.value}&lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;REAL DATE&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of active cases of COVID-19.&lt;/Typography&gt;
                    &lt;/CardContent&gt;
                &lt;/Grid&gt;
                &lt;Grid item component={Card}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Total Confirmed&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;{TotalConfirmed.value}&lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;REAL DATE&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of active cases of COVID-19.&lt;/Typography&gt;
                    &lt;/CardContent&gt;
                &lt;/Grid&gt;
                &lt;Grid item component={Card}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;New Deaths&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;{NewDeaths.value}&lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;REAL DATE&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of active cases of COVID-19.&lt;/Typography&gt;
                    &lt;/CardContent&gt;
                &lt;/Grid&gt;
                &lt;Grid item component={Card}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Total Deaths&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;REAL DATA&lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;REAL DATE&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of recoveries of COVID-19.&lt;/Typography&gt;
                    &lt;/CardContent&gt;
                &lt;/Grid&gt;
                &lt;Grid item component={Card}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;New Recovered&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;REAL DATA&lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;REAL DATE&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of deaths of COVID-19.&lt;/Typography&gt;
                    &lt;/CardContent&gt;
                &lt;/Grid&gt;
                &lt;Grid item component={Card}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Total Recovered&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;REAL DATA&lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;REAL DATE&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of deaths of COVID-19.&lt;/Typography&gt;
                    &lt;/CardContent&gt;
                &lt;/Grid&gt;
            &lt;/Grid&gt;
        &lt;/div&gt;
    )

}

export default Cards;
</code></pre>
"
61297486,"<p>I am using dialogflow to fetch JSON value based on a variable. I want to provide Country as a variable, and wish to fetch JSON result under it. The Key parameter after the Country is not fetching the expected result.</p>

<p>Here is code:</p>

<pre><code>  axios({
   ""method"":""GET"",
    ""url"":""https://coronavirus-map.p.rapidapi.com/v1/summary/latest"",
    ""headers"":{
    ""content-type"":""application/octet-stream"",
    ""x-rapidapi-host"":""coronavirus-map.p.rapidapi.com"",
    ""x-rapidapi-key"":""b69dXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX70148c1179""
    }
    })
    .then((response)=&gt;{
      console.log(response.data);   //Works OK
      console.log(""--myCountry from Variable--""+ myCountry);   //variable Works Ok
      console.log(""--Total cases Response: Status--"" + response.data.status);   //Status OK
      console.log(""--Total Cases Response: Hardcoding Country variable--"" + response.data.data.regions.india.total_cases);   //Total cases OK
      console.log(""--Total Cases Response: System Input myCountry variable--"" + response.data.data.regions[myCountry].total_cases);   // NOT OK!
})
</code></pre>

<p>Attached is the error screenshot:<em>TypeError: Cannot read property 'total_cases' of undefined at axios.then</em>
<a href=""https://i.stack.imgur.com/Blx5d.png"" rel=""nofollow noreferrer"">Log screenshot</a></p>

<p>Here is JSON response.data:<a href=""https://i.stack.imgur.com/tVAdV.png"" rel=""nofollow noreferrer"">JSON response object</a></p>

<p>How can I fetch the 'total cases' under the Country using a variable?</p>

<p><a href=""https://rapidapi.com/Yatko/api/coronavirus-map?endpoint=apiendpoint_6692b41d-76da-4791-a0a7-d8b9d392bb21"" rel=""nofollow noreferrer"">JSON Data is accessed from endpoint.</a> </p>

<p>Sample data:</p>

<pre><code>{
   ""status"":200,
   ""type"":""stack"",
   ""data"":{
      ""summary"":{
         ""total_cases"":2243360,
         ""active_cases"":1518967,
         ""deaths"":153412,
         ""recovered"":570981,
         ""death_ratio"":0.06838492261607589,
         ""recovery_ratio"":0.25452045146565866
      },
      ""change"":{
         ""total_cases"":-18077,
         ""active_cases"":-14572,
         ""deaths"":-918,
         ""recovered"":-2587,
         ""death_ratio"":0.00014070444860095344,
         ""recovery_ratio"":0.000890569227064375
      },
      ""generated_on"":1587157203,
      ""regions"":{
         ""india"":{
            ""name"":""india"",
            ""total_cases"":698851,
            ""active_cases"":602681,
            ""deaths"":36842,
            ""recovered"":59328,
            ""death_ratio"":0.052717961339398524,
            ""recovery_ratio"":0.08489363254828282
         }
      }
   }
}
</code></pre>
"
61257681,"<p>How to bring this json file (<a href=""https://ix.cnn.io/data/novel-coronavirus-2019-ncov/us/historical.min.json"" rel=""nofollow noreferrer"">https://ix.cnn.io/data/novel-coronavirus-2019-ncov/us/historical.min.json</a>)  in as a dataframe? </p>

<p>I've tried several ways to no avail.</p>
"
60863045,"<p>I have a dataframe with a list of symptoms as the first row and 0's and 1's populating the columns specifying if each case has or does not have the symptom. I would like to make a bar chart showing the incidence of each symptom.</p>

<p>For instance:</p>

<pre><code>COVID


Case    Fever   Cough    SOB   Fatigue  Results
A        1        1        0     1         Positive
B        0        1        1     1         Positive
D        1        0        1     1         Positive
Z        1        1        1     1         Positive
</code></pre>

<p>The bar chart should have 4 bars: Fever (height 3), Cough (height 3), SOB (height 3), Fatigue (height 4)</p>

<p>As an added complication this file has both positive and negative cases and I need to take this data only from the positive cases. I left out any negative cases in my example above for simplicity's sake.</p>

<p>I have tried this but it only works for a single symptom:</p>

<pre><code>symptoms_plot &lt;- ggplot(subset(COVID, Results == ""Positive"" &amp; Cough == 1), aes(Cough)) + geom_bar()
</code></pre>

<p>I also have been able to separate out just the positive cases with this:</p>

<pre><code>split_by_result = split(COVID, COVID$Results)
split_by_result[[""Positive""]]
</code></pre>

<p>I realize it would be easier if the data were formatted differently however this is a living document and cases are being added daily and I can not change how cases are added.</p>
"
60871950,"<p>I know how to plot the figures separately but don't know how to combine the data and plot in one figure. 
my problem is the original data doesn't include days so I have to calculate it and add to the data frame. and I feel my way of doing it is not very smart. </p>

<pre><code>`library(tidyverse)`

`df &lt;- read_csv(""https://covid.ourworldindata.org/data/ecdc/full_data.csv"")`

###days vs log  in US

`filt1_US &lt;- df$location %in% ""United States""`

`filt2_US &lt;-df$total_cases &gt; 100`

`filt3_US &lt;-df[filt1_US &amp; filt2_US,]`


`daysUS &lt;- seq(1:23)`
         # 23 days (since total cases&gt;100)  3/3 - 3/25

`newUS &lt;- cbind(filt3_US,daysUS)`

`ggplot(data=newUS, aes(x=days, y=total_cases))+
 geom_line(stat = ""identity"",linejoin = ""round"",color=""red"")+
 scale_y_log10()+ 
 xlab(""Day of Infection"")+
 ylab(""Total Number of Cases"")+
 ggtitle(""Total COVID19 Cases in ""US"")+
 theme( text = element_text(family=""Arial""),
     axis.title.x = element_text(color=""DarkGreen"",size=20),
     axis.title.y = element_text(color=""DarkGreen"",size=15),
     axis.text.x = element_text(size=10),
     axis.text.y = element_text(size=10),
     legend.title = element_text(size=15,face = ""bold""),
     legend.text = element_text(size=10),         
     plot.title = element_text(color=""Dark blue"",
                               size=20,face = ""bold""))`
</code></pre>

<h3>days vs log  in China</h3>

<pre><code>`filt4_China &lt;- df$location %in% ""China""
 filt5_China &lt;-df$total_cases &gt; 100
 filt6_China &lt;-df[filt4_China &amp; filt5_China,]`

`daysChina &lt;- seq(1:67)`            # 67days  1/19 - 3/25

`newChina &lt;- cbind(filt6_China,daysChina)`

`ggplot(data=newChina, aes(x=daysChina, y=total_cases))+
 geom_line(stat = ""identity"",linejoin = ""round"",color=""red"")+
 scale_y_log10()+ 
 xlab(""Day of Infection"")+
 ylab(""Total Number of Cases"")+
 ggtitle(""Total COVID19 Cases in China"")+
 theme( text = element_text(family=""Arial""),
     axis.title.x = element_text(color=""DarkGreen"",size=20),
     axis.title.y = element_text(color=""DarkGreen"",size=15),
     axis.text.x = element_text(size=10),
     axis.text.y = element_text(size=10),
     legend.title = element_text(size=15,face = ""bold""),
     legend.text = element_text(size=10),
     plot.title = element_text(color=""Dark blue"",
                               size=20,face = ""bold""))`
</code></pre>
"
61087893,"<p>I am using the <code>rtweet</code> package to retrieve tweets that contain specific keywords. I know how to do an ""and""/""or"" match, but how to chain these together into one keyword query with multiple OR/and conditions . For example, a search query I may wish to put into the <code>search_twitter</code> function is: </p>

<p>('cash' or 'currency' or 'banknote' or 'accepting cash' or 'cashless') AND ('covid' or 'virus' or 'coronavirus')</p>

<p>So the tweets can contain any one of the words in the first bracket and also any one of the words in the second bracket.  </p>
"
60933835,"<p>I am new in reactjs. Currently I'm developing an app which shows json COVID-19 api data into visualization using chartjs. I tried this from yesterday but I can't show the visual data.</p>

<p>Here is my code </p>

<pre><code>App Component

import React, { useState, useEffect } from ""react"";
import axios from ""axios"";

import Chart from ""./Chart"";

const App = () =&gt; {
  const [state, setState] = useState({});
  const [loading, setLoading] = useState(true);
  const [chart, setChart] = useState({});

  useEffect(() =&gt; {
    getData(""italy"");
    setChart({
      labels: [""Cases"", ""Deaths"", ""Recovered""],
      datasets: [
        {
          label: ""cases"",
          data: [state.cases]
        },
        {
          label: ""deaths"",
          data: [state.deaths]
        },
        {
          label: ""recovered"",
          data: [state.recovered]
        }
      ]
    });
  }, []);

  const getData = async country =&gt; {
    try {
      const res = await axios.get(
        `https://corona.lmao.ninja/v2/historical/${country}`
      );
      setLoading(false);
      setState(res.data.timeline);
    } catch (error) {
      console.log(error.response);
    }
  };

  return (
    &lt;div&gt;
      {!loading
        ? console.log(
            ""cases"",
            state.cases,
            ""deaths"",
            state.deaths,
            ""recovered"",
            state.recovered
          )
        : null}

      {!loading ? &lt;Chart chart={chart} /&gt; : ""loading failed""}
    &lt;/div&gt;
  );
};

export default App;

And Here is Chart Component

import React from ""react"";

import { Line } from ""react-chartjs-2"";

const Chart = ({chart}) =&gt; {

  return (
    &lt;div&gt;
      &lt;Line
        data={chart}
        height={300}
        width={200}
        options={{
          maintainAspectRatio: false,
          title: {
            display: true,
            text: ""Covid-19"",
            fontSize: 25
          },
          legend: {
            display: true,
            position: ""top""
          }
        }}
      /&gt;
    &lt;/div&gt;
  );
};

export default Chart;


</code></pre>

<p>If I open browser and dev tools it look likes this</p>

<p><a href=""https://i.stack.imgur.com/w1ClK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/w1ClK.png"" alt=""browser and dev tool""></a></p>

<p>I want to visualize the data like this</p>

<p><a href=""https://i.stack.imgur.com/0DDi7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0DDi7.png"" alt=""data visualization""></a></p>

<p><strong>Here is <a href=""https://codesandbox.io/s/beautiful-neumann-53lh8"" rel=""nofollow noreferrer"">codeSandBox.io</a></strong></p>
"
61470302,"<p>I have tried every way to fetch my API data into a select list. However, I have failed. All the information comes successfully. But whenever I try to show them it doesn't work. Is there any problem in my code?</p>

<p>My routes/web.php file</p>

<pre><code>&lt;?php

Route::get('/','StatusController@index');
</code></pre>

<p>My Controller </p>

<pre><code>&lt;?php

namespace App\Http\Controllers;

use Illuminate\Http\Request;

class StatusController extends Controller
{
//

public function index(){


    return view('status-main');
   }
  }
</code></pre>

<p>My VueJS file</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>&lt;template&gt;
    &lt;div class=""container""&gt;

        &lt;h2&gt;Total Recovered: {{Recovered}}&lt;/h2&gt;

        &lt;select name="""" id="""" &gt;
            &lt;option value=""""&gt;Choose&lt;/option&gt;
            &lt;option   v-for=""(list,index) in countryList"" :key=""list.id""   :index=""index""&gt;

                {{list}}
            &lt;/option&gt;

        &lt;/select&gt;

    &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
    import axios from 'axios'
    export default {
        name:'CoronaStatus',
        data: function () {
            return {

                Recovered: ""Loading ..."",
                countryList:[],
                // Country:''

            }
        },
        // mounted(){
        //
        //     this.globalStatus();
        // },

        methods:{
            globalStatus:function () {
                const options = {
                    headers: 	{""x-rapidapi-host"": ""covid-193.p.rapidapi.com"",
                    ""x-rapidapi-key"": ""ad21211fe4mshba485cda44108adp1712e0jsn54ed45914a9a""}
                };
                axios
                    .get(""https://covid-193.p.rapidapi.com/countries"", options)
                    .then(response=&gt;response.json())
                    .then(response =&gt; {
                        // this.Recovered = response.data.Global.TotalRecovered;

                        this.countryList=response.data;

                        console.log(this.countryList);
                        // alert(this.countryList)
                    })
                    .catch(err =&gt; console.log(err));

            }

        },

        mounted(){

            this.globalStatus();
        },



    }
&lt;/script&gt;

&lt;style scoped&gt;

&lt;/style&gt;</code></pre>
</div>
</div>
</p>

<p>I have successfully fetched data every time. However, I have managed to fail to populate the select list.</p>

<p><a href=""https://i.stack.imgur.com/eBDz1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eBDz1.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/tr3wQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tr3wQ.png"" alt=""enter image description here""></a></p>

<p>My VueJS file after updating:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>&lt;template&gt;
    &lt;div class=""container""&gt;


        &lt;select name=""country""&gt;
            &lt;option disabled value=""""&gt;Choose&lt;/option&gt;
            &lt;option v-for=""country in countryList"" :key=""country"" :value=""country""&gt;
                {{ country }}
            &lt;/option&gt;
        &lt;/select&gt;

    &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
    import axios from 'axios'
    export default {
        data: () =&gt; ({
            Recovered: ""Loading ..."",
            countryList: []
        }),
        methods: {
            globalStatus () {
                const options = {
                    headers: 	{
                        ""x-rapidapi-host"": ""covid-193.p.rapidapi.com"",
                        ""x-rapidapi-key"": ""ad21211fe4mshba485cda44108adp1712e0jsn54ed45914a9a""
                    }
                }
                axios.get('https://covid-193.p.rapidapi.com/countries', options).then(res =&gt; {
                    this.countryList = res.data.response
                    console.log(this.countryList);
                })
            }
        },
        mounted () {
            this.globalStatus()
        }

    }
&lt;/script&gt;

&lt;style scoped&gt;

&lt;/style&gt;</code></pre>
</div>
</div>
</p>
"
60824130,"<p>I'm playing around with this API <a href=""https://covid19.mathdro.id/api"" rel=""nofollow noreferrer"">https://covid19.mathdro.id/api</a> what I want to do is get a value based on the arg set in the function. for example. </p>

<pre><code>const fetchCases = arg =&gt; {
  axios.get(""https://covid19.mathdro.id/api"").then(response =&gt; console.log(response.data.arg))
}

fetchCases(""confirmed"")
</code></pre>

<p>unfortunately, this yields undefined. How do you guys go about passing args such as this on fetch calls? what would be the best approach for these types of calls?</p>
"
61163890,"<p>Please I am able to get response from this Heroku Node.js app I deployed:</p>

<pre><code>const data = {
    region: {
      name: 'Africa',
      avgAge: 19.7,
      avgDailyIncomeInUSD: 5,
      avgDailyIncomePopulation: 0.71
    },
    periodType: 'days',
    timeToElapse: 58,
    reportedCases: 674,
    population: 66622705,
    totalHospitalBeds: 1380614
  };
const instance = axios.create({
    baseURL: 'https://covid-19-estimator-tk.herokuapp.com',
    timeout: 1000,
  });

instance.get('/api/v1/on-covid-19/logs')
  .then(function (response) {
    console.log(response.data);
  })
  .catch(function (error) {
    //console.log(error);
  });
</code></pre>

<p>Post returns 404. What could be wrong. Why can't I make a post call? It should return a json response.</p>

<pre><code> instance.post('/api/v1/on-covid-19', data)
  .then(function (response) {
    console.log(response.data);
  })
  .catch(function (error) {
    //console.log(error);
  });
</code></pre>

<p>The <a href=""https://covid-19-estimator-tk.herokuapp.com/"" rel=""nofollow noreferrer"">swagger UI works</a>. 
Use this data to test</p>

<pre><code>{
  ""region"": {
    ""name"": ""Africa"",
    ""avgAge"": 19.7,
    ""avgDailyIncomeInUSD"": 5,
    ""avgDailyIncomePopulation"": 0.71
  },
  ""periodType"": ""ays"",
  ""timeToElapse"":  58,
  ""reportedCasee"": 674,
  ""population"": 66622705,
  ""totalHospitalBeds"": 1380614
}
</code></pre>
"
61195064,"<p>I have searched the net, maybe not the right place,s but have been trying to simply insert a dropdown list with a ""go"" button that when selected will take me to a page for that state. Here is the code I have added to my theme's function page:</p>

<pre><code>function wpb_hook_javascript() {
  if (is_page ('covid-19-resources-for-artists')) { 
    ?&gt;
        &lt;script type=""text/javascript""&gt;
        // your javscript code goes here
          function gotosite() {
  window.location = document.getElementById(""menu"").value; // JQuery:  $(""#menu"").val();
}// your javscript code goes here
        &lt;/script&gt;
    &lt;?php
  }
}
add_action('wp_head', 'wpb_hook_javascript');
</code></pre>

<p>and here is the html on the page</p>

<pre><code>&lt;select id=""menu""&gt;
&lt;option value=""""&gt;Please Choose...&lt;/option&gt;
&lt;option value=""http://www.google.com/""&gt;Google&lt;/option&gt;
&lt;option value=""http://www.youtube.com/""&gt;Youtube&lt;/option&gt;
&lt;option value=""http://www.pinterest.com/""&gt;Pinterest&lt;/option&gt;
&lt;/select&gt;
&lt;button id=""go"" onclick=""gotosite()""&gt;Go&lt;/button&gt;
</code></pre>

<p>the console error is: 
?preview=true:324 Uncaught ReferenceError: gotosite is not defined
    at HTMLButtonElement.onclick (?preview=true:324)</p>

<p>Can anyone help me with what I am doing wrong? Supposedly wordpress loads everything automatically? Thanks!</p>
"
61672897,"<p>I'm building an api that retrieves time series data of covid cases for each country in nodejs/Express with a mongo DB. The data source is courtesy of <a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">John Hopkins</a>.</p>

<p>For those lazy to hit the link, the headers look like this: </p>

<pre><code>Province/State,Country/Region,Lat,Long,1/22/20,1/23/20,1/24/20,1/25/20,1/26/20,1/27/20,1/28/20,1/29/20,1/30/20,1/31/20,2/1/20,2/2/20,2/3/20,2/4/20,2/5/20,2/6/20,2/7/20,2/8/20,2/9/20,2/10/20,2/11/20,2/12/20,2/13/20,2/14/20,2/15/20,2/16/20,2/17/20,2/18/20,2/19/20,2/20/20,2/21/20,2/22/20,2/23/20,2/24/20,2/25/20,2/26/20,2/27/20,2/28/20,2/29/20,3/1/20,3/2/20,3/3/20,3/4/20,3/5/20,3/6/20,3/7/20,3/8/20,3/9/20,3/10/20,3/11/20,3/12/20,3/13/20,3/14/20,3/15/20,3/16/20,3/17/20,3/18/20,3/19/20,3/20/20,3/21/20,3/22/20,3/23/20,3/24/20,3/25/20,3/26/20,3/27/20,3/28/20,3/29/20,3/30/20,3/31/20,4/1/20,4/2/20,4/3/20,4/4/20,4/5/20,4/6/20,4/7/20,4/8/20,4/9/20,4/10/20,4/11/20,4/12/20,4/13/20,4/14/20,4/15/20,4/16/20,4/17/20,4/18/20,4/19/20,4/20/20,4/21/20,4/22/20,4/23/20,4/24/20,4/25/20,4/26/20,4/27/20,4/28/20,4/29/20,4/30/20,5/1/20,5/2/20,5/3/20,5/4/20,5/5/20,5/6/20,5/7/20
</code></pre>

<p>A typical row:</p>

<pre><code>New South Wales,Australia,-33.8688,151.2093,0,0,0,0,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,6,6,13,22,22,26,28,38,48,55,65,65,92,112,134,171,210,267,307,353,436,669,669,818,1029,1219,1405,1617,1791,2032,2032,2182,2298,2389,2493,2580,2637,2686,2734,2773,2822,2857,2857,2863,2870,2886,2897,2926,2936,2957,2963,2969,2971,2976,2982,2994,3002,3004,3016,3016,3025,3030,3035,3033,3035,3042,3044,3047
</code></pre>

<p>I'm trying to model the .csv into a schema that allows for CRUD operations. Having trouble wrapping my head around how each date will dynamically be added on a daily basis.</p>

<p>Currently, I have:</p>

<pre><code>const mongoose = require(""mongoose"");

const confirmedTimeSeriesSchema = new mongoose.Schema({
  Province_State: {
    type: String,
    required: true,
    unique: true,
  },
  Country_Region: {
    type: String,
    required: true,
    unique: true,
  },
  Lat: {
    type: String,
    required: true,
    unique: true,
  },
  Long: {
    type: String,
    required: true,
    unique: true,
  },
  Records: mongoose.Schema.Types.Mixed,
});

const ConfirmedTimeSeries = mongoose.model(
  ""confirmed_time_series"",
  confirmedTimeSeriesSchema
);

module.exports = ConfirmedTimeSeries;
</code></pre>

<p>How best should do I design the mongo schema based on the .csv?</p>

<p>Thanks!</p>
"
61082163,"<p>I am trying to fix my WordPress site, in which reports should be listed under a area of the site, however instead of reports being listed as they have been, the table shows ""No Results Found"".</p>

<p>The following plugins are in use:</p>

<ul>
<li>Advanced Custom Fields Pro</li>
<li>Advanced Custom Fields: Repeater Field</li>
<li>Advanced Custom Fields: User Role Selector</li>
<li>Advanced Taxonomy Terms Order</li>
<li>FirePHP / Firebug PHP Integration</li>
<li>WPFront User Role Editor</li>
<li>WPFront User Role Editor Personal Pro</li>
</ul>

<p>In Firefox dev tools the following error is listed:</p>

<pre><code>Error: [$parse:lexerr] http://errors.angularjs.org/1.3.19/$parse
/lexerr?p0=Unexpected%20nextharacter%20&amp;p1=s%205203-5203%20%5B%26%5D&amp;p2=reports%20%3D%20%5B%0A%0A
%09%09%0A%09%09%09%7B%0A%09%09%09%09id%3A%202129%2C%0A%09%09%09%09tags%3A%20%5B%0A%09%09%09%09%09%09
%09%09%095%2C%0A%09%09%09%09%09%09%09%09%5D%2C%0A%09%09%09%09title
%3A%20'Precious%20Metals%20Weekly%20-%20COVID-19mpacts%20gold%20production
%2C%20but%20gold%20price%20will%20push%20margins%20higher'%2C%0A%09%09%09%09issue%3A%20'348'%2C%0A
%09%09%09%09link%3A%20'http%3A%2F%2F{SITE NAME HERE}%2Freports%2Fprecious-metals-weekly-
covid-19-impacts-gold-production-but-gold-price-will-push-margins-higher%2F'%2C%0A%09%09%09%09mime
%3A%20'pdf'%2C%0A%09%09%09%09date%3A%20'01%2F04%2F2020'%2C%0A%09%09%09%09timestamp%3A%20'1585750652'...
</code></pre>

<p>in debug.log the following is listed:
<code>[07-Apr-2020 14:50:50 UTC] PHP Notice:  Undefined index: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet in /var/www/vhosts/NAME/clientarea/wordpress/wp-content/themes/NAME/inc/utils.php on line 66</code></p>

<p>It has been suggested that the file names could be an issue however I have checked for any problematic characters within the file names and could not find a solution</p>

<p>Thanks in advance!</p>
"
60712829,"<p>I can't scroll in the listView in NestedScrollView (fragment)</p>

<p>Attempted code:</p>

<pre><code>setNestedScrollingEnabled(true);

&lt;android.support.v4.widget.NestedScrollView android:fillViewport=""true"" /&gt; and &lt;View android:nestedScrollingEnabled = ""true"" /&gt;
</code></pre>

<p>
    </p>

<pre><code>    &lt;LinearLayout
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:orientation=""vertical""
        android:paddingBottom=""50px""&gt;

        &lt;WebView
            android:id=""@+id/wb""
            android:layout_width=""match_parent""
            android:layout_height=""244dp""
            android:visibility=""gone"" /&gt;

        &lt;LinearLayout
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:orientation=""horizontal""&gt;

            &lt;TextView
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:fontFamily=""@font/roboto_bold""
                android:text=""Recherche statistique des pays ""
                android:textColor=""#5E5E5E""
                android:textSize=""24dp"" /&gt;

            &lt;View
                android:layout_width=""40dp""
                android:layout_height=""6dp""
                android:layout_gravity=""center""
                android:layout_marginLeft=""8dp""
                android:background=""@drawable/bg_view""&gt;

            &lt;/View&gt;

        &lt;/LinearLayout&gt;

        &lt;TextView
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:fontFamily=""@font/roboto_regular""
            android:text=""ÉVOLUTION DU CORONAVIRUS COVID-19 ""
            android:textColor=""#5E5E5E""
            android:textSize=""18dp"" /&gt;




        &lt;LinearLayout
            android:layout_width=""match_parent""
            android:layout_height=""match_parent""
            android:orientation=""vertical""
            android:padding=""16dp""&gt;

            &lt;SearchView
                android:id=""@+id/cher""
                android:layout_width=""match_parent""
                android:layout_height=""match_parent"" /&gt;


        &lt;/LinearLayout&gt;
        &lt;LinearLayout
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""14dp""
            android:orientation=""horizontal""&gt;

            &lt;TextView
                android:id=""@+id/title""
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:layout_gravity=""center""
                android:fontFamily=""@font/roboto_medium""
                android:text=""Statistiques""
                android:textColor=""#5E5E5E""
                android:textSize=""18dp"" /&gt;

            &lt;View
                android:layout_width=""match_parent""
                android:layout_height=""2dp""
                android:layout_gravity=""center""
                android:layout_marginLeft=""8dp""
                android:background=""#7a8b8b8b""&gt;&lt;/View&gt;

        &lt;/LinearLayout&gt;

        &lt;LinearLayout
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:orientation=""vertical""
            android:visibility=""visible""&gt;

            &lt;ProgressBar
                android:id=""@+id/loadin""

                android:layout_width=""match_parent""
                android:layout_height=""200dp""
                android:layout_weight=""250"" /&gt;

            &lt;ListView
                android:id=""@+id/ListC""
                android:layout_width=""match_parent""
                android:layout_height=""500dp""
                android:layout_gravity=""center""
                android:divider=""#ffffff""&gt;&lt;/ListView&gt;


        &lt;/LinearLayout&gt;


        &lt;LinearLayout
            android:id=""@+id/lst1""
            android:layout_width=""match_parent""
            android:layout_height=""446dp""
            android:layout_marginTop=""14dp""
            android:orientation=""horizontal""/&gt;

        &lt;LinearLayout
            android:id=""@+id/lin1""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""8dp""
            android:orientation=""horizontal""
            android:visibility=""gone""&gt;

            &lt;android.support.v7.widget.CardView
                android:layout_width=""160dp""
                android:layout_height=""120dp""
                android:layout_weight=""1""
                app:cardCornerRadius=""8dp""
                app:cardElevation=""2dp""&gt;

                &lt;RelativeLayout
                    android:layout_width=""match_parent""
                    android:layout_height=""match_parent""
                    android:padding=""8dp""&gt;

                    &lt;TextView
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:fontFamily=""@font/roboto_bold""
                        android:text=""Nombre total de cas""
                        android:textColor=""#5E5E5E""
                        android:textSize=""18dp"" /&gt;

                    &lt;TextView
                        android:id=""@+id/tot1""
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:textColor=""#FFFFFF""
                        android:textSize=""29dp"" /&gt;


                    &lt;ProgressBar
                        android:id=""@+id/l1""

                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:indeterminate=""true"" /&gt;
                &lt;/RelativeLayout&gt;

            &lt;/android.support.v7.widget.CardView&gt;

            &lt;android.support.v7.widget.CardView
                android:layout_width=""160dp""
                android:layout_height=""120dp""
                android:layout_marginLeft=""18dp""
                android:layout_weight=""1""
                app:cardCornerRadius=""8dp""
                app:cardElevation=""2dp""&gt;

                &lt;RelativeLayout
                    android:layout_width=""match_parent""
                    android:layout_height=""match_parent""
                    android:padding=""8dp""&gt;

                    &lt;TextView
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:fontFamily=""@font/roboto_bold""
                        android:text=""Nouveaux  cas""
                        android:textColor=""#5E5E5E""
                        android:textSize=""18dp"" /&gt;

                    &lt;TextView
                        android:id=""@+id/casN1""
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:textColor=""#FFFFFF""
                        android:textSize=""29dp"" /&gt;


                    &lt;ProgressBar
                        android:id=""@+id/l2""

                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:indeterminate=""true"" /&gt;

                &lt;/RelativeLayout&gt;

            &lt;/android.support.v7.widget.CardView&gt;


        &lt;/LinearLayout&gt;

        &lt;LinearLayout
            android:id=""@+id/lin2""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""16dp""
            android:orientation=""horizontal""
            android:visibility=""gone""&gt;

            &lt;android.support.v7.widget.CardView
                android:layout_width=""160dp""
                android:layout_height=""120dp""
                android:layout_weight=""1""
                app:cardCornerRadius=""8dp""
                app:cardElevation=""2dp""&gt;

                &lt;RelativeLayout
                    android:layout_width=""match_parent""
                    android:layout_height=""match_parent""
                    android:padding=""8dp""&gt;

                    &lt;TextView
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:fontFamily=""@font/roboto_bold""
                        android:text=""Total des décès""
                        android:textColor=""#5E5E5E""
                        android:textSize=""18dp"" /&gt;

                    &lt;TextView
                        android:id=""@+id/dead1""
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:textColor=""#FFFFFF""
                        android:textSize=""29dp"" /&gt;


                    &lt;ProgressBar
                        android:id=""@+id/l3""

                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:indeterminate=""true"" /&gt;

                &lt;/RelativeLayout&gt;

            &lt;/android.support.v7.widget.CardView&gt;

            &lt;android.support.v7.widget.CardView
                android:layout_width=""160dp""
                android:layout_height=""120dp""
                android:layout_marginLeft=""18dp""
                android:layout_weight=""1""
                app:cardCornerRadius=""8dp""
                app:cardElevation=""2dp""&gt;

                &lt;RelativeLayout
                    android:layout_width=""match_parent""
                    android:layout_height=""match_parent""
                    android:padding=""8dp""&gt;

                    &lt;TextView
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:fontFamily=""@font/roboto_bold""
                        android:text=""Nouvelles  morts""
                        android:textColor=""#5E5E5E""
                        android:textSize=""18dp"" /&gt;

                    &lt;TextView
                        android:id=""@+id/Ndead1""
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:textColor=""#FFFFFF""
                        android:textSize=""29dp"" /&gt;


                    &lt;ProgressBar
                        android:id=""@+id/l4""

                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:indeterminate=""true"" /&gt;

                &lt;/RelativeLayout&gt;

            &lt;/android.support.v7.widget.CardView&gt;


        &lt;/LinearLayout&gt;

        &lt;LinearLayout
            android:id=""@+id/lin3""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""16dp""
            android:layout_marginBottom=""8dp""
            android:orientation=""horizontal""
            android:visibility=""gone""&gt;

            &lt;android.support.v7.widget.CardView
                android:layout_width=""160dp""
                android:layout_height=""120dp""
                android:layout_weight=""1""
                app:cardCornerRadius=""8dp""
                app:cardElevation=""2dp""&gt;

                &lt;RelativeLayout
                    android:layout_width=""match_parent""
                    android:layout_height=""match_parent""
                    android:padding=""8dp""&gt;

                    &lt;TextView
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:fontFamily=""@font/roboto_bold""
                        android:text=""Total récupéré""
                        android:textColor=""#5E5E5E""
                        android:textSize=""18dp"" /&gt;

                    &lt;TextView
                        android:id=""@+id/Totrec1""
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:textColor=""#FFFFFF""
                        android:textSize=""29dp"" /&gt;


                    &lt;ProgressBar
                        android:id=""@+id/l5""

                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:indeterminate=""true"" /&gt;

                &lt;/RelativeLayout&gt;

            &lt;/android.support.v7.widget.CardView&gt;

            &lt;android.support.v7.widget.CardView
                android:layout_width=""160dp""
                android:layout_height=""120dp""
                android:layout_marginLeft=""18dp""
                android:layout_weight=""1""
                app:cardCornerRadius=""8dp""
                app:cardElevation=""2dp""&gt;

                &lt;RelativeLayout
                    android:layout_width=""match_parent""
                    android:layout_height=""match_parent""
                    android:padding=""8dp""&gt;

                    &lt;TextView
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:fontFamily=""@font/roboto_bold""
                        android:text=""Cas active""
                        android:textColor=""#5E5E5E""
                        android:textSize=""18dp"" /&gt;

                    &lt;TextView
                        android:id=""@+id/act1""
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:textColor=""#FFFFFF""
                        android:textSize=""29dp"" /&gt;


                    &lt;ProgressBar
                        android:id=""@+id/l6""

                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:indeterminate=""true"" /&gt;

                &lt;/RelativeLayout&gt;

            &lt;/android.support.v7.widget.CardView&gt;


        &lt;/LinearLayout&gt;

        &lt;LinearLayout
            android:id=""@+id/lin4""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""16dp""
            android:layout_marginBottom=""8dp""
            android:orientation=""horizontal""
            android:visibility=""gone""&gt;

            &lt;android.support.v7.widget.CardView
                android:layout_width=""160dp""
                android:layout_height=""120dp""
                android:layout_weight=""1""
                app:cardCornerRadius=""8dp""
                app:cardElevation=""2dp""&gt;

                &lt;RelativeLayout
                    android:layout_width=""match_parent""
                    android:layout_height=""match_parent""
                    android:padding=""8dp""&gt;

                    &lt;TextView
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:fontFamily=""@font/roboto_bold""
                        android:text=""Cas critique""
                        android:textColor=""#5E5E5E""
                        android:textSize=""18dp"" /&gt;

                    &lt;TextView
                        android:id=""@+id/cri1""
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:textColor=""#FFFFFF""
                        android:textSize=""29dp"" /&gt;


                    &lt;ProgressBar
                        android:id=""@+id/l7""

                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:indeterminate=""true"" /&gt;

                &lt;/RelativeLayout&gt;

            &lt;/android.support.v7.widget.CardView&gt;

            &lt;android.support.v7.widget.CardView
                android:layout_width=""160dp""
                android:layout_height=""120dp""
                android:layout_marginLeft=""18dp""
                android:layout_weight=""1""
                app:cardCornerRadius=""8dp""
                app:cardElevation=""2dp""&gt;

                &lt;RelativeLayout
                    android:layout_width=""match_parent""
                    android:layout_height=""match_parent""
                    android:padding=""8dp""&gt;

                    &lt;TextView
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:fontFamily=""@font/roboto_bold""
                        android:text=""Nombre total de cas / 1M habitants""
                        android:textColor=""#5E5E5E""
                        android:textSize=""18dp"" /&gt;

                    &lt;TextView
                        android:id=""@+id/tot1m1""
                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:textColor=""#FFFFFF""
                        android:textSize=""29dp"" /&gt;


                    &lt;ProgressBar
                        android:id=""@+id/l8""

                        android:layout_width=""wrap_content""
                        android:layout_height=""wrap_content""
                        android:layout_alignParentRight=""true""
                        android:layout_alignParentBottom=""true""
                        android:indeterminate=""true"" /&gt;

                &lt;/RelativeLayout&gt;




            &lt;/android.support.v7.widget.CardView&gt;


        &lt;/LinearLayout&gt;


    &lt;/LinearLayout&gt;

&lt;/android.support.v4.widget.NestedScrollView&gt;
</code></pre>

<p>I know I shouldn't use ListView in NestedScrollView, but I have no other option for now</p>

<p>Hope someone can help !</p>
"
61188088,"<p>I am trying to run an api call periodically every one hour. I know the minimum time interval for periodic request is 15 minutes i have definitely kept it more than that.</p>

<p>Below is my code to run periodic request</p>

<pre><code>val data = Data.Builder().putString(
            ""covid_country"",
            viewModel?.getSavedCountry()
        ).build()

        val request =
        PeriodicWorkRequest.Builder(CovidWorker::class.java, 1, TimeUnit.HOURS)
            .setInputData(data)
            .setConstraints(
                Constraints.Builder()
                    .setRequiredNetworkType(NetworkType.CONNECTED)
                    .build()
            )
            .build()


        WorkManager.getInstance(this)
            .enqueueUniquePeriodicWork(""simplified"", ExistingPeriodicWorkPolicy.KEEP, request)
</code></pre>

<p>In the <code>workmanager</code> class's <code>doWork</code> method i am just calling the api and send local notification if successfully.</p>

<pre><code>override fun doWork(): Result {
        val covidCountry = inputData.getString(""covid_country"")
        Log.i(""savedd112"", covidCountry)
        Coroutines.main {

            val response =
                CovidApi().getCovidCases(""india"")

            val count = response?.get(response.size - 1)?.Cases ?: 0
            Log.i(""hereeached"", ""mark"")
            displayNotification(""Cases in india"", ""$count"")


        }
        return Result.retry()
    }
</code></pre>

<p>But it is never runned. I dont see my local notification. I waited the whole day for this. There is no easy way to debug this so i decided to convert my periodic work request to one time work request and added a button in my <code>UI</code> and on the button on click listener i called the following code</p>

<pre><code>WorkManager.getInstance(this).enqueue(request)
</code></pre>

<p>Now the api gets called correctly and the local notification is displayed when the <code>api</code> succeeds. I dont understand why my periodic request is not running</p>
"
61628199,"<p>State Fragment :</p>

<pre><code>public class StatesFragment extends Fragment implements MyCustomAdaptorState.OnItemClickListener {
    private TextView tvcases_india, tvdeath_india, tvrecoverey_india;


    EditText serachstr_india;
    RecyclerView recyclerView;

    public static List&lt;StatesModel&gt; statesModelList = new ArrayList&lt;&gt;();
    private StatesModel statesModel;
    private MyCustomAdaptorState myCustomAdaptorState;


    @Nullable
    @Override
    public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {
        View inflate = inflater.inflate(R.layout.fragment_states, container, false);
        //Active Calls
        tvcases_india = inflate.findViewById(R.id.india_covid_cases);
        tvdeath_india = inflate.findViewById(R.id.india_covid_death);
        tvrecoverey_india = inflate.findViewById(R.id.india_covid_recovered);

        serachstr_india = inflate.findViewById(R.id.edtext_search_bar_india_states);
        recyclerView = inflate.findViewById(R.id.covid_india_state);


        //Volley Call 1
        getDataIndia();
        //Volley Call 2
        getDataState();


        //Search Bar
        serachstr_india.addTextChangedListener(new TextWatcher() {
            @Override
            public void beforeTextChanged(CharSequence charSequence, int i, int i1, int i2) {

            }

            @Override
            public void onTextChanged(CharSequence charSequence, int i, int i1, int i2) {
                myCustomAdaptorState.getFilter().filter(charSequence);
                myCustomAdaptorState.notifyDataSetChanged();
            }

            @Override
            public void afterTextChanged(Editable editable) {

            }
        });


        return inflate;
    }


    private void getDataIndia() {
        RequestQueue queue = Volley.newRequestQueue(getActivity());
        String url = ""https://corona.lmao.ninja/v2/countries/india"";

        StringRequest request = new StringRequest(Request.Method.GET, url, new Response.Listener&lt;String&gt;() {
            @Override
            public void onResponse(String response) {


                try {
                    JSONObject object = new JSONObject(response.toString());
                    tvcases_india.setText(object.getString(""cases""));
                    tvdeath_india.setText(object.getString(""deaths""));
                    tvrecoverey_india.setText(object.getString(""recovered""));
                } catch (JSONException e) {
                    e.printStackTrace();
                }
            }
        }, new Response.ErrorListener() {
            @Override
            public void onErrorResponse(VolleyError error) {

                Log.d(""Error Response"", error.toString());
            }

        });

        queue.add(request);
    }

    private void getDataState() {
        RequestQueue queue = Volley.newRequestQueue(getActivity());
        String Url = ""http://covid19-india-adhikansh.herokuapp.com/states"";
        StringRequest stringRequest = new StringRequest(Request.Method.GET, Url, new Response.Listener&lt;String&gt;() {
            @Override
            public void onResponse(String response) {
                try {
                    JSONObject jsonObject = new JSONObject(response);
                    JSONArray array = jsonObject.getJSONArray(""state"");
                    for (int i = 0; i &lt; array.length(); i++) {
                        statesModel = new StatesModel();
                        JSONObject object = array.getJSONObject(i);
                        statesModel.setStateName(object.getString(""name""));
                        statesModelList.add(statesModel);
                    }
                    recyclerView.setLayoutManager(new LinearLayoutManager(getActivity()));
                    myCustomAdaptorState = new MyCustomAdaptorState(getActivity(), statesModelList);
                    recyclerView.setAdapter(myCustomAdaptorState);
                    myCustomAdaptorState.setOnItemClickListener(StatesFragment.this);


                } catch (JSONException e) {
                    e.printStackTrace();
                }


            }
        }, new Response.ErrorListener() {
            @Override
            public void onErrorResponse(VolleyError error) {
                Log.d(""onResponse"", error.toString());
            }
        });
        queue.add(stringRequest);
    }


    @Override
    public void onClickListener(int position) {
        Intent intent = new Intent(getActivity(),DetailStateActivity.class);
        intent.putExtra(""position"",position);
        startActivity(intent);
    }
}
</code></pre>

<p>CustomAdaptorState.java:</p>

<pre><code>public class MyCustomAdaptorState extends RecyclerView.Adapter&lt;MyCustomAdaptorState.ViewHolder&gt; {

    LayoutInflater layoutInflater;
    private static List&lt;StatesModel&gt; statesModelList ;
    private List&lt;StatesModel&gt; statesModelListFilter;
    private OnItemClickListener mListener;

    public interface OnItemClickListener{
        void onClickListener(int position);
    }

    public void setOnItemClickListener(OnItemClickListener listener){
        mListener = listener;
    }


    public MyCustomAdaptorState(Context ctx ,List&lt;StatesModel&gt; statesModelList){
        this.layoutInflater = LayoutInflater.from(ctx);
        this.statesModelList = statesModelList;
        this.statesModelListFilter = statesModelList;
    }

    @NonNull
    @Override
    public ViewHolder onCreateViewHolder(@NonNull ViewGroup parent, int viewType) {
        View view = layoutInflater.inflate(R.layout.custom_list_item_states,parent,false);
        return new ViewHolder(view);
    }

    @Override
    public void onBindViewHolder(@NonNull ViewHolder holder, int position) {
        holder.stateName.setText(statesModelListFilter.get(position).getStateName());

    }

    @Override
    public int getItemCount() {
        return statesModelListFilter.size();
    }

    public Filter getFilter(){
        Filter filter = new Filter() {
            @Override
            protected FilterResults performFiltering(CharSequence charSequence) {
                FilterResults filterResults = new FilterResults();
                if(charSequence == null || charSequence.length()==0){
                    filterResults.count = statesModelList.size();
                    filterResults.values = statesModelList;
                }else {
                    List&lt;StatesModel&gt; statesModelsResult = new ArrayList&lt;&gt;();
                    String searchStr = charSequence.toString().toLowerCase();

                    for(StatesModel statesItemModel : statesModelList){
                        if (statesItemModel.getStateName().toLowerCase().contains(searchStr)){
                            statesModelsResult.add(statesItemModel);
                        }
                        filterResults.count = statesModelsResult.size();
                        filterResults.values = statesModelsResult;
                    }
                }
                return filterResults;
            }

            @Override
            protected void publishResults(CharSequence charSequence, FilterResults filterResults) {
                statesModelListFilter = (List&lt;StatesModel&gt;)filterResults.values;
                StatesFragment.statesModelList = (List&lt;StatesModel&gt;)filterResults.values;
                notifyDataSetChanged();
            }
        };
        return filter;
    }


    public class ViewHolder extends RecyclerView.ViewHolder {

        TextView stateName;

        public ViewHolder(@NonNull View itemView) {
            super(itemView);

            stateName = itemView.findViewById(R.id.tv_india_state_name);
            itemView.setOnClickListener(new View.OnClickListener() {
                @Override
                public void onClick(View view) {
                    if(mListener != null){
                        int position = getAdapterPosition();
                        if(position!=RecyclerView.NO_POSITION){
                            mListener.onClickListener(position);
                        }
                    }
                }
            });
        }
    }
</code></pre>

<p>StateModel.java</p>

<pre><code>public class StatesModel {
    private String stateName,stateCases,stateDeath,stateRecovered;

    public StatesModel() {
    }

    public StatesModel(String stateName, String stateCases, String stateDeath, String stateRecovered) {
        this.stateName = stateName;
        this.stateCases = stateCases;
        this.stateDeath = stateDeath;
        this.stateRecovered = stateRecovered;
    }

    public String getStateName() {
        return stateName;
    }

    public void setStateName(String stateName) {
        this.stateName = stateName;
    }

    public String getStateCases() {
        return stateCases;
    }

    public void setStateCases(String stateCases) {
        this.stateCases = stateCases;
    }

    public String getStateDeath() {
        return stateDeath;
    }

    public void setStateDeath(String stateDeath) {
        this.stateDeath = stateDeath;
    }

    public String getStateRecovered() {
        return stateRecovered;
    }

    public void setStateRecovered(String stateRecovered) {
        this.stateRecovered = stateRecovered;
    }
}

DetailStateActitvity.java
public class DetailStateActivity extends AppCompatActivity {
    int position;
    private TextView stateNameIndia,stateCases,stateDeath,stateRecovered;


    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_detail_state);
        stateNameIndia = (TextView)findViewById(R.id.detail_state);
        stateCases = (TextView)findViewById(R.id.no_cases_state);
        stateRecovered = (TextView)findViewById(R.id.no_recovered_state);
        stateDeath = (TextView)findViewById(R.id.no_death_state);

        Intent intent = getIntent();
        position = intent.getIntExtra(""position"",0);

        stateNameIndia.setText(StatesFragment.statesModelList.get(position).getStateName());
        stateCases.setText(StatesFragment.statesModelList.get(position).getStateCases());
        stateRecovered.setText(StatesFragment.statesModelList.get(position).getStateRecovered());
        stateDeath.setText(StatesFragment.statesModelList.get(position).getStateDeath());

    }
}
</code></pre>

<p>fragment_state.xml:</p>

<pre><code>&lt;androidx.appcompat.widget.LinearLayoutCompat
    xmlns:android=""http://schemas.android.com/apk/res/android""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    xmlns:tools=""http://schemas.android.com/tools""
    android:orientation=""vertical""
    xmlns:app=""http://schemas.android.com/apk/res-auto""&gt;

    &lt;androidx.cardview.widget.CardView
        android:layout_width=""match_parent""
        android:layout_height=""200dp""
        app:cardBackgroundColor=""#fcf2d8""
        android:layout_marginLeft=""15dp""
        android:layout_marginTop=""15dp""
        android:layout_marginRight=""15dp""
        app:cardCornerRadius=""15dp""
        app:cardElevation=""15dp""
        app:layout_constraintBottom_toBottomOf=""parent""
        app:layout_constraintTop_toTopOf=""parent""
        app:layout_constraintHorizontal_bias=""0.061""
        tools:layout_editor_absoluteX=""0dp""&gt;
        &lt;RelativeLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""10dp""
            android:layout_gravity=""center_horizontal""
            android:layout_marginBottom=""10dp""
            android:layout_marginLeft=""25dp""
            android:layout_marginRight=""25dp""&gt;
        &lt;TextView
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:fontFamily=""@font/poppins_medium""
            android:text=""India COVID-19 Report""
            android:textSize=""20sp""/&gt;
        &lt;/RelativeLayout&gt;
        &lt;RelativeLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""50dp""
            android:layout_marginBottom=""10dp""
            android:layout_marginLeft=""25dp""
            android:layout_marginRight=""25dp""&gt;
            &lt;TextView
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:fontFamily=""@font/poppins_medium""
                android:text=""Cases""
                android:textSize=""20sp""/&gt;
            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""wrap_content""
                android:text=""0""
                android:textColor=""@color/TotalCases""
                android:id=""@+id/india_covid_cases""
                android:textSize=""18sp""
                android:textAlignment=""textEnd""
                android:textStyle=""bold""
                android:fontFamily=""@font/poppins_bold""
                /&gt;
        &lt;/RelativeLayout&gt;
        &lt;RelativeLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""90dp""
            android:layout_marginBottom=""10dp""
            android:layout_marginLeft=""25dp""
            android:layout_marginRight=""25dp""&gt;
            &lt;TextView
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:fontFamily=""@font/poppins_medium""
                android:text=""Death""
                android:textSize=""20sp""/&gt;
            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""wrap_content""
                android:text=""0""
                android:textColor=""@color/TotalDeath""
                android:id=""@+id/india_covid_death""
                android:textSize=""18sp""
                android:textAlignment=""textEnd""
                android:textStyle=""bold""
                android:fontFamily=""@font/poppins_bold""
                /&gt;
        &lt;/RelativeLayout&gt;
        &lt;RelativeLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""130dp""
            android:layout_marginBottom=""10dp""
            android:layout_marginLeft=""25dp""
            android:layout_marginRight=""25dp""&gt;
            &lt;TextView
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:fontFamily=""@font/poppins_medium""
                android:text=""Recovered""
                android:textSize=""20sp""/&gt;
            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""wrap_content""
                android:text=""0""
                android:textColor=""@color/TotalRecovery""
                android:id=""@+id/india_covid_recovered""
                android:textSize=""18sp""
                android:textAlignment=""textEnd""
                android:textStyle=""bold""
                android:fontFamily=""@font/poppins_bold""
                /&gt;
        &lt;/RelativeLayout&gt;

    &lt;/androidx.cardview.widget.CardView&gt;
    &lt;androidx.cardview.widget.CardView
        android:layout_width=""match_parent""
        android:layout_height=""530dp""
        app:cardBackgroundColor=""#fcf2d8""
        android:layout_marginLeft=""15dp""
        android:layout_marginTop=""15dp""
        android:layout_marginRight=""15dp""
        app:cardCornerRadius=""15dp""
        app:cardElevation=""15dp""
        app:layout_constraintBottom_toBottomOf=""parent""
        app:layout_constraintTop_toTopOf=""parent""
        app:layout_constraintHorizontal_bias=""0.061""
        tools:layout_editor_absoluteX=""0dp""&gt;
        &lt;EditText
            android:id=""@+id/edtext_search_bar_india_states""
            android:layout_width=""match_parent""
            android:layout_height=""45dp""
            android:layout_margin=""15dp""
            android:background=""@drawable/edittext_design""
            android:drawableLeft=""@drawable/ic_search_black_24dp""
            android:paddingLeft=""10dp""
            android:hint=""Search Here...""
            android:fontFamily=""@font/poppins_medium""
            android:singleLine=""true""
            android:drawablePadding=""5dp""
            app:layout_constraintBottom_toBottomOf=""parent""
            app:layout_constraintTop_toTopOf=""parent""
            app:layout_constraintVertical_bias=""0.009""
            tools:ignore=""MissingConstraints""
            tools:layout_editor_absoluteX=""13dp"" /&gt;
            &lt;androidx.recyclerview.widget.RecyclerView
                android:layout_width=""match_parent""
                android:layout_height=""wrap_content""
                android:layout_marginTop=""66dp""
                android:layout_marginLeft=""10dp""
                android:layout_marginRight=""10dp""
                android:layout_marginBottom=""10dp""
                android:id=""@+id/covid_india_state""
                android:layout_below=""@id/edtext_search_bar_india_states""
                tools:listitem=""@layout/custom_list_item_states""
                tools:ignore=""MissingConstraints""&gt;
            &lt;/androidx.recyclerview.widget.RecyclerView&gt;
    &lt;/androidx.cardview.widget.CardView&gt;






    &lt;/androidx.appcompat.widget.LinearLayoutCompat&gt;
custom_list_item_state.xml:
&lt;androidx.appcompat.widget.LinearLayoutCompat
    xmlns:android=""http://schemas.android.com/apk/res/android""
    android:layout_width=""match_parent""
    android:orientation=""horizontal""
    android:layout_margin=""5dp""
    android:layout_height=""wrap_content""&gt;

    &lt;ImageView
        android:layout_width=""80dp""
        android:layout_height=""60dp""
        android:id=""@+id/imageview_india""
        android:src=""@drawable/indiaflag""
        android:padding=""5dp""
        android:layout_margin=""5dp""/&gt;
    &lt;TextView
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        android:id=""@+id/tv_india_state_name""
        android:layout_gravity=""center_vertical""
        android:fontFamily=""@font/poppins_medium""
        android:text=""State Name""
        android:textSize=""20sp""
        android:paddingLeft=""15dp""/&gt;

&lt;/androidx.appcompat.widget.LinearLayoutCompat&gt;
activity_detail_state.xml:
&lt;androidx.appcompat.widget.LinearLayoutCompat xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    xmlns:tools=""http://schemas.android.com/tools""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    android:orientation=""vertical""
    tools:context="".DetailActivity""&gt;

    &lt;androidx.cardview.widget.CardView
        android:layout_width=""match_parent""
        android:layout_height=""200dp""
        android:layout_marginLeft=""15dp""
        android:layout_marginTop=""80dp""

        android:layout_marginRight=""15dp""
        android:layout_marginBottom=""15dp""
        app:cardElevation=""20dp""
        app:cardBackgroundColor=""#fcf2d8""
        app:cardCornerRadius=""15dp""&gt;

        &lt;RelativeLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""10dp""
            android:layout_marginBottom=""10dp""
            android:layout_marginLeft=""25dp""
            android:layout_marginRight=""25dp""&gt;
            &lt;TextView
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:fontFamily=""@font/poppins_medium""
                android:text=""States""
                android:textSize=""20sp""/&gt;
            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""wrap_content""
                android:text=""0""
                android:id=""@+id/detail_state""
                android:textSize=""18sp""
                android:textAlignment=""textEnd""
                android:textStyle=""bold""
                android:fontFamily=""@font/poppins_bold""
                /&gt;

        &lt;/RelativeLayout&gt;
        &lt;RelativeLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""55dp""
            android:layout_marginBottom=""10dp""
            android:layout_marginLeft=""25dp""
            android:layout_marginRight=""25dp""&gt;
            &lt;TextView
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:fontFamily=""@font/poppins_medium""
                android:text=""Cases""
                android:textSize=""20sp""/&gt;
            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""wrap_content""
                android:text=""0""
                android:id=""@+id/no_cases_state""
                android:textSize=""18sp""
                android:textAlignment=""textEnd""
                android:textStyle=""bold""
                android:fontFamily=""@font/poppins_bold""
                /&gt;

        &lt;/RelativeLayout&gt;
        &lt;RelativeLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""102dp""
            android:layout_marginBottom=""10dp""
            android:layout_marginLeft=""25dp""
            android:layout_marginRight=""25dp""&gt;
            &lt;TextView
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:fontFamily=""@font/poppins_medium""
                android:text=""Recovered""
                android:textSize=""20sp""/&gt;
            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""wrap_content""
                android:text=""0""
                android:id=""@+id/no_recovered_state""
                android:textSize=""18sp""
                android:textAlignment=""textEnd""
                android:textStyle=""bold""
                android:fontFamily=""@font/poppins_bold""
                /&gt;

        &lt;/RelativeLayout&gt;
        &lt;RelativeLayout
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:layout_marginTop=""149dp""
            android:layout_marginBottom=""10dp""
            android:layout_marginLeft=""25dp""
            android:layout_marginRight=""25dp""&gt;
            &lt;TextView
                android:layout_width=""wrap_content""
                android:layout_height=""wrap_content""
                android:fontFamily=""@font/poppins_medium""
                android:text=""Death""
                android:textSize=""20sp""/&gt;
            &lt;TextView
                android:layout_width=""fill_parent""
                android:layout_height=""wrap_content""
                android:text=""0""
                android:id=""@+id/no_death_state""
                android:textSize=""18sp""
                android:textAlignment=""textEnd""
                android:textStyle=""bold""
                android:fontFamily=""@font/poppins_bold""
                /&gt;

        &lt;/RelativeLayout&gt;


    &lt;/androidx.cardview.widget.CardView&gt;



&lt;/androidx.appcompat.widget.LinearLayoutCompat&gt;
</code></pre>

<p>please help me to get all results and display in the activity_detail_state. I only get the name of the state name and not the rest details. So please help me to complete my project. Sorry for not providing the image of the problem. but when you run the code you know the problem.</p>
"
61386355,"<p>I m calling an API using volley which is in the form of JSON. That JSON has JSON objects inside a JSON array. I have written a code calling JSONArrayRequest first then I run a loop to find all the objects inside that array after that I get state name through getString and matches it the state name which is pressed if it same then next loop runs to find all the ""district"" name and ""active"" from the districtData. I am not able to get output but in ErrorResponse toast, I get the full array with all its data of API. </p>

<p>if I am changing <strong>""JSONObject array = object1.getJSONObject(""districtData"");""</strong>
to <strong>""JSONArray array = object1.getJSONArray(""districtData"");</strong> "" I am getting error screenshot attached bellow...</p>

<p>if not changing this <strong>""JSONObject array = object1.getJSONObject(""districtData"");""</strong>
then I don't know what to write here <strong>""JSONObject object2 = array.getJSONObject(/<em>What To do after that, what to enter here pls tell me... I m new to this</em>/);""</strong> because whatever I m writing there toast's me that not getting the value of what I m entring.</p>

<p><strong>Some part of JSON</strong></p>

<p>[ {
    ""state"": ""Andaman and Nicobar Islands"",
    ""statecode"": ""AN"",
    ""districtData"": [
      {
        ""district"": ""North and Middle Andaman"",
        ""notes"": """",
        ""active"": 0,
        ""confirmed"": 1,
        ""deceased"": 0,
        ""recovered"": 1,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      {
        ""district"": ""South Andaman"",
        ""notes"": """",
        ""active"": 10,
        ""confirmed"": 20,
        ""deceased"": 0,
        ""recovered"": 10,
        ""delta"": {
          ""confirmed"": 4,
          ""deceased"": 0,
          ""recovered"": 0
        }
      },
      {
        ""district"": ""Unknown"",
        ""notes"": """",
        ""active"": 1,
        ""confirmed"": 1,
        ""deceased"": 0,
        ""recovered"": 0,
        ""delta"": {
          ""confirmed"": 0,
          ""deceased"": 0,
          ""recovered"": 0
        }
      }
    ]
  }
]</p>

<pre><code>private void getData2(){
    final ProgressDialog progressDialog = new ProgressDialog(this);
    final String clickedState = getIntent().getStringExtra(""stateName"");
    progressDialog.setMessage(""Loading..."");
    progressDialog.show();
    String url = ""https://api.covid19india.org/v2/state_district_wise.json"";
    StringRequest request = new StringRequest(Request.Method.GET, url,
            new Response.Listener&lt;String&gt;() {
                @Override
                public void onResponse(String response) {
                    progressDialog.dismiss();
                    try {
                        JSONObject object = new JSONObject(response);
                        assert clickedState != null;
                        JSONObject object1 = object.getJSONObject(clickedState);
                        JSONObject array = object1.getJSONObject(""districtData"");
                        for (int i = 0; i&lt;array.length();i++){
                            JSONObject object2 = array.getJSONObject(/*What To do after that, what to enter here pls tel me... I m new to this*/);
                            String s1 = object2.getString(""district"");
                            String s2 = object2.getString(""active"");
                            StateList item = new StateList(s1,s2);
                            mData2.add(item);
                            initRecyclerView();
                        }
                    } catch (JSONException e) {
                        e.printStackTrace();
                        Toast.makeText(getApplicationContext(),e.getMessage(),Toast.LENGTH_SHORT).show();
                    }
                }
            }, new Response.ErrorListener() {
        @Override
        public void onErrorResponse(VolleyError error) {
            Toast.makeText(getApplicationContext(),error.getMessage(),Toast.LENGTH_SHORT).show();
        }
    });
    Volley.newRequestQueue(this).add(request);
}
private void initRecyclerView(){
    Log.d(TAG, ""initRecyclerView: initRecyclerView"");
    RecyclerView recyclerView = findViewById(R.id.districtsDetailedRecycler);
    StateDistrictsAdapter adapter2 = new StateDistrictsAdapter(mData2,this);
    recyclerView.setAdapter(adapter2);
    recyclerView.setLayoutManager(new LinearLayoutManager(this));
}
</code></pre>

<p>}</p>

<p><a href=""https://i.stack.imgur.com/xESQd.jpg"" rel=""nofollow noreferrer"">Error ScreenShot</a></p>
"
61467100,"<p>My SearchView not works... I m trying to search in RecyclerView but it through an error Of JavaExeption...I have done everyThing that I can do, but the problem is still there where it was. Pls guide me I am a student.
'void android.widget.SearchView.setOnQueryTextListener(android.widget.SearchView$OnQueryTextListener)' on a null object reference</p>

<p><strong>SupportAdapter code</strong></p>

<pre><code>public class SupportAdapter extends RecyclerView.Adapter&lt;SupportAdapter.viewHolder&gt; implements Filterable {
    private static final  String TAG = ""SupportAdapter"";
    private Context mContext;
    private List&lt;SupportList&gt; mData;
    private List&lt;SupportList&gt; mDataFull;

public static class viewHolder extends RecyclerView.ViewHolder{

    private TextView Category;
    private TextView City;
    private TextView Contact;
    private TextView Description;
    private TextView Organisation;
    private TextView Phone;
    private TextView State;
    private LinearLayout container;

    private viewHolder(View itemView) {
        super(itemView);

       container = itemView.findViewById(R.id.supportContainer);
        Category = itemView.findViewById(R.id.category);
        City = itemView.findViewById(R.id.city);
        Contact = itemView.findViewById(R.id.contact);
        Description = itemView.findViewById(R.id.description);
        Organisation = itemView.findViewById(R.id.name_of_org);
        Phone = itemView.findViewById(R.id.phone);
        State = itemView.findViewById(R.id.state);

    }
}

public SupportAdapter(Context mContext, List&lt;SupportList&gt; mData) {
    this.mContext = mContext;
    this.mData = mData;
    mDataFull = new ArrayList&lt;&gt;(mData);
}

@NonNull
@Override
public viewHolder onCreateViewHolder(@NonNull ViewGroup parent, int viewType) {
    View v = LayoutInflater.from(parent.getContext())
            .inflate(R.layout.search_item_list,parent,false);

    return new viewHolder(v);
}

@Override
public void onBindViewHolder(@NonNull SupportAdapter.viewHolder holder, int position) {

    holder.container.setAnimation(AnimationUtils.loadAnimation(mContext, R.anim.fade_scale_animation));
    holder.Category.setText(mData.get(position).getCategory());
    holder.City.setText(mData.get(position).getCity());
    holder.Contact.setText(mData.get(position).getContact());
    holder.Description.setText(mData.get(position).getDescription());
    holder.Organisation.setText(mData.get(position).getOrganisation());
    holder.Phone.setText(mData.get(position).getPhone());
    holder.State.setText(mData.get(position).getState());
}

@Override
public int getItemCount() {
    return mData.size();
}


@Override
public Filter getFilter() {
    return mDataFullFilter;
}

private Filter mDataFullFilter = new Filter() {
    @Override
    protected FilterResults performFiltering(CharSequence constraint) {
        List&lt;SupportList&gt; filteredList = new ArrayList&lt;&gt;();
        if (constraint == null || constraint.length() == 0){
            filteredList.addAll(mDataFull);
        }else {
            String filterPattern =constraint.toString().toLowerCase().trim();

            for(SupportList item : mDataFull){
                if(item.getCity().toLowerCase().contains(filterPattern)){
                    filteredList.add(item);
                }
                else if (item.getCity().toLowerCase().contains(filterPattern)){
                    filteredList.add(item);
                }
            }
        }

        FilterResults results = new FilterResults();
        results.values = filteredList;
        return results;
    }

    @Override
    protected void publishResults(CharSequence constraint, FilterResults results) {

        mData.clear();
        mData.addAll((List) results.values);
        notifyDataSetChanged();

    }
};
</code></pre>

<p><strong>SearchFragment</strong></p>

<pre><code>private RecyclerView NewRecyclerView;
private SupportAdapter supportAdapter;
private List&lt;SupportList&gt; mData;
private SearchView searchItem;

public View onCreateView(@NonNull LayoutInflater inflater,
                         ViewGroup container, Bundle savedInstanceState) {
    ViewModelProviders.of(this).get(SearchViewModel.class);
    View root = inflater.inflate(R.layout.fragment_search, container, false);
    searchItem = root.findViewById(R.id.searchItem);
    NewRecyclerView = root.findViewById(R.id.searchList);
    supportAdapter = new SupportAdapter (getContext(),mData);
    NewRecyclerView.setLayoutManager(new LinearLayoutManager(getActivity()));
    NewRecyclerView.setAdapter(supportAdapter);


    return root;
}




@Override
public void onCreate(@Nullable Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    mData = new ArrayList&lt;&gt;();
    getSupport();

    searchItem.setOnQueryTextListener(new SearchView.OnQueryTextListener() {
        @Override
        public boolean onQueryTextSubmit(String query) {
            supportAdapter.getFilter().filter(query);
            return false;
        }

        @Override
        public boolean onQueryTextChange(String newText) {
            supportAdapter.getFilter().filter(newText);
            return false;
        }
    });

}
</code></pre>

<p><strong>Logcat</strong></p>

<pre><code>2020-04-28 00:58:02.828 12382-12382/com.praso.indiacovid_19 E/AndroidRuntime: FATAL EXCEPTION: main
    Process: com.praso.indiacovid_19, PID: 12382
    java.lang.NullPointerException: Attempt to invoke virtual method 'void android.widget.SearchView.setOnQueryTextListener(android.widget.SearchView$OnQueryTextListener)' on a null object reference
        at com.praso.indiacovid_19.ui.search.SearchFragment.onCreate(SearchFragment.java:64)
        at androidx.fragment.app.Fragment.performCreate(Fragment.java:2414)
        at androidx.fragment.app.FragmentManagerImpl.moveToState(FragmentManager.java:1418)
        at androidx.fragment.app.FragmentManagerImpl.addAddedFragments(FragmentManager.java:2646)
        at androidx.fragment.app.FragmentManagerImpl.executeOpsTogether(FragmentManager.java:2416)
        at androidx.fragment.app.FragmentManagerImpl.removeRedundantOperationsAndExecute(FragmentManager.java:2372)
        at androidx.fragment.app.FragmentManagerImpl.execPendingActions(FragmentManager.java:2273)
        at androidx.fragment.app.FragmentManagerImpl$1.run(FragmentManager.java:733)
        at android.os.Handler.handleCallback(Handler.java:883)
        at android.os.Handler.dispatchMessage(Handler.java:100)
        at android.os.Looper.loop(Looper.java:228)
        at android.app.ActivityThread.main(ActivityThread.java:7782)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:981)
</code></pre>
"
61445346,"<p>I have been trying to fetch data from an API and then converting it to an object of a particular class but each time I do so, and Then try to print the properties of the objects, an error comes that I am trying to invoke the class function on a null object. I am using the retrofit API, Can someone help me with this code!!</p>

<p>this is the asynctask class which is retrieving the data from the API</p>

<pre><code>private class fetchData() : AsyncTask&lt;Any, Void, String&gt;(){
        override fun doInBackground(vararg params: Any?): String {
            val retrofit = Retrofit.Builder()
                .baseUrl(Constants.BASE_URL)
                .addConverterFactory(GsonConverterFactory.create())
                .build()
            val service = retrofit.create&lt;CovidDataService&gt;(CovidDataService::class.java)
            val listCalled = service.getCovidData()
            listCalled.enqueue(
                object : retrofit2.Callback&lt;CovidData&gt; {


                    override fun onFailure(call: Call&lt;CovidData&gt;, t: Throwable) {
                    }

                    override fun onResponse(call: Call&lt;CovidData&gt;, response: Response&lt;CovidData&gt;) {
                        if (response!!.isSuccessful) {
                            val weatherList: CovidData = response.body()!!
                            Log.i(""Data"", weatherList.countries[1].data[1].date)
                        } else {
                        }
                    }

                }
            )
            return """"
        }

    }
</code></pre>

<p>This are the model classes that I am trying to use to map the data to an object</p>

<pre><code>data class CovidData (
    val countries:List&lt;Countries&gt;
) : Serializable

data class Countries (
    val name : String,
    val data : List&lt;CountryData&gt;
) : Serializable

data class CountryData(
    val date : String,
    val confirmed : Long,
    val deaths : Long,
    val recovered : Long
) : Serializable
</code></pre>

<p>this is the interface which is used to call the API service</p>

<pre><code>interface CovidDataService {

    @GET(""/timeseries.json"")
    fun getCovidData(): Call&lt;CovidData&gt;

}
</code></pre>

<p>Also, the response which we are getting in the list.enqueue function is creating an error and when I am printhing the error body, the following line is printed</p>

<p><code>I/Error: com.squareup.okhttp.ResponseBody$1@d11e0cc</code></p>
"
61557243,"<p>I got coronavirus df and I need to compare Israel and UK data from the time both countries had more than 10 confirmed patients, this is my code :</p>

<pre><code>library(ggplot2)
library(dplyr)

#Data frame
df.raw &lt;- read.csv(url('https://raw.githubusercontent.com/datasets/covid-19/master/data/countries-aggregated.csv'))
str(df)
df &lt;- df.raw
df$Date &lt;- as.Date(df$Date)
str(df)

df.israel &lt;- df %&gt;% filter(Country == 'Israel', Confirmed&gt;10)
df.uk &lt;- df %&gt;% filter(Country == 'United Kingdom', Confirmed&gt;10)
if(df.israel$Date[1] &gt; df.uk$Date[1]){
  df.uk &lt;- df.uk %&gt;% filter(Date &gt;= df.israel$Date[1])
} else {
  df.israel &lt;- df.israel %&gt;% filter(Date &gt;= df.uk$Date[1])
}

ggplot() +
  geom_point(data = df.israel, aes(Date, Confirmed), color = 'blue') +
  geom_point(data = df.uk, aes(Date,Confirmed), color = 'red')
</code></pre>

<p>Now, I need that my X axis will be numeric (1,2,3 etc) but I don't know how (tried xlim, scale_x_continuous) someone knows how to do this?</p>

<p><a href=""https://i.stack.imgur.com/cYc7j.png"" rel=""nofollow noreferrer"">My graph</a></p>
"
60683013,"<p>I have this data </p>

<pre><code>Data &lt;- structure(list(
  Date = c(
    ""2020-03-12"", ""2020-03-11"", ""2020-03-10"",
    ""2020-03-10"", ""2020-03-09"", ""2020-03-09"", ""2020-03-08"", ""2020-03-07"",
    ""2020-03-07"", ""2020-03-07"", ""2020-03-07"", ""2020-03-06"", ""2020-03-05"",
    ""2020-03-04"", ""2020-03-04"", ""2020-03-04"", ""2020-03-03"", ""2020-03-02"",
    ""2020-03-02"", ""2020-03-02"", ""2020-02-03"", ""2020-02-02"", ""2020-01-30""
  ), CASES = c(
    2L, 1L, 6L, 3L, 5L, 1L, 5L, 1L, 2L, 2L, 1L, 1L,
    1L, 1L, 6L, 15L, 1L, 1L, 1L, 1L, 1L, 1L, 1L
  ), STATE = c(
    ""Mumbai       "",
    ""Jaipur        "", ""Kerala       "", ""Karnataka        "", ""Jammu       "",
    ""Kerala        "", ""Kerala        "", ""Tamil Nadu       "", ""Ladakh       "",
    ""Hoshiarpur        "", ""Jammu       "", ""Delhi      "", ""Ghaziabaad UP       "",
    ""Gurgaon       "", ""Agra       "", ""Delhi      "", ""Jaipur        "",
    ""Jaipur        "", ""Hyderabad       "", ""Delhi       "", ""Kerala        "",
    ""Kerala        "", ""Kerala        ""
  ), CASES_CF = c(
    2L, 3L, 15L,
    3L, 2L, 9L, 8L, 1L, 2L, 2L, 1L, 17L, 1L, 1L, 6L, 15L, 2L, 1L,
    1L, 1L, 3L, 2L, 1L
  ), CF = c(
    60L, 58L, 57L, 51L, 48L, 43L, 42L,
    38L, 36L, 34L, 32L, 31L, 30L, 29L, 28L, 22L, 7L, 6L, 5L, 4L,
    3L, 2L, 1L
  ), State_wise = c(
    2L, 3L, 35L, 1L, 1L, 20L, 11L, 1L,
    2L, 1L, 1L, 3L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 3L, 2L, 1L
  ),
  Date2 = c(
    ""2020-03-12"", ""2020-03-11"", ""2020-03-10"", ""2020-03-10"",
    ""2020-03-09"", ""2020-03-09"", ""2020-03-08"", ""2020-03-07"", ""2020-03-07"",
    ""2020-03-07"", ""2020-03-07"", ""2020-03-06"", ""2020-03-05"", ""2020-03-04"",
    ""2020-03-04"", ""2020-03-04"", ""2020-03-03"", ""2020-03-02"", ""2020-03-02"",
    ""2020-03-02"", ""2020-02-03"", ""2020-02-02"", ""2020-01-30""
  ),
  Short = c(
    ""M"", ""J"", ""Ker"", ""Krn"", ""Jam"", ""Ker"", ""Ker"", ""TN"",
    ""lad"", ""Hosh"", ""Jmu"", ""Del"", ""Gazz"", ""Gur"", ""Agr"", ""Del"",
    ""Jai"", ""Jai"", ""hyd"", ""Del"", ""Ker"", ""Ker"", ""Ker""
  ), Date3 = c(
    ""2020-03-12"",
    ""2020-03-02"", ""2020-01-30"", ""2020-03-10"", ""2020-03-07"", ""2020-01-30"",
    ""2020-01-30"", ""2020-03-07"", ""2020-03-07"", ""2020-03-07"", ""2020-03-07"",
    ""2020-03-02"", ""2020-03-05"", ""2020-03-04"", ""2020-03-04"", ""2020-03-02"",
    ""2020-03-02"", ""2020-03-02"", ""2020-03-02"", ""2020-03-02"", ""2020-01-30"",
    ""2020-01-30"", ""2020-01-30""
  )
), class = ""data.frame"", row.names = c(
  NA,
  -23L
))
</code></pre>

<pre><code>library(ggplot2)
library(gganimate)

class(Data$Date)
Data$Date3 &lt;- as.Date(Data$Date3)
Data$Date3 
B &lt;- ggplot(data = Data,aes(CASES_CF,Data$Date3,colour=Data$STATE,group=Data$STATE))+geom_point()+theme(axis.text.x=element_text(size=rel(1), angle=90))+xlab(""Total number of cases confrimed"")+ylab(""Date"")
Text &lt;- B+geom_text(aes(label=Data$STATE),hjust=0, vjust=0)+scale_y_date(breaks = ""3 day"")
annim &lt;- Text+transition_states(Data$Date2)
annim
</code></pre>

<p><a href=""https://imgur.com/gQ1gT6P"" rel=""nofollow noreferrer"">
This is the result I am getting </a></p>

<p><a href=""https://i.stack.imgur.com/DFBnh.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DFBnh.gif"" alt=""enter image description here""></a></p>

<p>I am having problem getting smooth animation and my <code>geom_point</code>s disappear after some frames. With the help of <code>shadow_mark</code> I have maintained the path but I want single point to reach the destination without getting disappear. </p>

<p><a href=""https://www.reddit.com/r/dataisbeautiful/comments/feupf0/oc_timelapse_of_coronavirus_cases_by_country/"" rel=""nofollow noreferrer"">Inspired by</a></p>
"
61000814,"<p>I have a scrollView that works very slow. Inside this ScrollView I have fragments with custom UI. I am adding fragments with FragmentTransactions. How can i improve ScrollView perfomance. I consider that using fragments inside ScrollView is not the best choice? What  do you think. </p>

<p>Here is my ScrollView in main_activity.xml </p>

<pre><code>    &lt;ScrollView
    android:id=""@+id/scrollView""
    style=""@style/scrollbar_shape_style""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    android:paddingStart=""15dp""
    android:paddingTop=""145dp""
    android:scrollbarSize=""10dip""
    android:scrollbarTrackVertical=""@android:color/white""
    android:paddingEnd=""25dp""
    app:layout_constraintTop_toBottomOf=""@id/amount""
    tools:layout_editor_absoluteX=""202dp""&gt;

    &lt;FrameLayout
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content""
        android:paddingTop=""20dp""
        app:layout_constraintTop_toBottomOf=""@id/amount""&gt;

        &lt;androidx.fragment.app.FragmentContainerView
            android:id=""@+id/first_business""
            android:name=""stoppandemic.emptymindgames.com.HospitalFragment""
            android:layout_width=""match_parent""
            android:layout_height=""283dp"" /&gt;

        &lt;androidx.fragment.app.FragmentContainerView
            android:id=""@+id/second_business""
            android:name=""stoppandemic.emptymindgames.com.HospitalFragment""
            android:layout_width=""match_parent""
            android:layout_height=""283dp""
            android:layout_marginTop=""120dp"" /&gt;


        &lt;androidx.fragment.app.FragmentContainerView
            android:id=""@+id/third_business""
            android:name=""stoppandemic.emptymindgames.com.HospitalFragment""
            android:layout_width=""match_parent""
            android:layout_height=""283dp""
            android:layout_marginTop=""240dp"" /&gt;

        &lt;androidx.fragment.app.FragmentContainerView
            android:id=""@+id/fourth_business""
            android:name=""stoppandemic.emptymindgames.com.HospitalFragment""
            android:layout_width=""match_parent""
            android:layout_height=""283dp""
            android:layout_marginTop=""360dp"" /&gt;

        &lt;androidx.fragment.app.FragmentContainerView
            android:id=""@+id/fifth_business""
            android:name=""stoppandemic.emptymindgames.com.HospitalFragment""
            android:layout_width=""match_parent""
            android:layout_height=""283dp""
            android:layout_marginTop=""480dp"" /&gt;

        &lt;androidx.fragment.app.FragmentContainerView
            android:id=""@+id/sixth_business""
            android:name=""stoppandemic.emptymindgames.com.HospitalFragment""
            android:layout_width=""match_parent""
            android:layout_height=""283dp""
            android:layout_marginTop=""600dp"" /&gt;

        &lt;androidx.fragment.app.FragmentContainerView
            android:id=""@+id/seventh_business""
            android:name=""stoppandemic.emptymindgames.com.HospitalFragment""
            android:layout_width=""match_parent""
            android:layout_height=""283dp""
            android:layout_marginTop=""720dp"" /&gt;

        &lt;androidx.fragment.app.FragmentContainerView
            android:id=""@+id/eighth_business""
            android:name=""stoppandemic.emptymindgames.com.HospitalFragment""
            android:layout_width=""match_parent""
            android:layout_height=""283dp""
            android:layout_marginTop=""840dp"" /&gt;

        &lt;androidx.fragment.app.FragmentContainerView
            android:id=""@+id/ninth_business""
            android:name=""stoppandemic.emptymindgames.com.HospitalFragment""
            android:layout_width=""match_parent""
            android:layout_height=""283dp""
            android:layout_marginTop=""960dp"" /&gt;

        &lt;androidx.fragment.app.FragmentContainerView
            android:id=""@+id/tenth_business""
            android:name=""stoppandemic.emptymindgames.com.HospitalFragment""
            android:layout_width=""match_parent""
            android:layout_height=""283dp""
            android:layout_marginTop=""1080dp"" /&gt;


    &lt;/FrameLayout&gt;

&lt;/ScrollView&gt;
</code></pre>

<p>Here is my FragmentClass</p>

<pre><code>public class HospitalFragment extends Fragment {


public onImageClickListener mCallBack;

public final static String TAG = ""ArtemyDebugger"";

private int mTime;
private int mAmountOfProduction;
private int mPrice;
private int mId;
private int mMultiplier;
private int MultiplierPeople;

private View view;
OneBusinesBinding binding;

public HospitalFragment() {
}

public void setmHospital(Hospital hospital) {
    this.mTime = hospital.getTime();
    this.mAmountOfProduction = hospital.getAmount();
    this.mPrice = hospital.getPrice();
    this.mId = hospital.getId();
    this.mMultiplier = hospital.getMultiplier();
    this.MultiplierPeople = hospital.getMultiplierPeople();
}

public interface onImageClickListener {
    void clickOnImage(int id);

    void onTextViewOfPriceSelected(int id, int amountOfProduction, int price, int time, int multiplier);
}

@Override
public void onCreate(@Nullable Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
}

@Override
public void onAttach(Context context) {
    super.onAttach(context);

    try {
        mCallBack = (onImageClickListener) context;
    } catch (ClassCastException e) {
        throw new ClassCastException(context.toString()
                + "" must implement OnImageClickListener"");
    }
}

@Override
public void onViewCreated(@NonNull View view, @Nullable Bundle savedInstanceState) {
    super.onViewCreated(view, savedInstanceState);
}


@Nullable
@Override
public View onCreateView(@NonNull LayoutInflater inflater, @Nullable ViewGroup container, @Nullable Bundle savedInstanceState) {

    binding = DataBindingUtil.inflate(
            inflater, R.layout.one_busines, container, false);
    view = binding.getRoot();
    binding.imageBusiness.setImageResource(AndroidImageAssets.getPictures().get(mId));
    binding.amountofProduction.setText(getString(R.string.amount_of_production, mAmountOfProduction));
    binding.price.setText(getString(AssetsUpgradeStrings.getStrings_On_Button_Buy().get(mId), convertNumberToString(mPrice)));
    binding.progressBar.setProgressTintList(ColorStateList.valueOf(Color.GRAY));
    ;
    binding.nameHospital.setText(AssetsUpgradeStrings.getHospitalsNames().get(mId));
    binding.textViewOnProgressbar.setText(getString(R.string.string_on_progressbar, mTime));
    binding.imageBusiness.setOnClickListener((v) -&gt; {

        mCallBack.clickOnImage(mId);
    });
    binding.price.setOnClickListener((v) -&gt; {
        if (MainActivity.mAllMoney &gt;= mPrice) {

            mAmountOfProduction++;
            MainActivity.mAllMoney -= mPrice;
            mPrice = (int) Math.ceil(MyConstants.getPrices().get(mId) * Math.pow(1.12, mAmountOfProduction));
            mCallBack.onTextViewOfPriceSelected(mId, mAmountOfProduction, mPrice, mTime, mMultiplier);
            binding.price.setText(getString(AssetsUpgradeStrings.getStrings_On_Button_Buy().get(mId), convertNumberToString(mPrice)));
            binding.amountofProduction.setText(getString(R.string.amount_of_production, mAmountOfProduction));
        }
    });
    return view;
}
</code></pre>

<p>Here is my MainActivity</p>

<pre><code>HospitalFragment firstHospitalFragment = new HospitalFragment();
    HospitalFragment secondHospitalFragment = new HospitalFragment();
    HospitalFragment thirdHospitalFragment = new HospitalFragment();
    HospitalFragment fourthHospitalFragment = new HospitalFragment();
    HospitalFragment fifthHospitalFragment = new HospitalFragment();
    HospitalFragment sixthHospitalFragment = new HospitalFragment();
    HospitalFragment seventhHospitalFragment = new HospitalFragment();
    HospitalFragment eighthHospitalFragment = new HospitalFragment();
    HospitalFragment ninthHospitalFragment = new HospitalFragment();
    HospitalFragment tenthHospitalFragment = new HospitalFragment();
     firstHospitalFragment.setmHospital(mListHospitals.get(0));
    secondHospitalFragment.setmHospital(mListHospitals.get(1));
    thirdHospitalFragment.setmHospital(mListHospitals.get(2));
    fourthHospitalFragment.setmHospital(mListHospitals.get(3));
    fifthHospitalFragment.setmHospital(mListHospitals.get(4));
    sixthHospitalFragment.setmHospital(mListHospitals.get(5));
    seventhHospitalFragment.setmHospital(mListHospitals.get(6));
    eighthHospitalFragment.setmHospital(mListHospitals.get(7));
    ninthHospitalFragment.setmHospital(mListHospitals.get(8));
    tenthHospitalFragment.setmHospital(mListHospitals.get(9));

    fragmentManager.beginTransaction()
            .replace(R.id.first_business, firstHospitalFragment)
            .replace(R.id.second_business, secondHospitalFragment)
            .replace(R.id.third_business, thirdHospitalFragment)
            .replace(R.id.fourth_business, fourthHospitalFragment)
            .replace(R.id.fifth_business, fifthHospitalFragment)
            .replace(R.id.sixth_business, sixthHospitalFragment)
            .replace(R.id.seventh_business, seventhHospitalFragment)
            .replace(R.id.eighth_business, eighthHospitalFragment)
            .replace(R.id.ninth_business, ninthHospitalFragment)
            .replace(R.id.tenth_business, tenthHospitalFragment)
            .commit();
</code></pre>
"
60878351,"<p>Having this long task that I will resume:</p>

<p>Perform a regression model over the normalized active cases in China using the model.....(long assignment that I'm not worried about and will save you time). <strong>Tip: To convert from datetime to a numeric variable for the regression, use <code>x=day(date-min(date(:)))+1;</code> being “date” the datetime vector return from getdata function.</strong></p>

<p>This is what I have:</p>

<pre><code>function RP_ejercicio1

    data = readtable('COVID-19.csv');
    [active_res, confirmed_res, death_res, recovered_res, date]  = getdata(data, 'China', 93/147);

    x=day(date-min(date(:)))+1;
    y = active_res;
    yp = log(y./x);
    a = [x ones(size(x))];
    sol = inv(a'*a)*(a'*yp);
    b = sol(1);
    c = sol(2);
    a = exp(c);

end
</code></pre>

<p>I get this error: <code>Check for missing argument or incorrect argument data type in call to function 'day'.</code> In this line: <code>x=day(date-min(date(:)))+1;</code>. The one that is supposed to help as a tip is giving me a headache. I can ensure that <code>date</code> is a 1x50 datetime array after executing the getdata function.</p>

<p>Am I doing something wrong? Is the tip wrong? And if it's the second case, is there other way to do the same?</p>

<p>I add an image for more clarity:</p>

<p><a href=""https://i.stack.imgur.com/6XbG1.png"" rel=""nofollow noreferrer"">Date array</a></p>
"
60689120,"<p>Considering I have a data frame ordered by date and for each one I have some quantities, how can I calculate <strong>X<sub>day</sub> / X<sub>day-1</sub></strong> index for each row?</p>

<p>My dataset: <a href=""https://raw.githubusercontent.com/imdevskp/covid_19_jhu_data_web_scrap_and_cleaning/master/covid_19_clean_complete.csv"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/imdevskp/covid_19_jhu_data_web_scrap_and_cleaning/master/covid_19_clean_complete.csv</a></p>

<p>My processe dataset (R code):</p>

<pre><code>library(tidyverse)
library(lubridate)

covid19 &lt;- read.table(file = ""covid_19_clean_complete.csv"",
                      header = TRUE,
                      stringsAsFactors = FALSE,
                      sep = "","",
                      dec = ""."",
                      quote = ""\"""")

covid19$Date &lt;- mdy(covid19$Date)

brasil &lt;- covid19 %&gt;%
    filter(Country.Region == ""Brazil"") %&gt;%
    group_by(Country.Region, Date) %&gt;%
    summarise(Cases = sum(Confirmed))
</code></pre>

<p>My rate will be calculated over <em>Cases</em> variable.</p>
"
60875716,"<p>I am working on a coronavirus project and the animation rot-corona is not working I want it to rotate 360 degrees after every  3 sec
and for a note bootstrap-4 is included in it </p>

<p><strong>Code</strong></p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>/* SCSS */

#rotate-corona-text {
  h1 {
    font-size: 3rem;
  }
  img {
    width: 100px;
    height: 100px;
  }
  #rotate-corona-text {
    img {
      animation: rot-corona 3s linear infinite;
    }
  }
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;section id=""main-header"" class=""py-4""&gt;
  &lt;div class=""container py-4""&gt;
    &lt;div class=""row border py-4 align-items-center justify-content-between""&gt;
      &lt;div class=""col-12 col-md-4  order-2 order-lg-1  "" id=""unity-images""&gt;
      &lt;/div&gt;
      &lt;div class=""col-12 col-md-7 order-1 order-lg-2"" id=""rotate-corona-text""&gt;
        &lt;h1 class=""text-primary""&gt;lets stay safe and fight against cor&lt;span id=""rotate-cororna""&gt;&lt;img src=""./assets/corona-icon.jpg""  alt=""""&gt;&lt;/span&gt;na &lt;/h1&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;</code></pre>
</div>
</div>
</p>

<p>and for the image which I want to rotate is <a href=""https://ibb.co/qFSqkyq"" rel=""nofollow noreferrer"">https://ibb.co/qFSqkyq</a> </p>
"
60981793,"<p>Here is the .sass file:</p>

<pre><code>/* Welcome to Compass.
 *
 * ie.sass
 *
 * Use this file to write IE specific override styles.
 *
 * Import this file using the following HTML or equivalent:
 * &lt;!--[if IE]&gt;
 *   &lt;link rel=""stylesheet"" type=""text/css""
 *         href=""/stylesheets/ie.css"" media=""screen, projection"" /&gt;
 * &lt;![endif]--&gt;
 */

html {
    font-size: 24px;
}
</code></pre>

<p>Here is the error generated by Koala:</p>

<pre><code>/*
Error: Invalid CSS after ""html "": expected selector, was ""{""
        on line 14 of /Users/johnlove/Sites/www.lovetoteach.dev/Web_Site_Storage/lovesongforever.com/coronavirus/Coronavirus_Support/sass_test/ie_test.sass

9:  *   &lt;link rel=""stylesheet"" type=""text/css""
10:  *         href=""/stylesheets/ie.css"" media=""screen, projection"" /&gt;
11:  * &lt;![endif]--&gt;
12:  *\/
13:  
14: html {
15: 
16: }
</code></pre>

<p>I've made certain all properties are indented once. I have also eliminated the <code>{}</code> and trailing semi-colons.</p>

<p>Same error!</p>

<p>Why?</p>
"
61063373,"<p>I have this text file stored on GitHub: </p>

<p><a href=""https://github.com/lopezbec/COVID19_Tweets_Dataset/blob/master/Coronavirus%20Tweets_ID/coronavirus_2020_01_22.txt"" rel=""nofollow noreferrer"">https://github.com/lopezbec/COVID19_Tweets_Dataset/blob/master/Coronavirus%20Tweets_ID/coronavirus_2020_01_22.txt</a></p>

<p>That contains a unique large line with values saved as a list (values separated as <code>[""123"", ""1234"", ...]</code>). </p>

<p>I would like to split the values and write each value on one line.</p>

<p>I tried to figure this out but my code seems not to be working.</p>

<pre><code>my_data &lt;- scan (file=input, what = character())
row &lt;- strsplit(my_data, "","")
</code></pre>
"
60858460,"<p>I have a dataset on Coivd-19 cases and deaths by day and country. I wish to find the date when the first death occured for every country, and the filter away all the preceding days. How would you tackle this problem in R/Tidyverse? </p>

<pre><code>library(readxl)
library(httr)
url &lt;- paste(""https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide-"",format(Sys.time(), ""%Y-%m-%d""), "".xlsx"", sep = """")
GET(url, authenticate("":"", "":"", type=""ntlm""), write_disk(tf &lt;- tempfile(fileext = "".xlsx"")))
df &lt;- read_excel(tf)
</code></pre>
"
61045605,"<p>I'm not really sure how to even title this but I'm having an issue getting a non-null value back... I'm hoping someone can help me out and tell me what I'm doing wrong...</p>

<p>The api I'm pulling from returns the following format...</p>

<pre><code>{
    ""countrytimelinedata"": [
        {
            ""info"": {
                ""ourid"": 167,
                ""title"": ""USA"",
                ""code"": ""US"",
                ""source"": ""https://thevirustracker.com/usa-coronavirus-information-us""
            }
        }
    ],
    ""timelineitems"": [
        {
            ""1/22/20"": {
                ""new_daily_cases"": 1,
                ""new_daily_deaths"": 0,
                ""total_cases"": 1,
                ""total_recoveries"": 0,
                ""total_deaths"": 0
            },
            ""1/23/20"": {
                ""new_daily_cases"": 0,
                ""new_daily_deaths"": 0,
                ""total_cases"": 1,
                ""total_recoveries"": 0,
                ""total_deaths"": 0
            }
         }
     ]
}
</code></pre>

<p>My issue is that I cannot pull anything within the timelineitems array with what I have in my schema</p>

<p>My schema is the following</p>

<pre><code>gql`
  extend type Query {
    getCountryData: getCountryData
  }
  type getCountryData {
    countrytimelinedata: [countrytimelinedata]
    timelineitems: [timelineitems]
  }
  type countrytimelinedata {
    info: Info
  }
  type Info {
    ourid: String!
    title: String!
    code: String!
    source: String!
  }
  type timelineitems {
    timelineitem: [timelineitem]
  }
  type timelineitem {
    new_daily_cases: Int!
    new_daily_deaths: Int!
    total_cases: Int!
    total_recoveries: Int!
    total_deaths: Int!
  }
`;
</code></pre>

<p>I hope this is the right place to ask this, and I'm sorry if I am not understanding something basic.</p>

<p>Is there something better I should be using?</p>

<p>Thank you in advance</p>
"
61306554,"<p>I developed a dashboard to monitor covid-19 cases in Brazil using shiny and flexdashboard. It's working fine, but not on mobile devices (at least in some of them). At the sidebar there is a <code>selectinput()</code> with <code>multiple=TRUE</code>, and the problem is that every time the mobile user tries to select a value to update the plots, the screen keyboard is shown and the whole app is realoaded before the selection (for the correct usage the user needs to select the states and click on ""Atualizar"" button to update).</p>

<p>I tried to solve it by duplicating the siderbar section, and use <code>{.no-mobile}</code> for the first one, and <code>{.mobile)</code> for the second, and using <code>multiple=FALSE</code> in this second selectinput(). Unfortunately it won't work, and both sections were shown overlapping.</p>

<p>I thought about another way (and i don't know how to do it), using something like <code>multiple=ifelse(""is mobile test"",FALSE,TRUE)</code>. </p>

<p>My questions are: Is there a way to test if the browser is mobile? Is there another approach do solve this problem?</p>

<p>Any help will be highly appreciated. </p>

<p>App link (code embed): <a href=""https://costafilho.shinyapps.io/monitor_covid19/"" rel=""nofollow noreferrer"">https://costafilho.shinyapps.io/monitor_covid19/</a></p>

<p>Github project: <a href=""https://github.com/sergiocostafh/monitor_covid19"" rel=""nofollow noreferrer"">https://github.com/sergiocostafh/monitor_covid19</a></p>

<p>Problematic line:</p>

<p><code>selectInput(""estado"",h3(""Estados""),choices = est_nome, selected = ""Sao Paulo"", multiple =  TRUE)</code></p>
"
61120731,"<p>My Shiny app has a universal sidebarPanel. I want to hide it for one particular tab, i.e. whenever the used would navigate to that tab the sidebarPanel would collapse. The code I am trying is as follows-</p>

<p>The UI-</p>

<pre><code>library(shiny)
shinyUI(fluidPage (
  theme = shinytheme(""superhero""),
  headerPanel(""COVID-19 Data Visualizer""),
  sidebarPanel(
    width = 2,
    selectInput(
      ""countries"",
      label = ""Select Countries"",
      choices =
        c(""B"", ""C"", ""A""),
      selected = c(""A""),
      multiple = T
    ),
    submitButton(text = ""View"")
  ),
  mainPanel (h1(""""),
             tabsetPanel(
               tabPanel(
                 ""Global Status"",
                 div(id=""Main""),
                 plotlyOutput(""figG""),
                 br(),
                 plotlyOutput(""global_time""),
                 br(),
                 plotlyOutput(""global_cfr""),
                 br(),
                 plotlyOutput(""global_p""),
                 br(),
                 plotlyOutput(""global_recov_dead"")
               ),
               tabPanel(
                 ""Comparative Charts"",
                 plotlyOutput(""fig_confirm""),
                 br(),
                 plotlyOutput(""fig_dead""),
                 br(),
                 plotlyOutput(""fig_recov"")
               ),
               tabPanel(
                 ""Ratio Analysis"",
                 plotlyOutput(""fig_confirm_S""),
                 br(),
                 plotlyOutput(""fig_confirm_D""),
                 br(),
                 plotlyOutput(""fig_Ratio""),
                 br(),
                 plotlyOutput(""fig_cfr_print"")
               )
             ))
))
</code></pre>

<p>The server part-</p>

<pre><code>server &lt;- function(input, output) {
  observeEvent(input$tabs == ""Global Status"", {
    shinyjs::hide(id = ""Main"")
  })

}
</code></pre>

<p>I don't really want to use the navbarPage and want single sidebarPanel for all the inputs.</p>

<p>A screenshot of the output I am getting-
<a href=""https://i.stack.imgur.com/ji7RK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ji7RK.png"" alt=""enter image description here""></a></p>

<p>Thanks in advance. </p>
"
60685854,"<p>I'm making a Chrome Extension providing Coronavirus updates but when I try to run it, I get this error:</p>

<blockquote>
  <p>Refused to load the script 'chrome-extension://cdn.iframe.ly/embed.js' because it violates the following Content Security Policy directive: ""script-src 'self' blob: filesystem:"". Note that 'script-src-elem' was not explicitly set, so 'script-src' is used as a fallback.</p>
</blockquote>

<p>This is the code in my manifest.json file:</p>

<pre><code>{
  ""name"": ""Coronavirus Updates Extension"",
  ""version"": ""1.0"",
  ""description"": ""The Coronavirus Updates Extension will provide updates on the coronavirus so that every time you open a new tab, you can hear the latest updates on the coronavirus crisis."",
  ""manifest_version"": 2,
  ""permissions"": [
    ""tabs"",
    ""http://www.vox.com/*"",
    ""http://www.cnn.com/*"",
    ""http://*.iframe.ly/"",
    ""http://www.nbcnews.com/*"",
    ""unlimitedStorage""
],

    ""chrome_url_overrides"" : {
      ""newtab"": ""popup.html""
    }
}
</code></pre>

<p>And this is the code in my popup.html file:</p>

<pre><code>&lt;html lang=""en""&gt;
    &lt;head&gt;
        &lt;link rel=""stylesheet""
            href=""https://fonts.googleapis.com/css?family=Roboto+Condensed""&gt;
        &lt;title=""Coronavirus Live Updates""&gt;
        &lt;meta charset=""UTF-8""&gt;
        &lt;meta name=""author"" content=""Enzo Gilchrist""&gt;
        &lt;style&gt;
            body {
                font-family: 'Roboto Condensed', serif;
                font-size: 48px,
            }
        &lt;/style&gt;
    &lt;/head&gt;
    &lt;body&gt;
        &lt;center&gt;
            &lt;h1&gt;Coronavirus LIVE Updates&lt;/h1&gt;
            &lt;h3&gt;Live updates on the coronavirus crisis, powered by your favorite news sources!&lt;/h3&gt;
        &lt;/center&gt;
        &lt;center&gt;

            &lt;div class=""iframely-embed""&gt;&lt;div class=""iframely-responsive"" style=""padding-bottom: 52.5%; padding-top: 120px;""&gt;&lt;a href=""https://www.cnn.com/world/live-news/coronavirus-outbreak-03-14-20-intl-hnk/index.html"" data-iframely-url=""//cdn.iframe.ly/v9YceJJ""&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;script async src=""//cdn.iframe.ly/embed.js"" charset=""utf-8""&gt;&lt;/script&gt;&lt;br&gt;

            &lt;div class=""iframely-embed""&gt;&lt;div class=""iframely-responsive"" style=""padding-bottom: 52.5%; padding-top: 120px;""&gt;&lt;a href=""https://www.nbcnews.com/health/health-news/live-blog/coronavirus-updates-live-house-approves-coronavirus-aid-bill-n1158821"" data-iframely-url=""//cdn.iframe.ly/5trJ3RR""&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;script async src=""//cdn.iframe.ly/embed.js"" charset=""utf-8""&gt;&lt;/script&gt;&lt;br&gt;

            &lt;div class=""iframely-embed""&gt;&lt;div class=""iframely-responsive"" style=""padding-bottom: 52.5%; padding-top: 120px;""&gt;&lt;a href=""https://www.vox.com/science-and-health/2020/1/23/21079069/coronavirus-update-usa-cases-news"" data-iframely-url=""//cdn.iframe.ly/Ds5QI8b""&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;script async src=""//cdn.iframe.ly/embed.js"" charset=""utf-8""&gt;&lt;/script&gt;



    &lt;/body&gt;
&lt;html&gt;
</code></pre>

<p>What should I do?</p>
"
61076548,"<p>Financial Times have a nice faceted coronavirus chart: see Daily death tolls at <a href=""https://www.ft.com/coronavirus-latest"" rel=""nofollow noreferrer"">https://www.ft.com/coronavirus-latest</a> Do you have an idea how make it using R and ggplot2?</p>

<p><a href=""https://i.stack.imgur.com/FPOMi.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FPOMi.jpg"" alt=""Financial Times chart""></a></p>

<p>Facet_wrap function is not useful in this case, it separates every country line to single minigraphs. The other countries are not visible in gray.</p>

<p>Should I prepare 20+ charts and join them using gridExtra::grid.arrange()?</p>
"
60685525,"<p>I am trying to get a plot of the number of Cov-19 in Italy over time, and came across this <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">repository in GitHub</a>, and tried to subset the data for Italy as such:</p>

<pre><code>require(RCurl)
require(foreign)
x = getURL(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"")
corona = read.csv(text = x, sep ="","",header = T)
str(corona)
Italy &lt;- corona[,corona$Country.Region=='Italy']
Italy &lt;- corona[corona$Country.Region=='Italy',][1,5:ncol(corona)]
head(Italy)[,45:52]
</code></pre>

<p>which outputs:</p>

<pre><code>&gt; head(Italy)[,45:52]
   X3.6.20 X3.7.20 X3.8.20 X3.9.20 X3.10.20 X3.11.20 X3.12.20
17    4636    5883    7375    9172    10149    12462    12462
   X3.13.20
17    17660
</code></pre>

<p>Converting this to a time series with <code>xts</code> led me to several posts asking how to convert a database to a time series, where every day is a row in the variable Date, but in this dataframe it seems as though the each date is a variable.</p>

<p>I don't necessarily need to get this formatted as a time series, but I would like to plot over time the number of cases.</p>

<hr>

<p>Here is a way to bypass timeseries:</p>

<pre><code>require(RCurl)
require(foreign)
x = getURL(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"")
corona = read.csv(text = x, sep ="","",header = T)
str(corona)
Italy &lt;- corona[,corona$Country.Region=='Italy']
Italy &lt;- corona[corona$Country.Region=='Italy',][1,5:ncol(corona)]
Italy &lt;- as.matrix(sapply(Italy, as.numeric))
plot(Italy[,1],typ='l',xlab='', ylab='', col='red', lwd=3,
     main=""Italy Cov-19 cum cases"")
</code></pre>
"
60916444,"<p>Johns Hopkins Universty COVID-19 dataset changed its data repository structure from a single time series file to a system where each day generates a separate csv file with state numbers partitioned down by counties, plus an ""unassigned"" entry for each county, which I am not sure what it means. These files can be found <a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports"" rel=""nofollow noreferrer"">here</a>.</p>

<p><a href=""https://i.stack.imgur.com/xMbKI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xMbKI.png"" alt=""enter image description here""></a></p>

<p>I want to generate a time series plot of the number of cases and deaths in the states of Washington v New York, which would entail adding all counties in each file separately and then plotting these sums as a unified time series.</p>

<p>I know that this can be done in R, but I am not sure how, and I immediately run across the hurdle of having to reference a lot of different files is I am to follow the steps mentioned in <a href=""https://stackoverflow.com/a/31438245/4089351"">this post</a>, for example. Further, it would be necessary to revise the code every day to add the latest file to compile.</p>

<p>Is there a way of streamlining this process? Sorry I am not showing my attempt, but I don't even know how to start without importing all ~50 files individually.</p>
"
61203143,"<p>I have created a parallax scrolling affect on my website, and that all works fine, but the header, even though it is in the same div as that of the parallax scrolling., doesn't stay in the same place, but moves up with the main text. I have tried a lot of thing but none of them seem to work. I have included the HTML and CSS that is relevant. Thanks</p>

<p>Relevant HTML:</p>

<pre><code>&lt;div class=""parallax-effect""&gt;
    &lt;h1 class=""para""&gt;&lt;strong&gt;We Will Beat Coronavirus&lt;/strong&gt;&lt;/h1&gt;
&lt;/div&gt;
</code></pre>

<p>Relevant CSS:</p>

<pre><code>.parallax-effect {
    background-image: url(""https://eyeq.photos/wp-content/uploads/2018/07/pexels-photo-371633.jpg"");
    min-height: 600px; 
    background-attachment: fixed;
    background-position: center;
    background-repeat: no-repeat;
    background-size: cover;
}

.para {
    size: 100%
    margin: 0;
    position: absolute;
    top: 45%;
    left: 50%;
    -ms-transform: translate(-50%, -50%);
    transform: translate(-50%, -50%);
    color: white;
    text-align: center;
}
</code></pre>

<p>If you need any extra CSS that I missed out then just say. Could this please be a CSS fix, not anything to do with JS. Thanks.</p>
"
61071284,"<p>I have an anchor tag inside of a paragraph tag that has 3 words in it, when it is displayed on my browser (Google Chrome) the size of the paragraph text and anchor text are the same, however when I view it on my iPhone in Safari the anchor tag text gets much smaller than the rest of the paragraph...</p>

<p>How can i fix this and make the anchor tag text the same size as the rest of the paragraph when viewed in mobile?</p>

<p>I have tried setting the anchor font size to 100% but it does not seem to work..</p>

<p>My code for it is the following:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;div class=""middlecontainer""&gt;
  &lt;h2&gt;A Little Background About Myself.&lt;/h2&gt;
  
  &lt;div class=""backgroundparagraph""&gt;
    &lt;p&gt;I was born on September 7, 2000, in Guadalajara, Mexico, where I lived for about 13 years of my life. When I finished 6th grade, my family and I moved to Texas, where I graduated from &lt;a class=""intext-link"" href=""http://schools.friscoisd.org/campus/high-school/centennial/home""&gt;Centennial High School&lt;/a&gt;      in the summer of 2019. After graduation, I went to Munich for a semester to study German in order to open the possibilty of studying business management and engineering in Germany. Then when the coronavirus pandemic hit in 2020 and we were prompted
      to stay quarantined and practice social distancing, I decided to learn code. This website is my first project towards mastering my programming skills, because developing an app has always been a dream of mine.&lt;/p&gt;

    &lt;img class=""graduationpic"" src=""images/graduation.jpg"" alt=""graduation-img""&gt;
  &lt;/div&gt;

  &lt;hr&gt;
&lt;/div&gt;</code></pre>
</div>
</div>
</p>
"
60536428,"<p>I am working with the Johns Hopkins coronavirus R package, but I haven't yet figured out how to get it to provide me with the underlying updated data each day. I have restarted R and reloaded the package, but it seems as though the data is static from when I installed the package. It does not provide updated data each time I run it unless I reinstall the package. The data behind this package gets updated nightly on the repository. I'm trying to figure out a good way to have mine updated daily as well. </p>

<p>Thanks in advance for any help you can provide!</p>

<pre><code>
library(coronavirus) 
library(dplyr)

data(""coronavirus"")

summary_df &lt;- coronavirus %&gt;% group_by(Country.Region, type) %&gt;%
  summarise(total_cases = sum(cases)) %&gt;%
  arrange(-total_cases)
df &lt;- coronavirus %&gt;%
  group_by(Province.State,Country.Region,Lat,Long,type) %&gt;%
  mutate(TotalCasesRegion = cumsum(cases))```
</code></pre>
"
73828,"<p>I'd like to test my DBSCAN clustering algorithm on Covid-19 Data. I've thought about looking for clusters of countries using latitude, longitude, and # of cases, but this is a bit tricky.</p>

<p>Is there something simple but interesting to look at in terms of clustering with Covid Data?</p>
"
61624271,"<p>I would like to know, is there currently any consideration in regards to adding a real-time ""voice memo"" and ""attachment"" feature to the private comment section of student answers (Ex. Facebook Messenger, LinkedIn Messenger, Instagram Direct Messenger)?</p>

<p>The reason why I am asking is because as an educator, I often find myself wanting to explain a concept or question verbally and I believe that my students have the same desire. </p>

<p>In addition, having a real-time voice memo feature will also provide a greater learning experience for students who may have difficulty reading.</p>

<p>I hope that this suggestion inspires the implementation of a real-time voice memo and file attachment feature as educators interact with their students in new ways during COVID-19.</p>
"
61585457,"<p>I have crated a repo in github named <a href=""https://github.com/abd-shoumik/Covid-19-Predictor-BD"" rel=""nofollow noreferrer"">Covid-19-Predictor-BD</a>. I have also linked it up to <strong>Github Pages</strong> which you can see at
<a href=""https://abd-shoumik.github.io/Covid-19-Predictor-BD/"" rel=""nofollow noreferrer"">https://abd-shoumik.github.io/Covid-19-Predictor-BD/</a> 
But when I search 'Covid-19-Predictor-BD' or some related keyword in google , my repo doesn't appear in the search. What I can do to make the repo appear in google search??</p>
"
61181229,"<p>I am contributing to an open source project that aims to aggregate COVID-19 data across multiple local governments (Bay Area, CA, USA). One jurisdiction has their data updating on a qlik dashboard: 
<a href=""https://dashboard.cchealth.org/sense/app/93b7808b-5a6d-4e9a-9161-ed2eafeb4afc/overview"" rel=""nofollow noreferrer"">https://dashboard.cchealth.org/sense/app/93b7808b-5a6d-4e9a-9161-ed2eafeb4afc/overview</a></p>

<p>I'm just a curious citizen without a qlik account. Are there any open-source libraries that would be able to fetch the underlying data, ideally for a daily update?</p>
"
60710377,"<p>My colleagues and I have planned to make another update of our application during 13th week of 2020. According to COVID-19 danger, today every developer has seen <a href=""https://i.stack.imgur.com/qGsst.png"" rel=""nofollow noreferrer"">this message</a> and it directly relates to <a href=""https://www.latimes.com/business/technology/story/2020-03-10/google-employees-north-america-work-from-home"" rel=""nofollow noreferrer"">this news</a>. Okay, there's no point in denying the obvious — the situation is really serious. But also we have roadmaps and commitments. </p>

<p>So we need to find out any Plan B in order to release the update. <strong>Timed Publishing</strong> functional suits better than any kangaroo court trying to guess the date of review and correct UA campaigns. </p>

<p>But there is a nuance — our application was released via <strong>Open Beta Track</strong>. </p>

<p>I've already researched <a href=""https://support.google.com/googleplay/android-developer/answer/9543912?hl=en"" rel=""nofollow noreferrer"">the official guide</a> and there's no word about timed publishing of OBT versions. </p>

<p>Please, help: </p>

<ol>
<li>Everytime I firstly release the version via Internal Test Track and, when QA and leads have given me a green light, I transfer the version from Internal Track to Open Beta track. </li>
<li>Do I have to to enable Timed Publishing, than re-upload the approved version to Open Beta Track directly and than tap ""Go Live"" when the processing is finished? </li>
<li>How can I transfer the version from Internal test track to Open Beta Track with enabled Timed Publishing? </li>
</ol>

<p>Thanks a lot. </p>
"
61400937,"<p>I am thinking about a project to make a device to restrict COVID-19. I want information that Can I measure the distance between two Bluetooth sensors, Connected with raspberry pi? </p>

<p>or can I measure by another sensor?</p>

<p>I also want to know if I can measure the distance than can I know any address of other devices.</p>

<p>If yes then plz give me this information.</p>
"
73228,"<p>I have daily data of my sales and a daily update of how the COVID-19 cases increase. My daily sales contains information on my customer and on my product. My end goal would be to see if certain products are correlated (sold more or less) after covid than before. Or if certain regions had more sales before or after COVID.</p>

<p>My initial thought would be to do some kind of event analysis and compare if I have more sales before and after that certain event. Does anyone has some experience with this or can link some papers/references on this topic?</p>
"
61334020,"<p>I'd like to make a capsule that provides COVID-19 information to Bixby users. Can I do that? If so, what steps should I take?</p>
"
60686379,"<p>if you embed a google doc inside a website  - including google sites - some external webpage links including in the document  refuse to connect eg <a href=""https://www.gov.uk/guidance/coronavirus-covid-19-information-for-the-public"" rel=""nofollow noreferrer"">https://www.gov.uk/guidance/coronavirus-covid-19-information-for-the-public</a> particularly on mobiles . nb these are public webpages. </p>

<p>Can anyone explain a reason ?.  I dont think its https , because  another webpage on same site  , such as <a href=""https://www.gov.uk/health-and-social-care/health-protection"" rel=""nofollow noreferrer"">https://www.gov.uk/health-and-social-care/health-protection</a>  works fine . </p>

<p>I have tried publishing the document to the web and use iframes or just insert the  document directly into Google sites. </p>

<p>Please note,  i get the same problem in wordpress if i open the embedded document on a mobile phone. </p>

<p>nb . It looks like an embedded google docs  tries to view links within its own viewer, rather than the devices default browser</p>

<p>I have seen the post :</p>

<p><a href=""https://stackoverflow.com/questions/4377324/force-iframe-links-in-embedded-google-doc-to-open-in-new-window"">Force iFrame links (in embedded Google Doc) to open in new window</a></p>

<p>but wondered if there was an inline solution that anyone knows of </p>

<p>Many thanks </p>
"
71382,"<p>I have been looking for a dataset that includes: </p>

<ul>
<li>Age </li>
<li>Hospitalized</li>
<li>ICU</li>
<li>Disposition (Recovered,Death) </li>
</ul>

<p>Has anyone located one ? 
Preferably from a western country as China's data is suspect.
I find it hard to believe CDC is not gathering this data.</p>
"
61241186,"<p>I would like to know if there is any API outhere with specific information about confirming cases that you could filter by zipcode or addresses? </p>
"
61497891,"<p>I wanted to use gnuplot to plot wind direction and in one region, but there were two keys appearing on the map, I didn't know how to work it out. The number of Data is too big, I can't stick them, I feel sorry about that. [1:97][1:88] is the domain of that region.</p>

<pre><code>set terminal postscript portrait color enhanced 12
set output ""wind.ps""
set pm3d corners2color c1 map
set palette defined (0 0 0 1, 0.5 1 1 1, 1 1 0 0)
set multiplot
unset xtics
unset ytics
set lmargin 0
set rmargin 0
set tmargin 0.5
set bmargin 0
set size 1,0.5
set size ratio 0.80745
set origin 0,0.2
set key at 92,13 title ""Difference""
set title ""(a) Test Wind Field""
splot ""wind.txt"" u ($1):($2):(1):($3):($4):(1) w vec lt 1 notitle
splot [1:97][1:88] ""counrty.txt"" u ((($1)-282)/12)+1:((($2)+906)/12)+1:1 notitle  w l lt -1 lw 0.5
unset label
</code></pre>

<p><a href=""https://i.stack.imgur.com/X4k4v.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/X4k4v.png"" alt=""enter image description here""></a></p>

<p>If I add [1:97][1:88] to the command line of wind, the ghosting key disappeared while unwanted lines appeared. </p>

<pre><code>splot [1:97][1:88] ""wind.txt"" u ($1):($2):(1):($3):($4):(1) w vec lt 1 notitle
</code></pre>

<p>wind direction after add [1:97][1:88]</p>

<p><a href=""https://i.stack.imgur.com/HGrQm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HGrQm.png"" alt=""enter image description here""></a></p>

<p>If I use the command 'plot' to plot the wind direction, then it will be like that.</p>

<pre><code>plot  ""yrd.wind.covid19.txt"" u ($1):($2):($3):($4) w vec lt 1 notitle
</code></pre>

<p><a href=""https://i.stack.imgur.com/20eFX.png"" rel=""nofollow noreferrer"">the third situation</a></p>

<p>If removed the [1:97][1:88], it will be the map displayed below.</p>

<pre><code>splot ""counrty.txt"" u ((($1)-282)/12)+1:((($2)+906)/12)+1:1 notitle  w l lt -1 lw 0.5,\
      ""yrd.wind.covid19.txt"" u ($1):($2):(1):($3):($4):(1) w vec lt 1 notitle
</code></pre>

<p><a href=""https://i.stack.imgur.com/li1z0.png"" rel=""nofollow noreferrer"">the forth situation</a></p>

<p>This is the data file of wind direction.   </p>

<pre><code>   1           1   1.108715      -1.988065    
   1           7 -0.2828265      -2.514480    
   1          13 -0.5162781      -2.534442    
   1          19 -0.8041242      -2.118783    
   1          25  -1.005743      -2.119185    
   1          31  -1.385974      -2.011106    
   1          37  -1.303812      -1.727541    
   1          43  -1.198456      -2.012927    
   1          49 -0.8044212      -1.074293    
   1          55  -1.169173     -0.9435396    
   1          61 -0.4521698     -0.8306611    
   1          67 -0.3398472     -0.9110256    
   1          73  0.5497940     -0.4957737    
   1          79 -0.4249686     -0.6902521    
   1          85 -0.4333920     -0.2701551    
   7           1 -0.1291364       1.197334    
   7           7  -1.620592      -1.361079    
   7          13  -1.087388      -1.573736    
   7          19  -1.024136      -1.235521    
   7          25  -1.517918      -1.773767    
   7          31 -0.9683833      -1.493137    
   7          37  -1.105461      -1.764376    
   7          43  -1.145569      -1.821003    
   7          49  -1.238689      -1.697086    
   7          55 -0.5481215      -1.310746    
   7          61 -0.3959183     -0.8476363    
   7          67 -0.5949239     -0.5122660    
   7          73 -0.4818483     -0.4196534    
   7          79 -0.7659698     -0.6680192    
   7          85  0.1679092     -0.5400997    
  13           1  0.1285889      -1.156056    
  13           7  -1.094984      -1.434627    
  13          13 -0.7929572      -1.323432    
  13          19  -1.180756      -1.600855    
  13          25 -0.8877360      -1.613529    
  13          31 -0.9996457      -1.527605    
  13          37 -0.8238124      -1.481949    
  13          43 -0.7603424      -1.890813    
  13          49  -1.025161     -0.9066794    
  13          55  -1.015571      -1.118257    
  13          61 -0.9035642     -0.7665278    
  13          67 -0.8321055     -0.4831027    
  13          73 -0.5451021     -0.3968017    
  13          79 -0.3045120     -0.3047466    
  13          85 -0.2497719     -0.2208077    
  19           1 -0.4189178      -1.090045    
  19           7 -0.8407141      -1.320205    
  19          13 -0.7748231      -1.871686    
  19          19  -1.469146      -2.367272    
  19          25 -0.4649383      -2.798267    
  19          31 -0.8860437      -1.073503    
  19          37 -0.9572746     -0.9297332    
  19          43  -1.515875      -1.190284    
  19          49  -1.218172     -0.7791679    
  19          55  -1.102582     -0.8772109    
  19          61  -1.027370     -0.8195735    
  19          67 -0.8127689     -0.5485391    
  19          73 -0.6441864     -0.4022478    
  19          79 -0.4570150     -0.2033543    
  19          85 -0.3651582     -0.1294938    
  25           1 -0.6054268      -1.217132    
  25           7 -0.7407182      -1.054351    
  25          13 -0.3321512      -1.567139    
  25          19 -0.7483002      -2.253104    
  25          25 -0.5543621      -2.247710    
  25          31 -3.9390892E-02  -2.343734    
  25          37  -1.865113      -2.181415    
  25          43 -0.6020843      -2.038653    
  25          49 -0.7623259     -0.8114057    
  25          55  -1.108817     -0.9892372    
  25          61  -1.052694     -0.8037179    
  25          67 -0.8688669     -0.5916344    
  25          73 -0.7590979     -0.4595649    
  25          79 -0.6104036     -0.1946686    
  25          85 -0.6588074     -9.9366516E-02
  31           1 -0.8138685     -0.3746961    
  31           7 -8.4147170E-02 -0.4973753    
  31          13 -0.4337556      -1.334884    
  31          19 -0.5457593      -1.698407    
  31          25 -0.6577969      -1.845301    
  31          31  -1.668889      -1.828117    
  31          37  -1.203819      -2.057196    
  31          43 -0.8879474      -2.134445    
  31          49 -0.8857535      -1.102471    
  31          55  -1.218498     -0.9184581    
  31          61  -1.039025     -0.9237540    
  31          67 -0.9691579     -0.6676291    
  31          73 -0.8615177     -0.5763185    
  31          79  -1.137353     -0.4897482    
  31          85 -0.5943280      6.2492140E-02
  37           1 -0.2393228      -2.732805    
  37           7  1.4593905E-03 -0.2020176    
  37          13 -0.6303372     -0.6133371    
  37          19 -0.1975699      -1.174240    
  37          25  -1.635683     -0.3627254    
  37          31  -1.515109      -1.981583    
  37          37 -0.9375111     -0.9931212    
  37          43  -1.363843      -1.549649    
  37          49  -1.103831      -1.363177    
  37          55  -1.198775      -1.181059    
  37          61  -1.067938      -1.018348    
  37          67  -1.019575     -0.9246353    
  37          73 -0.8779502     -0.7895511    
  37          79 -0.6863562     -0.5990396    
  37          85 -0.2886097      -1.089483    
  43           1 -0.5776793      -1.863631    
  43           7 -0.8106826      0.1502321    
  43          13 -0.2556422      -1.022820    
  43          19  0.4982220     -0.6224557    
  43          25  -1.896362      -2.046345    
  43          31  -1.211233      -1.518835    
  43          37  -1.179512      -1.064433    
  43          43 -0.7514921     -0.7757724    
  43          49  -1.386158      -1.085640    
  43          55  -1.237744     -0.7980262    
  43          61  -1.026357      -1.128340    
  43          67 -0.8532083      -1.149826    
  43          73 -0.7615938      -1.093191    
  43          79  -1.032157      -1.251013    
  43          85  0.1180898      -1.280765    
  49           1  -1.416179      -1.748146    
  49           7  -1.354303     -0.5188729    
  49          13 -0.1323060      0.1955658    
  49          19 -0.7697926     -0.4313597    
  49          25  -1.090581     -0.9820307    
  49          31  -1.288527      -1.482457    
  49          37 -0.6602023      -1.378953    
  49          43 -0.4385801      -1.378801    
  49          49 -0.9442692      -1.078182    
  49          55  -1.032356      -1.220377    
  49          61 -0.8567170      -1.207471    
  49          67 -0.7183477      -1.265018    
  49          73 -0.7031319      -1.422170    
  49          79 -0.7852651      -1.986811    
  49          85 -0.1566966      -1.852246    
  55           1  -3.425642      -6.448854    
  55           7  -1.469432      -2.156902    
  55          13  -1.287400      -1.237925    
  55          19 -0.4426567     -0.1621204    
  55          25 -0.5064512     -0.5391338    
  55          31 -0.8294089      -1.852616    
  55          37 -0.3235397      -1.513118    
  55          43 -0.6228370      -1.469255    
  55          49 -0.3641820      -1.158833    
  55          55 -0.7003435      -1.330863    
  55          61 -0.7077910      -1.501531    
  55          67 -0.8625396      -1.746131    
  55          73 -0.5731955      -2.341928    
  55          79 -0.2062361      -2.510644    
  55          85  0.1337020      -2.625733    
  61           1  -3.594511      -7.119893    
  61           7  -2.916506      -6.654611    
  61          13  -1.526737      -5.768787    
  61          19 -0.8728814      -1.713666    
  61          25 -0.2510585      -1.518069    
  61          31 -0.3304124      -1.740066    
  61          37 -0.6777682     -0.9511366    
  61          43 -0.9548255      -1.906161    
  61          49 -0.2237290      -1.057160    
  61          55 -0.5366179      -1.610021    
  61          61 -0.3388043      -2.533017    
  61          67 -5.2883465E-02  -2.602082    
  61          73  8.4104441E-02  -2.728072    
  61          79  0.3083426      -3.101685    
  61          85  0.6281470      -3.323454    
  67           1  -3.591135      -6.110843    
  67           7  -2.808191      -6.083955    
  67          13  -2.218929      -5.853451    
  67          19  -1.551557      -5.526210    
  67          25 -0.8014249      -4.485489    
  67          31 -0.2734919      -2.635132    
  67          37  6.3866340E-02  -1.407375    
  67          43 -0.5734074      -3.024708    
  67          49 -0.2926151      -3.075855    
  67          55  8.9385703E-02  -2.991796    
  67          61  0.3396000      -2.895279    
  67          67  0.4880296      -2.971023    
  67          73  0.5908360      -3.184648    
  67          79  0.7696878      -3.535027    
  67          85   1.180078      -3.724377    
  73           1  -3.195315      -4.600032    
  73           7  -2.661445      -5.165293    
  73          13  -2.144600      -5.453991    
  73          19  -1.574927      -5.353052    
  73          25 -0.9251302      -5.067198    
  73          31 -0.4386413      -4.627797    
  73          37 -0.1486760      -4.121565    
  73          43 -8.9298077E-02  -3.799821    
  73          49  0.1656444      -3.675627    
  73          55  0.4952539      -3.458287    
  73          61  0.7696480      -3.331255    
  73          67  0.9322686      -3.305074    
  73          73  0.9246070      -3.680920    
  73          79   1.177059      -3.925296    
  73          85   1.434534      -4.003213    
  79           1  -2.478489      -3.738322    
  79           7  -2.199367      -4.388821    
  79          13  -1.998997      -4.846165    
  79          19  -1.682757      -5.056147    
  79          25  -1.212069      -4.917627    
  79          31 -0.7750097      -4.671583    
  79          37 -0.4503339      -4.445899    
  79          43 -6.7934789E-02  -4.259037    
  79          49  0.3466863      -4.121108    
  79          55  0.7716087      -3.834810    
  79          61   1.160804      -3.709754    
  79          67   1.286913      -3.756347    
  79          73   1.337452      -4.116672    
  79          79   1.485781      -4.284969    
  79          85   1.637745      -4.279395    
  85           1  -2.286411      -3.578472    
  85           7  -1.926950      -4.014696    
  85          13  -1.693225      -4.556112    
  85          19  -1.435391      -4.864839    
  85          25  -1.129859      -4.952620    
  85          31 -0.7496938      -4.783909    
  85          37 -0.3693850      -4.655892    
  85          43  4.0247269E-02  -4.621067    
  85          49  0.6217631      -4.493557    
  85          55   1.285700      -4.096997    
  85          61   1.558276      -3.922729    
  85          67   1.736984      -4.029644    
  85          73   1.762489      -4.368790    
  85          79   1.741113      -4.516823    
  85          85   1.786210      -4.364361    
  91           1  -1.992153      -3.462013    
  91           7  -1.543924      -3.709724    
  91          13  -1.160260      -4.089428    
  91          19 -0.8943509      -4.533711    
  91          25 -0.7803432      -4.849048    
  91          31 -0.4351161      -4.924956    
  91          37 -7.1642451E-02  -4.876300    
  91          43  0.5249092      -4.859890    
  91          49   1.223204      -4.581639    
  91          55   1.716675      -4.218869    
  91          61   1.937666      -4.022886    
  91          67   1.963387      -4.261041    
  91          73   2.042464      -4.537063    
  91          79   2.071948      -4.722070    
  91          85   2.073677      -4.249052    
  97           1  -1.938535      -3.435567    
  97           7  -1.470977      -3.447064    
  97          13 -0.8900484      -3.581853    
  97          19 -0.4317943      -4.024282    
  97          25 -0.2391478      -4.587556    
  97          31 -4.8176501E-02  -4.875938    
  97          37  0.3352192      -4.947895    
  97          43  0.9634075      -4.756529    
  97          49   1.574929      -4.427122    
  97          55   1.967954      -4.123986    
  97          61   2.099698      -4.017962    
  97          67   2.158964      -4.377975    
  97          73   1.652494      -2.916106    
  97          79   2.083248      -4.143603    
  97          85   1.686909      -2.099738    
</code></pre>
"
60314125,"<p>I have solr field </p>

<pre><code>&lt;field name=""AllTitles"" type=""text_general"" indexed=""true"" stored=""false"" multiValued=""true""/&gt;

&lt;fieldType name=""text_general"" class=""solr.TextField"" positionIncrementGap=""100""&gt;
  &lt;analyzer type=""index""&gt;
    &lt;charFilter class=""solr.MappingCharFilterFactory"" mapping=""mapping-ISOLatin1Accent.txt""/&gt;
    &lt;tokenizer class=""solr.StandardTokenizerFactory""/&gt;
    &lt;filter class=""solr.StopFilterFactory"" ignoreCase=""true"" words=""stopwords.txt"" /&gt;
    &lt;!-- in this example, we will only use synonyms at query time --&gt;
    &lt;filter class=""solr.SynonymFilterFactory"" synonyms=""synonyms.txt"" ignoreCase=""true"" expand=""false""/&gt;
    &lt;filter class=""solr.LowerCaseFilterFactory""/&gt;
  &lt;/analyzer&gt;
  &lt;analyzer type=""query""&gt;
    &lt;tokenizer class=""solr.StandardTokenizerFactory""/&gt;
    &lt;filter class=""solr.StopFilterFactory"" ignoreCase=""true"" words=""stopwords.txt"" /&gt;
    &lt;filter class=""solr.SynonymFilterFactory"" synonyms=""synonyms.txt"" ignoreCase=""true"" expand=""true""/&gt;
    &lt;filter class=""solr.LowerCaseFilterFactory""/&gt;
  &lt;/analyzer&gt;
&lt;/fieldType&gt;
</code></pre>

<p>Example of Value for AllTitles entered is </p>

<pre><code>AllTitles: [ ""Anything"", ""wuhan coronavirus"", ""anything"" ]
AllTitles: [ ""wuhan coronavirus"", ""anything"", ""anything"" ]
</code></pre>

<p>It searches from first index but if any matching term on index other than 1st then it's not searching</p>

<p>For example when I search </p>

<pre><code>q=""wuhan coronavirus""
</code></pre>

<p>I get 2 results. When I search using field name ""AllTitles""</p>

<pre><code>q=AllTitles:""wuhan coronavirus""
</code></pre>

<p>I get 7 results correctly.</p>

<p>Can anybody help me identifying the issue?</p>
"
61296710,"<p>Please! </p>

<p>I'm getting tweets from LinqToTwitter, and some tweets seem to have the text truncated, with part of the text following with an ellipsis. In some cases, the search criteria are not returned in the text, as it appears to be in the unearned part of the message. That's right? Is there a way to get this missing part of the message? I have already looked at other posts, but I could not understand which parameter allows the full text to be obtained. I'm using linqToTwitter version 4.1.0.</p>

<p>Thank you</p>

<pre class=""lang-vb prettyprint-override""><code> Dim twitterCtx As TwitterContext = New TwitterContext(twAuth)

 Dim Response As Search = Await (From search In twitterCtx.Search()
                                    Where search.Type = SearchType.Search _
                                    AndAlso search.SearchLanguage = ""pt"" _
                                    AndAlso search.Query = ""Coronavirus"").SingleOrDefaultAsync()

 Dim tweets As List(Of Status) = Response.Statuses()

 If Response IsNot Nothing AndAlso Response.Statuses IsNot Nothing Then
    For Each str As Status In tweets
        Console.WriteLine(str.StatusID.ToString() + "" "" + str.Text)
    Next
 End If
</code></pre>
"
60928342,"<p>World bank stood up a visualization tool at the link below. At the bottom of the page they have the relevant indicators and those data can be downloaded. When viewing the .csv or other styles, I see the complete data. But, when grabbing the JSON objects from the API I see only the ""Arab World"" and no other countries or data.</p>

<p>Anyone else able to grab the complete JSON data, perhaps I am making a mistake?</p>

<p><a href=""http://datatopics.worldbank.org/universal-health-coverage/covid19/?fbclid=IwAR3nkRHks2DcduwimcrSz5kVagvAJHGbK4QkxnKJyOSUb2Hqdo4-XIOuRJU"" rel=""nofollow noreferrer"">http://datatopics.worldbank.org/universal-health-coverage/covid19/?fbclid=IwAR3nkRHks2DcduwimcrSz5kVagvAJHGbK4QkxnKJyOSUb2Hqdo4-XIOuRJU</a></p>
"
60868504,"<p>.htaccess redirect entire directory to subfolder <em>(folders, subfolders and files to different subfolder)</em></p>

<p>Trying to redirect <code>quarantine.country/coronavirus/svg</code> to <code>https://quarantine.country/coronavirus/images/svg</code> and while it works fine with the mentioned url (with or without the trailing slash /) it won't redirect <a href=""https://quarantine.country/coronavirus/svg/coronavirus.svg"" rel=""nofollow noreferrer"">https://quarantine.country/coronavirus/svg/coronavirus.svg</a></p>

<pre><code>RewriteEngine on

RewriteOptions inherit
RewriteCond %{HTTP_HOST} ^quarantine\.country$ [OR]
RewriteCond %{HTTP_HOST} ^www\.quarantine\.country$
RewriteRule ^coronavirus\/svg\/?(.*)$ ""https\:\/\/quarantine\.country\/coronavirus\/images\/svg\/$1"" [R=301,L]
</code></pre>

<p>*since this is a repeating mistake, please explain what am I doing wrong here</p>
"
61583079,"<p><a href=""https://i.stack.imgur.com/4yw95.png"" rel=""nofollow noreferrer"">Currently trying this</a><br/>I am trying to analyze some COVID-19 data from Kaggle <br/>
<code>https://www.kaggle.com/kimjihoo/coronavirusdataset</code><br/>
I'm using tableau and every time I try to connect more than 9 tables out of the total 11 my pc just hangs <br/>
I've checked the system for low memory and low storage. It seems fine, I have 16gb ddr3, 1tb ssd, intel i7-6500u.<br/>
Some help will be very appreciated.</p>
"
61000526,"<p>I just updated to Android Studio 3.6.2 IDE.</p>

<p>And when I run my project, it shows error message as:</p>

<p>2:40 AM Executing tasks: [:app:assembleDebug] in project /Users/Covid19-Mobile/android</p>

<p>2:40 AM Gradle build failed with 1 error(s) in 82 ms</p>

<p>And cannot see the detail error message why build failed. And I cannot find Message View.</p>

<p>Please advise where can I check the detail error message.</p>
"
61181650,"<p>I want to leverage the C3.ai COVID-19 Data Lake to look for line list records where the patient has a chronic disease. I'm using <code>linelistrecord/fetch</code>. How do I construct the correct filter for this? </p>

<p>The POST request body that I tried was </p>

<pre><code>{""spec"" : {""filter"" : ""chronicDisease""}}
</code></pre>

<p>But I got the following error: </p>

<pre><code>""ERROR: argument of AND must be type boolean, not type character varying"".
</code></pre>
"
61625344,"<p>I am trying to integrate a Chatbot on my website. I followed <a href=""https://developer.ibm.com/tutorials/create-a-covid-19-chatbot-embedded-on-a-website/"" rel=""nofollow noreferrer"">this tutoria</a>l to set up the Watson Chatbot. </p>

<p>The bot is working as expected on the IBM cloud platform. And all my credentials are correct to set up the env. </p>

<p>However when I run the chatbot in my localhost:3000, I am not able to connect to the server. When I try to post a message to the bot for some reason I can not connect to the server and generate a session id. </p>

<p>this is the input JSON:</p>

<pre><code>{
 ""session_id"": null,
 ""input"": {
           ""message_type"": ""text"",
           ""text"": ""covid""
          }
}
</code></pre>

<p>And the console is giving me this message: <code>Uncaught TypeError: Cannot read property 'session_id' of undefined</code>.</p>

<p>Would anyone know what could have gone wrong in my app? </p>

<p>Thanks. </p>
"
60999096,"<p>I have just started the study about Snowflake and I faced with one situation:</p>

<p>I'm creating a JOB in pentaho data integration, to conect in this URL to get the JSON:
<a href=""https://pomber.github.io/covid19/timeseries.json"" rel=""nofollow noreferrer"">https://pomber.github.io/covid19/timeseries.json</a></p>

<p>To load it into a snowflake table, I must have a Data Type as a VARIANT. My column is already variant, but when I create the JOB, Pentaho is not able to convert the streaming  to a VARIANT Data Type and them I got the error that I cannot insert VARCHAR value into VARIANT data type.</p>

<p>Is there any workaround for that?</p>

<p>Thank you very much.</p>

<p><a href=""https://i.stack.imgur.com/djHbS.png"" rel=""nofollow noreferrer"">Error</a></p>
"
60998029,"<p>The situation is this: I'm building an MS Access database for use by my Population Health department to manage data for calls to people put on COVID-19 quarantine. During intake, they ask if there are any cohabitants in the home. On follow-up calls, they will then ask the status of the cohabitants.</p>

<p>I have a form built to capture all of the intake data (FullTable_frm), and an additional form called Cohabitants. Cohabitants is a subdatasheet within my main demographic table. I want to use the case number (CaseID) to cover both the main member of the household as well as any cohabitants. My goal is to use the Cohabitants form as a pop-up, where if a checkbox on FullTable_form is checked, it will open the popup where records can be entered for any cohabitants at the home.</p>

<p>Every way in which I've tried to do this, I receive the error, ""You cannot add or change a record because a related record is required..."" I have a 1:many relationship between FullTable and Cohabitants table, and on the table view it shows Cohabitants as a subdatasheet, which I can directly enter data into.</p>

<p>Any ideas as to where I might be going wrong and how to fix it? </p>
"
60851306,"<p>I am facing a problem in Text Translation (MLKit)
I am getting errors like, Firebase Instance ID not found and dictionary not found for translation.
But it dies download the dictionary when needed, just translation does not take place.
I have tried deleting the dictionary, I tried creating new app, changing json file, and any other solution I could see on stackoverflow or any other similar website
Am I missing something?
Below is the error: (I have used downloadModelIfNeeded)</p>

<pre><code>    translate_api.cc:98 dictionary_dir = /data/user/0/com.aniketbanginwar.covid/no_backup/com.google.firebase.ml.translate.models/W0RFRkFVTFRd+MTo3ODIwODU2MjA5NTQ6YW5kcm9pZDpkMWVjNzZmMjNiZTdjYzY5Njg5MWUz/af_en
    translate_api.cc:99 secondary_dictionary_dir = 
    translate_api.cc:100 cache_dir = /data/user/0/com.aniketbanginwar.covid/cache
    translate_api.cc:101 source_language = af
    translate_api.cc:102 target_language = en
    translate_api.cc:103 nmt_rr = 
    translate_api.cc:104 secondary_nmt_rr = 
    translate_api.cc:105 fallback_pbmt = /data/user/0/com.aniketbanginwar.covid/no_backup/com.google.firebase.ml.translate.models/W0RFRkFVTFRd+MTo3ODIwODU2MjA5NTQ6YW5kcm9pZDpkMWVjNzZmMjNiZTdjYzY5Njg5MWUz/af_en/fallback_to_pb_af_en.pb.bin
    translate_api.cc:106 secondary_fallback_pbmt = 
    translate_api.cc:107 stt_rr = 
    translate_api.cc:108 secondary_stt_rr = 
E/ModelResourceManager: Error preloading model resource
    com.google.firebase.ml.common.FirebaseMLException: Translation model files not found. Make sure to call downloadModelIfNeeded and if that fails, delete the models and retry.
        at com.google.firebase.ml.naturallanguage.translate.internal.TranslateJni.zzcz(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:37)
        at com.google.firebase.ml.naturallanguage.translate.FirebaseTranslator$zza.zzcz(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:8)
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzdy.zzf(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:53)
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzdy$zza.zzdl(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:7)
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzdy$zza.call(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:24)
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzdl.zza(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:32)
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzdk.run(Unknown Source:4)
        at android.os.Handler.handleCallback(Handler.java:873)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzb.dispatchMessage(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:6)
        at android.os.Looper.loop(Looper.java:201)
        at android.os.HandlerThread.run(HandlerThread.java:65)
     Caused by: com.google.firebase.ml.naturallanguage.translate.internal.TranslateJni$zzb
        at com.google.firebase.ml.naturallanguage.translate.internal.TranslateJni.newLoadingException(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:50)
        at com.google.firebase.ml.naturallanguage.translate.internal.TranslateJni.nativeInit(Native Method)
        at com.google.firebase.ml.naturallanguage.translate.internal.TranslateJni.zzcz(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:31)
        at com.google.firebase.ml.naturallanguage.translate.FirebaseTranslator$zza.zzcz(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:8) 
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzdy.zzf(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:53) 
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzdy$zza.zzdl(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:7) 
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzdy$zza.call(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:24) 
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzdl.zza(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:32) 
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzdk.run(Unknown Source:4) 
        at android.os.Handler.handleCallback(Handler.java:873) 
        at android.os.Handler.dispatchMessage(Handler.java:99) 
        at com.google.android.gms.internal.firebase_ml_naturallanguage_translate.zzb.dispatchMessage(com.google.firebase:firebase-ml-natural-language-translate@@22.0.0:6) 
        at android.os.Looper.loop(Looper.java:201) 
        at android.os.HandlerThread.run(HandlerThread.java:65) 
</code></pre>
"
61063837,"<p>I have an external drive which I would like to clone git repositories to. When I run git clone on the external drive I get the following error</p>

<pre><code>Cloning into 'covid-19-data'...
remote: Enumerating objects: 4, done.
remote: Counting objects: 100% (4/4), done.
remote: Compressing objects: 100% (4/4), done.
error: insufficient permission for adding an object to repository database /mnt/d/covid-19-data/.git/objects
fatal: failed to write object
fatal: unpack-objects failed
</code></pre>

<p>However when I run git clone on my C drive it clones not problem. I can create a new file on the external drive from the command line.</p>
"
61386401,"<p>I am trying to implement Facebook Open Graph on one of my page <code>https://www.talent-trust.com/documents/News2020.03/covid5.htm</code> </p>

<p>I think I have all the meta tags in place but I keep getting inferred and missing properties error and could not display the description, url, images and so on... I have followed the requirements for the image. It just won't detect my Meta.</p>

<p>To all the gurus, I don't know what is wrong,  please help, thanks in advance</p>

<p><strong>CODE</strong></p>

<pre><code>&lt;!DOCTYPE html&gt;
&lt;html xmlns:og=""http://ogp.me/ns#"" xmlns:fb=""http://www.facebook.com/2008/fbml"" &gt;
&lt;head&gt;

&lt;title&gt;COVID19 and TTc&lt;/title&gt;

&lt;meta charset=UTF-8&gt;
&lt;meta http-equiv=X-UA-Compatible content=""IE=edge""&gt;
&lt;meta name=viewport content=""width=device-width, initial-scale=1""&gt;

&lt;meta property=""og:url"" content=""http://www.talent-trust.com/documents/News2020.03/covid5.htm"" /&gt;
&lt;meta property=""og:type"" content=""article"" /&gt;
&lt;meta property=""og:title"" content=""COVID-19 and TTc"" /&gt;
&lt;meta property=""og:description"" content=""Full medical cover for COVID-19 available now with additional support"" /&gt;
&lt;meta property=""og:image"" content=""http://www.talent-trust.com/images/covic.png"" /&gt;
&lt;meta property=""fb:app_id"" content=""665025050962344"" /&gt;

&lt;/head&gt;
</code></pre>

<p><strong>ERROR</strong></p>

<p><a href=""https://i.stack.imgur.com/KHPwv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/KHPwv.png"" alt=""Errors""></a></p>
"
61126579,"<p>I’m trying to hit the <code>https://api.c3.ai/covid/api/1/outbreaklocation/evalmetrics</code> API endpoint with a request body that looks like the following.</p>

<pre><code>{
  ""ids"": [""Hubei_China""],
  ""expressions"":[
   ""ConfirmedDeathsJHU""
  ],
  ""interval"":""DAY"",
  ""start"":""2020-03-01"",
  ""end"":""2020-03-30""
}
</code></pre>

<p>However, I get the error: <code>Invalid argument name ""ids"" for function OutbreakLocation.evalMetrics at JSON document at 2:11</code></p>

<p>Any idea what could be wrong?</p>
"
60879041,"<p>I've been working with plotting covid-19 on a US county map, and thanks to help on this forum have gotten a product I'm pretty happy with.  However, I'd like to make a change to the way the legends are produced and am unsure how to.  There are several dataframes that go into the below snippet</p>

<pre><code>p &lt;- counties_cov %&gt;%
  ggplot() +
  geom_sf(mapping = aes(fill = cases), color = NA) +
  geom_sf(data = states_sf, fill = NA, color = ""black"", size = 0.25) +
  coord_sf(datum = NA) +   
  scale_fill_gradient(name = ""Cases"", trans = ""log"", low='green', high='red',
                      na.value = ""white"",
                      breaks=c(1, max(counties_cov$cases))) +
  geom_point(data=myBizLocations, aes(x=longitude.1, y=latitude.1,size=personnel), color = ""hotpink"") +
  theme_bw() + 
  theme(legend.position=""bottom"", 
        panel.border = element_blank(),
        axis.title.x=element_blank(), 
        axis.title.y=element_blank())
</code></pre>

<p>For yesterday's data this produces</p>

<p><a href=""https://i.stack.imgur.com/1BXT5.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1BXT5.png"" alt=""enter image description here""></a></p>

<p>What I'd like to do is simply modify the legend text from the current ""personnel"" which is just the name of the data column used to size the geom_points.  I'm unsure of how to do that without impacting the ""cases"" scale...</p>

<p>Ideally I'd like to go one step further and leave the cases scale on the bottom but put the personnel scale on the right...that's secondary though.</p>
"
60977244,"<p>I am using <code>plot.ly</code> within <code>r</code> to display a time series in which I have dates on the X axis (see code below). I would also like to highlight the weekends, most likely using a darker background. I know that I can set a background colour using <code>layout</code>, but AFAIK this applies to all the plot area, not a particular region. </p>

<p>Is there any way to use a different background colour for weekends in an horizontal axis with dates like in the image below?</p>

<p><img src=""https://i.stack.imgur.com/Tnn13.png"" alt=""""></p>

<pre class=""lang-r prettyprint-override""><code>library(plotly)

df &lt;- read.csv(""https://raw.githubusercontent.com/datadista/datasets/master/COVID%2019/nacional_covid19.csv"")               


plot_ly(data = df) %&gt;% 
  add_trace(x = ~ fecha,
            y = ~ casos,
            type = ""scatter"",
            mode = ""lines+markers"",
            name = ""Contagios detectados"") %&gt;% 
  layout(title = ""My title"",
         legend = list(x = 0.1, y = 0.9),
         hovermode = ""compare"")  
</code></pre>

<p>This is the dataframe:</p>

<pre><code>&gt; tail(df)
        fecha  casos altas fallecimientos ingresos_uci hospitalizados
32 2020-03-27  64059  9357           4858         4165          36293
33 2020-03-28  72248 12285           5690         4575          40630
34 2020-03-29  78797 14709           6528         4907          43397
35 2020-03-30  85195 16780           7340         5231          46617
36 2020-03-31  94417 19259           8189         5607          49243
37 2020-04-01 102136 22647           9053         5872          51418
</code></pre>

<pre><code>&gt; dput(df)
structure(list(fecha = structure(1:37, .Label = c(""2020-02-25"", 
""2020-02-26"", ""2020-02-27"", ""2020-02-28"", ""2020-02-29"", ""2020-03-01"", 
""2020-03-02"", ""2020-03-03"", ""2020-03-04"", ""2020-03-05"", ""2020-03-06"", 
""2020-03-07"", ""2020-03-08"", ""2020-03-09"", ""2020-03-10"", ""2020-03-11"", 
""2020-03-12"", ""2020-03-13"", ""2020-03-14"", ""2020-03-15"", ""2020-03-16"", 
""2020-03-17"", ""2020-03-18"", ""2020-03-19"", ""2020-03-20"", ""2020-03-21"", 
""2020-03-22"", ""2020-03-23"", ""2020-03-24"", ""2020-03-25"", ""2020-03-26"", 
""2020-03-27"", ""2020-03-28"", ""2020-03-29"", ""2020-03-30"", ""2020-03-31"", 
""2020-04-01""), class = ""factor""), casos = c(3L, 10L, 16L, 32L, 
44L, 66L, 114L, 135L, 198L, 237L, 365L, 430L, 589L, 999L, 1622L, 
2128L, 2950L, 4209L, 5753L, 7753L, 9191L, 11178L, 13716L, 17147L, 
19980L, 24926L, 28572L, 33089L, 39673L, 47610L, 56188L, 64059L, 
72248L, 78797L, 85195L, 94417L, 102136L), altas = c(NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 23L, 135L, 183L, 189L, 
189L, 517L, 517L, 530L, 1028L, 1081L, 1107L, 1585L, 2125L, 2575L, 
3355L, 3794L, 5367L, 7015L, 9357L, 12285L, 14709L, 16780L, 19259L, 
22647L), fallecimientos = c(NA, NA, NA, NA, NA, NA, NA, NA, 1L, 
3L, 5L, 8L, 17L, 17L, 35L, 47L, 84L, 120L, 136L, 288L, 309L, 
491L, 598L, 767L, 1002L, 1326L, 1720L, 2182L, 2696L, 3434L, 4089L, 
4858L, 5690L, 6528L, 7340L, 8189L, 9053L), ingresos_uci = c(NA, 
NA, NA, NA, NA, NA, NA, NA, 7L, 9L, 11L, NA, NA, 68L, 100L, 142L, 
190L, 272L, 293L, 382L, 432L, 563L, 774L, 939L, 1141L, 1612L, 
1785L, 2355L, 2636L, 3166L, 3679L, 4165L, 4575L, 4907L, 5231L, 
5607L, 5872L), hospitalizados = c(NA, NA, NA, NA, NA, NA, NA, 
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 3215L, 
5717L, NA, 10542L, 13282L, 15554L, 18374L, 22762L, 26960L, 31912L, 
36293L, 40630L, 43397L, 46617L, 49243L, 51418L)), .Names = c(""fecha"", 
""casos"", ""altas"", ""fallecimientos"", ""ingresos_uci"", ""hospitalizados""
), class = ""data.frame"", row.names = c(NA, -37L))
</code></pre>

<p>And this is the output plot:</p>

<p><img src=""https://i.stack.imgur.com/x3sew.png"" alt=""""></p>
"
60799406,"<p>I am working with <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">JHU data on coronavirus infections</a>, and I'm trying to compute new cases (and deaths) by group. Here's the code:</p>

<pre><code>base &lt;- ""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-""
world.confirmed &lt;- read.csv(paste0(base,""Confirmed.csv""), sep=',', head=T)
world.confirmed &lt;- gather( world.confirmed, Date, Cases, X1.22.20:X3.21.20)

world.deaths &lt;- read.csv(paste0(base,""Deaths.csv""), sep=',', head=T)
world.deaths &lt;- gather(world.deaths, Date, Deaths, X1.22.20:X3.21.20)

world.data &lt;- merge(world.confirmed, world.deaths, 
                 by=c(""Province.State"",""Country.Region"",""Lat"", ""Long"", ""Date""))

world.data$Date &lt;- as.Date(world.data$Date, ""X%m.%d.%y"")
world.data &lt;- world.data %&gt;% 
    group_by(Province.State,Country.Region,Date) %&gt;%
    arrange(Province.State, Country.Region, as.Date(Date))
</code></pre>

<p>Following <a href=""https://stackoverflow.com/questions/33049092/difference-between-rows-in-r-on-dataframe-grouped-by-column"">solutions to this question in SO</a> I have tried to compute differences by group using something like this:</p>

<pre><code>world.data &lt;- world.data %&gt;% 
   group_by(Lat,Long) %&gt;% 
   mutate(New.Cases = Cases - lag(Cases))
</code></pre>

<p>That does not work, however; any other grouping does not either. Here're results on boundary between two first countries:</p>

<p><a href=""https://i.stack.imgur.com/VVhR6.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/VVhR6.png"" alt=""Value for first element of Albania""></a></p>

<p>I have tried also inserting an <code>arrange</code> phase, and even trying to zero the first element of the group. Same problem. Any idea?</p>

<p><em>Update</em> I'm using R 3.4.4 and dplyr_0.8.5  </p>
"
61537702,"<p>I'm attempting to show my students how to replicate <a href=""https://www.technologyreview.com/2020/03/27/950263/the-covid-19-pandemic-in-two-animated-charts/"" rel=""nofollow noreferrer"">this animated COIVD-19 chart</a> in <code>{gganimate}</code>. I've found <a href=""https://towardsdatascience.com/https-towardsdatascience-com-everything-you-need-to-know-about-animated-bar-charts-be033f398619"" rel=""nofollow noreferrer"">this tutorial post</a> to be quite helpful. </p>

<p>Only showing a snippet here because I could not figure out how to keep the upload size small:</p>

<p><a href=""https://i.stack.imgur.com/RKmC3.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RKmC3.gif"" alt=""enter image description here""></a></p>

<p><strong>I'm struggling a bit with two things</strong>:</p>

<ol>
<li>Getting country flags and tile labels placed correctly. <a href=""https://github.com/thomasp85/gganimate/issues/317"" rel=""nofollow noreferrer"">Here's the example</a> I'm trying to follow.</li>
<li>General look and feel (transitions are not as smooth, counter text is not positioned in body of chart, counter text styling is not as nice)</li>
</ol>

<p>Here is my code:</p>

<pre><code># load packages
  library(tidyverse)
  library(gganimate)   # install.packages(c(""av"", ""gifski""))
  library(viridis)
  library(ggflags)     # devtools::install_github(""ellisp/ggflags"")
  library(countrycode) # install.packages(""countrycode"")

# get and prep the data
  library(""rio"")
  url &lt;- ""https://gist.githubusercontent.com/ericpgreen/123599c21fae4a2a653ae3b7795236d0/raw/0584ff1769adc9c1fb8062012699bdccffe1d170/animate.R""
  df &lt;- rio::import(url)

  static &lt;- 
  leaderboard %&gt;%
# convert to factor
  mutate(monthDay = factor(monthDay, 
                           levels = monthDayLevels,
                           labels = monthDayLevels)) %&gt;%
# plot
  ggplot(., aes(x = rank, group = country, 
                fill = country, color = country
                #,country = cc) # needed if embedding flags
       )) +
  geom_tile(aes(y = cases/2, height = cases,
                width = 0.9), alpha = 0.8, color = NA) +
# if trying to embed flags
  #geom_flag(aes(y = cases+50), size = 20) +
  geom_text(aes(y = 0, label = paste(country, ""   "")),
                vjust = 0.2, hjust = 1, size = 10) +
  geom_text(aes(y=cases+50, label = label, hjust=0),
                size = 10) +
  coord_flip(clip = ""off"", expand = TRUE) +
  scale_x_reverse()

# define animation
  animate &lt;- 
  static +
  transition_states(monthDay,
                    transition_length = 4,
                    state_length = 1) +
  ease_aes('cubic-in-out') +
  view_follow(fixed_x = TRUE) 

# render
  animate(animate, fps = 10, duration = 50, width = 1000, 
          height = 600,
          renderer=gifski_renderer(""gganim.gif""))
</code></pre>

<p>Additional plotting code to reproduce my gif. Add this <code>static</code> plot to reproduce my gif:</p>

<pre><code>  scale_fill_viridis_d(option = ""plasma"") +
  scale_color_viridis_d(option = ""plasma"") +
  theme_minimal() +
  theme(axis.line=element_blank(),
        axis.text.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks=element_blank(),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        legend.position=""none"",
        panel.background=element_blank(),
        panel.border=element_blank(),
        panel.grid.major=element_blank(),
        panel.grid.minor=element_blank(),
        panel.grid.major.x = element_line(size=.4, 
                                          color=""grey"" ),
        panel.grid.minor.x = element_line(size=.1, 
                                          color=""grey"" ),
        plot.title.position = ""plot"",
        plot.title=element_text(size=20, 
                                face=""bold"", 
                                colour=""#313632""),
        plot.subtitle=element_text(size=50, 
                                   color=""#a3a5a8""),
        plot.caption =element_text(size=15, 
                                   color=""#313632""),
        plot.background=element_blank(),
        plot.margin = margin(1, 9, 1, 9, ""cm"")) +
  labs(title = 'Cumulative number confirmed COVID-19 cases by date and country',  
       subtitle = '{closest_state}',
       caption  = ""Data: Johns Hopkins CCSE"")
</code></pre>
"
61096795,"<p>I am running a series of <a href=""https://covid-at-home.info"" rel=""nofollow noreferrer"">websites with information about the COVID-19 pandemic</a> in different languages. They live in their own GitHub repositories and are served using GitHub Pages. Right now each of these repositories has a copy of all the files except the ones that are part of the <a href=""https://github.com/pages-themes/slate"" rel=""nofollow noreferrer"">theme</a>. Somewhat inconveniently, I have no previous experience with Jekyll, Ruby or GitHub Pages.</p>

<p>I know there are multilingual jekyll tricks, but that is not what I am here for, mostly because I want sites on different domains.</p>

<p>So I decided that it might be good to hijack the theme as a store for files common to my sites. So I made a <a href=""https://github.com/covid-at-home/testsite"" rel=""nofollow noreferrer"">test copy</a> of my site without the common files. It uses as ""<code>remote_theme</code>"" a <a href=""https://github.com/covid-at-home/common"" rel=""nofollow noreferrer"">copy</a> of the theme where I stuck my common files in the theme's assets directory, so they get pulled in by the different language sites. This works for images, PDF files and such: I just move them to <code>/assets/images</code> in the theme and it all works.</p>

<p>However, next to data files local to each language, such as the menu below our site title, I also have some common data files, such as the list of languages that the site is available in and the list of volunteers we thank for their work. I'd like to also place these in the theme somehow so I don't have to commit them to all the repos separately... Cannot get this to work.</p>

<p>What I have tried:</p>

<ul>
<li><p>Adding <code>_data</code> to the regexp in the <code>.gemspec</code> file of the theme where it reads:
<code>f.match(%r{^((_includes|_layouts|_sass|assets)/|(LICENSE|README)((\.(txt|md|markdown)|$)))}i)</code></p>

<blockquote>
  <p>Does not lead to the data files being accessible</p>
</blockquote></li>
<li><p>Creating dummy _data files that <code>{% include</code> the real ones from the theme's <code>_include</code> dir.</p>

<blockquote>
  <p>""<code>found character that cannot start any token while scanning for the next token</code>""</p>
</blockquote></li>
<li><p>Set <code>data_dir</code> in <code>_config.yml</code> to <code>assets/data</code></p>

<blockquote>
  <p>I can use the data files that are site specific just fine, but the data files on the theme side are not seen by the Liquid processing. (They are copied to the <code>_site</code> directory along with the site-specific ones.)</p>
</blockquote></li>
</ul>

<p>Is there a way to have a GitHub Pages site with some data coming from its own files and some data coming from the theme files? I realise I'd probably have to rebuild the site to make the theme changes show. (Right?) (Is there a way to trigger a rebuild on GitHub Pages other than to change files? What does the version number on the theme do?)</p>

<p>Is there a more in-depth writeup of how the files from the theme and the site get mixed and what order things happen in than the jekyll user documentation?</p>

<p>Please by all means also tell me if there's a much better, simpler and/or more elegant way to do what I am trying to accomplish. We have a fast-growing existing project, but I'm ready to do things differently if that's simply better...</p>
"
61664773,"<p>I am trying to do #8 on this problem set from sqlzoo (<a href=""https://sqlzoo.net/wiki/Window_LAG#LAG_using_a_JOIN"" rel=""nofollow noreferrer"">https://sqlzoo.net/wiki/Window_LAG#LAG_using_a_JOIN</a>).</p>

<p>The question is ""For each country that has had at last 1000 new cases in a single day, show the date of the peak number of new cases.""</p>

<p>The table covid gives the number of covid cases, deaths, and recoveries per day by country as so:</p>

<pre><code>+-------------+-------------------------------+-----------+--------+-----------+
|    Name     |              whn              | confirmed | deaths | recovered |
+-------------+-------------------------------+-----------+--------+-----------+
| Afghanistan | Sun, 01 Mar 2020 00:00:00 GMT |         1 |      0 |         0 |
| Albania     | Sun, 01 Mar 2020 00:00:00 GMT |         0 |      0 |         0 |
| Algeria     | Sun, 01 Mar 2020 00:00:00 GMT |         1 |      0 |         0 |
+-------------+-------------------------------+-----------+--------+-----------+
</code></pre>

<p>Currently I have this code: </p>

<pre><code>SELECT c.name, DATE_FORMAT(c.whn,'%Y-%m-%d') as this, d.peak
from ( select tw.name, max(tw.confirmed-lw.confirmed) as peak
FROM covid tw LEFT JOIN covid lw ON 
  DATE_ADD(lw.whn, INTERVAL 1 DAY) = tw.whn
   AND tw.name=lw.name
where tw.confirmed-lw.confirmed &gt; 1000
group by tw.name) d
join covid as c
on d.name = c.name
group by name
</code></pre>

<p>which gives me each country, the date, and the peak number of cases. However, the date is showing the first day for each country when the cases are above a 1000. How would I get the date where there is the peak number of cases?</p>

<pre><code>|  Name   |    this    | peak |
|---------|------------|------|
| Austria | 2020-03-26 | 1321 |
| Belarus | 2020-04-20 | 1485 |
| Belgium | 2020-03-26 | 2454 |
</code></pre>
"
61187185,"<p>I have a table like this:</p>

<pre><code>[ID]  [Country_Region]  [Date1]  [Date2]  [Date3] ... [Date150]
</code></pre>

<p>I wrote a SQL query in BigQuery that returns a dataset like this:</p>

<pre><code>[ID] [Country_Region] [Date.ColumnName] [Date.Value] 
-----------------------------------------------------
 1    China           _1_22_20           12
 2    China           _1_23_20           34
 [3   China           _1_24_20           54] &lt;----- I want this row and all the next ones to appear as well
</code></pre>

<p>My SQL query:</p>

<pre><code>WITH timestamped_table AS 
(
    SELECT
        Country_Region,
        [STRUCT&lt;timestamp STRING, timestamp_value INT64&gt;
        ('2020-2-22', _2_22_20),
        ('2020-2-23', _2_23_20)] AS timestamp_data
    FROM
        `username.bq_timeseries_covid19.recovered_global` 
    WHERE
        Country_Region = 'China' AND Province_State = 'Zhejiang'
)
SELECT
    Country_Region, timestamp
FROM
    timestamped_table
CROSS JOIN
    UNNEST(timestamped_table.timestamp_data) AS timestamp
</code></pre>

<p>Now the only problem I have is that I have to extend these lines from the query:</p>

<pre><code>STRUCT&lt;timestamp STRING, timestamp_value INT64&gt;
        ('2020-2-22', _2_22_20),
        ('2020-2-23', _2_23_20)
</code></pre>

<p>So that they include all the date columns.</p>

<p>I would imagine it to be something like this if I would be extending it by some script(which I think is not the best idea?):</p>

<pre><code>STRUCT&lt;timestamp STRING, timestamp_value INT64&gt;
        for column in get_date_columns():
        (timestamp_from_columnname(), column)
</code></pre>

<p>I think that writing a SQL script/function would be better but I don't know how to start with this exactly</p>
"
60988150,"<p>I'm doing some coronavirus statistics. Would you help me with a query, please. I'd like to get the LAST infected ('confirmed' field) growth for each country. Some countries doesn't update every day, so it needs to be a difference between second last meassure and the last one for each country.</p>

<p>In short - how to find last value increase in a groupped table?</p>

<p>The table looks like this:</p>

<p><code>CREATE TABLE coronavirus (
id INT(6) UNSIGNED AUTO_INCREMENT PRIMARY KEY,
place VARCHAR(30),
province VARCHAR(30),
country VARCHAR(40),
updated TIMESTAMP,
confirmed INTEGER,
deaths INTEGER,
recovered INTEGER,
latitude FLOAT,
longitude FLOAT);</code></p>

<p>Thanks!</p>

<p>PS. The table contents looks like this:</p>

<pre><code>mysql&gt; select * from coronavirus where id&gt;8000 order by id limit 10;
+------+-------+-----------------+-------------+---------------------+-----------+--------+-----------+----------+-----------+
| id   | place | province        | country     | updated             | confirmed | deaths | recovered | latitude | longitude |
+------+-------+-----------------+-------------+---------------------+-----------+--------+-----------+----------+-----------+
| 8001 | NULL  | Shanghai        | China       | 2020-03-23 14:18:01 |       404 |      4 |       329 |   31.202 |   121.449 |
| 8002 | NULL  | Shanxi          | China       | 2020-03-13 08:56:40 |       133 |      0 |       133 |  37.5777 |   112.292 |
| 8003 | NULL  | Sichuan         | China       | 2020-03-22 07:20:38 |       543 |      3 |       536 |  30.6171 |    102.71 |
| 8004 | NULL  | Sint Maarten    | Netherlands | 2020-03-23 23:19:21 |         2 |      0 |         0 |  18.0425 |  -63.0548 |
| 8005 | NULL  | South Australia | Australia   | 2020-03-23 23:23:20 |       134 |      0 |         6 | -34.9285 |   138.601 |
| 8006 | NULL  | St Martin       | France      | 2020-03-23 23:19:21 |         8 |      0 |         0 |  18.0708 |  -63.0501 |
| 8007 | NULL  | Tasmania        | Australia   | 2020-03-23 23:23:20 |        28 |      0 |         3 | -42.8821 |   147.327 |
| 8008 | NULL  | Tianjin         | China       | 2020-03-23 03:57:57 |       141 |      3 |       133 |  39.3054 |   117.323 |
| 8009 | NULL  | Tibet           | China       | 2020-02-23 11:19:02 |         1 |      0 |         1 |  31.6927 |   88.0924 |
| 8010 | NULL  | Victoria        | Australia   | 2020-03-23 23:23:20 |       355 |      0 |        97 | -37.8136 |   144.963 |
+------+-------+-----------------+-------------+---------------------+-----------+--------+-----------+----------+-----------+

mysql&gt; select count(*) from coronavirus;                                                                                                                           +----------+
+----------+
| count(*) |
+----------+
|    34783 |
+----------+
</code></pre>
"
61430639,"<p>i am building a COVID-19 app tracker on IOS. </p>

<p>In order to display the data by country, I have built a pickerView that will contain all the country names.</p>

<p>thanks to an HTTP cal, I have managed to get the JSON data i.e the name of each country. ideally I wish to append each value to an array that in turn will populate the pickerView.</p>

<p>Is that possible ? If yes, how would I do that ? </p>

<p>I am also open to other ways to do it. Here is my code : </p>

<pre><code> @IBOutlet weak var confirmedCasesLabel: UILabel!
 @IBOutlet weak var deathsLabel: UILabel!
 @IBOutlet weak var recoveriesLabel: UILabel!

 //MARK: - Relevant variables
 private let covidUrl: String = ""https://corona-api.com/countries""
 var countryArray: [String] = [String]()


 override func viewDidLoad() {
     super.viewDidLoad()

     // Do any additional setup after loading the view.
     countryPickerView.delegate = self
     countryPickerView.dataSource = self

     //
     httpCall()
 }


 /*
 // MARK: - Navigation

 // In a storyboard-based application, you will often want to do a little preparation before navigation
 override func prepare(for segue: UIStoryboardSegue, sender: Any?) {
     // Get the new view controller using segue.destination.
     // Pass the selected object to the new view controller.
 }
 */

 //MARK: - Functions that handles picker view delegates and data source
 func numberOfComponents(in pickerView: UIPickerView) -&gt; Int {
        return 1
    }

 func pickerView(_ pickerView: UIPickerView, numberOfRowsInComponent component: Int) -&gt; Int {
     return countryArray.count
    }

 func pickerView(_ pickerView: UIPickerView, titleForRow row: Int, forComponent component: Int) -&gt; String? {
     return countryArray[row]
 }

 //MARK: - HTTP CALL - GET COUNTRY DATA
 func httpCall() {
     request(covidUrl, method: .get).responseJSON { (response) in
         if response.result.isSuccess {
             //test just print some data
             let dataJSON: JSON = JSON(response.result.value)
             //print(dataJSON)
             //on va identifier chaque pays + l'ajouter au tableau des pays
//                let countryNameJSON = dataJSON[""data""][99][""name""]
//                print(countryNameJSON)
             for country in 0...99 {
                 let countryNameJSON = dataJSON[""data""][country][""name""].stringValue
                 print(countryNameJSON)
                 //on ajoute ce nom au tabeleau de pays
                 //self.countryArray.append(countryNameJSON)
             }

         }
     }
 }



}
</code></pre>
"
61353846,"<p>I am trying to extract the hashtag info from a twitter data cell in google sheets.</p>

<p>We can call this Cell A1:</p>

<pre><code>[{""text"":""QOTD"",""indices"":[13,18]},{""text"":""CSEC4CG"",""indices"":[87,95]},{""text"":""myCSEC"",""indices"":[96,103]},{""text"":""Connecticut"",""indices"":[104,116]},{""text"":""GiveBack"",""indices"":[117,126]},{""text"":""COVID19"",""indices"":[127,135]}]
</code></pre>

<p>In a perfect situation I would be able to produce this in another cell extracted from A1:</p>

<pre><code>#QOTD #CSEC4CG #myCSEC #Connecticut #Giveback #COVID19
</code></pre>

<p>I am lost how to do it using REGEXTRACT.  I assume this is the best method, but any that gets the job done is good.</p>

<p>Thank you for any help!</p>
"
61325610,"<p>this is a working code that prints statics from covid data [], run it so you can understand, i want to turn this code to read not from this covid data[] but from a csv file that i have full with data same like in covid data []
i have no idea how to do it , if you can please copy the working code, thank you a lot!</p>

<p>this array covid data [] is a part of the csv file so you can understand.</p>

<pre><code>
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

typedef struct {
    unsigned int SNo;
    char ObservationDate[11];
    char Province_State[50];
    char Country_Region[50];
    char Last_Update[50];
    float Confirmed;
    float Deaths;
    float Recovered;
}covid;

void printGraph(int number) {
int i;
    for (i = 0; i &lt; number; i++) {
        printf(""*"");
    }
    printf(""\n"");
}

void printDistribution(covid data[], int datalength, char country[50], char date[11]) {
int i;
    for (i = 0; i &lt; datalength; i++) {
        if (strcmp(country, data[i].Country_Region) == 0) {
            if (strcmp(date, data[i].ObservationDate) == 0) {
                printf(""Total Cases: %f"", data[i].Confirmed);
                printGraph(data[i].Confirmed);
                printf(""Total Deaths: %f"", data[i].Deaths);
                printGraph(data[i].Deaths);
                printf(""Total Recovered: %f"", data[i].Recovered);
                printGraph(data[i].Recovered);
                float fatalityRate = (data[i].Deaths / data[i].Confirmed) * 100;
                float recoveryRate = (data[i].Recovered / data[i].Confirmed) * 100;
                printf(""Fatality Rate: %f%%\n"", fatalityRate);
                printf(""Recovery Rate: %f%%\n"", recoveryRate);
            }
        }
    }
}
int main(int argc, char** argv) {
    covid data[] = {
                    {1, ""1/22/2020"", ""Anhui"", ""Mainland China"", ""1/22/2020 5:00:00 PM"", 1, 0 , 0},
                    {2, ""1/22/2020"", ""Beijing"", ""Mainland China"", ""1/22/2020 5:00:00 PM"", 14, 0 , 0},
                    {3, ""1/22/2020"", ""Fujian"", ""Mainland China"", ""1/22/2020 5:00:00 PM"", 6, 0 , 0},
                    {4, ""1/22/2020"", ""Washington"", ""US"", ""1/22/2020 5:00:00 PM"", 1, 0 , 0},
                    {5, ""1/22/2020"", ""Beirut"", ""Lebanon"", ""1/22/2020 5:00:00 PM"", 1, 0 , 0},
                    {6, ""2/22/2020"", ""Anhui"", ""Mainland China"", ""2020-02-22T07:43:03"", 989, 6 , 597},
                    {7, ""2/22/2020"", ""Beijing"", ""Mainland China"", ""1/22/2020 5:00:00 PM"", 399, 4 , 178},
                    {8, ""2/22/2020"", ""Fujian"", ""Mainland China"", ""1/22/2020 5:00:00 PM"", 293, 1 , 162},
                    {9, ""2/22/2020"", ""Washington"", ""US"", ""1/22/2020 5:00:00 PM"", 150, 10 , 96},
                    {10, ""2/13/2020"", ""Beirut"", ""Lebanon"", ""1/22/2020 5:00:00 PM"", 50, 10 , 15},
                    {11, ""3/13/2020"", ""Anhui"", ""Mainland China"", ""1/22/2020 5:00:00 PM"", 1500, 20 , 785},
                    {12, ""3/13/2020"", ""Beijing"", ""Mainland China"", ""1/22/2020 5:00:00 PM"", 450, 50 , 300},
                    {13, ""3/13/2020"", ""Fujian"", ""Mainland China"", ""1/22/2020 5:00:00 PM"", 6, 0 , 0},
                    {14, ""3/13/2020"", ""Washington"", ""US"", ""1/22/2020 5:00:00 PM"", 1, 0 , 0},
                    {15, ""3/13/2020"", ""Beirut"", ""Lebanon"", ""1/22/2020 5:00:00 PM"", 1, 0 , 0},
                    {16, ""4/15/2020"", ""Anhui"", ""Mainland China"", ""2020-02-22T07:43:03"", 989, 6 , 597},
                    {17, ""4/15/2020"", ""Beijing"", ""Mainland China"", ""1/22/2020 5:00:00 PM"", 399, 4 , 178},
                    {18, ""4/15/2020"", ""Fujian"", ""Mainland China"", ""1/22/2020 5:00:00 PM"", 293, 1 , 162},
                    {19, ""4/15/2020"", ""Washington"", ""US"", ""1/22/2020 5:00:00 PM"", 150, 10 , 96},
                    {20, ""4/15/2020"", ""Beirut"", ""Lebanon"", ""1/22/2020 5:00:00 PM"", 50, 10 , 15},
    };
    char country[] = ""US"";
    char date[] = ""4/15/2020"";
    printDistribution(data, 20, country, date);

    return 0;
}

</code></pre>
"
60989605,"<p>I'm wondering how to write a unit test in c# using selenium, which will satisfy my need. This is my code, however I do not know what to do next. I found some language detection packages, but I don't know how to use them. 
<a href=""https://www.nuget.org/packages/LanguageDetection.NETStandard/"" rel=""nofollow noreferrer"">https://www.nuget.org/packages/LanguageDetection.NETStandard/</a>
<a href=""https://www.nuget.org/packages/LanguageDetection/"" rel=""nofollow noreferrer"">https://www.nuget.org/packages/LanguageDetection/</a> - this one is for java, but there is a version for c#</p>

<pre><code>    [Test(Description = """")]
            public void searchTest_DoesAnyResultInDesiredLanguageExistInFirst10Results()
            {


                driver.Navigate().GoToUrl(URL);

                driver.Manage().Window.Maximize();
                ChromeOptions options = new ChromeOptions();
                options.AddArguments(""--lang=pl"");

                IWebElement element = driver.FindElement(By.Name(""q""));

                element.SendKeys(""Coronavirus COVID-19 Global Cases by Johns Hopkins CSSE"");

                element.Submit();


                driver.Manage().Timeouts().ImplicitWait = TimeSpan.FromSeconds(2);


                IReadOnlyCollection&lt;IWebElement&gt; results = driver.FindElements(By.XPath(""//*[@id=\""rcnt\""]""));



            }
</code></pre>
"
61384274,"<p>im trying to make this so that when someone selects a different country on my combo box the image will change to a different flag, Ive used a pretty crude version without binding and put a switch in a box.
My switch which is currently in a button. </p>

<pre><code>    private void Button_Click(object sender, RoutedEventArgs e)
        {
            switch((string)CountrySelector.SelectedItem)
            {
                case ""South Africa"":
                    CasesNumLabel.Content = southAfricaData.Data.Covid19Stats[0].Confirmed.ToString();
                    DeathsNumLabel.Content = southAfricaData.Data.Covid19Stats[0].Deaths.ToString();
                    RecoveredNumLabel.Content = southAfricaData.Data.Covid19Stats[0].Recovered.ToString();

                    break;
                case ""United Kingdom"":
                    CasesNumLabel.Content = unitedKingdomData.Data.Confirmed.ToString();
                    DeathsNumLabel.Content = unitedKingdomData.Data.Deaths.ToString();
                    RecoveredNumLabel.Content = unitedKingdomData.Data.Recovered.ToString();

                    break;
                default:

                    break;
            }
        }
</code></pre>

<p>XAML </p>

<pre><code>            &lt;Image Source=""ZAFlag.gif"" HorizontalAlignment=""Left"" Height=""43"" Margin=""285,56,0,0"" VerticalAlignment=""Top"" Width=""70""/&gt;
        &lt;ComboBox x:Name=""CountrySelector"" HorizontalAlignment=""Left"" Height=""43"" Margin=""360,56,0,0"" VerticalAlignment=""Top"" Width=""160"" /&gt;
        &lt;Button Content=""Refresh"" HorizontalAlignment=""Left"" VerticalAlignment=""Top"" Width=""88"" Height=""28"" Click=""Button_Click""/&gt;
</code></pre>
"
60994442,"<p>I have an MediaRSS feed URL and I want to parse it and read media tags as a list. 
As an example, my URL is 
<a href=""http://www.ipreunion.com/export/rss,0.xml"" rel=""nofollow noreferrer"">http://www.ipreunion.com/export/rss,0.xml</a></p>

<pre><code>&lt;item&gt;
&lt;guid isPermaLink=""false""&gt;
http://www.ipreunion.com/coronavirus/reportage/2020/04/02/la-poste-s-organise-pour-accueillir-ses-clients-34-bureaux-de-poste-ouverts-au-lieu-de-16,117016.html
&lt;/guid&gt;
&lt;dcterms:alternative xml:lang=""fr""&gt;
&lt;![CDATA[ Organisation pour accueillir ses clients ]]&gt;
&lt;/dcterms:alternative&gt;
&lt;title&gt;
&lt;![CDATA[ La Poste : 34 bureaux ouverts au lieu de 16 ]]&gt;
&lt;/title&gt;
&lt;dcterms:abstract&gt;
&lt;![CDATA[
Pour protéger la santé des postiers et de ses clients tout en assurant ses missions essentielles, La Poste a adapté son organisation à l'évolution de la situation sanitaire avec 34 bureaux ouverts au public et des postiers toujours aussi mobilisés au service des Réunionnais. Nous publions ci-dessous le communiqué de La Poste. (Photo d'illustration rb/www.ipreunion.com)
]]&gt;
&lt;/dcterms:abstract&gt;
&lt;description&gt;
&lt;![CDATA[
&lt;p&gt; Afin que le versement des prestations sociales aux allocataires se déroule dans les meilleures conditions possibles, La Poste met en place un dispositif adapté, accessible dès le 4 avril via les distributeurs automatiques de billets, et dès le 6 avril dans ses bureaux de poste. Dès le 4 avril, un retrait d&amp;rsquo;espèces anticipé dans les distributeurs automatiques&lt;/p&gt;&lt;p&gt; Grâce à la décision de la CAF d&amp;rsquo;avancer le versement des prestations sociales, les bénéficiaires qui disposent de cartes de retrait auront la possibilité d&amp;rsquo;effectuer des retraits dès le samedi 4 avril (au lieu du 7 avril) dans le réseau de 130 distributeurs automatiques de billets.&lt;/p&gt;&lt;p&gt; Dans cette période, La Poste rappelle que les déplacements en bureaux de poste doivent être limités à ce qui est strictement nécessaire. C&amp;rsquo;est pourquoi, seuls les retraits d&amp;rsquo;espèces dans les distributeurs automatiques seront possibles le week-end des 4 et 5 avril, les bureaux de poste seront fermés le samedi 4 avril et accueilleront de nouveau le public dès le lundi 6 avril.&lt;/p&gt;&lt;p&gt; Les 6, 7 et 10 avril, 34 bureaux de poste, au lieu de 16, seront ouverts et seront exclusivement dédiés au versement des prestations sociales et aux opérations bancaires de première nécessité. Les services liés à l&amp;rsquo;affranchissement reprendront le 8 avril.&lt;/p&gt;&lt;p&gt; &lt;b&gt;Seront ouverts les bureaux de poste de :&lt;/b&gt; &amp;bull; Nord : LLa Montagne, Le Chaudron, Les Camélias, Saint-Denis Les Flamboyants, Sainte-Clotilde, Sainte- Marie &amp;bull; Est : Bras Panon, Hell Bourg, La Plaine des Palmistes, Saint-André, Saint-Benoit, Sainte-Rose &amp;bull; Sud : Cilaos, Entre Deux, La Rivière, La Plaine des Cafres, Le Tampon, Ravine Blanche, Ravines des Cabris, Saint-Joseph, Saint-Louis, Saint-Pierre &amp;bull; Ouest : La Possession, Le Plate, Le Port, Saint-Gilles Les Bains, Saint-Gilles Les Hauts, Saint-Leu, Saint- Paul, Savannah, Tan Rouge, Tevelave, Trois Bassins&lt;/p&gt;
]]&gt;
&lt;/description&gt;
&lt;pubDate&gt;Thu, 02 Apr 2020 18:24:00 +0400&lt;/pubDate&gt;
&lt;dcterms:provenance&gt;
Imaz Press Réunion : l'actualité de la Réunion en photos
&lt;/dcterms:provenance&gt;
&lt;dcterms:isReferencedBy&gt;filinfo:-1&lt;/dcterms:isReferencedBy&gt;
&lt;dc:subject xml:lang=""fr"" type=""index""&gt;Actualités de La Réunion&lt;/dc:subject&gt;
&lt;dc:subject xml:lang=""fr"" type=""index""&gt;La Poste&lt;/dc:subject&gt;
&lt;dc:subject xml:lang=""fr"" type=""index""&gt;Coronavirus&lt;/dc:subject&gt;
&lt;dc:subject xml:lang=""fr"" type=""index""&gt;Confinement&lt;/dc:subject&gt;
&lt;dc:subject xml:lang=""fr"" type=""rubrique""&gt;Coronavirus&lt;/dc:subject&gt;
&lt;dc:subject xml:lang=""fr"" type=""rubrique""&gt;Actus Reunion&lt;/dc:subject&gt;
&lt;media:content url=""http://www.ipreunion.com/medias/source/0385651001520593330.jpg"" type=""image/jpeg""&gt;
&lt;media:title&gt;
&lt;![CDATA[ la poste ]]&gt;
&lt;/media:title&gt;
&lt;media:description&gt;
&lt;![CDATA[ photo d'archive imaz press reunion ]]&gt;
&lt;/media:description&gt;
&lt;/media:content&gt;
&lt;/item&gt;
</code></pre>

<p>I want to get media tag value for every Item tags.
result should be like this as list</p>

<pre><code>| tag name                | tag value
-------------------------------------------
|media:title              | la poste
|media.desc               | photo d'archive imaz press reunion
|media.[other tag name]   |
</code></pre>

<p>I tried using with SyndicationFeed class, but SyndicationFeed cannot parse media tags.</p>
"
61701877,"<p>Hi I would like to transfer some couts into a string, how can I do that?
For instance:</p>

<pre><code>std::cout &lt;&lt; ""The number of coronavirus infected: ""&lt;&lt; allCount &lt;&lt; std::endl;
std::cout &lt;&lt; ""The number of not infected: "" &lt;&lt; allpatient_ - allCount &lt;&lt; std::endl;
std::cout &lt;&lt; ""The number of coronavirus infected hospitals: "" &lt;&lt; hospital &lt;&lt; std::endl;
std::cout &lt;&lt; ""The number of not infected hospitals: "" &lt;&lt; hospitalcount_-hospital &lt;&lt; std::endl;
std::cout &lt;&lt; ""The number of infected rooms in hospitals: "" &lt;&lt; room &lt;&lt; std::endl;
std::cout &lt;&lt; ""The number of not infected rooms: "" &lt;&lt; hospitalcount_*roomcount_ - room &lt;&lt; std::endl;
</code></pre>

<p>I would like to transform into a string, any tips?</p>
"
60904241,"<p>This is my first post, so sorry for errors. I have a problem I can't make a button which open radom page in my apk. The project is connected with Coronavirus. </p>
"
60889924,"<p><a href=""https://i.stack.imgur.com/oGUpB.jpg"" rel=""nofollow noreferrer"">enter image description here</a>I'm trying to make a simple flutter app. I've made a drawer on the homepage that leads to different routes on my app. A problem I'm facing is when I click on a list element on my drawer, it successfully navigates to that page and the new page opens BUT there is a time in between clicking(on list element) and new page(opening) in which both of the pages are shown on the screen, one over another. This looks very unprofessional. 
In the picture shown, when I try to navigate from 'Home' to 'More Statistics', there is a small noticeable period of time where both the scaffolds (Home scaffold and More Statistics scaffold) are visible.
How can I remove that, please help.</p>

<p>This is my drawer class</p>

<pre><code>import 'package:covid19/MoreStatistics.dart';
import 'package:flutter/material.dart';

bool isPresse1=true;
bool isPresse2=false;
bool isPresse3=false;
bool isPresse4=false;

class MyDrawer extends StatelessWidget {

@override
Widget build(BuildContext context) {
return Drawer(
      child: ListView(
        children: &lt;Widget&gt;[
          DrawerHeader(
            decoration: BoxDecoration(
                color: Colors.black,
                image: DecorationImage(
                  image: AssetImage('assets/earth.PNG'),
                  fit: BoxFit.fitWidth
                )
            ),
           /* child: Align(
              alignment: Alignment.topRight,
              child: Text(
                ""Social Distancing \n \t \t \t \t \t \t is the key"",
                style: TextStyle(
                    color: Colors.black54,
                    fontSize: 30.0,
                    fontWeight: FontWeight.bold
                ),
              ),
            ),*/
          ),
          Card(
            elevation: 10.0,
            child: ListTile(
              leading: IconButton(
                  icon: Icon(
                    Icons.home,
                    color: Colors.deepOrange,
                  )
              ),
              contentPadding: EdgeInsets.symmetric(
                  horizontal: 0.0,
                  vertical: 0.0
              ),
              onTap: () {
                isPresse1 ? Navigator.pop(context) : 
Navigator.pushNamed(context, '/HomePage');
                isPresse1=true;
                isPresse2=false;
                isPresse3=false;
                isPresse4=false;
              },
              title: Text(
                ""Home"",
                style: TextStyle(
                    fontSize: 18.0,
                    fontStyle: FontStyle.italic
                ),
              ),
            ),
            color: isPresse1 ? Colors.green : Colors.white
          ),
          Card(
            elevation: 5.0,
            child: ListTile(
              leading: IconButton(
                  icon: Icon(
                      Icons.assessment,
                      color: Colors.blue
                  )
              ),
              contentPadding: EdgeInsets.symmetric(
                  horizontal: 0.0,
                  vertical: 0.0
              ),
              onTap: () {
                if(isPresse2){
                  Navigator.pop(context);
                }
                else{
                  Navigator.pushNamed(context, '/MoreStatistics');
                }
                isPresse1=false;
                isPresse2=true;
                isPresse3=false;
                isPresse4=false;
              },
              title: Text(
                ""More Statistics"",
                style: TextStyle(
                  fontSize: 18.0,
                  fontStyle: FontStyle.italic,
                ),
              ),
            ),
            color: isPresse2 ? Colors.green : Colors.white
          ),
          Card(
            elevation: 5.0,
            child: ListTile(
              leading: IconButton(
                  icon: Icon(
                      Icons.book,
                      color: Colors.red
                  )
              ),
              contentPadding: EdgeInsets.symmetric(
                  horizontal: 0.0,
                  vertical: 0.0
              ),
              onTap: () {
                isPresse3 ? Navigator.pop(context) : 
Navigator.pushNamed(context, '/Guidelines');
                isPresse1=false;
                isPresse2=false;
                isPresse3=true;
                isPresse4=false;
              },
              title: Text(
                ""Guidelines"",
                style: TextStyle(
                    fontSize: 18.0,
                    fontStyle: FontStyle.italic
                ),
              ),
            ),
            color: isPresse3 ? Colors.green : Colors.white
          ),
          Card(
            elevation: 15.0,
            child: ListTile(
              leading: IconButton(
                  icon: Icon(
                    Icons.phone,
                    color: Colors.blue,
                  )
              ),
              contentPadding: EdgeInsets.symmetric(
                  horizontal: 0.0,
                  vertical: 0.0
              ),
              onTap: () {
                isPresse4 ? Navigator.pop(context) : 
Navigator.pushNamed(context, '/HelplineNumbers');
                isPresse1=false;
                isPresse2=false;
                isPresse3=false;
                isPresse4=true;
              },
              title: Text(
                ""Helpline numbers"",
                style: TextStyle(
                    fontSize: 18.0,
                    fontStyle: FontStyle.italic
                  ),
                  ),
                ),
                color: isPresse4 ? Colors.green : Colors.white
              ),
            ],
          )
      );
  }
}
</code></pre>

<p>This is my home class</p>

<pre><code>import 'package:flutter/material.dart';
import 'package:flutter/widgets.dart';
import 'package:covid19/totalcases.dart';
import 'package:covid19/totalcured.dart';
import 'package:covid19/drawer.dart';

class HomePage extends StatelessWidget {
@override
Widget build(BuildContext context) {
return Scaffold(
    backgroundColor: Colors.transparent,
    appBar: AppBar(
      backgroundColor: Colors.black,
      title: Center(
        child: Align(
          alignment: Alignment(-0.25,1.0),
          child: Text(
            ""Corona Virus- India""
          )
        )
      )
    ),
  drawer: MyDrawer(),
  body: Center(
          child: Column(
              children: [
                Divider(
                  color: Colors.white,
                ),
                Spacer(),
                Hero(
                  tag: 'lol',
                  child: Container(
                      padding: EdgeInsets.all(70.0),
                      decoration: BoxDecoration(
                          shape: BoxShape.circle,
                          color: Colors.white
                      ),
                      child: HomePageData()
                  ),
                ),
                Container(
                  padding: EdgeInsets.all(10.0),
                  child: Text(""TOTAL CASES"",
                    style: TextStyle(
                      color: Colors.white,
                    ),
                  ),
                ),
                Spacer(),
                Hero(

                  tag: 'lol2',
                  child: Container(
                    padding: EdgeInsets.all(70.0),
                    decoration: BoxDecoration(
                        shape: BoxShape.circle,
                        color: Colors.white
                    ),
                    child: HomePageData2()
                  ),
                ),
                Container(
                  padding: EdgeInsets.all(10.0),
                  child: Text(""CURED"",
                    style: TextStyle(
                      color: Colors.white,
                    ),
                  ),
                ),
                Spacer()
              ]
          )
      ),

  floatingActionButton: FloatingActionButton(
    child: Image.asset('assets/git.JPG'),
    backgroundColor: Colors.black,
    onPressed: ()=&gt;{},
  ),
  );
  }
  }
</code></pre>
"
60823037,"<p>Hello guys i'm working on an app to decrease the spread of coronavirus in my country can anyone help me on how to fully control Bluetooth ?
like the app right here in this video : <a href=""https://www.youtube.com/watch?v=6n9ZsHSc4YA"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=6n9ZsHSc4YA</a></p>
"
61444018,"<p>I am trying to validate my fields before submitting in <code>flutter</code>. But somehow it doesn't validate as the validate always comes true even if the fields are empty.</p>

<p>This is what I tried. Can someone help me to identify what I have done wrong?</p>

<p>as you can see below, I have even set the <code>validators</code> and <code>controller</code>. But still the <strong>Submission happens even when the fields are empty</strong></p>

<pre><code>class _AddNewsState extends State&lt;AddNews&gt; {
  GlobalKey&lt;FormState&gt; _key = GlobalKey&lt;FormState&gt;();

  TextEditingController _headlineController;
  TextEditingController _descriptionController;
  String _dropDownActivity;

  // get current date
  static var now = new DateTime.now();
  static var formatter = new DateFormat('yyyy-MM-dd');
  String formattedDate = formatter.format(now);

  // get current timie
  dynamic currentTime = DateFormat.jm().format(DateTime.now());

  @override
  void initState() {
    super.initState();
    _headlineController = TextEditingController();
    _descriptionController = TextEditingController();
    _dropDownActivity = """";
  }

  @override
  Widget build(BuildContext context) {
    File _image;
    String image_url = """";

    FileImage _getImage() {
      var img = (File(widget.imgPath));
      setState(() {
        _image = img;
      });
      return FileImage(_image);
    }

    Future _showToastMsg(String msgType, String msg) {
      if (msgType == ""success"") {
        return Fluttertoast.showToast(
          msg: msg,
          textColor: Colors.white,
          toastLength: Toast.LENGTH_SHORT,
          timeInSecForIosWeb: 1,
          gravity: ToastGravity.BOTTOM,
          backgroundColor: Colors.green,
        );
      } else if (msgType == ""error"") {
        return Fluttertoast.showToast(
          msg: msg,
          textColor: Colors.white,
          toastLength: Toast.LENGTH_SHORT,
          timeInSecForIosWeb: 1,
          gravity: ToastGravity.BOTTOM,
          backgroundColor: Colors.red,
        );
      } else {
        return Fluttertoast.showToast(
          msg: msg,
          textColor: Colors.white,
          toastLength: Toast.LENGTH_SHORT,
          timeInSecForIosWeb: 1,
          gravity: ToastGravity.BOTTOM,
          backgroundColor: Colors.black,
        );
      }
    }

    get_image_url_from_uploadPicture(String url) {
      image_url = url;
      return image_url;
    }

    showLoadingWhileSaving(BuildContext context) {
      AlertDialog alert = AlertDialog(
        content: new Row(
          children: [
            CircularProgressIndicator(),
            Container(margin: EdgeInsets.only(left: 5), child: Text(""Loading"")),
          ],
        ),
      );
      showDialog(
        barrierDismissible: false,
        context: context,
        builder: (BuildContext context) {
          return alert;
        },
      );
    }

    Future _uploadPicture(BuildContext context) async {
      String fileName = basename(_image.path);
      StorageReference storageReference =
          FirebaseStorage.instance.ref().child(fileName);

      StorageUploadTask storageUploadTask = storageReference.putFile(_image);

      showLoadingWhileSaving(context);
      StorageTaskSnapshot storageTaskSnapshot =
          await storageUploadTask.onComplete;

      image_url =
          await (await storageUploadTask.onComplete).ref.getDownloadURL();

      get_image_url_from_uploadPicture(image_url);

      Navigator.pop(context);

      setState(() {
        _showToastMsg(""success"", ""News Successfully Saved!"");
      });
    }

    return Scaffold(
      appBar: AppBar(
        leading: Builder(
          builder: (BuildContext context) {
            return IconButton(
              icon: const Icon(null),
              color: Colors.white,
              onPressed: () {},
            );
          },
        ),
        centerTitle: true,
        title: Text(
          ""Report a News"",
        ),
        backgroundColor: Colors.blueGrey,
      ),
      body: Container(
        child: SingleChildScrollView(
          padding: const EdgeInsets.all(26.0),
          child: Form(
            key: _key,
            child: Column(
              crossAxisAlignment: CrossAxisAlignment.start,
              mainAxisAlignment: MainAxisAlignment.start,
              children: &lt;Widget&gt;[
                Align(
                    alignment: Alignment.center,
                    child: GFImageOverlay(
                      border: Border.all(color: Colors.blueGrey, width: 4.0),
                      height: 200,
                      width: 200,
                      color: Colors.red,
                      shape: BoxShape.circle,
                      boxFit: BoxFit.fill,
                      image: (widget.imgPath != null)
                          ? _getImage()
                          : AssetImage(""images/default_news_image.png""),
                    )),
                SizedBox(
                  height: 30.0,
                ),
                TextFormField(
                  textInputAction: TextInputAction.next,
                  controller: _headlineController,
                  validator: (headline) {
                    if (headline == null || headline.isEmpty) {
                      _showToastMsg(""error"", ""Please enter a Headline"");
                    }
                  },
                  decoration: InputDecoration(
                    labelText: ""Headline"",
                    hintText: ""Covid-19 new stats"",
                    border: OutlineInputBorder(),
                    icon: Icon(Icons.add_box),
                  ),
                ),
                SizedBox(
                  height: 16.0,
                ),
                TextFormField(
                  maxLines: 5,
                  textInputAction: TextInputAction.next,
                  controller: _descriptionController,
                  validator: (description) {
                    if (description == null || description.isEmpty) {
                      _showToastMsg(""error"", ""Please provide a Headline"");
                    }
                  },
                  decoration: InputDecoration(
                    labelText: ""Description"",
                    hintText: ""Covid-19 new stats are sky-rock..."",
                    border: OutlineInputBorder(),
                    icon: Icon(Icons.message),
                  ),
                ),
                SizedBox(
                  height: 16.0,
                ),
                DropDownFormField(
                  titleText: 'Priority',
                  value: _dropDownActivity,
                  hintText: 'Select the priority',
                  onSaved: (value) {
                    setState(() {
                      _dropDownActivity = value;
                    });
                  },
                  onChanged: (value) {
                    setState(() {
                      _dropDownActivity = value;
                    });
                  },
                  validator: (value) {
                    if (value == null || value == """") {
                      _showToastMsg(""error"", ""Please select a priority"");
                    }
                  },
                  dataSource: [
                    {
                      ""display"": ""High"",
                      ""value"": ""High"",
                    },
                    {
                      ""display"": ""Medium"",
                      ""value"": ""Medium"",
                    },
                    {
                      ""display"": ""Low"",
                      ""value"": ""Low"",
                    },
                  ],
                  textField: 'display',
                  valueField: 'value',
                ),
                SizedBox(
                  height: 16.0,
                ),
                Column(
                  mainAxisAlignment: MainAxisAlignment.start,
                  crossAxisAlignment: CrossAxisAlignment.start,
                  children: &lt;Widget&gt;[
                    Row(
                      children: &lt;Widget&gt;[
                        GFButtonBadge(
                          size: GFSize.SMALL,
                          onPressed: () {
                            _showToastMsg(
                                ""other"", ""Today is : ${formattedDate}"");
                          },
                          icon: Icon(
                            Icons.calendar_today,
                            size: 16.0,
                            color: Colors.white,
                          ),
                          text: '',
                        ),
                        SizedBox(
                          width: 10.0,
                        ),
                        Text(
                          ""- ${formattedDate}"",
                          style: TextStyle(fontSize: 18.0),
                        ),
                      ],
                    ),
                    SizedBox(
                      height: 10.0,
                    ),
                    Row(
                      children: &lt;Widget&gt;[
                        GFButtonBadge(
                          size: GFSize.SMALL,
                          onPressed: () {
                            _showToastMsg(""other"", ""Time is : ${currentTime}"");
                          },
                          icon: Icon(
                            Icons.alarm,
                            size: 16.0,
                            color: Colors.white,
                          ),
                          text: '',
                        ),
                        SizedBox(
                          width: 10.0,
                        ),
                        Text(
                          ""- ${currentTime}"",
                          style: TextStyle(fontSize: 18.0),
                        ),
                      ],
                    ),
                    SizedBox(
                      height: 14.0,
                    ),
                  ],
                ),
                Align(
                  alignment: Alignment.center,
                  child: Text(
                    ""Date and time will be saved automaticallt on \""Save\"""",
                    textAlign: TextAlign.center,
                    style: TextStyle(
                      color: Colors.grey,
                    ),
                  ),
                ),
                SizedBox(
                  height: 20.0,
                ),
                Row(
                  crossAxisAlignment: CrossAxisAlignment.end,
                  mainAxisAlignment: MainAxisAlignment.spaceEvenly,
                  children: &lt;Widget&gt;[
                    RaisedButton.icon(
                      icon: Icon(Icons.refresh),
                      color: Colors.orange,
                      textColor: Colors.white,
                      label: Text(""Retake""),
                      onPressed: () async {
                        Navigator.of(context).pop();
                      },
                    ),
                    RaisedButton.icon(
                      icon: Icon(Icons.add_a_photo),
                      color: Colors.green,
                      textColor: Colors.white,
                      label: Text(""Snap""),
                      onPressed: () async {
                        try {
                          // first upload the photo
                          if (_key.currentState.validate()) {
                            _showToastMsg(""other"",
                                get_image_url_from_uploadPicture(""cool""));
                          } else {
                            _showToastMsg(""other"",
                                get_image_url_from_uploadPicture(""empty""));
                          }

                          // await FireStoreServiceApi().add_news(News(
                          //   headline: _headlineController.text,
                          //   description: _descriptionController.text,
                          //   imageUrl: image_url,
                          //   timeNews: currentTime.toString(),
                          //   timeDate: formattedDate.toString(),
                          //   priority: _dropDownActivity.toString(),
                          // ));
                        } catch (e) {
                          print(e);
                        }
                      },
                    ),
                  ],
                ),
              ],
            ),
          ),
        ),
      ),
    );
  }
}
</code></pre>

<p><strong>Tell me where I have gone wrong and how to fix that</strong></p>

<p>Thank you.</p>
"
61504283,"<p>I am trying to set a value to the <code>TextFormField</code> in <code>flutter</code>.</p>

<p>But I couldn't find a way to do that.</p>

<p>this is how my <code>widget</code> looks like:</p>

<pre><code>Widget _showHeadlineField() {
      return TextFormField(
        textInputAction: TextInputAction.next,
        onEditingComplete: () {
          FocusScope.of(context).requestFocus(_descriptionNode);
        },
        controller: _headlineController,

        validator: (headline) {
          if (headline == null || headline.isEmpty) {
            return ""Headline cannot be empty"";
          }
        },
        decoration: InputDecoration(
          labelText: ""Headline"",
          hintText: ""Covid-19 new stats"",
          border: OutlineInputBorder(),
          icon: Icon(Icons.add_box),

        ),
      );
    }
</code></pre>

<p>I even tried <code>initialValue</code> but doesn't work. Can someone help me?</p>
"
61089855,"<p>I'm writing a really simple app in Flutter, but I have a problem with state management. </p>

<p>Here's the video of what I have. Link: <a href=""https://streamable.com/ir3ztr"" rel=""nofollow noreferrer"">https://streamable.com/ir3ztr</a></p>

<p>The video shows my application, but when I switch a screen using Bottom Navigation Bar, the data loads again and again from the API. I don't want that. I want the once downloaded data to be saved in RAM and not being downloaded again from the API. Is that possible? I heard about Provider, but I don't know how to use that in my case. </p>

<p>Is there anyone who can help me?</p>

<p>My code: </p>

<h2>World</h2>

<pre class=""lang-dart prettyprint-override""><code>import 'package:flutter/material.dart';
import 'package:easy_localization/easy_localization.dart';
import 'package:flutter_placeholder_textlines/flutter_placeholder_textlines.dart';
import '../../models/world.dart';
import '../../data/world_service.dart';

class WorldScreenAndroid extends StatefulWidget {
  @override
  _WorldScreenAndroidState createState() =&gt; _WorldScreenAndroidState();
}

class _WorldScreenAndroidState extends State&lt;WorldScreenAndroid&gt; {
  Future&lt;World&gt; futureWorld;

  @override
  void initState() {
    super.initState();
    futureWorld = fetchWorld();
  }

  @override
  Widget build(BuildContext context) {
    return Container(
      padding: EdgeInsets.all(8.0),
      child: FutureBuilder&lt;World&gt; (
        future: futureWorld,
        builder: (context, snapshot) {

          if (snapshot.hasData) {
            return ListView(
            children: [
              Card(
                child: ListTile(
                  leading: Icon(Icons.public),
                  title: Text('coronavirus_cases').tr(context: context),
                  subtitle: Text(NumberFormat('#,###,###', 'en_US').format(snapshot.data.cases).toString())
                ),
              ),
              Card(
                child: ListTile(
                  leading: Icon(Icons.public),
                  title: Text('deaths').tr(context: context),
                  subtitle: Text(NumberFormat('#,###,###', 'en_US').format(snapshot.data.deaths).toString())
                ),
              ),
              Card(
                child: ListTile(
                  leading: Icon(Icons.public),
                  title: Text('recovered').tr(context: context),
                  subtitle: Text(NumberFormat('#,###,###', 'en_US').format(snapshot.data.recovered).toString())
                ),
              )
            ],
          );
        }

          return ListView(
            children: [
              Card(
                child: ListTile(
                  leading: Icon(Icons.public),
                  title: Text('coronavirus_cases').tr(context: context),
                  subtitle: PlaceholderLines(
                    count: 1,
                    animate: true,
                    color: Colors.grey,
                    minWidth: 0.10,
                    maxWidth: 0.50,
                  ),
                ),
              ),
              Card(
                child: ListTile(
                  leading: Icon(Icons.public),
                  title: Text('deaths').tr(context: context),
                  subtitle: PlaceholderLines(
                    count: 1,
                    animate: true,
                    color: Colors.grey,
                    minWidth: 0.10,
                    maxWidth: 0.50,
                  ),
                ),
              ),
              Card(
                child: ListTile(
                  leading: Icon(Icons.public),
                  title: Text('recovered').tr(context: context),
                  subtitle: PlaceholderLines(
                    count: 1,
                    animate: true,
                    color: Colors.grey,
                    minWidth: 0.10,
                    maxWidth: 0.50,
                  ),
                ),
              )
            ],
          );
        },
      ) 
    );
  }
}
</code></pre>

<h2>Countries</h2>

<pre class=""lang-dart prettyprint-override""><code>import 'package:flutter/material.dart';
import 'package:easy_localization/easy_localization.dart';
import '../../models/country.dart';
import '../../data/countries_service.dart';

class CountriesScreenAndroid extends StatefulWidget {
  @override
  _CountriesScreenAndroidState createState() =&gt; _CountriesScreenAndroidState();
}

class _CountriesScreenAndroidState extends State&lt;CountriesScreenAndroid&gt; {
  Future&lt;List&lt;Country&gt;&gt; futureCountries;

  @override
  void initState() {
    super.initState();
    futureCountries = fetchCountries();
  }

  @override
  Widget build(BuildContext context) {
    return Container(
      padding: EdgeInsets.all(8.0),
      child: FutureBuilder(
        future: futureCountries,
        builder: (context, snapshot) {
          if (snapshot.hasData) {
            return Column(
              children: [
                TextField(),
                SizedBox(height: 10.0),
                Expanded(
                  child: ListView.builder(
                    itemCount: snapshot.data.length,
                    itemBuilder: (context, index) {

                      final List&lt;String&gt; _countriesAllArgs = [
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].cases),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].todayCases),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].active),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].deaths),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].todayDeaths),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].recovered),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].critical)
                      ];

                      return Card(
                        child: Padding(
                          padding: EdgeInsets.all(12.0),
                          child: Column(
                            crossAxisAlignment: CrossAxisAlignment.stretch,
                            children: [
                              Text(
                                snapshot.data[index].country,
                                style: TextStyle(
                                  fontSize: 18.0,
                                  color: Colors.grey[600],
                                ),
                              ),
                              SizedBox(height: 6.0),
                              Text(
                                'countries_all',
                                style: TextStyle(
                                  fontSize: 14.0,
                                  color: Colors.grey[800],
                                ),
                              ).tr(args: _countriesAllArgs),
                            ],
                          ),
                        )
                      );
                    }
                  ),
                )
              ],
            );
          }

          return Center(
            child: CircularProgressIndicator(),
          );
        },
      )
    );
  }
}
</code></pre>
"
61139776,"<p>I am writing a really simple app for coronavirus cases, however I have a problem. I have no clue how to create a filterable Search Bar, where I can search for any result in my ListView. I fetch some data from an API and use that for my Future Builder.</p>

<p>Is there anyone here, who can help me create it?</p>

<h1>My code</h1>

<h2>Countries screen</h2>

<pre class=""lang-dart prettyprint-override""><code>import 'package:flutter/material.dart';
import 'package:easy_localization/easy_localization.dart';
import '../../models/country.dart';
import '../../data/countries_service.dart';

class CountriesScreenAndroid extends StatefulWidget {
  @override
  _CountriesScreenAndroidState createState() =&gt; _CountriesScreenAndroidState();
}

class _CountriesScreenAndroidState extends State&lt;CountriesScreenAndroid&gt; {
  Future&lt;List&lt;Country&gt;&gt; futureCountries;

  @override
  void initState() {
    super.initState();
    futureCountries = fetchCountries();
  }

  @override
  Widget build(BuildContext context) {
    return Container(
      padding: EdgeInsets.all(8.0),
      child: FutureBuilder(
        future: futureCountries,
        builder: (context, snapshot) {
          if (snapshot.hasData) {
            return Column(
              children: [
                TextField(
                  decoration: InputDecoration(
                    fillColor: Colors.white,
                    border: OutlineInputBorder(
                      borderRadius: BorderRadius.circular(25.0)
                    )
                  ),
                ),
                SizedBox(height: 10.0),
                Expanded(
                  child: ListView.builder(
                    itemCount: snapshot.data.length,
                    itemBuilder: (BuildContext context, int index) {

                      final List&lt;String&gt; _countriesAllArgs = [
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].cases),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].todayCases),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].active),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].deaths),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].todayDeaths),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].recovered),
                        NumberFormat('#,###,###', 'en_US').format(snapshot.data[index].critical)
                      ];

                      return Card(
                        child: Padding(
                          padding: EdgeInsets.all(12.0),
                          child: Column(
                            crossAxisAlignment: CrossAxisAlignment.stretch,
                            children: [
                              Text(
                                snapshot.data[index].country,
                                style: TextStyle(
                                  fontSize: 18.0,
                                  color: Colors.grey[600],
                                ),
                              ),
                              SizedBox(height: 6.0),
                              Text(
                                'countries_all',
                                style: TextStyle(
                                  fontSize: 14.0,
                                  color: Colors.grey[800],
                                ),
                              ).tr(args: _countriesAllArgs),
                            ],
                          ),
                        )
                      );
                    }
                  ),
                )
              ],
            );
          }

          return Center(
            child: CircularProgressIndicator(),
          );
        },
      )
    );
  }
}
</code></pre>

<p><a href=""https://i.stack.imgur.com/dCGep.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dCGep.png"" alt=""enter image description here""></a></p>
"
61324236,"<p>I am trying to parse 'topojson' files of '<a href=""https://github.com/covid19india/covid19india-react/tree/master/public/maps"" rel=""nofollow noreferrer"">https://github.com/covid19india/covid19india-react/tree/master/public/maps</a>' and render it on home screen on android(flutter) app.</p>

<p>I am not clear about how to parse and render 'topojson' file. </p>

<p>Kindly Share any resources, which would help me to solve above problem. Thank You.</p>
"
61150057,"<p>Problem: 
I can create exercises and add to the animated list in CustomExScreen.</p>

<p>When I return to the previous stack level, being the MenuScreen(), then revisit my exercise list my previously submitted data is removed. How do I save the data state even when leaving the widget? Save the stack and restore it. Thanks in advance!</p>

<p>CustomExScreenState</p>

<pre><code>class CustomExScreen extends StatefulWidget {
  @override
  CustomExScreenState createState() =&gt; CustomExScreenState();
}

class CustomExScreenState extends State&lt;CustomExScreen&gt;
    with TickerProviderStateMixin {
  List&lt;Exerciselist&gt; items = new List&lt;Exerciselist&gt;();
  GlobalKey&lt;AnimatedListState&gt; animatedListKey = GlobalKey&lt;AnimatedListState&gt;();
  AnimationController emptyListController;

  @override
  void initState() {
    emptyListController = AnimationController(
      vsync: this,
      duration: Duration(milliseconds: 200),
    );
    emptyListController.forward();
    super.initState();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: Text(
          'CUSTOM EXERCISES',
          key: Key('main-app-title'),
        ),
        centerTitle: true,
      ),
      floatingActionButton: Container(
        child: FloatingActionButton(
          child: Icon(Icons.add),
          onPressed: () =&gt; goToNewItemView(),
        ),
      ),
      body: renderBody(),
    );
  }

  Widget renderBody() {
    if (items.length &gt; 0) {
      return buildListView();
    } else {
      return emptyList();
    }
  }

  Widget emptyList() {
    return Center(
        child: FadeTransition(
            opacity: emptyListController,
            child: Text('No exercise, press + to add some!')));
  }

  Widget buildListView() {
    return AnimatedList(
      key: animatedListKey,
      initialItemCount: items.length,
      itemBuilder: (BuildContext context, int index, animation) {
        setState(() {
          buildItem(items[index], index);
        });
        return SizeTransition(
          sizeFactor: animation,
          child: buildItem(items[index], index),
        );
      },
    );
  }

  Widget buildItem(Exerciselist item, int index) {
    return Dismissible(
      key: Key('${item.hashCode}'),
      background: Container(color: Colors.red[700]),
      onDismissed: (direction) =&gt; removeItemFromList(item, index),
      direction: DismissDirection.startToEnd,
      child: buildListTile(item, index),
    );
  }

  Widget buildListTile(item, index) {
    return ListTile(
      onTap: () =&gt; changeItemCompleteness(item),
      onLongPress: () =&gt; goToEditItemView(item),
      title: Text(
        item.title,
        key: Key('item-$index'),
        style: TextStyle(
            color: item.completed ? Colors.grey : Colors.black,
            decoration: item.completed ? TextDecoration.lineThrough : null),
      ),
      trailing: Icon(
        item.completed ? Icons.check_box : Icons.check_box_outline_blank,
        key: Key('completed-icon-$index'),
      ),
    );
  }

  void changeItemCompleteness(Exerciselist item) {
    setState(() {
      item.completed = !item.completed;
    });
  }

  void goToNewItemView() {
    // Here we are pushing the new view into the Navigator stack. By using a
    // MaterialPageRoute we get standard behaviour of a Material app, which will
    // show a back button automatically for each platform on the left top corner
    Navigator.of(context).push(MaterialPageRoute(builder: (context) {
      return NewCustomExercise();
    })).then((title) {
      if (title != null) {
        addItem(Exerciselist(title: title));
      }
    });
  }

  void addItem(Exerciselist item) {
    // Insert an item into the top of our list, on index zero
    items.insert(0, item);
    if (animatedListKey.currentState != null)
      animatedListKey.currentState.insertItem(0);
  }

  void goToEditItemView(Exerciselist item) {
    // We re-use the NewTodoView and push it to the Navigator stack just like
    // before, but now we send the title of the item on the class constructor
    // and expect a new title to be returned so that we can edit the item
    Navigator.of(context).push(MaterialPageRoute(builder: (context) {
      return NewCustomExercise(item: item);
    })).then((title) {
      if (title != null) {
        editItem(item, title);
      }
    });
  }

  void editItem(Exerciselist item, String title) {
    item.title = title;
  }

  void removeItemFromList(Exerciselist item, int index) {
    animatedListKey.currentState.removeItem(index, (context, animation) {
      return SizedBox(
        width: 0,
        height: 0,
      );
    });
    deleteItem(item);
  }

  void deleteItem(Exerciselist item) {
    // We don't need to search for our item on the list because Dart objects
    // are all uniquely identified by a hashcode. This means we just need to
    // pass our object on the remove method of the list
    items.remove(item);
    if (items.isEmpty) {
      emptyListController.reset();
      setState(() {});
      emptyListController.forward();
    }
  }
}
</code></pre>

<p>Exerciselist</p>

<pre><code>class Exerciselist {
  String title;
  bool completed;

  Exerciselist({
    this.title,
    this.completed = false,
  });

  Exerciselist.fromMap(Map&lt;String, dynamic&gt; map)
      : title = map['title'],
        completed = map['completed'];

  updateTitle(title) {
    this.title = title;
  }

  Map toMap() {
    return {
      'title': title,
      'completed': completed,
    };
  }
}
</code></pre>

<p>MenuScreen</p>

<pre><code>class MenuScreen extends StatefulWidget {
  @override
  _MenuScreenState createState() =&gt; _MenuScreenState();
}

class _MenuScreenState extends State&lt;MenuScreen&gt; {
  int difficulty = 2;

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: kBackgroundColour,
      appBar: AppBar(
        backgroundColor: kButtonAndBarColour,
        title: Text('COVID-19 WORKOUTS', style: kTitleStyle),
      ),
      body: Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          crossAxisAlignment: CrossAxisAlignment.center,
          children: &lt;Widget&gt;[
            RaisedButton(
              elevation: 100.0,
              color: kButtonAndBarColour,
              child: Text('CARDIO', style: kTitleStyle),
              onPressed: () {
                //NEED TO UPDATE STATE AND HAVE NEW DATA FOR CARDIO SCREEN
                FeedDifficulty cardioDifficulty =
                    FeedDifficulty(difficulty: difficulty);
                GenerateCardio generateCardio =
                    GenerateCardio(difficulty: difficulty);
                Navigator.push(
                  context,
                  MaterialPageRoute(
                      builder: (context) =&gt; CardioScreen(
                            cardioDifficulty:
                                cardioDifficulty.checkDifficulty(),
                            cardioWorkout1: generateCardio.cExerciseOne(),
                            cardioWorkout2: generateCardio.cExerciseTwo(),
                            cardioWorkout3: generateCardio.cExerciseThree(),
                            cardioWorkout4: generateCardio.cExerciseFour(),
                            cardioWorkout5: generateCardio.cExerciseFive(),
                          )),
                );
                print('Cardio Pressed');
              },
            ),
            SizedBox(
              height: 20.0,
            ),
            RaisedButton(
              elevation: 100.0,
              color: kButtonAndBarColour,
              child: Text(
                'STRENGTH &amp; ENDURANCE',
                style: kTitleStyle,
              ),
              onPressed: () {
                FeedDifficulty strengthWorkout =
                    FeedDifficulty(difficulty: difficulty);
                GenerateStrength generateStrength =
                    GenerateStrength(difficulty: difficulty);
                Navigator.push(
                  context,
                  MaterialPageRoute(
                    builder: (context) =&gt; StrengthScreen(
                      strengthDifficulty: strengthWorkout.checkDifficulty(),
                      strengthWorkout1: generateStrength.sExerciseOne(),
                      strengthWorkout2: generateStrength.sExerciseTwo(),
                      strengthWorkout3: generateStrength.sExerciseThree(),
                      strengthWorkout4: generateStrength.sExerciseFour(),
                      strengthWorkout5: generateStrength.sExerciseFive(),
                    ),
                  ),
                );
//                Navigator.pushNamed(context, '/strength');
                print('Strength Pressed');
              },
            ),
            RaisedButton(
              elevation: 100.0,
              color: kButtonAndBarColour,
              child: Text(
                'CUSTOM WORKOUT',
                style: kTitleStyle,
              ),
              onPressed: () {
                Navigator.push(context, MaterialPageRoute(builder: (context) {
                  return CustomExScreen(
                      //construct
                      );
                }));
//                Navigator.pushNamed(context, '/strength');
                print('CUSTOM Pressed');
              },
            ),
            SliderTheme(
              data: SliderTheme.of(context).copyWith(
                inactiveTrackColor: Color(0xFF8D8E98),
                activeTrackColor: Colors.white,
                thumbColor: Color(0xFFEB1555),
                overlayColor: Color(0x29EB1555),
                thumbShape: RoundSliderThumbShape(enabledThumbRadius: 15.0),
                overlayShape: RoundSliderOverlayShape(overlayRadius: 30),
              ),
              child: Slider(
                value: difficulty.toDouble(),
                min: 1.0,
                max: 3.0,
                onChanged: (double newValue) {
                  setState(() {
                    difficulty = newValue.round();
                    print(difficulty);
                  });
                },
              ),
            ),
            Text(
              difficulty.toString(),
              style: kTitleStyleDark,
            ),
            SizedBox(height: 8.0),
            Text(
              'DIFFICULTY',
              style: kTitleStyleDark,
            ),
          ],
        ),
      ),
    );
  }
}

</code></pre>
"
61497021,"<p>I'm building a COVID tracker and i have some json data from where i want to create a list, which i'll then use in a dropdown .. the json format is in the form of an array like:</p>

<pre><code>statewise:
    0:
        state: state1
    1: 
        state: state2
    etc ..

</code></pre>

<p>I tried hardcoding it, but the value of state keeps changing it, according to the no of COVID cases. For eg, in the above code, state1 is at 0: index since it has more cases than state2. But if the no of cases of state2 increases to more than that of state1, then the new json is like this</p>

<pre><code>statewise:
    0:
        state: state2
    1: 
        state: state1
    etc ..

</code></pre>

<p>How do I create a list that automatically changes when the data in the json changes? I have tried this so far, but it doesnt work</p>

<pre><code>if (snapshot.hasData) {             
              for(int a = 0; a&lt;_state(snapshot.data); a++) {
               getState.insert(a, _state(snapshot.data[a]).toString());
             }
</code></pre>

<p>the _state function</p>

<pre><code>_state(dynamic data) {
    return data['state'];
  }
</code></pre>

<p>the api function</p>

<pre><code>Future&lt;dynamic&gt; fetchData() async {
    var result = await http.get(apiUrl);
    return json.decode(result.body)['statewise'];
  }
</code></pre>

<p>How do I create a list that automatically changes when the data in the json changes?</p>
"
61575049,"<p>I created a search function with new class <code>extends SearchDelegate</code>. And I want to custom appBar <code>background color</code>, <code>font size</code>. How to achieve this?</p>

<p>My search class</p>

<pre><code>import 'package:flutter/material.dart';

class Search extends SearchDelegate {
  final List countryList;

  Search(this.countryList);

  @override
  List&lt;Widget&gt; buildActions(BuildContext context) {
    return [
      IconButton(
        icon: Icon(Icons.clear),
        onPressed: () {
          query = '';
        },
      )
    ];
  }

  @override
  Widget buildLeading(BuildContext context) {
    return IconButton(
      icon: Icon(Icons.arrow_back_ios),
      onPressed: () {
        Navigator.pop(context);
      },
    );
  }

  @override
  Widget buildResults(BuildContext context) {
    return Container();
  }

  @override
  Widget buildSuggestions(BuildContext context) {
    final suggestionList = query.isEmpty
        ? countryList
        : countryList
            .where((element) =&gt;
                element['country'].toString().toLowerCase().startsWith(query))
            .toList();

    return ListView.builder(
      itemCount: suggestionList.length,
      itemBuilder: (context, index) {
        return Card(
          child: Container(
            height: 70,
            margin: EdgeInsets.symmetric(horizontal: 10, vertical: 10),
            child: Row(
              children: &lt;Widget&gt;[
                Container(
                  width: 200,
                  margin: EdgeInsets.symmetric(horizontal: 10),
                  child: Column(
                    crossAxisAlignment: CrossAxisAlignment.start,
                    mainAxisAlignment: MainAxisAlignment.center,
                    children: &lt;Widget&gt;[
                      Text(
                        suggestionList[index]['country'],
                        style: TextStyle(fontWeight: FontWeight.bold),
                      ),
                      Image.network(
                        suggestionList[index]['countryInfo']['flag'],
                        height: 50,
                        width: 60,
                      ),
                    ],
                  ),
                ),
                Expanded(
                    child: Container(
                  child: Column(
                    children: &lt;Widget&gt;[
                      Text(
                        'CONFIRMED:' +
                            suggestionList[index]['cases'].toString(),
                        style: TextStyle(
                          fontWeight: FontWeight.bold,
                          color: Colors.red,
                        ),
                      ),
                      Text(
                        'ACTIVE:' + suggestionList[index]['active'].toString(),
                        style: TextStyle(
                          fontWeight: FontWeight.bold,
                          color: Colors.blue,
                        ),
                      ),
                      Text(
                        'RECOVERED:' +
                            suggestionList[index]['recovered'].toString(),
                        style: TextStyle(
                          fontWeight: FontWeight.bold,
                          color: Colors.green,
                        ),
                      ),
                      Text(
                        'DEATHS:' + suggestionList[index]['deaths'].toString(),
                        style: TextStyle(
                          fontWeight: FontWeight.bold,
                          color: Theme.of(context).brightness == Brightness.dark
                              ? Colors.grey[100]
                              : Colors.grey[900],
                        ),
                      ),
                    ],
                  ),
                ))
              ],
            ),
          ),
        );
      },
    );
  }
}
</code></pre>

<p>This class create a appbar like this</p>

<p><a href=""https://i.stack.imgur.com/2i7f2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2i7f2.png"" alt=""enter image description here""></a></p>

<p>When I try to change backgound color use</p>

<pre><code>ThemeData appBarTheme(BuildContext context) {
  return ThemeData(
    primaryColor: Color(0xff202c3b),
  );
}
</code></pre>

<p>Background color changed but some style are changed too</p>

<p><a href=""https://i.stack.imgur.com/j7ucW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/j7ucW.png"" alt=""enter image description here""></a></p>

<p>I want to custom a little bit style like</p>

<ul>
<li>Font size <code>bigger</code></li>
<li>Font color <code>to white</code></li>
<li>Don't use <code>underline</code></li>
</ul>

<p>How to achieve this? I can't find any <code>TextStyle</code> or something like that</p>

<p><strong>EDITED</strong></p>

<p><strong>CountryPage</strong> class for use search</p>

<pre><code>import 'package:flutter/material.dart';
import 'package:http/http.dart' as http;
import 'dart:convert';

import 'package:tgd_covid_tracker/pages/search.dart';

class CountryPage extends StatefulWidget {
  @override
  _CountryPageState createState() =&gt; _CountryPageState();
}

class _CountryPageState extends State&lt;CountryPage&gt; {
  List countryData;

  fetchCountryData() async {
    if (this.mounted) {
      http.Response response =
          await http.get('https://corona.lmao.ninja/v2/countries');
      setState(() {
        countryData = json.decode(response.body);
      });
    }
  }

  @override
  void initState() {
    fetchCountryData();
    super.initState();
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        centerTitle: true,
        actions: &lt;Widget&gt;[
          countryData == null
              ? Container()
              : searchButton(
                  context,
                  countryData,
                ),
        ],
        title: Text('Country Stats'),
      ),
      body: countryData == null
          ? Center(
              child: CircularProgressIndicator(),
            )
          : ListView.builder(
              itemBuilder: (context, index) {
                return Card(
                  child: Container(
                    height: 70,
                    margin: EdgeInsets.symmetric(horizontal: 10, vertical: 10),
                    child: Row(
                      children: &lt;Widget&gt;[
                        Container(
                          width: 200,
                          margin: EdgeInsets.symmetric(horizontal: 10),
                          child: Column(
                            crossAxisAlignment: CrossAxisAlignment.start,
                            mainAxisAlignment: MainAxisAlignment.center,
                            children: &lt;Widget&gt;[
                              Text(
                                countryData[index]['country'],
                                style: TextStyle(fontWeight: FontWeight.bold),
                              ),
                              Image.network(
                                countryData[index]['countryInfo']['flag'],
                                height: 50,
                                width: 60,
                              ),
                            ],
                          ),
                        ),
                        Expanded(
                          child: Container(
                            child: Column(
                              children: &lt;Widget&gt;[
                                Text(
                                  'CONFIRMED:' +
                                      countryData[index]['cases'].toString(),
                                  style: TextStyle(
                                    fontWeight: FontWeight.bold,
                                    color: Colors.red,
                                  ),
                                ),
                                Text(
                                  'ACTIVE:' +
                                      countryData[index]['active'].toString(),
                                  style: TextStyle(
                                    fontWeight: FontWeight.bold,
                                    color: Colors.blue,
                                  ),
                                ),
                                Text(
                                  'RECOVERED:' +
                                      countryData[index]['recovered']
                                          .toString(),
                                  style: TextStyle(
                                    fontWeight: FontWeight.bold,
                                    color: Colors.green,
                                  ),
                                ),
                                Text(
                                  'DEATHS:' +
                                      countryData[index]['deaths'].toString(),
                                  style: TextStyle(
                                    fontWeight: FontWeight.bold,
                                    color: Theme.of(context).brightness ==
                                            Brightness.dark
                                        ? Colors.grey[100]
                                        : Colors.grey[900],
                                  ),
                                ),
                              ],
                            ),
                          ),
                        )
                      ],
                    ),
                  ),
                );
              },
              itemCount: countryData == null ? 0 : countryData.length,
            ),
    );
  }
}

Widget searchButton(BuildContext context, countryData) {
  return IconButton(
    icon: Icon(Icons.search),
    onPressed: () {
      showSearch(context: context, delegate: Search(countryData));
    },
  );
}
</code></pre>
"
61014928,"<p>I want to make multiple calls at the same time using retrofit. When both calls end, I want to make something with the results.</p>

<p>Here is my interface</p>

<pre><code>public interface IService {
    @GET(""all"")
    Observable&lt;Global&gt; getGlobal();

    @GET(""countries"")
    Observable&lt;Country&gt; getCountries();
}
</code></pre>

<p>This is my incomplete code</p>

<pre><code>Retrofit retrofit = new Retrofit.Builder()
                .baseUrl(""https://coronavirus-19-api.herokuapp.com/"")
                .addConverterFactory(GsonConverterFactory.create())
                .addCallAdapterFactory(RxJava3CallAdapterFactory.create())
                .build();

        IService api = retrofit.create(IService.class);

        List&lt;Observable&lt;?&gt;&gt; requests = new ArrayList&lt;&gt;();
        requests.add(api.getGlobal());
        requests.add(api.getCountries());
</code></pre>
"
60755397,"<p>I'm trying to scrape some data from table on this site:<a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a></p>

<p>Here is the source code of scraper I've tried</p>

<pre><code> public static void main(String[] args) throws Exception {

    String url = ""https://www.worldometers.info/coronavirus/"";
    try{
        Document doc = Jsoup.connect(url).get();
        Element table = doc.getElementById(""main_table_countries_today"");
        Elements rows = table.getElementsByTag(""tr"");

        for(Element row : rows){
            Elements tds = row.getElementsByTag(""td"");

            for(int i = 0;i&lt;tds.size();i++){
                System.out.println(tds.get(i).text());
            }
        }

    }catch (IOException e){
        e.printStackTrace();
    }
}
</code></pre>

<p>And here is the output 
China
80,928
+34
3,245
+8
70,420
7,263
2,274
56
Italy
35,713 ....</p>

<p>I would like to scrape only data for one specific country,eg. France.
But I don't have any idea how to do it.</p>
"
60962823,"<p>I have some stock data that I have imported from excel to model in Nebula. I have the visualizations for the graph working, but I'm having trouble formatting the time along the x-axis properly. I tried creating a temp x array with 1 data point for each coordinate value, and I've successfully created a date array of the same length. It seems to me I should be able to tell Nebula to use my date array for the labels on the x-axis, but I can't figure out what parameter of get x-axis to modify. Right now, with the date format enabled, it starts at Oct 1 1969 and then has unlabeled tick marks until the last one which also says Oct 1 1969 (default value?) Here's some of my code:</p>

<pre><code>    //Data source
    List&lt;Book&gt; stocks = readBooksFromCSV(""COVID_DJI.csv"");
    for (Book b : stocks) {
        System.out.println(b);
    }

            //Create arrays that can hold output
            double[] opening;
            double[] closing;
            String[] time;
            int len = stocks.size();
            opening = new double[len];
            closing = new double[len];
            time = new String[len];
            int j = 0;
            for (Book x : stocks) {
                double o_value = x.getOpen();
                double c_value = x.getClose();
                String d_value = x.getDate();
                opening[j] = o_value;
                closing[j] = c_value;
                time[j] = d_value;
                j++;
            }

            Date[] dates = new Date[len];
            SimpleDateFormat df = new SimpleDateFormat(""dd/MM/yyyy"");
            for(int i = 0; i &lt; len; i++) {
                try {
                    dates[i] = df.parse(time[i]);
                }
                catch(ParseException e) {
                    System.out.println(""Ooof..."");
                }
            }

            //Create temp x array
            double[] temp;
            temp = new double[len];
            for (int i = 0; i &lt; len; i++) {
                temp[i] = i;
            }

            //Shell window generation and lightweight system- omitted

    XYGraph xyGraph = new XYGraph();
    xyGraph.setTitle(""DJIA PPS During COVID-19 Outbreak"");

    //Set Axis Bounds
    double min = opening[0];
    for(int i = 0; i &lt; len; i++) {
        if(opening[i] &lt; min) {
            min = opening[i];
        }
    }
    double max = opening[0];
    for(int i = 0; i &lt; len; i++) {
        if(opening[i] &gt; max) {
            max = opening[i];
        }
    }
    double drop = ((max - min)/max) * 100;
    System.out.println(""Peak to trough drop: "" + drop + ""%"");

    //Set axis parameters **I think this is where I need to change a parameter
    xyGraph.getPrimaryXAxis().setRange(0, len);
    xyGraph.getPrimaryXAxis().setDateEnabled(true);
    xyGraph.getPrimaryXAxis().setTimeUnit(Calendar.DATE);
    xyGraph.getPrimaryXAxis().setFormatPattern(""yyyy-MM-dd"");
    xyGraph.getPrimaryXAxis().setMajorGridStep(7);
    xyGraph.getPrimaryYAxis().setRange(min-100,max+100);
    xyGraph.getPrimaryYAxis().setFormatPattern(""$00000.00"");
    xyGraph.getPrimaryXAxis().setTitle(""Day"");
    xyGraph.getPrimaryYAxis().setTitle(""Price Per Share"");

    //Plot graph
    lws.setContents(xyGraph);

    //Trace implementation- omitted
</code></pre>
"
60820772,"<p>I'm trying to fetch <strong>Report coronavirus cases</strong> table data from <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a> to my android app using java.</p>

<p><a href=""https://i.stack.imgur.com/xYCyX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xYCyX.png"" alt=""Report coronavirus cases""></a>
for example,</p>

<p>so I have an object called country and instance of the object are countryName, TotalCase, Total death, etc. and then I will store the object in an arrayList.</p>

<p>here is my code</p>

<pre><code>import android.os.AsyncTask;
import org.jsoup.Jsoup;
import org.jsoup.nodes.Document;
import org.jsoup.select.Elements;

public class SammaryHandler extends AsyncTask&lt;Void,Void,Void&gt; {
    @Override
    protected Void doInBackground(Void... voids) {
        try{
            Document document= Jsoup.connect(""https://www.worldometers.info/coronavirus/"").userAgent(""mozilla/17.0"").get();
//            Elements temp= document.select(""table table-bordered table-hover main_table_countries dataTable no-footer"");

            Elements temp= document.select(""table.dataTable"");//?????????????????

            int size= temp.size();
            for(int i=0; i&lt;size;i++){
                String data= temp.select(""table.dataTable"").eq(i).attr("""");//?????????????
                System.out.println(data);
            }
        }catch (Exception e){
            System.out.println(e);
        }
        return null;
    }
    @Override
    protected void onPreExecute() {
        super.onPreExecute();
    }
    @Override
    protected void onPostExecute(Void aVoid) {
        super.onPostExecute(aVoid);
    }
    @Override
    protected void onCancelled() {
        super.onCancelled();
    }
}

</code></pre>

<p>So how can I read all of the data from the table and save load in the object?</p>

<p><strong>Please help me</strong></p>

<p>Thanks.</p>
"
61409105,"<p>I have this paragraph(this is just a random text) which I want to remove the last part of the paragraph. I have tried using <code>replaceAll</code> but it only works for shorter sentences, for example, <strong>The virus that causes COVID-19</strong> </p>

<p>but I want to remove: <strong>You can be infected by breathing in the virus if you are within close proximity of someone who has COVID-19, or by touching a contaminated surface and then your eyes, nose or mouth.\n\nMost people who fall sick with COVID-19 will experience mild to moderate symptoms and recover without special treatment.</strong></p>

<p>"" The virus that causes COVID-19 is mainly transmitted through droplets generated when an infected person coughs, sneezes, or exhales. These droplets are too heavy to hang in the air, and quickly fall on floors or surfaces.\n\nYou can be infected by breathing in the virus if you are within close proximity of someone who has COVID-19, or by touching a contaminated surface and then your eyes, nose or mouth.\n\nMost people who fall sick with COVID-19 will experience mild to moderate symptoms and recover without special treatment.""</p>

<pre><code>  String comment = ""The virus that causes COVID-19 is mainly transmitted through droplets generated when an infected person coughs, sneezes, or exhales. These droplets are too heavy to hang in the air, and quickly fall on floors or surfaces.\n\nAlso, SOS stands for Style Or Service and we?re here to help you with all your shopping needs. Feel free to contact us at 1.877.765.3009 or e-mail us at sos@solesociety.com. #mysolesociety Have a great day! Feel free to contact us at 855-435-5050 or customerservice@vincecamuto.com if you have any further questions or concerns. Have a great day!""

//produces the right result.
println(comment.replaceAll(""Also, SOS stands"", "" "")) 
</code></pre>

<pre><code>//this does not produce the right result, instead it prints the entire paragraph with this part included.
println(comment.replaceAll(""Also, SOS stands for Style Or Service and we?re here to help you with all your shopping needs. Feel free to contact us at 1.877.765.3009 or e-mail us at sos@solesociety.com. #mysolesociety Have a great day! Feel free to contact us at 855-435-5050 or customerservice@vincecamuto.com if you have any further questions or concerns. Have a great day!"", "" "")) 
</code></pre>

<p>Please help with suggestions on how to go about this</p>
"
61559025,"<p>I have an URL's which I like to parse by a java app.
These urls can have characters, which can't be called by :</p>

<pre><code>url.openStream()
</code></pre>

<p>example:</p>

<pre><code>https://en.wikipedia.org/w/api.php?format=json&amp;action=query&amp;prop=langlinks&amp;titles=2019–20_coronavirus_pandemic&amp;redirects=&amp;lllimit=400
</code></pre>

<p>there is a character – in it (2019–20_coronavirus_pandemic), which I have to encode. Resp. I would like to encode the complete URL, because it could have other special characters.</p>

<p>I am doing this as follow, which doesn't work for me:</p>

<pre><code>String urlEncoded = URLEncoder.encode(wikiID, StandardCharsets.UTF_8.toString());
String sURL = ""https://en.wikipedia.org"" + ""/w/api.php?format=json&amp;action=query&amp;prop=langlinks&amp;titles="" + urlEncoded + ""&amp;redirects=&amp;lllimit=400"";
    URL url = new URL(sURL);
    BufferedReader reader = new BufferedReader(new InputStreamReader(url.openStream(), ""UTF-8""));
</code></pre>

<p>URLEncoder.encode encodes 2019–20 to 2019%3F20, which is not correct, resp. can't be called.
correct encoding would be : 2019%E2%80%9320</p>

<p>Howto encode the url by code correctly ?</p>
"
60682497,"<p>I wanted to attempt to write a program in java or python in order to parse a large amount of data and calculate what the % decrease the Coronavirus has caused in stock value for a class in finance I'm taking, and wanted to run through the real-time and 3 month ago historical values for a number of top companies. Is there a way to access this data via an importable publicly accessible java library?</p>
"
61690360,"<p>I am trying to display different Components when I click a button with my OnClick in the Render Function of my App.js. </p>

<p>I would like to show a certain component when the button is clicked and it hides the other components. </p>

<p>this is an example of what I want to do</p>

<pre class=""lang-js prettyprint-override""><code>    return (
      &lt;div className={styles.container}&gt;
        &lt;img className={styles.image} src={image} alt=""COVID-19"" /&gt;

      //If the Country Button which is the default is clicked show This 

          &lt;ThemeProvider theme = {theme}&gt;
            &lt;CountryPicker handleCountryChange={this.handleCountryChange} /&gt;
            &lt;CountryCards CountryData = {CountryData} CountryYesterdayData = {CountryYesterdayData}/&gt;
            &lt;/ThemeProvider&gt;
            &lt;Chart countrydailydata ={countrydailydata} /&gt;

    //If the State Button is clicked show this 

    &lt;ThemeProvider theme= {theme}&gt;
            &lt;StatePicker handleStateChange={this.handleStateChange} /&gt;
            &lt;StateCards stateData= {stateData} yesterdayStateData = {yesterdayStateData}/&gt;

          &lt;/ThemeProvider&gt; 
    //If the City Button is clicked show this 
            &lt;CityPicker handleCityChange={this.handleCityChange}/&gt;
          &lt;CityCard cityData = {cityData}/&gt;
      &lt;/div&gt;
    );
</code></pre>
"
61506166,"<p>EDIT: Issue was with the condition. Thank you guys!</p>

<p>I am designing a covid19 watcher application using an open source API. I log out the state to see if it updates, which it does, but when I pass the the state to a component, it doesn't get the data passed. </p>

<p>So I put in a condition on the render() and it seems the state doesn't update so the component doesn't get it. Maybe because componentDidMount runs after render has. How do I fix it?</p>

<p>App.js</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>import React from 'react';
import Homepage from './pages/homepage/homepage.component.jsx';
import './App.css';

class App extends React.Component{
  constructor(){
    super()
    this.state = {
      statistics:{},
    }
  }

   componentDidMount(){
    fetch('https://api.covid19api.com/summary')
    .then(response =&gt; response.json())
    .then(data =&gt; {
      const all_data = data;
      this.setState({statistics: all_data});
      console.log(this.state);
      })
  }


  render(){
    const { statistics } = this.state;
      return !statistics.length ? 
        &lt;div&gt; Nawa oh &lt;/div&gt; :
      (
      &lt;Homepage statistics={statistics} /&gt;
      );  
  }
}
export default App;</code></pre>
</div>
</div>
</p>
"
61256412,"<p>I have a Script in a Google Spreadsheet, the script downloads a zipped CSV from an URL and then import it to the spreadsheet. Actually, the CVS is too big and I don't need all the data from it. My question is, How can I filter the data before importing it to the spreadsheet? For example filter Column A with X value. </p>

<p>This is the code I have so far:</p>

<pre><code>function descargarzip() 
{
var urldescarga = ""http://187.191.75.115/gobmx/salud/datos_abiertos/datos_abiertos_covid19.zip""
var url = urldescarga
var zipblob = UrlFetchApp.fetch(url).getBlob(); 
zipblob.setContentTypeFromExtension();
var unzipblob = Utilities.unzip(zipblob); 
var unzipstr=unzipblob[0].getDataAsString();
var csv = Utilities.parseCsv(unzipstr);

var ss = SpreadsheetApp.getActiveSpreadsheet().getSheetByName('Sheet1');
ss.getRange(1, 1, csv.length, csv[0].length).setValues(csv);
}
</code></pre>

<p>Thank you in advance! </p>
"
61233320,"<p>How can I make the code work for every country?
Right now I just coded the bot, so It can answer !corona with the corona confirmed cases of germany.</p>

<p>Here is the code: </p>

<pre><code>bot.on('message', msg=&gt;{
if(msg.content === '!corona'){
    const url = ""https://coronavirus-19-api.herokuapp.com/countries/germany""
    req(url, function(err, response, body){
        if(err) return msg.reply(""err"")
        body = JSON.parse(body)
        msg.reply(`Corona Fälle für: + \*\*${body.cases}\*\*\ ` ,)
    }


,)}
</code></pre>
"
61105480,"<p>I'm making a Pi livestreaming covid tracker, but watching my CPU/RAM get decimated</p>

<pre><code>VBR=""2500k""
FPS=""30""
QUAL=""medium""
YOUTUBE_URL=""rtmp://a.rtmp.youtube.com/live2""
KEY=""...""
TEXTFILE=""message.txt""

ffmpeg \
    -re -stream_loop -1 \
    -i a.mp4 \
    -vf ""drawtext=fontfile=font.ttf:fontsize=30: \
    fontcolor=white:x=(w-text_w)/2:y=(h-text_h)/2:textfile=$TEXTFILE:reload=1"" \
    -vcodec libx264 -preset $QUAL -r $FPS \
    -f flv ""$YOUTUBE_URL/$KEY""
</code></pre>

<p>When I run that, top gives me <code>%CPU 282</code> <code>%MEM 4.0</code></p>

<p>I installed ffmpeg with <code>sudo apt-get ffmpeg</code></p>

<p>I'm not sure if I'm using hardware acceleration.  It was brought up in a number of posts that were a year old or so.</p>
"
61675585,"<p>I am a beginner in React. I am going through a very interesting React project, called Covid-19 tracker, on <a href=""https://www.youtube.com/watch?v=khJlrj3Y6Ls&amp;t=3135s"" rel=""nofollow noreferrer"">YouTube</a>. 
I am facing an issue at 36:21, I am supposed to see Card like this:
<a href=""https://i.stack.imgur.com/CPt7k.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CPt7k.png"" alt=""enter image description here""></a></p>

<p>Instead, I am seeing Card like this:</p>

<p><a href=""https://i.stack.imgur.com/N732p.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/N732p.jpg"" alt=""enter image description here""></a>
As you can see, the cards displaying the number of infected people are not showing up. How can I fix the issue?</p>

<p>Here are my codes in <code>Cards.jsx</code> file:</p>

<pre><code>import React from 'react';
import {Card, CardContent, Typography, Grid } from '@material-ui/core';
import CountUp from 'react-countup';

import styles from './Cards.module.css';

const Cards = ({data: {confirmed, recovered, deaths, lastUpdate} }) =&gt; {
    if(!confirmed){
        return 'Loading...';
    }
    return(
        &lt;div className={styles.container}&gt;
            &lt;Grid container spacing={3} justify=""center""&gt;
                &lt;Grid item component={Card}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Infected&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;{confirmed.value}&lt;/Typography&gt;
                            &lt;CountUp
                                start={0}
                                end={confirmed.value}
                                separator={0}
                            /&gt;
                        &lt;Typography color=""textSecondary""&gt;Real Date&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of Activate Cases of COVID-19&lt;/Typography&gt;
                    &lt;/CardContent&gt;

                &lt;/Grid&gt;
                &lt;Grid item component={Card}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Recovered&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;Real Data&lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;Real Date&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of Recoveries from COVID-19&lt;/Typography&gt;
                    &lt;/CardContent&gt;

                &lt;/Grid&gt;
                &lt;Grid item component={Card}&gt;
                    &lt;CardContent&gt;
                        &lt;Typography color=""textSecondary"" gutterBottom&gt;Deaths&lt;/Typography&gt;
                        &lt;Typography variant=""h5""&gt;Real Data&lt;/Typography&gt;
                        &lt;Typography color=""textSecondary""&gt;Real Date&lt;/Typography&gt;
                        &lt;Typography variant=""body2""&gt;Number of Deaths Caused by COVID-19&lt;/Typography&gt;
                    &lt;/CardContent&gt;

                &lt;/Grid&gt;

            &lt;/Grid&gt;

        &lt;/div&gt;
    )
}

export default Cards;
</code></pre>

<p>Here are my codes in <code>app.js</code>:</p>

<pre><code>import React from 'react';
import {Cards, Chart, CountryPicker} from './components';
import styles from './App.module.css';
import {fetchData} from ""./api"";

class  App extends React.Component {
    state = {
        data: {},
    }

    async componentDidMount() {
        const fetchedData = await fetchData();

        this.setState({data:fetchedData})
    }


    render() {
        const data = this.state;

        return (
            &lt;div className={styles.container}&gt;
                &lt;Cards data={data} /&gt;
                &lt;Chart /&gt;
                &lt;CountryPicker /&gt;
            &lt;/div&gt;
        )
    }
}

export default App;
</code></pre>

<p>Here are my codes in <code>index.js</code>:</p>

<pre><code>export { default as Cards } from './Cards/Cards'
export { default as Chart } from './Chart/Chart'
export { default as CountryPicker } from './CountryPicker/CountryPicker'
</code></pre>

<p>Here is the link to my project files:</p>
"
60993575,"<p>I am new in react native, making a basic app that will find no of cases of corona in every country 
so i have made 2 component both on separate file. how to switch from child to child component ?
Now i want to switch between them when i click on a button using stack navigator</p>

<p><strong>App.js</strong></p>

<pre><code>import 'react-native-gesture-handler';
import React from 'react';
import { NavigationContainer } from '@react-navigation/native';
import { createStackNavigator } from '@react-navigation/stack';
import Splash from './scenes/splash';
import Corona from './scenes/corona';

const Stack = createStackNavigator();

export default function App() {
  return (
    &lt;NavigationContainer&gt;
      &lt;Stack.Navigator initialRouteName=""Splash""&gt;
        &lt;Stack.Screen name=""Splash"" component={Splash} /&gt;
        &lt;Stack.Screen name=""Corona"" component={Corona} /&gt;
      &lt;/Stack.Navigator&gt;
    &lt;/NavigationContainer&gt;
  );
}
</code></pre>

<p><strong>splash.js</strong></p>

<pre><code>import React from 'react'
import { StyleSheet, Text, View, Image, Button} from 'react-native';

export default function splash({navigation}) {
    return (
            &lt;View style={styles.container}&gt;
                &lt;Image 
                source={require('../assets/corona.jpg')} 
                resizeMode=""cover"" style={styles.img} /&gt;
                &lt;Text style={styles.txt}&gt;
                    Track the current status {""\n""} 
                    of the COVID-19 and{""\n""}
                    stay up to date.&lt;/Text&gt;
                &lt;Text 
                style={styles.btn}
                onPress={() =&gt; this.props.navigation.navigate('Corona')}
                &gt;Continue&lt;/Text&gt;
            &lt;/View&gt;
    )
}      

</code></pre>

<p><strong>corona.js (navigate to here)</strong></p>

<pre><code>import React from 'react'
import { StyleSheet, Text, View, Image, Button} from 'react-native';

export default function corona({navigation}) {
    return (
        &lt;div&gt;
            &lt;View&gt;
                &lt;Text&gt;Hello next screen&lt;/Text&gt;
            &lt;/View&gt;
        &lt;/div&gt;
    )
}

</code></pre>
"
61031974,"<p>I am trying to convert a csv file to json using the convert-csv-to-json package from npm. I am able to get the csv from the url and the 'data.csv' is created, but the corresponding json file is just an empty array. Am i calling the wrong file path, or is there some js quirks with promises that I am missing. I am pretty new to js.</p>

<pre><code>
const csvToJson = require('convert-csv-to-json');
const fs = require(""fs"");
const https = require(""https"");
const file = fs.createWriteStream(""data.csv"");



https.get(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv"", response =&gt; {
  var stream = response.pipe(file);

  stream.on(""finish"", function() {
    console.log(""done"");
  });
});



const input = './data.csv'; 
const output = './data.json';

csvToJson.fieldDelimiter(',')
         .formatValueByType()
         .generateJsonFileFromCsv(input, output);
</code></pre>
"
61510018,"<p>So I am pretty new to React Hooks and can't seem to figure this out.  What I am trying to do is have the user select an item from the dropdown menu and fetch data every time a user selects a new item. The 'selectedState' variable is updating when a user chooses an item from the dropdown menu, but my useEffect function has to fetch data twice before getting the correct data for the current 'selectedState'. I have thought about separating the dropdown into its own component and passing the data to another component to fetch the data, but I don't know if that would actually fix the problem.  </p>

<p>here is my code: </p>

<pre><code>    const initialState = () =&gt; {
        return {
            loading: true,
            post: '',
            error: ''
        }
    }

function reducer(state, action) {
        switch (action.type) {
            case 'fetch_success':
                return {
                    loading: false,
                    post: action.payload,
                    error: ''
                }
            case 'fetch_error':
                return {
                    loading: false,
                    post: {},
                    error: 'Something went wrong'
                }
            default:
                return state
        }
    }

    export default () =&gt; {
        const [state, dispatch] = useReducer(reducer, initialState);
        const [selectedState, getSelectedState] = useState('');
        const dropDownList = ['Alabama', 'Alaska', 'American Samoa', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Guam', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Minor Outlying Islands', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Northern Mariana Islands', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Puerto Rico', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'U.S. Virgin Islands', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']


        const dropDown =
            &lt;select
                id=""state-dropdown""
                onChange={e =&gt; getSelectedState(e.target.value)}
                value={selectedState}
                disabled={!dropDownList.length}&gt;
                &lt;option&gt;Choose State&lt;/option&gt;
                {dropDownList.map((item) =&gt; &lt;option key={item} value={item}&gt;{item}&lt;/option&gt;)}
            &lt;/select &gt;


        useEffect(() =&gt; {
            async function fetchData() {
                const response = await fetch((`https://covid-19-statistics.p.rapidapi.com/reports?&amp;iso=USA&amp;region_name=US&amp;date=2020-04-16&amp;q=US%20${selectedState}`), {
                    ""method"": ""GET"",
                    ""headers"": {
                        ""x-rapidapi-host"": ""covid-19-statistics.p.rapidapi.com"",
                        ""x-rapidapi-key"": ""8eb0a7c674msh30916dd1116d55cp1700f5jsn651eb7015384""
                    }
                });
                dispatch({ type: 'fetch_success', payload: response.json() });
            }
            fetchData();
        }, [selectedState, dispatch]);

        {console.log(state)}


        return (
            &lt;div&gt;
                &lt;CardHeader&gt;- State -&lt;/CardHeader&gt;
                &lt;Card&gt;
                    &lt;label&gt;
                        {dropDown}
                    &lt;/label&gt;
                &lt;/Card&gt;
            &lt;/div&gt;
        )
    }
</code></pre>
"
61180374,"<p>I am learning ionic 5 and want to create a simple app which display list of all nearby Bluetooth enabled phones. My problem is that when I use invoke scan of BLE plugin, my callback methods are never invoked. I tested this on attached phone (Samsung 9 ) and also by generating app-debug.apk and install on phone. </p>

<p>Here are the details of my project. I am using Capacitor for native apps.</p>

<p>SDK:
<a href=""https://i.stack.imgur.com/GgNFG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GgNFG.png"" alt=""enter image description here""></a></p>

<p><strong>tab-1.ts</strong></p>

<pre><code>import { Component, NgZone } from '@angular/core';
import { BLE } from '@ionic-native/ble/ngx';
import { AlertController } from '@ionic/angular';

@Component({
  selector: 'app-tab1',
  templateUrl: 'tab1.page.html',
  styleUrls: ['tab1.page.scss']
})
export class Tab1Page {
text = 'hello';
devices: any[] = [];
constructor(private ble: BLE,
            private ngZone: NgZone,
            public alertController: AlertController) { }
 scan() {
  this.text = 'Loading...';
  console.log('going to this.scan.....');
  this.devices = [];
  this.showAlert('starting scan.....');


  this.ble.scan([], 60).subscribe(devices1=&gt;{
    this.showDeviceList(devices1);
    this.text = devices1;
    this.showAlert('scan finished success');
  },error=&gt; this.showAlert('scan fini with error'), 
  ()=&gt;this.showAlert('scan void finish'));
}

async showDeviceList(devices) {
  const alert = await this.alertController.create({
    header: 'Alert',
    subHeader: 'Subtitle',
    message: 'Going to start scan',
    buttons: ['OK']
  });
  await alert.present();
  console.log('devices are ', devices);
  this.ngZone.run(() =&gt; {
    this.devices.push(...devices);
    this.text = 'finished';
  });
}

async showAlert(msg){
  const alert = await this.alertController.create({
    header: 'Alert',
    subHeader: 'Subtitle',
    message: msg,
    buttons: ['OK']
  });
  await alert.present();
}
}
</code></pre>

<p><strong>ionic info:</strong></p>

<p><a href=""https://i.stack.imgur.com/eWVZX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eWVZX.png"" alt=""enter image description here""></a></p>

<p><strong>Package.json:</strong></p>

<pre><code>{
  ""name"": ""COVID-TRACKING"",
  ""version"": ""0.0.1"",
  ""author"": ""Ionic Framework"",
  ""homepage"": ""https://ionicframework.com/"",
  ""scripts"": {
    ""ng"": ""ng"",
    ""start"": ""ng serve"",
    ""build"": ""ng build"",
    ""test"": ""ng test"",
    ""lint"": ""ng lint"",
    ""e2e"": ""ng e2e""
  },
  ""private"": true,
  ""dependencies"": {
    ""@angular/common"": ""~8.2.14"",
    ""@angular/core"": ""~8.2.14"",
    ""@angular/forms"": ""~8.2.14"",
    ""@angular/platform-browser"": ""~8.2.14"",
    ""@angular/platform-browser-dynamic"": ""~8.2.14"",
    ""@angular/router"": ""~8.2.14"",
    ""@capacitor/android"": ""^2.0.1"",
    ""@capacitor/core"": ""2.0.1"",
    ""@ionic-native/ble"": ""^5.23.0"",
    ""@ionic-native/core"": ""^5.0.7"",
    ""@ionic-native/splash-screen"": ""^5.0.0"",
    ""@ionic-native/status-bar"": ""^5.0.0"",
    ""@ionic/angular"": ""^5.0.0"",
    ""cordova-plugin-ble-central"": ""^1.2.4"",
    ""core-js"": ""^2.5.4"",
    ""rxjs"": ""~6.5.1"",
    ""tslib"": ""^1.9.0"",
    ""zone.js"": ""~0.9.1""
  },
  ""devDependencies"": {
    ""@angular-devkit/build-angular"": ""~0.803.20"",
    ""@angular/cli"": ""~8.3.23"",
    ""@angular/compiler"": ""~8.2.14"",
    ""@angular/compiler-cli"": ""~8.2.14"",
    ""@angular/language-service"": ""~8.2.14"",
    ""@capacitor/cli"": ""2.0.1"",
    ""@ionic/angular-toolkit"": ""^2.1.1"",
    ""@types/jasmine"": ""~3.3.8"",
    ""@types/jasminewd2"": ""~2.0.3"",
    ""@types/node"": ""~8.9.4"",
    ""codelyzer"": ""^5.0.0"",
    ""jasmine-core"": ""~3.4.0"",
    ""jasmine-spec-reporter"": ""~4.2.1"",
    ""karma"": ""~4.1.0"",
    ""karma-chrome-launcher"": ""~2.2.0"",
    ""karma-coverage-istanbul-reporter"": ""~2.0.1"",
    ""karma-jasmine"": ""~2.0.1"",
    ""karma-jasmine-html-reporter"": ""^1.4.0"",
    ""protractor"": ""~5.4.0"",
    ""ts-node"": ""~7.0.0"",
    ""tslint"": ""~5.15.0"",
    ""typescript"": ""~3.4.3""
  },
  ""description"": ""An Ionic project""
}
</code></pre>

<p><strong>Command to install plugin:</strong></p>

<pre><code>npm install cordova-plugin-ble-central
npm install @ionic-native/ble
ionic cap sync
</code></pre>
"
61191268,"<p>I'm trying to pass the country name to the action in Redux from the React component but when it arrives in the action creator it becomes undefined. I think its something to do with the mapDispatchToProps() section below the component but I'm quite new to Redux so I'm not entirely sure.</p>

<p>It gets the list of countries from the API ok but then when I want to pass the selected country back up to Actions.js the country becomes undefined.</p>

<p>Component.js</p>

<pre><code>import React, { useEffect, useState } from ""react"";
import { connect } from ""react-redux"";
import {
  getCountryCasesAction,
  getAllAvailableCountriesAction,
} from ""../redux/Actions"";

import { Form } from ""semantic-ui-react"";

function CasesByCountry({
  countryOptions,
  getAllAvailableCountries,
  getCountryCases,
}) {
  useEffect(() =&gt; {
    getAllAvailableCountries();
  }, [getAllAvailableCountries]);

  const onDropdownOptionSelect = (e, result, country, countryData) =&gt; {
    console.log(result.value);
    getCountryCases(result.value);
  };

  return (
    &lt;div&gt;
      &lt;Form.Dropdown
        placeholder=""Select Country""
        fluid
        selection
        search
        onChange={onDropdownOptionSelect}
        options={
          countryOptions &amp;&amp;
          countryOptions.map((c) =&gt; {
            return {
              key: c.ISO2,
              text: c.Country,
              value: c.Country,
            };
          })
        }
      /&gt;
    &lt;/div&gt;
  );
}

const mapStateToProps = (state) =&gt; {
  return {
    countryOptions: state.data,
    countryData: state.data,
  };
};

const mapDispatchToProps = {
  getAllAvailableCountries: getAllAvailableCountriesAction,
  getCountryCases: getCountryCasesAction,
};

export default connect(mapStateToProps, mapDispatchToProps)(CasesByCountry);
</code></pre>

<p>Actions.js</p>

<pre><code>import axios from ""axios"";

export const GET_WORLDWIDE_SUMMARY = ""GET_WORLDWIDE_SUMMARY"";
export const GET_COUNTRY_CASES = ""GET_COUNTRY_CASES"";
export const GET_ALL_AVAILABLE_COUNTRIES = ""GET_ALL_COUNTRIES"";

export const getWorldwideSummaryAction = () =&gt; async (dispatch, getState) =&gt; {
  // const response = await axios
  //   .get
  //   // ""https://cors-anywhere.herokuapp.com/"" +
  //   // ""process.env.REACT_APP_GET_WORLDWIDE_SUMMARY""
  //   ();
  // console.log(response);
  // return dispatch({
  //   type: GET_WORLDWIDE_SUMMARY,
  //   payload: response.data,
  // });
};

export const getAllAvailableCountriesAction = () =&gt; async (
  dispatch,
  getState
) =&gt; {
  const response = await axios.get(""https://api.covid19api.com/countries"");
  console.log(response);

  return dispatch({
    type: GET_ALL_AVAILABLE_COUNTRIES,
    payload: response.data,
  });
};

export const getCountryCasesAction = () =&gt; async (
  dispatch,
  getState,
  country
) =&gt; {
  console.log(""getCountryCasesAction"");
  const response = await axios.get(
    `https://api.covid19api.com/dayone/country/${country}/status/confirmed`
  );
  console.log(response);
  return dispatch({
    type: GET_COUNTRY_CASES,
    payload: response.data,
  });
};
</code></pre>

<p>Reducer.js</p>

<pre><code>import {
  GET_WORLDWIDE_SUMMARY,
  GET_ALL_AVAILABLE_COUNTRIES,
  GET_COUNTRY_CASES,
} from ""./Actions"";

const initialState = {
  data: """",
};

export const rootReducer = (state = initialState, action) =&gt; {
  switch (action.type) {
    case GET_WORLDWIDE_SUMMARY:
      console.log(action.payload);
      return {
        ...state,
        data: action.payload,
      };

    case GET_ALL_AVAILABLE_COUNTRIES:
      console.log(action.payload);
      return {
        ...state,
        data: action.payload,
      };

    case GET_COUNTRY_CASES:
      console.log(action.payload);
      return {
        ...state,
        data: action.payload,
      };

    default:
      return state;
  }
};
</code></pre>
"
60750391,"<p>I am trying to create a <a href=""https://www.datatables.net/"" rel=""nofollow noreferrer"">Datatables</a> using the fetch API.</p>

<p>So i am using the following <a href=""https://covid19.mathdro.id/api/daily/3-18-2020"" rel=""nofollow noreferrer"">API</a> </p>

<p>I am basically trying to get all the stats for USA so i did the following.</p>

<pre><code>const getNewCases = async () =&gt; {
  const response = await fetch('https://cors-anywhere.herokuapp.com/https://covid19.mathdro.id/api/daily/3-18-2020');
  const data = await response.json();
  let usa = data.filter(val =&gt; {
  return val.countryRegion === 'US';
});
  console.log(usa)
};
</code></pre>

<p>So at this point i am wondering if it is possible to create a DataTable using this result. All the examples i saw on Datatables are using JQuery and making some ajax call. I would love some guidance on how to make a datatable without JQuery.</p>

<p>I am very new to JS so please forgive if it is a bad question. I am just trying to learn this.</p>
"
60919461,"<p>I'm currently trying to build a simple html page that displays data obtained from csv files on GitHub. To do that, I used jQuery's .get calls in order to get the full text from the URL and then manipulated it through jQuery-CSV.
The data I'm using comes from <a href=""https://github.com/pcm-dpc/COVID-19/tree/master/dati-andamento-nazionale"" rel=""nofollow noreferrer"">https://github.com/pcm-dpc/COVID-19/tree/master/dati-andamento-nazionale</a>.</p>

<p>The organization managing the repository always uses <code>dpc-covid19-ita-andamento-nazionale-latest.csv</code> as filename for newest data, so I just use </p>

<pre><code>    var national_csv = null; 
        jQuery.get(LATEST_URL, function (data) {
        national_csv = $.csv.toObjects(data)[0];
    }, 'text');
</code></pre>

<p>The issue comes when I have to get data from the day before (in order to compare it with current data). URLs for past info have a format like this: <code>dpc-covid19-ita-andamento-nazionale-YYYYMMDD.csv</code>. </p>

<p>A solution I came up with was using the date parameter in the CSV file I'd just get (since it's included along with the rest of the data) and manipulate it through Date() in order to get the date of the past day, and then create a function that would return this date, as a string, included in the url.</p>

<pre><code>function yesterdayURL(date) {
    return ""dpc-covid19-ita-andamento-nazionale-""+dayBeforeAsString(date)+"".csv"";
}
</code></pre>

<p>Now, I'm trying to do the following:</p>

<pre><code>var national_csv = null;
var today = null;
jQuery.get(LATEST_URL, function(data) {
    national_csv = $.csv.toObjects(data)[0];
    today = national_csv.data;
}).then(jQuery.get(yesterdayURL(today), function() {/*do stuff*/}));
</code></pre>

<p>Though, it seems the value of <code>today</code> is still null. How can I solve this?</p>

<p>P.S.: I'm pretty new to Ajax and asynchronous programming, but I've been trying hard to solve this issue despite failing, so I'm sorry if the question appears to be dumb. Thanks in advance!</p>
"
61329586,"<p>I have setup the following parent-child component interaction using @Input decorator. But this doesnt seem to work. Can anyone please help me with this?</p>

<p><strong>Parent ts file :</strong></p>

<pre><code>import { Component, OnInit } from '@angular/core';

import { Covid19Service } from '../services/get-covid19-data';

@Component({
   selector: 'app-countries',
   templateUrl: 'countries.component.html',
   styleUrls: ['countries.component.css']
})

export class CountriesComponent implements OnInit {

   constructor(private covid19Service: Covid19Service) { }

   countries: Array&lt;string&gt; = [];
   countriesCount: Number;
   selectedCountry: string = 'Sample';


   ngOnInit() {
     this.covid19Service.getCountries().subscribe(data =&gt; {
        this.countriesCount = data['affectedCountries'];
        this.countries = data['countries'];
     });
   }

  countrySelected(country: string) {
    this.selectedCountry = country;
    console.log(`Selected Country from Parent: ${this.selectedCountry}`);
    /*         console.log(`Clicked on : ${country}!`);
            this.covid19Service.getCountry(country).subscribe(data =&gt; {
                console.log(`${JSON.stringify(data)}`);
            }); */
}
}
</code></pre>

<p><strong>Parent HTML:</strong>  </p>

<pre><code>&lt;div&gt;
&lt;li *ngFor=""let country of countries""&gt;
    &lt;span class=""badge"" (click)=""countrySelected(country)""&gt;{{country}}&lt;/span&gt;
&lt;/li&gt;
&lt;/div&gt;
&lt;app-country [country]=""selectedCountry""&gt;&lt;/app-country&gt;  
</code></pre>

<p><strong>Child ts file:</strong>  </p>

<pre><code>import { Component, Input, OnInit } from '@angular/core';

@Component({
  selector: 'app-country',
  templateUrl: 'country.component.html',
  styleUrls: ['country.component.css']
})
export class CountryComponent implements OnInit {
  @Input() country: string;

  ngOnInit() {
    console.log(`Selected Country in Child: ${this.country}`);
  }
 }  
</code></pre>

<p><strong>Child HTMLfile:</strong>  </p>

<pre><code>&lt;p&gt;Country component works!&lt;/p&gt;
&lt;p&gt;This is the selected Country: {{country}}&lt;/p&gt;  
</code></pre>

<p>The above code using @Input component doesnt work. Can anyone please help me with this? I'm fairly new to Angular and I'm lost. Any help would be appreciated</p>
"
60740609,"<p>I'm trying to plot (GNUPlot) some <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">covid-19 data</a> contained in a CSV file which uses the first row as the time data and corresponding case counts in each column. I'd like to make a single plot for each state (each row) but not having much luck. Any help? This is what my plot script is so far. I'm using <code>plot for [col=5:30:1]...</code> in the script because the first 4 columns are the state name and geolocation. I thought I'd just concentrate on the datapoints for now and eventually figure out how to display the state name on the plot as well. I've grep'd the USA data out of the main CSV data to create ""us.dat"":</p>

<pre><code>set key autotitle columnhead
set term png size 1024, 768
set key outside
set datafile separator "",""
set title 'mygraph'
set ylabel 'count'
set xlabel 'time'
set grid
set term png
set output ""/tmp/covid19.png""    
plot for [col=5:30:1] ""us.dat"" using col
</code></pre>

<p>And a snip of the ""us.dat"" file:</p>

<pre><code>Province/State,Country/Region,Lat,Long,1/22/20,1/23/20,1/24/20,1/25/20,1/26/20,1/27/20,1/28/20,1/29/20,1/30/20,1/31/20,2/1/20,2/2/20,2/3/20,2/4/20,2/5/20,2/6/20,2/7/20,2/8/20,2/9/20,2/10/20,2/11/20,2/12/20,2/13/20,2/14/20,2/15/20,2/16/20,2/17/20,2/18/20,2/19/20,2/20/20,2/21/20,2/22/20,2/23/20,2/24/20,2/25/20,2/26/20,2/27/20,2/28/20,2/29/20,3/1/20,3/2/20,3/3/20,3/4/20,3/5/20,3/6/20,3/7/20,3/8/20,3/9/20,3/10/20,3/11/20
Washington,US,47.4009,-121.4905,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,267,366
New York,US,42.1657,-74.9481,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,173,220
California,US,36.1162,-119.6816,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,144,177
Massachusetts,US,42.2302,-71.5301,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,92,95
</code></pre>

<p>The plot image isn't quite right however:</p>

<p><img src=""https://i.stack.imgur.com/OD74V.png"" alt=""plot image""></p>
"
73007,"<p>I trained the LSTM model to forecast the number of people infected with COVID-19. Since each country and state (geo location) has different number of population as well as the infected over time, I normalised each time series data by/within geo location (using min-max scaler). So, the model can learn change in time series in the same scale. After the normalisation, my model appears to have lower error rate than when it was NOT normalised by/within geo location.</p>

<p>However, I wonder if this is a fair way to create universal forecaster to predict for multiple countries. I saw some does forecasting after time series clustering instead. Do you think that is better approach?</p>

<p>Here is the <a href=""https://www.kaggle.com/yohancheong/predicting-covid-19-infections-with-lstm-public?scriptVersionId=32527595"" rel=""nofollow noreferrer"">link</a> for my solution.</p>

<p>Please share your thoughts on this. Thanks!</p>
"
61612973,"<p>I've installed linkerd correctly (linkerd check --proxy -n linkerd checkings are all ok).</p>

<p>After that, I've annotated my <code>covid</code> namespace with <code>""auto-injection""</code>:</p>

<pre><code>$ kubectl annotate namespace covid linkerd.io/inject=enabled
</code></pre>

<p>After having deployed my deployment:</p>

<pre><code>$ linkerd stat deployments -n covid
NAME                MESHED   SUCCESS   RPS   LATENCY_P50   LATENCY_P95   LATENCY_P99   TCP_CONN
dev-covid-backend      0/1         -     -             -             -             -          -

$ linkerd stat pods -n covid
NAME                                 STATUS   MESHED   SUCCESS   RPS   LATENCY_P50   LATENCY_P95   LATENCY_P99   TCP_CONN
dev-covid-backend-7ccc987d4-494lv   Running      0/1         -     -             -             -             -          -
</code></pre>

<p>As you can see, deployment is not meshed.</p>

<p>I've trigerred heartbeat manually. I'm getting:</p>

<pre><code>time=""2020-05-05T12:29:39Z"" level=info msg=""running version stable-2.7.1""
time=""2020-05-05T12:29:39Z"" level=error msg=""Prometheus query failed: unexpected result Prometheus result vector length: 0""
time=""2020-05-05T12:29:39Z"" level=error msg=""Prometheus query failed: unexpected result Prometheus result vector length: 0""
time=""2020-05-05T12:29:39Z"" level=error msg=""Prometheus query failed: unexpected result Prometheus result vector length: 0""
time=""2020-05-05T12:29:39Z"" level=error msg=""Prometheus query failed: unexpected result Prometheus result vector length: 0""
time=""2020-05-05T12:29:39Z"" level=error msg=""Prometheus query failed: unexpected result Prometheus result vector length: 0""
time=""2020-05-05T12:29:39Z"" level=error msg=""Prometheus query failed: unexpected result Prometheus result vector length: 0""
time=""2020-05-05T12:29:39Z"" level=error msg=""Prometheus query failed: unexpected result Prometheus result vector length: 0""
time=""2020-05-05T12:29:39Z"" level=info msg=""Sending heartbeat: https://versioncheck.linkerd.io/version.json?install-time=1588663782&amp;k8s-version=v1.17.3%2Bk3s1&amp;meshed-pods=9&amp;p99-handle-us=50000&amp;source=heartbeat&amp;total-rps=3&amp;uuid=991db911-da8b-45c7-98b5-eb63e6162e8d&amp;version=stable-2.7.1""
time=""2020-05-05T12:29:43Z"" level=fatal msg=""Failed to send heartbeat: Check URL [https://versioncheck.linkerd.io/version.json?install-time=1588663782&amp;k8s-version=v1.17.3%2Bk3s1&amp;meshed-pods=9&amp;p99-handle-us=50000&amp;source=heartbeat&amp;total-rps=3&amp;uuid=991db911-da8b-45c7-98b5-eb63e6162e8d&amp;version=stable-2.7.1] request failed with: Get https://versioncheck.linkerd.io/version.json?install-time=1588663782&amp;k8s-version=v1.17.3%2Bk3s1&amp;meshed-pods=9&amp;p99-handle-us=50000&amp;source=heartbeat&amp;total-rps=3&amp;uuid=991db911-da8b-45c7-98b5-eb63e6162e8d&amp;version=stable-2.7.1: dial tcp: lookup versioncheck.linkerd.io on 10.43.0.10:53: server misbehaving""
</code></pre>

<p>Any ideas?</p>
"
61255915,"<p>I'm trying to use GitHub REST api to get files from public repositories but I get a message not found, although it exists. </p>

<p>This is the link of the file: <a href=""https://github.com/COVID19Tracking/covid-tracking-data/blob/master/data/counties.csv"" rel=""nofollow noreferrer"">https://github.com/COVID19Tracking/covid-tracking-data/blob/master/data/counties.csv</a></p>

<p>I changed it as specified in Github REST specification: <a href=""https://api.github.com/repos/COVID19Tracking/covid-tracking-data/blob/master/data/counties.csv"" rel=""nofollow noreferrer"">https://api.github.com/repos/COVID19Tracking/covid-tracking-data/blob/master/data/counties.csv</a></p>

<p>I'm using Postman, and I get the following:</p>

<p><a href=""https://i.stack.imgur.com/APzMe.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/APzMe.png"" alt=""enter image description here""></a></p>

<p>So What am I missing?</p>
"
61423003,"<p>I have created <a href=""https://cutting.scot/covid-19/increase-in-deaths"" rel=""nofollow noreferrer"">this graph</a> but I need to normalise it per population size to give a better comparison.</p>

<p>the <code>y</code> axis is the delta in deaths from the day before.</p>

<p>I was thinking of doing this:</p>

<pre><code>y: (d.delta / countryData[c].population) * 100000,
</code></pre>

<p>But I am not sure if that is right and if it is how I would label the <code>y</code> axis.  It looks like this if I do this calculation:</p>

<p><a href=""https://i.stack.imgur.com/xXmiL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xXmiL.png"" alt=""new image""></a></p>
"
60843342,"<p>I am running a wordpress docker container , the site is accessible through host machines port <code>8000</code> , if go to localhost:8000 boom i get to see my wordpress site. </p>

<p>It's boring to always type <code>localhost:8000</code> to see my website, so i decided to commission nginx as a reverse proxy for my site. I've set up a virtual host in nginx that has the name <code>proxy.site</code> , i can now access by wordpress site by visiting <code>http://proxy.site</code>. </p>

<p>Up until this point, we are doing great, when <code>http://proxy.site</code> opens up, i can see a list of my blog posts, lets say i want to read my latest blog post about COVID-19 , when i click on the link, ohohohoho it opens up as <code>http://localhost:8000/posts/covid19</code> </p>

<p>I want it to open with the proxy url as in <code>http://proxy.site/posts/covid19</code> , i need to whole site to be accessible through the <code>http://proxy.site</code> site name, </p>

<p>I need nginx to rewrite all my links in <code>localhost:8000/*</code> to <code>proxy.site/*</code> , no body loves typing ports when accessing a blog,</p>

<p>Here is how my nginx conf file looks like</p>

<pre><code>server {
        listen 80;
        listen [::]:80;

        root /var/www/proxy.site/html;
        index index.html index.htm index.nginx-debian.html;

        server_name proxy.site www.proxy.site;

        location / {
                proxy_pass http://localhost:8000;
                #proxy_set_header HOST $host;
                #proxy_redirect http://localhost:8000/ http://proxy.site/ ;
                #try_files $uri $uri/ =404;
        }
}
</code></pre>

<p>How do i achieve rewrite all urls in the proxied site with my custom host name ?</p>
"
61044309,"<p>I am trying to read data of the following format with textscan:</p>

<pre><code>date,location,new_cases,new_deaths,total_cases,total_deaths
2019-12-31,Afghanistan,0,0,0,0
2020-01-01,Afghanistan,0,0,0,0
2020-01-02,Afghanistan,0,0,0,0
2020-01-03,Afghanistan,0,0,0,0
2020-01-04,Afghanistan,0,0,0,0
...
</code></pre>

<p>(Full data file available here: <a href=""https://covid.ourworldindata.org/data/ecdc/full_data.csv"" rel=""nofollow noreferrer"">https://covid.ourworldindata.org/data/ecdc/full_data.csv</a>)</p>

<p>My code is:</p>

<pre><code># Whitespace replaced with _
file_name = ""full_data.csv""; 
fid = fopen(file_name, ""rt"");
data= textscan(fid, ""%s%s%d%d%d%d"", ""Delimiter"", "","", ""HeaderLines"", 1, ...
  ""ReturnOnError"", 0);
fclose(fid);
</code></pre>

<p>Text scan terminates with an error:</p>

<pre><code>error: textscan: Read error in field 3 of row 421
</code></pre>

<p>Row 421 is the center row in the example below:</p>

<pre><code>2020-01-12,Australia,0,0,0,0
2020-01-13,Australia,0,0,0,0
2020-01-14,Australia,0,0,0,0
2020-01-15,Australia,0,0,0,0
2020-01-16,Australia,0,0,0,0
2020-01-17,Australia,0,0,0,0
2020-01-18,Australia,0,0,0,0
</code></pre>

<p>I've checked the row it complains about and there is nothing different from the example above. I've replaced all spaces in the file with underscores too. Am I doing something wrong with textcan?</p>
"
61170837,"<p>I'm trying to do the same as descriped in this article: <a href=""https://science.sciencemag.org/content/sci/early/2020/04/07/science.abb4557.full.pdf"" rel=""nofollow noreferrer"">https://science.sciencemag.org/content/sci/early/2020/04/07/science.abb4557.full.pdf</a></p>

<p>I use GNU Octave.</p>

<p>This is the function file with the ODE System:</p>

<pre><code>function f = COVID19ODE(t,y0)

  alpha = 3.07*0.38;
  beta = 0.38;
  kappa = 0.5;
  kappa0 = 0.5;
  ydot =@(t,y,a) ([-alpha*y(1)*y(2) - kappa*y(1);
                  alpha*y(1)*y(2) - beta*y(2) - kappa0*y(2) - kappa*y(2);
                  (kappa0 + kappa)*y(2);
                  kappa0*y(1) + beta*y(2)]);
  odeopt = odeset (""InitialStep"", 1e-2, ""MaxStep"", 1);           
  [t,y] = ode45(ydot, t, y0, odeopt);
  f = y;
endfunction
</code></pre>

<p>This is the script to fit the data to the ODE model:</p>

<pre><code>pkg load optim

Cases = [2,3,20,79,150,227,320,445,650,888,1128,1694,2036,2502,3089,3858,4636,5883,7375,9172,10149,12462,15113,17660,21157,24747,27980,31506,35713,41035,47021,53578,59138,63927,69176,74386,80539,86498,92472,97689,101739,105792,110574,115242,119827,124632,128948,132547,135586,139422,143626,147577,152271];
Days = (1:1:length(Cases));

% Fit
xdata = Days;
ydata = Cases';
F = @(a,xdata) COVID19ODE(xdata,a)(:,3);
a0=[1 1 1 1];
[a,resnorm,~,exitflag,output] = lsqcurvefit(F,a0,xdata,ydata);

% Plot
plot(Days,Cases,'-+' , Days,F(a,Days)) 
grid
legend(""Cases"" , ""Fit"" , ""location"",""northwest"")
title('Covid 19 pandemic')
xlabel('Days')
ylabel('Cases')
</code></pre>

<p>The computation takes very long and in the end there is an error message:</p>

<pre><code>warning:  Solving was not successful.  The iterative integration loop exited at time t = 1.000000 before the endpoint at tend= 53.000000 was reached.  This may happen if the stepsize becomes too small.  Try to reduce the value of 'InitialStep' and/or'MaxStep' with the command 'odeset'.
warning: called from
    integrate_adaptive at line 312 column 7
    ode45 at line 232 column 12
    COVID19ODE at line 12 column 8
    COVID19Model&gt;@&lt;anonymous&gt; at line 9 column 16
    nonlin_curvefit&gt;@&lt;anonymous&gt; at line 84 column 14
    __nonlin_residmin__&gt;@&lt;anonymous&gt; at line 316 column 41
    __lm_svd__ at line 469 column 11
    __nonlin_residmin__ at line 452 column 21
    nonlin_curvefit at line 83 column 18
    lsqcurvefit at line 268 column 19
    COVID19Model at line 11 column 30
</code></pre>

<p>I tried to reduce the value of 'InitialStep' and/or 'MaxStep' but it didn't help. 
The fit-function doesn't seem to be a good approximation for the data:
<a href=""https://i.stack.imgur.com/S7HJd.png"" rel=""nofollow noreferrer"">Plot</a></p>
"
60965721,"<p>I downloaded the library <a href=""http://phpqrcode.sourceforge.net/"" rel=""nofollow noreferrer"">http://phpqrcode.sourceforge.net/</a> and wrote simplest code for it</p>

<pre class=""lang-php prettyprint-override""><code>include('./phpqrcode/qrlib.php');
QRcode::png('иванов иван иванович 11111');
</code></pre>

<p>But resulted qr code contains only half of string </p>

<p>Resulted qr code - 'иванов иван ив';<br></p>

<p>url - <a href=""http://vologda-oblast.ru/coronavirus/qr/parampng.php"" rel=""nofollow noreferrer"">vologda-oblast.ru/coronavirus/qr/parampng.php</a></p>

<p>What can be wrong?</p>
"
60974270,"<p>I pull data from a json file on the remote server. This json file has 97000 Lines of json code. It returns null when I decode the Json file. When I debug the Json errors, I see that there is no error.</p>

<p>Json file : <a href=""https://opendata.ecdc.europa.eu/covid19/casedistribution/json/"" rel=""nofollow noreferrer"">https://opendata.ecdc.europa.eu/covid19/casedistribution/json/</a></p>

<pre><code>$json = file_get_contents(""https://opendata.ecdc.europa.eu/covid19/casedistribution/json/"");
$json =  json_decode($json, true);
var_dump($json); // Return Null
</code></pre>

<p>But when I decode another json file there is no error </p>

<pre><code>$json = file_get_contents(""https://randomuser.me/api/"");
$json =  json_decode($json, true);
var_dump($json); // Return Array
</code></pre>

<p>Could this be due to the size of the data? </p>

<p>Thanks for advance</p>
"
61259811,"<p>I have CakePHP project which runs on IIS8 (WinServer2012). I'm trying to cache site mainpage using static html file. So I try to achieve the following:</p>

<ol>
<li>when client requests mainpage <code>/</code> I rewrite this URL to <code>cache/index.html</code></li>
<li>If this file actually exists I want IIS to show it to client</li>
<li>If not - rewrite to index.php, which actually generates it.</li>
</ol>

<p>In Cake I have 2 routes to Home/index:</p>

<pre><code>$routes-&gt;connect('/', ['controller' =&gt; ""Home""]);
$routes-&gt;connect('/cache/index.html', ['controller' =&gt; ""Home""]);
</code></pre>

<p>and index action like</p>

<pre><code>....
$debug = Configure::read('debug');
if(!$debug) {
     $html = $this-&gt;render('index');
     $cfilename = ROOT. DS . ""cache"" . DS . ""index.html"";
     file_put_contents($cfilename, $html);
}
</code></pre>

<p>I've modified default cake's web.config and added rule to rewrite root to <code>cache/index.html</code>:</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;configuration&gt;
    &lt;system.webServer&gt;
        &lt;rewrite&gt;
            &lt;rules&gt;
                &lt;rule name=""cachedIndex"" stopProcessing=""false""&gt;
                    &lt;match url=""^$"" ignoreCase=""false"" /&gt;                   
                    &lt;action type=""Rewrite"" url=""cache/index.html"" appendQueryString=""true"" /&gt;
                &lt;/rule&gt;
                &lt;rule name=""Exclude direct access to webroot/*"" stopProcessing=""true""&gt;
                    &lt;match url=""^webroot/(.*)$"" ignoreCase=""false"" /&gt;
                    &lt;action type=""None"" /&gt;
                &lt;/rule&gt;
                &lt;rule name=""Rewrite routed access to assets(img, css, files, js, favicon)"" stopProcessing=""true""&gt;
                    &lt;match url=""^(img|css|js|webfonts|favicon|robots.txt)(.*)$"" /&gt;
                    &lt;action type=""Rewrite"" url=""webroot/{R:1}{R:2}"" appendQueryString=""false"" /&gt;
                &lt;/rule&gt;             
                &lt;rule name=""Rewrite requested file/folder to index.php"" stopProcessing=""true""&gt;
                    &lt;match url=""^(.*)$"" ignoreCase=""false"" /&gt;
                    &lt;conditions logicalGrouping=""MatchAll""&gt;
                        &lt;add input=""{REQUEST_FILENAME}"" matchType=""IsFile"" ignoreCase=""false"" negate=""true"" /&gt;
                    &lt;/conditions&gt;                       
                    &lt;action type=""Rewrite"" url=""index.php"" appendQueryString=""true"" /&gt;
                &lt;/rule&gt;
            &lt;/rules&gt;
        &lt;/rewrite&gt;
        &lt;handlers&gt;
            &lt;clear /&gt;
            &lt;add name=""php-7.1.15"" path=""*.php"" verb=""GET,HEAD,POST"" modules=""FastCgiModule"" scriptProcessor=""C:\Program Files (x86)\PHP\v7.1.15\php-cgi.exe"" resourceType=""Either"" requireAccess=""Script"" /&gt;                                   
            &lt;add name=""StaticFile"" path=""*"" verb=""*"" modules=""StaticFileModule,DefaultDocumentModule,DirectoryListingModule"" resourceType=""Either"" requireAccess=""Read"" /&gt;
        &lt;/handlers&gt;

        &lt;caching enabled=""false"" enableKernelCache=""false""&gt;
            &lt;profiles&gt;
                &lt;add extension="".html"" policy=""DontCache"" kernelCachePolicy=""DontCache"" duration=""00:01:00"" /&gt;
            &lt;/profiles&gt;
        &lt;/caching&gt;
        &lt;urlCompression doStaticCompression=""false"" /&gt;
    &lt;/system.webServer&gt;
&lt;/configuration&gt;
</code></pre>

<p>Now I expect that rule 1 checks for mainpage, rewrites URL to <code>cache/index.html</code> and then goes to rule 4, which checks <code>IsFile</code> and serves file to browser, and if there is no such file, it runs Cake/Home/index.
Sometimes it works, if I delete file it runs php and generates it, but in most cases I get 404, which says about <code>StaticHandler</code>. If I refresh page I get 404 (from IIS, not from Cake) response again and again, and 1-2 minutes later it runs php and I get 200 OK.
I've already disabled caching (I initially wanted to cache this html at kernel level with file modification notification).<br>
Or vice versa it runs php few times in a row. looks like some filesystem time lag.</p>

<p>Does anone know how to achieve desired behaviour, and what am i doing wrong? Or any other strategies of caching without running php?</p>

<p>Of course insted of deleting cached file I can refresh it. But this fallback to php seems pretty clear, and Apache work fine in this situation.</p>

<p>ps: before that I had symlinked index.html and IIS cached it until AppPool restart, as I found this is some kind of weird behavior with symlinks. Now if I have 404 I can rstart app pool and it runs fine.</p>

<p>Failed Request Tracing log:
<div class=""snippet"" data-lang=""js"" data-hide=""true"" data-console=""false"" data-babel=""false"">
<div class=""snippet-code snippet-currently-hidden"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>* { font-size: 11px; font-family: arial; }</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;table style=""width: 100%; border-collapse: collapse; table-layout: fixed;"" border=""1"" cellspacing=""0"" cellpadding=""0""&gt;
&lt;tbody&gt;&lt;tr align=""Left"" class=""subhead""&gt;&lt;th width=""32""&gt;No.&lt;/th&gt;&lt;th width=""250""&gt;EventName&lt;/th&gt;&lt;th&gt;Details&lt;/th&gt;&lt;th width=""100"" title=""Timestamp in GMT (low resolution timer)""&gt;Time&lt;/th&gt;&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;1.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""FailedRequestsTracingModule"", Notification=""BEGIN_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""ApplicationInitializationModule"", Notification=""BEGIN_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;3.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""ApplicationInitializationModule"", Notification=""BEGIN_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""ConfigurationValidationModule"", Notification=""BEGIN_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;5.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""ConfigurationValidationModule"", Notification=""BEGIN_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""RewriteModule"", Notification=""BEGIN_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;7.&lt;/td&gt;
&lt;td&gt;URL_REWRITE_START&lt;/td&gt;
&lt;td&gt;RequestURL=""/"", Scope=""Distributed"", Type=""Inbound""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8.&lt;/td&gt;
&lt;td&gt;REWRITE_FROM_CACHE_ACTION&lt;/td&gt;
&lt;td&gt;CachedRewriteURL=""/cache/index.html""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;9.&lt;/td&gt;
&lt;td&gt;URL_REWRITE_END&lt;/td&gt;
&lt;td&gt;RequestURL=""/cache/index.html""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10.&lt;/td&gt;
&lt;td&gt;GENERAL_CHILD_REQUEST_START&lt;/td&gt;
&lt;td&gt;SiteId=""29"", RequestURL=""http://example.com:80/cache/index.html"", RequestVerb=""GET"", RecursiveLevel=""1""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;11.&lt;/td&gt;
&lt;td&gt;GENERAL_REQUEST_START&lt;/td&gt;
&lt;td&gt;SiteId=""29"", AppPoolId=""covid"", ConnId=""1610649729"", RawConnId=""0"", RequestURL=""http://example.com:80/cache/index.html"", RequestVerb=""GET""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12.&lt;/td&gt;
&lt;td&gt;PRE_BEGIN_REQUEST_START&lt;/td&gt;
&lt;td&gt;ModuleName=""DynamicIpRestrictionModule""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;13.&lt;/td&gt;
&lt;td&gt;PRE_BEGIN_REQUEST_END&lt;/td&gt;
&lt;td&gt;ModuleName=""DynamicIpRestrictionModule"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;14.&lt;/td&gt;
&lt;td&gt;PRE_BEGIN_REQUEST_START&lt;/td&gt;
&lt;td&gt;ModuleName=""FailedRequestsTracingModule""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;15.&lt;/td&gt;
&lt;td&gt;PRE_BEGIN_REQUEST_END&lt;/td&gt;
&lt;td&gt;ModuleName=""FailedRequestsTracingModule"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16.&lt;/td&gt;
&lt;td&gt;PRE_BEGIN_REQUEST_START&lt;/td&gt;
&lt;td&gt;ModuleName=""RequestMonitorModule""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;17.&lt;/td&gt;
&lt;td&gt;PRE_BEGIN_REQUEST_END&lt;/td&gt;
&lt;td&gt;ModuleName=""RequestMonitorModule"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;18.&lt;/td&gt;
&lt;td&gt;PRE_BEGIN_REQUEST_START&lt;/td&gt;
&lt;td&gt;ModuleName=""IsapiFilterModule""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;19.&lt;/td&gt;
&lt;td&gt;PRE_BEGIN_REQUEST_END&lt;/td&gt;
&lt;td&gt;ModuleName=""IsapiFilterModule"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;20.&lt;/td&gt;
&lt;td&gt;PRE_BEGIN_REQUEST_START&lt;/td&gt;
&lt;td&gt;ModuleName=""RewriteModule""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;21.&lt;/td&gt;
&lt;td&gt;PRE_BEGIN_REQUEST_END&lt;/td&gt;
&lt;td&gt;ModuleName=""RewriteModule"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;22.&lt;/td&gt;
&lt;td&gt;GENERAL_ENDPOINT_INFORMATION&lt;/td&gt;
&lt;td&gt;RemoteAddress=""193.232.254.109"", RemotePort=""63904"", LocalAddress=""193.232.254.193"", LocalPort=""80""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;23.&lt;/td&gt;
&lt;td&gt;GENERAL_REQUEST_HEADERS&lt;/td&gt;
&lt;td&gt;Headers=""Cache-Control: no-cache
Connection: keep-alive
Pragma: no-cache
Content-Length: 0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
Accept-Encoding: gzip, deflate
Accept-Language: ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:75.0) Gecko/20100101 Firefox/75.0
Upgrade-Insecure-Requests: 1
X-Original-URL: /
""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;24.&lt;/td&gt;
&lt;td&gt;URL_CACHE_ACCESS_START&lt;/td&gt;
&lt;td&gt;RequestURL=""/cache/index.html""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;25.&lt;/td&gt;
&lt;td&gt;URL_CACHE_ACCESS_END&lt;/td&gt;
&lt;td&gt;PhysicalPath="""", URLInfoFromCache=""true"", URLInfoAddedToCache=""false"", ErrorCode=""Операция успешно завершена.
 (0x0)""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;26.&lt;/td&gt;
&lt;td&gt;GENERAL_GET_URL_METADATA&lt;/td&gt;
&lt;td&gt;PhysicalPath="""", AccessPerms=""513""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;27.&lt;/td&gt;
&lt;td&gt;HANDLER_CHANGED&lt;/td&gt;
&lt;td&gt;OldHandlerName="""", NewHandlerName=""StaticFile"", NewHandlerModules=""StaticFileModule,DefaultDocumentModule,DirectoryListingModule"", NewHandlerScriptProcessor="""", NewHandlerType=""""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;28.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""IsapiFilterModule"", Notification=""MAP_PATH"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;29.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""IsapiFilterModule"", Notification=""MAP_PATH"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;30.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""HttpCacheModule"", Notification=""BEGIN_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;31.&lt;/td&gt;
&lt;td&gt;OUTPUT_CACHE_DISABLED&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;32.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""HttpCacheModule"", Notification=""BEGIN_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;33.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""IpRestrictionModule"", Notification=""BEGIN_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;34.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""IpRestrictionModule"", Notification=""BEGIN_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;35.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""RequestFilteringModule"", Notification=""BEGIN_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;36.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""RequestFilteringModule"", Notification=""BEGIN_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;37.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""FailedRequestsTracingModule"", Notification=""BEGIN_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;38.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""FailedRequestsTracingModule"", Notification=""BEGIN_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;39.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""ApplicationInitializationModule"", Notification=""BEGIN_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;40.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""ApplicationInitializationModule"", Notification=""BEGIN_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;41.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""ConfigurationValidationModule"", Notification=""BEGIN_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;42.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""ConfigurationValidationModule"", Notification=""BEGIN_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;43.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""RewriteModule"", Notification=""BEGIN_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;44.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""RewriteModule"", Notification=""BEGIN_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;45.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""IsapiFilterModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;46.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""IsapiFilterModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;47.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""CertificateMappingAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;48.&lt;/td&gt;
&lt;td&gt;AUTH_START&lt;/td&gt;
&lt;td&gt;AuthTypeSupported=""MapCliCert""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;49.&lt;/td&gt;
&lt;td&gt;AUTH_END&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;50.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""CertificateMappingAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;51.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""BasicAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;52.&lt;/td&gt;
&lt;td&gt;AUTH_START&lt;/td&gt;
&lt;td&gt;AuthTypeSupported=""Basic""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;53.&lt;/td&gt;
&lt;td&gt;AUTH_END&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;54.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""BasicAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;55.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""WindowsAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;56.&lt;/td&gt;
&lt;td&gt;AUTH_START&lt;/td&gt;
&lt;td&gt;AuthTypeSupported=""NT""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;57.&lt;/td&gt;
&lt;td&gt;AUTH_END&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;58.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""WindowsAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;59.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""DigestAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;60.&lt;/td&gt;
&lt;td&gt;AUTH_START&lt;/td&gt;
&lt;td&gt;AuthTypeSupported=""Digest""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;61.&lt;/td&gt;
&lt;td&gt;AUTH_END&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;62.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""DigestAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;63.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""IISCertificateMappingAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;64.&lt;/td&gt;
&lt;td&gt;AUTH_START&lt;/td&gt;
&lt;td&gt;AuthTypeSupported=""MapCliCert""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;65.&lt;/td&gt;
&lt;td&gt;AUTH_END&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;66.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""IISCertificateMappingAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;67.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""AnonymousAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;68.&lt;/td&gt;
&lt;td&gt;AUTH_START&lt;/td&gt;
&lt;td&gt;AuthTypeSupported=""Anonymous""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;69.&lt;/td&gt;
&lt;td&gt;AUTH_REQUEST_AUTH_TYPE&lt;/td&gt;
&lt;td&gt;RequestAuthType=""Anonymous""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;70.&lt;/td&gt;
&lt;td&gt;AUTH_SUCCEEDED&lt;/td&gt;
&lt;td&gt;AuthType=""NT"", NTLMUsed=""false"", RemoteUserName="""", AuthUserName="""", TokenImpersonationLevel=""ImpersonationImpersonate""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;71.&lt;/td&gt;
&lt;td&gt;USER_SET&lt;/td&gt;
&lt;td&gt;AuthType="""", UserName="""", SupportsIsInRole=""true""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;72.&lt;/td&gt;
&lt;td&gt;AUTH_END&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;73.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""AnonymousAuthenticationModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;74.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""IsapiFilterModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotification=""true""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;75.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""IsapiFilterModule"", Notification=""AUTHENTICATE_REQUEST"", fIsPostNotificationEvent=""true"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;76.&lt;/td&gt;
&lt;td&gt;FILE_CACHE_ACCESS_START&lt;/td&gt;
&lt;td&gt;FileName=""C:\inetpub\covid\cache\index.html"", UserName=""IUSR"", DomainName=""NT AUTHORITY""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;77.&lt;/td&gt;
&lt;td&gt;FILE_CACHE_ACCESS_END&lt;/td&gt;
&lt;td&gt;Successful=""false"", FileFromCache=""false"", FileAddedToCache=""false"", FileDirmoned=""true"", LastModCheckErrorIgnored=""true"", ErrorCode=""Не удается найти указанный файл.
 (0x80070002)"", LastModifiedTime=""""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;78.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""UrlAuthorizationModule"", Notification=""AUTHORIZE_REQUEST"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;79.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""UrlAuthorizationModule"", Notification=""AUTHORIZE_REQUEST"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;80.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""HttpCacheModule"", Notification=""RESOLVE_REQUEST_CACHE"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;81.&lt;/td&gt;
&lt;td&gt;OUTPUT_CACHE_LOOKUP_START&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;82.&lt;/td&gt;
&lt;td&gt;OUTPUT_CACHE_LOOKUP_END&lt;/td&gt;
&lt;td&gt;Result=""CACHING_DISABLED""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;83.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""HttpCacheModule"", Notification=""RESOLVE_REQUEST_CACHE"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;84.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""ApplicationRequestRouting"", Notification=""MAP_REQUEST_HANDLER"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;85.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""ApplicationRequestRouting"", Notification=""MAP_REQUEST_HANDLER"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;86.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""StaticCompressionModule"", Notification=""MAP_REQUEST_HANDLER"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;87.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""StaticCompressionModule"", Notification=""MAP_REQUEST_HANDLER"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;88.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_START&lt;/td&gt;
&lt;td&gt;ModuleName=""HttpRedirectionModule"", Notification=""MAP_REQUEST_HANDLER"", fIsPostNotification=""false""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=""alt""&gt;
&lt;td&gt;89.&lt;/td&gt;
&lt;td&gt;NOTIFY_MODULE_END&lt;/td&gt;
&lt;td&gt;ModuleName=""HttpRedirectionModule"", Notification=""MAP_REQUEST_HANDLER"", fIsPostNotificationEvent=""false"", NotificationStatus=""NOTIFICATION_CONTINUE""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;90.&lt;/td&gt;
&lt;td&gt;MODULE_SET_RESPONSE_ERROR_STATUS&lt;br&gt;
&lt;span class=""severity-warning""&gt;Warning&lt;/span&gt;
&lt;/td&gt;
&lt;td&gt;ModuleName=""IIS Web Core"", Notification=""MAP_REQUEST_HANDLER"", HttpStatus=""404"", HttpReason=""Not Found"", HttpSubStatus=""0"", ErrorCode=""Не удается найти указанный файл.
 (0x80070002)"", ConfigExceptionInfo=""""&lt;/td&gt;
&lt;td&gt;11:14:15.431&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;</code></pre>
</div>
</div>
</p>
"
60763700,"<p>I'm trying to show JSON data from this <a href=""https://pomber.github.io/covid19/timeseries.json"" rel=""nofollow noreferrer"">https://pomber.github.io/covid19/timeseries.json</a>, but I got an error:</p>

<p><code>(ErrorException(code: 0): Undefined index: confirmed</code></p>

<p>What I expect is I can show the list of Country Name following with the Date, Confirmed, etc.</p>

<p>Here's my view:</p>

<pre><code>@foreach($results as $json_d)

  {{ $json_d['date'] }}
  {{ $json_d['confirmed'] }}
  {{ $json_d['deaths'] }}
  {{ $json_d['recovered'] }}

@endforeach
</code></pre>

<p>And here's my controller:</p>

<pre><code>$client = new Client();

$request = $client-&gt;get('https://pomber.github.io/covid19/timeseries.json');
$response = $request-&gt;getBody()-&gt;getContents();
$results = json_decode($response, true);

return view('dashboard', compact('results'));

</code></pre>

<p>Any help would be appreciated :)</p>
"
61408968,"<p>I made an API call and got the data.
Here is the code: </p>

<pre><code>&lt;html&gt;
&lt;script&gt;
function APIcall()
{
    var xhr = new XMLHttpRequest();
    xhr.open('GET', 'https://api.covid19india.org/state_district_wise.json', true)
    xhr.send();
    xhr.onreadystatechange = function(){
        if(this.readyState==4 &amp;&amp; this.status==200)
        {
            var returnData=JSON.parse(xhr.responseText);
            console.log(returnData);
        }
    }
}
&lt;/script&gt;
&lt;body onload=""APIcall()""&gt;&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>Now how do i loop through this data.
I tried using for loop on this but it did not work.</p>
"
61664359,"<p>I have been working on a COVID-19 dashboard where I want to display the daily cases and daily deaths in the line graph. I can get the data from the following api <a href=""https://api.covid19api.com/total/dayone/country/United%20Kingdom"" rel=""nofollow noreferrer"">https://api.covid19api.com/total/dayone/country/United%20Kingdom</a> but it return me the total commutative cases and total commutative deaths on the given date. The data returned is in the following structure</p>

<pre><code> const data = [ 
 {
""Country"": ""United Kingdom"",
""CountryCode"": """",
""Province"": """",
""City"": """",
""CityCode"": """",
""Lat"": ""0"",
""Lon"": ""0"",
""Confirmed"": 190584,
""Deaths"": 28734,
""Recovered"": 0,
""Active"": 161850,
""Date"": ""2020-05-04T00:00:00Z""
},
{
""Country"": ""United Kingdom"",
""CountryCode"": """",
""Province"": """",
""City"": """",
""CityCode"": """",
""Lat"": ""0"",
""Lon"": ""0"",
""Confirmed"": 194990,
""Deaths"": 29427,
""Recovered"": 0,
""Active"": 165563,
""Date"": ""2020-05-05T00:00:00Z""
},
{
""Country"": ""United Kingdom"",
""CountryCode"": """",
""Province"": """",
""City"": """",
""CityCode"": """",
""Lat"": ""0"",
""Lon"": ""0"",
""Confirmed"": 201101,
""Deaths"": 30076,
""Recovered"": 0,
""Active"": 171025,
""Date"": ""2020-05-06T00:00:00Z""
}
] 
</code></pre>

<p>Where Confirmed is the total number of cases detected on that day. To calculate the daily cases on the specific day we can subtract the confirmed from the previous confirmed of previous date. For example 2020-05-05 the number of cases confirmed on that day can be calculated by subtracting the number of cases on 20-05-04 the previous day. So the calculation would be 194990- 190584 = 4442. For the first object of the array the value stays the same since there is no previous record to subtract from as I will be fetching the day one when a case was detected in that country. Therefore the desired data would be the following </p>

<pre><code>const desiredData= [ 
 {
""Country"": ""United Kingdom"",
""CountryCode"": """",
""Province"": """",
""City"": """",
""CityCode"": """",
""Lat"": ""0"",
""Lon"": ""0"",
""Confirmed"": 190584,
""Deaths"": 28734,
""Recovered"": 0,
""Active"": 161850,
""Date"": ""2020-05-04T00:00:00Z""
},
{
""Country"": ""United Kingdom"",
""CountryCode"": """",
""Province"": """",
""City"": """",
""CityCode"": """",
""Lat"": ""0"",
""Lon"": ""0"",
""Confirmed"": 4442,
""Deaths"": 29427,
""Recovered"": 0,
""Active"": 165563,
""Date"": ""2020-05-05T00:00:00Z""
},
{
""Country"": ""United Kingdom"",
""CountryCode"": """",
""Province"": """",
""City"": """",
""CityCode"": """",
""Lat"": ""0"",
""Lon"": ""0"",
""Confirmed"": 6111,
""Deaths"": 30076,
""Recovered"": 0,
""Active"": 171025,
""Date"": ""2020-05-06T00:00:00Z""
}
] 
</code></pre>

<p>I am using Vue.js I think this could be a basic javascript function which can loop through the array and subtract the ""Confirmed"" of current object from the ""Confirmed"" of previous object. Please do let me know how this can be acheived. Many Thanks </p>
"
61366080,"<p>Hi I am doing a NodeJS practice and I would like to let the input appear on the url as (website).com/results/NameOfCountry, where NameOfCountry is a variable containing the input by the user.
I don't know how to do it after trying path.dirname(), which I don't think is correct.</p>

<p>Everytime I key in the country name, it would show a link ending like /results?searchCountry=America and I'd like to get rid of the ?searchCountry because the correct path has an ending like /results/America</p>

<p>Could anyone help me with this? Thanks in advance.</p>

<p>Here's the Code
<strong>NodeJS:</strong></p>

<pre><code>var express = require(""express"");
var haste = express();
var bp = require(""body-parser"");
var request = require(""request"");
 var mime=require('mime-types');

haste.set(""view engine"", ""ejs"");

haste.get(""/"", function(req, res){
    res.render(""search"");
})

haste.get(""/results"", function(req, res){
    var apple = ""https://api.covid19api.com/total/country/"" + query;
    var query = req.you.value;
    request(apple, function(error, response, require){
        if(!error &amp;&amp; response.statusCode == 200){
            var data = JSON.parse();
            res.render(""info"", {data:data});
        }
    })
})



haste.listen(process.env.PORT || 3000, process.env.IP, function(){
    console.log(""Server has started!"");
});
</code></pre>

<p>On EJS, here's how the input form is:</p>

<pre><code>&lt;h1&gt;
    Find Cases By Country:
&lt;/h1&gt;
&lt;form action=""/results"" method=""GET""&gt;
    &lt;input type=""text"" placeholder=""enter country"" class=""you""&gt;
    &lt;input type=""submit""&gt;
&lt;/form&gt;
</code></pre>
"
61337147,"<p>I have tried all possible means but no one seems to work as expected. I trying to extract data from a particular country in this covid-19 api but all my attempts failed. </p>

<p>Here is some part of the JSON data am trying to extract data from; </p>

<pre><code>{
""Global"": {
""NewConfirmed"": 70871,
""TotalConfirmed"": 2470922,
""NewDeaths"": 4940,
""TotalDeaths"": 169952,
""NewRecovered"": 21835,
""TotalRecovered"": 645094
},
""Countries"": [
{
""Country"": ""ALA Aland Islands"",
""CountryCode"": ""AX"",
""Slug"": ""ala-aland-islands"",
""NewConfirmed"": 0,
""TotalConfirmed"": 0,
""NewDeaths"": 0,
""TotalDeaths"": 0,
""NewRecovered"": 0,
""TotalRecovered"": 0,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Afghanistan"",
""CountryCode"": ""AF"",
""Slug"": ""afghanistan"",
""NewConfirmed"": 30,
""TotalConfirmed"": 1026,
""NewDeaths"": 3,
""TotalDeaths"": 36,
""NewRecovered"": 4,
""TotalRecovered"": 135,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Albania"",
""CountryCode"": ""AL"",
""Slug"": ""albania"",
""NewConfirmed"": 22,
""TotalConfirmed"": 584,
""NewDeaths"": 0,
""TotalDeaths"": 26,
""NewRecovered"": 13,
""TotalRecovered"": 327,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Algeria"",
""CountryCode"": ""DZ"",
""Slug"": ""algeria"",
""NewConfirmed"": 89,
""TotalConfirmed"": 2718,
""NewDeaths"": 9,
""TotalDeaths"": 384,
""NewRecovered"": 52,
""TotalRecovered"": 1099,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""American Samoa"",
""CountryCode"": ""AS"",
""Slug"": ""american-samoa"",
""NewConfirmed"": 0,
""TotalConfirmed"": 0,
""NewDeaths"": 0,
""TotalDeaths"": 0,
""NewRecovered"": 0,
""TotalRecovered"": 0,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Andorra"",
""CountryCode"": ""AD"",
""Slug"": ""andorra"",
""NewConfirmed"": 4,
""TotalConfirmed"": 717,
""NewDeaths"": 1,
""TotalDeaths"": 37,
""NewRecovered"": 13,
""TotalRecovered"": 248,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Angola"",
""CountryCode"": ""AO"",
""Slug"": ""angola"",
""NewConfirmed"": 0,
""TotalConfirmed"": 24,
""NewDeaths"": 0,
""TotalDeaths"": 2,
""NewRecovered"": 0,
""TotalRecovered"": 6,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Anguilla"",
""CountryCode"": ""AI"",
""Slug"": ""anguilla"",
""NewConfirmed"": 0,
""TotalConfirmed"": 0,
""NewDeaths"": 0,
""TotalDeaths"": 0,
""NewRecovered"": 0,
""TotalRecovered"": 0,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Antarctica"",
""CountryCode"": ""AQ"",
""Slug"": ""antarctica"",
""NewConfirmed"": 0,
""TotalConfirmed"": 0,
""NewDeaths"": 0,
""TotalDeaths"": 0,
""NewRecovered"": 0,
""TotalRecovered"": 0,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Antigua and Barbuda"",
""CountryCode"": ""AG"",
""Slug"": ""antigua-and-barbuda"",
""NewConfirmed"": 0,
""TotalConfirmed"": 23,
""NewDeaths"": 0,
""TotalDeaths"": 3,
""NewRecovered"": 0,
""TotalRecovered"": 3,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Argentina"",
""CountryCode"": ""AR"",
""Slug"": ""argentina"",
""NewConfirmed"": 102,
""TotalConfirmed"": 2941,
""NewDeaths"": 4,
""TotalDeaths"": 136,
""NewRecovered"": 28,
""TotalRecovered"": 737,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Armenia"",
""CountryCode"": ""AM"",
""Slug"": ""armenia"",
""NewConfirmed"": 48,
""TotalConfirmed"": 1339,
""NewDeaths"": 2,
""TotalDeaths"": 22,
""NewRecovered"": 35,
""TotalRecovered"": 580,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Aruba"",
""CountryCode"": ""AW"",
""Slug"": ""aruba"",
""NewConfirmed"": 0,
""TotalConfirmed"": 0,
""NewDeaths"": 0,
""TotalDeaths"": 0,
""NewRecovered"": 0,
""TotalRecovered"": 0,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Australia"",
""CountryCode"": ""AU"",
""Slug"": ""australia"",
""NewConfirmed"": 0,
""TotalConfirmed"": 6547,
""NewDeaths"": 0,
""TotalDeaths"": 67,
""NewRecovered"": 0,
""TotalRecovered"": 4124,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Austria"",
""CountryCode"": ""AT"",
""Slug"": ""austria"",
""NewConfirmed"": 46,
""TotalConfirmed"": 14795,
""NewDeaths"": 18,
""TotalDeaths"": 470,
""NewRecovered"": 130,
""TotalRecovered"": 10631,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Azerbaijan"",
""CountryCode"": ""AZ"",
""Slug"": ""azerbaijan"",
""NewConfirmed"": 38,
""TotalConfirmed"": 1436,
""NewDeaths"": 0,
""TotalDeaths"": 19,
""NewRecovered"": 79,
""TotalRecovered"": 791,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Bahamas"",
""CountryCode"": ""BS"",
""Slug"": ""bahamas"",
""NewConfirmed"": 5,
""TotalConfirmed"": 60,
""NewDeaths"": 0,
""TotalDeaths"": 9,
""NewRecovered"": 1,
""TotalRecovered"": 11,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Bahrain"",
""CountryCode"": ""BH"",
""Slug"": ""bahrain"",
""NewConfirmed"": 26,
""TotalConfirmed"": 1907,
""NewDeaths"": 0,
""TotalDeaths"": 7,
""NewRecovered"": 10,
""TotalRecovered"": 769,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Bangladesh"",
""CountryCode"": ""BD"",
""Slug"": ""bangladesh"",
""NewConfirmed"": 492,
""TotalConfirmed"": 2948,
""NewDeaths"": 10,
""TotalDeaths"": 101,
""NewRecovered"": 10,
""TotalRecovered"": 85,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Barbados"",
""CountryCode"": ""BB"",
""Slug"": ""barbados"",
""NewConfirmed"": 0,
""TotalConfirmed"": 75,
""NewDeaths"": 0,
""TotalDeaths"": 5,
""NewRecovered"": 2,
""TotalRecovered"": 19,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Belarus"",
""CountryCode"": ""BY"",
""Slug"": ""belarus"",
""NewConfirmed"": 1485,
""TotalConfirmed"": 6264,
""NewDeaths"": 4,
""TotalDeaths"": 51,
""NewRecovered"": 20,
""TotalRecovered"": 514,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Belgium"",
""CountryCode"": ""BE"",
""Slug"": ""belgium"",
""NewConfirmed"": 1487,
""TotalConfirmed"": 39983,
""NewDeaths"": 145,
""TotalDeaths"": 5828,
""NewRecovered"": 138,
""TotalRecovered"": 8895,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Belize"",
""CountryCode"": ""BZ"",
""Slug"": ""belize"",
""NewConfirmed"": 0,
""TotalConfirmed"": 18,
""NewDeaths"": 0,
""TotalDeaths"": 2,
""NewRecovered"": 0,
""TotalRecovered"": 2,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Benin"",
""CountryCode"": ""BJ"",
""Slug"": ""benin"",
""NewConfirmed"": 19,
""TotalConfirmed"": 54,
""NewDeaths"": 0,
""TotalDeaths"": 1,
""NewRecovered"": 9,
""TotalRecovered"": 27,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Bermuda"",
""CountryCode"": ""BM"",
""Slug"": ""bermuda"",
""NewConfirmed"": 0,
""TotalConfirmed"": 0,
""NewDeaths"": 0,
""TotalDeaths"": 0,
""NewRecovered"": 0,
""TotalRecovered"": 0,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Bhutan"",
""CountryCode"": ""BT"",
""Slug"": ""bhutan"",
""NewConfirmed"": 0,
""TotalConfirmed"": 5,
""NewDeaths"": 0,
""TotalDeaths"": 0,
""NewRecovered"": 0,
""TotalRecovered"": 2,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Bolivia"",
""CountryCode"": ""BO"",
""Slug"": ""bolivia"",
""NewConfirmed"": 44,
""TotalConfirmed"": 564,
""NewDeaths"": 1,
""TotalDeaths"": 33,
""NewRecovered"": 0,
""TotalRecovered"": 31,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Bosnia and Herzegovina"",
""CountryCode"": ""BA"",
""Slug"": ""bosnia-and-herzegovina"",
""NewConfirmed"": 24,
""TotalConfirmed"": 1309,
""NewDeaths"": 1,
""TotalDeaths"": 49,
""NewRecovered"": 34,
""TotalRecovered"": 381,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Botswana"",
""CountryCode"": ""BW"",
""Slug"": ""botswana"",
""NewConfirmed"": 0,
""TotalConfirmed"": 20,
""NewDeaths"": 0,
""TotalDeaths"": 1,
""NewRecovered"": 0,
""TotalRecovered"": 0,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Bouvet Island"",
""CountryCode"": ""BV"",
""Slug"": ""bouvet-island"",
""NewConfirmed"": 0,
""TotalConfirmed"": 0,
""NewDeaths"": 0,
""TotalDeaths"": 0,
""NewRecovered"": 0,
""TotalRecovered"": 0,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""Brazil"",
""CountryCode"": ""BR"",
""Slug"": ""brazil"",
""NewConfirmed"": 2089,
""TotalConfirmed"": 40743,
""NewDeaths"": 125,
""TotalDeaths"": 2587,
""NewRecovered"": 0,
""TotalRecovered"": 22130,
""Date"": ""2020-04-21T03:35:46Z""
},
{
""Country"": ""British Indian Ocean Territory"",
""CountryCode"": ""IO"",
""Slug"": ""british-indian-ocean-territory"",
""NewConfirmed"": 0,
""TotalConfirmed"": 0,
""NewDeaths"": 0,
""TotalDeaths"": 0,
""NewRecovered"": 0,
""TotalRecovered"": 0,
""Date"": ""2020-04-21T03:35:46Z""
},
</code></pre>

<p>Here is my code the one provided by the api using node.js </p>

<pre><code>var request = require('request');
var axios = require('axios')
var options = {
    'method': 'GET',
    'url': 'https://api.covid19api.com/summary',
    'headers': {

    }
};
request(options, function (error, response) {
    if (error) throw new Error(error);
    console.log(JSON.parse(response.body.countries));
});

</code></pre>
"
61639841,"<p>I am trying to visualize the number of covid-19 cases worldwide. And found out that <a href=""https://plotly.com"" rel=""nofollow noreferrer"">plotly</a> was the easiest and fasted javascript library to do a world choropleth map for the world. Below is the map which I could plot based on the number of cases per million population: 
<a href=""https://i.stack.imgur.com/ADqsb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ADqsb.png"" alt=""enter image description here""></a>
But the problem is that I wanted to change the range of the colourbar shown on the right, as the maximum value for any particular country is much lesser than 1200. Please suggest a way so that I can change the range of the colourbar.</p>

<p>Below is my javascript code:</p>

<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
    &lt;title&gt;CORONA PLOTTING&lt;/title&gt;
    &lt;script src=""https://cdn.plot.ly/plotly-latest.min.js""&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div id=""myDiv"" style=""width:1000px;height:600px;""&gt;&lt;/div&gt;

    &lt;script&gt;
    TESTER = document.getElementById('tester');
    Plotly.d3.csv('https://raw.githubusercontent.com/thinking-tomorrow/Covid19/master/covid_data.csv', function(err, rows){
        function unpack(rows, key) {
          return rows.map(function(row) { return row[key]; });
        }

        var data = [{
            type: 'choropleth',
            locationmode: 'country names',
            locations: unpack(rows, 'location'),
            z: unpack(rows, 'total_deaths_per_million'),
            text: unpack(rows, 'location'),
            autocolorscale: true,
        }];

        var layout = {
          title: 'Covid19 Cases World Wide',
          geo: {
              projection: {
                  type: 'robinson'
              }
          }
        };

        Plotly.newPlot(""myDiv"", data, layout, {showLink: false});

    });
    &lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>Thank you in advance.</p>
"
61397152,"<p>I am following <a href=""https://github.com/adrianhajdin/project_corona_tracker"" rel=""nofollow noreferrer"">https://github.com/adrianhajdin/project_corona_tracker</a>
<a href=""https://www.youtube.com/watch?v=khJlrj3Y6Ls"" rel=""nofollow noreferrer"">https://www.youtube.com/watch?v=khJlrj3Y6Ls</a></p>

<p>So in this project the following api is used-
<a href=""https://covid19.mathdro.id/api/daily"" rel=""nofollow noreferrer"">https://covid19.mathdro.id/api/daily</a></p>

<p>here I am getting covid cases values for each day. I need to display the number of cases that increased from yesterday  to today</p>

<p>so I am trying to get values of current date confirmed cases(total cases)- yesterday's date confirmed cases</p>

<p>this is my card.jsx file:</p>

<pre><code>    import React from ""react"";
    import { Card, CardContent, Typography, Grid } from ""@material-ui/core"";
    import CountUp from ""react-countup"";
    import cx from ""classnames"";

    import styles from ""./Cards.module.css"";

    const Info = ({ data: { confirmed, recovered, deaths, lastUpdate } }) =&gt; {
      if (!confirmed) {
        return ""Loading..."";
      }

      return (
        &lt;div className={styles.container}&gt;
          &lt;Grid container spacing={3} justify=""center""&gt;
            &lt;Grid
              item
              xs={12}
              md={3}
              component={Card}
              className={cx(styles.card, styles.infected)}
            &gt;
              &lt;CardContent&gt;
                &lt;Typography color=""textSecondary"" gutterBottom&gt;
                  Infected
                &lt;/Typography&gt;
                &lt;Typography variant=""h5"" component=""h2""&gt;
                  &lt;div&gt;
 ---------------&gt; total cases-yesterday's cases
                  &lt;/div&gt;
                  &lt;CountUp
                    start={0}
                    end={confirmed.value}
                    duration={2.75}
                    separator="",""
                  /&gt;
                &lt;/Typography&gt;
                &lt;Typography color=""textSecondary""&gt;
                  {new Date(lastUpdate).toDateString()}
                &lt;/Typography&gt;
                &lt;Typography variant=""body2"" component=""p""&gt;
                  Number of active cases of COVID-19.
                &lt;/Typography&gt;
              &lt;/CardContent&gt;
            &lt;/Grid&gt;
            &lt;Grid
              item
              xs={12}
              md={3}
              component={Card}
              className={cx(styles.card, styles.recovered)}
            &gt;
              &lt;CardContent&gt;
                &lt;Typography color=""textSecondary"" gutterBottom&gt;
                  Recovered
                &lt;/Typography&gt;
                &lt;Typography variant=""h5"" component=""h2""&gt;
                  &lt;div&gt;
                    {(
                      (Number(recovered.value) / Number(confirmed.value)) *
                      100
                    ).toFixed(2)}{"" ""}
                    %
                  &lt;/div&gt;
                  &lt;CountUp
                    start={0}
                    end={recovered.value}
                    duration={2.75}
                    separator="",""
                  /&gt;
                &lt;/Typography&gt;
                &lt;Typography color=""textSecondary""&gt;
                  {new Date(lastUpdate).toDateString()}
                &lt;/Typography&gt;
                &lt;Typography variant=""body2"" component=""p""&gt;
                  Number of recoveries from COVID-19.
                &lt;/Typography&gt;
              &lt;/CardContent&gt;
            &lt;/Grid&gt;
            &lt;Grid
              item
              xs={12}
              md={3}
              component={Card}
              className={cx(styles.card, styles.deaths)}
            &gt;
              &lt;CardContent&gt;
                &lt;Typography color=""textSecondary"" gutterBottom&gt;
                  Deaths
                &lt;/Typography&gt;
                &lt;Typography variant=""h5"" component=""h2""&gt;
                  &lt;div&gt;
                    {(
                      (Number(deaths.value) / Number(confirmed.value)) *
                      100
                    ).toFixed(2)}{"" ""}
                    %
                  &lt;/div&gt;
                  &lt;CountUp
                    start={0}
                    end={deaths.value}
                    duration={2.75}
                    separator="",""
                  /&gt;
                &lt;/Typography&gt;
                &lt;Typography color=""textSecondary""&gt;
                  {new Date(lastUpdate).toDateString()}
                &lt;/Typography&gt;
                &lt;Typography variant=""body2"" component=""p""&gt;
                  Number of deaths caused by COVID-19.
                &lt;/Typography&gt;
              &lt;/CardContent&gt;
            &lt;/Grid&gt;
          &lt;/Grid&gt;
        &lt;/div&gt;
      );
    };
    export default Info;
</code></pre>
"
60825119,"<p>I am creating a table, want to have 'filter' icon on each of the elements of the table header, which tell user the row is sortable, need help !!! </p>

<p><a href=""https://i.stack.imgur.com/tnoN2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/tnoN2.png"" alt=""enter image description here""></a></p>

<p><a href=""https://material-table.com/#/docs/all-props"" rel=""nofollow noreferrer"">https://material-table.com/#/docs/all-props</a></p>

<pre><code>        return (
            &lt;div className=""rank-table""&gt;
                &lt;MaterialTable
                    columns={(isMobile ? mobileColumnArray : desktopColumnArray)}
                    data={dataArray}
                    localization={{
                        toolbar: {
                            searchPlaceholder: ""Search for Country""
                        }
                    }}
                    options={{
                        exportButton: true,
                        showTitle: false,
                        exportFileName: moment().format(""YYYY-MMMM-DD"").toString() + "" COVID-19 Data"",
                        // searchFieldStyle: {
                        //     border: ""1px solid black"",
                        //     width: ""100%""
                        // },
                        searchFieldAlignment: ""left"",
                        fixedColumns: {
                            left: 1,
                            right: 0
                        },
                        pageSize: 15,
                        pageSizeOptions: [15,20,25],
                        paginationType: ""normal"",
                        draggable: false,
                    }}
                /&gt;
            &lt;/div&gt;
        )
    }
</code></pre>
"
61218708,"<p>I am trying to consume an API and display it on my app. It is currently pulling in the data in the console log but I can't seem to access it to display it on my app as it is just stuck on loading... I want to show the data with the number of confirmed cases on the h5 variant of the first card {confirmed.value} But not to sure why it is not showing.  </p>

<p>Cards</p>

<pre><code>import React from 'react'
import {Card, CardContent, Typography, Grid} from '@material-ui/core'
import styles from './Cards.module.css'



export default function Cards({data: {confirmed, recovered, deaths}}){


    if(!confirmed){
        return`Loading...`


    }


    return (
        &lt;div className={styles.container}&gt;
            &lt;Grid container spacing={3} justify=""center""&gt;
            &lt;Grid item component={Card}&gt;
                &lt;CardContent&gt;
                    &lt;Typography color=""textSecondary"" gutterBottom&gt;Infected&lt;/Typography&gt;
                    &lt;Typography variant=""h5""&gt;{confirmed.value}&lt;/Typography&gt;
                    &lt;Typography color=""textSecondary""&gt;REAL DATE&lt;/Typography&gt;
                    &lt;Typography variant=""body2""&gt;Number of active cases of COVID-19&lt;/Typography&gt;
                &lt;/CardContent&gt;
            &lt;/Grid&gt;
            &lt;/Grid&gt;
            &lt;Grid container spacing={3} justify=""center""&gt;
            &lt;Grid item component={Card}&gt;
                &lt;CardContent&gt;
                    &lt;Typography color=""textSecondary"" gutterBottom&gt;Recovered&lt;/Typography&gt;
                    &lt;Typography variant=""h5""&gt;REAL DATA&lt;/Typography&gt;
                    &lt;Typography color=""textSecondary""&gt;REAL DATE&lt;/Typography&gt;
                    &lt;Typography variant=""body2""&gt;Number of Recovered cases of COVID-19&lt;/Typography&gt;
                &lt;/CardContent&gt;
            &lt;/Grid&gt;
            &lt;/Grid&gt;
            &lt;Grid container spacing={3} justify=""center""&gt;
            &lt;Grid item component={Card}&gt;
                &lt;CardContent&gt;
                    &lt;Typography color=""textSecondary"" gutterBottom&gt;Deaths&lt;/Typography&gt;
                    &lt;Typography variant=""h5""&gt;REAL DATA&lt;/Typography&gt;
                    &lt;Typography color=""textSecondary""&gt;REAL DATE&lt;/Typography&gt;
                    &lt;Typography variant=""body2""&gt;Number of Death cases of COVID-19&lt;/Typography&gt;
                &lt;/CardContent&gt;
            &lt;/Grid&gt;
            &lt;/Grid&gt;
        &lt;/div&gt;
    )
}
</code></pre>

<p>App JS</p>

<pre><code>import React, { Component } from 'react'

import {Cards, Chart, CountryPicker} from './components'
import styles from './App.module.css'
import {fetchData} from './api'


export default class App extends Component {
    state = {
        data: {},
    }

    async componentDidMount(){
        const fetchedData = await fetchData()
    console.log(fetchedData);

    this.setState({data: fetchedData})


    }

    render() {

        const {data} = this.state;

        return (
            &lt;div className={styles.container}&gt;
                &lt;Cards data={data} /&gt;
                &lt;CountryPicker/&gt;
                &lt;Chart/&gt;

            &lt;/div&gt;
        )
    }
}
</code></pre>

<p><a href=""https://i.stack.imgur.com/lptE6.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lptE6.png"" alt=""enter image description here""></a></p>
"
61268741,"<p>I am working on kepler.gl .... wright now i am reading data from an api and plot that data in keplr.gl and that's working fine here is the code ...</p>

<pre><code>import keplerGlReducer from ""kepler.gl/reducers"";
import { createStore, combineReducers, applyMiddleware } from ""redux"";
import { taskMiddleware } from ""react-palm/tasks"";
import { Provider, useDispatch } from ""react-redux"";
import KeplerGl from ""kepler.gl"";
import { addDataToMap } from ""kepler.gl/actions"";
import useSwr from ""swr"";

const reducers = combineReducers({
  keplerGl: keplerGlReducer
});

const store = createStore(reducers, {}, applyMiddleware(taskMiddleware));

export default function App() {
  return (
    &lt;Provider store={store}&gt;
      &lt;Map /&gt;
      &lt;csv/&gt;
    &lt;/Provider&gt;
  );
}

function Map() {
  const dispatch = useDispatch();
  const { data } = useSwr(""covid"", async () =&gt; {
    const response = await fetch(
     ""https://gist.githubusercontent.com/leighhalliday/a994915d8050e90d413515e97babd3b3/raw/a3eaaadcc784168e3845a98931780bd60afb362f/covid19.json""
     );
     const data = await response.json();
     return data;
   });

  React.useEffect(() =&gt; {
    if (data) {
      dispatch(
        addDataToMap({
          datasets: {
            info: {
              label: ""COVID-19"",
              id: ""covid19""
            },
            data
          },
          option: {
            centerMap: true,
            readOnly: false
          },
          config: {}
        })
      );
    }
  }, [dispatch, data]);

  return (
    &lt;KeplerGl
      id=""covid""
      mapboxApiAccessToken=""pk.eyJ1IjoiYWxpcmF6YTcwNSIsImEiOiJjazh5d2hjb3AwOHBqM2VsY21wOHo5eXprIn0.9G5CE4KqfbvU9HQ6WBuo3w""
      width={window.innerWidth}
      height={window.innerHeight}
    /&gt;
  );
}
</code></pre>

<p>now i want to read data from jason or csv file and plot that data into kepler.gl map .. how can i do this can anyone help me ?..... thanks </p>
"
61578516,"<p>After creating new module for my feature modules and separating their route paths from the app.module.ts I'm getting the error of,</p>

<pre><code>    core.js:6185 ERROR Error: Uncaught (in promise): NullInjectorError: R3InjectorError(AppModule)[LoginService -&gt; HttpClient -&gt; HttpClient -&gt; HttpClient]: 
  NullInjectorError: No provider for HttpClient!
NullInjectorError: R3InjectorError(AppModule)[LoginService -&gt; HttpClient -&gt; HttpClient -&gt; HttpClient]: 
  NullInjectorError: No provider for HttpClient!
    at NullInjector.get (core.js:1076)
    at R3Injector.get (core.js:16629)
    at R3Injector.get (core.js:16629)
    at R3Injector.get (core.js:16629)
    at injectInjectorOnly (core.js:931)
    at Module.ɵɵinject (core.js:941)
    at Object.LoginService_Factory [as factory] (login.service.ts:10)
    at R3Injector.hydrate (core.js:16865)
    at R3Injector.get (core.js:16617)
    at NgModuleRef$1.get (core.js:36027)
    at resolvePromise (zone-evergreen.js:798)
    at resolvePromise (zone-evergreen.js:750)
    at zone-evergreen.js:860
    at ZoneDelegate.invokeTask (zone-evergreen.js:399)
    at Object.onInvokeTask (core.js:41264)
    at ZoneDelegate.invokeTask (zone-evergreen.js:398)
    at Zone.runTask (zone-evergreen.js:167)
    at drainMicroTaskQueue (zone-evergreen.js:569)
    at ZoneTask.invokeTask [as invoke] (zone-evergreen.js:484)
    at invokeTask (zone-evergreen.js:1621)
</code></pre>

<p>I am creating a simple login service. From a welcome page once user clicks the ""play"" button the login page will arrive. However, whenever I'm clicking the respective button I'm getting the above error. And this seems like started arriving after I separated the login feature in a feature module. However, my service has injector defined as,</p>

<pre><code>@Injectable({
providedIn:'root'
</code></pre>

<p>})</p>

<p>So this means only one instance of service will be created and will be shared in entire APP. However, I'm now doubtful. Do, I need to declare my service somewhere in my feature module ? I have correctly imported,</p>

<pre><code>import { HttpClientModule } from '@angular/common/http';
</code></pre>

<p>in my app.module.ts. Here is my app.module.ts,</p>

<pre><code>import { BrowserModule } from '@angular/platform-browser';
import { NgModule } from '@angular/core';
import { HttpClientModule } from '@angular/common/http';
//import { RouterModule } from '@angular/router';
import { FormsModule }   from '@angular/forms';
import { ReactiveFormsModule } from '@angular/forms';


import { AppComponent } from './app.component';
import { WelcomeComponent } from './home/welcome.component';
import { ActivityComponent } from './shared_component/activitiy-progress.component';
import { SmartWatchComponent } from './smart-watch/smart-watch.component';
import { SmartPhoneComponent } from './smart-phone/smart-phone.component';
import { SmartPhoneMenuComponent } from './smart-phone-menu/smart-phone-menu.component';
import { GameStartComponent } from './game-start/game-start.component';
//import { UserLoginComponent } from './user-login/user-login.component';
import { PageNotfoundComponent } from './page-notfound/page-notfound.component';
import { ResetPasswordComponent } from './reset-password/reset-password.component';
import { UserSignupComponent } from './user-signup/user-signup.component';
import { UserCalendarComponent } from './user-calendar/user-calendar.component';
import { UserNewsComponent } from './user-news/user-news.component';
import { UserStorageComponent } from './user-storage/user-storage.component';
import { TodoListComponent } from './todo-list/todo-list.component';
import { AuthenticationModule } from './authentication/authentication.module';
import { LoginService } from './login.service';
import { AppRoutingModule } from './app-routing.module';


@NgModule({
  declarations: [
    AppComponent,
    WelcomeComponent,
    ActivityComponent,
    SmartWatchComponent,
    SmartPhoneComponent,
    SmartPhoneMenuComponent,
    GameStartComponent,
    PageNotfoundComponent,
    //ResetPasswordComponent,
    //UserLoginComponent,
    //UserSignupComponent,
    UserCalendarComponent,
    UserNewsComponent,
    UserStorageComponent,
    TodoListComponent
  ],
  imports: [
    BrowserModule,
    HttpClientModule,
    FormsModule,
    ReactiveFormsModule,
    AuthenticationModule,
    AppRoutingModule

  ],
 // providers: [LoginService],
 providers : [],
  bootstrap: [AppComponent]
})
export class AppModule { }
</code></pre>

<p>Here is my feature module,</p>

<pre><code>import { NgModule } from '@angular/core';
import { CommonModule } from '@angular/common';
import {RouterModule} from '@angular/router';
import { FormsModule,ReactiveFormsModule }   from '@angular/forms';
import { UserLoginComponent } from '../user-login/user-login.component';
import { UserSignupComponent } from '../user-signup/user-signup.component';
import { ResetPasswordComponent } from '../reset-password/reset-password.component';


@NgModule({
  imports: [
    CommonModule,
    RouterModule.forChild([
      {path:'login',component: UserLoginComponent},
      {path:'signup',component: UserSignupComponent},
      {path:'reset-password',component: ResetPasswordComponent},
     // {path:'',redirectTo:'login',pathMatch:'full'}
    ]),
    FormsModule,
    ReactiveFormsModule
  ],
  declarations: [
    UserLoginComponent,
    UserSignupComponent,
    ResetPasswordComponent
  ],

})
export class AuthenticationModule { }
</code></pre>

<p>Here is the service,</p>

<pre><code>import { Injectable } from '@angular/core';
import {HttpClient,HttpErrorResponse} from '@Angular/common/http';
import { Observable, throwError } from 'rxjs';
import{map,catchError} from 'rxjs/operators';

@Injectable({
  providedIn: 'root',
})

export class LoginService {

  private loginUrl : string;
  constructor(private http:HttpClient){}



  getCurrentUserInfo(loginInfo) : Observable&lt;any&gt;{

    this.loginUrl = &lt;my-url&gt;; //for privacy I had to omit the URL
    console.log(""this.loginUrl ="", this.loginUrl);
    return this.http.get&lt;any&gt;(this.loginUrl)
    .pipe(map(response =&gt; response as any),
    catchError(this.handleError));
  }

  private handleError(err:HttpErrorResponse){
    let errorMessage = '';
    if(err.error instanceof ErrorEvent){
        errorMessage = `An error has occurred ${err.error.message}`;
    }else{
        errorMessage = `server returned code: ${err.status}, error message is: ${err.message} `;
    }

    console.error(errorMessage);
    return throwError(errorMessage);

   }
}
</code></pre>

<p>here is my login component,</p>

<pre><code>import { Component, OnInit } from '@angular/core';
import { Router } from '@angular/router';
import { FormGroup, FormControl } from '@angular/forms';
import { LoginService } from '../login.service';


@Component({
  selector: 'app-user-login',
  templateUrl: './user-login.component.html',
  styleUrls: ['./user-login.component.css']
})
export class UserLoginComponent{
  testId = ""testuser"";
  testPwd = ""pwd"";
  userLoginForm = new FormGroup({
    userId : new FormControl(''),
    password : new FormControl('')

  });

constructor(private loginService : LoginService, private router : Router){}

  onLoginSubmit(){

    let loginInfo = {
      id : this.userLoginForm.value.userId,
      password : this.userLoginForm.value.password

    }

    if(loginInfo.id === """" || loginInfo.password === """"){
      alert(""Please enter Id &amp; passowrd"");
    }else if(loginInfo.id === this.testId){
      if(loginInfo.password === this.testPwd){
        this.router.navigate(['/game-start']);
      }else{
        alert(""password doesn't exist"");
        this.router.navigate(['/reset-password']);
      }
    }else{
      alert(""userId doesn't exist"");
    }





    this.loginService.getCurrentUserInfo(loginInfo).subscribe({
      next : data =&gt; console.log(""returned data : "" , data)
    });

  }


}
</code></pre>

<p>Here is my welcome component. Whenever it is navigating to the login page, the error is occurring.</p>

<pre><code>import { Component } from '@angular/core';
import { Router } from '@angular/router';
@Component({
  selector : 'welcome',
  templateUrl: './welcome.component.html',
  styleUrls : ['./welcome.component.css']
})
export class WelcomeComponent {
  public pageTitle = 'SurvCovid App';
  submitted = false;
  constructor(private router: Router){}

  onSubmit(){
    this.submitted = true;
    this.processInitialServerCommunitaion();
  }

  processInitialServerCommunitaion(){
    //this.ngZone.run(() =&gt; this.router.navigate(['/app-start']))
    //this.router.navigate(['/game-start'], {state: {""Test"":""test""}});
    this.router.navigate(['/login']);
   //alert('from game start');
  }
}
</code></pre>

<p>Here is my app routing module,</p>

<pre><code>import {NgModule} from '@angular/core';
import {RouterModule} from '@angular/router';
import { UserCalendarComponent } from './user-calendar/user-calendar.component';
import { UserNewsComponent } from './user-news/user-news.component';
import { UserStorageComponent } from './user-storage/user-storage.component';
import { TodoListComponent } from './todo-list/todo-list.component';
import { SmartPhoneMenuComponent } from './smart-phone-menu/smart-phone-menu.component';
import { GameStartComponent } from './game-start/game-start.component';
//import { ResetPasswordComponent } from './reset-password/reset-password.component';
import { PageNotfoundComponent } from './page-notfound/page-notfound.component';
import { WelcomeComponent } from './home/welcome.component';

const ROUTES = [
    //{path:'login',component: UserLoginComponent},
   // {path:'signup',component: UserSignupComponent},
    {path:'welcome',component: WelcomeComponent},
    {path:'calendar',component: UserCalendarComponent},
    {path: 'news',component:UserNewsComponent},
    {path: 'storage',component:UserStorageComponent},
    {path: 'todo-list',component:TodoListComponent},
    {path : 'smartPhone-menu',component:SmartPhoneMenuComponent},
    {path : 'game-start',component :GameStartComponent},
    {path:'',redirectTo:'welcome',pathMatch:'full'},
   // {path:'reset-password',component: ResetPasswordComponent},
    {path : '**',component : PageNotfoundComponent}
    /*{path:'**',redirectTo:'welcome', pathMatch: 'full'}*/
  ];

@NgModule({
    imports: [
        RouterModule.forRoot(ROUTES)
    ],
    exports : [RouterModule]
})

export class AppRoutingModule{}
</code></pre>

<p>Here is the versions I'm using,</p>

<pre><code>Package                           Version
-----------------------------------------------------------
@angular-devkit/architect         0.900.7
@angular-devkit/build-angular     0.900.7
@angular-devkit/build-optimizer   0.900.7
@angular-devkit/build-webpack     0.900.7
@angular-devkit/core              9.0.7
@angular-devkit/schematics        9.0.7
@ngtools/webpack                  9.0.7
@schematics/angular               9.0.7
@schematics/update                0.900.7
rxjs                              6.5.4
typescript                        3.7.5
webpack                           4.41.2
</code></pre>

<p>I'm learning Angular and quite lost with this problem. I searched the solution in similar stakoverflow posts but mostly everyone suggested to import HttpClientModule which I already did. And also, it seems nobody faced this while routing/loading a component while loading the service. That's why I feel this is a new problem. Any help therefore would be very much appreciated.</p>
"
61208153,"<p>I am using a PHP array and foreach loop to create a drop down list of the 50 US states with links to each of their COVID-19 response pages.</p>

<p>When the ""Go"" button is clicked, it should take you to the selected state's link.</p>

<p>I run tests, but the ""Go"" button does not work for any of the selections.</p>

<p>Here is the PHP code:</p>

<pre><code>&lt;html&gt;
    &lt;body&gt;
        &lt;?php
        $states = array(
            ""Alabama"" =&gt; ""governor.alabama.gov/newsroom/covid-19"",
            ""Alaska"" =&gt; ""dhss.alaska.gov/dph/Epi/id/Pages/COVID-19/default.aspx"",
            ""Arizona"" =&gt; ""www.azdhs.gov/index.php"",
            ""Arkansas"" =&gt; ""www.healthy.arkansas.gov/programs-services/topics/novel-coronavirus"",
            ""California"" =&gt; ""www.cdcr.ca.gov/covid19/"",
            ""Colorado"" =&gt; ""covid19.colorado.gov/"",
            ""Connecticut"" =&gt; ""portal.ct.gov/Coronavirus"",
            ""Delaware"" =&gt; ""coronavirus.delaware.gov/"",
            ""District of Columbia"" =&gt; ""https://coronavirus.dc.gov/"",
            ""Florida"" =&gt; ""www.floridadisaster.org/covid19/"",
            ""Georgia"" =&gt; ""georgia.gov/covid-19-state-services-georgia"",
            ""Hawaii"" =&gt; ""health.hawaii.gov/coronavirusdisease2019/"",
            ""Idaho"" =&gt; ""coronavirus.idaho.gov/"",
            ""Illinois"" =&gt; ""coronavirus.illinois.gov/s/"",
            ""Indiana"" =&gt; ""coronavirus.in.gov/"",
            ""Iowa"" =&gt; ""coronavirus.iowa.gov/"",
            ""Kansas"" =&gt; ""govstatus.egov.com/coronavirus"",
            ""Kentucky"" =&gt; ""governor.ky.gov/covid19"",
            ""Louisiana"" =&gt; ""ldh.la.gov/coronavirus/"",
            ""Maine"" =&gt; ""www.maine.gov/covid19/"",
            ""Maryland"" =&gt; ""coronavirus.maryland.gov/"",
            ""Massachusetts"" =&gt; ""www.mass.gov/resource/information-on-the-outbreak-of-coronavirus-disease-2019-covid-19"",
            ""Michigan"" =&gt; ""www.michigan.gov/coronavirus"",
            ""Minnesota"" =&gt; ""mn.gov/covid19/"",
            ""Mississippi"" =&gt; ""msdh.ms.gov/msdhsite/_static/14,0,420.html#Mississippi"",
            ""Missouri"" =&gt; ""dss.mo.gov/covid-19/"",
            ""Montana"" =&gt; ""covid19.mt.gov/"",
            ""Nebraska"" =&gt; ""dhhs.ne.gov/pages/Coronavirus.aspx"",
            ""Nevada"" =&gt; ""nvhealthresponse.nv.gov/"",
            ""New Hampshire"" =&gt; ""www.nh.gov/covid19/"",
            ""New Jersey"" =&gt; ""www.nj.gov/health/cd/topics/covid2019_community.shtml"",
            ""New Mexico"" =&gt; ""www.dws.state.nm.us/COVID-19-Info"",
            ""New York"" =&gt; ""coronavirus.health.ny.gov/home"",
            ""New York City"" =&gt; ""www1.nyc.gov/site/coronavirus/index.page"",
            ""North Carolina"" =&gt; ""www.ncdhhs.gov/divisions/public-health/covid19"",
            ""North Dakota"" =&gt; ""www.ndresponse.gov/covid-19-resources"",
            ""Ohio"" =&gt; ""coronavirus.ohio.gov/wps/portal/gov/covid-19/home"",
            ""Oaklahoma"" =&gt; ""coronavirus.health.ok.gov/"",
            ""Oregon"" =&gt; ""coronavirus.oregon.gov/"",
            ""Pennsylvania"" =&gt; ""www.health.pa.gov/topics/disease/coronavirus/Pages/Coronavirus.aspx"",
            ""Rhode Island"" =&gt; ""www.ride.ri.gov/InsideRIDE/AdditionalInformation/Covid19.aspx"",
            ""South Carolina"" =&gt; ""www.scdhec.gov/infectious-diseases/viruses/coronavirus-disease-2019-covid-19"",
            ""South Dakota"" =&gt; ""covid.sd.gov/"",
            ""Tennessee"" =&gt; ""www.tn.gov/governor/covid-19.html"",
            ""Texas"" =&gt; ""dshs.texas.gov/coronavirus/"",
            ""Utah"" =&gt; ""coronavirus.utah.gov/"",
            ""Vermont"" =&gt; ""www.healthvermont.gov/response/coronavirus-covid-19"",
            ""Virgina"" =&gt; ""www.vdh.virginia.gov/coronavirus/"",
            ""Washington"" =&gt; ""coronavirus.wa.gov/"",
            ""West Virginia"" =&gt; ""dhhr.wv.gov/COVID-19/Pages/default.aspx"",
            ""Wisconsin"" =&gt; ""www.dhs.wisconsin.gov/covid-19/index.html"",
            ""Wyoming"" =&gt; ""health.wyo.gov/publichealth/infectious-disease-epidemiology-unit/disease/novel-coronavirus/""
            );
            ?&gt;

            &lt;form action="""" method=""POST""&gt;
                &lt;select name=""states"" id=""states""&gt;

                    &lt;?php

                    foreach ($states as $array_key =&gt; $array_value) {
                    ?&gt;
                    &lt;option value=""https://&lt;?php echo $array_value; ?&gt;""&gt;&lt;?php echo $array_key; ?&gt;&lt;/option&gt;
                    &lt;?php
                    } //end loop

                    ?&gt;

                &lt;/select&gt;
                &lt;input id=""submit"" type=""submit"" name=""submit"" value=""Go""&gt;
            &lt;/form&gt;

            &lt;?php
            if(isset($_POST['submit'])) {
                $option = $_POST['states'];

                header(""Location: "" . $option);
            }
            ?&gt;
    &lt;/body&gt;
&lt;/html&gt;

</code></pre>

<p>Thank you in advance.</p>
"
61323968,"<p>I am working on kepler.gl . i am trying to add another point on map and change the state of kepler.gl on a button click . I mean when i click the button another point is mapped on keppler.gl map . wright now i am having 4 point on the kepler.gl map and that's working fine ... here is the code of 4 point on the map</p>

<pre><code>import React, { useState } from ""react"";
import keplerGlReducer, {mapStateUpdaters}  from ""kepler.gl/reducers"";
import { createStore, combineReducers, applyMiddleware } from ""redux"";
import { taskMiddleware } from ""react-palm/tasks"";
import { Provider, useDispatch } from ""react-redux"";
import KeplerGl from ""kepler.gl"";
import { addDataToMap } from ""kepler.gl/actions"";
import useSwr from ""swr"";
import {csv} from 'd3';
import datajson from './Data/data.json'
const reducers = combineReducers({
  keplerGl: keplerGlReducer,

});

const store = createStore(reducers, {}, applyMiddleware(taskMiddleware));

export default function App() {
  return (
    &lt;Provider store={store}&gt;
      &lt;Map /&gt;
    &lt;/Provider&gt;
  );
}

function Map() {
  const dispatch = useDispatch();

  const data=datajson;

  React.useEffect(() =&gt; {
    if (data) {
      dispatch(
        addDataToMap({
          datasets: {
            info: {
              label: ""COVID-19"",
              id: ""covid19""
            },
            data
          },
          option: {
            centerMap: true,
            readOnly: false
          },
          config: {}
        })
      );
    }
  }, [dispatch, data]);

  return (


    // &lt;button onClick ={this.handledata} &gt;changedata&lt;/button&gt;
    &lt;KeplerGl
      id=""covid""
      mapboxApiAccessToken=""pk.eyJ1IjoiYWxpcmF6YTcwNSIsImEiOiJjazh5d2hjb3AwOHBqM2VsY21wOHo5eXprIn0.9G5CE4KqfbvU9HQ6WBuo3w""
      width={window.innerWidth}
      height={window.innerHeight}

    /&gt;

  );
  }}
</code></pre>

<p>my data.jason file look like this ....</p>

<pre><code>[
     {
        ""id"": 139010,
        ""state"": 4,
        ""subState"": 0,
        ""paid"": 1,
        ""stateReason"": ""Trip finished by user"",
        ""id_turistic"": 5,
        ""priceFinal"": 60,
        ""consumedFreeMinutes"": 0,
        ""id_user"": 4627,
        ""id_vehicle"": 245,
        ""from"": ""nan"",
        ""to"": ""Sol"",
        ""batt_diff"": -8,
        ""duracion"": 412,
        ""fecha"": ""2018-09-01"",
        ""start30"": ""2018-09-01 08:00:00"",
        ""end30"": ""2018-09-01 08:00:00"",
        ""distancia"": 2,
        ""latitude"": 40.0,
        ""longitude"": -4.0
    },
     {
        ""id"": 138888,
        ""state"": 4,
        ""subState"": 0,
        ""paid"": 1,
        ""stateReason"": ""Trip finished by user"",
        ""id_turistic"": 5,
        ""priceFinal"": 100,
        ""consumedFreeMinutes"": 0,
        ""id_user"": 4627,
        ""id_vehicle"": 245,
        ""from"": ""Universidad"",
        ""to"": ""Embajadores"",
        ""batt_diff"": -4,
        ""duracion"": 646,
        ""fecha"": ""2018-09-01"",
        ""start30"": ""2018-09-01 00:00:00"",
        ""end30"": ""2018-09-01 00:00:00"",
        ""distancia"": 4,
        ""latitude"": ""40.0"",
        ""longitude"": ""-4.0""
    },
     {
        ""id"": 138878,
        ""state"": 4,
        ""subState"": 0,
        ""paid"": 1,
        ""stateReason"": ""Trip finished by user"",
        ""id_turistic"": 5,
        ""priceFinal"": 110,
        ""consumedFreeMinutes"": 0,
        ""id_user"": 10244,
        ""id_vehicle"": 173,
        ""from"": ""Vallehermoso"",
        ""to"": ""Cuatro Caminos"",
        ""batt_diff"": -7,
        ""duracion"": 682,
        ""fecha"": ""2018-09-01"",
        ""start30"": ""2018-09-01 00:00:00"",
        ""end30"": ""2018-09-01 00:00:00"",
        ""distancia"": 3,
        ""latitude"": ""40.0"",
        ""longitude"": ""-4.0""
    },
     {
        ""id"": 138941,
        ""state"": 4,
        ""subState"": 0,
        ""paid"": 0,
        ""stateReason"": ""Trip finished by user"",
        ""id_turistic"": 5,
        ""priceFinal"": 170,
        ""consumedFreeMinutes"": 0,
        ""id_user"": 12133,
        ""id_vehicle"": 207,
        ""from"": ""Justicia"",
        ""to"": ""Prosperidad"",
        ""batt_diff"": -7,
        ""duracion"": 1031,
        ""fecha"": ""2018-09-01"",
        ""start30"": ""2018-09-01 02:00:00"",
        ""end30"": ""2018-09-01 02:00:00"",
        ""distancia"": 5,
        ""latitude"": ""40.0"",
        ""longitude"": ""-4.0""
    }
]
</code></pre>

<p>now i want to add another point on a click of button ? like for example i want to add that point on a button click </p>

<pre><code>{
    ""fields"": [
        {
            ""name"": ""id"",
            ""format"": """",
            ""type"": ""integer""
        },
        {
            ""name"": ""state"",
            ""format"": """",
            ""type"": ""integer""
        },
        {
            ""name"": ""substate"",
            ""format"": """",
            ""type"": ""integer""
        },
        {
            ""name"": ""paid"",
            ""format"": """",
            ""type"": ""integer""
        },
        {
            ""name"": ""stateReason"",
            ""format"": """",
            ""type"": ""string""
        },
        {
            ""name"": ""id_turistic"",
            ""format"": """",
            ""type"": ""integer""
        },
        {
            ""name"": ""priceFinal"",
            ""format"": """",
            ""type"": ""integer""
        },
        {
            ""name"": ""consumedFreeMinutes"",
            ""format"": """",
            ""type"": ""integer""
        },
        {
            ""name"": ""consumed"",
            ""format"": """",
            ""type"": ""integer""
        },

        {
            ""name"": ""id_user"",
            ""format"": """",
            ""type"": ""integer""
        },
        {
            ""name"": ""id_vehicle"",
            ""format"": """",
            ""type"": ""integer""
        },
        {
            ""name"": ""from"",
            ""format"": """",
            ""type"": ""string""
        },
        {
            ""name"": ""to"",
            ""format"": """",
            ""type"": ""string""
        },
        {
            ""name"": ""batt_diff"",
            ""format"": """",
            ""type"": ""string""
        },
        {
            ""name"": ""duracion"",
            ""format"": """",
            ""type"": ""string""
        },
        {
            ""name"": ""fecha"",
            ""format"": ""YYYY-M-D H:m:s"",
            ""type"": ""timestamp""
        },
        {
            ""name"": ""start30"",
            ""format"": ""YYYY-M-D H:m:s"",
            ""type"": ""timestamp""
        },
        {
            ""name"": ""end30"",
            ""format"": ""YYYY-M-D H:m:s"",
            ""type"": ""timestamp""
        },
        {
            ""name"": ""distancia"",
            ""format"": """",
            ""type"": ""integer""
        },
        {
            ""name"": ""latitude"",
            ""format"": """",
            ""type"": ""real""
        },
        {
            ""name"": ""longitude"",
            ""format"": """",
            ""type"": ""real""
        },
        {
            ""name"": ""lo"",
            ""format"": """",
            ""type"": ""real""
        }

    ],
    ""rows"": [
        [
            139010,
            4,
            0,
            1,
            ""Trip finished by user"",
            5,
            60,
            0,
            4627,
            245,
            ""nan"",
            ""Sol"",
            -8,
            412,
            ""2018-09-01"",
            ""2018-09-01 08:00:00"",
            ""2018-09-01 08:00:00"",
            2,
            40.0,
    -12,
    40.0
        ],
        [
            138888,
            4,
            0,
            1,
            ""Trip finished by user"",
            5,
            100,
            0,
            4627,
            245,
            ""Universidad"",
            ""Embajadores"",
            -4,
            646,
            ""2018-09-01"",
            ""2018-09-01 08:00:00"",
            ""2018-09-01 08:00:00"",
            4,
            40.0,
            0,
            40.0
        ],
        [
            138878,
            4,
            0,
            1,
            ""Trip finished by user"",
            5,
            110,
            0,
            10244,
            173,
            ""Vallehermoso"",
            ""Cuatro Caminos"",
            -7,
            682,
            ""2018-09-01"",
            ""2018-09-01 08:00:00"",
            ""2018-09-01 08:00:00"",
            3,
            40.0,
            -8.0,
            40.0
        ],
        [
            138941,
            4,
            0,
            0,
            ""Trip finished by user"",
            5,
            170,
            0,
            12133,
            207,
            ""Justicia"",
            ""Prosperidad"",
            -7,
            1031,
            ""2018-09-01"",
            ""2018-09-01 08:00:00"",
            ""2018-09-01 08:00:00"",
            5,
            40.0,
            -4.0,
            40.0
        ]
    ]
    }
</code></pre>

<p>how can i do this can anyone help me for this? i already tried mapstateupdataer function but not been able to get desired results ? </p>
"
61696720,"<p>I am working on kepler.gl . I want to disable side panel of kepler.gl map . i  don't want to show side panel of kepler.gl to my customer . This is my code to display my data on kepler.gl map .in this code i am reading data from api and display that data to kepler.gl map ?</p>

<pre><code>import React from ""react"";
import keplerGlReducer from ""kepler.gl/reducers"";
import { createStore, combineReducers, applyMiddleware } from ""redux"";
import { taskMiddleware } from ""react-palm/tasks"";
import { Provider, useDispatch } from ""react-redux"";
import KeplerGl from ""kepler.gl"";
import { addDataToMap } from ""kepler.gl/actions"";
import useSwr from ""swr"";

const reducers = combineReducers({
  keplerGl: keplerGlReducer
});

const store = createStore(reducers, {}, applyMiddleware(taskMiddleware));

export default function App() {
  return (
    &lt;Provider store={store}&gt;
      &lt;Map /&gt;
    &lt;/Provider&gt;
  );
}

function Map() {
  const dispatch = useDispatch();
  const { data } = useSwr(""covid"", async () =&gt; {
    const response = await fetch(

      ""https://gist.githubusercontent.com/leighhalliday/a994915d8050e90d413515e97babd3b3/raw/a3eaaadcc784168e3845a98931780bd60afb362f/covid19.json""

    );
    const data = await response.json();

    return data;
  });
  console.log(data);
  React.useEffect(() =&gt; {
    if (data) {
      dispatch(
        addDataToMap({
          datasets: {
            info: {
              label: ""COVID-19"",
              id: ""covid19""
            },
            data
          },
          option: {
            centerMap: true,
            readOnly: false
          },
          config: {}
        })
      );
    }
  }, [dispatch, data]);

  return (
    &lt;KeplerGl
      id=""covid""
      mapboxApiAccessToken=""pk.eyJ1IjoiYWxpcmF6YTcwNSIsImEiOiJjazh5d2hjb3AwOHBqM2VsY21wOHo5eXprIn0.9G5CE4KqfbvU9HQ6WBuo3w""
      width={window.innerWidth}
      height={window.innerHeight}
    /&gt;
  );
}
</code></pre>

<p>can any one help me how can i disable side panel of kepler.gl map ?</p>
"
61282019,"<p>Hi can someone please tell me what I am doing wrong? I am trying to add the google analytics as per instructions on multiple sources but it keeps crashing my site no matter where I put the information Here is the code as I tried this last time for the 7th time., Below is the contents of the function.php code:</p>

<pre><code>    &lt;?php

add_action('wp_head', 'wpb_add_googleanalytics');
function wpb_add_googleanalytics() { ?&gt;

// Paste your Google Analytics code from Step 4 here
&lt;!-- Global site tag (gtag.js) - Google Analytics --&gt;
&lt;script async src=""https://www.googletagmanager.com/gtag/js?id=G-xxx""&gt;&lt;/script&gt;
&lt;script&gt;
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-xxx');
&lt;/script&gt;

function denRegScript(){
    wp_enqueue_style( 'datatable-css', get_theme_file_uri('/assets/css/datatables.css'), false );
    wp_enqueue_script( 'datatables-js', get_theme_file_uri('/assets/js/datatables.min.js'), array('jquery'), '0.1', true ); 
}
add_action('wp_enqueue_scripts','denRegScript');


add_action('wp_ajax_movie_datatables', 'datatables_server_side_callback');
add_action('wp_ajax_nopriv_movie_datatables', 'datatables_server_side_callback');
//add_action('wp_ajax_nopriv_movie_datatables', 'datatables_server_side_callback');
function datatables_server_side_callback()
{

    header(""Content-Type: application/json"");

    $request = $_GET;

    $json_pre_result = newfunc($request);

    if(isset($json_pre_result)) {
        echo json_encode($json_pre_result);
    }

    wp_die();

}

function newfunc($request){

        global $wpdb;

        // $catnamewithid = $wpdb-&gt;get_results( 
        //     ""SELECT id_category,category_title FROM {$wpdb-&gt;prefix}expert_jobs_categories"", OBJECT_K
        // );
        $data = array();
        $maincatParam = $request['maincat'];
        $subcatParam = $request['subcat'];
        error_log($maincatParam);
        error_log($subcatParam);
        $regionParam = $regionParamOrig = $request['region'];
        $regionParam = explode("", "",$regionParam);
        if(isset($regionParam[0]) &amp;&amp; isset($regionParam[1])){
            $regionParamCity = $regionParam[0];
            $regionParamstate = $regionParam[1];
        }else{
            $regionParamCity = $regionParamstate = $regionParamOrig;
        }

        $empsql = """";
        if($regionParamCity!=""all""){
            // find the employer ids
            $employeeresults = $wpdb-&gt;get_results(
                ""SELECT id_professional FROM {$wpdb-&gt;prefix}expert_jobs_professionals WHERE `pro_address` LIKE '%, $regionParamstate%' OR `pro_address` LIKE '%$regionParamCity%' "", ARRAY_A
            );

            if(!empty($employeeresults)){
                $te3 = array();
                foreach ($employeeresults as $value) {
                    array_push($te3,$value['id_professional']);
                }
                $subEmpString = join("","",$te3);
                $empsql = ""AND id_employer IN ($subEmpString)"";
            }

        }


        if($maincatParam==-1){
            $allMainCats = $wpdb-&gt;get_results( 
                ""SELECT id_category,category_title FROM {$wpdb-&gt;prefix}expert_jobs_categories WHERE id_parent IN (0) "", OBJECT_K
            );
            // need to return all data
        }else{
            $allMainCats = $wpdb-&gt;get_results( 
                ""SELECT id_category,category_title FROM {$wpdb-&gt;prefix}expert_jobs_categories WHERE id_category IN ($maincatParam) "", OBJECT_K
            );
        }



        $superFArray = array();

        foreach ($allMainCats as $maincategoryid =&gt; $maincategorynameArray) {

            $subcatids = array();
            if($subcatParam==-1){
                $subcategries = $wpdb-&gt;get_results( 
                    ""SELECT id_category,category_title FROM {$wpdb-&gt;prefix}expert_jobs_categories WHERE id_parent IN ($maincategoryid) AND id_category NOT BETWEEN 123 AND 198 "", OBJECT_K
                );
            }else{
                $subcategries = $wpdb-&gt;get_results( 
                    ""SELECT id_category,category_title FROM {$wpdb-&gt;prefix}expert_jobs_categories WHERE id_category IN ($subcatParam) AND id_category NOT BETWEEN 123 AND 198 "", OBJECT_K
                );
                //$subcategries = getSingleSubCat($subcatParam);
            }


            $tempar1 = array();
            // find wage for all sub category id of this main category and assign sub cat id as key, assign wages as values
            $implodedsubcatid = """";


            if(!empty($subcategries)){
                $fored = array();
                $te3 = array();
                $budgetarrayforcat = array();
                foreach ($subcategries as $subcategoryid =&gt; $subcategoryname) {
                    array_push($te3,$subcategoryid);
                }
                $implodedsubcatid = join("","",$te3);

                // Hourly
                $jobsresults2 = $wpdb-&gt;get_results(
                    ""SELECT id_category,job_budget FROM {$wpdb-&gt;prefix}expert_jobs_job WHERE id_category IN ($implodedsubcatid) AND job_payment_type='Per hour' $empsql ORDER BY job_budget LIMIT 100 "", ARRAY_A
                );
                if(!empty($jobsresults2)){


                    // make new array of obj_k

                    foreach ($jobsresults2 as $key =&gt; $jobline) {
                        $catid = $jobline['id_category'];
                        $rawbudget = $jobline['job_budget'];

                        $averageofone = 0;
                        $explodeall = explode("" "",$rawbudget);

                        if (($key = array_search(""00"", $explodeall)) !== false) {
                            unset($explodeall[$key]);
                        }
                        if(count($explodeall)) {
                            $a = array_filter($explodeall, function($explodeall) { return is_numeric($explodeall) == true; });
                            //$a = array_filter($explodeall);
                            $averageofone = array_sum($a)/count($a);
                        }
                        $budget = $averageofone;

                        $fored[$catid]['hour'][] = $budget;
                    }

                    // foreach ($fored as $subcatid =&gt; $job_budget) {
                    //  $budg = $job_budget['job_budget'];
                    //  $budgetarrayforcat[$subcatid]['hour'][] = $budg;
                    // }
                }

                  // Week
                $jobsresults = $wpdb-&gt;get_results(
                    ""SELECT id_category,job_budget FROM {$wpdb-&gt;prefix}expert_jobs_job WHERE id_category IN ($implodedsubcatid) AND job_payment_type='Weekly' $empsql ORDER BY job_budget LIMIT 100 "", ARRAY_A
                );
                if(!empty($jobsresults)){


                    // make new array of obj_k

                    foreach ($jobsresults as $key =&gt; $jobline) {
                        $catid = $jobline['id_category'];
                        $rawbudget = $jobline['job_budget'];

                        $averageofone = 0;
                        $explodeall = explode("" "",$rawbudget);

                        if (($key = array_search(""00"", $explodeall)) !== false) {
                            unset($explodeall[$key]);
                        }
                        if(count($explodeall)) {
                            $a = array_filter($explodeall, function($explodeall) { return is_numeric($explodeall) == true; });
                            //$a = array_filter($explodeall);
                            if(count($a)!=0){
                            $averageofone = array_sum($a)/count($a);
                            }
                        }
                        $budget = $averageofone;

                        $fored[$catid]['week'][] = $budget;
                    }

                    // foreach ($fored as $subcatid =&gt; $job_budget) {
                    //  $budg = $job_budget['job_budget'];
                    //  $budgetarrayforcat[$subcatid]['hour'][] = $budg;
                    // }
                }


                $newfored = array();
                foreach ($fored as $catid =&gt; $value) {
                    foreach ($value as $daytype =&gt; $average) {

                        if(count($average)!=0){
                            $sav = array_sum($average)/count($average);
                        }else{
                            $sav = 0;
                        }

                        switch ($daytype) {
                            case ""month"":
                                $newfored[$catid]['month'] = $sav;
                                //$averageString .=  ""&lt;span class='fixwl'&gt;Monthly: &lt;/span&gt;"".$average.""&lt;br/&gt;"";
                                break;
                            case ""week"":
                                $newfored[$catid]['week'] = $sav;
                                //$averageString .=  ""&lt;span class='fixwl'&gt;Weekly: &lt;/span&gt;"".$average.""&lt;br/&gt;"";
                                break;
                            case ""hour"":
                                $newfored[$catid]['hour'] = $sav;
                                //$averageString .=  ""&lt;span class='fixwl'&gt;Hourly:&amp;nbsp;&amp;nbsp;&lt;/span&gt;"".$average.""&lt;br/&gt;"";
                                break;
                            default:

                        }
                    }
                }

            }


            foreach ($subcategries as $subcategoryid =&gt; $subcategoryname) {
                $wages = array();
                if(isset($newfored[$subcategoryid])){
                    $wages = $newfored[$subcategoryid];
                }
                $subcategoryname-&gt;wages = $wages;
                $tempar1[$subcategoryid] = $subcategoryname;
            }
            $maincategoryname = $maincategorynameArray-&gt;category_title;
            $superFArray[$maincategoryname] = $tempar1;


        }


        foreach ($superFArray as $maincatname =&gt; $subarray) {

            foreach ($subarray as $subvalue) {
                if(!empty($subvalue-&gt;wages)){
                $nestedData = array();
                $subcatname = $subvalue-&gt;category_title;
                $averageString = '';



                foreach ($subvalue-&gt;wages as $daytype =&gt; $average) {
                    $average = money_format('$%i', $average);

                    $breakweek = false;
                    if(isset($subvalue-&gt;wages['hour']) &amp;&amp; isset($subvalue-&gt;wages['week']) ){
                        if($subvalue-&gt;wages['hour']&gt;$subvalue-&gt;wages['week']){
                            $breakweek = true;
                        }
                    }

                            switch ($daytype) {
                                case ""month"":
                                    $averageString .=  ""&lt;span class='fixwl'&gt;Monthly: &lt;/span&gt;"".$average.""&lt;br/&gt;"";
                                    break;
                                case ""week"":
                                    if(!$breakweek){
                                        $averageString .=  ""&lt;span class='fixwl'&gt;Weekly: &lt;/span&gt;"".$average.""&lt;br/&gt;"";
                                    }
                                    break;
                                case ""hour"":
                                    $averageString .=  ""&lt;span class='fixwl'&gt;Hourly:&amp;nbsp;&amp;nbsp;&lt;/span&gt;"".$average.""&lt;br/&gt;"";
                                    break;
                                default:

                            }

                }


                $nestedData[] = $maincatname;
                $nestedData[] = $subcatname;
                $nestedData[] = $averageString;

                $data[] = $nestedData;
                }
            }
        }

        $final_data = array(
            ""draw"" =&gt; intval($request['draw']),
            ""recordsTotal"" =&gt; count($data),
            //""recordsFiltered"" =&gt; 12,
            ""data"" =&gt; $data
        );
        return $final_data;

}

function get_pre_json_time_sheets($request){
    $columns=array(
        0=&gt;'name',
        1=&gt;'date',
        2=&gt;'starttime',
        3=&gt;'endtime',
    );

    // $posts_per_page = $request['length'];
    // $doffset = $request['start'];
    // $order = $request['order'][0]['dir'];
    // $orderby = $columns[$request['order'][0]['column']];
    global $wpdb;
    $data = array();
    $maincatParam = $request['maincat'];
    $subcatParam = $request['subcat'];
    $regionParam = $regionParamOrig = $request['region'];
    $regionParam = explode("", "",$regionParam);
    if(isset($regionParam[0]) &amp;&amp; isset($regionParam[1])){
        $regionParamCity = $regionParam[0];
        $regionParamstate = $regionParam[1];
    }else{
        $regionParamCity = $regionParamstate = $regionParamOrig;
    }

    $subEmpString = """";
    $empsql = """";
    if($regionParamCity!=""all""){
        // find the employer ids
        $employeeresults = $wpdb-&gt;get_results( 
            ""SELECT id_professional FROM {$wpdb-&gt;prefix}expert_jobs_professionals WHERE `pro_address` LIKE '%, $regionParamstate%' OR `pro_address` LIKE '%$regionParamCity%' "", ARRAY_A
        );

        if(!empty($employeeresults)){
            $te3 = array();
            foreach ($employeeresults as $value) {
                array_push($te3,$value['id_professional']);
            }
            $subEmpString = join("","",$te3);
            $empsql = ""AND id_employer IN ($subEmpString)"";
        }

    }

    $nestedData = array();
    $budgetarrayforcat = array();
    $maincatbudgetarray = array();


    $catnamewithid = $wpdb-&gt;get_results( 
        ""SELECT id_category,category_title FROM {$wpdb-&gt;prefix}expert_jobs_categories"", OBJECT_K
    );
    //error_log(print_r($catnamewithid,true));


    if($maincatParam==-1){
        $allMainCat = getIMainCat();      
        // need to return all data
    }else{
        $allMainCat = getSingleMainCat($maincatParam);
    }



    if(!empty($allMainCat)){
        foreach ($allMainCat as $singlemain) {
           $maincatid = $singlemain-&gt;id_category;
           $maincatname = $singlemain-&gt;category_title;

           if($subcatParam==-1){
                $subcatids = getsubcatidsStringOfMainCat($maincatid);
           }else{
                $subcatids = $subcatParam;
           }

           if(!empty($subcatids)){

            // Week
           $jobsresults = $wpdb-&gt;get_results( 
                     ""SELECT job_budget,id_category FROM {$wpdb-&gt;prefix}expert_jobs_job WHERE id_category IN ($subcatids) AND job_payment_type = 'Weekly' $empsql ORDER BY job_budget LIMIT 12 "", ARRAY_A
           );
           //(job_budget like '%per week%' OR job_budget like '%week%')
           if(!empty($jobsresults)){
               foreach ($jobsresults as $key =&gt; $jobline) {
                   $budg = $jobline['job_budget'];
                   $idcat = $jobline['id_category'];
                   if(isset($catnamewithid[$idcat]-&gt;category_title)){
                   $idname = $catnamewithid[$idcat]-&gt;category_title;
                   $budgetarrayforcat[$idname]['week'][] = $budg;
                   }
               }
           }


           // Hourly
           $jobsresults2 = $wpdb-&gt;get_results( 
            ""SELECT job_budget,id_category FROM {$wpdb-&gt;prefix}expert_jobs_job WHERE id_category IN ($subcatids) AND job_payment_type='Per hour' $empsql ORDER BY job_budget LIMIT 12 "", ARRAY_A
            );
            //(job_budget like '%per hour%' OR job_budget like '%hourly%' )

            if(!empty($jobsresults2)){
                foreach ($jobsresults2 as $key =&gt; $jobline) {
                    $budg = $jobline['job_budget'];
                    $idcat = $jobline['id_category'];
                    if(isset($catnamewithid[$idcat]-&gt;category_title)){
                    $idname = $catnamewithid[$idcat]-&gt;category_title;
                    $budgetarrayforcat[$idname]['hour'][] = $budg;
                    }
                }
            }

            // Anually
        //    $jobsresults3 = $wpdb-&gt;get_results( 
        //     ""SELECT job_budget,id_category FROM {$wpdb-&gt;prefix}expert_jobs_job WHERE id_category IN ($subcatids) AND (job_budget like '%per month%' OR job_budget like '%monthly%') $empsql LIMIT 12"", ARRAY_A
        //     );

        //     if(!empty($jobsresults3)){
        //         foreach ($jobsresults3 as $key =&gt; $jobline) {
        //             $budg = $jobline['job_budget'];
        //             $idcat = $jobline['id_category'];
        //             if(isset($catnamewithid[$idcat]-&gt;category_title)){
        //             $idname = $catnamewithid[$idcat]-&gt;category_title;
        //             $budgetarrayforcat[$idname]['month'][] = $budg;
        //             }
        //         }
        //     }



           $maincatbudgetarray[$maincatname] = $budgetarrayforcat;
        }
        }
    }
        //error_log(print_r($maincatbudgetarray,true));
        echo '&lt;pre&gt;';
        print_r($maincatbudgetarray);
        echo '&lt;/pre&gt;';


        foreach ($maincatbudgetarray as $maincatname =&gt; $subcatarray) {



            foreach ($subcatarray as $subcatname =&gt; $wagearray) {
                    $nestedData = array();

                    // we have week and hour array here in $wagearray
                    $averageString = """";

                    foreach ($wagearray as $daytype =&gt; $singlewage) {

                                    $countjobs = count($singlewage);
                                    $allave = array();
                                    foreach ($singlewage as $rawtext) {
                                            $averageofone = 0;
                                            $explodeall = explode("" "",$rawtext);

                                            if (($key = array_search(""00"", $explodeall)) !== false) {
                                                unset($explodeall[$key]);
                                            }
                                            if(count($explodeall)) {
                                                $a = array_filter($explodeall, function($explodeall) { return is_numeric($explodeall) == true; });
                                                $a = array_filter($explodeall);
                                                $averageofone = array_sum($a)/count($a);
                                            }
                                            array_push($allave,$averageofone);
                                    }
                                    $average = money_format('$%i', array_sum($allave)/$countjobs);

                        switch ($daytype) {
                            case ""month"":
                                $averageString .=  ""&lt;span class='fixwl'&gt;Monthly: &lt;/span&gt;"".$average.""&lt;br/&gt;"";
                            break;
                            case ""week"":
                                $averageString .=  ""&lt;span class='fixwl'&gt;Weekly: &lt;/span&gt;"".$average.""&lt;br/&gt;"";
                                break;
                            case ""hour"":
                                $averageString .=  ""&lt;span class='fixwl'&gt;Hourly:&amp;nbsp;&amp;nbsp;&lt;/span&gt;"".$average.""&lt;br/&gt;"";
                                break;
                            default:

                        }


                    }

                        $nestedData[] = $maincatname;
                        $nestedData[] = $subcatname;
                        $nestedData[] = $averageString;
                        $data[] = $nestedData;
            }

        }




    $final_data = array(
        ""draw"" =&gt; intval($request['draw']),
        ""recordsTotal"" =&gt; count($data),
        ""recordsFiltered"" =&gt; 12,
        ""data"" =&gt; $data
    );
    return $final_data;
}

function getsubcatidsStringOfMainCat($maincat){
    global $wpdb;

    $results = $wpdb-&gt;get_results(
        ""SELECT id_category FROM {$wpdb-&gt;prefix}expert_jobs_categories WHERE id_parent IN ($maincat) AND id_category NOT BETWEEN 123 AND 198"", ARRAY_A
    );

    if(!empty($results)){
        $te2 = array();
        foreach ($results as $value) {
            array_push($te2,$value['id_category']);
        }
        $subCatString = join("","",$te2);

    }
    //error_log(print_r($subCatString,true));
    return $subCatString;
    //wp_die();
}

function getIMainCat(){
    global $wpdb;
    $results = $wpdb-&gt;get_results( 
        ""SELECT * FROM {$wpdb-&gt;prefix}expert_jobs_categories WHERE id_parent IN (0) ""
    );

    return $results;
    //wp_die();
}

function getSingleMainCat($catid){
    global $wpdb;
    $results = $wpdb-&gt;get_results( 
        ""SELECT * FROM {$wpdb-&gt;prefix}expert_jobs_categories WHERE id_category IN ($catid) ""
    );

    return $results;
    //wp_die();
}

function getSingleSubCat($catid){
    global $wpdb;
    $results = $wpdb-&gt;get_results( 
        ""SELECT * FROM {$wpdb-&gt;prefix}expert_jobs_categories WHERE id_category IN ($catid) ""
    );

    return $results;
    //wp_die();
}



add_action('wp_ajax_changesubcategorydropdown_action', 'changesubcategorydropdown');
add_action('wp_ajax_nopriv_changesubcategorydropdown_action', 'changesubcategorydropdown');
function changesubcategorydropdown(){

        if(!isset($_POST['maincategory'])) 
            return;

        if( isset($_POST['maincategory']) &amp;&amp; $_POST['maincategory']&lt;0 ) 
            return;

        header(""Content-Type: application/json"");

        $main_category  = $_POST['maincategory'];

        global $wpdb;
        $results = $wpdb-&gt;get_results( 
            ""SELECT * FROM {$wpdb-&gt;prefix}expert_jobs_categories WHERE id_parent IN ($main_category) AND id_category NOT BETWEEN 123 AND 198 ""
        );

        echo json_encode($results);
        wp_die();

}


function wpb_hook_javascript() {
  if (is_page ('covid-19-resources-for-artists')) { 
    ?&gt;
        &lt;script type=""text/javascript""&gt;
        // your javscript code goes here
          function gotosite() {
  window.location = document.getElementById(""menu"").value; // JQuery:  $(""#menu"").val();
}// your javscript code goes here
        &lt;/script&gt;
    &lt;?php
  }
}
add_action('wp_head', 'wpb_hook_javascript');
</code></pre>

<p>Have also tried adding it like this outside of the main php tags - </p>

<pre><code>    &lt;?php
add_action('wp_head', 'wpb_add_googleanalytics');
function wpb_add_googleanalytics() { ?&gt;

// Paste your Google Analytics code from Step 4 here
&lt;!-- Global site tag (gtag.js) - Google Analytics --&gt;
&lt;script async src=""https://www.googletagmanager.com/gtag/js?id=G-xxx""&gt;&lt;/script&gt;
&lt;script&gt;
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-xxx');
&lt;/script&gt;

&lt;?php } ?&gt;
</code></pre>

<p>can someone please tell me what I am doing wrong? Since I cant place this in a comment here is additional commentary based on the very kind assistance provided so far:</p>

<p>=================================================================================</p>

<p>Thanks but sorry I dont understand. If I literally copy and paste what you have written then it breaks the page. If I compare the first lines of your code to the top of the lines of code that exists then they too are different. </p>

<pre><code>&lt;?php
function denRegScript() {
  wp_enqueue_style(
    'datatable-css',
    get_theme_file_uri('/assets/css/datatables.css'),
    false
  );
  wp_enqueue_script(
    'datatables-js',
    get_theme_file_uri('/assets/js/datatables.min.js'),
    array('jquery'),
    '0.1',
    true
  );
}

add_action('wp_enqueue_scripts','denRegScript');

// …

compared to current lines-27:

&lt;?php

function denRegScript(){
    wp_enqueue_style( 'datatable-css', get_theme_file_uri('/assets/css/datatables.css'), false );
    wp_enqueue_script( 'datatables-js', get_theme_file_uri('/assets/js/datatables.min.js'), array('jquery'), '0.1', true ); 
}
add_action('wp_enqueue_scripts','denRegScript');


add_action('wp_ajax_movie_datatables', 'datatables_server_side_callback');
add_action('wp_ajax_nopriv_movie_datatables', 'datatables_server_side_callback');
//add_action('wp_ajax_nopriv_movie_datatables', 'datatables_server_side_callback');
function datatables_server_side_callback()
{

    header(""Content-Type: application/json"");

    $request = $_GET;

    $json_pre_result = newfunc($request);

    if(isset($json_pre_result)) {
        echo json_encode($json_pre_result);
    }

    wp_die();

If I just copy this portion:
function wpb_hook_javascript() {
  if ( is_page( 'covid-19-resources-for-artists' ) ) { 
  ?&gt;

    &lt;script type=""text/javascript""&gt;
      function gotosite() {
        window.location = document.getElementById(""menu"").value; // JQuery:  $(""#menu"").val();
      }
    &lt;/script&gt;

  &lt;?php
  }
}

add_action( 'wp_head', 'wpb_hook_javascript' );

function wpb_add_googleanalytics() {
?&gt;

  &lt;!-- Global site tag (gtag.js) - Google Analytics --&gt;
  &lt;script async src=""https://www.googletagmanager.com/gtag/js?id=G-xxx""&gt;&lt;/script&gt;
  &lt;script&gt;
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-xxx');
  &lt;/script&gt;

&lt;?php
}
</code></pre>

<p>add_action( 'wp_head', 'wpb_add_googleanalytics' );</p>

<p>and place it in the last portion of the code then it does nothing when I code inspect and check the head, there is no analytics code called. What am I missing?</p>
"
60826148,"<p>I'm trying to get the countries inside a select option from the API 
<a href=""https://covid19.mathdro.id/api/countries"" rel=""nofollow noreferrer"">https://covid19.mathdro.id/api/countries</a>.</p>

<p>github link : <a href=""https://github.com/nitink66/corona-updates"" rel=""nofollow noreferrer"">https://github.com/nitink66/corona-updates</a></p>

<p>It used to work like past two days but now i'm just getting the numbers inside the select option instead of the countries.
How should I access the countries so that I can display it on the select option tag.</p>

<pre><code>  const respCountries = await Axios.get(""https://covid19.mathdro.id/api/countries"");
  const countries = Object.keys(respCountries.data.countries);
  this.setState({
    confirmed: respApi.data.confirmed.value,
    recovered: respApi.data.recovered.value,
    deaths: respApi.data.deaths.value,
    countries
  });
}

renderCountryOptions(){
  return this.state.countries.map((country,i)=&gt;{
      return &lt;option key={i}&gt;{country}&lt;/option&gt;
  });
}



</code></pre>
"
61677285,"<p>My data has invoiced rental with a start date and end date, which more often than not overlaps our fiscal periods. I used the function List.Dates to create records for each date between the start and end dates, which worked great. When trying to merge the data to get the fiscal periods for each new record, I lose all the listed dates except for the first one.  Here is the advanced editor info:</p>

<pre><code>let
    Source = Covid19,
    #""Removed Columns"" = Table.RemoveColumns(Source,{""DTTRANS"", ""NOPRODUIT"", ""DSLIGNE"", ""QTEXP"", ""PXVENDANT"", ""MTLIGNE"", ""DTDEB"", ""DTFIN"", ""Location"", ""Tableau1.Nocardex""}),
    #""Reordered Columns"" = Table.ReorderColumns(#""Removed Columns"",{""NoCardex"", ""COMLOC"", ""Facture"", ""JoursAjustés"", ""DateDébut"", ""DateFin"", ""ParJour""}),
    #""Grouped Rows"" = Table.Group(#""Reordered Columns"", {""NoCardex"", ""COMLOC"", ""Facture"", ""JoursAjustés"", ""DateDébut"", ""DateFin""}, {{""LocationParJour"", each List.Sum([ParJour]), type number}}),
    #""Added Custom"" = Table.AddColumn(#""Grouped Rows"", ""Journee"", each List.Dates([DateDébut],[JoursAjustés],#duration(1, 0, 0, 0))),
    #""Expanded {0}"" = Table.ExpandListColumn(#""Added Custom"", ""Journee""),
    #""Changed Type"" = Table.TransformColumnTypes(#""Expanded {0}"",{{""Journee"", type date}}),
    #""Removed Columns1"" = Table.RemoveColumns(#""Changed Type"",{""JoursAjustés"", ""DateDébut"", ""DateFin""}),
    #""Merged Queries"" = Table.NestedJoin(#""Removed Columns1"", {""Journee""}, PériodesFiscales, {""DateTrans""}, ""PériodesFiscales"", JoinKind.LeftOuter),
    #""Expanded {0}1"" = Table.ExpandTableColumn(#""Merged Queries"", ""PériodesFiscales"", {""Produit""}, {""PériodesFiscales.Produit""})
in
    #""Expanded {0}1"" 
</code></pre>

<p>I am puzzled as to why I lose the dates. I am sure it is triviial. Hoping someone can help me figure this one out</p>
"
60961968,"<p>How do I get minnStats to work outside the req.end function. I performing a get call from unirest, and I want to export the data. I'm not sure how to use the parameter of 'covidData' outside the req.end function though. How do i get the console.log on the bottom to work?</p>

<pre><code>var unirest = require(""unirest"");

var req = unirest(""GET"", ""https://covid-19-coronavirus-statistics.p.rapidapi.com/v1/stats"");

req.query({
    ""country"": ""US""
});

req.headers({
    ""x-rapidapi-host"": ""covid-19-coronavirus-statistics.p.rapidapi.com"",
    ""x-rapidapi-key"": ""2e6a00a0b7mshb40a079e7a67f38p181597jsn5910590141c3""
});


req.end(function (covidData) {
    if (covidData.error) {
         throw new Error(covidData.error)
     } else {

    var covidStats = covidData.body.data.covid19Stats

    var minnStats = covidStats.filter(stat =&gt; stat.province === 'Minnesota')
    module.exports = minnStats

    console.table(minnStats)
    console.table(covidData.body)
    return covidData;
    }
})
console.log(minnStats)
</code></pre>
"
61057900,"<p>I have one form and one formset on the same page. Prior to my deletion of information from django admin, I could see both the form and the formset. After I deleted some 'patient' information and updated my css file, the formset stopped showing.</p>

<p>views.py</p>

<pre><code>def patient_new(request):
    patientForm = PatientForm()
    formset = LocationFormSet()
    if request.method == ""POST"":
        patientForm = PatientForm(request.POST)
        formset = LocationFormSet(request.POST) 
        if patientForm.is_valid() and formset.is_valid():
            patient = patientForm.save(commit=True)
            for form in formset:
                location = form.save(commit=False)
                location.patient = patient
                location.save()
            return index(request)
        else:
            print('ERROR FORM INVALID')

    return render(request, 'covidapp/patient_new.html',{'patientForm':patientForm, 'formset':formset}) 
</code></pre>

<p>html file</p>

<pre><code>&lt;form class=""form-horizontal"" method=""POST""&gt;
    {% csrf_token %}
    &lt;div class=""jumbotron""&gt;
        &lt;div class=""row spacer""&gt;
            &lt;div class=""col-2""&gt;
                &lt;div class=""input-group""&gt;
                    {{ patientForm.as_p }}       
                &lt;/div&gt;
            &lt;/div&gt; 
        &lt;/div&gt; 
    {{ formset.management_form }}
    {% for form in formset %}
    &lt;div class=""row form-row spacer""&gt;
        &lt;div class=""col-6""&gt;
            &lt;div class=""input-group""&gt;
                {{ form.as_p }}
                &lt;div class=""input-group-append""&gt;
                    &lt;button type=""button"" class=""btn btn-success add-form-row""&gt;+&lt;/button&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
    {% endfor %}

    &lt;div class=""row spacer""&gt;
        &lt;div class=""col-4 offset-2""&gt;&lt;/div&gt;
            &lt;button type=""submit"" class=""btn btn-block btn-primary""&gt;Create&lt;/button&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/form&gt;
</code></pre>

<p>html output</p>

<p><a href=""https://i.stack.imgur.com/NvEpX.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NvEpX.png"" alt=""enter image description here""></a></p>

<p>I am not sure whether the hidden input is supposed to be my formset and why it is hidden. </p>

<p>model.py</p>

<pre><code>class Patient(models.Model):
    name = models.CharField(max_length=200)
    idn = models.IntegerField(unique=True)
    date_of_birth = models.DateField()
    date_of_confirm = models.DateField()
    case_number = models.IntegerField()

    def get_absolute_url(self):
        return reverse(""patient_detail"", kwargs={'pk':self.pk})

    def __str__(self):
        return self.name

class Location(models.Model):
    patient = models.ForeignKey(Patient, related_name='locations', on_delete=models.CASCADE)
    location_name = models.CharField(max_length=50, null=True)
    address = models.CharField(max_length=300, null=True)
    grid_x = models.IntegerField(null=True)
    grid_y = models.IntegerField(null=True)
    date_from = models.DateField(null=True)
    date_to = models.DateField(null=True)
    details = models.CharField(max_length=300, null=True)
    category = models.CharField(max_length=300, null=True)

    def __str__(self):
        return self.location_name
</code></pre>

<p>form.py</p>

<pre><code>class PatientForm(forms.ModelForm):
    class Meta:
        model = Patient
        fields = '__all__'

LocationFormSet = modelformset_factory(
    Location,
    extra=0,
    exclude = ('patient',)
)
</code></pre>
"
61202524,"<p>I'm trying to make a line chart like the New York Times <a href=""https://www.nytimes.com/interactive/2020/03/21/upshot/coronavirus-deaths-by-country.html?smtyp=cur&amp;smid=fb-nytupshot"" rel=""nofollow noreferrer"">Coronavirus Deaths by U.S. State and Country Over Time: Daily Tracker</a>.</p>

<p>NYT has some clever lines in the chart showing the doubling rate, every day, every 2 days, every 3 days, every week, and so on.
I'm wondering how to write a function that returns an array of values that represent these lines given a start value of 10 and a maxX-value of 36 (total number of days as of today).</p>

<p>This is where I'm at right now, I'm afraid it does not calculate the values correctly but it might explain what I want to achieve.</p>

<p>How can I do this in a correct way? My math is too rusty for this.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>var maxX = 36;
var start = 10;

function double(factor) {
  var f = start;
  var arr = [f];
  for (var i = 1; i &lt; maxX; i++) {
    f = f + (f / factor)
    arr.push(f)
  }
  return arr
}

var lines = [1, 2, 3, 7, 30].map(f =&gt; {
  return {
    days: f,
    arr: double(f)
  }
})
console.log(lines)</code></pre>
</div>
</div>
</p>
"
61117386,"<p>I was doing some analysis about the Coronavirus and PyLint detect some undefined variables that are defined in an if statement or by a with statement. my code work as expected and is see no errors or runtime warnings. Here's my code :</p>

<pre class=""lang-py prettyprint-override""><code>import matplotlib.pyplot as plt
import pandas as pd
from datetime import datetime,date
import os
import requests
import numpy as np

class Covid:
    filename = 'data/' + str(date.today()) + '.csv'
    if not os.path.exists(filename):
        res = requests.get(""https://opendata.ecdc.europa.eu/covid19/casedistribution/csv"")
        with open(filename, 'w') as f:
            f.write(res.content.decode( ""ISO-8859-1""))    
    dateparse = lambda x: pd.datetime.strptime(x, '%d/%m/%Y')
    df = pd.read_csv(filename,sep=',', parse_dates=['dateRep'], date_parser=dateparse, encoding= ""ISO-8859-1"")    


</code></pre>

<p>the <code>__init__</code> and the other functions of the class are after this. </p>

<p>My problem is that PyLint show me warnings about undefined variables:<br>
the <code>f</code> at line 12, just after the <code>as</code>, where it's defined,<br>
the <code>f</code> at line 13,<br>
the <code>res</code> at line 13 (this warning disappear if i define <code>res</code> outside of the if statement).</p>

<p>It's not a major issue since my program still run but I'd like to understand why does PyLint shows me theses warnings and to get rid of theses warnings.
They don't appear if I do all of this outside the class definition.</p>

<p>Am I doing something wrong ?
Is it PyLint that not do what it is supposed to do ?</p>

<p>I am working with Visual Studio Code,
pylint 2.4.4
astroid 2.3.3
and Python 3.8.2</p>
"
61333662,"<p>I'm trying to get the first chunk listed below to replicate the second chunk. However, I've noticed in jupyter that when I try to get to the same table; it displays it differently (the first chunk looks like a nice dataframe and the second just looks like a plain table). Is there a difference between the two methods? The other thing I have also noticed is that the first method the column 'cases' comes out in dtypes while in the second chunk it displays something different. Thanks!</p>

<pre><code>url = 'https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv'
states = pd.read_csv(url, 
                     usecols=['date', 'county', 'state', 'cases'],
                     parse_dates=['date'],
                     squeeze=True
                    ).sort_index()
states = states.loc[states['state'] == 'Alabama']
states = states.drop(columns=['state'])
states.set_index(['county', 'date'], inplace=True)
states.dtypes
</code></pre>

<p>cases    int64</p>

<p>dtype: object</p>

<pre><code>url = 'https://covidtracking.com/api/v1/states/daily.csv'
states = pd.read_csv(url,
                     usecols=['date', 'state', 'positive'],
                     parse_dates=['date'],
                     index_col=['state', 'date'],
                     squeeze=True).sort_index()

states.dtypes
</code></pre>

<p>dtype('float64')</p>
"
61265856,"<p>In light of the COVID-19 pandemic, I have been working with some of the data and come across a comprehensive and updated source for cases/deaths/etc:
<a href=""https://opendata.ecdc.europa.eu/covid19/casedistribution/csv"" rel=""nofollow noreferrer"">https://opendata.ecdc.europa.eu/covid19/casedistribution/csv</a></p>

<p>There are some missing data, but instead of taking out my 'dropna' sledgehammer, I wanted to see what was going on and recover anything that could be recovered. It turns out that the two-letter country code of Namibia is 'NA,' and is seen as missing when imported.</p>

<p>I am working in Pandas 1.0.1 so I started out converting the columns to a string:</p>

<pre><code>dt = pd.read_csv(""https://opendata.ecdc.europa.eu/covid19/casedistribution/csv"")    
dt['geoId'] = dt['geoId'].astype('string')
</code></pre>

<p>Now I could have just used a '.fillna()' at the end of that but I wanted to handle any future cases where there were real NaNs.</p>

<p>My solution seems like a bit of a hack and probabaly not optimal:</p>

<pre><code>namibia_rows = dt['geoId'][dt['countriesAndTerritories'] == 'Namibia'].index
for x in namibia_rows:
    dt.loc[x, 'geoId'] = 'NA' 
</code></pre>

<p>Is there a better way to do this using a single line and a built-in Pandas function?</p>
"
60804630,"<p>I'm making a website for my church so we don't have to miss services and kids don't have to miss their classes during this pandemic and I made it so we can stream directly to the website but we can't stream to both the website and youtube at the same time since both require either an encoder or a webcam. Do you think I'd be able to somehow emulate an encoder to stream to youtube as well? I don't need help coding it, I just need to know if you think it's possible and if it is, if I should code a package so others can do the same. If I can help give other developers a bigger tool belt, I will. Through some modification of django-encode it may work. I don't think it's against their Terms of Service but I'll do more reading into that.</p>
"
61442830,"<p>I have a geopandas dataframe of shapes for all census tracts in the state of New York, with the general format of:</p>

<pre><code>0   36  081 044800  36081044800 448 G5020   S   208002  0   +40.7110219 -073.8026344    POLYGON ((-73.80646 40.71206, -73.80556 40.712..
</code></pre>

<p>The tract value is the fifth value in the frame. I also have a separate dataframe organized by tracts of new york city with various data points pertaining to covid-19 such as:</p>

<pre><code>TRACT    CASES     DEATHS   ...
</code></pre>

<p>What I need is a geographical layout of new york city, and I would like to shade tracts based on the various factors (cases, deaths) if they are in the later dataframe. Essentially, if the tract is in the geopandas frame but not in the COVID dataframe, I am not interested in it. What is the best way to create this select geographical plot and display the data that I need?</p>
"
60894898,"<p>I am trying to solve this reward/risk problem which would depend on an individual preference. I have two countries with 2 different hospitalization capabilities. Both of them wants to flatten the curve of a pandemic so they do not want to saturate their hospitals and at the same time they want to end the pandemic early so they can return to normal life and bring back the economy to life and the population can return to their jobs and full salaries. </p>

<p>Based on several decision variables, I ran a multi-objective optimization and I got a pareto front with the following results which is also shown on the scatter graph: </p>

<pre><code>pandemicEnd = [28,35,45,53,63,82,90,95,102,105,110]  ## the time when the pandemic will end - the earlier the better
peakTime = [10,26,32,52,66,75,83,90,100,110,112] ## the time when the peak will occur -- the later the better
</code></pre>

<p><a href=""https://i.stack.imgur.com/GCE06.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GCE06.png"" alt=""enter image description here""></a></p>

<p>The pareto front generates all the good ""non-dominated"" solutions that both countries can follow. My question: what would be the best way to choose <strong>the best</strong> pareto optimal solution from this set? </p>

<p>The extra information that I have is that country-B will have less economical impact than Country-A if the pandemic lasts longer. On the other hand, Country-B have better hospital capacity and can absorb having the peak time faster. Assuming I have a function to calculate the forecast confirmed cases and the following number of hospitals, current cases, and economic impact per capita for each country. </p>

<p>I was thinking to assign weights for every bit of extra information based on the above knowledge but I am wondering if there is any way that can make a better sound decision to choose the best solution and can be general for a third country or a fourth country if they have data. </p>

<pre><code>def confirmedCases_project(currentConfirmedCases, numberOfDays):
    c = np.zeros(numberOfDays)
    for day in range(numberOfDays):
        confirmedCasesFunction = currentConfirmedCases * math.exp(0.05*day) 
        c[day] = confirmedCasesFunction
    return c

## Country 1: 
population_1 = 50000000 ## citizens 
economicImpact_PerCapita_1 = 10000 ## $MM economic loss for each confirmed case 
current_Confirmed_Cases_1 = 3000 ## patients
numberOfCurrentHospitals = 389
costToBuildTempHopsital = 500000 ## $MM - The cost to build temporary hospital 

## Country 2: 
population = 2000000000 ## citizens 
economicImpact = 40000 ## $MM economic loss for each confirmed case 
current_Confirmed_Cases_2 = 6000 ## $MM economic loss for each confirmed case 
numberOfCurrentHospitals = 790
costToBuildTempHopsital = 500000 ## $MM - The cost to build temporary hospital 
</code></pre>
"
60924860,"<p>I am trying to pull some csv files from a <a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports"" rel=""nofollow noreferrer"">public repository</a> using Python. I have the code to process the data after I have the files' URL. Is there some sort of equivalent to <code>ls</code> for GitHub? I'm not seeing anything in GitHub's API, also it seems like it's possible using PyCurl, but then I'll need to parse through the html. Is there any prebuilt way to do this?</p>
"
61710311,"<p>This is my very first post on stackoverflow, so I will try my best to explain my struggle as clearly as I can!  I created a choropleth map of COVID-19 Confirmed Cases by US Counties using plotly.figure_factory (used <a href=""https://plotly.com/python/choropleth-maps/"" rel=""nofollow noreferrer"">this</a> as a reference).  I want to create a total of 11 scales for legend, but the output shows only 5 scales.  Here is my code and the output plot:</p>

<pre><code>import pandas as pd
import plotly.figure_factory as ff
import numpy as np
import datetime

latest_update = datetime.datetime.now()

color_scale = ['#ffffff', '#ffe6e6', '#ffcccc', '#ff9999', '#ff6666', '#ff3333',
               '#ff0000', '#e60000', '#cc0000', '#b30000', '#990000', '#800000']

endpts = list(np.linspace(0, 200000, num = len(color_scale) - 1))
# the 11 scales I want are:
# [0, 20000, 40000, 60000, 80000, 100000, 120000, 140000, 160000, 180000, 200000]

fips = jhu_county_latest_df['FIPS'].tolist()
values = jhu_county_latest_df['Cases'].tolist()

fig = ff.create_choropleth(
    fips=fips, values=values, 
    scope=['usa'],
    binning_endpoints=endpts, 
    # I also tried [0, 20000, 40000, 60000, 80000, 100000, 120000, 140000, 160000, 180000, 200000], but it didn't work 
    colorscale=color_scale,
    show_state_data=False,
    show_hover=True,
    county_outline=dict(color='white', width=0.25),
    asp = 2.9, # the width-to-height aspect ratio for the camera. Default = 2.5
    title_text = 'US State COVID-19 Confirmed Cases (latest update: ' + latest_update.strftime('%b %d') + ')',
    legend_title = 'confirmed cases'
)
fig.layout.template = None
fig.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/OHNLc.png"" rel=""nofollow noreferrer"">OUTPUT IMAGE</a></p>
"
61689897,"<pre><code>from selenium import webdriver
import time

driver = webdriver.Chrome()
driver.get('https://www.worldometers.info/coronavirus/country/canada/')
time.sleep(1)
button = driver.execute_script(""window.scrollTo(0, 5500)"") 
button1 = driver.find_element_by_xpath('/html/body/div[4]/div[2]/div[1]/div[8]/div/div[9]/a/button')
button1.click()
</code></pre>

<p><a href=""https://i.stack.imgur.com/gJvXk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/gJvXk.png"" alt=""enter image description here""></a></p>

<p>Trying to click this button using xpath but it just doesn't seem to click the button to extend the webpage. I first tried to copy by xpath which didn't work and then I copied the full xpath which also didn't work. After that, I tried to find by name and enter the text on the button and click the button. But none of these methods actually worked and clicked the button. So how can I click this button so that it extends the webpage allowing me to scrape more of the webpage?</p>
"
61535935,"<p>So I wrote a code that gathers data on the number of cases and deaths from COVID 19 in the US, one problem is it runs fine on my friend's computer and does what it is supposed to but it gives me a plethora of errors, we have the same modules installed and are on the same version of python, the only difference is that he is on a Windows PC while Inam on a MacBook. however, I do not see how that would affect it if anyone has any insight on this I would greatly appreciate it
Code:</p>

<pre><code>from urllib.request import urlopen
from bs4 import BeautifulSoup

url = 'https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/cases-in-us.html'
soup = BeautifulSoup(urlopen(url), 'html.parser')
i = []
remove_spaces = re.compile(r'[1234567890,]+')
callouts = soup.select('.callout')

for class_ in callouts:
    cases = class_.get_text()
    cases2 = remove_spaces.findall(cases)
    str(cases)
    cases = cases2
    i.append(cases)

print(f'Total US Cases {i[0][0]}')```
</code></pre>
"
61479306,"<p>when i run this code <a href=""https://i.stack.imgur.com/EAXwl.jpg"" rel=""nofollow noreferrer"">it looks like this on console</a> but
I want it to appear in the popup I created <a href=""https://i.stack.imgur.com/gJmgK.jpg"" rel=""nofollow noreferrer"">like this</a></p>

<pre><code>        data = pd.read_csv('covid_19_data.csv')
        turkiye = data[data[""Country/Region""]==""Turkey""]
        italya = data[data[""Country/Region""]==""Italy""]
        ispanya = data[data[""Country/Region""]==""Spain""]


        plt.scatter(turkiye.Deaths,turkiye.Recovered,color=""red"",label=""turkiye"")
        plt.scatter(italya.Deaths,italya.Recovered,color=""blue"",label=""italya"")
        plt.scatter(ispanya.Deaths,ispanya.Recovered,color=""black"",label=""ispanya"")
        plt.legend()
        fig1=plt.show()

        canvas = FigureCanvasTkAgg(fig1, master = tab1)
        canvas.draw()
        canvas.get_tk_widget().pack(side = tk.TOP, fill = tk.BOTH, expand = 1)
</code></pre>
"
61422882,"<p>I want to scrape data in a table on a website. I just want to get data from the first column to the fifth column (County, Cases, Deaths, Recov, Casws/10k). However, the results don't have the county names ( Los Angeles..). Can you help me to correct my mistakes?</p>

<pre>  
# Import libraries
import pandas as pd
import csv
import requests
from bs4 import BeautifulSoup

#This function is to scrape data from a website# 
def scrape_data(url):
    response = requests.get(url, timeout=10)
    soup = BeautifulSoup(response.content, 'html.parser')

    table = soup.find_all('table')[2]

    rows = table.select('tbody > tr')

    header = [th.text.rstrip() for th in rows[0].find_all('th')[0:5]]

    with open('output.csv', 'w') as csv_file:
        writer = csv.writer(csv_file)
        writer.writerow(header)
        for row in rows[2:]:
            data = [th.text.rstrip() for th in row.find_all('td')]
            writer.writerow(data)

# Main function 
if __name__==""__main__"":
        url = ""https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_California#cite_note-7""
        scrape_data(url)
</pre>
"
61508254,"<p>I was trying to web scrape data from a website but with no success.
I have run tests in the terminal and I seem to have no problem with running a for loop to print one list. The problem comes when I try to use 2 variables in a for loop.
I have tried to use <code>zip</code> but it doesn't seem to be working. Since I didn't know about how to use zip, I have checked other pages in StackOverflow but nothing seems to be working with my case.
This is the code I came up with:</p>

<pre><code>browser = webdriver.Chrome(""C:\webdrivers\chromedriver.exe"")
browser.get(""https://www.worldometers.info/coronavirus/"")
countries = browser.find_elements_by_tag_name(""mt_a"")
cases = browser.find_elements_by_tag_name(""sorting_1"")
[print(i.text, '-', j.text) for i, j in zip(countries, cases)]
</code></pre>

<p>When I tried running the program both from my IDE and terminal, nothing happened.
Can anyone please help me solve this issue?
All help appericiated.</p>
"
61406250,"<p>Is there a solution to this , the <code>Optionmenu</code> with <code>ttkthemes</code> seems to not give the normal functioning of the Optionmenu. 
Code: </p>

<pre><code>from tkinter import *
from tkinter.font import Font
from tkinter.font import Font
from tkinter import messagebox
from tkinter import filedialog
from PIL import ImageTk,Image
from tkcalendar import Calendar
import mysql.connector as mysql
from tkinter import ttk
from ttkthemes import themed_tk as tktheme
#root=Tk()

root = tktheme.ThemedTk()
root.get_themes()
root.set_theme('vista')
root.title('Patient Information')
font_text = Font(family='helvetica',size='11')
font_button = Font(size='10')

gen = ['Male','Female']
bl_gr = ['A+','A-','B+','B-','O+','O-','AB+','AB-']
cov = ['Yes','No','N/A']

def database():
    nme = name.get()
    p_h = ph.get()
    eid = e_id.get()
    ema_id = em_id.get()
    nat = nation.get()
    emer = emerg.get()
    gend = g.get()
    bloo = b.get()
    covi = co.get()
    dat = cal.selection_get()

    if nme=="""" or p_h=="""" or eid=="""" or ema_id=="""" or nat=="""" or emer=="""" or gend=="""" or bloo=="""" or covi=="""" or dat=="""":
        messagebox.showinfo('Fill all','All fields are necessary')
    else:
        con = mysql.connect(host='db4free.net', user='nihaalnz', password='monkey12345', database='nihaalnztrying')
        c = con.cursor()
        c.execute(""Insert into PATIENTS VALUES ('""+nme+""','""+p_h+""','""+eid+""','""+ema_id+""','""+gend+""','""+str(dat)+""','""+nat+""','""+str(bloo)+""','""+str(covi)+""','""+emer+""')"")
        c.execute('commit')
        con.close()
        messagebox.showinfo('Success','All values have been entered to the database')
        e1.delete(0, END)
        e2.delete(0, END)
        e3.delete(0, END)
        e4.delete(0, END)
        e5.delete(0, END)
        e6.delete(0, END)

def datepicker():
    global cal
    global a
    def date():
        global cal
        a = cal.selection_get()

    top = Toplevel(root)
    top.title('Choose Date')
    cal = Calendar(top,font=""Arial 14"", selectmode='day', year=2006, month=1, day=1)
    cal.pack(fill=""both"", expand=True)
    Button(top, text=""OK"", command=top.destroy,font=font_text).pack(fill='both')

def newtop():
    global new
    global img
    global img_prof
    new = Toplevel(root)
    mainfiledir = Image.open('/HSPTL/ID Card.png')
    img = ImageTk.PhotoImage(mainfiledir)
    img_label = Label(new, image=img)
    img_label.grid(row=1, column=2)
    dir = Image.open(path)
    dir = dir.resize((150, 150), Image.ANTIALIAS)
    img_prof = ImageTk.PhotoImage(dir)
    img_label = Label(new, image=img_prof)
    img_label.place(x=500, y=150)
    lo1 = Label(new, text=e1.get(), bg='white', font=font_text).place(x=330, y=127)
    lo2 = Label(new, text=e2.get(), bg='white', font=font_text).place(x=345, y=155)
    lo3 = Label(new, text=e3.get(), bg='white', font=font_text).place(x=315, y=183)
    lo4 = Label(new, text=g.get(), bg='white', font=font_text).place(x=165, y=227)
    lo5 = Label(new, text=b.get(), bg='white', font=font_text).place(x=220, y=257)
    lo6 = Label(new, text=cal.selection_get(), bg='white', font=font_text).place(x=220, y=288)

def imgpath():
    global path
    path = filedialog.askopenfilename(initialdir='/Donwloads',title='Select Photo',filetypes=(('PNG files','*.png'),
                                                                                              ('JPEG files','*.jpg')))

def popup():
    selection = messagebox.askyesno('Exit','Are you sure you want to exit?')
    if selection == 1:
        root.destroy()
    else:
        Label(root,text="""")

def reset():
    select = messagebox.askyesno('Reset', 'Are you sure you want to Reset?')
    if select == 1:
        e1.delete(0, END)
        e2.delete(0, END)
        e3.delete(0, END)
        e4.delete(0, END)
        e5.delete(0, END)
        e6.delete(0, END)
    else:
        Label(root, text="""")


l1 = ttk.Label(root,text='Name',font=font_text)
l2 = ttk.Label(root,text='Phone Number',font=font_text)
l3 = ttk.Label(root,text='Emirates ID',font=font_text)
l4 = ttk.Label(root,text='Email Address',font=font_text)
l5 = ttk.Label(root,text='Gender',font=font_text)
l6 = ttk.Label(root,text='Date Of Birth',font=font_text)
l7 = ttk.Label(root,text='Nationality',font=font_text)
l8 = ttk.Label(root,text='Blood Group',font=font_text)
l9 = ttk.Label(root,text='Test for COVID-19',font=font_text)
l10 = ttk.Label(root,text='Emergency Contact Number',font=font_text)
l11 = ttk.Label(root,text='Select Photo',font=font_text)

name = StringVar()
ph = StringVar()
e_id = StringVar()
em_id = StringVar()
nation = StringVar()
emerg = StringVar()


e1 = ttk.Entry(root,textvariable=name)
e2 = ttk.Entry(root,textvariable=ph)
e3 = ttk.Entry(root,textvariable=e_id)
e4 = ttk.Entry(root,textvariable=em_id)
e5 = ttk.Entry(root,textvariable=nation)
e6 = ttk.Entry(root,textvariable=emerg)

b_ch = ttk.Button(root,text='Select Image',command=imgpath)
b_id = ttk.Button(root,text='Make ID Card',command=newtop)
b_db = ttk.Button(root,text='Enter Database',command=database)
b_ex = ttk.Button(root,text='Exit',command=popup)
b_re = ttk.Button(root,text='Reset',command=reset)
b_dt = ttk.Button(root,text='Choose Date',command=datepicker)

g = StringVar()
g.set('Choose Gender')
opt_g = OptionMenu(root,g,*gen)

b = StringVar()
b.set('Choose group')
opt_blo = OptionMenu(root,b,*bl_gr)

co = StringVar()
co.set('Choose result')
opt_cov = OptionMenu(root,co,*cov)


l1.grid(row=0,column=0,padx=10)
l2.grid(row=1,column=0,padx=10)
l3.grid(row=2,column=0,padx=10)
l4.grid(row=3,column=0,padx=10)
l5.grid(row=4,column=0,padx=10)
l6.grid(row=5,column=0,padx=10)
l7.grid(row=6,column=0,padx=10)
l8.grid(row=7,column=0,padx=10)
l9.grid(row=8,column=0,padx=10,pady=5)
l10.grid(row=9,column=0,padx=10)
l11.grid(row=10,column=0,padx=10)

e1.grid(row=0,column=1,pady=5,ipady=5,padx=5)
e2.grid(row=1,column=1,pady=5,ipady=5,padx=5)
e3.grid(row=2,column=1,pady=5,ipady=5,padx=5)
e4.grid(row=3,column=1,pady=5,ipady=5,padx=5)
e5.grid(row=6,column=1,pady=6,ipady=5,padx=5)
e6.grid(row=9,column=1,pady=5,ipady=5,padx=5)

b_ch.grid(row=10,column=1,sticky=E+W,pady=5,padx=5)
b_id.grid(row=11,column=0,sticky=E+W,padx=10,pady=5)
b_db.grid(row=11,column=1,sticky=E+W,padx=5,pady=5)
b_ex.grid(row=12,column=1,sticky=E+W,padx=5,pady=5)
b_re.grid(row=12,column=0,sticky=E+W,padx=10,pady=5)
b_dt.grid(row=5,column=1,sticky=E+W,padx=7,pady=5,ipadx=5)

opt_g.grid(row=4,column=1,ipadx=6,pady=3)
opt_blo.grid(row=7,column=1,padx=5,ipadx=10)
opt_cov.grid(row=8,column=1,ipadx=12,pady=5)

root.mainloop()
</code></pre>

<p>Output:</p>

<p><strong>Without ttkthemes</strong></p>

<p><a href=""https://i.stack.imgur.com/Ff1bG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ff1bG.png"" alt=""Without ttkthemes""></a></p>

<p><strong>With ttkthemes</strong></p>

<p><a href=""https://i.stack.imgur.com/dmo8X.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dmo8X.png"" alt=""With ttkthemes""></a></p>

<p>Is it a problem in code or is it like that and has no fix?</p>
"
61386419,"<p>hello i am trying to push 2 variables from flask to javascript in chart.js
im using this  variable  graphdata_for_dates for in labels(x axis) and graphdata_for_cases for the y axis 
everything works out until i import the x axis variable inn javascript and the graph dissapears</p>

<pre><code>data: {
    labels: {{graphdata_for_dates}},
    datasets: [{
        label: 'Κρούσματα Covid-19 (Ελλάδα)',
        backgroundColor: 'rgb(255, 99, 132)',
        borderColor: 'rgb(255, 99, 132)',
        data: {{graphdata_for_cases}}
    }]
</code></pre>

<p>but when i do this it works flawlesly`</p>

<pre><code> data: {
    labels: {{graphdata_for_cases}},
    datasets: [{
        label: 'Κρούσματα Covid-19 (Ελλάδα)',
        backgroundColor: 'rgb(255, 99, 132)',
        borderColor: 'rgb(255, 99, 132)',
        data: {{graphdata_for_cases}}
    }]
</code></pre>

<p>and shows correct data but its the same on both axis
graphdata_for_cases = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 4, 4, 7, 7, 7, 9, 31, 45, 46, 73, 73, 89, 99, 99, 190, 228, 331, 331, 387, 418, 418, 495, 530, 624, 695, 743, 821, 892, 966, 1061, 1156, 1212, 1314, 1415, 1544, 1613, 1673, 1735, 1755, 1832, 1884, 1955, 2011, 2081, 2114, 2145, 2170, 2192, 2207, 2224, 2235, 2235, 2245, 2401, 2408]</p>

<p>and graphdata_for_dates = ['2020/01/22',.......................... '2020/01/23', '2020/04/22']
graphdata_for_cases is a list
graphdata_for_dates is a string ty</p>
"
61289529,"<p>I have been at this for hours now. I am trying to plot the spread (and deaths) of Covid-19 in different countries of the world (it shows new cases, total cases, new deaths and total deaths in different tabs). I want to allow the user to choose which countries they want to see using the CheckBoxGroup widget from Bokeh but my plot isn't updating. Additionally, when debugging, I noticed that the update function only updates when there is a new selection (or so it seems). When I select a country, if I print the src data from the update function, the data from the new country is present (but is not plotted). However, when I unselect a country, the data from that country is still present after it is supposed to have been updated. </p>

<p>I don't know if the use of groupby creates a problem (I haven't seen any working examples with groupby, I tried using MultiLine but I'm not quite sure I understood the purpose).</p>

<p>PS : If anyone knows how to format  CheckBoxGroup to have columns it would also be great, but it's far from being a priority right now.</p>

<p>Thanks in advance !</p>

<pre><code>import pandas as pd
import numpy as np
import datetime as dt
from os.path import dirname, join


from bokeh.io import push_notebook
from bokeh.plotting import show, output_notebook,figure,curdoc

from bokeh.models import CategoricalColorMapper, HoverTool, ColumnDataSource, Panel,CustomJS
from bokeh.models.widgets import CheckboxGroup, Slider, RangeSlider, Tabs, MultiSelect

from bokeh.layouts import column, row, WidgetBox
from bokeh.palettes import all_palettes

from bokeh.application.handlers import FunctionHandler
from bokeh.application import Application   





def make_dataset(select_countries):
    prep_data={}
    for i,group in enumerate(select_countries):
        group[1].set_index('date', drop=True, inplace=True)
        data=group[1].reindex(all_days)
        data[""location""].fillna(method='backfill',inplace=True)
        data.fillna(value=0,inplace=True)
        data['color']=color_list[i]
        data.reset_index(inplace=True)
        prep_data[group[0]]=data
    return ColumnDataSource(prep_data)

def make_plot(src):

    p1 = figure(plot_width=1000, plot_height=600,x_axis_type='datetime',title = 'Chart of new cases over time',
              x_axis_label = 'Date', y_axis_label = 'Number of new cases')
    p2 = figure(plot_width=1000, plot_height=600,x_axis_type='datetime',title = 'Chart of total cases over time',
              x_axis_label = 'Date', y_axis_label = 'Number of total cases')
    p3 = figure(plot_width=1000, plot_height=600,x_axis_type='datetime',title = 'Chart of new deaths over time',
              x_axis_label = 'Date', y_axis_label = 'Number of new deaths')
    p4 = figure(plot_width=1000, plot_height=600,x_axis_type='datetime',title = 'Chart of total deaths over time',
              x_axis_label = 'Date', y_axis_label = 'Number of total deaths')
    for group in src.data.values() :
        plot1=p1.line(x='index',y='new_cases',source=group,color=group['color'].values[0],legend=""location"")
        plot2=p2.line(x='index',y='total_cases',source=group,color=group['color'].values[0],legend=""location"")
        plot3=p3.line(x='index',y='new_deaths',source=group,color=group['color'].values[0],legend=""location"")
        plot4=p4.line(x='index',y='total_deaths',source=group,color=group['color'].values[0],legend=""location"")

    p1.legend.click_policy = 'hide'
    p2.legend.click_policy = 'hide'
    p3.legend.click_policy = 'hide'
    p4.legend.click_policy = 'hide' 

    tab1 = Panel(child=p1, title=""new_cases"")
    tab2 = Panel(child=p2, title=""total_cases"")
    tab3 = Panel(child=p3, title=""new_deaths"")
    tab4 = Panel(child=p4, title=""total_deaths"")


    tabs = Tabs(tabs=[ tab1, tab2, tab3, tab4 ])


    return tabs

def update(attr, old, new):
    # Get the list of countries
    select_countries_labels=[country_selection.labels[i] for i in country_selection.active]
    #print(select_countries_labels)
    select_countries=[countries_selected for countries_selected in countries
                  if countries_selected[0] in select_countries_labels]

    new_src = make_dataset(select_countries)
    #print(""new countries"")
    #print(new_country_list.data)
    # Update the source used the quad glpyhs
    src.data.update(new_src.data)
    #=new_country_list.data
    #print(country_df.data)


df=pd.read_csv(join(dirname(__file__),'full_data(2).csv'), encoding='utf-8',parse_dates=[""date""])
countries=df.groupby(""location"")
l=countries.describe(include=""all"")
all_days=pd.date_range(l.loc['World']['date']['first'],l.loc['World']['date']['last'],freq='D')

# Countries and colors

color_dicts=[list(colors.values()) for colors in list(all_palettes.values())]
color_list_int=[color for color_sublist in color_dicts for color in color_sublist]
color_list_dup=[color for color_sublist in color_list_int for color in color_sublist]
color_list=list(set(color_list_dup))
color_list.sort()

available_countries = list(set(df['location']))
available_countries.sort()


# Countries to plot
country_selection = CheckboxGroup(labels=available_countries, 
                                  active = [0,1])
country_selection.on_change('active', update)

# Initial carriers and data source

select_countries_labels=[country_selection.labels[i] for i in country_selection.active]
initial_countries=[countries_selected for countries_selected in countries
                  if countries_selected[0] in select_countries_labels]

# Prep the data
src = make_dataset(initial_countries)

# Make the covid plot
p1 = make_plot(src)

# Put controls in a single element
controls = WidgetBox(country_selection)

# Create a row layout
layout = row(controls, p1)


curdoc().add_root(layout)
curdoc().title = ""covid""
</code></pre>
"
61280561,"<p>I'm running this in Jupyter Notebook. I'll attach my full code. I'm using a csv file from Kaggle to plot the cumulative coronavirus cases throughout different countries in the world. </p>

<p>Here's the link to the Kaggle dataset download: <a href=""https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset"" rel=""nofollow noreferrer"">https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset</a> 
I'm using the ""covid_19_data.csv"" file.</p>

<pre><code>import chart_studio.plotly as py
import plotly.graph_objs as go
import pandas as pd

from plotly.offline import download_plotlyjs, init_notebook_mode, iplot, plot
init_notebook_mode(connected = True)
cf.go_offline()

df = pd.read_csv('covid_19_data.csv')

data = dict(type = 'choropleth',
       locations = df['Country/Region'],
        z = df['Confirmed'],
        text = df['Province/State'],
        colorbar = {'title':'Cases of COVID-19'} )

layout = dict(title = '2020 Global Coronavirus Cases', geo = dict(showframe = False, projection = {'type':'natural earth'}))

choromap = go.Figure(data = [data],layout = layout)

iplot(choromap)
</code></pre>

<p>The output is a gray map of the world. There is a legend with color, and a title as well. I'm confused why the data is not being plotted!</p>

<p>Any help is appreciated!  </p>
"
61114078,"<p>I was trying to get the information from a table on a web page, using Panda, but it doesn't throw me all the information and other ways and I can't either.</p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
calls_df = pd.read_html(""https://google.com/covid19-map/?hl=es-419"", index_col=1,
                        attrs={""class"":""SAGQRd""})
df = pd.DataFrame(calls_df)
print(calls_df)
</code></pre>

<p>I tried the code with other links and if they get the information from the tables, what is my error?</p>
"
61211578,"<p>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import COVID19Py
    covid19 = COVID19Py.COVID19()</p>

<pre><code>covid19 = COVID19Py.COVID19(data_source=""jhu"")

latest = covid19.getLatest()

location = covid19.getLocationByCountryCode(""IN"")

loc_data=location[0]
virusdata=dict(loc_data)

loc_data=location[0]
virusdata=dict(loc_data['latest'])

names=list(virusdata.keys())
values=list(virusdata.values())

plt.bar(range(len(virusdata)),values, tick_label=names)
plt.title('COVID-19 Analysis')
plt.show()
</code></pre>
"
60923428,"<p>I have a python script that produces a wrong date format.</p>

<pre><code>import csv
import urllib
import requests
import numpy as np
from urllib.request import urlopen
from matplotlib.dates import DateFormatter
import matplotlib.pyplot as plt 
import pandas as pd
import io

link = 'https://health-infobase.canada.ca/src/data/covidLive/covid19.csv'
s = requests.get(link).content
coviddata = pd.read_csv(io.StringIO(s.decode('utf-8')),
                        parse_dates=['date'],
                        index_col= ['date'],
                        na_values=['999.99'])
prinput = 'Quebec'
ispr = coviddata['prname'] == prinput
covidpr = coviddata[ispr]
print(covidpr)
</code></pre>

<p>The data it produces seems to garble up dates as shown below.</p>

<pre><code>        pruid  prname prnameFR  ...  numtotal  numtoday  numtested
</code></pre>

<p>date                                ...
<strong>2020-01-03     24  Quebec   Québec  ...         1         1        NaN
2020-03-03     24  Quebec   Québec  ...         1         0        NaN
2020-05-03     24  Quebec   Québec  ...         2         1        NaN
2020-06-03     24  Quebec   Québec  ...         2         0        NaN
2020-07-03     24  Quebec   Québec  ...         2         0        NaN
2020-08-03     24  Quebec   Québec  ...         3         1        NaN
2020-09-03     24  Quebec   Québec  ...         4         1        NaN
2020-11-03     24  Quebec   Québec  ...         7         3        NaN
2020-12-03     24  Quebec   Québec  ...        13         6        NaN</strong>
2020-03-13     24  Quebec   Québec  ...        17         4        NaN
2020-03-14     24  Quebec   Québec  ...        17         0        NaN</p>

<p>Now on the contrary
here is another code snippet which works.</p>

<pre><code>import csv
import urllib
import requests
from urllib.request import urlopen
from matplotlib.dates import DateFormatter
import matplotlib.pyplot as plt 
from datetime import datetime
link = 'https://health-infobase.canada.ca/src/data/covidLive/covid19.csv'

text = requests.get(link).text
lines = text.splitlines()
infile = csv.DictReader(lines)
prinput = input(""Enter province(EN):"")
xvalues=[]
yvalues=[]
for row in infile:
    if(row['prname']==prinput):
    xvalues.append(row['date'])
    yvalues.append(row['numconf'])
    print(row['prname'],row['date'],row['numconf'])
</code></pre>

<p>It produces the right dates
<strong>Quebec 01-03-2020 1
Quebec 03-03-2020 1
Quebec 05-03-2020 2
Quebec 06-03-2020 2
Quebec 07-03-2020 2
Quebec 08-03-2020 3
Quebec 09-03-2020 4
Quebec 11-03-2020 7
Quebec 12-03-2020 13</strong>
Quebec 13-03-2020 17
Quebec 14-03-2020 17
Quebec 15-03-2020 24
Quebec 16-03-2020 39
Quebec 17-03-2020 50</p>

<p>What is wrong with the first script?</p>
"
60975075,"<p>My study is about Coronavirus cases in the United States. The state population is on my y-axis, and the deaths-to-case ratio is on my x-axis. For whatever reason, my x-axis goes in increments of .5 up to 4.0 - this means that it's not going by millions, because for example, California has 39M residents. But I can't figure out what the logic is with this y-axis numbering. Screenshot is attached.<a href=""https://i.stack.imgur.com/Hp4rj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Hp4rj.png"" alt=""enter image description here""></a></p>

<pre><code>sns.scatterplot(x='deaths_to_cases', y='StatePopulation', data=df)
</code></pre>
"
60878794,"<p>On this page '<a href=""https://www.nj.gov/health/cd/topics/covid2019_dashboard.shtml"" rel=""nofollow noreferrer"">https://www.nj.gov/health/cd/topics/covid2019_dashboard.shtml</a>', I try to get the number of New Jersey Positives (upper right of the dashboard).</p>

<pre><code>    positiveCount = driver.find_elements_by_xpath(""//text[@style='stroke-width: 2; font-size: 160px; line-height: normal;']"")
    print len(positiveCount)
</code></pre>

<p>it always show 0.</p>

<p>What did I do wrong? Thanks.  </p>
"
61146746,"<p>I've tried to create a Web Scraper for CNN. My goal is to scrap all news articles within the search query. Sometimes I get an output for some of the scraped pages and sometimes it doesn't work at all. </p>

<p>I am using selenium and BeautifulSoup packages in Jupiter Notebook. I am iterating over the pages via the url parameters <code>&amp;page={}&amp;from={}</code>. I tried by.XPATH before and simply clicking the next button at the end of the page, but it gave me the same results. </p>

<p>Here's the code I'm using: </p>

<pre><code>#0 ------------import libraries
import requests
from bs4 import BeautifulSoup
from bs4.element import Tag
import feedparser
import urllib
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pickle
import pandas as pd

#3 ------------CNN SCRAPER
#3.1 ----------Define Funktion
def CNN_Scraper(max_pages):
    base = ""https://edition.cnn.com/""
    browser = webdriver.Chrome('C:/chromedriver_win32/chromedriver.exe')
    load_content = browser.implicitly_wait(30)
    base_url = 'https://edition.cnn.com/search?q=coronavirus&amp;sort=newest&amp;category=business,us,politics,world,opinion,health&amp;size=100'

 #-------------Define empty lists to be scraped
    CNN_title   = []
    CNN_date   = []
    CNN_article   = []
    article_count = 0


 #-------------iterate over pages and extract   
    for page in range(1, max_pages + 1):
        print(""Page %d"" % page)

        url= base_url + ""&amp;page=%d&amp;from=%d"" % (page, article_count)
        browser.get(url)
        load_content
        soup = BeautifulSoup(browser.page_source,'lxml')
        search_results = soup.find('div', {'class':'cnn-search__results-list'})
        contents = search_results.find_all('div', {'class':'cnn-search__result-contents'})

        for content in contents:
            try:
                title = content.find('h3').text
                print(title)
                link = content.find('a')
                link_url = link['href']    

                date = content.find('div',{'class':'cnn-search__result-publish-date'}).text.strip()
                article = content.find('div',{'class':'cnn-search__result-body'}).text
            except:
                print(""loser"")
                continue
            CNN_title.append(title)
            CNN_date.append(date)
            CNN_article.append(article)

        article_count += 100   
        print(""-----"")

 #-------------Save in DF    
    df = pd.DataFrame()
    df['title'] = CNN_title
    df['date'] = CNN_date      
    df['article'] = CNN_article 
    df['link']=CNN_link
    return df        

    #print(""Complete"")

    browser.quit()

#3.2 ----------Call Function - Scrape CNN and save pickled data
CNN_data = CNN_Scraper(2)
#CNN_data.to_pickle(""CNN_data"")
</code></pre>
"
60832842,"<p>I am trying to build a plot to display which job is more exposed to virus like [this][1] with Bokeh.
I tried to update the label when my selected value changes. However, It delay the changed. how example when I first select ""nurse"" in select, it did not show label, then when I select ""doctor"" , it showed ""nurse"" on the plot. please help me fix it. Thank you so much. </p>

<pre><code>source = ColumnDataSource(full_table) 
p = figure(title=""各職業之新型冠狀病毒之風險圖"", x_axis_label='暴露疾病頻率', y_axis_label='與人接近距離')
p.circle('Expose_frequency',
           'Physical_proximity', name = 'allcircle',
            size=10,fill_alpha=0.2, source=source, fill_color='gray', hover_fill_color='firebrick', hover_line_color=""firebrick"", line_color=None)
hover = HoverTool(tooltips=[('職業','@TW_Occupation'),('Occupation','@Occupation'),('暴露於疾病指數','@Expose_frequency'),('與人接近距離指數','@Physical_proximity')])
p.add_tools(hover)

# Define a callback function 
def update_plot(attr, old, new):

       old_choice=full_table[full_table['TW_Occupation']==old]  
       p.circle(old_choice['Expose_frequency'],old_choice['Physical_proximity'],size=10,fill_alpha=1,fill_color='Gray', line_color=None )

       choice=full_table[full_table['TW_Occupation']==new]
       a=choice['Expose_frequency']
       b=choice['Physical_proximity']
       p.circle(a,b,size=10,fill_alpha=1,fill_color='blue' )

       citation=Label(x=choice.Expose_frequency.item()+0.5,y=choice.Physical_proximity.item()+0.5, 
            text=choice.TW_Occupation.item(), 
            border_line_color=None, border_line_alpha=1.0,
            background_fill_color=None, background_fill_alpha=0,
            text_font_size=""8pt"", text_align=""center"")

       p.add_layout(citation) 

# Add Select 
select = Select(title='Occupation', options=full_table['TW_Occupation'].tolist(), value='')

# Attach the update_plot callback to the 'value' property of select
select.on_change('value', update_plot)

#layout 
layout = row(p, select)

# Add the plot to the current document
curdoc().add_root(layout)```

Qeustion 2: 
I also want to wish to show an annotation text box aside the selected circle which looks like the hover tool just without hovering on it. 
[enter image description here][2]


  [1]: https://www.nytimes.com/interactive/2020/03/15/business/economy/coronavirus-worker-risk.html?smid=fb-nytimes&amp;smtyp=cur&amp;fbclid=IwAR0UG6dj1eqMilukx9wit5FX4P4TxAodtvW8b0toGyYDCKygM087uZr8P38
  [2]: https://i.stack.imgur.com/El7Dv.png
</code></pre>
"
61026655,"<p>I have a problem about showing image in terms of width and height. Some parts of it cannot be shown in png file.(Especially right side , some text cannot be shown) How can I fix it?.</p>

<p><a href=""https://i.stack.imgur.com/vFhrS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/vFhrS.png"" alt=""enter image description here""></a></p>

<p>Here is my code shown below.</p>

<pre><code>plt.figure(figsize=(10,9))
ax = subplot_kw=dict(aspect=""equal"")
my_circle = plt.Circle((0, 0), 0.7, color='white')


d = plt.pie(symptoms['percentage'],
            autopct='%1.1f%%',
            pctdistance=0.85, 
            labeldistance=1.1,
            textprops = {'fontsize':10.5})

plt.axis('equal')
plt.gca().add_artist(my_circle)

plt.text(0, 
         0, 
         ""Symptoms of Coronavirus"",
         horizontalalignment='center',
         verticalalignment='center',
         size=16,
        )

plt.legend(symptoms['symptom'],loc='right',bbox_to_anchor=[1.2, 0.5])
plt.savefig('images/image2.png')
plt.savefig('images/image2.pdf')  
plt.show()
</code></pre>
"
61238270,"<p>I am trying to scrape a site for the values of cases but when I run the program it only returns 1 value. ['203,377'], How do I get the other values to return</p>

<pre><code>page = requests.get(""https://www.theguardian.com/world/ng-interactive/2020/apr/13/coronavirus-map-us-latest-covid-19-cases-state-by-state"")
soup = BeautifulSoup(page.content, 'html.parser')
state_table = soup.find(id='co-table-container')
item2 = state_table.find_all(class_='co-table')
case2 = [ c2.find(class_='co-td-cases').get_text() for c2 in item2]
print(case2)
</code></pre>
"
61351830,"<p>I am extract the information from the csv file that the user inputs. For example if the user types in Nevada it will go through the csv file and pull the information from that row and print it to the user. But the result i keep getting is the last row in the csv file.</p>

<pre><code>def create_csv(name):
    with open('details.csv', 'rt') as f:
        reader = csv.reader(f)
        for row in reader:
            if row[1] == name:
                print(name)
        return print(row)
 page = requests.get(""https://ix.cnn.io/data/novel-coronavirus-2019-ncov/us/states.json"")

    js_resp = json.loads(page.text)

    states = []
    case = []
    deaths = []

    for item in js_resp['data']:
        states.append(item['name'])
        case.append(item['cases'])
        deaths.append(item['deaths'])

    details = pd.DataFrame(
        {'State': states,
         'Cases': case,
         'Death': deaths,
         }
    )

    details.to_csv('details.csv') 
 select = int(input('Please enter how you would like to look up information '
                           '""Press 1 for State, 2 for City, 3 for Zip"" '))
 if select == 1:
            # Get input of which state the user want to look up
   s = input('Which state would you like to see ')
   break
</code></pre>
"
61493708,"<p>I am trying to create a plot that dynamically changes as the length of the x and y data sets change. </p>

<p>I got it to work by plotting the plot each loop, but that is not an efficient way to accomplish this. </p>

<p>I use the variable self.line, in line 165 to initialize this plot. At line 228 I change the plot <code>self.ax2.plot(self.stepData, self.nAlive, 'b-')</code></p>

<p>I am trying to use this instead to just change the data: ```self.line.set_data = (self.stepData, self.nAlive)</p>

<p>Here is my code:</p>

<pre><code>
import random
import numpy as np
import matplotlib.pyplot as plt


# ====================================================================================

class Person:

    def __init__(self, position):
        self.xpos = position[0]
        self.ypos = position[1]
        self.alive = True
        self.trapped = False  # if all people are trapped, need to end program
        self.distance = None  # distance to closest neighbor

    def move(self, xmax, ymax, bc, taken):
        """""" moves person, if possible, to an adjacent corner """"""
        # cannot step where someone else is currently standing
        taken[self.xpos, self.ypos] = False  # moving from current spot
        disallowed = set()  # empty set object; will add disallowed directions
        if bc == 'wall':
            if self.ypos == ymax or taken[self.xpos, self.ypos + 1]:
                disallowed.add('north')
            if self.xpos == xmax or taken[self.xpos + 1, self.ypos]:
                disallowed.add('east')
            if self.ypos == 0 or taken[self.xpos, self.ypos - 1]:
                disallowed.add('south')
            if self.xpos == 0 or taken[self.xpos - 1, self.ypos]:
                disallowed.add('west')
        elif bc == 'periodic':
            if (self.ypos == ymax and taken[self.xpos, (self.ypos + 1) % ymax]) \
                    or (self.ypos &lt; ymax and taken[self.xpos, self.ypos + 1]):
                disallowed.add('north')
            if (self.xpos == xmax and taken[(self.xpos + 1) % xmax, self.ypos]) \
                    or (self.xpos &lt; xmax and taken[self.xpos + 1, self.ypos]):
                disallowed.add('east')
            if (self.ypos == 0 and taken[self.xpos, (self.ypos - 1) % ymax]) \
                    or (self.ypos &gt; 0 and taken[self.xpos, self.ypos - 1]):
                disallowed.add('south')
            if (self.xpos == 0 and taken[(self.xpos - 1) % xmax, self.ypos]) \
                    or (self.xpos &gt; 0 and taken[self.xpos - 1, self.ypos]):
                disallowed.add('west')

        # Use the set method 'difference' to get set of allowed directions
        allowed = {'north', 'east', 'south', 'west'}.difference(disallowed)

        if len(allowed) == 0:
            self.trapped = True  # cannot move anymore
        else:
            """"""
            Randomly pick from the allowed directions; need to convert set
            object to a list because random.choice doesn't work on sets
            """"""
            self.direction = random.choice(list(allowed))
            if self.direction == 'north':
                if (bc == 'wall' and self.ypos &lt; ymax) or bc == 'periodic':
                    self.ypos += 1
            elif self.direction == 'east':
                if (bc == 'wall' and self.xpos &lt; xmax) or bc == 'periodic':
                    self.xpos += 1
            elif self.direction == 'south':
                if (bc == 'wall' and self.ypos &gt; 0) or bc == 'periodic':
                    self.ypos -= 1
            elif self.direction == 'west':
                if (bc == 'wall' and self.xpos &gt; 0) or bc == 'periodic':
                    self.xpos -= 1
            """"""

            With periodic boundary conditions, it's possible that (xpos, ypos) could
            be off the grid (e.g., xpos &lt; 0 or xpos &gt; xmax). The Python modulo
            operator can be used to give exactly what we need for periodic bc. For
            example, suppose xmax = 20; then if xpos = 21, 21 % 20 = 1; if xpos = -1,
            -1 % 20 = 19. (Modulo result on a negative first argument may seem
            strange, but it's intended for exactly this type of application. Cool!)
            If 0 &lt;= xpos &lt; xmax, then modulo simply returns xpos. For example,
            0 % 20 = 0, 14 % 20 = 14, etc. Only special case is when xpos = xmax, in
            which case we want to keep xpos = xmax and not xpos % xmax = 0
            """"""
            if self.xpos != xmax:
                self.xpos = self.xpos % xmax
            if self.ypos != ymax:
                self.ypos = self.ypos % ymax

    def proximity(self, xmax, ymax, bc, people):
        """"""
        Finds distance from closest neighbor, will calculate actual distance over diagonals, assuming 1 square is
        1 ft^2. If no one else is in range (less than 6 feet away), return None.
        """"""
        distance = None

        for person in people:
            if person is not self and person.alive:  # can only get infected by other alive people
                x = abs(self.xpos - person.xpos)
                y = abs(self.ypos - person.ypos)

                if bc == 'periodic':  # check other direction (across boundaries) for periodic bc
                    tempX1 = None
                    tempY1 = None
                    for i in range(2):
                        if tempX1 is None:
                            tempX1 = (self.xpos - 0) + (xmax - person.xpos)  # check distance in one direction
                        else:
                            tempX2 = (person.xpos - 0) + (xmax - self.xpos)  # check distance in other direction
                            if tempX2 &lt; tempX1:
                                tempX1 = tempX2
                        if tempY1 is None:
                            tempY1 = (self.ypos - 0) + (ymax - person.ypos)  # check distance in one direction
                        else:
                            tempY2 = (person.ypos - 0) + (ymax - self.ypos)  # check distance in other direction
                            if tempY2 &lt; tempY1:
                                tempY1 = tempY2
                    if tempX1 &lt; x:
                        x = tempX1
                    if tempY1 &lt; y:
                        y = tempY1

                if x &gt;= 6 or y &gt;= 6:
                    pass  # not close enough to infect
                else:  # need to find distance
                    temp = np.sqrt(x ^ 2 + y ^ 2)
                    if distance is None or temp &lt; distance:
                        distance = temp
        if distance is not None and distance &gt;= 6:
            distance = None
        return distance

    def gambleYourLife(self, distance):
        if distance is not None:  # chance of dying!!
            p = 0.5 * np.e ** (-0.3 * distance)
            if np.random.binomial(1, p) == 1:
                self.alive = False


# ====================================================================================


class Earth:

    def __init__(self, people, gridSize, bc, nSteps):

        # if nSteps = None, goes on until 1 person left
        """"""
        Grid class takes people inputs, along with size, boundary conditions, and number of maximum steps, and runs
        on a random walk until one person is left or until nSteps is reached, depending on user input.
        """"""
        self.people = people
        self.xmax = gridSize[0]
        self.ymax = gridSize[1]
        self.bc = bc
        self.point = []
        self.nSteps = nSteps
        self.nAlive = [len(self.people)]  # keep track of number of people alive after each step
        self.stepData = [0]  # list of each step
        # array to keep track of points that have are taken
        self.taken = np.zeros([self.xmax + 1, self.ymax + 1], dtype=bool)

        fig, (self.ax1, self.ax2) = plt.subplots(1, 2)  # create new figure window and ax (plot) attributes to Earth obj
        self.ax1.set_xlim(0, self.xmax)
        self.ax1.set_ylim(0, self.ymax)

        self.ax2.set_xlim(0, nSteps)
        self.ax2.set_ylim(0, len(people) + 10)
        self.line, = self.ax2.plot(self.stepData, self.nAlive, 'b-')
        self.ax2.plot(self.stepData, self.nAlive, '--')
        self.ax2.set_xlabel('Number of steps')
        self.ax2.set_ylabel('Number of people alive')

        self.ax2.set_autoscalex_on(True)
        # self.ax2.autoscale_view(True, True, False)

        for p in self.people:
            pnt, = self.ax1.plot([p.xpos], [p.ypos], 'bo')
            self.taken[p.xpos, p.ypos] = True
            self.point.append(pnt)

    def go(self):
        step = 1
        while not all([p.trapped for p in self.people]) and (self.nSteps is None or step &lt; self.nSteps):
            currAlive = 0  # number of alive each round
            for i, p in enumerate(self.people):
                if not p.trapped and p.alive:
                    p.move(self.xmax, self.ymax, self.bc, self.taken)
                    # update grid
                    self.point[i].set_data(p.xpos, p.ypos)
                    self.point[i].set_marker('o')
                    self.taken[p.xpos, p.ypos] = True
                    """"""
                    When using periodic boundary conditions, a position on a
                    wall is identical to the corresponding position on the
                    opposite wall. So if a walker visits (x, ymax) then
                    (x, 0) must also be marked as visited; if a walker vists
                    (0, y) then (xmax, y) must also be marked as visited; etc.
                    """"""
                    if self.bc == 'periodic':
                        if p.xpos == self.xmax:
                            self.taken[0, p.ypos] = True
                        elif p.xpos == 0:
                            self.taken[self.xmax, p.ypos] = True
                        if p.ypos == self.ymax:
                            self.taken[p.xpos, 0] = True
                        elif p.ypos == 0:
                            self.taken[p.xpos, self.ymax] = True

                    # plot path lines
                    if p.direction == 'north':
                        self.ax1.vlines(p.xpos, p.ypos - 1, p.ypos)
                    elif p.direction == 'east':
                        self.ax1.hlines(p.ypos, p.xpos - 1, p.xpos)
                    elif p.direction == 'south':
                        self.ax1.vlines(p.xpos, p.ypos + 1, p.ypos)
                    elif p.direction == 'west':
                        self.ax1.hlines(p.ypos, p.xpos + 1, p.xpos)

                    # determine proximity to others and potentially die
                    neighbor = p.proximity(self.xmax, self.ymax, self.bc, self.people)
                    p.gambleYourLife(neighbor)
                    if not p.alive:
                        self.point[i].set_color('r')
                    else:  # still alive
                        currAlive += 1

            # update plot
            self.nAlive.append(currAlive)
            self.stepData.append(step)
            # self.line.set_data = (self.stepData, self.nAlive)
            self.ax2.plot(self.stepData, self.nAlive, 'b-')


            step += 1
            plt.pause(0.2)


# ====================================================================================


def program(nPeople=10, gridSize=(20, 20), bc='wall', nSteps=100):
    initPositions = set()  # set of tuple of initial position of each person
    flock = []  # initialize - list of all people
    for p in range(nPeople):
        while True:
            x = random.randint(0, gridSize[0])  # randomly place person on graph, only one person per point
            y = random.randint(0, gridSize[1])
            if (x, y) not in initPositions:
                break
        initPositions.add((x, y))
        tempPerson = Person(position=(x, y))
        flock.append(tempPerson)  # add person to list of people
    flock = tuple(flock)  # turn list into tuple (not sure why... not sure if necessary)

    pandemic = Earth(flock, gridSize, bc, nSteps)
    pandemic.go()


# main program =======================================================================

program()
</code></pre>
"
60320674,"<p>I created a small excel file listing the confirmed cases, deaths, and recovered cases of the Coronavirus here in the U.S, but I can't seem to get the choropleth map working. </p>

<p>Here's my code:</p>

<pre><code>import pandas as pd
import chart_studio.plotly as py
import plotly.graph_objs as go

from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot
</code></pre>

<pre><code>init_notebook_mode(connected=True)

col_Names=[""State"", ""Country"", ""Time Discovered"", ""Confirmed"",  ""Deaths"",""Recovered""]

df = pd.read_csv(""coronavirusUS.csv"", names=col_Names)
data = dict(type='choropleth',
           colorscale= 'magma',
           locations = df['State'],
           locationmode= 'USA-states', 
           z = df['Confirmed'],
           text = df['Confirmed'],
            marker = dict(line=dict(color='rgb(255, 255, 255)', width=2)),
           colorbar = {'title':'Coronavirus in the U.S'})


layout = dict(title = 'Coronavirus in the US',
             geo= dict(scope = 'usa',
                      showlakes = True,
                      lakecolor = 'rgb(85, 173, 240)'))


choromap = go.Figure(data = [data], layout = layout)
iplot(choromap)

</code></pre>

<p>And then my map comes out looking like this:
<a href=""https://i.stack.imgur.com/1hZYD.png"" rel=""nofollow noreferrer"">empty map</a>
As you can see, the colorbar is accurate, but the map itself is blank. Except for the lakes. </p>

<p>Here's the .csv file I'm referring to.
<a href=""https://i.stack.imgur.com/ypoow.png"" rel=""nofollow noreferrer"">data table </a></p>

<p>I'm using jupyter notebook.</p>

<p>I've tried switching from a .xls to .csv, but that didn't work. </p>

<p>Thanks in advance.</p>
"
60746435,"<p>My goal is to create a function that will take in a hashtag, generate all tweets from that and append those tweets to a dictionary. Preferably with automatically generated ID numbers (like from the for loop?) and the value being the tweet content. </p>

<p>Its outputting an empty dictionary so i'm not sure where i'm going wrong.  </p>

<pre><code>from selenium import webdriver
import time

tweet_dict = {}
def find_hashtags(hashtags):
    browser = webdriver.Chrome('/Users/Vaish/Downloads/chromedriver')
    browser.get('https://twitter.com/hashtag/' + hashtags + '?src=hash')
    browser.execute_script('window.scrollTo(0, 100000)')
    time.sleep(1.5)
    tweets = browser.find_elements_by_class_name('content')
    for tweeter in range(len(tweets)):
        print(tweets[tweeter].text)
        tweet_dict['tweeter_%s' % tweeter] = tweets[tweeter].text

find_hashtags('coronavirus')

OUTPUT : {}
</code></pre>
"
61232348,"<p>I am only getting 308 rows on my CSV file. Where I should get more than 900 rows. I have written this below code. I am tried to change the iteration in links. But still the same. getting the amount of data every time. Is it problem with my data frame declaration or anything else? </p>

<pre><code>from bs4 import BeautifulSoup
import requests
import pandas as ps

#list of dataframe

suppliers_name = []
suppliers_location = []
suppliers_type = []
suppliers_content = []
suppliers_est =[]
suppliers_income = []

def parse(url):
    web = requests.get(url)
    soup = BeautifulSoup(web.content, ""html.parser"")

    container = soup.find_all(class_ = ""supplier-search-results__card profile-card profile-card profile-card--secondary supplier-tier-1"")

    for cont in container:
        # getting the names

        name = cont.find(""h2"").text
        suppliers_name.append(name)

        #getting the locations

        location =cont.find(class_ = ""profile-card__supplier-data"").find(""a"").text[8:]
        if ""  "" in location:
            suppliers_location.append(location.replace(""  "",""""))
        elif ""Locations"" in location:
            suppliers_location.append(location.replace(""Locations"", ""None""))

        #suppliers type

        types = cont.find(class_ = ""profile-card__supplier-data"").find_all(""span"")[1].text[2:]
        suppliers_type.append(types.replace(""*"", """"))

        # suppliers content

        content = cont.find(class_ = ""profile-card__body-text"").find(""p"").text
        suppliers_content.append(content)

        # suppliers establishment

        years = cont.find(class_ = ""profile-card__supplier-data"").find_all(""span"", {""data-toggle"":""popover""})
        if len(years) == 4:
            year = cont.find(class_ = ""profile-card__supplier-data"").find_all(""span"", {""data-toggle"":""popover""})[2].text
            suppliers_est.append(year[5:])

        elif len(years) == 3:
            year = cont.find(class_ = ""profile-card__supplier-data"").find_all(""span"", {""data-toggle"":""popover""})[1].text
            word =year[5:]
            if len(word) != 4:
                suppliers_est.append(""None"")
            else:
                suppliers_est.append(word) 

        elif len(years) == 2:
            year = cont.find(class_ = ""profile-card__supplier-data"").find_all(""span"", {""data-toggle"":""popover""})[1].text
            suppliers_est.append(year[5:])

        elif len(years)==1:
            suppliers_est.append(""None"")

        # suppliers income

        incomes =  cont.find(class_ = ""profile-card__supplier-data"").find_all(""span"", {""data-toggle"":""popover""})
        if len(incomes) == 4:
            income = cont.find(class_ = ""profile-card__supplier-data"").find_all(""span"", {""data-toggle"":""popover""})[1].text
            suppliers_income.append(income[4:])

        elif len(incomes) == 3:
            income = cont.find(class_ = ""profile-card__supplier-data"").find_all(""span"", {""data-toggle"":""popover""})[1].text
            word = income[4:]
            if len(word) != 5:
                suppliers_income.append(word)
            else:
                suppliers_income.append(""None"")
        elif len(incomes) == 2:
            suppliers_income.append(""None"")

        elif len(incomes) == 1:
            suppliers_income.append(""None"")

#itterate over links
number = 1
num =1
for i in range(43):
    urls = f'https://www.thomasnet.com/nsearch.html?_ga=2.53813992.1582589371.1586649402-45317423.1586649402&amp;cov=NA&amp;heading=97010359&amp;pg={num}'
    parse(urls)
    num += 1
    print(""\n"" f'{number} - done')
    number += 1

#dataframe

covid = ps.DataFrame({
    ""Name of the Suppliers"": suppliers_name,
    ""Location"": suppliers_location,
    ""Type of the suppliers"": suppliers_type,
    ""Establishment of the supplies"": suppliers_est,
    ""Motive"": suppliers_content
})

covid.to_csv(""E:/New folder/covid.csv"", index=False)
print(""File Creation Done"")
</code></pre>

<p>code works without any error but I am not getting all data.</p>
"
61013746,"<p>When requesting a website using class='even', I end up just receiving '[]' as my result.</p>

<pre><code>import requests
import urllib.request
import time
from bs4 import BeautifulSoup

url = 'https://www.worldometers.info/coronavirus/'
response = requests.get(url)

soup = BeautifulSoup(response.text, 'html.parser')
print(soup.findAll('tr', class_='even'))
</code></pre>

<p>This is my result</p>

<pre><code>[]
</code></pre>

<p>I tried looking in a lot of places but I couldn't find out why. The HTML code is really long as there is a lot of data.</p>
"
61226300,"<p>Hi Guys is there a way to properly space a statement/ strings in a particular position. i was able to successfully scrape some text for constant monitoring of daily Covid-19 results, but the output isnt well spaced as i want. example of my output below </p>

<blockquote>
  <p>2,016,549Total confirmed cases18,112Today
  127,635Total deaths1,056Today
  492,338Confirmed recoveries24,373Today
  1,396,576Active confirmed cases51,522 (4%)Critical
  21%Mortality / closed cases6%Mortality / confirmed cases
  16,096,027Total tests337,502Today.</p>
</blockquote>

<p>i would rather the out put be atleast more readable like this </p>

<blockquote>
  <p>2,015,031 Total confirmed cases 16,594 Today
  127,541 Total deaths 962 Today
  490,534 Confirmed recoveries 22,569 Today
  1,396,956 Active confirmed cases 51,570 (4%)Critical
  21% Mortality / closed cases 6% Mortality / confirmed cases
  16,061,619 Total tests 303,094 Today</p>
</blockquote>

<p>i have tried everything i can read up using join(), split() and i still didn't get the needed result.i had to manually space the better result in a text file. if i have to always manually space it, then the whole purpose is lost</p>
"
61084723,"<p>I've been trying to make graphs about covid-19, by starting couting from the first day in which there is more or equal to 100 cases on the country, but my axis doesn't seem to fit the way that i want, and none of the solutions i looked up seemed to work properly. here is the graph and the way i wanted it to be.</p>

<p>The blue drawings is how i want it to be.</p>

<p><img src=""https://i.stack.imgur.com/R4cpn.jpg"" alt=""Graph""></p>

<pre><code># IMPORTING MODULES

import pandas as pd
from datetime import datetime
import matplotlib.pyplot as plt

# READING CSV FILE
df = pd.read_csv('time_series_covid19_confirmed_global.csv')

# GROUPING DATA BY COUNTRY
df = df.groupby('Country/Region').sum()

# DROPPING LATITUDE AND LONGITUDE
df = df.drop(['Lat', 'Long'], axis=1).reset_index()

#SETTING Y AXIS
selected_countries = ['Argentina',
                      'Brazil',
                      'Chile',
                      'Ecuador',
                      'Peru',
                      'Colombia',
                      'Venezuela',
                      'Ecuador',
                      'Uruguay'
]
y_axis_parse1 = df.loc[df['Country/Region'] == 'Brazil'].values[0]
y_axis = [x for x in y_axis_parse1[1:] if x &gt;= 100]  # Setting starting point to 100 cases

#SETTING X AXIS
x_axis = range(len(y_axis))  # x axis based on lenght of y list data

#PLOTTING
plt.plot(x_axis, y_axis, '.-', color='red')
plt.xticks(x_axis)
plt.grid()

# STYLE OF THE GRAPH
plt.style.use('ggplot')

#PLOT SHOW
plt.show()
</code></pre>
"
61696135,"<pre><code>import requests
from requests import get
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np

url = ""https://www.covid19india.org/""
headers = {""Accept-Language"":""en-US, en;q=0.5""}
results = requests.get(url,headers = headers)
soup = BeautifulSoup(results.text,""html.parser"")
cases_div = soup.find_all('div', class_=""Level1"")
print(cases_div)
</code></pre>

<p>My expect output:
[the html]</p>

<p>However, I am getting an empty list
[] while printing cases_div.</p>

<p>Why is that and how can I fix it?</p>
"
60804023,"<p>I'm trying to sort a dataframe by a column. I'm writing a function to return the top <code>n</code> amount of results from the <code>totals</code> column.</p>

<p>Here is my function:</p>

<pre><code>def get_most(self, column, amt):
        most = OrderedDict()
        self.data = self.data.sort_values(by=[column])
        for i in range(amt):
            most.update({i : self.data.loc[i, :]})
        return most
</code></pre>

<p>When I call the function like so:</p>

<pre><code>most_amt = self.get_most('Total', 3)
    for key, value in most_amt.items():
        print(key, value)
</code></pre>

<p>It returns the first 3 rows in the dataframe before the sort. I've also tried using the <code>inplace</code> attribute, like so:</p>

<pre><code>self.data.sort_values(by=[column], inplace=True)
</code></pre>

<p>But to no avail.</p>

<p>The app itself is a little tracker I was making for myself to track the spread of the coronavirus. I'm using data from a github repo, and the input is a 312 row csv file. The first three rows are (I added the spaces on this question to make it easier to read, there are no spaces in the actual file):</p>

<pre><code>Hubei,China,2020-03-21T10:13:08,67800,3139,58946
NaN,  Italy,2020-03-21T17:43:03,53578,4825, 6072
NaN,  Spain,2020-03-21T13:13:30,25374,1375, 2125
etc. etc
NaN,  China, 2020-03-23,        81305,3259,71857
NaN,  US,    2020-03-23,        25493, 307,  171
</code></pre>

<p>My expected output would then be:</p>

<pre><code>NaN,  China, 2020-03-23,        81305,3259,71857
NaN,  Italy,2020-03-21T17:43:03,53578,4825, 6072
NaN,  US,    2020-03-23,        25493, 307,  171
</code></pre>

<p>Instead, it is just the first three rows of the CSV.</p>

<p>Any help would be appreciated.</p>

<p>Thanks!</p>
"
61474725,"<p>I am trying to get reponse from the below url. I have tried to get the data using below code, but unfortunately it is returning empty string.</p>

<pre><code>url = 'https://covid19index.in/wp-admin/admin-ajax.php?action=get_wdtable&amp;table_id=21'
params = {
    'action': 'get_wdtable',
    'table_id': 21
    }

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36',
    'Accept': 'application/json, text/javascript, */*; q=0.01',
    'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
    'X-Requested-With': 'XMLHttpRequest',
    'Connection': 'keep-alive',
    'Host': 'covid19index.in',
    'Cookie': '_ga=GA1.2.312051040.1587970650; _gid=GA1.2.1069938183.1587970650; _gat=1',
    'Sec-Fetch-Dest': 'empty',
    'Sec-Fetch-Mode': 'cors',
    'Referer': 'https://covid19index.in/district-wise-cases/',
    'Origin': 'https://covid19index.in'
}

s = requests.Session()
s.mount('http://', HTTPAdapter(max_retries=3))
time.sleep(2)

try:
    content = s.post(url,data= params, headers=headers)
except requests.exceptions.TooManyRedirects:
    try:
        for _ in range(10):
            content= s.post(url,data= params, headers= headers)          
    except:
        print('Failed: ', 'Too many Requets and redirect')
        sys.exit()
</code></pre>

<p>when i print content.text it returns '' (an empty string)</p>

<p>I have tried all the possible things to get the output.but iwas unable to get the output.If any help on this would be much appreciated.</p>
"
61454175,"<p>I am trying to get reponse from the below url. I have tried to get the data using below code, but unfortunately it is returning empty string.</p>

<pre><code>url = 'https://covid19index.in/wp-admin/admin-ajax.php?action=get_wdtable&amp;table_id=21'
params = {
    'action': 'get_wdtable',
    'table_id': 21
    }

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36',
    'Accept': 'application/json, text/javascript, */*; q=0.01',
    'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
    'X-Requested-With': 'XMLHttpRequest',
    'Connection': 'keep-alive',
    'Host': 'covid19index.in',
    'Cookie': '_ga=GA1.2.312051040.1587970650; _gid=GA1.2.1069938183.1587970650; _gat=1',
    'Sec-Fetch-Dest': 'empty',
    'Sec-Fetch-Mode': 'cors',
    'Referer': 'https://covid19index.in/district-wise-cases/',
    'Origin': 'https://covid19index.in'
}

s = requests.Session()
s.mount('http://', HTTPAdapter(max_retries=3))
time.sleep(2)

try:
    content = s.post(url,data= params, headers=headers)
except requests.exceptions.TooManyRedirects:
    try:
        for _ in range(10):
            content= s.post(url,data= params, headers= headers)          
    except:
        print('Failed: ', 'Too many Requets and redirect')
        sys.exit()
</code></pre>

<p>when i print content.text it returns '' (an empty string)</p>

<p>Please refer bellow for any data</p>

<pre><code>General:
    Request URL: https://covid19index.in/wp-admin/admin-ajax.php?action=get_wdtable&amp;table_id=21
    Request Method: POST
    Status Code: 200 OK
    Remote Address: 103.129.97.25:443
    Referrer Policy: no-referrer-when-downgrade

Response Headers:
    Access-Control-Allow-Credentials: true
    Access-Control-Allow-Origin: https://covid19index.in
    Cache-Control: no-cache, must-revalidate, max-age=0
    Connection: Keep-Alive
    Content-Encoding: gzip
    Content-Length: 15991
    Content-Type: text/html; charset=UTF-8
    Date: Mon, 27 Apr 2020 07:34:49 GMT
    Expires: Wed, 11 Jan 1984 05:00:00 GMT
    Keep-Alive: timeout=5, max=99
    Referrer-Policy: strict-origin-when-cross-origin
    Server: Apache
    Vary: Accept-Encoding,User-Agent
    X-Content-Type-Options: nosniff
    X-Frame-Options: SAMEORIGIN
    X-Robots-Tag: noindex


Requests headers:
    Accept: application/json, text/javascript, */*; q=0.01
    Accept-Encoding: gzip, deflate, br
    Accept-Language: en-US,en;q=0.9
    Connection: keep-alive
    Content-Length: 946
    Content-Type: application/x-www-form-urlencoded; charset=UTF-8
    Cookie: _ga=GA1.2.312051040.1587970650; _gid=GA1.2.1069938183.1587970650; _gat=1
    Host: covid19index.in
    Origin: https://covid19index.in
    Referer: https://covid19index.in/district-wise-cases/
    Sec-Fetch-Dest: empty
    Sec-Fetch-Mode: cors
    Sec-Fetch-Site: same-origin
    User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36
    X-Requested-With: XMLHttpRequest
    action: get_wdtable
    table_id: 21
    draw: 1
    columns[0][data]: 0
    columns[0][name]: state
    columns[0][searchable]: true
    columns[0][orderable]: false
    columns[0][search][value]: 
    columns[0][search][regex]: false
    columns[1][data]: 1
    columns[1][name]: district
    columns[1][searchable]: true
    columns[1][orderable]: false
    columns[1][search][value]: 
    columns[1][search][regex]: false
    columns[2][data]: 2
    columns[2][name]: date
    columns[2][searchable]: true
    columns[2][orderable]: false
    columns[2][search][value]: 
    columns[2][search][regex]: false
    columns[3][data]: 3
    columns[3][name]: date_total
    columns[3][searchable]: true
    columns[3][orderable]: false
    columns[3][search][value]: 
    columns[3][search][regex]: false
    start: 0
    length: -1
    search[value]: 
    search[regex]: false
    wdtNonce: cedfcdbcfd
</code></pre>

<p>I have tried all the possible things to get the output.but iwas unable to get the output.If any help on this would be much appreciated.</p>
"
61068655,"<p>Trying to scrape COVID cases from here:
<a href=""https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/cases-in-us.html"" rel=""nofollow noreferrer"">https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/cases-in-us.html</a></p>

<p>If you click on the ""+"" next to ""States"" below the map, you'll see the count of cases for each state. I want a dataframe that looks like this from each state</p>

<pre><code>Alabama         1841
Alaska          185
American Samoa  0
</code></pre>

<p>With my attempt, containers is empty</p>

<pre><code>my_url = 'https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/cases-in-us.html'
uClient = uReq(my_url)
page_html = uClient.read()
uClient.close()
page_soup = soup(page_html, ""html.parser"")
containers = page_soup.findAll(""div"", {""class"" : ""rt-td""})
</code></pre>

<p>I understand I'll need to loop through to get the info for each state but I need help getting the basic code to work. This is my first attempt at webscraping; I'm pretty sure I'm using the wrong tags or findAll arguments. I've tried a couple of different combination and none work. </p>

<p>I found a lady who did something similar to what I want here:
<a href=""https://towardsdatascience.com/scrape-cdc-for-covid-19-cases-a162924073ad"" rel=""nofollow noreferrer"">https://towardsdatascience.com/scrape-cdc-for-covid-19-cases-a162924073ad</a></p>

<p>But she's a developer I think and her skills are above mine. There has to be a much simpler way to do this. Right?</p>

<p>Thanks in advance.</p>
"
61235948,"<p>I have a simple regex that will not do what I want. I went here and tested the regex and it works:</p>

<p><a href=""https://regex101.com"" rel=""nofollow noreferrer"">https://regex101.com</a></p>

<p>it's just not working in Python. Why? Thanks in advance.</p>

<p>string = </p>

<pre><code>covid sucks and I want to go outside &lt;!--/* Font Definitions */@font-face{font-family:Wingdings;panose-1:5 0 0 0 0 0 0 0 0 0;}@font- 
face{font-family:""""Cambria Math"""";panose-1:2 4 5 3 5 4 6 3 2 4;}@font-face{font-family:Calibri;panose- 
1:2 15 5 2 2 2 4 3 2 4;}@font-face{font-family:""""Bradley Hand ITC"""";panose-1:3 7 4 2 5 3 2 3 2 3;}/* 
Style Definitions */p.MsoNormal, li.MsoNormal, div.MsoNormal{margin:0in;margin-bottom:.0001pt;font- 
size:11.0pt;font-family:""""Calibri"""",sans-serif;}p.MsoListParagraph, li.MsoListParagraph, 
div.MsoListParagraph{m{margin-bottom:0in;}--&gt; pop goes the peanut.
</code></pre>

<p>desired output = 'covid sucks and I want to go outside pop goes the peanut.'</p>

<p>I want everything between the <code>&lt; &gt;</code> to go away including the <code>&lt; &gt;</code>. Also, string is part of a much larger string. Sometimes the <code>&lt;...&gt;</code> is buried in the middle of a larger string. I need to be able to find it wherever it may be in the larger string and delete it.</p>

<p>My attempts:</p>

<pre><code>string.replace(""&lt;.*(?=&gt;)"", "" "")
</code></pre>

<p>and</p>

<pre><code>string.replace(""&lt;.*&gt;"", "" "")
</code></pre>
"
60836962,"<p>I am writing a Python script to fetch coronavirus data from <a href=""https://www.worldometers.info/coronavirus/&#39;"" rel=""nofollow noreferrer"">Wordlometers</a> using selenium's webdriver. My script consists of this: </p>

<pre><code>class Coronavirus():
    def __init__(self):
        options = webdriver.ChromeOptions()
        options.binary_location = ""/Applications/Google Chrome.app/Contents/MacOS/Google Chrome""
        chrome_driver_binary = ""/usr/local/bin/chromedriver""
        self.driver = webdriver.Chrome(chrome_driver_binary, chrome_options=options)

    def get_data(self):
        try:
            self.driver.get('https://www.worldometers.info/coronavirus/')
            table = self.driver.find_element_by_xpath('//*[@id=""main_table_countries""]/tbody[1]')
            country_element = table.find_element_by_xpath(""//td[contains(text(), 'Italy')]"")
            row = country_element.find_element_by_xpath(""./.."")
</code></pre>

<p>but what happens is that Chrome opens and closes immediately. I tried debugging this script adding some prints here and there, and it turns out that the line <code>self.driver.find_element_by_xpath</code> doesn't let me print anything else after. I tried reading the documentation but I can't get it to print anything, what can I do to solve this?<br>
Thanks a lot!</p>
"
61197705,"<p>I'm trying to sample tweets with <code>tweepy</code>. I wanted to get, for example, 100 tweets between today Apr 14th and Apr 8. 
But when I try:</p>

<pre><code>search_words = ""#COVID""
date_until = ""2020-04-09""

tweets = twepy.Cursor(api.search,
              q=search_words,
              lang=""en"",
              until = date_until, count = 100,
                     since = date_since).items(100)
</code></pre>

<p>I get the following result with tweets from same day:</p>

<pre><code>2020-04-08 23:58:23    3
2020-04-08 23:59:46    3
2020-04-08 23:58:02    3
2020-04-08 23:59:53    3
2020-04-08 23:58:37    3
2020-04-08 23:58:41    3
2020-04-08 23:59:06    2
2020-04-08 23:59:24    2
2020-04-08 23:59:10    2
2020-04-08 23:59:07    2
2020-04-08 23:58:56    2
2020-04-08 23:59:51    2
2020-04-08 23:58:44    2
2020-04-08 23:58:16    2
2020-04-08 23:59:32    2
2020-04-08 23:57:49    2
2020-04-08 23:57:53    2
2020-04-08 23:58:06    2
2020-04-08 23:59:09    2
2020-04-08 23:59:28    2
2020-04-08 23:58:55    2
2020-04-08 23:59:23    2
2020-04-08 23:59:29    2
2020-04-08 23:57:47    2
2020-04-08 23:59:20    2
2020-04-08 23:59:31    2
2020-04-08 23:57:51    2
2020-04-08 23:58:46    2
2020-04-08 23:58:14    1
2020-04-08 23:59:22    1
2020-04-08 23:58:03    1
2020-04-08 23:58:45    1
2020-04-08 23:59:21    1
2020-04-08 23:59:01    1
2020-04-08 23:58:29    1
2020-04-08 23:59:50    1
2020-04-08 23:59:27    1
</code></pre>

<p>Tweets with the same date only differing in some minutes...</p>
"
61478650,"<p>I want to sort my dataframe in decending order with ""Total Confirmed cases"" </p>

<p>My Code </p>

<pre><code>high_cases_sorted_df = df.sort_values(by='Total Confirmed cases',ascending=False)
print(high_cases_sorted_df)
</code></pre>

<p>Output</p>

<pre><code>                          state       Total Confirmed cases
19                  Maharashtra                  8590
14                    Jharkhand                    82
24                   Puducherry                     8
9                           Goa                     7
32                  West Bengal                   697
13            Jammu and Kashmir                   546
15                    Karnataka                   512
30                  Uttarakhand                    51
16                       Kerala                   481
6                    Chandigarh                    40
12             Himachal Pradesh                    40
7                  Chhattisgarh                    37
4                         Assam                    36
10                      Gujarat                  3548
5                         Bihar                   345
1   Andaman and Nicobar Islands                    33
25                       Punjab                   313
8                         Delhi                  3108
11                      Haryana                   296
26                    Rajasthan                  2262
18               Madhya Pradesh                  2168
17                       Ladakh                    20
20                      Manipur                     2
29                      Tripura                     2
31                Uttar Pradesh                  1955

</code></pre>

<p>I don't know why it shows like this it should be 
(1.Maharashtra, 2.Gujarat, 3.Delhi, etc) </p>

<p>complete script <a href=""https://github.com/meezanmalek/coronavirus_data/blob/sampe/corona_virus.py"" rel=""nofollow noreferrer"" title=""Github repo"">Here</a></p>
"
61072635,"<pre><code>fig = px.choropleth(c_lat_grp, locations=""Country"", locationmode='country names',
                color=""Cases"", hover_name=""Country"", 
                color_continuous_scale=""Emrld"", title='COVID-19')

fig.update_layout(margin={""r"":0,""t"":0,""l"":0,""b"":0})
fig.show()
</code></pre>

<p>Here is my python3 code which displays a world map, displays details of maps when you hover around it using the chloropleth library. It is running perfectly fine in my Jupyter notebook but when I am uploading it to Github it is not showing me any map. How can I resolve this issue?</p>
"
61417750,"<p>I'm trying to gather some data from a table on a web page with Python and Beautiful Soup. When I make a selection from the page, however, I'm getting different results than I get in the browser. Specifically, the tables are missing completely. Here's a screenshot of the table in the inspector of Firefox dev tools:</p>

<p><a href=""https://i.stack.imgur.com/0N1IS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0N1IS.png"" alt=""Screenshot of web page and inspector""></a></p>

<p>And here's the output that I get from Beautiful Soup:</p>

<p><a href=""https://i.stack.imgur.com/6Hi59.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6Hi59.png"" alt=""Screenshot of IDE with output""></a></p>

<p>I've tried using urllib instead of requests, and I've tried using different HTML parsers, (html.parser and lxml). All give the same results. Any advice on what might be happening here and how I might get around it to access the data from the table?</p>

<pre><code>import requests
from bs4 import BeautifulSoup
import pandas
import tabula
import html5lib

knox = requests.get(""https://covid.knoxcountytn.gov/case-count.html"")
knox_soup = BeautifulSoup(knox.text, 'html5lib')
knox_confirmed = knox_soup.find('div', id='covid_cases').prettify()

print(knox_confirmed)
</code></pre>
"
60926824,"<p>I tried scraping the table rows from the website <a href=""https://google.com/covid19-map/?hl=en"" rel=""nofollow noreferrer"">https://google.com/covid19-map/?hl=en</a> to get the data on corona virus spread. But it only returns a few rows, in my case 15. I am unable to scrape all rows. The table isn't fully visible on the website, one needs to scroll to see the contents of the table. Please help.</p>

<pre class=""lang-py prettyprint-override""><code>import requests 
from bs4 import BeautifulSoup 


URL = ""https://google.com/covid19-map/?hl=en""
r = requests.get(URL) 

soup = BeautifulSoup(r.content, 'html5lib') 

all_rows = soup.findAll('tr', attrs = {'class':'A5V3jc'})

for i in range(len(all_rows)):

    # Getting image link
    img_link = all_rows[i].find('img')
    if img_link != None:
        print(img_link['src'])

    # Getting name field
    name = all_rows[i].find('span')
    if(name != None):
        print(name.text, end =""\t"")

    # getting remaining data
    remaining_entries = all_rows[i].findAll('td', attrs = {'class':'uMsnNd HAChlc'})

    for j in remaining_entries:
        if(j != None):
            print(j.text, end=""\t\t\t"")
    print(""\n\n"")

</code></pre>
"
60981132,"<p>I am having trouble returning all desired data from a portion of a web page using BeautifulSoup. When I run the below python, the for-loop only brings back the first record it finds, not the entire data set from the web page:</p>

<pre><code>import requests  
from bs4 import BeautifulSoup  
r = requests.get('https://www.ncsl.org/research/health/state-action-on-coronavirus-covid-19.aspx')
soup = BeautifulSoup(r.text, 'html.parser')  
results = soup.find_all('tbody')
records = []  
for result in results:  
    state_name = result.find('td').text
    law_Name = result.find('a').text
    law_link = result.find('a').get('href')
    law_status = result.find('b').text
    law_descr = result.find('tr').text[16:-2]
    records.append((state_name, law_Name,law_link,law_status,law_descr))
</code></pre>

<p>Only one element populates in the records list, even though I am using a for loop to go through all of results object (which is a bs4.element.ResultSet):</p>

<pre><code>[('Alabama',
  'SJR 40',
  'http://alisondb.legislature.state.al.us/ALISON/SearchableInstruments/2020RS/PrintFiles/SJR40-enr.pdf',
  'Eligible for Governor.',
  ' Urges individuals to fist bump rather than shake hands. Eligible for Governor')]
</code></pre>

<p>Any assistance to fix my code would be greatly appreciated. Thank you!</p>
"
61239933,"<p>I'm working with covid-19 prediction model on sklearn. I tried to do it in Tensorflow, but it wans't working correctly. I was wondering is there's any equivalent to this specific sklearn model in Tensorflow 2.x. If there is not an equivalent, then that's the answer.</p>

<hr>

<p><strong>Code:</strong></p>

<pre class=""lang-py prettyprint-override""><code>from sklearn.model_selection import RandomizedSearchCV, train_test_split
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, mean_absolute_error
import operator

kernel = ['poly', 'sigmoid', 'rbf']
c = [0.01, 0.1, 1, 10]
gamma = [0.01, 0.1, 1]
epsilon = [0.01, 0.1, 1]
shrinking = [True, False]
svm_grid = {'kernel':kernel, 'C':c, 'gamma':gamma,'epsilon':epsilon,'shrinking':shrinking}

svm = SVR()
svm_search = RandomizedSearchCV(svm, svm_grid, scoring = 'neg_mean_squared_error', cv=3, return_train_score=True, n_jobs=-1, n_iter=100, verbose=1)

X_train_confirmed, X_test_confirmed, y_train_confirmed, y_test_confirmed = train_test_split(days, confirmed, test_size=0.15, shuffle=False)

svm_search.fit(X_train_confirmed, y_train_confirmed.ravel())
</code></pre>

<hr>

<p><strong>The rest of the code is in here:</strong> <a href=""https://github.com/GUNTERMAXIMUS/covid-19predictCL/blob/master/covod_19_2.ipynb"" rel=""nofollow noreferrer"">GITHUB COVID-19 CL</a></p>

<pre class=""lang-py prettyprint-override""><code>In [13]:
svm_search.best_params_

Out[13]:
{'C': 0.1, 'epsilon': 1, 'gamma': 0.1, 'kernel': 'poly', 'shrinking': False}

In [14]:
svm_confirmed = svm_search.best_estimator_
svm_prediction = svm_confirmed.predict(future_forecast_days)
</code></pre>

<p><em>Any suggestion to improve the question will be answered</em></p>
"
61564105,"<p>I am trying to extract the text between <code>&lt;p&gt;</code> tags in a new article. 
The article is broken into multiple paragraphs. </p>

<p>I want to loop through them and get all the text but strangely beautiful soup only returns the 3 first <code>&lt;p&gt;</code> tags until it reaches <code>&lt;style&gt;</code> tag. </p>

<p>Here is the structure of the webpage:
<a href=""https://i.stack.imgur.com/ArwwW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ArwwW.png"" alt=""enter image description here""></a></p>

<p>and here is my code : </p>

<pre><code>link = 'https://www.moneycontrol.com/news/india/pe-vc-investments-in-india-may-dip-up-to-60-in-2020-due-to-covid-19-ey-5172131.html'

news_page = requests.get(link)
soup = BeautifulSoup(news_page.content, 'html.parser')
head_line = soup.find('h1', {'class': 'artTitle'})
sub_head = soup.find('h2', {'class': 'subhead'})
news_content_section = soup.find('div', {'class': 'arti-flow'})
desired_tags = news_content_section.find_all('p')
for items in desired_tags:
   print(items.get_text())
</code></pre>

<p>Thanks in advance! </p>
"
61383562,"<p>I have collected data for Covid-19 per state in India. The first date is 2020-03-10, regardless of case_type. For each day, the API returns only the set of states which have cumulative cases > 0. Therefore I want to zero pad all states in the DataFrame per date and case_type where they have not had any cases yet.</p>

<pre><code>   Date       |            State           |   Case_Type  |    Cases
2020-03-10                 Delhi               Confirmed        4
2020-03-10    |            Delhi           |    Deaths    |     0 
   ...                     ...                   ...           ...    
2020-03-26      Andaman and Nicobar Islands     Confirmed       1
</code></pre>

<p>So in the example, Andaman and Nicobar Islands had its first confirmed case 2020-03-26, therefore I want to add one row for each Case_Type per date from 2020-03-10 -> 2020-03-25 where Cases = 0. I want to do this for each State and Case_Type.</p>

<pre><code>   Date       |            State           |   Case_Type  |    Cases
2020-03-10                 Delhi               Confirmed        4
2020-03-10    |            Delhi           |    Deaths    |     0 
   ...                     ...                   ...           ...    
2020-03-10      Andaman and Nicobar Islands     Confirmed       0
2020-03-10      Andaman and Nicobar Islands      Deaths         0
2020-03-11      Andaman and Nicobar Islands     Confirmed       0
   ....                    ....                  ....
2020-03-26      Andaman and Nicobar Islands     Confirmed       1
</code></pre>

<p>I tried the following solution, but it does not do what I want. </p>

<pre><code>df['Date'] = pd.to_datetime(df['Date'])

df = df.set_index('Date')\
    .groupby(['State','Case_Type'], sort=False)['Cases']\
    .resample('D').asfreq().fillna(0)\
    .reset_index()
df.sort_values(by=['State','Case_Type','Date'],ascending=True,inplace=True)
</code></pre>

<p>It did not pad the dates 2020-03-10 -> 2020-03-26 for Andaman and Nicobar Islands.</p>

<p>Anyone have any idea of how to do it correctly?</p>

<p>EDIT: Changed column names so that they align.</p>
"
61055301,"<p>I am trying to scrape table data from this Wikipedia page: <a href=""https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Nepal"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Nepal</a>
I've tried using pandas <strong>pd.read_html</strong> syntax but it doesn't work for the table I'm trying to scrape
(Confirmed COVID-19 cases in Nepal by district).</p>

<p>I tried using Beautifulsoup and pandas to scrape the data, but it doesn't work</p>

<pre><code>url = 'https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Nepal'
r = requests.get(url)
soup = BeautifulSoup(r.text,'html.parser')
table = soup.find('table', {'class': 'wikitable'})
dfs=pd.read_html(table)
dfs[0]
</code></pre>
"
61047041,"<p>I'm trying to read the number of confirmed cases of COVID-19 form the webpage of my state here in Brazil, but the page is really had to get the data from it. It is a PowerBI webpage, and the number of cases is on the second page of the presentation. I can read normally anything from the first page, but I can't seem to read anything from the second one (after I click the button to change to the next page, which is in the footnotes of the page). My code is this right now</p>

<pre><code>from selenium import webdriver
from time import sleep
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

class PowerBIBot:
    def __init__(self):
        self.driver = webdriver.Chrome()
        self.driver.get(""https://app.powerbi.com/view?r=eyJrIjoiMDgwOGI4YjItNGFjNC00ZThkLWIyNzctMmNjZTQxMmU1ZjRhIiwidCI6Ijg3ZTRkYTJiLTgyZGYtNDhmNi05MTU3LTY5YzNjYTYwMGRmMiIsImMiOjR9&amp;fbclid=IwAR1U64ZAVQ0IZ9RkiZnO7K7ysbvGtAGHCJWqIbIG8Z7SBfcM8hLSv7B2JSU"")
        sleep(8)
        test = self.driver.find_element_by_xpath(""/html/body/div[1]/ui-view/div/div[1]/div/div/div/div/exploration-container/exploration-container-legacy/div/div/exploration-host/div/div/exploration/div/explore-canvas-modern/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container-modern[3]/transform/div/div[3]/visual-modern/div/div"")
        # This works
        print(test)
        self.driver.find_element_by_xpath('/html/body/div[1]/ui-view/div/div[2]/logo-bar/div/div/div/logo-bar-navigation/span/a[3]/i') \
            .click()
        sleep(8)
        try:
            element = WebDriverWait(self.driver, 25).until(EC.presence_of_element_located((By.XPATH, ""/html/body/div[1]/ui-view/div/div[1]/div/div/div/div/exploration-container/exploration-container-legacy/div/div/exploration-host/div/div/exploration/div/explore-canvas-modern/div/div[2]/div/div[2]/div[2]/visual-container-repeat/visual-container-modern[3]/transform/div/div[3]/visual-modern/div/svg/g[1]/text"")))
            print(element)
        finally:
            pass

PowerBIBot()
</code></pre>

<p>In there you have URL of the website I'm trying to read automatically. I know the code is not so good but I'm just trying to get a sense of how selenium works and how I can read these PowerBI pages, which are really hard to read for some reason. I tried waiting for a long time for the page to load, but it never works. Any help would be much appreciated.</p>

<p>Thanks in advance.</p>

<p><strong>EDIT</strong>: This is the website for easier access: <a href=""https://app.powerbi.com/view?r=eyJrIjoiMDgwOGI4YjItNGFjNC00ZThkLWIyNzctMmNjZTQxMmU1ZjRhIiwidCI6Ijg3ZTRkYTJiLTgyZGYtNDhmNi05MTU3LTY5YzNjYTYwMGRmMiIsImMiOjR9&amp;fbclid=IwAR1U64ZAVQ0IZ9RkiZnO7K7ysbvGtAGHCJWqIbIG8Z7SBfcM8hLSv7B2JSU"" rel=""nofollow noreferrer"">https://app.powerbi.com/view?r=eyJrIjoiMDgwOGI4YjItNGFjNC00ZThkLWIyNzctMmNjZTQxMmU1ZjRhIiwidCI6Ijg3ZTRkYTJiLTgyZGYtNDhmNi05MTU3LTY5YzNjYTYwMGRmMiIsImMiOjR9&amp;fbclid=IwAR1U64ZAVQ0IZ9RkiZnO7K7ysbvGtAGHCJWqIbIG8Z7SBfcM8hLSv7B2JSU</a></p>
"
60649532,"<p>Hi guys I was trying to extract data from <a href=""https://newslab.malaysiakini.com/covid-19/en"" rel=""nofollow noreferrer"">https://newslab.malaysiakini.com/covid-19/en</a></p>

<pre><code>import requests
from bs4 import BeautifulSoup

page = requests.get(""https://newslab.malaysiakini.com/covid-19/en"")

soup = BeautifulSoup(page.content, 'html.parser')

option_tags = soup.find(id=""uk-grid uk-grid-small uk-width-auto uk-flex uk-flex-middle uk-flex-center"")

patient_items = option_tags.find_all(class_=""patient"")

first = patient_items[0]
print(first.prettigy())
</code></pre>

<p>I cant extract the result seems like my html.parser cannot get the data like I see in the google console. Anyone can help on this?</p>
"
61578723,"<p>I am trying to scrape <code>seekingalpha.com</code> news section as a personal project.
However, it seems I am not able to successfully emulate a browser as once I get to page 8 or so,I get the <code>403 forbidden output code</code>. If I open up my browser in private mode, I am able to browse all of the pages manually, so my IP isn't being blocked.</p>

<p>I am using <code>Requests</code> and <code>Beautifulsoup</code> in <code>Python3.8</code></p>

<p>I have:</p>

<ul>
<li><p>Added a legit User Agent as well as tried random user-agents</p></li>
<li><p>Using Request Session which should be automatically updating cookies, I believe (?)</p></li>
<li><p>Added a Referrer header</p></li>
<li>Increased time-delay between requests</li>
</ul>

<p>Here is my code:</p>

<pre><code>import requests
import time
import random
import webbrowser
from bs4 import BeautifulSoup
import re
import sys
import os



class SeekingAlpha():

    from fake_useragent import UserAgent
    ua = UserAgent()

    BASE_URL = 'https://seekingalpha.com/'
    NEWS_URL = BASE_URL + 'articles?page={}'


    def __init__(self):
             self.session = requests.Session()
             self.session.headers['User-Agent'] = 'Mozilla/5.0 (X11;  Ubuntu; Linux i686; rv:52.0) Gecko/20100101 Firefox/52.0'

             response =self.session.get(self.BASE_URL)
             response.raise_for_status() 
             self.session.headers['Referrer'] = 'https://seekingalpha.com/'
             print(self.session.headers)
             self.master_urls = []

             for i in range(1,100):        
                page = self.session.get(self.NEWS_URL.format(i))
                time.sleep(random.randint(3,5))
                page.raise_for_status()
                soup = BeautifulSoup(page.content, 'html.parser')
                links = soup.find_all('a', href = True)
                links = [link for link in links if link.has_attr(""sasource"") and link['sasource'] == 'all_articles']
                self.master_urls.extend(links) 


if __name__ == ""__main__"":

    master_urls = SeekingAlpha()
</code></pre>

<p>EDIT:</p>

<p>Here is what I see with page 8 via browser (removed headers as not to take up too much space within post):</p>

<p>""
LATEST ARTICLES</p>

<p>HIGHLIGHT:</p>

<pre><code>    All
    Top Ideas
    Editors' Picks
    Small-Cap Insight
    Outstanding Contribution
    Most Popular
</code></pre>

<p>ARTICLES |  NEWS |  TRANSCRIPTS</p>

<pre><code>Should I Open A Roth IRA Right Now? That Depends
Charles Lewis Sizemore, CFA • Thu, Apr. 30, 11:15 AM
China Continues To Lead World's Major Equity Regions In 2020
James Picerno • MCHI, SPY, VT• Thu, Apr. 30, 11:09 AM
Gold And Gas: 2 Anti-Recession Trades
Atlas Research • QQQ, UNG, SAND• Thu, Apr. 30, 11:05 AM
Excellent Total Return Bond Funds For Momentum-Based Fixed Income Portfolios
MyPlanIQ • TGMNX, BOND, DLTNX• Thu, Apr. 30, 11:04 AM
NXP's Share Price Already Assumes A Lot Of Growth And Improvement
Stephen Simpson, CFA • MCHP, RNECY, TXN• Thu, Apr. 30, 11:01 AM
[This article is one of the editors' picks] Chart Industries Worth Another Look With LNG Mostly Washed Out
Stephen Simpson, CFA • GTLS• Thu, Apr. 30, 10:53 AM
Dana Incorporated 2020 Q1 - Results - Earnings Call Presentation
SA Transcripts • DAN• Thu, Apr. 30, 10:43 AM
Don't Panic! Coronavirus, GDP, And Unemployment
CFA Institute Contributors • SPY, QQQ, DIA• Thu, Apr. 30, 10:42 AM
Predicting Depressions For Dummies, Part II
John Overstreet • SPY, QQQ, DIA• Thu, Apr. 30, 10:37 AM
Cognex Already Trading On Recovery Prospects
Stephen Simpson, CFA • FANUY, CGNX• Thu, Apr. 30, 10:29 AM
Meritor, Inc. 2020 Q2 - Results - Earnings Call Presentation
SA Transcripts • MTOR• Thu, Apr. 30, 10:28 AM
</code></pre>

<p>""</p>
"
61301323,"<p>I have the following code that should plot a graph. But, it's coming up blank.</p>

<pre><code>@app.callback(Output('third', 'figure'),
             [Input('country_drop', 'value')])

def summary_combined(country):

    df = infection_type.groupby(['country', 'date', 'type']).sum()
    df.reset_index(inplace = True)
    df = qq[qq['country'] == country]
    df['confirmed'] = df[df['type'] == 'confirmed']['cases'].cumsum()
    df['deaths'] = df[df['type'] == 'death']['cases'].cumsum()
    df['recovered'] = df[df['type'] == 'recovered']['cases'].cumsum()
    df = df.fillna(0)
    df['total'] = df['confirmed'] + df['deaths'] + df['recovered']
    cdf = df[df['type'] == 'confirmed']
    ddf = df[df['type'] == 'death']
    rdf = df[df['type'] == 'recovered']

    fig = go.Figure()

    fig.add_trace(go.Scatter(x = cdf['date'],
                            y = cdf['total'],
                            line=dict(color='royalblue', width=2),
                            name = 'Confirmed'))

    fig.add_trace(go.Scatter(x = ddf['date'],
                            y = ddf['total'],
                            line=dict(color='firebrick', width=2),
                            name = 'Deaths'))

    fig.add_trace(go.Scatter(x = rdf['date'],
                            y = rdf['total'],
                            line=dict(color='green', width=2),
                            name = 'Recovered'))
    #fig = {'data' : traces, 'layout': {'title':stock_ticker}}

    return fig
</code></pre>

<p>The html component code for the same is:</p>

<pre><code>app.layout = html.Div([

                        dcc.Dropdown(id = 'country_drop',
                                    options = country_dropdown,
                                    value = 'India'),
                        dcc.Graph(id = 'first'),


                        html.Div([
                                dcc.Graph(id = 'second')
                        ]),

                        html.Div([
                                dcc.Graph(id = 'third')
                        ])
])
</code></pre>

<p>This is the first time I am trying to plot a line graph using <code>add_trace</code> in Dash. I have plotted other graphs using</p>

<pre><code>return {'data' : traces, 'layout': go.Layout(title = 'Cases per day: {cc}'.format(cc = country) , xaxis = {'title' : 'Date'},
                              yaxis = {'title': '#'})}
</code></pre>

<p>or something similar. But that is not working for this code. Please guide me. Thank you!</p>

<p>Here's the full code for the app:</p>

<pre><code>country_dropdown = []
for c in df['country'].unique():
    country_dropdown.append({'label':str(c), 'value':str(c)})

app = dash.Dash()

app.layout = html.Div([

                        dcc.Dropdown(id = 'country_drop',
                                    options = country_dropdown,
                                    value = 'India'),
                        dcc.Graph(id = 'first'),


                        html.Div([
                                dcc.Graph(id = 'second')
                        ]),

                        html.Div([
                                dcc.Graph(id = 'third')
                        ])
])

#first graph: cases per day
@app.callback(Output('first', 'figure'),
             [Input('country_drop', 'value')])
def summary_cases(country):

    df = date_country[date_country['country'] == country].copy()    
    trace1 = [go.Bar(
                    x = df['date'],
                    y = df['cases'])]


    return {'data' : trace1, 'layout': go.Layout(title = 'Cases per day: {cc}'.format(cc = country) , xaxis = {'title' : 'Date'},
                              yaxis = {'title': '#'})}

#second graph: deaths per day
@app.callback(Output('second', 'figure'),
             [Input('country_drop', 'value')])
def summary_death(country):

    df = n_deaths[n_deaths['country'] == country].copy()    
    trace1 = [go.Bar(
                    x = df['date'],
                    y = df['cases'])]


    return {'data' : trace1, 'layout': go.Layout(title = 'Deaths per day: {c}'.format(c = country), xaxis = {'title' : 'Date'},
                              yaxis = {'title': '#'})}


@app.callback(Output('third', 'figure'),
             [Input('country_drop', 'value')])

def summary_combined(country):

    df = infection_type.groupby(['country', 'date', 'type']).sum()
    df.reset_index(inplace = True)
    df = qq[qq['country'] == country]
    df['confirmed'] = df[df['type'] == 'confirmed']['cases'].cumsum()
    df['deaths'] = df[df['type'] == 'death']['cases'].cumsum()
    df['recovered'] = df[df['type'] == 'recovered']['cases'].cumsum()
    df = df.fillna(0)
    df['total'] = df['confirmed'] + df['deaths'] + df['recovered']
    cdf = df[df['type'] == 'confirmed']
    ddf = df[df['type'] == 'death']
    rdf = df[df['type'] == 'recovered']

    fig = go.Figure()

    fig.add_trace(go.Scatter(x = cdf['date'],
                            y = cdf['total'],
                            line=dict(color='royalblue', width=2),
                            name = 'Confirmed'))

    fig.add_trace(go.Scatter(x = ddf['date'],
                            y = ddf['total'],
                            line=dict(color='firebrick', width=2),
                            name = 'Deaths'))

    fig.add_trace(go.Scatter(x = rdf['date'],
                            y = rdf['total'],
                            line=dict(color='green', width=2),
                            name = 'Recovered'))

    return fig


if __name__ == '__main__':
    app.run_server()
</code></pre>

<p>I have used the JHU based Coronavirus dataset available here:
<a href=""https://github.com/RamiKrispin/coronavirus-csv"" rel=""nofollow noreferrer"">https://github.com/RamiKrispin/coronavirus-csv</a></p>

<p>And my analysis and data manipulation for reference is here (No Dash code here):
<a href=""https://www.kaggle.com/sandeshpatkar/coronavirus-worldwide-cases-analysis"" rel=""nofollow noreferrer"">https://www.kaggle.com/sandeshpatkar/coronavirus-worldwide-cases-analysis</a></p>
"
60648140,"<p>I am working on a project to support COVID-2019 and I am attempting to leverage Beautifulsoup to pull daily statistics for reporting across the country. When I initially run my code I can see the HTML tables pull up but no columns are showing in my code. I think  I am getting hung up in the <code>column_headers # our column headers</code>' part but I am not quite sure.</p>

<pre><code>from urllib.request import Request, urlopen
from bs4 import BeautifulSoup
import pandas as pd
import csv

url = 'https://coronavirus.1point3acres.com/en'

req = Request(url , headers={'User-Agent': 'Mozilla/5.0'})
html = urlopen(req).read()
soup = BeautifulSoup(html)

type(soup)  # we see that soup is a BeautifulSoup object

div = soup.find(id=""ant-table-thead"")

table = soup.find('table')

table_rows = table.find_all('tr')

for tr in table_rows:
    td = tr.find_all('td')
    row = [i.text for i in td]
    print(row)

column_headers # our column headers

data_rows = table.findAll('td')[8:]

type(data_rows)  # now we have a list of table rows


virus_data = [[td.getText() for td in data_rows[i].findAll('td')]
            for i in range(len(data_rows))]

df = pd.DataFrame(virus_data, columns=column_headers)

df.head()  # head() lets us see the 1st 5 rows of our DataFrame by default

df.to_csv(r'C:/Junk/COVD/COVD1.csv', encoding='utf-8', index=False)
</code></pre>
"
61696454,"<p>I am trying to build a web scraper for creating covid-19 datasets for my data visualization project. I need this table from <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a></p>

<pre><code>import requests
from bs4 import BeautifulSoup

url = ""https://www.worldometers.info/coronavirus/""
page = requests.get(url,verify=True)

soup = BeautifulSoup(page.content,features=""lxml"")

rows = soup.select(""tr"")


for data in rows:
    print(data.text)
</code></pre>

<p>I am getting desired output but at each row(country) it also displays continent name which i dont want to include in my dataset. Is there any solution?
As i am new to webscraping, I need all the help i can get.</p>

<p>Update: This is html code, and the last td specifying ""europe"" is not needed in dataset.</p>

<pre><code>&lt;tr style="""" role=""row"" class=""odd""&gt;
&lt;td style=""font-weight: bold; font-size:15px; text-align:left;""&gt;&lt;a class=""mt_a"" href=""country/uk/""&gt;UK&lt;/a&gt;&lt;/td&gt;
&lt;td style=""font-weight: bold; text-align:right"" class=""sorting_1""&gt;211,364&lt;/td&gt;
&lt;td style=""font-weight: bold; text-align:right;""&gt;&lt;/td&gt;
&lt;td style=""font-weight: bold; text-align:right;""&gt;31,241 &lt;/td&gt;
&lt;td style=""font-weight: bold; text-align:right;""&gt;&lt;/td&gt;
&lt;td style=""font-weight: bold; text-align:right""&gt;N/A&lt;/td&gt;
&lt;td style=""text-align:right;font-weight:bold;""&gt;179,779&lt;/td&gt;
&lt;td style=""font-weight: bold; text-align:right""&gt;1,559&lt;/td&gt;
&lt;td style=""font-weight: bold; text-align:right""&gt;3,114&lt;/td&gt;
&lt;td style=""font-weight: bold; text-align:right""&gt;460&lt;/td&gt;
&lt;td style=""font-weight: bold; text-align:right""&gt;1,631,561&lt;/td&gt;
&lt;td style=""font-weight: bold; text-align:right""&gt;24,034&lt;/td&gt;
&lt;td style=""display:none"" data-continent=""Europe""&gt;Europe&lt;/td&gt;
&lt;/tr&gt;
</code></pre>
"
60794514,"<p>I have been trying to find a button a click on it but no matter what I try it has been unable to locate it. I have tried using all the <code>driver.find_element_by...</code> methods but nothing seems to be working</p>

<pre><code>from selenium import webdriver
import time


driver = webdriver.Chrome(executable_path=""/Users/shreygupta/Documents/ComputerScience/PythonLanguage/Automation/corona/chromedriver"")
driver.get(""https://ourworldindata.org/coronavirus"")
driver.maximize_window()
time.sleep(5)
driver.find_element_by_css_selector(""a[data-track-note='chart-click-data']"").click()
</code></pre>

<p>I am trying to click the DATA tab on the screenshot below
<a href=""https://i.stack.imgur.com/NmLkn.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NmLkn.png"" alt=""enter image description here""></a></p>
"
61082754,"<p>I'm  trying to change my non <code>datetime</code> type column into type <code>datetime</code>and format <code>2020-03-31</code> . The original format and type is <code>31-Mar-20</code> and object. I tried to change the type into <code>datetime</code> after formatting it into <code>2020-03-31</code> but somehow if i change it into type <code>datetype</code>, in my <code>dataframe</code> it's always including the <code>hh:mm:ss</code> <strong>but when i check it in the console it's already <code>datetype</code> and without</strong> <code>hh:mm:ss</code>. Why is this happening?</p>

<p>When i check it,this is my <code>DataFrame</code> table in my Variable explorer tab in Spyder</p>

<p><a href=""https://i.stack.imgur.com/PvgUz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/PvgUz.png"" alt=""my dataframe""></a></p>

<p>This is when i check it in the console</p>

<pre><code>covid.date
Out[156]: 
0    2020-03-02
1    2020-03-03
2    2020-03-04
3    2020-03-05
4    2020-03-06
5    2020-03-07
</code></pre>
"
61681274,"<p>I'm trying to forecast with Facebook Prophet, the input are all positive but the predictions returns negative. I'm kind of confused, i read this <a href=""https://facebook.github.io/prophet/docs/quick_start.html"" rel=""nofollow noreferrer"">quick start</a> and if the inputs are all positive then the predictions will be likely all positive and the shape of the prediction is similar like the input e.g if input is 0.86 then the output would be 0.81. Why is it like this? How to fix it?</p>

<pre><code>covid_pr = covid[['date','acc_confirmed']].copy()
covid_pr.rename(columns = {'date':'ds', 'acc_confirmed':'y'},inplace= True)

prt = Prophet()
prt.fit(covid_pr)

future_prt = prt.make_future_dataframe(30)
forecast = prt.predict(future_prt)
</code></pre>

<p>My input data</p>

<pre><code>           ds     y
0  2020-03-02     2
1  2020-03-03     2
2  2020-03-04     2
3  2020-03-05     2
4  2020-03-06     4
5  2020-03-07     4
6  2020-03-08     6
7  2020-03-09    19
8  2020-03-10    27
9  2020-03-11    34
10 2020-03-12    34
etc until thousands
</code></pre>

<p>Prediction of fbprophet</p>

<pre><code>     yhat   yhat_lower   yhat_upper
0   -261.572541  -499.409024    -4.741004
1   -208.490561  -446.503629    41.371788
2   -255.114682  -500.580393    -7.825269
3   -208.963597  -481.238870    33.707433
4   -146.566250  -394.337188    96.726382
5    -92.445918  -354.914790   150.409867
6    -38.341696  -293.639411   204.964963
7     83.483534  -158.412231   332.263619
8    136.565514   -95.174934   370.980615
9     89.941393  -153.219255   349.129866
10   136.097121   -95.508485   404.666524
etc until thousands
</code></pre>
"
61578031,"<p>I am writing a script which can be used to plot the country wise covid time-series data. It is working fine when I plot a single country but The scale at Y-axis is in appropriately printed. 
<a href=""https://i.stack.imgur.com/7kjEA.png"" rel=""nofollow noreferrer"">Plot which I am getting</a> The Problem is after printing the maximum value for one country the y axis is extrapolated with smaller values to plot the data points of subsequent countries. 
The code for my script is as follows</p>

<pre><code>import requests
from contextlib import closing
import csv
import matplotlib.pyplot as plt
url = ""https://raw.githubusercontent.com/datasets/covid-19/master/data/countries-aggregated.csv""

def prepareCountryWiseData(country):
    countryWise = {}
    with closing(requests.get(url, stream=True)) as r:
        f = (line.decode('utf-8') for line in r.iter_lines())
        reader = csv.reader(f, delimiter=',', quotechar='""')
        active = []
        recovered = []
        dates = []
        for row in reader:    
             if row[1] == country:
                     dates.append(row[0])
                     active.append(row[2])
                     recovered.append(row[3])
        return (dates, active, recovered)

def plotCountryWiseData(countryList):
    plotable = []
    for country in countryList:
            dates,active,recovered = (prepareCountryWiseData(country))
            plt.plot(active)                
    plt.ylabel('active_cases')
    plt.legend(countryList)
    plt.show()
    plotCountryWiseData(['India','US','Italy'])
</code></pre>
"
60891602,"<p>I a m working on <a href=""https://www.tableau.com/covid-19-coronavirus-data-resources"" rel=""nofollow noreferrer"">this</a> Data Set
I want to get cumulative confirmed cases so I filtered by confirmed cases, grouped by Date and aggregated by sum.</p>

<pre><code>import matplotlib.pyplot as plt
covid_tab=pd.read_csv('datasets/COVID-19 Cases.csv')

covid_tab['Date']=pd.to_datetime(covid_tab['Date'])
covid_tab.groupby([""Country_Region"",""Case_Type""]).agg({'Cases':'max'}).head()
cumulative_cases=covid_tab[covid_tab['Case_Type']=='Confirmed'].groupby('Date').agg({'Cases': 'sum'})
cumulative_cases.head()
</code></pre>

<p>I get something like this</p>

<p><a href=""https://i.stack.imgur.com/69uGq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/69uGq.png"" alt=""what i get""></a></p>

<p>but if I try to access the Date column I get a Key error, or if I try to print the column names I only get 'Cases' printed</p>

<p>Why is that?</p>
"
61062341,"<p>I will be more than happy to find out this question is a duplicate, but if so - I can't find that Q&amp;A.</p>

<p>There is this mysterious page from the <a href=""https://covid19tracker.health.ny.gov/views/NYS-COVID19-Tracker/NYSDOHCOVID-19Tracker-Fatalities?%3Aembed=yes&amp;%3Atoolbar=no&amp;%3Atabs=n"" rel=""nofollow noreferrer"">New York State Department of Health</a> containing ""Fatalities by County and Age Group"". As the title implies, it contains two tables (""By County""/""By Age Group""). </p>

<p>For some strange reason, the data on this page is super-secured. It can't be selected, the page can't be saved and it can't be printed. The data isn't on the page source. I also tried (and failed) to inspect xhr calls for the data.</p>

<p>Obviously, requests and beautifulsoup can't handle it. I tried the usual Selenium incantations (so, unless I'm told otherwise, I won't clutter this question with ""what I tried"" snippets). </p>

<p>Desire output: the data from those two tables, in any conceivable format.</p>

<p>The only thing I can think of is to take a screenshot and try to ocr the image...</p>

<p>I don't know if it's Selenium, Tableau, the NYS Dep't of Health or just me, but it's time to call in the heavy artillery...</p>
"
61645401,"<p>This may look like a duplicate question but believe me there is something new that I have observed with twitter.</p>

<p>I had previously made a twitter scraper that fetches a given number of tweets using scrolling and waiting for dynamic elements. But it doesn't seem to work now. It doesn't scrape more than 10 tweets. Also the tweets that it scrapes is just the last 10 tweets (of all the tweets I load initially through scrolling)</p>

<p>This function is supposed to scrape atleast n tweets. Roughly 10 tweets show up at the start. So I scroll the page <code>n/10-1</code> times to load all the n tweets. Then I scrape all the div's with a particular class name.</p>

<pre><code>def get_n_tweets(n, search_str='Covid 19'):
    driver = webdriver.Firefox(executable_path='geckodriver.exe')
    driver.get(""http://twitter.com/search?q="" + search_str + ""&amp;src=typd"")

    response = []
    for x in range(math.ceil(n / 10)-1):
        driver.execute_script(""window.scrollTo(0, document.body.scrollHeight);"")
        time.sleep(5)
    try:
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, ""div[class='css-1dbjc4n r-1iusvr4 r-16y2uox r-1777fci r-5f2r5o r-1mi0q7o']""))
        )

        e_tweets = driver.find_elements(By.CSS_SELECTOR, ""div[class='css-1dbjc4n r-1iusvr4 r-16y2uox r-1777fci r-5f2r5o r-1mi0q7o']"")

        for e_tweet in e_tweets:
            e_fullname = e_tweet.find_element(By.CSS_SELECTOR, ""div&gt;span[class='css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0']"")
            e_tweet_text = e_tweet.find_element(By.CSS_SELECTOR, ""div[class='css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0']"")
            response.append({'by': e_fullname.text,
                             'tweet': e_tweet_text.text,
                             'score': TextBlob(e_tweet_text.text).sentiment.polarity})            
    finally:
        driver.quit()
    return response
</code></pre>

<p><strong>What I tried?</strong>
I tried loading as many tweets I needed by scrolling to the bottom of the page, scrolled back up to the start of the page and then fetched the required elements. This is giving StaleElementError.</p>

<p>I suspect this to be the reason for this:
In the webpage when I scroll down so that a specified number of tweets load up and then return to the top of the page, the tweets that I had previously loaded disappear.</p>

<p>I am looking for a simple and a standard way to solve this problem. Any help would be greatly appreciated!</p>
"
61626229,"<p>So I recently moved my app to PythonAnywhere. The URL dispatchers were working fine on localhost. After moving to PythonAnywhere, I keep getting this error: </p>

<pre><code>django.urls.exceptions.NoReverseMatch: Reverse for 'blockdata' with arguments '('nameofdistrict',)' not found. 1 pattern(s) tried: ['rmgcovid/&lt;districtid&gt;']
</code></pre>

<p>districtid variable is a string and therefore my app's url.py file also represent it as a slug:</p>

<pre><code> url('&lt;slug:districtid&gt;',views.blockdata,name='blockdata')
</code></pre>

<p>Here is the part of my template that causes the app to crash and throw the error mentioned above:</p>

<pre><code>&lt;form action='{% url ""blockdata"" districtid %}' method=""POST""&gt;
</code></pre>

<p>My views are ok because if I pass 200 as HttpResponse, it shows up that. But with this form action, it is unable to match the URL. </p>

<p>I have tried solving this for a good 10 hours now. I would appreciate any help at this moment. Why is it working on local host fine but now on PythonAnywhere it crashes?</p>

<p>Here is my project's URL snapshot as well:</p>

<pre><code>url(r'^customurl/',include('myappname.urls'))
</code></pre>

<p>the customurl is replaced with my specific url</p>
"
60727696,"<h2>Background</h2>

<p>I am looking at the corona virus dataset from <strong>CSSEGISandData</strong>: github.com/CSSEGISandData/COVID-19.git. 
The data is <strong>stored in csv divided by day</strong> (eg: 01-24-2020.csv,  01-25-2020.csv,  01-26-2020.csv). </p>

<p>I have concatenated all the files into one pandas dataframe, however there are <strong>duplicates present</strong> as you can <strong>see below with Sweden</strong>. This happens becuase when the data for sweden is not updated, the next day file reports the Last Update (thus the last data).  </p>

<pre><code>             Province/State        Country/Region   Last Update    Confirmed
2229             Tibet        Mainland China 2020-02-01 01:52:40        1.0   
2990           Ningxia        Mainland China 2020-02-01 02:13:00       26.0   
3025               NaN                Sweden 2020-02-01 02:13:00        1.0   #THIS
3023               NaN                 Spain 2020-02-01 02:13:00        1.0   
1847               NaN                Sweden 2020-02-01 02:13:26        1.0   #THIS
5910               NaN                Sweden 2020-02-01 02:13:26        1.0   #THIS
2232               NaN                Sweden 2020-02-01 02:13:26        1.0   #THIS
</code></pre>

<h1>Objective</h1>

<p>I want to: </p>

<ol>
<li>Subset data based on Province/State </li>
<li>If Province/State is NaN --> Use Country/Region (eg: Sweden) </li>
<li>Drop all duplicates within the subsets based on 'Last update' Date precise to the day (excluding hour in case there is more than one result form the same day</li>
<li>return the Dataframe </li>
</ol>

<p>To adress 1 and 2, i have filled the NaN of Province/State with the Country/Region value. Howver this isn't ideal, i would prefer to be able to not fill the NaN. </p>

<p>This is my code so far, however i am not able to drop the duplicates. </p>

<pre class=""lang-py prettyprint-override""><code>!git clone https://github.com/CSSEGISandData/COVID-19.git

#@title Import files csse_covid_19_data { form-width: ""10px"" }
import pandas as pd 
import glob
path = r'/content/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports' # use your path
all_files = glob.glob(path + ""/*.csv"") #collect all files in one

li = []

for filename in all_files:
    df = pd.read_csv(filename, index_col=None, header=0)
    df['file']=filename[-14:]
    li.append(df)
frame = pd.concat(li, axis=0, ignore_index=True, sort=False) #one dataframe 


frame['Province/State'].fillna(frame['Country/Region'], inplace=True) #putting the Coutry in teh NaN of Province for data cleanup 

#change the 'Last Update'] to datetime format
frame['Last Update'] = pd.to_datetime(frame['Last Update'])
frame = frame.sort_values(by=""Last Update"")
</code></pre>

<h2>EDIT: Curret solution from:  FROM YOBEN_S</h2>

<p>This is the current solution, it works but i am am filling the Province/state with the Country/Region, instead of grouping on Country region when Province state is NaN </p>

<pre><code>
frame = frame.assign(day=frame['Last Update'].dt.date).\
          drop_duplicates(subset=(['day', 'Province/State'])).drop('day',axis=1)

</code></pre>

<p>Ideally i want to <strong>drop_duplicates</strong> using the date and Province/State as subsets, but when Province/State is NaN switch to Country Region </p>
"
61124428,"<p>I have a function which two crawl the webpage and look for a particular class and find a href tag inside it.</p>

<pre><code>url=""https://www.poynter.org/ifcn-covid-19-misinformation/page/220/""

def url_parse(site):
   hdr = {'User-Agent': 'Mozilla/5.0'}
   req = Request(site,headers=hdr)
   page = urlopen(req)
   soup = BeautifulSoup(page)
   return soup

def article_link(URL):
   try:
      soup=url_parse(URL)
      for i in soup.find_all(""a"", class_=""button entry-content__button entry-content__button--smaller""):
        link=i['href']
   except:
      pass    
return link



data['article_source']=""""
for i, rows in data.iterrows():
   rows['article_source']= article_link(rows['url'])
</code></pre>

<p><strong>Issue</strong></p>

<p>The function url_parse and article_link are working fine but when I use the function article_link to update the cell inside a datagram, it stops working after 1500 or 1000 URLs. I understand there could be an IP address with my laptop but I don't understand how to solve it because there is no error message.</p>

<p><strong>Expectation</strong></p>

<p>The function article_link parse all URL inside the data frame.</p>
"
61438990,"<p>I tried several types of XPath but none of those working as I want to  </p>

<pre><code>Xpath : //td[@class='sorting_1'], 
xpath: //tr[contains(@class,'even')]//td[@class='sorting_1'],
xpath : //tr[contains(@class,'odd')]//td[@class='sorting_1']

CSS: .even+ .odd .sorting_1 , .even .sorting_1
</code></pre>

<p>but the CSS selector does not work in the scrappy shell</p>

<p>can you please help me out of this situation??</p>
"
61611482,"<p>I am scraping data from Twitter for tweets, since Twitter has a limitation on this, I am scraping 2500 tweets data every 15 minutes, however, I observe that each run after 15 minutes is returning me the same tweets. Is there any way how I can skip the previously scraped tweet data using some offset.
Thank You!</p>

<p>Here is my code:</p>

<pre><code>    # Import libraries
from tweepy import OAuthHandler
#from tweepy.streaming import StreamListener
import tweepy
import csv
import pandas as pd
#import re
#from textblob import TextBlob
#import string
#import preprocessor as p
#import os
import time

# Twitter credentials
consumer_key = ''
consumer_secret = ''
access_key = ''
access_secret = ''

# Pass your twitter credentials to tweepy via its OAuthHandler
auth = OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_key, access_secret)
api = tweepy.API(auth)


def extract_tweets(search_words,date_since,numTweets):
    return(tweepy.Cursor(api.search, q=search_words, lang=""en"", since=date_since, tweet_mode='extended').items(numTweets))

def scraptweets(search_words, date_since, numTweets, numRuns):
    # Define a pandas dataframe to store the date:
    db_tweets = pd.DataFrame(columns = ['username', 'acctdesc', 'location', 'following', 'followers', 'totaltweets', 'usercreatedts', 'tweetcreatedts', 'retweetcount', 'text', 'hashtags'])
    #db_tweets = pd.DataFrame()

    for i in range(numRuns):

        tweets = extract_tweets(search_words,date_since,numTweets)
        # Store these tweets into a python list
        tweet_list = [tweet for tweet in tweets]
        print(len(tweet_list))
        noTweets = 0

        for tweet in tweet_list:
            username = tweet.user.screen_name
            acctdesc = tweet.user.description
            location = tweet.user.location
            following = tweet.user.friends_count
            followers = tweet.user.followers_count
            totaltweets = tweet.user.statuses_count
            usercreatedts = tweet.user.created_at
            tweetcreatedts = tweet.created_at
            retweetcount = tweet.retweet_count
            hashtags = tweet.entities['hashtags']
            lst=[]
            for h in hashtags:
                lst.append(h['text'])
            try:
                text = tweet.retweeted_status.full_text
            except AttributeError:  # Not a Retweet
                text = tweet.full_text

            itweet = [username,acctdesc,location,following,followers,totaltweets,usercreatedts,tweetcreatedts,retweetcount,text,lst]
            db_tweets.loc[len(db_tweets)] = itweet

            noTweets += 1
            print(noTweets,itweet)

            #filename = ""tweets.csv""
            #with open(filename, ""a"", newline='') as fp:
             #   wr = csv.writer(fp, dialect='excel')
              #  wr.writerow(itweet)

        print('no. of tweets scraped for run {} is {}'.format(i + 1, noTweets))
        if i+1 != numRuns:
            time.sleep(920)

        filename = ""tweets.csv""
        # Store dataframe in csv with creation date timestamp
        db_tweets.to_csv(filename, mode='a', index = False)

# Initialise these variables:


search_words = ""#India OR #COVID-19""
date_since = ""2020-04-29""
#date_until = ""2020-05-01""
numTweets = 2500
numRuns = 10
# Call the function scraptweets
program_start = time.time()
scraptweets(search_words, date_since, numTweets, numRuns)
program_end = time.time()
print('Scraping has completed!')
print('Total time taken to scrap is {} minutes.'.format(round(program_end - program_start)/60, 2))

</code></pre>

<p>I referred to a blog on medium for this purpose.</p>
"
60834567,"<p>I'm trying to read in a saved copy of the worldometer coronavirus html page with BeautifulSoup4 and python3 (Anaconda Jupyter Notebook).  Here's my code:</p>

<pre><code>from bs4 import BeautifulSoup

with open(r""c:\data\test.html"") as fp:
   soup = BeautifulSoup(fp.read(), ""html.parser"")
</code></pre>

<p>When I execute this I get the following error:</p>

<pre><code>---------------------------------------------------------------------------
UnicodeDecodeError                        Traceback (most recent call last)
&lt;ipython-input-3-cd472fc11bf6&gt; in &lt;module&gt;
      3 
      4 with open(r""c:\data\test.html"") as fp:
----&gt; 5     soup = BeautifulSoup(fp.read(), ""html.parser"")

~\Anaconda3\lib\encodings\cp1252.py in decode(self, input, final)
      21 class IncrementalDecoder(codecs.IncrementalDecoder):
      22     def decode(self, input, final=False):
---&gt; 23         return codecs.charmap_decode(input,self.errors,decoding_table)[0]
     24 
     25 class StreamWriter(Codec,codecs.StreamWriter):

UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 797676: character maps to 
&lt;undefined&gt;
</code></pre>

<p>When I read this file directly via http into BS4, it works Ok.  But, if I continue to access the page this way, I get blocked.  I am able to successfully access the page every 10 minutes directly through Chrome and have been storing them for the last week.  Now I need to be able to read them in so I can begin processing the data.  Not sure why I'm seeing this error.  Appreciate any help.  </p>
"
61354607,"<p>I want to make the background of the tabbed frames in this code white but for some reason, everything I have tried just is not working. The background color is currently gray but the background of the individual widgets are white. Ideally, they would all be white. The only solution I found that changed the background to white ended up removing the border of the Button.</p>

<p><a href=""https://i.stack.imgur.com/A8DiI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/A8DiI.png"" alt=""enter image description here""></a></p>

<pre><code>from tkinter import *
from tkinter import ttk

window = Tk()

width = 850
height = 450

window.title(""Sheltering the Homeless During a Pandemic"")
window.geometry(str(width) + ""x"" + str(height))

# style = ttk.Style()
# style.theme_create('st', settings={
#     ""."": {
#         ""configure"": {
#             ""background"": ""white"",
#         }
#     },
#     ""TNotebook"": {
#         ""configure"": {
#             ""tabmargins"": [2, 5, 0, 0],
#         }
#     },
#     ""TNotebook.Tab"": {
#         ""configure"": {
#             ""padding"": [10, 2]
#         },
#         ""map"": {
#             ""background"": [(""selected"", ""#D3D3D3"")],
#             ""expand"": [(""selected"", [1, 1, 1, 0])]
#         }
#     },
# })
# style.theme_use('st')

#Create Tab Control
tab_control = ttk.Notebook(window)
#Tab1
tab1 = ttk.Frame(tab_control)
tab_control.add(tab1, text='National Level')
#Tab2
tab2 = ttk.Frame(tab_control)
tab_control.add(tab2, text='State Level')
tab_control.pack(expand=1, fill=""both"")

# Define the Input Labels
lbl_people_per_room = Label(tab1, text=""People Per Room: "", pady=20)
lbl_people_per_room.grid(row=0, column=0)

lbl_num_employees_per_10_rooms = Label(tab1, text=""Employees Per 10 Rooms: "")
lbl_num_employees_per_10_rooms.grid(row=0, column=2)

lbl_min_wage_inflation_percentage = Label(tab1, text=""Miniumum Wage Inflation Percentage: "")
lbl_min_wage_inflation_percentage.grid(row=1, column=0)

lbl_nightly_compensation = Label(tab1, text=""Nightly Hotel Compensation"")
lbl_nightly_compensation.grid(row=1, column=2)

# Define the Entries
txt_people_per_room = DoubleVar(value=2)
entry_ppr = Entry(tab1, textvariable=txt_people_per_room)
entry_ppr.grid(row=0, column=1)

txt_num_employees_per_10_rooms = DoubleVar(value=1)
entry_ep10 = Entry(tab1, textvariable=txt_num_employees_per_10_rooms)
entry_ep10.grid(row=0, column=3)

txt_min_wage_inflation_percentage = DoubleVar(value=50)
entry_mwi = Entry(tab1, textvariable=txt_min_wage_inflation_percentage)
entry_mwi.grid(row=1, column=1)

txt_nightly_compensation = DoubleVar(value=72.05)
entry_nc = Entry(tab1, textvariable=txt_nightly_compensation)
entry_nc.grid(row=1, column=3)

# spacer
lbl_spacer = Label(tab1, text="""")
lbl_spacer.grid(row=2, column=0, columnspan=4)

style1 = ttk.Style()
btn_calculate = ttk.Button(tab1, text=""Calculate"", width=15)
btn_calculate.grid(row=3, column=0, columnspan=4)

# spacer
lbl_spacer = Label(tab1, text="""")
lbl_spacer.grid(row=4, column=0, columnspan=4)


window.mainloop()
</code></pre>
"
60844628,"<p>I am running the following cloud function. It runs with success and indicates data was loaded to the table. But when I query the BigQuery no data has been added. I am getting no errors and no indication that it isn't working.</p>

<pre><code>from google.cloud import bigquery
import pandas as pd


def download_data(event, context):

     df = pd.read_csv('https://covid.ourworldindata.org/data/ecdc/full_data.csv')

     # Create an empty list 
     Row_list =[] 

     # Iterate over each row 
     for index, rows in df.iterrows(): 
          # Create list for the current row 
          my_list =[rows.date, rows.location, rows.new_cases, rows.new_deaths, rows.total_cases, rows.total_deaths] 
          #print(my_list)     
     # append the list to the final list 
     Row_list.append(my_list) 


     ## Get Biq Query Set up
     client = bigquery.Client()
     table_id = ""&lt;project_name&gt;.raw.daily_load""
     table = client.get_table(table_id)

     print(client)
     print(table_id)
     print(table)


     errors = client.insert_rows(table, Row_list)  # Make an API request.
     if errors == []:
          print(""New rows have been added."")
</code></pre>

<p>Attempted so far;</p>

<ol>
<li>Check data was being pulled -> PASSED, I printed out row_list and
data is there </li>
<li>Run locally from my machine -> PASSED, data appeared when I ran it from a python terminal</li>
<li>Print out the table details -> PASSED, see attached screenshot it all appears in the logs </li>
<li>Confirm it is able to find the table -> PASSED, I changed the name
of    the table to one that didn't exist and it failed</li>
</ol>

<p>Not sure what is next, any advice would be greatly appreciated</p>

<p><a href=""https://i.stack.imgur.com/pMXxq.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pMXxq.png"" alt=""logfile indicating success""></a></p>
"
61421522,"<p>I have to scrape data from the tabulae workbook to csv file.
<a href=""https://public.tableau.com/views/2020_04_06_COVID19_India/Dashboard_India_Cases?:embed=y&amp;:showVizHome=no&amp;:host_url=https%3A%2F%2Fpublic.tableau.com%2F&amp;:embed_code_version=3&amp;:tabs=no&amp;:toolbar=yes&amp;:animate_transition=yes&amp;:display_static_image=no&amp;:display_spinner=no&amp;:display_overlay=yes&amp;:display_count=yes&amp;publish=yes&amp;:loadOrderID=0"" rel=""nofollow noreferrer"">https://public.tableau.com/views/2020_04_06_COVID19_India/Dashboard_India_Cases?:embed=y&amp;:showVizHome=no&amp;:host_url=https%3A%2F%2Fpublic.tableau.com%2F&amp;:embed_code_version=3&amp;:tabs=no&amp;:toolbar=yes&amp;:animate_transition=yes&amp;:display_static_image=no&amp;:display_spinner=no&amp;:display_overlay=yes&amp;:display_count=yes&amp;publish=yes&amp;:loadOrderID=0</a></p>

<p>I have tried the following but i am getting no output.</p>

<p>main.py </p>

<pre><code>import requests
from bs4 import BeautifulSoup


 r = requests.get(""https://public.tableau.com/views/2020_04_06_COVID19_India/Dashboard_India_Cases?:embed=y&amp;:showVizHome=no&amp;:host_url=https%3A%2F%2Fpublic.tableau.com%2F&amp;:embed_code_version=3&amp;:tabs=no&amp;:toolbar=yes&amp;:animate_transition=yes&amp;:display_static_image=no&amp;:display_spinner=no&amp;:display_overlay=yes&amp;:display_count=yes&amp;publish=yes&amp;:loadOrderID=0"")

     soup = BeautifulSoup(r.content, ""html.parser"")

     for td in soup.findAll(""table""):

     for a in td.findAll(""tr""):
      print(a.find('td'))
</code></pre>
"
61415090,"<p>When trying to read England's Covid_19 data into pandas, I've tried to use the URL provided by PHE <code>https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv</code> however, this file needs a http 308 redirect. I have tried the elegant solution:</p>

<pre><code>import pandas as pd
tabel = pd.read_csv('https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv')
</code></pre>

<p>which trows the error <code>HTTPError: HTTP Error 308: Permanent Redirect</code></p>

<p>However, the URL works as</p>

<pre><code>import pandas as pd
import requests
import io
datastr = requests.get('https://coronavirus.data.gov.uk/downloads/csv/coronavirus-cases_latest.csv',allow_redirects=True).text
data_file = io.StringIO(datastr)
table = pd.read_csv(data_file)
</code></pre>

<p>gives the desired result.</p>

<p>I would like something similar to the first solution, is this a problem of pandas or am I doing something wrong?</p>
"
61165839,"<p>I am trying to parse some HTML but the section that I want simply does not show up in the soup. Both the prior section and the posterior section are there, but not the one I want. Am I doing something wrong?</p>

<p>URL: <a href=""https://coronavirus-portugal-esriportugal.hub.arcgis.com/"" rel=""nofollow noreferrer"">https://coronavirus-portugal-esriportugal.hub.arcgis.com/</a>
My code (with the URL):</p>

<pre><code>from urllib.request import urlopen as uReq
from bs4 import BeautifulSoup as soup

url = 'https://coronavirus-portugal-esriportugal.hub.arcgis.com/'
uClient = uReq(url)
page_html = uClient.read()
uClient.close()

soup = soup(page_html, 'html.parser')
body = soup.body
print(body.prettify())
</code></pre>

<p>I am looking for the first four numbers (those corresponding to ""Casos Confirmados"", ""Casos Suspeitos"", ""Recuperados"", ""Óbitos"")</p>
"
61481830,"<p>I have this simple script but it simply doesn't seem to be running. I've tried with and without debugging, and it seems to go through it but it ignores the prints and the write csv portion, it's like it does nothing. I have a regular installation of VS code and python (no anaconda).</p>

<p>The code:</p>

<pre><code>import requests
import pandas as pd
import numpy as np
from bs4 import BeautifulSoup
from datetime import datetime
import locale
import csv

locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')

URL = 'https://www.worldometers.info/coronavirus/#countries'
html_page = requests.get(URL).text
soup = BeautifulSoup(html_page, 'lxml')
get_table = soup.find('table', id='main_table_countries_today')
get_table_data = get_table.tbody.find_all(""tr"")

dic = {}
for i in range(len(get_table_data)):
    try:
        key = get_table_data[i].find_all('a', href=True)[0].string
    except:
        key = get_table_data[i].find_all('td')[0].string

    values = [j.string for j in get_table_data[i].find_all('td')]
    dic[key] = values
    print(key)
pt = dic[""Portugal""]
today = datetime.today().strftime('%Y-%m-%d')

output = [today, locale.atoi(pt[1]), locale.atoi(pt[3]), locale.atoi(pt[5])]

print(output)

with open('C:/Users/HP/Documents/Scripts/coronavirus/data.csv','a+', newline='') as write_obj:
    csv_writer = csv.writer(write_obj)
    csv_writer.writerow(output)

print(output)
print(""Done!"")
</code></pre>

<p>What I see in the terminal:</p>

<p><a href=""https://i.stack.imgur.com/nG0py.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nG0py.png"" alt=""Error message""></a></p>
"
60932974,"<p>I wanted to play around a bit with the corona virus dataset of the new york times. 
I want to plot it and filter by date to only show the last weeks. However I get this error message:
<code>TypeError: '&gt;' not supported between instances of 'bool' and 'datetime.datetime'</code> driven by this line: <code>df_toplot = df[df['state'].isin(top_states) &amp; df['state'] &gt; da]</code>. Somehow I can't manage to turn the date column into a datetime format, instead its format is pandas.core.series.Series. How can I change that?</p>

<pre><code>import datetime
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
df = pd.read_csv(""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv"")

df['date']= pd.to_datetime(df['date'])
print(type(df['date'])) 
#print(df['date'].iloc[1] &gt; date_object)
variable = ""deaths"" # ""cases""
#print(df.head())

d = pd.pivot_table(df, index= 'state', values= variable,aggfunc=np.sum)
top_states = d.nlargest(10, variable, keep='first').index.values
s = ""2018-06-19 11:21:13.311""
da = datetime.datetime.strptime(s, '%Y-%m-%d %H:%M:%S.%f') 
print(type(df['date'])) 
df_toplot = df[df['state'].isin(top_states) &amp; df['state'] &gt; da]
df_toplot.pivot(index='date', columns='state', values=variable).plot()
plt.yscale('log')
</code></pre>
"
61298672,"<p>i am trying to get Tweets about coronavirus with location between a timeline. But it return nothing. If i changed until to April 18, it would only return tweets on Fri Apr 17 23:59:59 +0000 2020 , like {'text': 'A man who bought a ghost town with a sinister past has been forced to quarantine there after a snowstorm left him trapped ', 'created_at': 'Fri Apr 17 23:59:59 +0000 2020', 'location': 'Dallas'}</p>

<pre><code>q2=""quarantine since:2020-01-02 until:2020-04-10""
tweepy.Cursor(api.search, q=q2,geo=citydic[i],lang=""en"",tweet_mode='extended').items(20)
</code></pre>
"
60782597,"<p>I am using Folium to see the spread of COVID 19 in Spain by territories.</p>

<p>When I use the data in a normal Choropleth it works fine.</p>

<p>However, since I am interesting in the spread over time, I have to use a TimeSliderChoropleth.</p>

<p>Submitting the same data some territories visualize and some don't and I can't find the issue.</p>

<p>Can some experienced with Folium help me?</p>

<p>All the code is here:</p>

<p><a href=""https://www.kaggle.com/python10pm/covid-19-in-spain"" rel=""nofollow noreferrer"">https://www.kaggle.com/python10pm/covid-19-in-spain</a></p>

<p>Thanks in advance.</p>
"
61004075,"<p>In the graph, the date axis is not being displayed correctly with date formatting, the year that should be ""2020"" and is displayed as ""51"". Text text text Text text text Text text text Text text text Text text text Text text text Text text text Text text text Text text text </p>

<pre><code># -*- coding: latin-1 -*-

import pandas as pd
import datetime
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

hoje = datetime.datetime.now()
data = hoje.strftime(""%Y%m%d"")
dados_url = 'https://covid.saude.gov.br/assets/files/COVID19_'+data+'.csv'

try:
    print(dados_url)
    dados = pd.read_csv(dados_url, sep=';', parse_dates=['data'],  dayfirst=True)
except Exception as e:
    print(""Os dados para a data corrente ainda não foram atualizados, buscando dados do dia anterior..."")
    print(e)
    DD = datetime.timedelta(days=1)
    hoje = hoje - DD
    data = hoje.strftime(""%Y%m%d"")
    print(str(hoje))
    dados_url = 'https://covid.saude.gov.br/assets/files/COVID19_'+data+'.csv'
    print(str(dados_url))
    dados = pd.read_csv(dados_url, sep=';', parse_dates=['data'],  dayfirst=True)

#pd.set_option('display.max_rows', None)

dados_alagoas = dados[dados['estado'] == 'AL']
dados_alagoas.set_index('data',inplace=True)
#print(dados_alagoas)

plt.style.use('ggplot')

fig, ax = plt.subplots(figsize=(30,15))
dados_alagoas.plot(ax=ax, rot=75)

#grafico em barras
#dados_alagoas.plot(ax=ax, rot=75, kind='bar', width=2.0)

ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))
ax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m/%y'))
ax.set_title('Incidência do COVID-19 em Alagoas em '+hoje.strftime('%d/%m/%Y'))
ax.set_ylabel('Ocorrências')
ax.set_xlabel('Data')
plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/CnIM3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CnIM3.png"" alt=""enter image description here""></a></p>
"
61504237,"<p>I have a small application built using Flask and <a href=""https://flask-restx.readthedocs.io/en/latest/"" rel=""nofollow noreferrer""> Flask-restx</a>. I can run the app using <code>python app.py</code> and the flask server runs on port 8888. I try to run the file using <code>set FLASK_APP=app.py</code> and run using <code>flask run</code> which seems to run, but doesnt open my swagger page. Please advice.</p>

<p>app.py</p>

<pre><code>import logging.config

import os
from flask import Flask, Blueprint
from flask_cors import CORS
from werkzeug.middleware.proxy_fix import ProxyFix
from src.config import default
from src.api.controllers.endpoints.users import ns as users_namespace
from src.api.controllers.endpoints.statuses import ns as status_namespace
from src.api import api
from src.database import db

app = Flask(__name__)
CORS(app)
app.wsgi_app = ProxyFix(app.wsgi_app)
logging_conf_path = os.path.normpath(os.path.join(os.path.dirname(__file__), '../logging.conf'))
logging.config.fileConfig(logging_conf_path)
log = logging.getLogger(__name__)


def configure_app(flask_app):
    flask_app.config['SERVER_NAME'] = default.FLASK_SERVER_NAME
    flask_app.config['SQLALCHEMY_DATABASE_URI'] = default.SQLALCHEMY_DATABASE_URI
    flask_app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = default.SQLALCHEMY_TRACK_MODIFICATIONS
    flask_app.config['SWAGGER_UI_DOC_EXPANSION'] = default.RESTPLUS_SWAGGER_UI_DOC_EXPANSION
    flask_app.config['RESTPLUS_VALIDATE'] = default.RESTPLUS_VALIDATE
    flask_app.config['RESTPLUS_MASK_SWAGGER'] = default.RESTPLUS_MASK_SWAGGER
    flask_app.config['ERROR_404_HELP'] = default.RESTPLUS_ERROR_404_HELP


def initialize_app(flask_app):
    configure_app(flask_app)

    blueprint = Blueprint('CovidAPI', __name__, url_prefix='/')
    api.init_app(blueprint)
    api.add_namespace(users_namespace)
    api.add_namespace(status_namespace)
    flask_app.register_blueprint(blueprint)

    db.init_app(flask_app)


def main():
    initialize_app(app)
    log.info('&gt;&gt;&gt;&gt;&gt; Starting development server at http://{}/ &lt;&lt;&lt;&lt;&lt;'.format(app.config['SERVER_NAME']))
    app.run(debug=default.FLASK_DEBUG)


if __name__ == ""__main__"":
    main()
</code></pre>

<p>Flask Settings:</p>

<pre><code># Flask settings
FLASK_SERVER_NAME = 'localhost:8888'
FLASK_DEBUG = True  # Do not use debug mode in production

# Flask-Restplus settings
RESTPLUS_SWAGGER_UI_DOC_EXPANSION = 'list'
RESTPLUS_VALIDATE = True
RESTPLUS_MASK_SWAGGER = False
RESTPLUS_ERROR_404_HELP = False
</code></pre>

<p>Output using python command:</p>

<pre><code>2020-04-29 10:25:42,519 - __main__ - INFO - &gt;&gt;&gt;&gt;&gt; Starting development server at http://localhost:8888/ &lt;&lt;&lt;&lt;&lt;
 * Serving Flask app ""app"" (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: on
2020-04-29 10:25:42,610 - werkzeug - INFO -  * Restarting with stat
2020-04-29 10:25:45,398 - __main__ - INFO - &gt;&gt;&gt;&gt;&gt; Starting development server at http://localhost:8888/ &lt;&lt;&lt;&lt;&lt;
2020-04-29 10:25:45,426 - werkzeug - WARNING -  * Debugger is active!
2020-04-29 10:25:45,458 - werkzeug - INFO -  * Debugger PIN: 258-749-652
2020-04-29 10:25:45,530 - werkzeug - INFO -  * Running on http://localhost:8888/ (Press CTRL+C to quit)
</code></pre>

<p>Running through flask run:</p>

<pre><code> * Serving Flask app ""src\app.py"" (lazy loading)
 * Environment: production
   WARNING: This is a development server. Do not use it in a production deployment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 313-115-045
 * Running on http://localhost:6000/ (Press CTRL+C to quit)
</code></pre>
"
61316741,"<p>I have created this code (which you can find on my <a href=""https://colab.research.google.com/drive/1lXYWmwKPYw0NyadJ3K7lt_VlpJ-8uB9V#scrollTo=BiscW00iHuu3&amp;line=10&amp;uniqifier=1"" rel=""nofollow noreferrer"">colab</a>) and it calls <code>tfp.mcmc.sample_chain</code>, and it works perfectly on Google Colab, but as soon as I connect to local runtime on Windows 10, I start getting this weird error of failing to convert to a tensor because of the data type. Every single one of my inputs is clearly cast to tf.float32 so I do not understand where this comes from. I have included the trace stack below and the function in question.</p>

<p><strong>Function:</strong></p>

<pre class=""lang-py prettyprint-override""><code>def graph_sample_chain(*args, **kwargs):
  print(""current = "",kwargs[""current_state""])
  start_time = time.time()
  out = tfp.mcmc.sample_chain(*args, **kwargs)
  print(f""It took: {(time.time()-start_time)/60} min"")
  return out
</code></pre>

<p><strong>Stack trace:</strong></p>

<pre><code>    File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 96, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 266, in _constant_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 258, in constant
    allow_broadcast=True)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\framework\tensor_conversion_registry.py"", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1314, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\ops\math_ops.py"", line 705, in cast
    x = ops.convert_to_tensor(x, name=""x"")
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\util\dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_probability\python\math\generic.py"", line 111, in reduce_logmeanexp
    log_n = tf.math.log(tf.cast(n, lse.dtype))
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_probability\python\mcmc\simple_step_size_adaptation.py"", line 380, in one_step
    axis=prefer_static.range(num_reduce_dims))
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_probability\python\mcmc\internal\util.py"", line 315, in &lt;lambda&gt;
    body=lambda i, *args: [i + 1] + list(body_fn(*args)),
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\ops\control_flow_ops.py"", line 2714, in while_loop
    loop_vars = body(*loop_vars)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\ops\control_flow_ops.py"", line 2478, in while_loop_v2
    return_same_structure=True)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_probability\python\mcmc\internal\util.py"", line 317, in smart_for_loop
    parallel_iterations=parallel_iterations
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_probability\python\mcmc\sample.py"", line 343, in _trace_scan_fn
    parallel_iterations=parallel_iterations)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_probability\python\mcmc\internal\util.py"", line 384, in _body
    state = loop_fn(state, elems_array.read(i))
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\ops\control_flow_ops.py"", line 2714, in while_loop
    loop_vars = body(*loop_vars)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_core\python\ops\control_flow_ops.py"", line 2478, in while_loop_v2
    return_same_structure=True)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_probability\python\mcmc\internal\util.py"", line 395, in trace_scan
    parallel_iterations=parallel_iterations)
  File ""C:\Users\emore\Anaconda3\Lib\site-packages\tensorflow_probability\python\mcmc\sample.py"", line 359, in sample_chain
    parallel_iterations=parallel_iterations)
  File ""C:\Users\emore\Documents\covid19 analysis\code\test.py"", line 479, in graph_sample_chain
    out = tensorflow_probability.mcmc.sample_chain(*args, **kwargs)
  File ""C:\Users\emore\Documents\covid19 analysis\code\test.py"", line 527, in &lt;module&gt;
    kernel = kernel, parallel_iterations=nchain)
  File ""C:\Users\emore\Anaconda3\Lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\emore\Anaconda3\Lib\runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""C:\Users\emore\Anaconda3\Lib\runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""C:\Users\emore\Anaconda3\Lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\emore\Anaconda3\Lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
</code></pre>
"
61441415,"<p>I am struggling to solve a problem I am having with folium choropleth map. I am visualizing COVID-19 cases and try to plot the colour according to their quantiles affiliation. However, unfortunately, the legend overlaps. Hence, I am wondering if someone could please tell me how to fix this problem? Either by ""logarithmically"" scaling the legend or just showing the start and end. Unfortunately, I did not find sufficient advice online. Please find below the code and a visualization:</p>

<pre><code>myscale = (covid_cases['total_cases'].quantile((0,0.02,0.25,0.5,0.75,0.9,0.98,1))).tolist()

m = folium.Map([10, -10], zoom_start= 2)

folium.Choropleth(
    geo_data = world_countries,
    data = covid_cases,
    columns = ['code','total_cases'],
    nan_fill_color = 'gray',
    nan_fill_opacity = 0.20,
    key_on = 'feature.id',
    fill_color='YlGnBu',
    threshold_scale=myscale,
    fill_opacity=0.7,
    line_opacity=1.0,
    legend_name='COVID-19 Total Cases per Country | Data Source: OurWorldInData (own repr.)',
).add_to(m)


m.save(os.path.join('/Users/XXX/Results', 'covid_cases.html'))
</code></pre>

<p><a href=""https://i.stack.imgur.com/zjHMm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/zjHMm.png"" alt=""Overlapping legend""></a></p>

<p>Thank you in advance!</p>
"
61492207,"<p>I have this form with two fields. The second field should be populated with the names of existing projects but when rendered is stays empty and no dropdown appears.</p>

<pre><code>class UploadRawForm(forms.ModelForm):
    orig_file = forms.FileField(widget=forms.ClearableFileInput(attrs={'multiple': True}))
    project = forms.ModelChoiceField(queryset=Project.objects.all(), required=True)
    class Meta:
        model = RawFile
        fields = ['orig_file', 'project']
</code></pre>

<p>Template:</p>

<pre><code>{% extends 'base.html' %}

{% block title %}File upload{% endblock %}

{% block content %} 
    &lt;h1&gt; {{ name }} &lt;/h1&gt;
    &lt;form method=""POST"" id=""upload-form"" class=""upload-form"" enctype=""multipart/form-data"" novalidate&gt;
        {% csrf_token %}
        {{ form.as_p }}
        &lt;button type=""submit"" class=""save btn btn-default""&gt;Upload&lt;/button&gt;
    &lt;/form&gt;

    {% if form.errors %}
        {% for field in form %}
            {% for error in field.errors %}
                &lt;p&gt; {{ error }} &lt;/p&gt;
            {% endfor %}
        {% endfor %}
    {% endif %}

{% endblock %}
</code></pre>

<p>views.py:</p>

<pre><code>@login_required(login_url='accounts/login')
def upload_raw_view(request):
    '''Upload RAW files. Working for single file uploads'''
    form = UploadRawForm()
    name = 'Upload RAW files.'
    context = {'form': form, 'name': name}
    if request.method == 'POST':
        form = UploadRawForm(request.POST, request.FILES)
        context['form'] = form
        if not form.is_valid():
            return render(request, 'proteomics/upload.html', context=context)
        if form.is_valid():
            files = request.FILES.getlist('orig_file')
            for f in files:
                rawfile = RawFile(orig_file=f)
                rawfile.save()
            return render(request, 'proteomics/upload.html', context)
    return render(request, 'proteomics/upload.html', context)
</code></pre>

<p>models.py</p>

<pre><code>class RawFile(models.Model):
    # use the custom storage class fo the FileField
    orig_file = models.FileField(upload_to = media_file_name, 
                                 storage = public_storage, 
                                 max_length = 1000)
    md5sum = models.CharField(max_length = 36, 
                              default = timezone.now, 
                              unique = True)
    created = models.DateField(default=timezone.now)
    project = models.ForeignKey(Project, on_delete=models.CASCADE, null=False)

    def save(self, *args, **kwargs):
        print('Saving new raw file.', self.md5sum)
        if not self.pk:  # file is new
            md5 = hashlib.md5()
            for chunk in self.orig_file.chunks():
                md5.update(chunk)
            self.md5sum = md5.hexdigest()
        if not self.id:
            self.created = timezone.now()
        print('Saving new raw file.', self.md5sum)

        try:
            super(RawFile, self).save(*args, **kwargs) 
        except IntegrityError as e:
            pass

    def __str__(self):
        return basename(self.orig_file.name)

    @property
    def abs_path(self): 
        return f'{PUBLIC_MEDIA_ROOT}/{self.orig_file}'

    @property
    def filename(self):
        return basename(self.abs_path)

    @property
    def path(self):
        return dirname(self.abs_path)

    @property
    def rawtools_status(self):
        path = dirname(self.abs_path)
        if isfile('QcDataTable.csv'):
            return 'Done'
        elif isfile(join(path, 'rawtools.txt')):
            return 'Running'
        return 'New file'

    @property    
    def href(self):
        return os.path.dirname('/'+self.orig_file.name)

    def link(self):
        print(self.href)
        return mark_safe(r'&lt;a href=""{}""&gt;Output&lt;/a&gt;'.format(self.href))

    link.short_description = 'Browse'
</code></pre>

<p><a href=""https://i.stack.imgur.com/xK9MD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/xK9MD.png"" alt=""enter image description here""></a></p>

<h1>Versions</h1>

<pre><code>django                    3.0.5            py36h9f0ad1d_1    conda-forge
django-admin-index        1.3.0                    pypi_0    pypi
django-extensions         2.2.9              pyh9f0ad1d_0    conda-forge
django-ordered-model      3.3.0                    pypi_0    pypi
django-plotly-dash        1.3.1                    pypi_0    pypi
</code></pre>

<h1>The available projects appear in the HTML code though:</h1>

<pre><code>    &lt;form method=""POST"" id=""upload-form"" class=""upload-form"" enctype=""multipart/form-data"" novalidate&gt;
        &lt;input type=""hidden"" name=""csrfmiddlewaretoken"" value=""BCns828qAZlisCkj31ITefv5fn3YugsUIZRGsR5wfKnRyL2XTAvDsdWOKX2TSaKQ""&gt;
        &lt;p&gt;&lt;label for=""id_orig_file""&gt;Orig file:&lt;/label&gt; &lt;input type=""file"" name=""orig_file"" multiple required id=""id_orig_file""&gt;&lt;/p&gt;
&lt;p&gt;&lt;label for=""id_project""&gt;Project:&lt;/label&gt; &lt;select name=""project"" required id=""id_project""&gt;
  &lt;option value="""" selected&gt;---------&lt;/option&gt;

  &lt;option value=""1""&gt;COVID&lt;/option&gt;

  &lt;option value=""2""&gt;LSARP&lt;/option&gt;

&lt;/select&gt;&lt;/p&gt;
        &lt;button type=""submit"" class=""save btn btn-default""&gt;Upload&lt;/button&gt;
    &lt;/form&gt;
</code></pre>
"
61684062,"<p>I followed all step following my question here  : <a href=""https://stackoverflow.com/questions/61606615/pandas-dataframe-how-to-add-a-vertical-line-with-label-to-a-bar-plot-when-your"">Pandas Dataframe : How to add a vertical line with label to a bar plot when your data is time-series?</a></p>

<p>it was supposed to solve my problem but when I change the The kind of plot to line , the vertical line did not appear . I copy the same code and change plot type to line instead of bar :</p>

<p>as you can see with bar , the vertical line (in red ) appears .</p>

<pre><code># function to plot a bar 
def dessine_line3(madataframe,debut_date , mes_colonnes):

madataframe.index = pd.to_datetime(madataframe.index,format='%m/%d/%y')
df = madataframe.loc[debut_date:,mes_colonnes].copy()
filt = (df[df.index == '4/20/20']).index
df.index.searchsorted(value=filt)
fig,ax = plt.subplots()
df.plot.bar(figsize=(17,8),grid=True,ax=ax)
ax.axvline(df.index.searchsorted(filt), color=""red"", linestyle=""--"", lw=2, label=""lancement"")
plt.tight_layout()
</code></pre>

<p>out : <a href=""https://i.stack.imgur.com/1Othm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1Othm.png"" alt=""enter image description here""></a></p>

<p>but whan I just change code by changing the type of plot to line : there is no vertical line and also the   x axis (date ) changed . <a href=""https://i.stack.imgur.com/GlUSE.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GlUSE.png"" alt=""enter image description here""></a></p>

<p>so I wrote another code juste to draw line with vertical line </p>

<pre><code>ax = madagascar_maurice_case_df[[""Madagascar Covid-19 Ratio"",""Maurice Covid-19 Ratio""]].loc['3/17/20':].plot.line(figsize=(17,7),grid=True)
</code></pre>

<p>filt = (df[df.index=='4/20/20']).index
ax.axvline(df.index.searchsorted(filt),color=""red"",linestyle=""--"",lw=2 ,label=""lancement"")
plt.show()</p>

<p>but the result is the same </p>

<p>following the comment below , here is my final code :</p>

<pre><code>def dessine_line5(madataframe,debut_date , mes_colonnes):
    plt.figure(figsize=(17,8))
    plt.grid(b=True,which='major',axis='y')
    df = madataframe.loc[debut_date:,mes_colonnes]
    sns.lineplot(data=df)
    lt = datetime.toordinal(pd.to_datetime('4/20/20'))
    plt.axvline(lt,color=""red"",linestyle=""--"",lw=2,label=""lancement"")
    plt.show()
</code></pre>

<p>and the result is :
<a href=""https://i.stack.imgur.com/c5DBz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/c5DBz.png"" alt=""enter image description here""></a></p>
"
61051284,"<p>I have a python script that pulls from a 3 rd party API. The script runs for 3 different cities in loop and creates a data frame for each city. Then I transfer the data frame to an excel sheet as a tab. Below is the code.</p>

<pre><code>    sublocation_ids = [
                {
                  ""id"": 163,
                  ""name"": ""Atlanta, GA""
                },
                {
                  ""id"": 140,
                  ""name"": ""Austin, TX""
                },
                {
                  ""id"": 164,
                  ""name"": ""Baltimore, MD""
                } 
             ]
filter_text = ""(headline:coronavirus OR summary:coronavirus OR headline:covid-19 OR summary:covid-19) AND categories:{}""

writer = pd.ExcelWriter(excel_path)
    for sub in sublocation_ids:
        city_num_int = sub['id']
        city_num_str = str(city_num_int)
        city_name = sub['name']
        filter_text_new = filter_text.format(city_num_str)
        data = json.dumps({""filters"": [filter_text_new], ""sort_by"":""created_at"", ""size"":2})
        r = requests.post(url = api_endpoint, data = data).json()
        articles_list = r[""articles""] 
        articles_list_normalized = json_normalize(articles_list)
        df = articles_list_normalized
        df['publication_timestamp'] = pd.to_datetime(df['publication_timestamp'])
        df['publication_timestamp'] = df['publication_timestamp'].apply(lambda x: x.now().strftime('%Y-%m-%d'))
        df.to_excel(writer, sheet_name = city_name)
        writer.save()
</code></pre>

<p>The current issue I am facing is only one tab is getting created in the excel sheet for the first city ""Atlanta,GA"" I pull the data for from the API. How to create the tab for each and every city in the directory or does my code has any issue?</p>
"
60059964,"<p>I'm trying to do some basing textmining stuff on current research texts. I have an existing code base I used with previous researches, utilizing a WordNetLemmatizer from nltk to - among other things - get the singular form of plural nouns. This has been working pretty good so far.</p>

<p>Now I found a noun WordNetLemmatizer doesn't know.</p>

<pre><code>from nltk.stem import WordNetLemmatizer
&gt;&gt;&gt; lemmatizer = WordNetLemmatizer()
&gt;&gt;&gt; lemmatizer.lemmatize('coronaviruses')
</code></pre>

<p>The result is:</p>

<blockquote>
  <p>'coronaviruses'</p>
</blockquote>

<p>The output I'd expect would be:</p>

<blockquote>
  <p>'coronavirus'</p>
</blockquote>

<p>It works just fine with viruses:</p>

<pre><code>&gt;&gt;&gt; lemmatizer.lemmatize('viruses')
</code></pre>

<blockquote>
  <p>'virus'</p>
</blockquote>

<p>Can I somehow add coronaviruses / coronavirus to wordnet?</p>
"
61046790,"<p>I am trying to get <code>href</code> data for the below url </p>

<pre><code>url = r'https://pubmed.ncbi.nlm.nih.gov/?term=COVID-19&amp;filter=simsearch1.fha&amp;page=1'
</code></pre>

<p>using below code</p>

<pre><code>lxml.html.fromstring(url).xpath('//div[contains(@class,""inner-wrap"")]//div/a[contains(@class,""labs-docsum-title"")]//@href')
</code></pre>

<p>i have tried a number of other alternatives for the string inside the xpath such as </p>

<pre><code>.xpath('.//div/a/@href')
</code></pre>

<p>and</p>

<pre><code>.xpath(r'/html/body/main/div[8]/div[2]/section/div[1]/div/article[1]/div[2]/div[1]/a[1]/@href')
</code></pre>

<p>but i get an empty <code>[]</code> every time. I believe that I am not getting the hierarchy (parent-child) tree correct but not able to figure out what is wrong. My desired solution could look something like:</p>

<pre><code>print(href)
""/32139372/?from_term=COVID-19&amp;from_filter=simsearch1.fha&amp;from_page=1&amp;from_pos=1"" 
</code></pre>

<p>for the fist item in the iteration</p>
"
60840124,"<p>I am extending the Virus on Network <a href=""https://github.com/projectmesa/mesa/tree/master/examples/virus_on_network"" rel=""nofollow noreferrer"">example</a> from Mesa. The current network graph is like this. However, I want to remove the edges from the dead hosts (black). </p>

<p><a href=""https://i.stack.imgur.com/1YqDA.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/1YqDA.jpg"" alt=""enter image description here""></a></p>

<p>My attempt is within the <code>try_check_death()</code>:</p>

<p><code>model_agent.py</code></p>

<pre><code>import random
import pysnooper
import sys

from random import randrange
from mesa import Agent
from .model_state import State

class HostAgent(Agent):
    def __init__(self, unique_id, model, initial_state, virus_check_frequency, chance_spread_virus,
                 chance_recovery, chance_gain_resistance, chance_virus_kill_host, chance_severe_condition):
        super().__init__(unique_id, model)

        self.age = randrange(101) # Later to be reassign by another module (AB, Edmonton, Calgary specific)
        self.sex = random.choice(['M', 'F']) # Later to be reassign by another module (AB, Edmonton, Calgary specific)
        self.urban = random.choice(['Urban', 'Rural']) # Later to be reassign by another module (AB, Edmonton, Calgary specific); later to be interact with agent location and link assignment

        self.state = initial_state
        self.virus_check_frequency = virus_check_frequency
        self.chance_spread_virus = chance_spread_virus
        self.chance_recovery = chance_recovery
        self.chance_gain_resistance = chance_gain_resistance
        self.chance_virus_kill_host = chance_virus_kill_host
        self.chance_severe_condition = chance_severe_condition

        self.days_of_infection = None
        self.days_in_hospital_for_infection = None
        self.infection_severity = None
        self.clinical_outcomes_from_infection = None
        self.clinical_outcomes_after_recovery = None

    def modify_chance(self): # a generic function that modify chance attributes
        pass

    def try_infect_neighbors(self):
        neighbors_nodes = self.model.grid.get_neighbors(self.pos, include_center=False)
        susceptible_neighbors = [agent for agent in self.model.grid.get_cell_list_contents(neighbors_nodes) if
                                 agent.state is State.SUSCEPTIBLE]

        for neighbor_agent in susceptible_neighbors:
            if self.random.random() &lt; self.chance_spread_virus:
                neighbor_agent.state = State.INFECTED

    def try_gain_resistance(self):
        if self.random.random() &lt; self.chance_gain_resistance:
            self.state = State.RESISTANT

    def try_remove_infection(self):
        # Try to remove
        if self.random.random() &lt; self.chance_recovery:
            # Success
            self.state = State.SUSCEPTIBLE
            self.try_gain_resistance()
        else:
            # Failed
            self.state = State.INFECTED

    def try_kill_host(self):
        if self.random.random() &lt; self.chance_virus_kill_host:
            self.state = State.DEATH

    def try_check_infection(self):
        if self.random.random() &lt; self.virus_check_frequency:
            # Checking...
            if self.state is State.INFECTED:
                self.try_remove_infection()

    def try_check_death(self):
        if self.state is State.INFECTED:
            self.try_kill_host()

            if self.state is State.DEATH:
                neighbors_nodes = self.model.grid.get_neighbors(self.pos, include_center=False)
                neighbor_agents = [neighbor for neighbor in self.model.grid.get_cell_list_contents(neighbors_nodes)]
                agent_neighbor_pairs = [(self.unique_id, neighbor.unique_id) for neighbor in neighbor_agents]
                self.model.G.remove_edges_from(agent_neighbor_pairs)

    def step(self):
        if self.state is State.INFECTED:
            self.try_infect_neighbors()
        self.try_check_death()
        self.try_check_infection()
</code></pre>

<p><code>model_network.py</code></p>

<pre><code>import math
import sys
import networkx as nx

from mesa import Model
from mesa.time import RandomActivation
from mesa.datacollection import DataCollector
from mesa.space import NetworkGrid

from .model_state import State, number_infected, number_susceptible, number_resistant, number_state, number_death
from .model_agent import HostAgent

class HostNetwork(Model):
    """"""A virus model with some number of agents""""""

    def __init__(self, num_nodes=0, avg_node_degree=0, initial_outbreak_size=1, chance_spread_virus=0.0,
                    virus_check_frequency=0.0, chance_recovery=0.0, chance_gain_resistance=0.0,
                    chance_virus_kill_host=0.1, chance_severe_condition=0.0):

        # Some assert statement to make sure some chances together don't add up &gt; 1.0

        self.num_nodes = num_nodes
        prob = avg_node_degree / self.num_nodes
        self.G = nx.erdos_renyi_graph(n=self.num_nodes, p=prob)
        self.grid = NetworkGrid(self.G)
        self.schedule = RandomActivation(self)
        self.initial_outbreak_size = initial_outbreak_size if initial_outbreak_size &lt;= num_nodes else num_nodes
        self.chance_spread_virus = chance_spread_virus
        self.virus_check_frequency = virus_check_frequency
        self.chance_recovery = chance_recovery
        self.chance_gain_resistance = chance_gain_resistance
        self.chance_virus_kill_host = chance_virus_kill_host
        self.chance_severe_condition = chance_severe_condition

        self.datacollector = DataCollector({""Infected"": number_infected,
                                            ""Susceptible"": number_susceptible,
                                            ""Resistant"": number_resistant,
                                            ""Death"": number_death,
                                            })

        # Create agents
        for i, node in enumerate(self.G.nodes()):
            agent = HostAgent(i, self, State.SUSCEPTIBLE, self.chance_spread_virus, self.virus_check_frequency,
                                self.chance_recovery, self.chance_gain_resistance, self.chance_virus_kill_host,
                                self.chance_severe_condition)
            self.schedule.add(agent)
            # Add the agent to the node
            self.grid.place_agent(agent, node)

        # Infect some nodes
        infected_nodes = self.random.sample(self.G.nodes(), self.initial_outbreak_size)
        for agent in self.grid.get_cell_list_contents(infected_nodes):
            agent.state = State.INFECTED

        self.running = True
        self.datacollector.collect(self)

    def resistant_susceptible_ratio(self):
        try:
            return number_state(self, State.RESISTANT) / number_state(self, State.SUSCEPTIBLE)
        except ZeroDivisionError:
            return math.inf

    def step(self):
        self.schedule.step()
        # collect data
        self.datacollector.collect(self)

    def run_model(self, n):
        for i in range(n):
            self.step()
</code></pre>

<p><code>server.py</code></p>

<pre><code>import sys
import math

from mesa.visualization.ModularVisualization import ModularServer
from mesa.visualization.UserParam import UserSettableParameter
from mesa.visualization.modules import ChartModule
from mesa.visualization.modules import NetworkModule
from mesa.visualization.modules import TextElement

from .model_network import HostNetwork
from .model_state import State, number_infected, number_susceptible, number_resistant, number_death


def network_portrayal(G):
    # The model ensures there is always 1 agent per node

    def node_color(agent):
        return {
            State.INFECTED: '#FF0000',
            State.SUSCEPTIBLE: '#008000',
            State.DEATH: '#000000',
        }.get(agent.state, '#00C5CD')

    def edge_color(agent1, agent2):
        if State.RESISTANT in (agent1.state, agent2.state):
            return '#000000'
        return '#e8e8e8'

    def edge_width(agent1, agent2):
        if State.RESISTANT in (agent1.state, agent2.state):
            return 1
        else:
            return 3

    def get_agents(source, target):
        return G.nodes[source]['agent'][0], G.nodes[target]['agent'][0]

    portrayal = dict()
    portrayal['nodes'] = [{'size': 6,
                           'color': node_color(agents[0]),
                           'tooltip': ""id: {}&lt;br&gt;state: {}"".format(agents[0].unique_id, agents[0].state.name),
                           }
                          for (_, agents) in G.nodes.data('agent')]

    portrayal['edges'] = [{'source': source,
                           'target': target,
                           'color': edge_color(*get_agents(source, target)),
                           'width': edge_width(*get_agents(source, target)),
                           }
                          for (source, target) in G.edges]

    return portrayal


network = NetworkModule(network_portrayal, 500, 500, library='d3')
chart = ChartModule([{'Label': 'Infected', 'Color': '#FF0000'},
                     {'Label': 'Susceptible', 'Color': '#008000'},
                     {'Label': 'Resistant', 'Color': '#00C5CD'},
                     {'Label': 'Death', 'Color': '#000000'},
                     ])


class MyTextElement(TextElement):
    def render(self, model):
        ratio = model.resistant_susceptible_ratio()
        resistance_susceptible_ratio_text = '&amp;infin;' if ratio is math.inf else '{0:.2f}'.format(ratio)
        infected_text = str(number_infected(model))
        susceptible_text = str(number_susceptible(model))
        resistant_text = str(number_resistant(model))
        death_text = str(number_death(model))

        return ""Resistant/Susceptible Ratio: {}\
                &lt;br&gt;Infected Number: {}\
                &lt;br&gt;Susceptible Number: {}\
                &lt;br&gt;Resistant Number: {}\
                &lt;br&gt;Death Number: {}\
               "".format(resistance_susceptible_ratio_text, infected_text, susceptible_text,
                        resistant_text, death_text)


model_params = {
    'num_nodes': UserSettableParameter('slider', 'Number of agents', 10, 10, 300, 1,
                                       description='Choose how many agents to include in the model'),
    'avg_node_degree': UserSettableParameter('slider', 'Avg Node Degree', 2, 1, 8, 1,
                                             description='Avg Node Degree'),
    'initial_outbreak_size': UserSettableParameter('slider', 'Initial Outbreak Size', 1, 1, 100, 1,
                                                   description='Initial Outbreak Size'),
    'chance_spread_virus': UserSettableParameter('slider', 'Chance to spread virus', 0.4, 0.0, 1.0, 0.1,
                                                 description='Probability that susceptible neighbor will be infected'),
    'virus_check_frequency': UserSettableParameter('slider', 'Virus Check Frequency', 0.4, 0.0, 1.0, 0.1,
                                                   description='Frequency the nodes check whether they are infected by '
                                                               'a virus'),
    'chance_recovery': UserSettableParameter('slider', 'Chance to recover', 0.3, 0.0, 1.0, 0.1,
                                             description='Probability that the virus will be removed'),
    'chance_gain_resistance': UserSettableParameter('slider', 'Chance to gain resistance', 0.5, 0.0, 1.0, 0.1,
                                                    description='Probability that a recovered agent will become '
                                                                'resistant to this virus in the future'),
}

server = ModularServer(HostNetwork, [network, MyTextElement(), chart], 'Covid-19 Model', model_params)
server.port = 8521
</code></pre>

<p><code>self.model.G.remove_edges_from(agent_neighbor_pairs)</code> seems to give me troubles. What I am seeing is some duplicated nodes and edges similar (but not exactly the same) as the original graph.</p>

<p>One example:
<a href=""https://i.stack.imgur.com/S3HLd.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/S3HLd.jpg"" alt=""enter image description here""></a></p>

<p>Another example:
<a href=""https://i.stack.imgur.com/84Adb.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/84Adb.jpg"" alt=""enter image description here""></a></p>
"
60835750,"<p>I am trying to scrape a table from this website:</p>

<p><a href=""https://covidactnow.org/state/CA"" rel=""nofollow noreferrer"">https://covidactnow.org/state/CA</a></p>

<p>I am using the following code:</p>

<pre><code>import requests
from bs4 import BeautifulSoup

URL = 'https://covidactnow.org/state/CA'
page = requests.get(URL)

soup = BeautifulSoup(page.content, 'html.parser')

soup.find_all('tr')
</code></pre>

<p>I believed the code should find the table however it returns an empty list.</p>
"
61145610,"<p>Want to get total number 6968 or county level number from state health department website. but frustrated, can not get either way.</p>

<pre><code>from selenium import webdriver
import time
options = webdriver.ChromeOptions()
options.add_argument('--ignore-certificate-errors')
options.add_argument(""--test-type"")
#options.binary_location = ""/usr/bin/chromium""
driver = webdriver.Chrome(options=options)
driver.get('https://coronavirus.maryland.gov/')

#county level
table=driver.find_element_by_css_selector('table.topBlackBoxText')
for row in table.find_elements_by_css_selector('tr'):
    for cell in row.find_elements_by_tag_name('td'):
        print(cell.text)
#NoSuchElementException    

#total number
table=driver.find_elements_by_xpath(""//p[@class='topBoxH1Text']"")
for span in table:
    print(span)
#absolute path
table=driver.find_elements_by_xpath('//*[@id=""ember80""]/div/p[1]/text()[1]') 
</code></pre>

<p><a href=""https://i.stack.imgur.com/5p1bD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/5p1bD.png"" alt=""enter image description here""></a></p>
"
60838179,"<p>I am trying to update a worldmap tooltip using a slicer or dropdown select. I got following question which sorted the most of the stuff for a <a href=""https://stackoverflow.com/questions/50689700/bokeh-slider-custom-js-callback"">Bokeh Slider custom JS callback</a></p>

<pre><code>
import pandas as pd
import random
from datetime import timedelta

df = pd.DataFrame({'base' : [""2017-01-01"" for t in range(10000)],
    'Date' : [random.randint(0, 1035) for t in range(10000)], 
                   'Sales' : [random.random() for t in range(10000)]})
df['base'] = pd.to_datetime(df['base'])
df[""Date2""] = df.apply(lambda x: x[""base""] + timedelta(days=x['Date']), axis=1)
df.drop(['base', 'Date'], axis=1, inplace=True)
df.set_index('Date2', inplace=True)
df['month'] = df.index.month
df['year'] = df.index.year
df['day'] = df.index.day
df.head()

from bokeh.models.widgets import Slider,Select
from bokeh.io import output_notebook, show, output_file

from bokeh.layouts import widgetbox, column
from bokeh.models import Slider, ColumnDataSource, CustomJS
from bokeh.plotting import figure, curdoc
from bokeh.core.properties import value
from bokeh.models.ranges import FactorRange
from bokeh.plotting import figure, output_file, show, ColumnDataSource
from bokeh.models import ColumnDataSource, CDSView, IndexFilter, BooleanFilter, HoverTool


source1=df.groupby(['year','month','day'], as_index = False).sum()
source = source1[source1['year']== 2017]
sourcex = source[source['month'] ==1]
Overall=ColumnDataSource(source)
Curr=ColumnDataSource(sourcex)
boolinit = source['month']==1
view = CDSView(source=Overall, filters=[BooleanFilter(boolinit)])
hover3 = HoverTool(tooltips = [('day', '@day'),('Sales','@{Sales}{0,0}')],
                   formatters = {'day': 'datetime','Sales': 'numeral'})

p =  figure(title='YEARLY SALES',  plot_width=600, plot_height=400, min_border=3,
tools = [hover3,'box_zoom','wheel_zoom', 'pan','reset'],  
toolbar_location=""above"")

r = p.vbar(x='day', top='Sales', width=0.2, color='#e8bc76', source=Curr)
p.xaxis.axis_label = 'Day'
p.xaxis.axis_label_text_font_style = 'normal'
p.xaxis.axis_label_text_font_size = '12pt'



callback = CustomJS(args=dict(source=Overall, sc=Curr), code=""""""       
        var f = select.value;
        sc.data['day'] = [];
        sc.data['Sales'] = [];
        for (var i = 0; i &lt;= source.get_length(); i++){
          if (source.data['month'][i] == f){
            sc.data['day'].push(source.data['day'][i])
            sc.data['Sales'].push(source.data['Sales'][i])
          }
        }
        sc.change.emit();
    """""")
select = Select(options=[""1"",""2"",""3""], title=""Month"", callback=callback)
callback.args[""select""] = select

layout = column(select, p)
#Display plot inline in Jupyter notebook
output_notebook()
output_file(""Filterdata.html"")
show(layout)

</code></pre>

<p>Now, I replicated the same for a worldmap as below:</p>

<pre><code>import pandas as pd
import geopandas as gpd
current_week = 4
shapefile = 'data/countries_110m/ne_110m_admin_0_countries.shp'
gdf = gpd.read_file(shapefile)[['ADMIN', 'ADM0_A3', 'geometry']]
gdf.columns = ['country', 'country_code', 'geometry']
gdf = gdf.drop(gdf.index[159])
df = pd.DataFrame({'Country':['India','India'],
              'SalesGain':['10%','20%'],
                   'Week':[4,5],
                   'Color':[0.2,0.4]
             })

import json
from bokeh.models.widgets import Slider,Select
from bokeh.io import output_notebook, show, output_file
from bokeh.layouts import widgetbox, column
from bokeh.models import Slider, ColumnDataSource, CustomJS
from bokeh.plotting import figure, curdoc
from bokeh.core.properties import value
from bokeh.models.ranges import FactorRange
from bokeh.palettes import brewer
from bokeh.plotting import figure, output_file, show, ColumnDataSource
from bokeh.models import ColumnDataSource, CDSView, IndexFilter, BooleanFilter, HoverTool,GeoJSONDataSource, LinearColorMapper, ColorBar

from bokeh.plotting import figure, output_file, show
output_file(""worldmap.html"")


merged = gdf.merge(df, left_on = 'country', right_on = 'Country', how = 'left')
merged_json = json.loads(merged.to_json())
json_data = json.dumps(merged_json)
geosource_all = GeoJSONDataSource(geojson =  json_data)

df_curr = df[df['Week']==current_week]
merged_curr = gdf.merge(df_curr, left_on = 'country', right_on = 'Country', how = 'left')
merged_json_curr = json.loads(merged_curr.to_json())
json_data_curr = json.dumps(merged_json_curr)
geosource_curr = GeoJSONDataSource(geojson =  json_data_curr)


# boolinit = merged['Week']!=current_week
boolinit = merged['Week']==current_week
view = CDSView(source=geosource_all, filters=[BooleanFilter(boolinit)])
hover3 = HoverTool(tooltips = [('Country', '@Country'),('Sales','@SalesGain')])

#Define a sequential multi-hue color palette.
palette = brewer['YlGnBu'][8]
#Reverse color order so that dark blue is highest value
palette = palette[::-1]
#Instantiate LinearColorMapper that linearly maps numbers in a range, into a sequence of colors. Input nan_color.
color_mapper = LinearColorMapper(palette = palette, low = 0, high = 12, nan_color = '#d9d9d9')
#Define custom tick labels for color bar.
tick_labels = {'0': '0', '2':'2%',  '4':'4%',  '6':'6%', '8':'8%','10':'10%','12':'12%'}
#Create color bar. 
color_bar = ColorBar(color_mapper=color_mapper, label_standoff=6,width = 500, height = 20,
                     border_line_color=None,location = (0,0), orientation = 'horizontal', major_label_overrides = tick_labels)


#Create figure object.
p =  figure(title='Covid-19 Impact',  plot_width=900, plot_height=600, min_border=3,
            tools = [hover3,'box_zoom','wheel_zoom', 'pan','reset'],toolbar_location=""above"")

p.title.text_font_size = '20pt'
p.title.text_color = ""darkblue""
p.xgrid.grid_line_color = None
p.ygrid.grid_line_color = None


#Add patch renderer to figure. 
p.patches('xs','ys', source = geosource_curr,fill_color = {'field' :'Color', 'transform' : color_mapper},
          line_color = 'black', line_width = 0.25, fill_alpha = 1)
p.add_layout(color_bar, 'below')


callback = CustomJS(args=dict(source=geosource_all, sc=geosource_curr), code=""""""       
        var f = slider.value;
        sc.data['Country'] = [];
        sc.data['Week'] = [];
        sc.data['SalesGain'] = [];
        for (var i = 0; i &lt;= source.get_length(); i++){
          if ((source.data['Week'][i] == f ) || (source.data['Country'][i] == null) ){
            sc.data['SalesGain'].push(source.data['SalesGain'][i])
            sc.data['Week'].push(source.data['Week'][i])
            sc.data['Country'].push(source.data['Country'][i])
          }
        }
        sc.change.emit();
    """""")
# select = Select(options=[""201951"",""201952"",""201953""], title=""Week"", callback=callback)
# callback.args[""select""] = select
# layout = column(select, p)

slider = Slider(start=1, end=5, value=current_week, step=1, title=""Month"", callback=callback)
callback.args[""slider""] = slider
layout = column(slider, p)

#Display plot inline in Jupyter notebook
output_notebook()

show(layout)

</code></pre>

<p>But in this case, as soon as I click on the slider, tooltip data vanish away. World map input file can be found here to smoothly run the code:
<a href=""https://github.com/CrazyDaffodils/Interactive-Choropleth-Map-Using-Python/tree/master/bokeh-app/data"" rel=""nofollow noreferrer"">https://github.com/CrazyDaffodils/Interactive-Choropleth-Map-Using-Python/tree/master/bokeh-app/data</a></p>
"
61281446,"<p>I have the following code that plots COVID-19 confirmed cases country-wise against some dates.</p>

<pre><code>import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates



df = pd.DataFrame({'Countries': ['Australia', 'India', 'UAE',  'UK'],
                   '3/1/20':    [   27,        3,   21,    36],
                   '3/2/20':    [   30,        5,   21,    40],
                   '3/3/20':    [   39,        5,   27,    51],
                   '3/4/20':    [   52,        28,   27,    86],
                   },
                   index = [0, 1, 2, 3])

print('Datframe:\n')
print(df)

dft=df.T
print('\n Transposed data:\n')
print(dft)

print(dft.columns)
dft.columns=dft.iloc[0]
dft=dft[1:]
print('\n Final data:\n')
print(dft)


dft.plot.bar(align='center')

# Set date ticks with 2-day interval
plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=2))

# Change date format
plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))

''' Note: If I comment above two lines, I get back x-axis ticks. '''

# Autoformatting dates ticks
plt.gcf().autofmt_xdate()
plt.title('COVID-19 confirmed cases')

plt.show()
</code></pre>

<p>Here I intended to show the dates on the x-axis ticks with 2-day intervals and get the dates formatted in a different style. However, in the plot, I don't get any ticks and labels on the x-axis as shown in the figure below. </p>

<p><a href=""https://i.stack.imgur.com/ndTOO.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ndTOO.png"" alt=""enter image description here""></a></p>

<p>However, when I comment out the instructions with <code>matplotlib.dates</code>, I get back the x-ticks and labels. </p>

<p>Can this be explained and fixed in a simple way? Also, can we get the same result using <code>fig, ax = plt.subplots()</code>?</p>
"
60898418,"<p>To help fight covid19 here in the Philippines, I'm trying to do data analysis. My data source is table of incidences in Wikipedia. See <a href=""https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_the_Philippines"" rel=""nofollow noreferrer"">https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_the_Philippines</a></p>

<p>Tried to get table in python with Beautiful soup but I cannot seem to get the content of the columns [Facility of admission or consultation, Had recent travel history abroad]. See screenshot:</p>

<p><img src=""https://i.stack.imgur.com/EHwa5.png"" alt=""Screenshot of dataframe result""></p>

<p>What am I doing wrong?</p>

<p>Here's my code: (can also be found here <a href=""https://github.com/gio888/covid19_ph2/blob/master/covid_import_from_wikipedia.ipynb"" rel=""nofollow noreferrer"">https://github.com/gio888/covid19_ph2/blob/master/covid_import_from_wikipedia.ipynb</a>)</p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
import requests
from bs4 import BeautifulSoup
url = ""https://en.wikipedia.org/wiki/Template:2019%E2%80%9320_coronavirus_pandemic_data/Philippines_medical_cases_summary""
page = requests.get(url)
soup = BeautifulSoup(page.content, 'html.parser')
table = soup.find('table', class_='wikitable')

n_columns = 0
n_rows=0
column_names = []

for row in table.find_all('tr'):
   td_tags = row.find_all('td')
   if len(td_tags) &gt; 0:
      n_rows+=1
      if n_columns == 0:
         n_columns = len(td_tags)

   th_tags = row.find_all('th') 
   if len(th_tags) &gt; 0 and len(column_names) == 0:
      for th in th_tags:
         column_names.append(th.get_text())

columns = column_names if len(column_names) &gt; 0 else range(0,n_columns)
df = pd.DataFrame(columns = columns,index= range(0,n_rows))

row_marker = 0
for row in table.find_all('tr'):
   column_marker = 0
   columns = row.find_all('td')
   for column in columns:
      df.iat[row_marker,column_marker] = column.get_text()
      column_marker += 1
   if len(columns) &gt; 0:
      row_marker += 1

for col in df:
   try:
      df[col] = df[col].astype(float)
   except ValueError:
      pass

df
</code></pre>
"
60702573,"<p>It is simple to extract all content in <code>p</code> node with lxml,i extract all content from the webpage's <code>p</code> node,and write it into a file <code>/tmp/content1.txt</code> with the following code .</p>

<pre><code>import urllib.request
import lxml.html
url = 'https://www.statnews.com/pharmalot/2020/03/13/gilead-coronavirus-covid19-clinical-trials/'
ob=urllib.request.urlopen(url).read()
root=lxml.html.document_fromstring(ob)
content=root.xpath(""//p"")
with open('/tmp/content1.txt','w') as fh:
    for etxt in content:
        fh.write(etxt.text_content() + '\n') 
</code></pre>

<p>Now make the same job with selenium,write the parsed content in <code>content2.txt</code>.</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By

chrome_options = Options()
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
chrome_options.add_argument(""--headless"")
browser = webdriver.Chrome(options=chrome_options,executable_path='/usr/bin/chromedriver')

wait = WebDriverWait(browser, 30)
url = 'https://www.statnews.com/pharmalot/2020/03/13/gilead-coronavirus-covid19-clinical-trials/'
browser.get(url)
wait.until(lambda e: e.execute_script('return document.readyState') != ""loading"")
wait.until(EC.presence_of_all_elements_located([By.CSS_SELECTOR, ""p""]))
content = browser.find_elements_by_xpath('//p')
with open('/tmp/content2.txt','w') as fh:
    for etxt in content:
        fh.write(etxt.text + '\n')
</code></pre>

<p>Do as Svetlana Levinsohn suggest:try removing chrome_options.add_argument(""--headless"").</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By

chrome_options = Options()
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
browser = webdriver.Chrome(options=chrome_options,executable_path='/usr/bin/chromedriver')

wait = WebDriverWait(browser, 30)
url = 'https://www.statnews.com/pharmalot/2020/03/13/gilead-coronavirus-covid19-clinical-trials/'
browser.get(url)
wait.until(lambda e: e.execute_script('return document.readyState') != ""loading"")
wait.until(EC.presence_of_all_elements_located([By.CSS_SELECTOR, ""p""]))
content = browser.find_elements_by_xpath('//p')
with open('/tmp/content3.txt','w') as fh:
    for etxt in content:
        fh.write(etxt.text + '\n')
</code></pre>

<p>To compare <code>content1.txt</code> and <code>content2.txt</code> and <code>content3.txt</code>.</p>

<pre><code>cd  /tmp
wc -c content1.txt
11442 content1.txt
wc -c content2.txt
838 content2.txt
wc -c /tmp/content3.txt
12105 /tmp/content3.txt
</code></pre>

<p>1.Why get more lines when to remove <code>chrome_options.add_argument(""--headless"")</code> with selenium ?Why is the principle behind this action?<br>
2.Is there a way to get such the same content with selenium as with lxml? </p>

<p>Do as supputuri suggested,to change the last line into <code>fh.write(etxt.get_attribute(""textContent"") + '\n')</code>,issue still remains.</p>

<pre><code>wc -c content1.txt
12402 content1.txt
wc -c content2.txt
12410 content2.txt
</code></pre>

<p>Let's check why content2.txt is 8 bytes more than content1.txt.</p>

<pre><code>diff content1.txt  content2.txt
1c1
&lt; By Ed Silverman @Pharmalot 
---
&gt; By Ed Silverman2 @Pharmalot3 
3,4c3,4
&lt; As anticipation mounts over the prospects for an experimental Gilead Sciences (GILD) drug to combat the novel coronavirus, two Wall Street analysts suggested it remains uncertain whether the antiviral therapy will be successful after assessing a new paper that examined a dozen U.S. patients.
&lt; The paper, published on a preprint server without peer review, described the epidemiology, clinical course, and viral characteristics of the first 12 U.S. patients with Covid-19, only three of whom were treated with remdesivir, which was developed to treat the Ebola virus but shelved after proving less effective than other drugs during testing. The analysis was conducted by the Centers for Disease Control and Prevention Covid-19 response team.
---
&gt; As anticipation mounts over the prospects for an experimental Gilead Sciences (GILD4) drug to combat the novel coronavirus, two Wall Street analysts suggested it remains uncertain whether the antiviral therapy will be successful after assessing a new paper that examined a dozen U.S. patients.
&gt; The paper5, published on a preprint server without peer review, described the epidemiology, clinical course, and viral characteristics of the first 12 U.S. patients with Covid-19, only three of whom were treated with remdesivir, which was developed to treat the Ebola virus but shelved after proving less effective than other drugs during testing. The analysis was conducted by the Centers for Disease Control and Prevention Covid-19 response team.
22,24c22,24
&lt; Coronavirus
&lt; drug development
&lt; research
---
&gt; Coronavirus10
&gt; drug development11
&gt; research12
26c26
&lt;                                   Republish this article
---
&gt;                                   Republish this article13
59c59
&lt; 👍
---
&gt; 
</code></pre>

<p>Bytes in content2.txt ,not in content1.txt.</p>

<p>line1    2,3
  line3-4  4,5
  line22-24  10,11,12
  line26     13</p>

<p><code>4</code> bytes to store 2,3,4,5
<code>8</code> bytes to store  10,11,12,13</p>

<p>Bytes in content1.txt ,not in content2.txt.</p>

<pre><code>line59  👍
</code></pre>

<p>For 👍,it needs 4 bytes <code>f09f918d</code> to store .</p>

<pre><code>4+8-4 = 8 = 12410-12402
</code></pre>

<p>Note : the content parsed by lxml or selenium change dynamically,you maybe get different bytes for content1.txt and content2.txt.</p>

<p>It is time to check another important issue.<br>
For the first line in content1.txt parsed by lxml.</p>

<pre><code>By Ed Silverman @Pharmalot 
</code></pre>

<p>For the first line in content2.txt parsed by selenium.</p>

<pre><code>By Ed Silverman2 @Pharmalot3 
</code></pre>

<p>Why selenium add <code>2</code> and <code>3</code> here?<code>selenium</code> add some numbers which is not in original webpage,what do them mean?<br>
And i have never seen javascript code to change the dom tree of the webpage.<br>
How to prevent selenium from adding the numbers when to get <code>get_attribute(""textContent"")</code>?</p>

<p><code>Vladimir M</code> gave a notice that all numbers are in the original site.
I made a verification.</p>

<pre><code>import urllib.request
import lxml.html
url = 'https://www.statnews.com/pharmalot/2020/03/13/gilead-coronavirus-covid19-clinical-trials/'
ob=urllib.request.urlopen(url).read()
root=lxml.html.document_fromstring(ob)
content=root.xpath(""//p[@class='author']"")[0]
lxml.html.tostring(content)
</code></pre>

<p>We get the html source code:</p>

<pre><code> b'&lt;p class=""author""&gt;
     &lt;em&gt;By&lt;/em&gt; 
     &lt;a ...&gt;Ed  Silverman&lt;/a&gt; 
     &lt;a ...&gt;@Pharmalot&lt;/a&gt; 
   &lt;/p&gt;'
</code></pre>

<p>Do not contain such tag <code>sup</code> as  <code>Vladimir M</code> show: </p>

<pre><code>&lt;p class=""author""&gt;
  &lt;em&gt;By&lt;/em&gt; 
  &lt;a ...&gt;Ed Silverman&lt;/a&gt;
  &lt;sup class=""footnote""&gt;3&lt;/sup&gt; 
  &lt;a ...&gt;@Pharmalot&lt;/a&gt;
  &lt;sup class=""footnote""&gt;4&lt;/sup&gt; 
&lt;/p&gt;
</code></pre>

<p>If the original source html code contain <code>sup</code> tag,<code>text_content</code> in lxml can show it.</p>

<pre><code>import lxml.html as lh
data = """"""&lt;p class=""author""&gt;&lt;em&gt;By&lt;/em&gt; &lt;a href=""https://www.statnews.com/staff/ed-silverman/"" \
class=""author-name-link author-name author-main""&gt;Ed Silverman&lt;/a&gt;&lt;sup class=""footnote""&gt;3&lt;/sup&gt; \
&lt;a href=""https://twitter.com/Pharmalot"" class=""author-social"" target=""_blank"" rel=""noopener""&gt;  \
@Pharmalot&lt;/a&gt;&lt;sup class=""footnote""&gt;4&lt;/sup&gt; &lt;/p&gt;""""""
doc = lh.fromstring(data)
data = doc.xpath('//p')[0]
print(data.text_content())
</code></pre>

<p>It output the below:</p>

<pre><code>By Ed Silverman3   @Pharmalot4 
</code></pre>

<p>I infer  that the two tag <code>sup</code> were created by some javascript code.<br>
To improve my javascript knowledge ,the last issue is related with js:<br>
How to know which js file create the number located at <code>&lt;p class=""author""&gt;</code> node?<br>
Please answer it and get the 500 points.</p>
"
61367221,"<p>Here is the code, it produces what I want but not in the way I want to output the result</p>

<hr>

<pre><code>   import requests
    from bs4 import BeautifulSoup
    url = 'https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_Florida'

    fl = requests.get(url)
    fl_soup = BeautifulSoup(fl.text, 'html.parser')
    block = fl_soup.findAll('td', {'class': 'bb-04em'})

    for name in fl_soup.findAll('td', {'class': 'bb-04em'}):
        print(name.text)
</code></pre>

<hr>

<p>output</p>

<p>2020-04-21</p>

<p>27,869(+3.0%)</p>

<p>867</p>

<p>I would like the output like this
2020-04-21  27,869(+3.0%)  867</p>
"
60829084,"<p>I am trying to sum all columns based on the value of the first, but groupby.sum is unexpectedly not working. </p>

<p>Here is a minimal example:</p>

<pre><code>import pandas as pd
data = [['Alex',10, 11],['Bob',12, 10],['Clarke',13, 9], ['Clarke',1, 1]]
df = pd.DataFrame(data,columns=['Name','points1', 'points2'])
print(df)

df.groupby('Name').sum()

print(df)
</code></pre>

<p>I get this:</p>

<pre><code>     Name  points1  points2
0    Alex       10       11
1     Bob       12       10
2  Clarke       13        9
3  Clarke        1        1
</code></pre>

<p>And not this:</p>

<pre><code>     Name  points1  points2
0    Alex       10       11
1     Bob       12       10
2  Clarke       14       10
</code></pre>

<p>From what i understand, the dataframe is not the right format for pandas to perform group by. I would like to understand what is wrong with it because this is just a toy example but i have the same problem with a real data-set.</p>

<p>The real data i'm trying to read is the John Hopkins University Covid-19 dataset:</p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series</a></p>
"
61002031,"<p>I have built a small Dash app in Python and was successfully able to deploy it on Heroku. The link is here: <a href=""https://covid19-datachallenge-uconn.herokuapp.com/"" rel=""nofollow noreferrer"">https://covid19-datachallenge-uconn.herokuapp.com/</a></p>

<p>However, I tried doing the same on Microsoft Azure and I am getting the following error. I am using this link to do the deployment: <a href=""https://www.phillipsj.net/posts/deploying-dash-to-azure-app-service/"" rel=""nofollow noreferrer"">https://www.phillipsj.net/posts/deploying-dash-to-azure-app-service/</a></p>

<pre><code>2020-04-02T22:09:27.884279395Z Documentation: http://aka.ms/webapp-linux
2020-04-02T22:09:27.884282895Z Python 3.7.5
2020-04-02T22:09:27.884286595Z Note: Any data outside '/home' is not persisted
2020-04-02T22:09:27.945960082Z Starting OpenBSD Secure Shell server: sshd.
2020-04-02T22:09:27.957890157Z App Command Line not configured, will attempt auto-detect
2020-04-02T22:09:27.958488560Z Launching oryx with: -appPath /home/site/wwwroot -output /opt/startup/startup.sh -virtualEnvName antenv -defaultApp /opt/defaultsite -bindPort 8000
2020-04-02T22:09:27.961805781Z Oryx Version: 0.2.20200114.13, Commit: 204922f30f8e8d41f5241b8c218425ef89106d1d, ReleaseTagName: 20200114.13
2020-04-02T22:09:27.963589692Z Cound not find build manifest file at '/home/site/wwwroot/oryx-manifest.toml'
2020-04-02T22:09:27.963980095Z Could not find operation ID in manifest. Generating an operation id...
2020-04-02T22:09:27.964420697Z Build Operation ID: bb8a66d5-6773-4d7e-b210-6f10ca6ab9f8
2020-04-02T22:09:28.553535793Z Detected an app based on Flask
2020-04-02T22:09:28.870188279Z Generating `gunicorn` command for 'application:app'
2020-04-02T22:09:29.171148066Z Writing output script to '/opt/startup/startup.sh'
2020-04-02T22:09:29.368125402Z WARNING: Could not find virtual environment directory /home/site/wwwroot/antenv.
2020-04-02T22:09:29.368839706Z WARNING: Could not find package directory /home/site/wwwroot/__oryx_packages__.
2020-04-02T22:09:29.575754204Z [2020-04-02 22:09:29 +0000] [37] [INFO] Starting gunicorn 20.0.4
2020-04-02T22:09:29.577338814Z [2020-04-02 22:09:29 +0000] [37] [INFO] Listening at: http://0.0.0.0:8000 (37)
2020-04-02T22:09:29.577878817Z [2020-04-02 22:09:29 +0000] [37] [INFO] Using worker: sync
2020-04-02T22:09:29.585273464Z [2020-04-02 22:09:29 +0000] [40] [INFO] Booting worker with pid: 40
2020-04-02T22:09:29.733903996Z [2020-04-02 22:09:29 +0000] [40] [ERROR] Exception in worker process
2020-04-02T22:09:29.733937196Z Traceback (most recent call last):
2020-04-02T22:09:29.733943196Z   File ""/opt/python/3.7.5/lib/python3.7/site-packages/gunicorn/arbiter.py"", line 583, in spawn_worker
2020-04-02T22:09:29.733947796Z     worker.init_process()
2020-04-02T22:09:29.733951396Z   File ""/opt/python/3.7.5/lib/python3.7/site-packages/gunicorn/workers/base.py"", line 119, in init_process
2020-04-02T22:09:29.733963096Z     self.load_wsgi()
2020-04-02T22:09:29.733967196Z   File ""/opt/python/3.7.5/lib/python3.7/site-packages/gunicorn/workers/base.py"", line 144, in load_wsgi
2020-04-02T22:09:29.733970996Z     self.wsgi = self.app.wsgi()
2020-04-02T22:09:29.733974496Z   File ""/opt/python/3.7.5/lib/python3.7/site-packages/gunicorn/app/base.py"", line 67, in wsgi
2020-04-02T22:09:29.733978196Z     self.callable = self.load()
2020-04-02T22:09:29.733981596Z   File ""/opt/python/3.7.5/lib/python3.7/site-packages/gunicorn/app/wsgiapp.py"", line 49, in load
2020-04-02T22:09:29.733985396Z     return self.load_wsgiapp()
2020-04-02T22:09:29.733988897Z   File ""/opt/python/3.7.5/lib/python3.7/site-packages/gunicorn/app/wsgiapp.py"", line 39, in load_wsgiapp
2020-04-02T22:09:29.733992597Z     return util.import_app(self.app_uri)
2020-04-02T22:09:29.733996097Z   File ""/opt/python/3.7.5/lib/python3.7/site-packages/gunicorn/util.py"", line 358, in import_app
2020-04-02T22:09:29.733999897Z     mod = importlib.import_module(module)
2020-04-02T22:09:29.734003497Z   File ""/opt/python/3.7.5/lib/python3.7/importlib/__init__.py"", line 127, in import_module
2020-04-02T22:09:29.734007097Z     return _bootstrap._gcd_import(name[level:], package, level)
2020-04-02T22:09:29.734010597Z   File ""&lt;frozen importlib._bootstrap&gt;"", line 1006, in _gcd_import
2020-04-02T22:09:29.734014597Z   File ""&lt;frozen importlib._bootstrap&gt;"", line 983, in _find_and_load
2020-04-02T22:09:29.734018197Z   File ""&lt;frozen importlib._bootstrap&gt;"", line 967, in _find_and_load_unlocked
2020-04-02T22:09:29.734021797Z   File ""&lt;frozen importlib._bootstrap&gt;"", line 677, in _load_unlocked
2020-04-02T22:09:29.734025397Z   File ""&lt;frozen importlib._bootstrap_external&gt;"", line 728, in exec_module
2020-04-02T22:09:29.734029097Z   File ""&lt;frozen importlib._bootstrap&gt;"", line 219, in _call_with_frames_removed
2020-04-02T22:09:29.734032797Z   File ""/home/site/wwwroot/application.py"", line 2, in &lt;module&gt;
2020-04-02T22:09:29.734036497Z     import dash
2020-04-02T22:09:29.734039997Z ModuleNotFoundError: No module named 'dash'
2020-04-02T22:09:29.738362924Z [2020-04-02 22:09:29 +0000] [40] [INFO] Worker exiting (pid: 40)
2020-04-02T22:09:29.782459201Z [2020-04-02 22:09:29 +0000] [37] [INFO] Shutting down: Master
2020-04-02T22:09:29.783424607Z [2020-04-02 22:09:29 +0000] [37] [INFO] Reason: Worker failed to boot.


2020-04-02 22:09:30.001 ERROR - Container covid19-datachallenge-uconn_0_8ceb9c66 for site covid19-datachallenge-uconn has exited, failing site start
2020-04-02 22:09:30.004 ERROR - Container covid19-datachallenge-uconn_0_8ceb9c66 didn't respond to HTTP pings on port: 8000, failing site start. See container logs for debugging.
2020-04-02 22:09:30.014 INFO  - Stoping site covid19-datachallenge-uconn because it failed during startup.
</code></pre>

<p>I can see that it is happening because it is unable to import dash. The app is running fine is my localhost and virtual environment (as created for azure deployment as per the blog)</p>

<p>Please help!</p>
"
61571614,"<p>It is strange that 'Your app was successfully deployed.' was shown in Heroku dashboard but when clicking the 'View', it shows Application Error -->""An error occurred in the application and your page could not be served. If you are the application owner, check your logs for details. You can do this from the Heroku CLI with the command"". When I check the log in terminal, it shows below. I have attached requirements.txt in my github project. Anyone knows?</p>

<p>My github link: <a href=""https://github.com/Zakk-Yang/heroku_test"" rel=""nofollow noreferrer"">https://github.com/Zakk-Yang/heroku_test</a></p>

<pre><code>2020-05-02T19:33:24.000000+00:00 app[api]: Build failed -- check your build output: https://dashboard.heroku.com/apps/d509e851-0e0a-4c4f-b46f-c69ca1f19771/activity/builds/870305ce-1f94-4e25-8838-d3a2d3bde11b
2020-05-02T19:44:58.000000+00:00 app[api]: Build started by user abc@hotmail.com
2020-05-02T19:44:59.000000+00:00 app[api]: Build failed -- check your build output: https://dashboard.heroku.com/apps/d509e851-0e0a-4c4f-b46f-c69ca1f19771/activity/builds/7062835b-3c28-4d1e-894a-1ec232acee70
2020-05-02T19:46:05.000000+00:00 app[api]: Build started by user abc@hotmail.com
2020-05-02T19:46:06.000000+00:00 app[api]: Build failed -- check your build output: https://dashboard.heroku.com/apps/d509e851-0e0a-4c4f-b46f-c69ca1f19771/activity/builds/cbdac05d-8e51-4e6d-9c3e-89c1f9914e24
2020-05-02T19:48:46.000000+00:00 app[api]: Build started by user abc@hotmail.com
2020-05-02T19:48:47.000000+00:00 app[api]: Build failed -- check your build output: https://dashboard.heroku.com/apps/d509e851-0e0a-4c4f-b46f-c69ca1f19771/activity/builds/20d4b356-b440-4303-bb00-bb999388dad8
2020-05-02T19:53:30.000000+00:00 app[api]: Build started by user abc@hotmail.com
2020-05-02T19:56:33.476313+00:00 app[api]: Release v3 created by user abc@hotmail.com
2020-05-02T19:56:33.476313+00:00 app[api]: Deploy 3040a827 by user abc@hotmail.com
2020-05-02T19:57:30.000000+00:00 app[api]: Build succeeded
2020-05-02T19:58:26.000000+00:00 app[api]: Build started by user abc@hotmail.com
2020-05-02T20:00:45.417122+00:00 app[api]: Deploy 3040a827 by user abc@hotmail.com
2020-05-02T20:00:45.417122+00:00 app[api]: Release v4 created by user abc@hotmail.com
2020-05-02T20:01:47.000000+00:00 app[api]: Build succeeded
2020-05-02T20:04:33.506371+00:00 heroku[router]: at=error code=H14 desc=""No web processes running"" method=GET path=""/"" host=covid19streamlitdemo.herokuapp.com request_id=96e76633-7a47-4284-9f12-bb6588b76178 fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T20:04:34.059409+00:00 heroku[router]: at=error code=H14 desc=""No web processes running"" method=GET path=""/favicon.ico"" host=covid19streamlitdemo.herokuapp.com request_id=83cd8e9f-6ad6-4146-afb8-520a3fa15db5 fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T20:06:16.900305+00:00 heroku[router]: at=error code=H14 desc=""No web processes running"" method=GET path=""/"" host=covid19streamlitdemo.herokuapp.com request_id=fdda66dc-5892-42bf-b033-f80b2bef38c9 fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T20:06:17.311733+00:00 heroku[router]: at=error code=H14 desc=""No web processes running"" method=GET path=""/favicon.ico"" host=covid19streamlitdemo.herokuapp.com request_id=d24e7e75-8f31-49a3-9624-5c12eac58da1 fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T20:12:46.000000+00:00 app[api]: Build started by user abc@hotmail.com
2020-05-02T20:15:26.554818+00:00 app[api]: Deploy dcd7dbdf by user abc@hotmail.com
2020-05-02T20:15:26.554818+00:00 app[api]: Release v5 created by user abc@hotmail.com
2020-05-02T20:15:26.575162+00:00 app[api]: Scaled to web@1:Free by user abc@hotmail.com
2020-05-02T20:15:51.389986+00:00 heroku[web.1]: State changed from starting to crashed
2020-05-02T20:15:51.463093+00:00 heroku[web.1]: State changed from crashed to starting
2020-05-02T20:15:51.325104+00:00 app[web.1]: bash: gunicorn: command not found
2020-05-02T20:16:14.941058+00:00 heroku[web.1]: State changed from starting to crashed
2020-05-02T20:16:14.870393+00:00 app[web.1]: bash: gunicorn: command not found
2020-05-02T20:16:32.000000+00:00 app[api]: Build succeeded
2020-05-02T20:17:01.383913+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covid19streamlitdemo.herokuapp.com request_id=4eb4138e-1d97-4e47-8945-eb7e8d84f5e3 fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T20:17:01.722305+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=covid19streamlitdemo.herokuapp.com request_id=d64b4d30-6825-4239-b5d6-c3baf30dcc24 fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T20:31:51.000000+00:00 app[api]: Build started by user abc@hotmail.com
2020-05-02T20:34:29.210909+00:00 app[api]: Release v6 created by user abc@hotmail.com
2020-05-02T20:34:29.210909+00:00 app[api]: Deploy dcd7dbdf by user abc@hotmail.com
2020-05-02T20:34:30.707372+00:00 heroku[web.1]: State changed from crashed to starting
2020-05-02T20:34:53.655713+00:00 heroku[web.1]: State changed from starting to crashed
2020-05-02T20:34:53.728793+00:00 heroku[web.1]: State changed from crashed to starting
2020-05-02T20:34:53.599642+00:00 app[web.1]: bash: gunicorn: command not found
2020-05-02T20:35:16.967890+00:00 heroku[web.1]: State changed from starting to crashed
2020-05-02T20:35:16.905180+00:00 app[web.1]: bash: gunicorn: command not found
2020-05-02T20:35:25.000000+00:00 app[api]: Build succeeded
2020-05-02T20:37:00.519288+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covid19streamlitdemo.herokuapp.com request_id=b1d5afd4-0cf2-46f2-9491-6a6e0dee3001 fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T20:37:00.870318+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=covid19streamlitdemo.herokuapp.com request_id=e6e47cdd-a998-42a8-b6dd-71b1cee8b6ec fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T20:38:35.332641+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covid19streamlitdemo.herokuapp.com request_id=0cd8ab72-44ce-41af-a8a8-338d94e6b3b6 fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T20:38:35.558510+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=covid19streamlitdemo.herokuapp.com request_id=c6cd780c-f311-44ee-b1d2-fd41d2460d72 fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T20:57:20.114157+00:00 heroku[web.1]: State changed from crashed to starting
2020-05-02T20:57:45.023096+00:00 heroku[web.1]: State changed from starting to crashed
2020-05-02T20:57:44.955558+00:00 app[web.1]: bash: gunicorn: command not found
2020-05-02T21:15:25.725995+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covid19streamlitdemo.herokuapp.com request_id=c8d33f04-8e24-4597-89aa-283b5d745bbb fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T21:15:26.194574+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=covid19streamlitdemo.herokuapp.com request_id=e4c5c594-5840-4a10-a1fd-99e907021d45 fwd=""195.166.219.78"" dyno= connect= service= status=503 bytes= protocol=https
2020-05-02T21:32:05.000000+00:00 app[api]: Build started by user abc@hotmail.com
</code></pre>
"
61585462,"<p>Yesterday, I installed all the required modules and was running the flask app without any issues but today when I am trying to run it says No module named requests
So I downloaded it again, then it says no module named COVID19Py
I have set up my environment by using ..
- virtualenv env
- env\Scripts\activate.bat
Where am I going wrong ? Do I have to download those modules again whenever I restart my terminal ?</p>
"
61465497,"<p>I am deploying a flask app on a Centos7 server, the application is launched by <a href=""https://gunicorn.org/"" rel=""nofollow noreferrer"">gunicorn</a> on <code>localhost:8000</code> through:
<code>venv/bin/gunicorn -b localhost:8000 -w 4 microblog:app</code></p>

<p>This port is then forwarded to 443 through nginx (<code>/etc/nginx/conf.d/microblog.conf</code>):</p>

<pre><code>server {
    # listen on port 443 (https)
    listen 443 ssl;
    server_name _;

    # location of the self-signed SSL certificate
    ssl_certificate /home/cocchi/git_dir/covid20/certs/cert.pem;
    ssl_certificate_key /home/cocchi/git_dir/covid20/certs/key.pem;

    # write access and error logs to /var/log
    access_log /var/log/covid20_access.log;
    error_log /var/log/covid20_error.log;

    location / {
        absolute_redirect off;
        port_in_redirect off;
        # forward application requests to the gunicorn server
        proxy_pass http://localhost:8000;
        proxy_redirect off;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /static {
        # handle static files directly, without forwarding to the application
        alias /home/cocchi/git_dir/covid20/app/static;
        expires 30d;
    }
}
</code></pre>

<p>and here the general conf file for nginx <code>/etc/nginx/nginx.conf</code> :</p>

<pre><code># For more information on configuration, see:
#   * Official English Documentation: http://nginx.org/en/docs/
#   * Official Russian Documentation: http://nginx.org/ru/docs/

user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log;
pid /run/nginx.pid;

# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.
include /usr/share/nginx/modules/*.conf;

events {
    worker_connections 1024;
}

http {
    log_format  main  '$remote_addr - $remote_user [$time_local] ""$request"" '
                      '$status $body_bytes_sent ""$http_referer"" '
                      '""$http_user_agent"" ""$http_x_forwarded_for""';

    access_log  /var/log/nginx/access.log  main;

    sendfile            on;
    tcp_nopush          on;
    tcp_nodelay         on;
    keepalive_timeout   65;
    types_hash_max_size 2048;

    include             /etc/nginx/mime.types;
#    default_type        application/octet-stream;
    default_type        text/html;

    # Load modular configuration files from the /etc/nginx/conf.d directory.
    # See http://nginx.org/en/docs/ngx_core_module.html#include
    # for more information.
    include /etc/nginx/conf.d/*.conf;

    server {
        listen       80 default_server;
        listen       [::]:80 default_server;
        server_name  _;
        root         /usr/share/nginx/html;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

        location / {
            absolute_redirect off;
            port_in_redirect off;
            server_name_in_redirect off;
            # redirect any requests to the same URL but on https
            return 301 https://$host$request_uri;
        }

        error_page 404 /404.html;
            location = /40x.html {
        }

        error_page 500 502 503 504 /50x.html;
            location = /50x.html {
        }
    }

# Settings for a TLS enabled server.

#    server {
#        listen       443 ssl http2 default_server;
#        listen       [::]:443 ssl http2 default_server;
#        server_name  _;
#        root         /usr/share/nginx/html;

#        ssl_certificate ""/etc/pki/nginx/server.crt"";
#        ssl_certificate_key ""/etc/pki/nginx/private/server.key"";
#        ssl_session_cache shared:SSL:1m;
#        ssl_session_timeout  10m;
#        ssl_ciphers HIGH:!aNULL:!MD5;
#        ssl_prefer_server_ciphers on;

        # Load configuration files for the default server block.
#        include /etc/nginx/default.d/*.conf;

#        location / {
#        }

#        error_page 404 /404.html;
#            location = /40x.html {
#        }

#        error_page 500 502 503 504 /50x.html;
#            location = /50x.html {
#        }
#    }

}
</code></pre>

<p>My problem is that every time I have a <code>redirect()</code> in the flask app it gives me this error:</p>

<blockquote>
  <p>400 Bad Request The plain HTTP request was sent to HTTPS port</p>
</blockquote>

<p>And I cannot figure out how to solve it!
I read that <code>redirect()</code> does not respect http/https in <a href=""https://github.com/pallets/flask/issues/773"" rel=""nofollow noreferrer"">this post</a>, but I don't get how to configure it to make it works on my machine.</p>

<p>The port is forwarded to the outside world to port <code>4343</code> by the network administrator, and the problem is that I lost this specific port <code>4343</code> every time I have a <code>redirect()</code> in my code...</p>

<p>Any help is much appreciated!!!</p>
"
61598024,"<p>I have a flask app and would like to containerize it through docker. Normally I run the app using <code>flask run</code> and it serves the API at port 8888. However, when I try to run it using docker, the API doesnt start. I build the image using <code>docker-compose build --no-cache</code> and start using <code>docker-compose -f docker-compose.yml up</code>, the container starts. I use <code>docker exec -it covid-api /bin/bash</code>, I get to <code>root@d0659f0c1627:/app#</code> and ls returns nothing. Its empty.</p>

<p>This is my folder structure:</p>

<p><a href=""https://i.stack.imgur.com/mWsnf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mWsnf.png"" alt=""enter image description here""></a></p>

<p>Below is my docker configuration:</p>

<pre><code>FROM python:3.7-stretch
WORKDIR /app

COPY ./badproxy /etc/apt/apt.conf.d/99fixbadproxy

RUN apt-get update \
 &amp;&amp; apt-get install -y curl apt-utils gcc build-essential apt-transport-https ca-certificates \
 &amp;&amp; curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add - \
 &amp;&amp; curl https://packages.microsoft.com/config/debian/9/prod.list &gt; /etc/apt/sources.list.d/mssql-release.list \
 &amp;&amp; apt-get update \
 &amp;&amp; ACCEPT_EULA=Y apt-get install -y msodbcsql17 unixodbc-dev mssql-tools locales \
 &amp;&amp; echo ""en_US.UTF-8 UTF-8"" &gt; /etc/locale.gen \
 &amp;&amp; locale-gen

COPY .flaskenv ./
COPY requirements.txt ./
RUN pip install -r requirements.txt

ENV FLASK_ENV=development
ENV PATH=""/opt/mssql-tools/bin:${PATH}""

COPY . ./

CMD python setup.py develop

CMD [""flask"", ""run"", ""-h"", ""0.0.0.0"", ""-p"", ""8888""]
</code></pre>

<p>Docker-compose:</p>

<pre><code>version: '3.7'
services:
  web:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - '6000:6000'
    environment:
      SECRET_BASE_KEY: 'development-secret'
    volumes:
      - .:/app
    restart: unless-stopped
    networks:
      mynetwork:
        aliases:
          - web.myname.test

networks:
  mynetwork:
    driver: bridge
</code></pre>

<p>src/app.py:</p>

<pre><code>import logging.config

import os
from flask import Flask, Blueprint
from flask_cors import CORS
from werkzeug.middleware.proxy_fix import ProxyFix
from src.config import default
from src.api.controllers.endpoints.users import ns as users_namespace
from src.api.controllers.endpoints.statuses import ns as status_namespace
from src.api import api
from src.database import db

app = Flask(__name__)
CORS(app)
app.wsgi_app = ProxyFix(app.wsgi_app)
logging_conf_path = os.path.normpath(os.path.join(os.path.dirname(__file__), '../logging.conf'))
logging.config.fileConfig(logging_conf_path)
log = logging.getLogger(__name__)


def configure_app(flask_app):
    flask_app.config['SERVER_NAME'] = default.FLASK_SERVER_NAME
    flask_app.config['SQLALCHEMY_DATABASE_URI'] = default.SQLALCHEMY_DATABASE_URI
    flask_app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = default.SQLALCHEMY_TRACK_MODIFICATIONS
    flask_app.config['SWAGGER_UI_DOC_EXPANSION'] = default.RESTPLUS_SWAGGER_UI_DOC_EXPANSION
    flask_app.config['RESTPLUS_VALIDATE'] = default.RESTPLUS_VALIDATE
    flask_app.config['RESTPLUS_MASK_SWAGGER'] = default.RESTPLUS_MASK_SWAGGER
    flask_app.config['ERROR_404_HELP'] = default.RESTPLUS_ERROR_404_HELP

    return flask_app


def initialize_app(flask_app):
    configure_app(flask_app)

    blueprint = Blueprint('CovidAPI', __name__, url_prefix='/')
    api.init_app(blueprint)
    api.add_namespace(users_namespace)
    api.add_namespace(status_namespace)
    flask_app.register_blueprint(blueprint)

    db.init_app(flask_app)

    return flask_app


app = initialize_app(app)

# def main():
#     initialize_app(app)
#     log.info('&gt;&gt;&gt;&gt;&gt; Starting development server at http://{}/ &lt;&lt;&lt;&lt;&lt;'.format(app.config['SERVER_NAME']))
#     app.run(debug=default.FLASK_DEBUG)


if __name__ == ""__main__"":
    log.info('&gt;&gt;&gt;&gt;&gt; Starting development server at http://{}/ &lt;&lt;&lt;&lt;&lt;'.format(app.config['SERVER_NAME']))
    app.run(debug=default.FLASK_DEBUG)
</code></pre>

<p>Please advice. Any help is highly appreciated.</p>
"
61357038,"<p>I have conda 4.8.3 and Python 3.7.4 on Windows 8.1.</p>

<p>I have tf 2.0.0 installed in a conda environment. How do I upgrade to 2.2.x?</p>

<p>Or, how do I just install 2.2.x in a conda environment?</p>

<p>Edit 1: pip install --upgrade tensorflow says: <code>Requirement already up-to-date: tensorflow in d:\anaconda3\envs\tf2\lib\site-packages (2.1.0)</code></p>

<p>but tf version is still 2.0.</p>

<p>Edit 2: conda install tensorflow==2.2.0 says:</p>

<pre><code>PackagesNotFoundError: The following packages are not available from current channels:
</code></pre>

<ul>
<li>tensorflow==2.2.0</li>
</ul>

<p>Edit 3:</p>

<pre><code>(tf2) D:\ray\dev\covid-19&gt;conda list -n tf2
# packages in environment at D:\Anaconda3\envs\tf2:
#
# Name                    Version                   Build  Channel
_anaconda_depends         2019.03                  py37_0
_ipyw_jlab_nb_ext_conf    0.1.0                    py37_0
_tflow_select             2.3.0                       mkl
absl-py                   0.9.0                    pypi_0    pypi
alabaster                 0.7.12                   py37_0
anaconda                  custom                   py37_1
anaconda-client           1.7.2                    py37_0
anaconda-navigator        1.9.7                    py37_0
anaconda-project          0.8.3                      py_0
asn1crypto                1.0.1                    py37_0
astor                     0.8.1                    pypi_0    pypi
astroid                   2.3.1                    py37_0
astropy                   3.2.1            py37he774522_0
atomicwrites              1.3.0                    py37_1
attrs                     19.2.0                     py_0
babel                     2.7.0                      py_0
backcall                  0.1.0                    py37_0
backports                 1.0                        py_2
backports.functools_lru_cache 1.5                        py_2
backports.os              0.1.1                    py37_0
backports.shutil_get_terminal_size 1.0.0                    py37_2
backports.tempfile        1.0                        py_1
backports.weakref         1.0.post1                  py_1
beautifulsoup4            4.8.0                    py37_0
bitarray                  1.0.1            py37he774522_0
bkcharts                  0.2                      py37_0
blas                      1.0                         mkl
bleach                    3.1.0                    py37_0
blosc                     1.16.3               h7bd577a_0
bokeh                     1.3.4                    py37_0
boto                      2.49.0                   py37_0
bottleneck                1.2.1            py37h452e1ab_1
bzip2                     1.0.8                he774522_0
ca-certificates           2020.1.1                      0
cachetools                4.0.0                    pypi_0    pypi
certifi                   2019.9.11                py37_0
cffi                      1.12.3           py37h7a1dbc1_0
chardet                   3.0.4                 py37_1003
click                     7.0                      py37_0
cloudpickle               1.2.2                      py_0
clyent                    1.2.2                    py37_1
colorama                  0.4.1                    py37_0
comtypes                  1.1.7                    py37_0
conda-package-handling    1.6.0            py37h62dcd97_0
conda-verify              3.4.2                      py_1
console_shortcut          0.1.1                         3
contextlib2               0.6.0                      py_0
cryptography              2.7              py37h7a1dbc1_0
curl                      7.65.3               h2a8f88b_0
cycler                    0.10.0                   py37_0
cython                    0.29.13          py37ha925a31_0
cytoolz                   0.10.0           py37he774522_0
dask                      2.5.2                      py_0
dask-core                 2.5.2                      py_0
decorator                 4.4.0                    py37_1
defusedxml                0.6.0                      py_0
dill                      0.3.1.1                  pypi_0    pypi
distributed               2.5.2                      py_0
docutils                  0.15.2                   py37_0
entrypoints               0.3                      py37_0
et_xmlfile                1.0.1                    py37_0
fastcache                 1.1.0            py37he774522_0
filelock                  3.0.12                     py_0
flask                     1.1.1                      py_0
freetype                  2.9.1                ha9979f8_1
fsspec                    0.5.2                      py_0
future                    0.17.1                   py37_0
gast                      0.2.2                    pypi_0    pypi
get_terminal_size         1.0.0                h38e98db_0
gevent                    1.4.0            py37he774522_0
glob2                     0.7                        py_0
google-auth               1.11.0                   pypi_0    pypi
google-auth-oauthlib      0.4.1                    pypi_0    pypi
google-pasta              0.1.8                      py_0
googleapis-common-protos  1.51.0                   pypi_0    pypi
greenlet                  0.4.15           py37hfa6e2cd_0
grpcio                    1.26.0                   pypi_0    pypi
h5py                      2.9.0            py37h5e291fa_0
hdf5                      1.10.4               h7ebc959_0
heapdict                  1.0.1                      py_0
html5lib                  1.0.1                    py37_0
icc_rt                    2019.0.0             h0cc432a_1
icu                       58.2                 ha66f8fd_1
idna                      2.8                      py37_0
imageio                   2.6.0                    py37_0
imagesize                 1.1.0                    py37_0
importlib_metadata        0.23                     py37_0
intel-openmp              2019.4                      245
ipykernel                 5.1.2            py37h39e3cac_0
ipython                   7.8.0            py37h39e3cac_0
ipython_genutils          0.2.0                    py37_0
ipywidgets                7.5.1                      py_0
isort                     4.3.21                   py37_0
itsdangerous              1.1.0                    py37_0
jdcal                     1.4.1                      py_0
jedi                      0.15.1                   py37_0
jinja2                    2.10.3                     py_0
joblib                    0.13.2                   py37_0
jpeg                      9b                   hb83a4c4_2
json5                     0.8.5                      py_0
jsonschema                3.0.2                    py37_0
jupyter                   1.0.0                    py37_7
jupyter_client            5.3.3                    py37_1
jupyter_console           6.0.0                    py37_0
jupyter_core              4.5.0                      py_0
jupyterlab                1.1.4              pyhf63ae98_0
jupyterlab_server         1.0.6                      py_0
keras                     2.3.1            py37h21ff451_0    conda-forge
keras-applications        1.0.8                      py_0
keras-preprocessing       1.1.0                      py_1
keyring                   18.0.0                   py37_0
kiwisolver                1.1.0            py37ha925a31_0
krb5                      1.16.1               hc04afaa_7
lazy-object-proxy         1.4.2            py37he774522_0
libarchive                3.3.3                h0643e63_5
libcurl                   7.65.3               h2a8f88b_0
libgpuarray               0.7.6                hfa6e2cd_0
libiconv                  1.15                 h1df5818_7
liblief                   0.9.0                ha925a31_2
libmklml                  2019.0.5                      0
libpng                    1.6.37               h2a8f88b_0
libprotobuf               3.11.2               h7bd577a_0
libpython                 2.1                      py37_0
libsodium                 1.0.16               h9d3ae62_0
libssh2                   1.8.2                h7a1dbc1_0
libtiff                   4.0.10               hb898794_2
libxml2                   2.9.9                h464c3ec_0
libxslt                   1.1.33               h579f668_0
llvmlite                  0.29.0           py37ha925a31_0
locket                    0.2.0                    py37_1
lxml                      4.4.1            py37h1350720_0
lz4-c                     1.8.1.2              h2fa13f4_0
lzo                       2.10                 h6df0209_2
m2w64-binutils            2.25.1                        5
m2w64-bzip2               1.0.6                         6
m2w64-crt-git             5.0.0.4636.2595836               2
m2w64-gcc                 5.3.0                         6
m2w64-gcc-ada             5.3.0                         6
m2w64-gcc-fortran         5.3.0                         6
m2w64-gcc-libgfortran     5.3.0                         6
m2w64-gcc-libs            5.3.0                         7
m2w64-gcc-libs-core       5.3.0                         7
m2w64-gcc-objc            5.3.0                         6
m2w64-gmp                 6.1.0                         2
m2w64-headers-git         5.0.0.4636.c0ad18a               2
m2w64-isl                 0.16.1                        2
m2w64-libiconv            1.14                          6
m2w64-libmangle-git       5.0.0.4509.2e5a9a2               2
m2w64-libwinpthread-git   5.0.0.4634.697f757               2
m2w64-make                4.1.2351.a80a8b8               2
m2w64-mpc                 1.0.3                         3
m2w64-mpfr                3.1.4                         4
m2w64-pkg-config          0.29.1                        2
m2w64-toolchain           5.3.0                         7
m2w64-tools-git           5.0.0.4592.90b8472               2
m2w64-windows-default-manifest 6.4                           3
m2w64-winpthreads-git     5.0.0.4634.697f757               2
m2w64-zlib                1.2.8                        10
mako                      1.1.0                      py_0
markdown                  3.1.1                    py37_0
markupsafe                1.1.1            py37he774522_0
matplotlib                3.1.1            py37hc8f65d3_0
mccabe                    0.6.1                    py37_1
menuinst                  1.4.16           py37he774522_0
mistune                   0.8.4            py37he774522_0
mkl                       2019.4                      245
mkl-service               2.3.0            py37hb782905_0
mkl_fft                   1.0.14           py37h14836fe_0
mkl_random                1.1.0            py37h675688f_0
mock                      3.0.5                    py37_0
more-itertools            7.2.0                    py37_0
mpmath                    1.1.0                    py37_0
msgpack-python            0.6.1            py37h74a9793_1
msys2-conda-epoch         20160418                      1
multipledispatch          0.6.0                    py37_0
navigator-updater         0.2.1                    py37_0
nbconvert                 5.6.0                    py37_1
nbformat                  4.4.0                    py37_0
networkx                  2.3                        py_0
nltk                      3.4.5                    py37_0
nose                      1.3.7                    py37_2
notebook                  6.0.1                    py37_0
numba                     0.45.1           py37hf9181ef_0
numexpr                   2.7.0            py37hdce8814_0
numpy                     1.16.5           py37h19fb1c0_0
numpy-base                1.16.5           py37hc3f5095_0
numpydoc                  0.9.1                      py_0
oauthlib                  3.1.0                    pypi_0    pypi
olefile                   0.46                     py37_0
openpyxl                  3.0.0                      py_0
openssl                   1.1.1d               he774522_3
opt_einsum                3.1.0                      py_0
packaging                 19.2                       py_0
pandas                    0.25.1                   pypi_0    pypi
pandoc                    2.2.3.2                       0
pandocfilters             1.4.2                    py37_1
parso                     0.5.1                      py_0
partd                     1.0.0                      py_0
path.py                   12.0.1                     py_0
pathlib2                  2.3.5                    py37_0
patsy                     0.5.1                    py37_0
pep8                      1.7.1                    py37_0
pickleshare               0.7.5                    py37_0
pillow                    6.2.0            py37hdc69c19_0
pip                       20.0.2                   pypi_0    pypi
pkginfo                   1.5.0.1                  py37_0
pluggy                    0.13.0                   py37_0
ply                       3.11                     py37_0
powershell_shortcut       0.0.1                         2
prometheus_client         0.7.1                      py_0
promise                   2.3                      pypi_0    pypi
prompt_toolkit            2.0.10                     py_0
protobuf                  3.11.2                   pypi_0    pypi
psutil                    5.6.3            py37he774522_0
py                        1.8.0                    py37_0
py-lief                   0.9.0            py37ha925a31_2
pyasn1                    0.4.8                    pypi_0    pypi
pyasn1-modules            0.2.8                    pypi_0    pypi
pycodestyle               2.5.0                    py37_0
pycosat                   0.6.3            py37hfa6e2cd_0
pycparser                 2.19                     py37_0
pycrypto                  2.6.1            py37hfa6e2cd_9
pycurl                    7.43.0.3         py37h7a1dbc1_0
pyflakes                  2.1.1                    py37_0
pygments                  2.4.2                      py_0
pygpu                     0.7.6            py37h452e1ab_0
pylint                    2.4.2                    py37_0
pyodbc                    4.0.27           py37ha925a31_0
pyopenssl                 19.0.0                   py37_0
pyparsing                 2.4.2                      py_0
pyqt                      5.9.2            py37h6538335_2
pyreadline                2.1                      py37_1
pyrsistent                0.15.4           py37he774522_0
pysocks                   1.7.1                    py37_0
pytables                  3.5.2            py37h1da0976_1
pytest                    5.2.1                    py37_0
pytest-arraydiff          0.3              py37h39e3cac_0
pytest-astropy            0.5.0                    py37_0
pytest-doctestplus        0.4.0                      py_0
pytest-openfiles          0.4.0                      py_0
pytest-remotedata         0.3.2                    py37_0
python                    3.7.4                h5263a28_0
python-dateutil           2.8.0                    py37_0
python-libarchive-c       2.8                     py37_13
pytz                      2019.3                     py_0
pywavelets                1.0.3            py37h8c2d366_1
pywin32                   223              py37hfa6e2cd_1
pywinpty                  0.5.5                 py37_1000
pyyaml                    5.1.2            py37he774522_0
pyzmq                     18.1.0           py37ha925a31_0
qt                        5.9.7            vc14h73c81de_0
qtawesome                 0.6.0                      py_0
qtconsole                 4.5.5                      py_0
qtpy                      1.9.0                      py_0
requests                  2.22.0                   py37_0
requests-oauthlib         1.3.0                    pypi_0    pypi
rope                      0.14.0                     py_0
rsa                       4.0                      pypi_0    pypi
ruamel_yaml               0.15.46          py37hfa6e2cd_0
scikit-image              0.15.0           py37ha925a31_0
scikit-learn              0.21.3           py37h6288b17_0
scipy                     1.4.1                    pypi_0    pypi
seaborn                   0.9.0                    py37_0
send2trash                1.5.0                    py37_0
setuptools                41.4.0                   py37_0
simplegeneric             0.8.1                    py37_2
singledispatch            3.4.0.3                  py37_0
sip                       4.19.8           py37h6538335_0
six                       1.12.0                   py37_0
sklearn                   0.0                      pypi_0    pypi
snappy                    1.1.7                h777316e_3
snowballstemmer           2.0.0                      py_0
sortedcollections         1.1.2                    py37_0
sortedcontainers          2.1.0                    py37_0
soupsieve                 1.9.3                    py37_0
sphinx                    2.2.0                      py_0
sphinxcontrib             1.0                      py37_1
sphinxcontrib-applehelp   1.0.1                      py_0
sphinxcontrib-devhelp     1.0.1                      py_0
sphinxcontrib-htmlhelp    1.0.2                      py_0
sphinxcontrib-jsmath      1.0.1                      py_0
sphinxcontrib-qthelp      1.0.2                      py_0
sphinxcontrib-serializinghtml 1.1.3                      py_0
sphinxcontrib-websupport  1.1.2                      py_0
spyder                    3.3.6                    py37_0
spyder-kernels            0.5.2                    py37_0
sqlalchemy                1.3.9            py37he774522_0
sqlite                    3.30.0               he774522_0
statsmodels               0.10.1           py37h8c2d366_0
sympy                     1.4                      py37_0
tbb                       2019.4               h74a9793_0
tblib                     1.4.0                      py_0
tensorboard               2.1.0                    pypi_0    pypi
tensorflow                2.1.0                    pypi_0    pypi
tensorflow-base           2.0.0           mkl_py37hd1d5974_0
tensorflow-datasets       2.0.0                    pypi_0    pypi
tensorflow-estimator      2.1.0                    pypi_0    pypi
tensorflow-metadata       0.21.1                   pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
terminado                 0.8.2                    py37_0
testpath                  0.4.2                    py37_0
theano                    1.0.4                    py37_0
tk                        8.6.8                hfa6e2cd_0
toolz                     0.10.0                     py_0
tornado                   6.0.3            py37he774522_0
tqdm                      4.36.1                     py_0
traitlets                 4.3.3                    py37_0
unicodecsv                0.14.1                   py37_0
urllib3                   1.24.2                   py37_0
vc                        14.1                 h0510ff6_4
vs2015_runtime            14.16.27012          hf0eaf9b_0
wcwidth                   0.1.7                    py37_0
webencodings              0.5.1                    py37_1
werkzeug                  0.16.0                     py_0
wheel                     0.33.6                   py37_0
widgetsnbextension        3.5.1                    py37_0
win_inet_pton             1.1.0                    py37_0
win_unicode_console       0.5                      py37_0
wincertstore              0.2                      py37_0
winpty                    0.4.3                         4
wrapt                     1.11.2           py37he774522_0
xlrd                      1.2.0                    py37_0
xlsxwriter                1.2.1                      py_0
xlwings                   0.15.10                  py37_0
xlwt                      1.3.0                    py37_0
xz                        5.2.4                h2fa13f4_4
yaml                      0.1.7                hc54c509_2
zeromq                    4.3.1                h33f27b4_3
zict                      1.0.0                      py_0
zipp                      0.6.0                      py_0
zlib                      1.2.11               h62dcd97_3
zstd                      1.3.7                h508b16e_0
</code></pre>
"
61709636,"<pre><code>df5 = df4.copy()
for pc in pcs_vars.keys():
  df5[pc+""_tests""] = df5.apply(lambda x: 0 if x[pcs_vars[pc]].isnull().all() else 1,axis=1)
</code></pre>

<p>error ------- </p>

<pre><code>Passing list-likes to .loc or [] with any missing labels is no longer supported
</code></pre>

<p>where, </p>

<pre><code>pcs_vars = {'respiratory': ['Influenza B', 'Respiratory Syncytial Virus', 'Influenza A',
                            'Metapneumovirus', 'Parainfluenza 1', 'Inf A H1N1 2009',
                            'Bordetella pertussis', 'Chlamydophila pneumoniae', 'Coronavirus229E',
                            'Parainfluenza 2', 'Parainfluenza 3', 'CoronavirusNL63',
                            'Rhinovirus/Enterovirus', 'CoronavirusOC43', 'Coronavirus HKU1',
                            'Adenovirus', 'Parainfluenza 4'],
            'regular_blood': ['Proteina C reativa mg/dL',
                              'Neutrophils', 'Mean platelet volume ', 'Monocytes',
                              'Red blood cell distribution width (RDW)', 'Red blood Cells',
                              'Platelets', 'Eosinophils', 'Basophils', 'Leukocytes',
                              'Mean corpuscular hemoglobin (MCH)', 'Mean corpuscular volume (MCV)',
                              'Mean corpuscular hemoglobin concentration\xa0(MCHC)', 'Lymphocytes',
                              'Hemoglobin', 'Hematocrit'],
            'liver_kidney_gas': ['Creatine phosphokinase\xa0(CPK)\xa0', 
                                 'International normalized ratio (INR)', 
                                 'Alkaline phosphatase', 'Gamma-glutamyltransferase\xa0',
                                 'Alanine transaminase', 'Aspartate transaminase',
                                 'HCO3 (venous blood gas analysis)',
                                 'Hb saturation (venous blood gas analysis)',
                                 'Total CO2 (venous blood gas analysis)',
                                 'pCO2 (venous blood gas analysis)', 'pH (venous blood gas analysis)',
                                 'pO2 (venous blood gas analysis)',
                                 'Base excess (venous blood gas analysis)', 'Total Bilirubin',
                                 'Direct Bilirubin', 'Indirect Bilirubin',
                                 'Sodium', 'Potassium', 'Urea', 'Creatinine'],
            'urine': ['Urine - Ketone Bodies', 'Urine - Esterase', 'Urine - Protein',
                      'Urine - Hyaline cylinders', 'Urine - Urobilinogen',
                      'Urine - Bile pigments', 'Urine - Hemoglobin', 'Urine - pH',
                      'Urine - Granular cylinders', 'Urine - Aspect', 'Urine - Density',
                      'Urine - Color', 'Urine - Red blood cells', 'Urine - Leukocytes',
                      'Urine - Yeasts', 'Urine - Crystals'],
            'bone_narrow_cells': ['Metamyelocytes', 'Myelocytes', 'Promyelocytes', 'Rods #',
                                  'Myeloblasts', 'Segmented'],
            'influenza_rapid': ['Influenza B, rapid test', 'Influenza A, rapid test']}

vars_analyzed = [var for pc in pcs_vars for var in pcs_vars[pc]]
</code></pre>
"
61711506,"<p>I tried to create an interactive choropleth plot of COVID-19 Confirmed Cases by US State using plotly.express.choropleth, but I encountered an issue as I was trying to customize the hover_data. Here is the code:</p>

<pre class=""lang-py prettyprint-override""><code>import pandas as pd
import plotly.express as px

covtrack_states_hist_df = covtrack_states_hist_df.sort_values(by=['date'])

color_scale = ['#ffffff', '#ffe6e6', '#ffcccc', '#ff9999', '#ff6666', '#ff3333',
               '#ff0000', '#e60000', '#cc0000', '#b30000', '#990000', '#800000']

covtrack_states_hist_df = covtrack_states_hist_df.astype({'positive': str, 'death': str, 'test': str})
covtrack_states_hist_df['text'] = 'Confirmed: ' + covtrack_states_hist_df['positive'] + '&lt;br&gt;' + \ 
                                  'Deaths: ' + covtrack_states_hist_df['death'] + '&lt;br&gt;' + \
                                  'Tests: ' + covtrack_states_hist_df['test']
text = covtrack_states_hist_df['text'].tolist()

covtrack_states_hist_df[['positive', 'death', 'test']] = covtrack_states_hist_df[['positive', 'death', 'test']].apply(pd.to_numeric)

fig = px.choropleth(
    covtrack_states_hist_df,
    color='positive',
    locations='state',             
    locationmode = 'USA-states',
    scope='usa',
    hover_name='state',
    hover_data='text', # I've tried just text as well, but not working
    # I've also tried covtrack_states_hist_df['text'] and covtrack_states_hist_df.text but none of them worked
    animation_frame='date',
    title=""Daily New COVID-19 Confirmed Cases"",
    color_continuous_scale= color_scale, 
)

fig['layout'].pop('updatemenus')

fig.show()
</code></pre>

<p>The error I get is:</p>

<pre><code>ValueError: Value of 'hover_data_0' is not the name of a column in 'data_frame'. 
Expected one of ['date', 'state', 'fips', 'positive', 'death', 'test', 'datetime', 'text'] but received: t
</code></pre>

<p>Here is a screenshot of what my DataFrame looks like:
<a href=""https://i.stack.imgur.com/Q4PLS.png"" rel=""nofollow noreferrer"">DataFrame info and head</a></p>
"
61614868,"<p>am trying to work with SIDARTHE Model for predicting the evolution of covid-19 in Rwanda but am stuck my code can't run, am getting value error. setting an array element with a sequence, below is my code</p>

<p># EXERCISE ON COVID 19 wanda 2020#</p>

<p>##Import the libraries##</p>

<p><code>import numpy as np</code><br>
<code>import matplotlib.pyplot as plt</code><br>
 <code>from scipy.integrate import odeint</code>  </p>

<h3>The Total population of Rwanda is 12 881 262###</h3>

Parameters

<p><code>a=0.5700</code><br>
   <code>b=0.0114</code><br>
    <code>g=0.4560</code><br>
    <code>d=0.0114</code><br>
     <code>d=0.0114</code><br>
    <code>q=0.3705</code><br>
    <code>z=0.1254</code><br>
     <code>h=0.1254</code><br>
    <code>μ=0.0171</code><br>
    <code>n=0.0274</code><br>
    <code>w=0.0100</code><br>
     <code>l=0.0342</code><br>
     <code>r=0.0342</code><br>
    <code>k=0.0171</code><br>
     <code>x=0.0171</code><br>
    <code>s=0.0171</code><br>
    <code>#step=0.01;</code><br>
 <code>#Initalization</code><br>
    <code>y0=[1,3.3e-6,3.3e-7,1.6e-8,3.3e-8,0.0,0.0,0.0,]</code><br>
    <code>t=np.linspace(0,60,20)</code><br>
<code>#t=np.arange(0,60)</code><br>
<code>#fucnction</code><br>
     <code>def sidarthe(y,t,b,a,g,d,e,q,z,h,μ,n,w,l,r,k,x,s):</code><br>
        <code>S,I,D,A,R,T,H,E=y</code>  </p>

<pre><code>   `dS=-S*a*I+b*D+g*A+s*R `  

     `dI=S*a*I+b*D+g*A+s*R-e*I-z*I-l*I`  

   `dD=e*I-h*D-r*D`  

    `dA=z*I-q*A-μ*A-k*A`  

    `dR=h*D+q*A-n*R-z*R`  

     `dT=μ*A+n*R-s*T-w*T`  

    `dH=l*I+r*D+k*A+z*R+s*T `  

    `dE=w*T`  

   `dndt=[dS,dI,dD,dA,dR,dT,dH,dE]`  

     `return dndt`  
</code></pre>

<p><code>#solution</code><br>
     <code>sol=odeint(sidarthe,y0,t,args=(b,a,g,d,e,q,z,h,μ,n,t,l,r,k,x,s))</code><br>
 <code>#ploting</code><br>
<code>#print(t, sol[:,0])</code><br>
    <code>plt.figure(figsize=(13,5))</code>  </p>

<p><code>plt.plot(t,sol[:,0],""b"",label=""Susceptible"")</code>  </p>

<pre><code>`plt.plot(t,sol[:,1],""g"",label=""INFECTED"") `  
</code></pre>

<p><code>plt.plot(t,sol[:,2],""y"",label=""DIAGNOSED"")</code>  </p>

<p><code>plt.plot(t,sol[:,3],""r"",label=""AILING"")</code>  </p>

<p><code>plt.plot(t,sol[:,4],""o"",label=""RECOGNIZED"")</code>  </p>

<p><code>plt.plot(t,sol[:,5],""p"",label=""THREATENED"")</code>  </p>

<p><code>plt.plot(t,sol[:,6],""g--"",label=""HEALED"")</code>   </p>

<p><code>plt.plot(t,sol[:,7],""r--"",label=""EXTINCT"")</code><br>
   <code>plt.legend(loc=""best"")</code></p>

<p><code>plt.xlabel(""time(days)"")</code>  </p>

<p><code>plt.ylabel(""Fraction Population"")</code>  </p>

<pre><code>`plt.show()`  


`when i run it am geting an error(Value error, setting an array element with a sequence)`  
</code></pre>
"
61552878,"<p>I'm using the C3.ai COVID-19 Data Lake in Python, but I get missing authentication token errors. What am I doing wrong?
An example:</p>

<pre><code>import requests
r = requests.get(
    ""https://api.c3.ai/covid/api/1/therapeuticasset/fetch"", 
    json = {
        ""spec"" : {
            ""filter"" : ""therapyType == 'Vaccine'""
        }
    },
    headers = {'Accept' : 'application/json'}
)
r.json()
</code></pre>

<p>I get back:</p>

<pre><code>{'message': 'Missing Authentication Token'}
</code></pre>
"
61395531,"<p>I'm trying to install a github program on a beaglebone black. I updated the debian frimware. Then i passed all the files over to the BBB. I updated the apt-get, upgraded the setuptools. And now when i'm trying to install the code i recieve the following error:</p>

<pre><code>    pip3 install -r requirements.txt
WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.
Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.
To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.
Defaulting to user installation because normal site-packages is not writeable
Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple
Processing /home/debian/reespirator
Collecting docopt==0.6.2
  Using cached https://www.piwheels.org/simple/docopt/docopt-0.6.2-py2.py3-none-any.whl (13 kB)
ERROR: Could not find a version that satisfies the requirement PySide2==5.14.1 (from resPyRator==0.0.1.dev20200423-&gt;-r requirements.txt (line 1)) (from versions: none)
ERROR: No matching distribution found for PySide2==5.14.1 (from resPyRator==0.0.1.dev20200423-&gt;-r requirements.txt (line 1))
</code></pre>

<p>The link to the gitlab to all the files are here. Thanks!
Gitlab: <a href=""https://gitlab.com/reesistencia/reespirator-beagle-touch"" rel=""nofollow noreferrer"">https://gitlab.com/reesistencia/reespirator-beagle-touch</a></p>
"
61555925,"<p>My dictionary is as shown below. This dictionary is stored in the variable 'api'. I have used only an excerpt of the dictionary as the whole dictionary is very big and follows similar format.</p>

<pre><code>{
   ""sitedata"":[
      {
         ""info"":{
            ""source"":""https://thevirustracker.com/""
         }}],
         ""countryitems"":[{
                  ""1"":{
         ""ourid"":1,
         ""title"":""Afghanistan"",
         ""code"":""AF"",
         ""source"":""https://thevirustracker.com/afghanistan-coronavirus-information-af"",
         ""total_cases"":2335,
         ""total_recovered"":310,
         ""total_unresolved"":0,
         ""total_deaths"":68,
         ""total_new_cases_today"":0,
         ""total_new_deaths_today"":0,
         ""total_active_cases"":1957,
         ""total_serious_cases"":7         },
                 ""2"":{
         ""ourid"":2,
         ""title"":""Albania"",
         ""code"":""AL"",
         ""source"":""https://thevirustracker.com/albania-coronavirus-information-al"",
         ""total_cases"":782,
         ""total_recovered"":488,
         ""total_unresolved"":0,
         ""total_deaths"":31,
         ""total_new_cases_today"":0,
         ""total_new_deaths_today"":0,
         ""total_active_cases"":263,
         ""total_serious_cases"":4         },
                 ""3"":{
         ""ourid"":3,
         ""title"":""Algeria"",
         ""code"":""DZ"",
         ""source"":""https://thevirustracker.com/algeria-coronavirus-information-dz"",
         ""total_cases"":4154,
         ""total_recovered"":1821,
         ""total_unresolved"":0,
         ""total_deaths"":453,
         ""total_new_cases_today"":0,
         ""total_new_deaths_today"":0,
         ""total_active_cases"":1880,
         ""total_serious_cases"":22         },
                 ""4"":{
         ""ourid"":4,
         ""title"":""Angola"",
         ""code"":""AO"",
         ""source"":""https://thevirustracker.com/angola-coronavirus-information-ao"",
         ""total_cases"":30,
         ""total_recovered"":11,
         ""total_unresolved"":0,
         ""total_deaths"":2,
         ""total_new_cases_today"":0,
         ""total_new_deaths_today"":0,
         ""total_active_cases"":17,
         ""total_serious_cases"":0         },
                 ""5"":{
         ""ourid"":5,
         ""title"":""Argentina"",
         ""code"":""AR"",
         ""source"":""https://thevirustracker.com/argentina-coronavirus-information-ar"",
         ""total_cases"":4532,
         ""total_recovered"":1292,
         ""total_unresolved"":0,
         ""total_deaths"":225,
         ""total_new_cases_today"":0,
         ""total_new_deaths_today"":0,
         ""total_active_cases"":3015,
         ""total_serious_cases"":157         },
             .
             .
             .
                                   ""stat"":""ok""
        }]}
</code></pre>

<p>I am trying to iterate through this dictionary to fetch the country names using the below code:</p>

<hr>

<pre><code>api_request = requests.get('https://api.thevirustracker.com/free-api?countryTotals=ALL')

api = json.loads(api_request.content)

dict = api['countryitems'][0]

for key in dict:

    country = api['countryitems'][0][key]['title']
    print(country)
</code></pre>

<hr>

<p>But I am getting the error ""<strong>TypeError: string indices must be integers</strong>"". </p>

<p>Can someone please advise what exactly is going wrong here.
I am using this code on Python 3.7 (Tkinter)</p>
"
61547930,"<p>I am trying to web scrape news articles by certain keywords. I use Python 3. However, I am not able to get all the articles from the newspaper. After scraping some articles as output in the <code>csv</code> file I get <code>ArticleException</code> error. Could anyone help me with this? Ideally, I would like to solve the problem and download all the related articles from the newspaper website. Otherwise, it would also be useful to just skip the URL that shows error and continue from the next one. Thanks in advance for your help. </p>

<p>This is the code I am using:</p>

<pre><code>import urllib.request
import newspaper
from newspaper import Article
import csv, os
from bs4 import BeautifulSoup
import urllib

req_keywords = ['coronavirus', 'covid-19']

newspaper_base_url = 'http://www.thedailystar.net'
category = 'country'

def checkif_kw_exist(list_one, list_two):
    common_kw = set(list_one) &amp; set(list_two)
    if len(common_kw) == 0: return False, common_kw
    else: return True, common_kw

def get_article_info(url):
    a = Article(url)
    a.download()
    a.parse()
    a.nlp()
    success, checked_kws = checkif_kw_exist(req_keywords, a.text.split())
    if success:
        return [url, a.publish_date, a.title, a.text]
    else: return False


output_file = ""J:/B/output.csv""
if not os.path.exists(output_file):
    open(output_file, 'w').close() 


for index in range(1,50000,1):

    page_soup = BeautifulSoup( urllib.request.urlopen(page_url).read())

    primary_tag = page_soup.find_all(""h4"", attrs={""class"": ""pad-bottom-small""})

    for tag in primary_tag:

        url = tag.find(""a"")
        #print (url)
        url = newspaper_base_url + url.get('href')
        result = get_article_info(url)
        if result is not False:
            with open(output_file, 'a', encoding='utf-8') as f:
                writeFile = csv.writer(f)
                writeFile.writerow(result)
                f.close
        else: 
            pass
</code></pre>

<p>This is the error I am getting:</p>

<pre><code>---------------------------------------------------------------------------
ArticleException                          Traceback (most recent call last)
&lt;ipython-input-1-991b432d3bd0&gt; in &lt;module&gt;
     65         #print (url)
     66         url = newspaper_base_url + url.get('href')
---&gt; 67         result = get_article_info(url)
     68         if result is not False:
     69             with open(output_file, 'a', encoding='utf-8') as f:

&lt;ipython-input-1-991b432d3bd0&gt; in get_article_info(url)
     28     a = Article(url)
     29     a.download()
---&gt; 30     a.parse()
     31     a.nlp()
     32     success, checked_kws = checkif_kw_exist(req_keywords, a.text.split())

~\Anaconda3\lib\site-packages\newspaper\article.py in parse(self)
    189 
    190     def parse(self):
--&gt; 191         self.throw_if_not_downloaded_verbose()
    192 
    193         self.doc = self.config.get_parser().fromstring(self.html)

~\Anaconda3\lib\site-packages\newspaper\article.py in throw_if_not_downloaded_verbose(self)
    530         elif self.download_state == ArticleDownloadState.FAILED_RESPONSE:
    531             raise ArticleException('Article `download()` failed with %s on URL %s' %
--&gt; 532                   (self.download_exception_msg, self.url))
    533 
    534     def throw_if_not_parsed_verbose(self):

ArticleException: Article `download()` failed with HTTPSConnectionPool(host='www.thedailystar.net', port=443): Read timed out. (read timeout=7) on URL http://www.thedailystar.net/ugc-asks-private-universities-stop-admissions-grades-without-test-for-coronavirus-pandemic-1890151
</code></pre>
"
61553380,"<p>I am trying to web scrape coronavirus related articles from a news website. However, I get <code>HTTPError</code> error. The same error also shows for other news portals. The code works for a different website though. I have asked a different question with similar codes in <a href=""https://stackoverflow.com/questions/61547930/articleexception-error-in-web-scraping-news-articles-by-python"">this post</a>. Some previous answers to similar problems ask to change <code>user-agent</code>, but it does not still work after inserting <code>headers = {'User-Agent': 'Mozilla/5.0'}</code> along with the URL. This could be probably because I did not use the code properly. Any help would be much appreciated.</p>

<p>Here is the code I have used:</p>

<pre><code>import urllib.request
import newspaper
from newspaper import Article
import csv, os
from bs4 import BeautifulSoup
import urllib

req_keywords = ['coronavirus', 'covid-19']

newspaper_base_url = 'https://thehimalayantimes.com/'
category = 'nepal'

def checkif_kw_exist(list_one, list_two):
    common_kw = set(list_one) &amp; set(list_two)
    if len(common_kw) == 0: return False, common_kw
    else: return True, common_kw

def get_article_info(url):
    a = Article(url)
    try:
        a.download()
        a.parse()
        a.nlp()
        success, checked_kws = checkif_kw_exist(req_keywords, a.text.split())
        if success:
            return [url, a.publish_date, a.title, a.text]
        else: return False
    except:
        return False

output_file = ""J:/B/output_nepal.csv""
if not os.path.exists(output_file):
    open(output_file, 'w').close() 

for index in range(1,3700,1):
    page_url = newspaper_base_url + '/' + category + '?page='+str(index)

    page_soup = BeautifulSoup( urllib.request.urlopen(page_url).read())

    primary_tag = page_soup.find_all(""h4"", attrs={""class"": ""pad-bottom-small""})

    for tag in primary_tag:

        url = tag.find(""a"")
        url = newspaper_base_url + url.get('href')
        result = get_article_info(url)
        if result is not False:
            with open(output_file, 'a', encoding='utf-8') as f:
                writeFile = csv.writer(f)
                writeFile.writerow(result)
                f.close
        else: 
            pass
</code></pre>

<p>Here is the error I get:</p>

<pre><code>---------------------------------------------------------------------------
HTTPError                                 Traceback (most recent call last)
&lt;ipython-input-34-c9c043bb59fb&gt; in &lt;module&gt;
     69     page_url = newspaper_base_url + '/' + category + '?page='+str(index)
     70 
---&gt; 71     page_soup = BeautifulSoup( urllib.request.urlopen(page_url).read())
     72 
     73     primary_tag = page_soup.find_all(""h4"", attrs={""class"": ""pad-bottom-small""})

~\Anaconda3\lib\urllib\request.py in urlopen(url, data, timeout, cafile, capath, cadefault, context)
    221     else:
    222         opener = _opener
--&gt; 223     return opener.open(url, data, timeout)
    224 
    225 def install_opener(opener):

~\Anaconda3\lib\urllib\request.py in open(self, fullurl, data, timeout)
    530         for processor in self.process_response.get(protocol, []):
    531             meth = getattr(processor, meth_name)
--&gt; 532             response = meth(req, response)
    533 
    534         return response

~\Anaconda3\lib\urllib\request.py in http_response(self, request, response)
    640         if not (200 &lt;= code &lt; 300):
    641             response = self.parent.error(
--&gt; 642                 'http', request, response, code, msg, hdrs)
    643 
    644         return response

~\Anaconda3\lib\urllib\request.py in error(self, proto, *args)
    568         if http_err:
    569             args = (dict, 'default', 'http_error_default') + orig_args
--&gt; 570             return self._call_chain(*args)
    571 
    572 # XXX probably also want an abstract factory that knows when it makes

~\Anaconda3\lib\urllib\request.py in _call_chain(self, chain, kind, meth_name, *args)
    502         for handler in handlers:
    503             func = getattr(handler, meth_name)
--&gt; 504             result = func(*args)
    505             if result is not None:
    506                 return result

~\Anaconda3\lib\urllib\request.py in http_error_default(self, req, fp, code, msg, hdrs)
    648 class HTTPDefaultErrorHandler(BaseHandler):
    649     def http_error_default(self, req, fp, code, msg, hdrs):
--&gt; 650         raise HTTPError(req.full_url, code, msg, hdrs, fp)
    651 
    652 class HTTPRedirectHandler(BaseHandler):

HTTPError: HTTP Error 403: Forbidden
</code></pre>
"
61378297,"<p>I am trying to save a figure from Matplotlib to a folder location on a drive and i am getting some unwanted behavior from the filepath.</p>

<p>This is what i have set up to run with a real string type to handle the ""\"" escape character.</p>

<pre><code>save_path = r""\\nemesis\Network Planning\Team Members\Taylor\2020_04_23 - COVID Impact 
Adjustment\Test Stores\State and Region Growth - "" +str(Store_ID)+ "".jpg""
print(save_path)
plt.savefig(save_path)
</code></pre>

<p>The print statement displays the correct file path string</p>

<p>However when i run the savefig python appears to add an extra slash next to every existing slash in the string and gives the FileNotFound error. Full error transcript below.</p>

<p>FileNotFoundError: [Errno 2] No such file or directory: '\\\\nemesis\\Network Planning\\Team Members\\Taylor\\2020_04_23 - COVID Impact Adjustment\\Test Stores\\State and Region Growth - 17062.jpg'</p>

<p>I am at a loss for the reasons as to why this is occurring and have tried a bunch of different string methods and none have seemed to work.</p>

<p>Any help is much appreciated</p>
"
61689210,"<p>I am trying to impute my 'age' missing values with the median after grouping my dataframe data by sex and country using the code below. My dataframe data is a concatenation of train (2670 rows × 8 columns) and test (297 rows × 7 columns) data sets to do machine learning later. However, I get the following error :
ValueError: Length mismatch: Expected axis has 2966 elements, new values have 2967 elements</p>

<pre><code># Filling missing age data : Create a groupby object: by_sex_country

by_sex_country = data.groupby(['sex', 'country'])

# Write a function that imputes median
def impute_median(series):
    return series.fillna(series.median())

# Impute age and assign to covid_train['age']
data.age = by_sex_country['age'].transform(impute_median)
</code></pre>

<p>Please help me fix this error (I don't get this error when I apply the same code on the train data alone)</p>
"
61264795,"<p>community. I want to open a CSV using pandas and perform analysis on it. Please, help as I am not able to open the CSV itself. I tried opening it with UTF-8, Latin-1, and ISO-8859-1 encoding. It didn't work. 
CODE:</p>

<pre><code>csv_file3='COVID-19-geographic-disbtribution-worldwide.csv'
with open(csv_file3,'rt')as f:
    data = csv.reader(f)
    j=0
    for row in data:
         j+=1
</code></pre>

<p>ERROR:</p>

<pre><code>Traceback (most recent call last):
  File ""analysisofcases.py"", line 87, in &lt;module&gt;
    for row in data:
  File ""/usr/lib/python3.6/codecs.py"", line 321, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 15-16: invalid continuation byte
</code></pre>

<p><a href=""https://i.stack.imgur.com/pydeA.png"" rel=""nofollow noreferrer"">This is the CSV that I want to open. </a>
<a href=""https://i.stack.imgur.com/RRRxr.png"" rel=""nofollow noreferrer"">This is my code and the error when I ran the code.** Please check and see what the problem is**</a></p>
"
61235099,"<p>I have been trying a simple code on Pycharm 2019.2.1 on windows 10 (64bit)</p>

<pre><code>'''
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
df = pd.read_csv('covid_19_clean_complete.csv')
X = df[[""Deaths""]]
Y = df[""Confirmed""]
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.25, random_state=42)
acr = LinearRegression()    
acr.fit(X_train,Y_train)
print(acr.score(X_test,Y_test))
'''
</code></pre>

<p>but showing me this error </p>

<p><a href=""https://i.stack.imgur.com/cACV0.jpg"" rel=""nofollow noreferrer"">error massage</a> </p>

<p>I've already uninstalled pandas once and installed again using pip uninstall pandas and pip install pandas through cmd. 
<a href=""https://i.stack.imgur.com/QlhfO.jpg"" rel=""nofollow noreferrer"">pandas installed photo</a></p>

<p><a href=""https://i.stack.imgur.com/Txail.jpg"" rel=""nofollow noreferrer"">Interpreter photo</a></p>

<p>Did much google search but the links I found, were not clear to me(as I faced such problem first). Here's the link <a href=""https://stackoverflow.com/questions/25651990/oserror-winerror-193-1-is-not-a-valid-win32-application"">OSError: [WinError 193] %1 is not a valid Win32 application</a></p>

<p>Hope to find a solution. 
Thank You </p>
"
61227025,"<p>I want to scrape all comments (~7000) from <a href=""https://www.focus.de/gesundheit/news/coronavirus-news-trump-prahlt-mit-allumfassender-macht_id_11576018.html"" rel=""nofollow noreferrer"">https://www.focus.de/gesundheit/news/coronavirus-news-trump-prahlt-mit-allumfassender-macht_id_11576018.html</a>. As the website does not show all comments, but gives only the possibility to load 10 comments a time, i try to load all comments with selenium in python and then give the output to BeautifulSoup. </p>

<p>The HTML segment of the website that corresponds with the button ""Weitere Kommentare (10)"" and which loads the next 10 comments is:</p>

<pre><code>&lt;div id=""further_comments"" class=""getMoreComments""&gt;                 
    &lt;a rel=""1"" class=""moreComments bluebutton""&gt;
         &lt;span&gt;Weitere Kommentare (10)&lt;/span&gt;
    &lt;/a&gt;                        
&lt;/div&gt;
</code></pre>

<p>It loads the next ten comments (second div below, only one shown here instead of ten) and a new button for loading another 10 comments (a):</p>

<pre><code>&lt;div class=""moreComments""&gt;
    &lt;div class=""comment clearfix open oid-15051615""&lt;/div&gt;
    &lt;div class=""getMoreComments""&gt;
        &lt;a class=""moreCommentsAjx bluebutton"" rel=""1""&gt;&lt;/a&gt;
    &lt;/div&gt;
&lt;/div&gt;
</code></pre>

<p>My approach was to write a script that automatically clicks ""Weitere Kommentare (10)"", waits until the next 10 comments and the next button ""Weitere Kommentare (10)"" is loaded, finds the button, clicks it again... until all comments are loaded. My attempt was following (I center the button to avoid a pop-up at the bottom of the page, which would obscure the button):</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException

ignored_exceptions = (NoSuchElementException, StaleElementReferenceException)

driver = webdriver.Firefox()
driver.implicitly_wait(10)
driver.get('https://www.focus.de/gesundheit/news/coronavirus-news-trump-prahlt-mit-allumfassender-macht_id_11576018.html')
driver.fullscreen_window()

button = driver.find_element_by_class_name(""moreComments.bluebutton"")
driver.execute_script('arguments[0].scrollIntoView({block: ""center"", inline: ""center""})', button)
driver.execute_script(""arguments[0].click();"", button)

while driver.find_element_by_class_name(""moreCommentsAjx.bluebutton""):
    element = WebDriverWait(driver, 10, ignored_exceptions=ignored_exceptions).until(EC.visibility_of_element_located((By.CLASS_NAME, ""moreCommentsAjx.bluebutton"")))
    driver.execute_script('arguments[0].scrollIntoView({block: ""center"", inline: ""center""})', element)
    element.click()

page_source = driver.page_source
</code></pre>

<p>Unfortunately that code never goes through. At some point the button ""Weitere Kommentare (10)"" just does not appear anymore and a ""NoSuchElementException: Unable to locate element: .moreCommentsAjx.bluebutton"" is thrown (weirdly despite it being supposed to ignore it). What puzzles me is, it´s not systematic. Sometimes it manages to load a couple hundreds comments before it fails, sometimes only 30 etc. Occasionally a StaleElementReferenceException is thrown (again it should not, but it does), when the scrolling seems to fail and does not center the button, but that's seldom.  </p>

<p>Thanks in advance for any help.</p>
"
61216957,"<p>I have this problem when I try to run this code using 3 folders of dataset. Previously, this code ran perfectly with only 2 folders inside the dataset folder, one called <code>normal</code>, the other <code>covid</code>. But in this case I added another one called <code>pneumonia</code> to make it a 3 category image classifier. I'm new in machine learning, so I investigated a lot about how to fix this, but every solution is different and also the code. I tried them but they didn't work, that's the reason why I'm asking for your help.</p>

<p>This code doesn't belong to me, it's an Adrian Rosebrock code, all the credit goes to him. It's about classifying X-ray images in COVID or normal cases, but the idea to improve this code add a new category to classify images with normal (non-COVID) pneumonia. That's why I added a new folder into the dataset. Hope you can help me, thanks!</p>

<pre><code># USAGE
python train.py --dataset dataset
</code></pre>

<pre class=""lang-py prettyprint-override""><code># import the necessary packages

from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from imutils import paths

import numpy as np
import argparse
import cv2
import os

# construct the argument parser and parse the arguments

ap = argparse.ArgumentParser()
ap.add_argument(""-d"", ""--dataset"", required=True,
    help=""path to input dataset"")
ap.add_argument(""-p"", ""--plot"", type=str, default=""plot.png"",
    help=""path to output loss/accuracy plot"")
ap.add_argument(""-m"", ""--model"", type=str, default=""covid19.model"",
    help=""path to output loss/accuracy plot"")
args = vars(ap.parse_args())

# initialize the initial learning rate, number of epochs to train for,
# and batch size

INIT_LR = 1e-3
EPOCHS = 1
BS = 8

# grab the list of images in our dataset directory, then initialize
# the list of data (i.e., images) and class images

print(""[INFO] loading images..."")
imagePaths = list(paths.list_images(args[""dataset""]))
data = []
labels = []

# loop over the image paths

for imagePath in imagePaths:
    # extract the class label from the filename
    label = imagePath.split(os.path.sep)[-2]

    # load the image, swap color channels, and resize it to be a fixed
    # 224x224 pixels while ignoring aspect ratio
    image = cv2.imread(imagePath)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = cv2.resize(image,(224, 224))

    # update the data and labels lists, respectively
    data.append(image)
    labels.append(label)

# convert the data and labels to NumPy arrays while scaling the pixel
# intensities to the range [0, 255]

data = np.array(data) / 255.0
labels = np.array(labels)

# perform one-hot encoding on the labels

lb = LabelBinarizer()
labels = lb.fit_transform(labels)
labels = to_categorical(labels)

# partition the data into training and testing splits using 80% of
# the data for training and the remaining 20% for testing

(trainX, testX, trainY, testY) = train_test_split(data, labels,
    test_size=0.20, stratify=labels, random_state=42)
</code></pre>

<p>This is the error message:</p>

<pre><code>[INFO] loading images...
Traceback (most recent call last):
  File ""train_covid19.py"", line 77, in &lt;module&gt;
    test_size=0.20, stratify=labels, random_state=42)
  File ""C:\Users\KQ\anaconda3\lib\site-packages\sklearn\model_selection\_split.py"", line 2143, in train_test_split
    train, test = next(cv.split(X=arrays[0], y=stratify))
  File ""C:\Users\KQ\anaconda3\lib\site-packages\sklearn\model_selection\_split.py"", line 1737, in split
    y = check_array(y, ensure_2d=False, dtype=None)
  File ""C:\Users\KQ\anaconda3\lib\site-packages\sklearn\utils\validation.py"", line 574, in check_array
    % (array.ndim, estimator_name))
ValueError: Found array with dim 3. Estimator expected &lt;= 2.
</code></pre>
"
61096541,"<p>I have the following code:</p>

<pre><code>for item in classification:
        re_item = re.findall((""var {} = \'(.*?)\'"").format(item), req, re.DOTALL)[0]
        re_item = ast.literal_eval(re_item)
        for item_2 in re_item:
                category = reclassification(item)
                longitude = str(item_2['geometry']['coordinates'][0])
                latitude = str(item_2['geometry']['coordinates'][1])
                kab = item_2['properties']['kab']
                description = item_2['properties']['description']
                title = item_2['properties']['title']
                jenis = item_2['properties']['jenis']
                try:
                        rs = item_2['properties']['rs']
                except:
                        rs = ''
                kec = item_2['properties']['kec']
                tanggal = item_2['properties']['tanggal']
                umur = item_2['properties']['umur']
                container = [category, longitude, latitude, kab, kec, description, title, jenis, rs, umur, tanggal]
                output = ','.join(container)
                f.write('{}\n'.format(output))

f.close()
print('Selesai! Cek file di ./data/covid_sulsel.csv')
</code></pre>

<p>Error</p>

<pre><code>File ""C:\Users\satrio_budbud\Anaconda4\lib\re.py"", line 223, in findall
  return _compile(pattern, flags).findall(string)

TypeError: cannot use a string pattern on a bytes-like object
</code></pre>
"
61263128,"<p>File
<a href=""https://www.dropbox.com/sh/cx9kasx83qmsi33/AABfOzVgzBuQe2ORU_t65J4Ta?dl=0"" rel=""nofollow noreferrer"">https://www.dropbox.com/sh/cx9kasx83qmsi33/AABfOzVgzBuQe2ORU_t65J4Ta?dl=0</a></p>

<p>What I have done.</p>

<p>Here is the code I used
import pands as pd</p>

<h1>Read the csv file and set the file as 'covid'</h1>

<p>covid.groupby('continent').TotalCases() it generates 
KeyError: 'continent'</p>
"
61162211,"<p>Im trying to train a model to detect fake news and am trying to make a bag of words model. However when I try to fit my model i get this error: </p>

<pre><code>Traceback (most recent call last):
  File ""/Users/amanpuranik/PycharmProjects/covid/fake news 2.py"", line 89, in &lt;module&gt;
    headline_bow.fit(lower)
  File ""/Users/amanpuranik/PycharmProjects/covid/venv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py"", line 1186, in fit
    self.fit_transform(raw_documents)
  File ""/Users/amanpuranik/PycharmProjects/covid/venv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py"", line 1220, in fit_transform
    self.fixed_vocabulary_)
  File ""/Users/amanpuranik/PycharmProjects/covid/venv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py"", line 1131, in _count_vocab
    for feature in analyze(doc):
  File ""/Users/amanpuranik/PycharmProjects/covid/venv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py"", line 103, in _analyze
    doc = preprocessor(doc)
  File ""/Users/amanpuranik/PycharmProjects/covid/venv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py"", line 68, in _preprocess
    doc = doc.lower()
AttributeError: 'list' object has no attribute 'lower'
</code></pre>

<p>Im not sure why im getting this error. This is the dataset im trying to fit: </p>

<pre><code>[['four', 'way', 'bob', 'corker', 'skewer', 'donald', 'trump'], ['linklat', ""'s"", 'war', 'veteran', 'comedi', 'speak', 'modern', 'america', ',', 'say', 'star'], ['trump', '’', 'fight', 'with', 'corker', 'jeopard', 'his', 'legisl', 'agenda']]
</code></pre>

<p>Here is the rest of my code: </p>

<pre><code>data = pd.read_csv(""/Users/amanpuranik/Desktop/fake-news-detection/data.csv"")
data = data[['Headline', ""Label""]]

x = np.array(data['Headline'])
print(x[0])
y = np.array(data[""Label""])

# tokenization of the data here'
headline_vector = []

for  headline in x:
    headline_vector.append(word_tokenize(headline))

print(headline_vector)



stopwords = set(stopwords.words('english'))

#removing stopwords at this part
filtered = [[word for word in sentence if word not in stopwords]
            for sentence in headline_vector]
#print(filtered)


stemmed2 = [[stem(word) for word in headline] for headline in filtered]
#print(stemmed2)

#lowercase
lower = [[word.lower() for word in headline] for headline in stemmed2] #start here

#organising
articles = []


for headline in lower:
    articles.append(headline)

#creating the bag of words model

headline_bow = CountVectorizer()
headline_bow.fit(lower)
a = headline_bow.transform(lower)
</code></pre>

<p>why is this happening and what can I do to fix this? </p>
"
61162881,"<p>I have some data here:</p>

<pre><code>       Country/Region  1/22/20  1/23/20  1/24/20  1/25/20  1/26/20  1/27/20
0               Afghanistan        0        0        0        0        0   
1                   Albania        0        0        0        0        0   
2                   Algeria        0        0        0        0        0   
3                   Andorra        0        0        0        0        0   
4                    Angola        0        0        0        0        0   
5       Antigua and Barbuda        0        0        0        0        0   
6                 Argentina        0        0        0        0        0   
7                   Armenia        0        0        0        0        0   
8                 Australia        0        0        0        0        0   
9                 Australia        0        0        0        0        3   
10                Australia        0        0        0        0        0   
11                Australia        0        0        0        0        0   
12                Australia        0        0        0        0        0   
13                Australia        0        0        0        0        0   
14                Australia        0        0        0        0        1   
15                Australia        0        0        0        0        0   
16                  Austria        0        0        0        0        0   
17               Azerbaijan        0        0        0        0        0   
18                  Bahamas        0        0        0        0        0   
19                  Bahrain        0        0        0        0        0   
20               Bangladesh        0        0        0        0        0   

</code></pre>

<p>I'd like to rearrange this so that the dates are rows, while the countries are columns. Like this:</p>

<pre><code>Country/Region   Afghanistan   Albania

1/22/20              0            0
1/23/20              0            0
1/24/20              0            0

</code></pre>

<p>and so on. I've tried to use pd.melt, but can't quite nail how to get the desired output. Here's my attempt:</p>

<pre><code>%matplotlib inline
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math

data = pd.read_csv(""covid.csv"", sep="","")

data = data.drop([""Province/State"",""Lat"",""Long""], axis=1)

data_melted = data.melt(value_vars=data.columns[1:], var_name=""Date"",value_name=""Cases"")

          Date  Cases
0      1/22/20      0
1      1/22/20      0
2      1/22/20      0
3      1/22/20      0
4      1/22/20      0
5      1/22/20      0
6      1/22/20      0
7      1/22/20      0
8      1/22/20      0
9      1/22/20      0
10     1/22/20      0
11     1/22/20      0
12     1/22/20      0
13     1/22/20      0
14     1/22/20      0


</code></pre>

<p>I also tried:</p>

<pre><code>data_melted = data.melt(value_vars=[data.columns[1:], ""Country/Region""])

</code></pre>

<p>but this came up with a TypeError: unhashable type: 'Index' even though ""Country/Region"" wasn't the index.</p>

<p>Would appreciate any help on this.</p>
"
60894411,"<p>I'm working on the number of COVID-19 death cases by state and seeing whether a high state population contributes to a higher death likelihood from those who have caught COVID-19. </p>

<p>Currently working on splitting my dataframe into two groups, but the way I have things set up, that split would rely on two factors, not just one - ex. highpopulation_highdeath (this means the state population is greater than the median and the death rate is greater than the median) and the other group would be highpopulation_lowdeath (state population greater than the median and death rate is less than the median). Current code is below, but I keep getting an invalid syntax error. So I'm wondering if you can't split a dataframe into two groups based on two variables?</p>

<h1>Split the deaths_to_case dataset into two groups</h1>

<pre><code>highpop_highdeath = df.iloc[(df'StatePopulation' &gt; 4342705.0), (df'deaths_to_cases' &gt; 0.012143070253953211).values]
highpop_highdeath.name = 'States with a high population and high death rate'
highpop_lowdeath = df.iloc[(df'StatePopulation'&gt; 4342705.0), (df'deaths_to_cases' &lt;= 0.012143070253953211).values]
highpop_lowdeath.name = 'States with a high population and low death rate'
</code></pre>
"
60870507,"<p>im having an issue when running this, It says value error: cannot transform naive geometries. Please set a crs on the object first.</p>

<pre><code># data frame loading
df = pd.read_csv('C:/Users/barke/PycharmProjects/UK-COVID-19/data/NHSRcasestable.csv')

# geodataframe
gdf = geopandas.GeoDataFrame(
    df, geometry=geopandas.points_from_xy(df.Longitude, df.Latitude))

# plotting coordinates over a country level map
world = geopandas.read_file(geopandas.datasets.get_path(""naturalearth_lowres""))
ax = world[(world.name == ""United Kingdom"")].plot(color='white', edgecolor='black')

# base map addition
gdf = gdf.to_crs(epsg=27700)
ax = gdf.plot(figsize=(10, 10), alpha=0.5, edgecolor='k')
ctx.add_basemap(ax)
</code></pre>
"
61204791,"<p>I am trying to make an API request of Washington Post and extract all articles matching my <a href=""https://www.washingtonpost.com/newssearch/?query=coronavirus&amp;sort=Relevance&amp;datefilter=12%20Months"" rel=""nofollow noreferrer"">search query</a>.</p>

<pre><code>import requests
import json
import pandas as pd

#---------Define Parameters for API access
params = {
    ""count"": ""100"",
    ""datefilter"":""displaydatetime:[NOW/DAY-1YEAR TO NOW/DAY+1DAY]"",
    ""facets.fields"":""{!ex=include}contenttype,{!ex=include}name"",
    ""highlight.fields"":""headline,body"",
    ""highlight.on"":""true"",
    ""highlight.snippets"":""1"",
    ""query"":""coronavirus"",
    ""sort"":""displaydatetime desc"",
    ""startat"": ""0"",
    ""callback"":""angular.callbacks._0""}

#----------Define Funktion
def WP_Scraper(url):
 #-------------Define empty lists to be scraped
    WP_title   = []
    WP_date   = []
    WP_article   = []
    WP_link = []

    with requests.Session() as req:
        for item in range(0, 9527, 100):
            print(f""Extracting Article# {item +1}"")
            params[""startat""] = item
            r = req.get(url, params=params).json()
            for loop in r['results']:
                WP_title.append(loop['headline'])
                WP_date.append(loop['pubdatetime'])
                WP_link.append(loop['contenturl'])
                WP_article.append(loop['blurb'])

 #-------------Save in DF                  
    df = pd.DataFrame()
    df['title'] = WP_title
    df['date'] = WP_date      
    df['article'] = WP_article 
    df['link']=WP_link
    return df  

WP_data = WP_Scraper(""https://sitesearchapp.washingtonpost.com/sitesearch-api/v2/search.json"")
</code></pre>

<p>I get the following error when calling the function: 
<a href=""https://i.stack.imgur.com/lDo2C.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lDo2C.png"" alt=""enter image description here""></a></p>

<p>Does anyone know what is causing the error or if there is a more efficient method? </p>

<p>I searched stackoverflow for this answer. If this is a duplicate, please point me in the right direction. Thanks in advance.</p>
"
60836588,"<p>how to fix this python error (pandas lib).
why does it happen? please help</p>

<pre><code>import pandas as pd
url='https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_daily_reports/03-23-2020.csv'
data = pd.read_csv(url) 
data.describe()
</code></pre>

<blockquote>
  <p>ParserError                               Traceback (most recent call
  last)  in ()
        1 import pandas as pd
        2 url='<a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_daily_reports/03-23-2020.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_daily_reports/03-23-2020.csv</a>'
  ----> 3 data = pd.read_csv(url)
        4 data.describe()</p>
  
  <p>3 frames /usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py
  in read(self, nrows)    2057     def read(self, nrows=None):    2058<br>
  try:
  -> 2059             data = self._reader.read(nrows)    2060         except StopIteration:    2061             if self._first_chunk:</p>
</blockquote>
"
60872024,"<p>I tried to specify x and y axis ticks on Bokeh plot as [0,25,50,75,100] and try major_label_overrides x as distance {0:'alone(0)',25: 'not close(25)', 50: 'alright close(50)', 75: 'middle close(75)', 100:'very close(100)'},  y axis custom as frequency {0:'never',25: 'once a year', 50: 'once a month', 75: 'once a week', 100:'everyday(100)'}. However, it shows an error. Thank you. </p>

<blockquote>
  <p>ValueError: expected an instance of type Ticker, got [25, 50, 75, 100]
  of type list</p>
</blockquote>

<p>I have tried 
p.xaxis.ticker = FixedTicker(ticks=[0, 25, 50,75,100]) 
it fixes the tick problem but I can't customise it to frequency. </p>

<p>Below is my code and github repository. 
<a href=""https://github.com/Lastget/Covid19_Job_risks.git"" rel=""nofollow noreferrer"">https://github.com/Lastget/Covid19_Job_risks.git</a></p>

<pre><code>import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from bokeh.io import output_file, show
from bokeh.plotting import figure
from bokeh.models import ColumnDataSource, Select
from bokeh.models import HoverTool, Label, LabelSet
from bokeh.io import curdoc
from bokeh.layouts import row
from bokeh.models.renderers import GlyphRenderer
from math import pi
from bokeh.models import FixedTicker

# Improt files
expose = pd.read_csv(r'Exposed_to_Disease_or_Infections.csv',encoding='gbk')
expose.head() #context, code, occupation 
expose.shape #(968,3)

physical = pd.read_csv('Physical_Proximity.csv')
physical.head()
physical.shape #(967,3)

TW_job = pd.read_excel('Small_Chinese.xlsx',encoding='utf-8')
TW_job.shape #(968,3)
TW_job = TW_job.iloc[:,:2]
TW_job.head()

#Merge
temp_df = pd.merge(expose,physical,on=['Code','Occupation'])
temp_df.head()
temp_df.columns=['Expose_frequency','Code','Occupation','Physical_proximity']
temp_df.head()
full_table = temp_df.merge(TW_job,how='left',on='Code')
full_table.shape #967,5

# Delete Expose frequency for Rock splitter, timing deivce 
full_table = full_table.iloc[:965,:]

# change expose  to int64 
full_table['Expose_frequency']=full_table['Expose_frequency'].astype('int64')
full_table.info()

# Start plotting 
source = ColumnDataSource(full_table) 
p = figure(title=""各職業對新型冠狀病毒之風險圖"", x_axis_label='工作時與人接近程度', y_axis_label='工作時暴露於疾病頻率',
          plot_width=900, plot_height=600)
p.circle('Physical_proximity','Expose_frequency',
          name = 'allcircle',
          size=10,fill_alpha=0.2, source=source, fill_color='gray', hover_fill_color='firebrick', hover_line_color=""firebrick"", line_color=None)
hover = HoverTool(tooltips=[('職業','@TW_Occupation'),('Occupation','@Occupation'),('暴露於疾病指數','@Expose_frequency'),('與人接近距離指數','@Physical_proximity')])
p.add_tools(hover)


p.xaxis.ticker = [0, 25, 50,75,100]
p.xaxis.major_label_overrides = {0:'獨自工作(0)',25: '不近(25)', 50: '稍微近(50)', 75: '中等距離(75)', 100:'非常近(100)'}
p.yaxis.ticker = [0, 25, 50,75,100]
p.yaxis.major_label_overrides = {0:'從不(0)',25: '一年一次(25)', 50: '一個月一次(50)', 75: '一週一次(75)', 100:'每天(100)'}
p.yaxis.major_label_orientation = pi/4

# remove tool bar 
p.toolbar.logo = None
p.toolbar_location = None

def remove_glyphs(figure, glyph_name_list):
    renderers = figure.select(dict(type=GlyphRenderer))
    for r in renderers:
        if r.name in glyph_name_list:
            col = r.glyph.y
            r.data_source.data[col] = [np.nan] * len(r.data_source.data[col])


# Define a callback function 
def update_plot(attr, old, new):
       remove_glyphs(p,['point_select'])
       old_choice=full_table[full_table['TW_Occupation']==old]  

       choice=full_table[full_table['TW_Occupation']==new]
       a=choice['Physical_proximity']
       b=choice['Expose_frequency']
       p.circle(a,b,size=10,fill_alpha=1,fill_color=None,line_color=""firebrick"", name='point_select')

# Add Select 
select = Select(title='請選擇工作', options=sorted(full_table['TW_Occupation'].tolist()), value='')

# Attach the update_plot callback to the 'value' property of select
select.on_change('value', update_plot)

#layout 
layout = row(p, select)

# Add the plot to the current document
curdoc().add_root(layout)
</code></pre>
"
61666646,"<p>I know I am definitely doing something stupid here.</p>

<p>Building the list of countries works and setting the other api call directly to a country works. I'm trying to make a loop to pull all of the data I need in one go.</p>

<pre><code># Import the libraries
import requests
import requests_cache

import json

import pandas as pd
import numpy as np
from pandas import Series, DataFrame, json_normalize

from datetime import datetime

import matplotlib.pyplot as plt

# Make an API call and store the response.
sum_url = 'https://api.covid19api.com/summary'
sum_data = requests.get(sum_url)

# Store the API response in a variable.
available_sum_data = sum_data.json()
sum_df = json_normalize(available_sum_data[""Countries""])

# Make a list of countries
countries = sum_df['Country'].tolist()

# Create an empty dataframe
dataset = pd.DataFrame()

# loop through countries list to call data from dayone api
i = country

for i in countries:
    url = f'https://api.covid19api.com/total/dayone/country/{country}'
    data = requests.get(url)

    available_data = data.json()
    df = json_normalize(available_data)

pd.concat(df)
</code></pre>

<p>It's just getting stuck and giving me back this when I stop the kernel: </p>

<p>SSLError: HTTPSConnectionPool(host='api.covid19api.com', port=443): Max retries exceeded with url: /total/dayone/country/ALA%20Aland%20Islands (Caused by SSLError(SSLError(""bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])"")))</p>
"
60776508,"<p>I have some challenges with a wiki table and hope someone who has done it before can give me advice. From the wikitable mw-collapsible table  I need to get the data into a pandas data frames. (The code does not work). I am not sure how to get this going. In this initial attempt to pull data it ValueError: Length of values does not match length of index. Will appreciate your help!</p>

<pre><code>import urllib.request
url = ""https://en.wikipedia.org/wiki/2020_coronavirus_pandemic_in_South_Africa""
page = urllib.request.urlopen(url)
from bs4 import BeautifulSoup
soup = BeautifulSoup(page, ""lxml"")

# use the 'find_all' function to bring back all instances of the 'table' tag in the HTML and store in 'all_tables' variable
all_tables=soup.find_all(""table"")
all_tables

right_table=soup.find('table', class_='wikitable mw-collapsible')
right_table

A=[]
B=[]
C=[]
D=[]
E=[]
F=[]
G=[]
H=[]
I=[]
J=[]
K=[]
L=[]
M=[]
N=[]
O=[]
P=[]
Q=[]
U=[]

for row in right_table.findAll('tr'):
    cells=row.findAll('td')
    if len(cells)==17:
        A.append(cells[0].find(text=True))
        B.append(cells[1].find(text=True))
        C.append(cells[2].find(text=True))
        D.append(cells[3].find(text=True))
        E.append(cells[4].find(text=True))
        F.append(cells[5].find(text=True))
        G.append(cells[6].find(text=True))
        H.append(cells[7].find(text=True))
        I.append(cells[8].find(text=True))
        J.append(cells[9].find(text=True))
        K.append(cells[10].find(text=True))
        L.append(cells[11].find(text=True))
        M.append(cells[12].find(text=True))
        N.append(cells[13].find(text=True))
        P.append(cells[14].find(text=True))
        Q.append(cells[15].find(text=True))
        U.append(cells[16].find(text=True))

import pandas as pd
df=pd.DataFrame(A,columns=['DATE'])
df['EC']=B
df['FS']=C
df['GAU']=D
df['KJN']=F
df['LIM']=G
df['MPU']=H
df['NW']=I
df['NC']=J
df['WC']=K
df['NEW']=L
df['TOTAL']=M
df['NEW']=N
df['TOTAL']=O
df['REC']=P
df['TESTED']=Q
df['REF']=U
df
</code></pre>
"
60691705,"<p>I am trying to access JSON data on a website (<a href=""https://petition.parliament.uk/petitions/301397.json"" rel=""nofollow noreferrer"">https://petition.parliament.uk/petitions/301397.json</a>) for visualisation purposes.  I am trying to plot the ""signatures_by_country"" segment but just cannot seem to access this with the following code</p>

<pre><code>info = json.loads (data)
print (info)
print (info[""signatures_by_country""][0][""name""])
</code></pre>

<p>The second print errors out.  Below is a sample of the data </p>

<pre><code>{""links"":{""self"":""https://petition.parliament.uk/petitions/301397.json""},""data"":{""type"":""petition"",""id"":301397,""attributes"":{""action"":""Implement UK lockdown for preventing spread of COVID19"",""background"":""The UK needs to follow suit the containment procedures of countries that have been greatly affected by COVID19 such as Italy.\r\n\r\nThe UK should restrict unnecessary travel between towns and cities. Travel permitted should only be for work or emergencies. Public gatherings should also be discouraged."",""additional_details"":""It is time the government should prioritise the health of the public and should consider how vital it is to implement effective containment now.\r\n\r\nIt is better to spend money to contain the virus and treating the relatively low numbers who are ill now rather than wait for more casualties."",""committee_note"":"""",""state"":""open"",""signature_count"":190004,""created_at"":""2020-03-11T00:16:42.594Z"",""updated_at"":""2020-03-15T09:37:54.000Z"",""rejected_at"":null,""opened_at"":""2020-03-12T16:54:59.310Z"",""closed_at"":null,""moderation_threshold_reached_at"":""2020-03-11T13:44:24.000Z"",""response_threshold_reached_at"":""2020-03-13T10:32:54.000Z"",""government_response_at"":null,""debate_threshold_reached_at"":""2020-03-14T10:57:34.000Z"",""scheduled_debate_date"":null,""debate_outcome_at"":null,""creator_name"":""Beamari Alarva Suerte"",""rejection"":null,""government_response"":null,""debate"":null,""departments"":[{""acronym"":""DHSC"",""name"":""Department of Health and Social Care"",""url"":""https://www.gov.uk/government/organisations/department-of-health-and-social-care""}],""signatures_by_country"":[{""name"":""Albania"",""code"":""AL"",""signature_count"":2},{""name"":""Australia"",""code"":""AU"",""signature_count"":19},{""name"":""Austria"",""code"":""AT"",""signature_count"":6},{""name"":""Bahrain"",""code"":""BH"",""signature_count"":2},{""name"":""Belarus"",""code"":""BY"",""signature_count"":1},{""name"":""Belgium"",""code"":""BE"",""signature_count"":7},{""name"":""Brazil"",""code"":""BR"",""signature_count"":4},{""name"":""Bulgaria"",""code"":""BG"",""signature_count"":3},{""name"":""Cambodia"",""code"":""KH"",""signature_count"":1},{""name"":""Canada"",""code"":""CA"",""signature_count"":22},{""name"":""Cayman Islands"",""code"":""KY"",""signature_count"":1},{""name"":""Chile"",""code"":""CL"",""signature_count"":1},{""name"":""China"",""code"":""CN"",""signature_count"":20},{""name"":""Colombia"",""code"":""CO"",""signature_count"":1},{""name"":""Cyprus"",""code"":""CY"",""signature_count"":12},{""name"":""Czechia"",""code"":""CZ"",""signature_count"":7},{""name"":""Denmark"",""code"":""DK"",""signature_count"":10},{""name"":""Egypt"",""code"":""EG"",""signature_count"":2},{""name"":""Estonia"",""code"":""EE"",""signature_count"":1},{""name"":""Finland"",""code"":""FI"",""signature_count"":6},{""name"":""France"",""code"":""FR"",""signature_count"":92},{""name"":""Germany"",""code"":""DE"",""signature_count"":34},{""name"":""Gibraltar"",""code"":""GI"",""signature_count"":6},{""name"":""Greece"",""code"":""GR"",""signature_count"":16},{""name"":""Guernsey"",""code"":""GG"",""signature_count"":7},{""name"":""Hong Kong"",""code"":""HK"",""signature_count"":41},{""name"":""Hungary"",""code"":""HU"",""signature_count"":4},{""name"":""
</code></pre>
"
60843170,"<p>I am building a classification model for COVID-19 by using Logistic Regression. I am using jupyter notebook and I am importing Logistic Regression by <code>from sklearn.linear_model import LogisticRegression</code>.
The following import error pops up. </p>

<pre><code>---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
&lt;ipython-input-30-d98c89d6b4be&gt; in &lt;module&gt;
----&gt; 1 from sklearn.linear_model import LogisticRegression

~\Anaconda3\lib\site-packages\sklearn\__init__.py in &lt;module&gt;
    80     from . import _distributor_init  # noqa: F401
    81     from . import __check_build  # noqa: F401
---&gt; 82     from .base import clone
    83     from .utils._show_versions import show_versions
    84 

~\Anaconda3\lib\site-packages\sklearn\base.py in &lt;module&gt;
    18 
    19 from . import __version__
---&gt; 20 from .utils import _IS_32BIT
    21 
    22 _DEFAULT_TAGS = {

~\Anaconda3\lib\site-packages\sklearn\utils\__init__.py in &lt;module&gt;
    25 from ..exceptions import DataConversionWarning
    26 from .deprecation import deprecated
---&gt; 27 from .fixes import np_version
    28 from .validation import (as_float_array,
    29                          assert_all_finite,

~\Anaconda3\lib\site-packages\sklearn\utils\fixes.py in &lt;module&gt;
    16 import scipy.sparse as sp
    17 import scipy
---&gt; 18 import scipy.stats
    19 from scipy.sparse.linalg import lsqr as sparse_lsqr  # noqa
    20 

~\Anaconda3\lib\site-packages\scipy\stats\__init__.py in &lt;module&gt;
    382 from __future__ import division, print_function, absolute_import
    383 
--&gt; 384 from .stats import *
    385 from .distributions import *
    386 from .morestats import *

~\Anaconda3\lib\site-packages\scipy\stats\stats.py in &lt;module&gt;
    183 import scipy.special as special
    184 from scipy import linalg
--&gt; 185 from . import distributions
    186 from . import mstats_basic
    187 from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,

~\Anaconda3\lib\site-packages\scipy\stats\distributions.py in &lt;module&gt;
    8 from __future__ import division, print_function, absolute_import
    9 
---&gt; 10 from ._distn_infrastructure import (entropy, rv_discrete, rv_continuous,
    11                                     rv_frozen)
    12 

~\Anaconda3\lib\site-packages\scipy\stats\_distn_infrastructure.py in &lt;module&gt;
    23 
    24 # for root finding for discrete distribution ppf, and max likelihood estimation
---&gt; 25 from scipy import optimize
    26 
    27 # for functions of continuous distributions (e.g. moments, entropy, cdf)

~\Anaconda3\lib\site-packages\scipy\optimize\__init__.py in &lt;module&gt;
    388 
    389 from .optimize import *
--&gt; 390 from ._minimize import *
    391 from ._root import *
    392 from ._root_scalar import *

~\Anaconda3\lib\site-packages\scipy\optimize\_minimize.py in &lt;module&gt;
    28 from ._trustregion_krylov import _minimize_trust_krylov
    29 from ._trustregion_exact import _minimize_trustregion_exact
---&gt; 30 from ._trustregion_constr import _minimize_trustregion_constr
    31 
    32 # constrained minimization

~\Anaconda3\lib\site-packages\scipy\optimize\_trustregion_constr\__init__.py in &lt;module&gt;
    2 
    3 
----&gt; 4 from .minimize_trustregion_constr import _minimize_trustregion_constr
    5 
    6 __all__ = ['_minimize_trustregion_constr']

~\Anaconda3\lib\site-packages\scipy\optimize\_trustregion_constr\minimize_trustregion_constr.py in &lt;module&gt;
    2 import time
    3 import numpy as np
----&gt; 4 from scipy.sparse.linalg import LinearOperator
    5 from .._differentiable_functions import VectorFunction
    6 from .._constraints import (

~\Anaconda3\lib\site-packages\scipy\sparse\linalg\__init__.py in &lt;module&gt;
    114 from .dsolve import *
    115 from .interface import *
--&gt; 116 from .eigen import *
    117 from .matfuncs import *
    118 from ._onenormest import *

~\Anaconda3\lib\site-packages\scipy\sparse\linalg\eigen\__init__.py in &lt;module&gt;
    9 from __future__ import division, print_function, absolute_import
    10 
---&gt; 11 from .arpack import *
    12 from .lobpcg import *
    13 

~\Anaconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\__init__.py in &lt;module&gt;
    20 from __future__ import division, print_function, absolute_import
    21 
---&gt; 22 from .arpack import *

~\Anaconda3\lib\site-packages\scipy\sparse\linalg\eigen\arpack\arpack.py in &lt;module&gt;
    43 __all__ = ['eigs', 'eigsh', 'svds', 'ArpackError', 'ArpackNoConvergence']
    44 
---&gt; 45 from . import _arpack
    46 import numpy as np
    47 import warnings

ImportError: DLL load failed: The specified procedure could not be found.
</code></pre>

<h3>In the same python installation I tried importing LogisitcRegression in Spyder and it is imported successfully.</h3>
"
61299678,"<p>Trying to scrape this website to get the state name, cases, deaths to pass in csv file but when i run the program keep getting a error: </p>

<pre><code>page = requests.get(""https://www.cnn.com/interactive/2020/health/coronavirus-us-maps-and-cases/"")
soup = BeautifulSoup(page.content, 'html.parser')

state_table = soup.find(id='root')

items = state_table.find(class_='region-table-list')

states = [s.get_text() for s in items.find_all(class_='region')]

case = [c2.get_text() for c2 in items.find_all(class_='cases numeric')]

deaths = [c2.get_text() for c2 in items.find_all(class_ = 'deaths numeric')]


details = pd.DataFrame(
   {'State': states,
    'Cases': case,
    'Death': deaths,
    }
)
details.to_csv('details.csv') 

    states = [s.get_text() for s in items.find_all(class_='region')]
    AttributeError: 'NoneType' object has no attribute 'find_all'
</code></pre>
"
61588984,"<p>I'm currently encountering this error: </p>

<blockquote>
  <p>KeyError: ""['Malaysia' 'Singapore'] not in index""</p>
</blockquote>

<p>with the error pointing at :</p>

<blockquote>
  <p>---> 37         wide_data = wide_data[['Malaysia','Singapore']]</p>
</blockquote>

<p>Upon checking <strong>wide_data</strong> with <code>print(wide_data.columns)</code> it returns :</p>

<pre><code>MultiIndex([( 'total_cases',  'Malaysia'),
            ( 'total_cases', 'Singapore'),
            (   'new_cases',  'Malaysia'),
            (   'new_cases', 'Singapore'),
            ('total_deaths',  'Malaysia'),
            ('total_deaths', 'Singapore'),
            (  'new_deaths',  'Malaysia'),
            (  'new_deaths', 'Singapore')],
           names=[None, 'location'])
</code></pre>

<p>Both does exist. I'm not sure where did my code goes wrong.</p>

<p>Below are my code snippet and <a href=""https://ourworldindata.org/coronavirus-source-data"" rel=""nofollow noreferrer"">Dataset</a> used:</p>

<pre><code>import plotly.express as px

df = pd.read_csv('covid-data-2020.csv', index_col='date', parse_dates=True)
data = df[df.location.isin(['Malaysia', 'Singapore'])]

wide_data = data.pivot(columns='location', values=list(data.columns[2:6]))
wide_data = wide_data[['Malaysia','Singapore']]
wide_data.reset_index(level=0, inplace=True)
fig = px.line(wide_data.melt(id_vars='date'), x='date', y='value', color='location')
fig.update_yaxes(title='Malaysia vs Singapore')
fig.show()
</code></pre>
"
61669998,"<pre><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('ggplot')


df = pd.read_csv('time_series_covid_19_deaths_US.csv')
df = df.drop(['UID','iso2','iso3','code3','FIPS','Admin2','Combined_Key'],axis =1)
for name, values in df.iteritems():
    if '/' in name:
        df.drop([name],axis=1,inplace =True)
df2 = df.set_index(['Lat','Long_'])
print(df2.head())
lat = df2[df2[""Lat""]]
print(lat)
long = df2[df2['Long_']]
</code></pre>

<p>Code is above. I got the data set from <a href=""https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset"" rel=""nofollow noreferrer"">https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset</a> - using the US deaths.
<a href=""https://i.stack.imgur.com/HVHoT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HVHoT.png"" alt=""What it looks like""></a></p>

<p>I have attached an image of the output. I do not know what this error means.</p>

<p>Apologies if worded ambiguously / incorrectly, or if there is a preexisting answer somewhere</p>
"
60913195,"<p>Hi I'm tring to run the code below and i get an error, HTTPError: Forbidden. It tells me that the line with a problem is in the requests.py file in the urllib folder. I wanted to extract data from an online website.</p>

<p><strong>This is my code which i try to run</strong></p>

<pre><code>import pandas as pd
import geopandas as gpd

data = pd.read_html('https://www.worldometers.info/coronavirus/')
</code></pre>

<p><strong>And this is the response i get from the spyder console</strong></p>

<pre><code>Python 3.8.2 (default, Mar 26 2020, 15:53:00)
</code></pre>

<p>Type ""copyright"", ""credits"" or ""license"" for more information.</p>

<p>IPython 7.13.0 -- An enhanced Interactive Python.</p>

<p>runfile('/home/evans/Desktop/GIS DEVELOPMENTS/PROJECTS/Coronavirus2020.py', wdir='/home/evans/Desktop/GIS DEVELOPMENTS/PROJECTS')
Traceback (most recent call last):</p>

<p>File ""/home/evans/Desktop/GIS DEVELOPMENTS/PROJECTS/Coronavirus2020.py"", line 5, in 
    data = pd.read_html('<a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a>')</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/html.py"", line 1085, in read_html
    return _parse(</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/html.py"", line 895, in _parse
    tables = p.parse_tables()</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/html.py"", line 213, in parse_tables
    tables = self._parse_tables(self._build_doc(), self.match, self.attrs)</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/html.py"", line 733, in _build_doc
    raise e</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/html.py"", line 714, in _build_doc
    with urlopen(self.io) as f:</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/site-packages/pandas/io/common.py"", line 141, in urlopen
    return urllib.request.urlopen(*args, **kwargs)</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/urllib/request.py"", line 222, in urlopen
    return opener.open(url, data, timeout)</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/urllib/request.py"", line 531, in open
    response = meth(req, response)</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/urllib/request.py"", line 640, in http_response
    response = self.parent.error(</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/urllib/request.py"", line 569, in error
    return self._call_chain(*args)</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/urllib/request.py"", line 502, in _call_chain
    result = func(*args)</p>

<p>File ""/home/evans/anaconda3/envs/myenv/lib/python3.8/urllib/request.py"", line 649, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)</p>

<p>HTTPError: Forbidden</p>

<p>The problem at first was that lxml was missing, so i decided to install it from my environment using <code>pip3 install lxml</code>, but this is the return message i got.</p>

<pre><code>Requirement already satisfied: lxml in /usr/lib/python3/dist-packages (4.4.1).
</code></pre>

<p>But this is not in my environment folder, it is in the base/root folder. So i just decided to use pip install lxml and it worked. Then when i executed it, it returned the above error.</p>

<p>I will appreciate any guidance to help me overcome this problem.</p>
"
60918991,"<p>I have been working on a project that deals with pandas and geopandas. But i came across an error with the last line. The .shp file is in my specified path and everything is fine. Below is my code</p>

<pre><code>import pandas as pd
import geopandas as gpd


from urllib.request import Request, urlopen

req = Request('https://www.worldometers.info/coronavirus/', headers={'User-Agent':'Mozilla/5.0'})
webpage = urlopen(req).read()


data = pd.read_html(webpage)

for data_cases in data:
print(data_cases)

data_cases = data_cases[['Country,Other', 'TotalCases']]

world_data = gpd.read_file(r'/home/evans/Desktop/GIS DEVELOPMENTS/PROJECTS/World_countries/World_Countries.shp')
</code></pre>

<p>Everything executes well with no errors on the console. But when i try opening the variable <em>world_data</em>, in the variable explorer, I get the error:</p>

<pre><code>Spyder was unable to retrieve the value of this variable from the console.

The error message was:
'tuple' object has no attribute 'raise_error'
</code></pre>

<p>I will appreciate any assistance. Thank you.</p>
"
61502845,"<p>I want to iterate through the columnn df['Social Distancing Advisory'] and replace elements by others using .replace(), but nothing seems to work when I set it up like this. </p>

<hr>

<pre><code>import pandas as pd 

df = pd.read_excel('/Users/Arthur/Desktop/COVID-RA/state_data.xlsx')

for column in df['Social Distancing Advisory']:

  if df['Social Distancing Advisory'] == 'sah':
    df['Social Distancing Advisory'].replace('sah','1')

  if df['Social Distancing Advisory'] == 'sip':    
    df['Social Distancing Advisory'].replace('sip','0')
df
</code></pre>

<p>ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().</p>
"
61217024,"<p>So i have this dataframe: </p>

<pre><code>    Text                                             target
    #Coronavirus is a cover for something else. #5...   D
    Crush the One Belt One Road !! \r\n#onebeltonf...   B
    RT @nickmyer: It seems to be, #COVID-19 aka #c...   B
    @Jerusalem_Post All he knows is how to destroy...   B
    @newscomauHQ Its gonna show us all. We will al...   B

</code></pre>

<p>Where Text are tweets and i am trying to get the count of each string in the text column and input the count into the dataframe. And i have tried this </p>

<pre><code>d = pd.read_csv('5gCoronaFinal.csv')
d['textlength'] = [len(int(t)) for t in d['Text']]
</code></pre>

<p>But it keeps giving me this error:</p>

<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-42-dabcab1de7b2&gt; in &lt;module&gt;
----&gt; 1 d['textlength'] = [len(t) for t in d['Text']]

&lt;ipython-input-42-dabcab1de7b2&gt; in &lt;listcomp&gt;(.0)
----&gt; 1 d['textlength'] = [len(t) for t in d['Text']]

TypeError: object of type 'float' has no len()
</code></pre>

<p>I've tried converting t to integer like so:</p>

<pre><code>d['textlength'] = [len(int(t)) for t in d['Text']]
</code></pre>

<p>but then it gives me this error:</p>

<pre><code>---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-43-9ae56e5f7912&gt; in &lt;module&gt;
----&gt; 1 d['textlength'] = [len(int(t)) for t in d['Text']]

&lt;ipython-input-43-9ae56e5f7912&gt; in &lt;listcomp&gt;(.0)
----&gt; 1 d['textlength'] = [len(int(t)) for t in d['Text']]

ValueError: invalid literal for int() with base 10: '#Coronavirus is a cover for something else. #5g is being rolled out and they are expecting lots to...what? Die from #60ghz +. They look like they are to keep the cold in? #socialdistancing #covid19 #

</code></pre>

<p>I need some help thanks!</p>
"
60599753,"<p>I'm trying to extract the Coronavirus from a website (<a href=""https://www.trackcorona.live"" rel=""nofollow noreferrer"">https://www.trackcorona.live</a>) but I got an error.</p>

<p>This is my code:</p>

<pre><code>response = requests.get('https://www.trackcorona.live')
data = BeautifulSoup(response.text,'html.parser')
li = data.find_all(class_='numbers')
confirmed = int(li[0].get_text())
print('Confirmed Cases:', confirmed)
</code></pre>

<p>It gives the following error (though it was working few days back) because it is returning an empty list (li)</p>

<pre><code> IndexError                               
 Traceback (most recent call last)
&lt;ipython-input-15-7a09f39edc9d&gt; in &lt;module&gt;
      2 data=BeautifulSoup(response.text,'html.parser')
      3 li=data.find_all(class_='numbers')
----&gt; 4 confirmed = int(li[0].get_text())
      5 countries = li[1].get_text()
      6 dead = int(li[3].get_text())

IndexError: list index out of range
</code></pre>

<p>​</p>
"
61175444,"<p>I am trying to get some data from an API but have been getting the error <code>'dict' object has no attribute 'META'</code> when I try to print it. I am using Requests module for this. Here is the code:</p>

<pre><code>url = ""https://coronavirus-map.p.rapidapi.com/v1/summary/region""

    querystring = {""region"":""Bangladesh""}

    headers = {
        'x-rapidapi-host': ""coronavirus-map.p.rapidapi.com"",
        'x-rapidapi-key': ""leaving this out :P""
    }

    request = requests.get(url, headers=headers, params=querystring).json()

    print(request.text)
</code></pre>

<p>Everything works on Postman. Can anyone help?</p>
"
60645163,"<p>I'm working on building a model using XGBoost to predict corona virus infections based on province and region codes. dataset: <a href=""https://www.kaggle.com/sudalairajkumar/covid19-in-italy"" rel=""nofollow noreferrer"">https://www.kaggle.com/sudalairajkumar/covid19-in-italy</a>.</p>

<p>I have split the data, but when I try to set up the model, I get the following error:</p>

<pre><code>XGBoostError: [16:16:15] C:/Users/Administrator/workspace/xgboost- 
win64_release_1.0.0/src/objective/multiclass_obj.cu:115: 
SoftmaxMultiClassObj: label must be in [0, num_class).
</code></pre>

<p>Code is as follows:</p>

<pre><code>train = df[['RegionCode','ProvinceCode']].astype(int)
test = df['TotalPositiveCases'].astype(int)
X_test, X_train, y_test, y_train = train_test_split(train, test, 
test_size=0.30, random_state=42)

train = xgb.DMatrix(X_train, label=y_train)
test = xgb.DMatrix(X_test, label=y_test)

param = {
'max_depth':4,
'eta':0.3,
'objective': 'multi:softmax',
'num_class': 3}
epochs = 10

model = xgb.train(param, train, epochs)
</code></pre>

<p>the model attribute is where I get the error</p>
"
61252805,"<p>Tried the following code it works one or two times then it stops and throws error. even If i pass a list with few values it works for while and then its is throwing the same error. not sure this is kind of an IP issue that's getting blocked with my request for clarity i am seeking your help</p>

<pre><code> import importlib 
    import googletrans 
    from googletrans import Translator
    lc_cntry = df_conf['Country/Region'].unique()
    result = translator.translate(lc_cntry, src='en',dest='ta')
    for translation in result:
        print( translation.text)


**error**
&gt;  : --------------------------------------------------------------------------
&gt;TypeError                                 Traceback (most recent call last)
&lt;ipython-input-75-9ff7a03a78a9&gt; in &lt;module&gt;
      3 from googletrans import Translator
      4 lc_cntry = df_conf['Country/Region'].unique()
----&gt; 5 result = translator.translate(lc_cntry, src='en',dest='ta')
      6 for translation in result:
      7     print( translation.text)

&gt;E:\ProgramData\Anaconda3\envs\covid\lib\site-packages\googletrans\client.py in translate(self, text, dest, src)
    170 
    171         origin = text
--&gt; 172         data = self._translate(text, dest, src)
    173 
    174         # this code will be updated when the format is changed.

&gt;E:\ProgramData\Anaconda3\envs\covid\lib\site-packages\googletrans\client.py in _translate(self, text, dest, src)
     73             text = text.decode('utf-8')
     74 
---&gt; 75         token = self.token_acquirer.do(text)
     76         params = utils.build_params(query=text, src=src, dest=dest,
     77                                     token=token)

&gt;E:\ProgramData\Anaconda3\envs\covid\lib\site-packages\googletrans\gtoken.py in do(self, text)
    199     def do(self, text):
    200         self._update()
--&gt; 201         tk = self.acquire(text)
    202         return to

&gt;E:\ProgramData\Anaconda3\envs\covid\lib\site-packages\googletrans\gtoken.py in acquire(self, text)
    145         # Convert text to ints
    146         for i in text:
--&gt; 147             val = ord(i)
    148             if val &lt; 0x10000:
    149                 a += [val]

&gt;TypeError: ord() expected a character, but string of length 11 found
</code></pre>

<p>Any changes to code will work permanently. Need your expert advice</p>
"
60643883,"<p>I'm doing a stupid 'anticoronavirus' for PC. 
This is the code: </p>

<pre><code>import tkinter as tk
from tkinter import *
from tkinter import ttk
import random
window=Tk()
window.geometry('500x500')
window.resizable(False, False)
window.title('Anti Corona')
window.config(bg='light blue')
anti=tk.Label(text='Anti Corona')
anti.config(bg='light blue', font=('Arial black', 50))
anti.pack()
anti2=tk.Label(text='')
anti2.config(bg='light blue', font=('Arial black', 100))
anti2.pack()
def scaner(self):
    self.f1=tk.Frame()
    self.f1.pack()
    self.progress=ttk.Progressbar(f1)
    self.progress.length(50)
    self.progress.pack() 
scan=tk.Button(window, text='Scan!')
scan.config(height=1, width=10, font=('Century gothic', 30, 'bold'), bg='green', disabledforeground='', command=scaner())
scan.pack()

window.mainloop()
</code></pre>

<p>The problem is it outputs an error: </p>

<pre><code>Traceback (most recent call last):
  File ""C:\Users\cicle.EAAULAINF1W-008\Desktop\Anticorona.py"", line 23, in &lt;module&gt;
    scan.config(height=1, width=10, font=('Century gothic', 30, 'bold'), bg='green', disabledforeground='', command=scaner())
TypeError: scaner() missing 1 required positional argument: 'self'
</code></pre>

<p>But when I quit all the <code>self</code> in the def, the output is:</p>

<pre><code>Traceback (most recent call last):
  File ""C:\Users\cicle.EAAULAINF1W-008\Desktop\Anticorona.py"", line 23, in &lt;module&gt;
    scan.config(height=1, width=10, font=('Century gothic', 30, 'bold'), bg='green', disabledforeground='', command=scaner())
  File ""C:\Users\cicle.EAAULAINF1W-008\Desktop\Anticorona.py"", line 20, in scaner
    progress.length(50)
AttributeError: 'Progressbar' object has no attribute 'length'
</code></pre>

<p>I don't know what to do! Help me, please!</p>
"
60756650,"<pre><code>PS D:\Py\PyDiscord\coronabot\covid19krbot&gt; heroku run python3 app.py
Running python3 app.py on ⬢ covid19krbot... up, run.7553 (Free)
bash: app.py: command not found
</code></pre>

<p>What is this Error? and How Can I Fix This Error?</p>
"
60963030,"<p>I have a Flask app created and the code below is part of a view.</p>

<pre><code>msg = Message(""[STATSUMM] DATA REQUESTED"", sender=""mateobonnett@gmail.com"",recipients=[form.email.data])

msg.attach('app/Covid/Files/Covid_19_2020-03-31.csv', 'application/octet-stream')

mail.send(msg)
</code></pre>

<p>It performs well when sending the email with no attachment. However, when attaching the csv file I get this error</p>

<pre><code>TypeError: expected bytes-like object, not NoneType
</code></pre>

<p>How can I fix it?</p>
"
61030241,"<p>I have run the below program method corona_dif.nlargest(15, 'Confirmed'),in the python 3.7,but  i got the following errors, can anyone explain to me the solution of the problem awaiting for your kind response
[<img src=""https://i.stack.imgur.com/xflyn.jpg"" alt=""error Screenshot"">]</p>
"
72680,"<p>Whenever I try to use the data augmentation ImageDataGenerator I'm getting an error like could not convert string to float. Here is my code.</p>

<pre><code>import numpy as np
import os
import cv2
import matplotlib.pyplot as plt

from pathlib import Path

jpeg_images = 
list(Path(r'D:\covid_deep_learning\train\train').glob('**/*.jpg'))
np.array([np.array(cv2.imread(str(file))).flatten() for file in jpeg_images])
folder = ['COVID19_AND_PNEUMONIA','NORMAL']
Path = r'D:\covid_deep_learning\train\train'
for i in range(2):
    listing = os.listdir(Path+'/'+folder[i])
    for file in listing :
        img = cv2.imread(Path+'/'+folder[i]+'/'+file)
        resize=cv2.resize(img,(70,70))
        cv2.imwrite(Path+'/'+folder[i]+'/'+file,resize)
        cv2.imshow('resize', img)
        plt.imshow(resize)
    print(listing)
    print(len(listing))
def load_images(path, df):
    train_image = []
    for i in tqdm(range(df.shape[0])):
        try:



            train_image.append(resize)
        except OSError:
            print(df['id'][i])
    image_array = np.array(train_image)   
    return image_array


train_image_path = r'D:\covid_deep_learning\train\train/'
test_image_path  = r'D:\covid_deep_learning\test/'

X = load_images(train_image_path,train)
test_images = load_images(test_image_path, test)

 X_train, X_test, y_train, y_test_class = train_test_split(X, y, random_state=42, test_size=0.2)
 y_train = pd.get_dummies(y_train)
 y_test = pd.get_dummies(y_test_class)
 model = Sequential()


model.add(Conv2D(32, (3, 3), padding=""same"",  activation='relu',input_shape=(70,70,3)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(3, 3)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding=""same"", activation='relu' ))
model.add(BatchNormalization())
model.add(Conv2D(64, (3, 3), padding=""same"", activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))


model.add(Conv2D(128, (3, 3), padding=""same"", activation='relu' ))
model.add(BatchNormalization())
model.add(Conv2D(128, (3, 3), padding=""same"", activation='relu' ))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())

model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))

model.add(Dense(256, activation='relu'))
model.add(Dropout(0.50))

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.25))

model.add(Dense(2, activation='softmax'))
model.summary()
opt = SGD(lr=1e-3, momentum=0.9, decay=1e-3 / 25)
model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img

datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest')

datagen.fit(X_train)
print('augmentation')
</code></pre>

<h2>After data augmentation I'm getting an error like this:</h2>

<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-61-f6bc9e2818e8&gt; in &lt;module&gt;
     11         fill_mode='nearest')
     12 
 ---&gt; 13 datagen.fit(X_train)
     14 print('augmentation')

~\Anaconda3\lib\site-packages\keras_preprocessing\image\image_data_generator.py in fit(self, x, augment, rounds, seed)
    924             seed: Int (default: None). Random seed.
    925        """"""
--&gt; 926         x = np.asarray(x, dtype=self.dtype)
    927         if x.ndim != 4:
    928             raise ValueError('Input to `.fit()` should have rank 4. '

~\Anaconda3\lib\site-packages\numpy\core\numeric.py in asarray(a, dtype, order)
    536 
    537     """"""
--&gt; 538     return array(a, dtype, copy=False, order=order)
    539 
    540 

ValueError: could not convert string to float: 'NORMAL2-IM-0340-0001.jpeg'
</code></pre>
"
61011675,"<p>I wan't to implement SEIR model of <a href=""https://www.aimspress.com/MBE/2020/3/2725"" rel=""nofollow noreferrer"">Effect of delay in diagnosis on transmission of COVID-19</a> (with little modification) using Python <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.curve_fit.html"" rel=""nofollow noreferrer"">curve_fit</a> and <a href=""https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html"" rel=""nofollow noreferrer"">odeint</a>. Without <code>curve_fit</code>, my code is like this:</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
from scipy.integrate import odeint
import matplotlib.pyplot as plt

def func_ode(y,t,qS,qSq,betaV1,betaV2,beta1,beta2,e1,eta1,eta2,etaH,delta2,deltaH,theta2,f1,f2,fH,d):

    S_q,S,E1,E2,H,R,D,V=y

    dSq=qS*S-qSq*S_q
    dS=qSq*S_q-(betaV1*V+betaV2*V+beta1*E1+beta2*E2)*S
    dE1=(betaV1*V+beta1*E1)*S-(e1+eta1)*E1
    dE2=(betaV2*V+beta2*E2)*S+e1*E1-(eta2+delta2+theta2)*E2
    dH=theta2*E2-(etaH+deltaH)*H # theta is for recovered
    dR=eta1*E1+eta2*E2+etaH*H # eta is for recovered
    dD=delta2*E2+deltaH*H # delta is for death
    dV=f1*E1+f2*E2+fH*H-d*V 

    dy=[dSq, dS, dE1, dE2, dH, dR, dD, dV]
    return dy

if __name__ == ""__main__"":
    ## Parameters (dummy)
    qS, qSq, betaV1, betaV2, beta1, beta2, e1, eta1, eta2, etaH, delta2, deltaH, theta2, f1, f2, fH, d = \
        0, 1e-4, 4e-9, 1e-9, 4e-9, 1e-9, 1/100, 1/21, 1/104, 1/10, 1/200, 1/10400, 1/3.5, 1400, 1000, 1700, 144

    ## Initial (dummy)
    y_0=[1000,100000000,10,1,0,0,0,100]

    ## Solve
    t= np.linspace(1,60,60)
    result=odeint(func_ode,y_0,t,args=(qS,qSq,betaV1,betaV2,beta1,beta2,e1,eta1,eta2,etaH,delta2,deltaH,theta2,f1,f2,fH,d))

    ## Plot
    plt.plot(t, result[:, 0], label='Sq')
    plt.plot(t, result[:, 1], label='S')
    plt.plot(t, result[:, 2], label='E1')
    plt.plot(t, result[:, 3], label='E2')
    plt.plot(t, result[:, 4], label='H')
    plt.plot(t, result[:, 5], label='R')
    plt.plot(t, result[:, 6], label='D')
    plt.plot(t, result[:, 7], label='V')
    plt.legend(loc='best')
    plt.xlabel('t')
    plt.grid()
    plt.show()
    pass

</code></pre>

<p>To use optimized parameters with input data, this is my <em>not working</em> code:</p>

<pre class=""lang-py prettyprint-override""><code>import numpy as np
from scipy.integrate import odeint
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
import os
import pandas as pd

def func_ode(y,t,qS,qSq,betaV1,betaV2,beta1,beta2,e1,eta1,eta2,etaH,delta2,deltaH,theta2,f1,f2,fH,d):

    S_q,S,E1,E2,H,R,D,V=y

    dSq=qS*S-qSq*S_q
    dS=qSq*S_q-(betaV1*V+betaV2*V+beta1*E1+beta2*E2)*S
    dE1=(betaV1*V+beta1*E1)*S-(e1+eta1)*E1
    dE2=(betaV2*V+beta2*E2)*S+e1*E1-(eta2+delta2+theta2)*E2
    dH=theta2*E2-(etaH+deltaH)*H # theta is for recovered
    dR=eta1*E1+eta2*E2+etaH*H # eta is for recovered
    dD=delta2*E2+deltaH*H # delta is for death
    dV=f1*E1+f2*E2+fH*H-d*V 

    dy=[dSq, dS, dE1, dE2, dH, dR, dD, dV]
    return dy

def func_y(t,qS,qSq,betaV1,betaV2,beta1,beta2,e1,eta1,eta2,etaH,delta2,deltaH,theta2,f1,f2,fH,d,y_0):
    """"""
    Solution to the ODE y'(t) = f(t,y,parameters) with initial condition y(0) = y_0
    """"""
    y = odeint(func_ode, y_0, t, args=(qS,qSq,betaV1,betaV2,beta1,beta2,e1,eta1,eta2,etaH,delta2,deltaH,theta2,f1,f2,fH,d))
    return y[1:,:]

if __name__ == ""__main__"":
    file_name='Data Dummy.xlsx'
    current_path=os.getcwd()
    file_path=os.path.join(current_path,file_name)
    sheet_name='Sheet1'

    df_raw=pd.read_excel(file_path,sheet_name=sheet_name)
    numpy_data=df_raw[[
        'Self-quarantine susceptible',
        'Susceptible',
        'E1 (OTG)',
        'E2 (ODP)',
        'H (Hospitalized: PDP + Positif)',
        'R (Sembuh)',
        'D (Meninggal)',
        'V (Virus)'
    ]].to_numpy()               

    ## Parameters (dummy)
    qS, qSq, betaV1, betaV2, beta1, beta2, e1, eta1, eta2, etaH, delta2, deltaH, theta2, f1, f2, fH, d = \
        0, 1e-4, 4e-9, 1e-9, 4e-9, 1e-9, 1/100, 1/21, 1/104, 1/10, 1/200, 1/10400, 1/3.5, 1400, 1000, 1700, 144

    # Used Data
    y_0=numpy_data[0,:].tolist()
    numpy_data=numpy_data[1:60,:]

    ## Reference Time
    number_of_reference_time,_=np.shape(numpy_data)

    ## Solve
    param = qS, qSq, betaV1, betaV2, beta1, beta2, e1, eta1, eta2, etaH, delta2, deltaH, theta2, f1, f2, fH, d, y_0
    t= np.linspace(1,number_of_reference_time,number_of_reference_time)
    popt, cov = curve_fit(func_y, t, numpy_data,p0=[param])

    qS,qSq,betaV1,betaV2,beta1,beta2,e1,eta1,eta2,etaH,delta2,deltaH,theta2,f1,f2,fH,d = popt

    ## Check Result
    result=odeint(func_ode,y_0,t,args=(qS,qSq,betaV1,betaV2,beta1,beta2,e1,eta1,eta2,etaH,delta2,deltaH,theta2,f1,f2,fH,d))

    ## Plot
    plt.plot(t, result[:, 0], label='Sq')
    plt.plot(t, result[:, 1], label='S')
    plt.plot(t, result[:, 2], label='E1')
    plt.plot(t, result[:, 3], label='E2')
    plt.plot(t, result[:, 4], label='H')
    plt.plot(t, result[:, 5], label='R')
    plt.plot(t, result[:, 6], label='D')
    plt.plot(t, result[:, 7], label='V')
    plt.legend(loc='best')
    plt.xlabel('t')
    plt.grid()
    plt.show()
    pass
</code></pre>

<p>The error result shows:</p>

<pre><code>File ""...\Programs\Python\Python37\lib\site-packages\scipy\optimize\minpack.py"", line 458, in func_wrapped
    return func(xdata, *params) - ydata
ValueError: operands could not be broadcast together with shapes (58,8) (59,8)
</code></pre>

<p>It seems that <code>curve_fit</code> can't fit <code>odeint</code> that has multiple graphs? Or I miss something here?</p>

<p>Edit:
I edit fixed <code>y[1:,:]</code> into <code>y.flatten()</code> and <code>popt, cov = curve_fit(func_y, t, numpy_data,p0=[param])</code> into <code>popt, cov = curve_fit(func_y, t, numpy_data.flatten(),p0=[param])</code>. Also, change the input into <code>numpy.array(list)</code> The code can be seen in <a href=""https://pastebin.com/kiFta2TS"" rel=""nofollow noreferrer"">pastebin</a>. Now the problem become:</p>

<pre class=""lang-py prettyprint-override""><code>File ""....py"", line 164, in &lt;module&gt;
    popt, cov = curve_fit(func_y, t, numpy_data.flatten(),p0=[param])
  File ""...\Python\Python37\lib\site-packages\scipy\optimize\minpack.py"", line 752, in curve_fit  
    res = leastsq(func, p0, Dfun=jac, full_output=1, **kwargs)
  File ""...\Python\Python37\lib\site-packages\scipy\optimize\minpack.py"", line 396, in leastsq    
    gtol, maxfev, epsfcn, factor, diag)
TypeError: Cannot cast array data from dtype('O') to dtype('float64') according to the rule 'safe'
</code></pre>
"
61234913,"<p>I am trying to create an program where I receive the number of COVID-19 patients from and API and use that data. </p>

<p>This is my code:</p>

<pre><code>    import requests
    from datetime import date
    from datetime import timedelta

    date = str(date.today() - timedelta(days=1))
    country = 'india'
    def search(date, country):
        print(""Showing Data For :"", date)

        url = ""https://covid-19-data.p.rapidapi.com/report/country/name""

        querystring = {""date-format"":""undefined"",""format"":""undefined"",""date"":date,""name"":country}

        headers = {
            'x-rapidapi-host': ""covid-19-data.p.rapidapi.com"",
            'x-rapidapi-key': ""286798d6demshcf160ec64afce22p11662bjsn40bdced08453""
            }

        response = requests.request(""GET"", url, headers=headers, params=querystring).json()

        data = response[0]
        data = data[""provinces""]
        data = data[0]
        return data
    search(date, country)

    print(""Total Cases In India :"", data['confirmed'])
</code></pre>

<p>Whenever I execute the code I get an error.</p>

<p>This is the Error : NameError: name 'data' is not defined</p>
"
61300260,"<p>I have been trying to get data from an API and convert it to a Pandas DataFrame.</p>

<p>However, after reading the data from the API, I'm unable to convert the response to JSON.</p>

<pre><code>import pandas as pd
import numpy as np
import requests
import json

r = requests.get('https://api.rootnet.in/covid19-in/')
x = r.json()
print(type(x))
df = pd.DataFrame(x['teams'])
df
</code></pre>

<p>error:</p>

<pre><code>JSONDecodeError                           Traceback (most recent call last)
&lt;ipython-input-13-e2dd33599256&gt; in &lt;module&gt;()
      5 
      6 r = requests.get('https://api.rootnet.in/covid19-in/')
----&gt; 7 x = r.json()
      8 print(type(x))
      9 df = pd.DataFrame(x['teams'])

~/anaconda3/lib/python3.7/site-packages/requests/models.py in json(self, **kwargs)
    894                     # used.
    895                     pass
--&gt; 896         return complexjson.loads(self.text, **kwargs)
    897 
    898     @property

~/anaconda3/lib/python3.7/json/__init__.py in loads(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)
    346             parse_int is None and parse_float is None and
    347             parse_constant is None and object_pairs_hook is None and not kw):
--&gt; 348         return _default_decoder.decode(s)
    349     if cls is None:
    350         cls = JSONDecoder

~/anaconda3/lib/python3.7/json/decoder.py in decode(self, s, _w)
    338         end = _w(s, end).end()
    339         if end != len(s):
--&gt; 340             raise JSONDecodeError(""Extra data"", s, end)
    341         return obj
    342 

JSONDecodeError: Extra data: line 1 column 5 (char 4)
</code></pre>

<p>The API details: <a href=""https://www.programmableweb.com/api/covid-19-india-rest-api-v10"" rel=""nofollow noreferrer"">https://www.programmableweb.com/api/covid-19-india-rest-api-v10</a></p>
"
61285406,"<pre><code>import requests
from bs4 import BeautifulSoup
import pandas as pd
import dash
import dash_core_components as dcc
import dash_html_components as html
import dash_table

url='https://docs.google.com/spreadsheets/d/e/2PACX-1vSc_2y5N0I67wDU38DjDh35IZSIS30rQf7_NYZhtYYGU1jJYT6_kDx4YpF-qw0LSlGsBYP8pqM_a1Pd/pubhtml#'
response=requests.get(url)
#print(response)

#parsing html to beautiful soup
html_file=response.text
soup = BeautifulSoup(html_file,'html.parser')

table=soup.find_all('table')[2]
table_rows=table.find_all('tr')[4:]
#create empty lists to store data scraped
state=[]
confirmed=[]
recovered=[]
deaths=[]
active=[]
state_code=[]

for tr in table_rows:
    td=tr.find_all('td')
    state.append(td[0].text)
    confirmed.append(int(td[2].text))
    recovered.append(int(td[3].text))
    deaths.append(int(td[4].text))
    active.append(int(td[5].text))
    state_code.append(td[7].text)

#Data discrepency alteration
position=state.index('Andaman and Nicobar Islands')
state[position]='AN Islands'

#converting to a data frame
headers = ['state_name','confirmed','recovered','deaths','active','state']
df_state = pd.DataFrame(list(zip(state,confirmed,recovered,deaths,active,state_code)),columns=headers)

rec_total=df_state['recovered'].sum()
dec_total=df_state['deaths'].sum()
act_total=df_state['active'].sum()
con_total=df_state['confirmed'].sum()
#print(rec_total,dec_total,act_total,con_total)

#maximum recovery ratio and maximum death ratio
max_recovery_ratio=(df_state['recovered']/df_state['confirmed']).max()
max_recovery_state=df_state.loc[df_state['recovered']/df_state['confirmed']==max_recovery_ratio,'state_name']
max_death_ratio=(df_state['deaths']/df_state['confirmed']).max()
max_death_state=df_state.loc[df_state['deaths']/df_state['confirmed']==max_death_ratio,'state_name']
#print(max_recovery_state,max_recovery_ratio)
#print(max_death_state,max_death_ratio)

table2=soup.find_all('table')[6]
table_rows2=table2.find_all('tr')[2:]

date=[]
daily_con=[]
total_con=[]
daily_rec=[]
total_rec=[]
daily_dec=[]
total_dec=[]

for tr in table_rows2:
    td=tr.find_all('td')
    date.append(td[0].text)
    daily_con.append(td[1].text)
    total_con.append(td[2].text)
    daily_rec.append(td[3].text)
    total_rec.append(td[4].text)
    daily_dec.append(td[5].text)
    total_dec.append(td[6].text)

#Data discrepency alteration
del(date[1])
del(daily_con[1])
del(total_con[1])
del(daily_rec[1])
del(total_rec[1])
del(daily_dec[1])
del(total_dec[1])

#time-series dataframe
headers2=['date','dailyConfirmed','totalConfirmed','dailyRecovered','totalRecovered','dailyDeceased','totalDeceased']
df_ts=pd.DataFrame(list(zip(date,daily_con,total_con,daily_rec,total_rec,daily_dec,total_dec)),columns=headers2)

df_temp=df_state[['state','confirmed','active','recovered','deaths']]

app=dash.Dash(__name__)
app.layout=html.Div([
    html.H1('COVID19 TRACKER INDIA',
           style={
               'textAlign':'left',
               'background':'#EAECEE',
               'padding':'25px',
               'color':'#2C3E50'
           }),
    html.Div([
    html.Div([
        html.H1(con_total,
           style={
               'color':'#CB4335',
               'paddingTop':'0px',
               'marginTop':'-10px',
           }),
        html.P('Confirmed',
           style={
               'color':'#CB4335',
               'marginTop':'-20px',
           })

    ],
    style={
        'textAlign':'center',
        'fontfamily':'sans-serif',
        'background':'#F5B7B1',
        'width':'120px',
        'height':'40px',
        'padding':'12px',
        'borderRadius':'4px',
        'display':'inline-block'
    }),
    html.Div([
        html.H1(act_total,
           style={
               'color':'#3498DB',
               'paddingTop':'0px',
               'marginTop':'-10px',
           }),
        html.P('Active',
           style={
               'color':'#3498DB',
               'marginTop':'-20px',
           })

    ],
    style={
        'textAlign':'center',
        'background':'#D6EAF8',
        'width':'120px',
        'height':'40px',
        'padding':'12px',
        'borderRadius':'4px',
        'display':'inline-block',
        'marginLeft':'15px'
    }),
    html.Div([
        html.H1(rec_total,
           style={
               'color':'#1D8348',
               'paddingTop':'0px',
               'marginTop':'-10px',
           }),
        html.P('Recovered',
           style={
               'color':'#1D8348',
               'marginTop':'-20px',
           })

    ],
    style={
        'textAlign':'center',
        'background':'#A9DFBF',
        'width':'120px',
        'height':'40px',
        'padding':'12px',
        'borderRadius':'4px',
        'display':'inline-block',
        'marginLeft':'15px'
    }),
    html.Div([
        html.H1(dec_total,
           style={
               'color':'#2C3E50',
               'paddingTop':'0px',
               'marginTop':'-10px',
           }),
        html.P('Deceased',
           style={
               'color':'#2C3E50',
               'marginTop':'-20px',
           })

    ],
    style={
        'textAlign':'center',
        'background':'#EAECEE',
        'width':'120px',
        'height':'40px',
        'padding':'12px',
        'borderRadius':'4px',
        'display':'inline-block',
        'marginLeft':'15px'
    }),
        html.Div([
        html.H1(max_recovery_state,
           style={
               'color':'#1D8348',
               'paddingTop':'0px',
               'marginTop':'-10px',
           }),
        html.P('the state with most recovery ratio',
           style={
               'color':'#1D8348',
               'marginTop':'-20px',
           })

    ],
    style={
        'textAlign':'center',
        'background':'#A9DFBF',
        'width':'26%',
        'height':'40px',
        'padding':'12px',
        'borderRadius':'4px',
        'display':'inline-block',
        'marginLeft':'15px'
    }),
    html.Div([
        html.H1(max_death_state,
           style={
               'color':'#CB4335',
               'paddingTop':'0px',
               'marginTop':'-10px',
           }),
        html.P('the state with most deceased ratio',
           style={
               'color':'#CB4335',
               'marginTop':'-20px',
           })

    ],
    style={
        'textAlign':'center',
        'background':'#F5B7B1',
        'width':'26%',
        'height':'40px',
        'padding':'12px',
        'borderRadius':'4px',
        'display':'inline-block',
        'marginLeft':'15px'
    })
    ]),
    html.Div([
    dcc.Graph(
        figure={
            'data':[{'x':df_temp.state,'y':df_state.confirmed,'name':'Confirmed','line':{'color':'red'}},
                    {'x':df_temp.state,'y':df_state.recovered,'name':'Recovered','line':{'color':'#2ECC71 '}},
                    {'x':df_temp.state,'y':df_state.deaths,'name':'Deceased','line':{'color':'#85929E'}}
                   ],
            'layout':{
                'title':'STATE - TOTAL CASES',
                'width':'150px',
                'xaxis':{'title':'State/Union Territory','showgrid':False},
                'hovermode':'x unified',
            }
        }
    )],
    style={
    'width':'500px',
    'padding-left':'0px',
    'padding-top':'10px',
    'float':'left'
}),
    html.Div([
    dcc.Graph(
        figure={
            'data':[{'x':df_ts.date,'y':df_ts.totalConfirmed,'name':'Total Confirmed','line':{'color':'red'}},
                    {'x':df_ts.date,'y':df_ts.totalRecovered,'name':'Total Recovered','line':{'color':'#2ECC71'}},
                    {'x':df_ts.date,'y':df_ts.totalDeceased,'name':'Total Deceased','line':{'color':'#85929E'}}],
            'layout':{
                'title':'CUMULATIVE CASES BY DATE',
                'width':'150px',
                'hovermode':'x unified',
                'xaxis':{'showgrid':False}
            }
        }
    )],
    style={
    'width':'500px',
    'padding':'10px',
    'float':'left'
}),
    html.Div([
        dash_table.DataTable(
            id='table',
            columns=[{""name"":i,""id"":i} for i in df_temp.columns],
            data=df_temp.to_dict(""rows""),
            style_table={
                'maxHeight':'490px'
            },
            style_cell={
                'fontFamily':'sans-serif',
                'textAlign':'center',
                'border':'2px solid white',
                'borderCollapse':'collapse'
            },
            style_header={
                'color':'#2C3E50',
                'backgroundColor':'#EAECEE'
            },
            style_cell_conditional=[{
                'if':{'row_index':'odd'},
                'backgroundColor':'#F4F6F6'
            }],
            fixed_rows={
                'headers':True
            }
        )
    ],style={
        ""width"":""30%"",
        ""marginTop"":""40px"",
        ""float"":""left"",
        ""marginLeft"":""30px"",
    })
],
style={
    'font-family':'sans-serif'
})
server=app.server
if __name__=='__main__':
    app.run_server(debug=True)

</code></pre>

<p>The gist of the above code is just to scrap a site and with the dataframe construct a dashboard with dash plotly framework.The code runs fine on localhost.I want the dashboard to get updated whenever the spreadsheet updates.Hereby, I include the link of the spread sheet <a href=""https://docs.google.com/spreadsheets/d/e/2PACX-1vSz8Qs1gE_IYpzlkFkCXGcL_BqR8hZieWVi-rphN1gfrO3H4lDtVZs4kd0C3P8Y9lhsT1rhoB-Q_cP4/pubhtml"" rel=""nofollow noreferrer"">link</a></p>

<p>.gitignore file</p>

<pre><code>venv
*.pyc
.DS_Store
.env

</code></pre>

<p>Procfile</p>

<pre><code>web: gunicorn app:server
</code></pre>

<p>requirements.txt</p>

<pre><code>alabaster==0.7.12
argh==0.26.2
asn1crypto==1.3.0
astroid==2.3.3
astropy==4.0
atomicwrites==1.3.0
attrs==19.3.0
autopep8==1.4.4
Babel==2.8.0
backcall==0.1.0
backports.functools-lru-cache==1.6.1
backports.shutil-get-terminal-size==1.0.0
backports.tempfile==1.0
backports.weakref==1.0.post1
bcrypt==3.1.7
beautifulsoup4==4.8.2
bitarray==1.2.1
bkcharts==0.2
bleach==3.1.0
bokeh==1.4.0
boto==2.49.0
Bottleneck==1.3.2
certifi==2019.11.28
cffi==1.14.0
chardet==3.0.4
Click==7.0
cloudpickle==1.3.0
colorama==0.4.3
comtypes==1.1.7
contextlib2==0.6.0.post1
cryptography==2.8
cycler==0.10.0
Cython==0.29.15
cytoolz==0.10.1
dash==1.11.0
dash-auth==1.3.2
dash-core-components==1.9.1
dash-html-components==1.0.3
dash-renderer==1.4.0
dash-table==4.6.2
dask==2.11.0
decorator==4.4.1
defusedxml==0.6.0
diff-match-patch==20181111
distributed==2.11.0
docutils==0.16
entrypoints==0.3
et-xmlfile==1.0.1
fastcache==1.1.0
filelock==3.0.12
flake8==3.7.9
Flask==1.1.1
Flask-Compress==1.4.0
Flask-SeaSurf==0.2.2
fsspec==0.6.2
future==0.18.2
gevent==1.4.0
glob2==0.7
greenlet==0.4.15
gunicorn==19.7.1
h5py==2.10.0
HeapDict==1.0.1
html5lib==1.0.1
hypothesis==5.5.4
idna==2.8
imageio==2.6.1
imagesize==1.2.0
importlib-metadata==1.5.0
intervaltree==3.0.2
ipykernel==5.1.4
ipython==7.12.0
ipython-genutils==0.2.0
ipywidgets==7.5.1
isort==4.3.21
itsdangerous==1.1.0
jdcal==1.4.1
jedi==0.14.1
Jinja2==2.11.1
joblib==0.14.1
json5==0.9.1
jsonschema==3.2.0
jupyter==1.0.0
jupyter-client==5.3.4
jupyter-console==6.1.0
jupyter-core==4.6.1
jupyterlab==1.2.6
jupyterlab-server==1.0.6
keyring==21.1.0
kiwisolver==1.1.0
lazy-object-proxy==1.4.3
libarchive-c==2.8
llvmlite==0.31.0
locket==0.2.0
lxml==4.5.0
MarkupSafe==1.1.1
matplotlib==3.1.3
mccabe==0.6.1
mistune==0.8.4
mock==4.0.1
more-itertools==8.2.0
mpmath==1.1.0
msgpack==0.6.1
multipledispatch==0.6.0
nbconvert==5.6.1
nbformat==5.0.4
networkx==2.4
nltk==3.4.5
nose==1.3.7
notebook==6.0.3
numba==0.48.0
numexpr==2.7.1
numpy==1.18.1
numpydoc==0.9.2
olefile==0.46
openpyxl==3.0.3
packaging==20.1
pandas==1.0.1
pandocfilters==1.4.2
paramiko==2.7.1
parso==0.5.2
partd==1.1.0
path==13.1.0
pathlib2==2.3.5
pathtools==0.1.2
patsy==0.5.1
pep8==1.7.1
pexpect==4.8.0
pickleshare==0.7.5
Pillow==7.0.0
pkginfo==1.5.0.1
plotly==4.6.0
pluggy==0.13.1
ply==3.11
prometheus-client==0.7.1
prompt-toolkit==3.0.3
psutil==5.6.7
py==1.8.1
pycodestyle==2.5.0
pycosat==0.6.3
pycparser==2.19
pycrypto==2.6.1
pycurl==7.43.0.5
pydocstyle==4.0.1
pyflakes==2.1.1
Pygments==2.5.2
pylint==2.4.4
PyNaCl==1.3.0
pyOpenSSL==19.1.0
pyparsing==2.4.6
pyreadline==2.1
pyrsistent==0.15.7
PySocks==1.7.1
pytest==5.3.5
pytest-arraydiff==0.3
pytest-astropy==0.8.0
pytest-astropy-header==0.1.2
pytest-doctestplus==0.5.0
pytest-openfiles==0.4.0
pytest-remotedata==0.3.2
python-dateutil==2.8.1
python-jsonrpc-server==0.3.4
python-language-server==0.31.7
pytz==2019.3
PyWavelets==1.1.1
pywin32-ctypes==0.2.0
pywinpty==0.5.7
PyYAML==5.3
pyzmq==18.1.1
QDarkStyle==2.8
QtAwesome==0.6.1
qtconsole==4.6.0
QtPy==1.9.0
requests==2.22.0
retrying==1.3.3
rope==0.16.0
ruamel-yaml==0.15.87
scikit-image==0.16.2
scikit-learn==0.22.1
scipy==1.4.1
seaborn==0.10.0
Send2Trash==1.5.0
simplegeneric==0.8.1
singledispatch==3.4.0.3
six==1.14.0
snowballstemmer==2.0.0
sortedcollections==1.1.2
sortedcontainers==2.1.0
soupsieve==1.9.5
Sphinx==2.4.0
sphinxcontrib-applehelp==1.0.1
sphinxcontrib-devhelp==1.0.1
sphinxcontrib-htmlhelp==1.0.2
sphinxcontrib-jsmath==1.0.1
sphinxcontrib-qthelp==1.0.2
sphinxcontrib-serializinghtml==1.1.3
sphinxcontrib-websupport==1.2.0
spyder==4.0.1
spyder-kernels==1.8.1
SQLAlchemy==1.3.13
statsmodels==0.11.0
sympy==1.5.1
tables==3.6.1
tblib==1.6.0
terminado==0.8.3
testpath==0.4.4
toolz==0.10.0
tornado==6.0.3
tqdm==4.42.1
traitlets==4.3.3
ua-parser==0.10.0
ujson==1.35
unicodecsv==0.14.1
urllib3==1.25.8
watchdog==0.10.2
wcwidth==0.1.8
webencodings==0.5.1
Werkzeug==1.0.0
widgetsnbextension==3.5.1
win-inet-pton==1.1.0
win-unicode-console==0.5
wincertstore==0.2
wrapt==1.11.2
xlrd==1.2.0
XlsxWriter==1.2.7
xlwt==1.3.0
xmltodict==0.12.0
yapf==0.28.0
zict==1.0.0
zipp==2.2.0
</code></pre>

<p>when deployed on <strong>heroku</strong> it shows <a href=""https://i.stack.imgur.com/sdCgz.png"" rel=""nofollow noreferrer"">application error</a></p>

<p>The error logs of the application is included below.</p>

<pre><code>2020-04-18T06:46:35.042938+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 74, in run
2020-04-18T06:46:35.043081+00:00 app[web.1]: WSGIApplication(""%(prog)s [OPTIONS] [APP_MODULE]"").run()
2020-04-18T06:46:35.043086+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 203, in run
2020-04-18T06:46:35.043272+00:00 app[web.1]: super(Application, self).run()
2020-04-18T06:46:35.043277+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 72, in run
2020-04-18T06:46:35.043419+00:00 app[web.1]: Arbiter(self).run()
2020-04-18T06:46:35.043423+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 231, in run
2020-04-18T06:46:35.043606+00:00 app[web.1]: self.halt(reason=inst.reason, exit_status=inst.exit_status)
2020-04-18T06:46:35.043611+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 344, in halt
2020-04-18T06:46:35.043826+00:00 app[web.1]: self.stop()
2020-04-18T06:46:35.043872+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 393, in stop
2020-04-18T06:46:35.044141+00:00 app[web.1]: time.sleep(0.1)
2020-04-18T06:46:35.044146+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 244, in handle_chld
2020-04-18T06:46:35.044326+00:00 app[web.1]: self.reap_workers()
2020-04-18T06:46:35.044364+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 524, in reap_workers
2020-04-18T06:46:35.044625+00:00 app[web.1]: raise HaltServer(reason, self.WORKER_BOOT_ERROR)
2020-04-18T06:46:35.044656+00:00 app[web.1]: gunicorn.errors.HaltServer: &lt;HaltServer 'Worker failed to boot.' 3&gt;
2020-04-18T06:46:35.136895+00:00 heroku[web.1]: State changed from up to crashed
2020-04-18T06:46:35.141197+00:00 heroku[web.1]: State changed from crashed to starting
2020-04-18T06:47:11.217990+00:00 app[web.1]: [2020-04-18 06:47:11 +0000] [4] [INFO] Starting gunicorn 19.7.1
2020-04-18T06:47:11.218560+00:00 app[web.1]: [2020-04-18 06:47:11 +0000] [4] [INFO] Listening at: http://0.0.0.0:6439 (4)
2020-04-18T06:47:11.218675+00:00 app[web.1]: [2020-04-18 06:47:11 +0000] [4] [INFO] Using worker: sync
2020-04-18T06:47:11.223000+00:00 app[web.1]: [2020-04-18 06:47:11 +0000] [10] [INFO] Booting worker with pid: 10
2020-04-18T06:47:11.258684+00:00 app[web.1]: [2020-04-18 06:47:11 +0000] [11] [INFO] Booting worker with pid: 11
2020-04-18T06:47:12.683728+00:00 heroku[web.1]: State changed from starting to up
2020-04-18T06:47:14.866373+00:00 app[web.1]: [2020-04-18 06:47:14 +0000] [10] [ERROR] Exception in worker process
2020-04-18T06:47:14.866393+00:00 app[web.1]: Traceback (most recent call last):
2020-04-18T06:47:14.866394+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 578, in spawn_worker
2020-04-18T06:47:14.866414+00:00 app[web.1]: worker.init_process()
2020-04-18T06:47:14.866415+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py"", line 126, in init_process
2020-04-18T06:47:14.866415+00:00 app[web.1]: self.load_wsgi()
2020-04-18T06:47:14.866415+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py"", line 135, in load_wsgi
2020-04-18T06:47:14.866416+00:00 app[web.1]: self.wsgi = self.app.wsgi()
2020-04-18T06:47:14.866417+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 67, in wsgi
2020-04-18T06:47:14.866417+00:00 app[web.1]: self.callable = self.load()
2020-04-18T06:47:14.866417+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 65, in load
2020-04-18T06:47:14.866418+00:00 app[web.1]: return self.load_wsgiapp()
2020-04-18T06:47:14.866418+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 52, in load_wsgiapp
2020-04-18T06:47:14.866418+00:00 app[web.1]: return util.import_app(self.app_uri)
2020-04-18T06:47:14.866419+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/util.py"", line 352, in import_app
2020-04-18T06:47:14.866419+00:00 app[web.1]: __import__(module)
2020-04-18T06:47:14.866419+00:00 app[web.1]: File ""/app/app.py"", line 17, in &lt;module&gt;
2020-04-18T06:47:14.866420+00:00 app[web.1]: table=soup.find_all('table')[2]
2020-04-18T06:47:14.866428+00:00 app[web.1]: IndexError: list index out of range
2020-04-18T06:47:14.868025+00:00 app[web.1]: [2020-04-18 06:47:14 +0000] [10] [INFO] Worker exiting (pid: 10)
2020-04-18T06:47:14.895749+00:00 app[web.1]: [2020-04-18 06:47:14 +0000] [11] [ERROR] Exception in worker process
2020-04-18T06:47:14.895751+00:00 app[web.1]: Traceback (most recent call last):
2020-04-18T06:47:14.895752+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 578, in spawn_worker
2020-04-18T06:47:14.895752+00:00 app[web.1]: worker.init_process()
2020-04-18T06:47:14.895753+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py"", line 126, in init_process
2020-04-18T06:47:14.895753+00:00 app[web.1]: self.load_wsgi()
2020-04-18T06:47:14.895753+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py"", line 135, in load_wsgi
2020-04-18T06:47:14.895754+00:00 app[web.1]: self.wsgi = self.app.wsgi()
2020-04-18T06:47:14.895755+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 67, in wsgi
2020-04-18T06:47:14.895755+00:00 app[web.1]: self.callable = self.load()
2020-04-18T06:47:14.895756+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 65, in load
2020-04-18T06:47:14.895756+00:00 app[web.1]: return self.load_wsgiapp()
2020-04-18T06:47:14.895756+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 52, in load_wsgiapp
2020-04-18T06:47:14.895757+00:00 app[web.1]: return util.import_app(self.app_uri)
2020-04-18T06:47:14.895757+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/util.py"", line 352, in import_app
2020-04-18T06:47:14.895757+00:00 app[web.1]: __import__(module)
2020-04-18T06:47:14.895758+00:00 app[web.1]: File ""/app/app.py"", line 17, in &lt;module&gt;
2020-04-18T06:47:14.895758+00:00 app[web.1]: table=soup.find_all('table')[2]
2020-04-18T06:47:14.895816+00:00 app[web.1]: IndexError: list index out of range
2020-04-18T06:47:14.898083+00:00 app[web.1]: [2020-04-18 06:47:14 +0000] [11] [INFO] Worker exiting (pid: 11)
2020-04-18T06:47:15.359619+00:00 heroku[web.1]: State changed from up to crashed
2020-04-18T06:47:15.255279+00:00 app[web.1]: Traceback (most recent call last):
2020-04-18T06:47:15.255291+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 209, in run
2020-04-18T06:47:15.255658+00:00 app[web.1]: self.sleep()
2020-04-18T06:47:15.255681+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 359, in sleep
2020-04-18T06:47:15.256001+00:00 app[web.1]: ready = select.select([self.PIPE[0]], [], [], 1.0)
2020-04-18T06:47:15.256051+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 244, in handle_chld
2020-04-18T06:47:15.256408+00:00 app[web.1]: self.reap_workers()
2020-04-18T06:47:15.256413+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 524, in reap_workers
2020-04-18T06:47:15.256837+00:00 app[web.1]: raise HaltServer(reason, self.WORKER_BOOT_ERROR)
2020-04-18T06:47:15.256880+00:00 app[web.1]: gunicorn.errors.HaltServer: &lt;HaltServer 'Worker failed to boot.' 3&gt;
2020-04-18T06:47:15.256881+00:00 app[web.1]:
2020-04-18T06:47:15.256882+00:00 app[web.1]: During handling of the above exception, another exception occurred:
2020-04-18T06:47:15.256882+00:00 app[web.1]:
2020-04-18T06:47:15.256886+00:00 app[web.1]: Traceback (most recent call last):
2020-04-18T06:47:15.256913+00:00 app[web.1]: File ""/app/.heroku/python/bin/gunicorn"", line 8, in &lt;module&gt;
2020-04-18T06:47:15.257380+00:00 app[web.1]: sys.exit(run())
2020-04-18T06:47:15.257381+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 74, in run
2020-04-18T06:47:15.257575+00:00 app[web.1]: WSGIApplication(""%(prog)s [OPTIONS] [APP_MODULE]"").run()
2020-04-18T06:47:15.257576+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 203, in run
2020-04-18T06:47:15.257833+00:00 app[web.1]: super(Application, self).run()
2020-04-18T06:47:15.257834+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 72, in run
2020-04-18T06:47:15.258041+00:00 app[web.1]: Arbiter(self).run()
2020-04-18T06:47:15.258046+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 231, in run
2020-04-18T06:47:15.258302+00:00 app[web.1]: self.halt(reason=inst.reason, exit_status=inst.exit_status)
2020-04-18T06:47:15.258303+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 344, in halt
2020-04-18T06:47:15.258636+00:00 app[web.1]: self.stop()
2020-04-18T06:47:15.258637+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 393, in stop
2020-04-18T06:47:15.258989+00:00 app[web.1]: time.sleep(0.1)
2020-04-18T06:47:15.258990+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 244, in handle_chld
2020-04-18T06:47:15.259259+00:00 app[web.1]: self.reap_workers()
2020-04-18T06:47:15.259260+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 524, in reap_workers
2020-04-18T06:47:15.259678+00:00 app[web.1]: raise HaltServer(reason, self.WORKER_BOOT_ERROR)
2020-04-18T06:47:15.259682+00:00 app[web.1]: gunicorn.errors.HaltServer: &lt;HaltServer 'Worker failed to boot.' 3&gt;
2020-04-18T06:47:15.253084+00:00 heroku[router]: at=error code=H13 desc=""Connection closed without response"" method=GET path=""/favicon.ico"" host=westayhome.herokuapp.com request_id=48e93cd8-d6b4-455c-aae3-c5b757d09f8c fwd=""42.109.129.238"" dyno=web.1 connect=5000ms service=1184ms status=503 bytes=0 protocol=https
</code></pre>
"
61403995,"<p>I want to click a button using selenium, and to select the button on the site's dropdown date picker. </p>

<p><a href=""https://i.stack.imgur.com/OCpJ7.png"" rel=""nofollow noreferrer"">The button I wish to click is highlighted in yellow</a> </p>

<blockquote>
  <p><a href=""http://covid.gov.pk/stats/ict"" rel=""nofollow noreferrer"">http://covid.gov.pk/stats/ict</a></p>
</blockquote>

<p>I am using the following xpath.</p>

<blockquote>
  <p>//*[@id=""datepicker-1361-7562-title""]/strong</p>
</blockquote>

<p>and Here is the code I am using</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import date
import time

#calculating days from first day 
d1 = date(2020, 3, 10)
dCurrent = date.today()
daysElapsed = int((dCurrent - d1).days)

#setting up driver and fetching website
driver = webdriver.Chrome()
driver.get('http://covid.gov.pk/stats/ict')

#wait for page and resources to load
WebDriverWait(driver, 25).until(EC.invisibility_of_element((By.XPATH, ""//div[@id=\""preloader\""]"")))
WebDriverWait(driver, 15).until(EC.frame_to_be_available_and_switch_to_it((By.XPATH, '//*[@id=""app""]/div[2]/iframe')))


driver.find_element_by_xpath('//*[@id=""body""]/div/div/div[1]/div[2]/div/div[1]/div[1]/div[1]/div/lego-report/lego-canvas-container/div/file-drop-zone/span/content-section/canvas-component[29]/div/div/div/div/ga-date-range-picker/lego-date-duration-control/control-layout-wrapper/button/div').click()
time.sleep(3)
driver.find_element_by_xpath('//*[@id=""datepicker-1361-7562-title""]/strong').click()
</code></pre>

<p>The problem is that I am able to click other elements on the drop down menu just not this button.</p>

<p>The error I encounter when I run my code.</p>

<blockquote>
  <p>in check_response
      raise exception_class(message, screen, stacktrace) selenium.common.exceptions.NoSuchElementException: Message: no such
  element: Unable to locate element:
  {""method"":""xpath"",""selector"":""//*[@id=""datepicker-1361-7562-title""]/strong""}
  (Session info: chrome=81.0.4044.122)</p>
</blockquote>

<p>I have been  trying to resolve this issue but can't seem to pin point what exactly I maybe doing wrong, any help would be highly appreciated.</p>
"
60797074,"<p>I am not able to print a specific state details.</p>

<p>Code:</p>

<pre><code>import pandas as pd
file1 = r'D:\Work\Projects\COVID-19\covid_19_data.csv'
df = pd.read_csv(file1)
df1 = df.loc[df['State'] == 'Hubei', ['State', 'Date', 'Confirmed', 'Deaths']]
print (df1.head())
bins = np.linspace(min(df1), max(df1), 4)
print(df1)
group = [""Mild"",""Severe"",""Critical""]
df1['Hubei-binned'] = pd.cut(df1, bins, labels=group, include_lowest = True)
</code></pre>
"
61096374,"<p>I'm actaully just running some code I found on github, so it should run smoothly I didn't change anything.
<a href=""https://github.com/neuml/cord19q/blob/master/setup.py"" rel=""nofollow noreferrer"">https://github.com/neuml/cord19q/blob/master/setup.py</a></p>

<p>The first part runs without problems:</p>

<pre><code># pylint: disable = C0111
from setuptools import find_packages, setup

with open(""/content/drive/My Drive/CoLab/Data/covid19/cord19q-master/README.md"", ""r"") as f:
    DESCRIPTION = f.read()
</code></pre>

<p>I can even print the DESCRIPTION variable on console.
When I try to use the setup function:</p>

<pre><code>setup(name=""cord19q"",
      version=""1.0.0"",
      author=""NeuML"",
      description=""CORD-19 Analysis"",
      long_description=DESCRIPTION,
      long_description_content_type=""text/markdown"",
      url=""https://github.com/neuml/cord19q"",
      project_urls={
          ""Documentation"": ""https://github.com/neuml/cord19q"",
          ""Issue Tracker"": ""https://github.com/neuml/cord19q/issues"",
          ""Source Code"": ""https://github.com/neuml/cord19q"",
      },
      license=""MIT License: http://opensource.org/licenses/MIT"",
      packages=find_packages(where=""src/python/""),
      package_dir={"""": ""src/python/""},
      keywords=""python search embedding machine-learning"",
      python_requires=""&gt;=3.5"",
      entry_points={
          ""console_scripts"": [
              ""cord19q = cord19q.shell:main"",
          ],
      },
      install_requires=[
          ""faiss-gpu&gt;=1.6.1"",
          ""fasttext&gt;=0.9.1"",
          ""html2text&gt;=2019.9.26"",
          ""mdv&gt;=1.7.4"",
          ""networkx&gt;=2.4"",
          ""nltk&gt;=3.4.5"",
          ""numpy&gt;=1.17.4"",
          ""pymagnitude&gt;=0.1.120"",
          ""regex&gt;=2019.12.9"",
          ""scikit-learn&gt;=0.22.1"",
          ""scipy&gt;=1.4.1"",
          ""spacy&gt;=2.2.3"",
          ""tqdm&gt;=4.40.2"",
          ""xlsxwriter&gt;=1.2.8""
      ],
      classifiers=[
          ""License :: OSI Approved :: MIT License"",
          ""Operating System :: OS Independent"",
          ""Programming Language :: Python :: 3"",
          ""Topic :: Software Development"",
          ""Topic :: Text Processing :: Indexing"",
          ""Topic :: Utilities""
      ])
</code></pre>

<p>It gives me this error:</p>

<pre><code>An exception has occurred, use %tb to see the full traceback.

SystemExit: usage: ipykernel_launcher.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]
   or: ipykernel_launcher.py --help [cmd1 cmd2 ...]
   or: ipykernel_launcher.py --help-commands
   or: ipykernel_launcher.py cmd --help

error: option -f not recognized
</code></pre>

<p>The same happens even if I run only:
setup(name=""cord19q"")</p>

<p>What am I missing? I'm running this on a Colab Notebook.</p>
"
61110091,"<p>Is there any problem related to Johns Hopkins data set in GitHub?
In particular when I'm trying to parse the CSV file of updated cases and I receive the error : HTTPError: HTTP Error 404: Not Found</p>

<pre><code>import pandas as pd
main_link = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/'
CONFIRMED = pd.read_csv(main_link+'time_series_19-covid-Confirmed.csv')
DEATHS = pd.read_csv(main_link+'time_series_19-covid-Deaths.csv')
RECOVERED = pd.read_csv(main_link+'time_series_19-covid-Recovered.csv')
</code></pre>
"
60526051,"<p><a href=""https://i.stack.imgur.com/B11Oz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/B11Oz.png"" alt=""Coronavirus Data""></a></p>

<p>I have sliced the list still I am able to see a huge list. Can someone please explain how is the list defined for each column of a dataframe work. Also, when I am trying to convert this list to a set in order to view the unique elements it throws an error.</p>

<blockquote>
  <p>TypeError: 'Series' objects are mutable, thus they cannot be hashed</p>
</blockquote>
"
61149354,"<p>I'm hoping to scrape data from the table for passengers going through TSA security lines, but I keep getting this error.</p>

<pre><code>UnicodeEncodeError: 'charmap' codec can't encode character '\u2713' in position 33780: character maps to &lt;undefined&gt;
</code></pre>

<p>from this code</p>

<pre><code>url = ""https://www.tsa.gov/coronavirus/passenger-throughput""
page = requests.get(url).content
soup = BeautifulSoup(page, features = 'lxml')
text = soup.get_text()
soup.prettify()

print(soup)
</code></pre>

<p>Are there any suggestions?</p>
"
60934400,"<p>im using this model:</p>

<pre><code>from keras import models
from keras import layers
from keras.applications import VGG19
from keras import optimizers
from keras.layers.core import Flatten, Dense, Dropout, Lambda

conv_base = VGG19(weights='imagenet',
 include_top=False,
 input_shape=(150, 150, 3))
conv_base.trainable = False
model = models.Sequential()
model.add(conv_base)
model.add(layers.Flatten())
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy',
 optimizer=optimizers.Adam(lr=LEARNING_RATE),
 metrics=['acc'])

STEP_SIZE_TRAIN=train_batches.n//train_batches.batch_size
STEP_SIZE_VALID=valid_batches.n//valid_batches.batch_size
result=model.fit_generator(train_batches,
 steps_per_epoch =STEP_SIZE_TRAIN,
 validation_data = valid_batches,
 validation_steps = STEP_SIZE_VALID,
 epochs= NUM_EPOCHS
 )
</code></pre>

<p>to predict pneumonia from chest x-rays, then i want to create a heatmap about what does activate the last layer, i found this on the francois chollet book of deep learning w/ python</p>

<pre><code>from keras.preprocessing import image
from keras.applications.vgg16 import preprocess_input, decode_predictions
import numpy as np
img_path = '/home/workstation/Desktop/covid/1.jpeg'
img = image.load_img(img_path, target_size=(150, 150))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

preds = result.predict(x)
print('Predicted:', decode_predictions(preds)[0])
</code></pre>

<p>but im getting this error</p>

<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-19-8607e0dccecf&gt; in &lt;module&gt;
----&gt; 1 preds = result.predict(x)
      2 print('Predicted:', decode_predictions(preds)[0])

AttributeError: 'History' object has no attribute 'predict'
</code></pre>

<p>if there any advice or help in order to solve this i will be very grateful w/ you people</p>
"
60937956,"<p>i have trained a CNN for classify pneumonia chest x-rays vs healty people chest x-rays, then i tried to use a Class Activation map here is the code:</p>

<pre><code>import cv2
from keras import backend as K
import numpy as np
from keras.models import load_model  
def visualize_class_activation_map(model_path, img_path, output_path):
    model = load_model(model_path)
    original_img = cv2.imread(img_path, 1)
    width, height, _ = original_img.shape

    #Reshape to the network input shape (3, w, h).
    img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])

    #Get the 512 input weights to the softmax.
    class_weights = model.layers[-1].get_weights()[0]

    final_conv_layer = model.get_layer('vgg19').get_layer('block3_conv1').output
    get_output = K.function([model.layers[0].input], [final_conv_layer.output, model.layers[-1].output])
    [conv_outputs, predictions] = get_output([img])
    conv_outputs = conv_outputs[0, :, :, :]

    #Create the class activation map.
    cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])
    target_class = 1
    for i, w in enumerate(class_weights[:, target_class]):
        cam += w * conv_outputs[i, :, :]

visualize_class_activation_map('covid_t93.h5','/home/workstation/Desktop/covid/1.jpeg','block3_conv1')
</code></pre>

<p>now when i try to use the CAM i get this error</p>

<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-1-bfc49ce56c97&gt; in &lt;module&gt;
     25         cam += w * conv_outputs[i, :, :]
     26 
---&gt; 27 visualize_class_activation_map('covid_t93.h5','/home/workstation/Desktop/covid/1.jpeg','block3_conv1')

&lt;ipython-input-1-bfc49ce56c97&gt; in visualize_class_activation_map(model_path, img_path, output_path)
     15 
     16     final_conv_layer = model.get_layer('vgg19').get_layer('block3_conv1').output
---&gt; 17     get_output = K.function([model.layers[0].input], [final_conv_layer.output, model.layers[-1].output])
     18     [conv_outputs, predictions] = get_output([img])
     19     conv_outputs = conv_outputs[0, :, :, :]

~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/keras/engine/base_layer.py in input(self)
    782         if len(self._inbound_nodes) &gt; 1:
    783             raise AttributeError('Layer ' + self.name +
--&gt; 784                                  ' has multiple inbound nodes, '
    785                                  'hence the notion of ""layer input"" '
    786                                  'is ill-defined. '

AttributeError: Layer vgg19 has multiple inbound nodes, hence the notion of ""layer input"" is ill-defined. Use `get_input_at(node_index)` instead.
</code></pre>

<p>i was hoping any of you can helpme to make it work, i read about the error but cant get it work i tried to change the layers[0].input for the get_inputat() but i guess i do it wrong, thanks for reading</p>
"
61554700,"<p>I'm using scrapy with selenium the code is:</p>

<pre><code>    import scrapy
from scrapy.selector import Selector
from  selenium import webdriver 
from selenium.webdriver.chrome.options import Options
from shutil import which


class GoldendataSpider(scrapy.Spider):
    name = 'goldendata'
    allowed_domains = ['www.golden.com']
    #start_urls = ['https://golden.com/wiki/Cluster%3A_COVID-19-ZXJX9AR/']

    def __init__(self):

        chrome_options= Options()
        chrome_options.add_argument(""--headless"")


        chrome_path=which('chromedriver')

        driver = webdriver.Chrome(executable_path=chrome_path, options=chrome_options)
        driver.get(""https://golden.com/wiki/Cluster%3A_COVID-19-ZXJX9AR/"")



        self.html = driver.page_source

        driver.close()
</code></pre>

<p>But I'm getting the following error:</p>

<pre><code>Unhandled error in Deferred:
2020-05-02 10:11:35 [twisted] CRITICAL: Unhandled error in Deferred:
2020-05-02 10:19:16 [twisted] CRITICAL: 
Traceback (most recent call last):
 File ""F:\Git Contribution\Fightpandemic\Scrpers\golden\golden\spiders\goldendata.py"", line 22, in 
 __init__
driver = webdriver.Chrome(executable_path=chrome_path, chrome_options=chrome_options)
needquote = ("" "" in arg) or (""\t"" in arg) or not arg
TypeError: argument of type 'NoneType' is not iterable
</code></pre>

<p>I tried installing pywin32 and updating py and selenium but it doesn't do anything..
so how could I solve this error I tried most of the things i know and i also searched for github issues and stack overflow but didn't found anything.
Thanks in advance </p>
"
61552888,"<p>I am trying to create a simple Android application using Python and Kivy. As part of this, I am importing <code>pandas</code>. This all seems to work fine when I run it in on my Windows PC. I am creating the Android app using Python for Android. </p>

<p>When I run it in an Android environment I get:</p>

<blockquote>
  <p>ModuleNotFoundError: No module named 'pandas'</p>
</blockquote>

<p>What could cause the module to not properly build into the app? I can't seem to find an answer.</p>

<p>Below is the complete log. Thanks.</p>

<pre><code>2020-04-25 15:38:05.723 8066-8066/? W/SDLThread: type=1400 audit(0.0:29030): avc: granted { execute } for path=""/data/data/com.graffbt.coronaviruscp/files/app/_python_bundle/modules/math.cpython-38.so"" dev=""sda35"" ino=670093 scontext=u:r:untrusted_app_27:s0:c512,c768 tcontext=u:object_r:app_data_file:s0:c512,c768 tclass=file
2020-04-25 15:38:05.726 8066-8066/? W/SDLThread: type=1400 audit(0.0:29031): avc: granted { execute } for path=""/data/data/com.graffbt.coronaviruscp/files/app/_python_bundle/modules/_queue.cpython-38.so"" dev=""sda35"" ino=670132 scontext=u:r:untrusted_app_27:s0:c512,c768 tcontext=u:object_r:app_data_file:s0:c512,c768 tclass=file
2020-04-25 15:38:05.766 8066-8066/? W/SDLThread: type=1400 audit(0.0:29032): avc: granted { execute } for path=""/data/data/com.graffbt.coronaviruscp/files/app/_python_bundle/modules/_bisect.cpython-38.so"" dev=""sda35"" ino=670095 scontext=u:r:untrusted_app_27:s0:c512,c768 tcontext=u:object_r:app_data_file:s0:c512,c768 tclass=file
2020-04-25 15:38:05.773 8066-8066/? W/SDLThread: type=1400 audit(0.0:29033): avc: granted { execute } for path=""/data/data/com.graffbt.coronaviruscp/files/app/_python_bundle/modules/_sha512.cpython-38.so"" dev=""sda35"" ino=670115 scontext=u:r:untrusted_app_27:s0:c512,c768 tcontext=u:object_r:app_data_file:s0:c512,c768 tclass=file
2020-04-25 15:38:05.776 8066-8066/? W/SDLThread: type=1400 audit(0.0:29034): avc: granted { execute } for path=""/data/data/com.graffbt.coronaviruscp/files/app/_python_bundle/modules/_random.cpython-38.so"" dev=""sda35"" ino=670144 scontext=u:r:untrusted_app_27:s0:c512,c768 tcontext=u:object_r:app_data_file:s0:c512,c768 tclass=file
2020-04-25 15:38:05.796 8066-8066/? W/SDLThread: type=1400 audit(0.0:29035): avc: granted { execute } for path=""/data/data/com.graffbt.coronaviruscp/files/app/_python_bundle/modules/_opcode.cpython-38.so"" dev=""sda35"" ino=670086 scontext=u:r:untrusted_app_27:s0:c512,c768 tcontext=u:object_r:app_data_file:s0:c512,c768 tclass=file
2020-04-25 15:38:05.853 8025-8066/com.graffbt.coronaviruscp I/python: [INFO   ] [Logger      ] Record log in /data/user/0/com.graffbt.coronaviruscp/files/app/.kivy/logs/kivy_20-04-25_1.txt
2020-04-25 15:38:05.853 8025-8066/com.graffbt.coronaviruscp I/python: [INFO   ] [Kivy        ] v1.11.1
2020-04-25 15:38:05.853 8025-8066/com.graffbt.coronaviruscp I/python: [INFO   ] [Kivy        ] Installed at ""/data/user/0/com.graffbt.coronaviruscp/files/app/_python_bundle/site-packages/kivy/__init__.pyc""
2020-04-25 15:38:05.853 8025-8066/com.graffbt.coronaviruscp I/python: [INFO   ] [Python      ] v3.8.1 (default, Apr 20 2020, 03:42:32) 
2020-04-25 15:38:05.853 8025-8066/com.graffbt.coronaviruscp I/python: [Clang 8.0.2 (https://android.googlesource.com/toolchain/clang 40173bab62ec7462
2020-04-25 15:38:05.854 8025-8066/com.graffbt.coronaviruscp I/python: [INFO   ] [Python      ] Interpreter at """"
2020-04-25 15:38:05.855 8025-8066/com.graffbt.coronaviruscp I/python:  Traceback (most recent call last):
2020-04-25 15:38:05.855 8025-8066/com.graffbt.coronaviruscp I/python:    File ""/content/main.py"", line 3, in &lt;module&gt;
2020-04-25 15:38:05.856 8025-8066/com.graffbt.coronaviruscp I/python:  ModuleNotFoundError: No module named 'pandas'
2020-04-25 15:38:05.856 8025-8066/com.graffbt.coronaviruscp I/python: Python for android ended.
</code></pre>
"
60825969,"<p>I have a CSV file, news.csv, that contains many data. I wanted to check whether the row contains any year, and if yes,1, else 0. This also applies to percentage, if the row contains percentage, return 1, else 0. And also to extract them.</p>

<p>Below are my codes so far. I got errors(ValueError: Wrong number of items passed 2, placement implies 1), when i tried to extract the percentage</p>

<pre><code>news=pd.read_csv(""news.csv"")
news['year']= news['STORY'].str.extract(r'(?!\()\b(\d+){1}')
news[""howmanyyear""] = news[""STORY""].str.count(r'(?!\()\b(\d+){1}')
news[""existyear""] = news[""howmany""] != 0
news[""existyear""] = news[""existyear""].astype(int)
news['percentage']= news['STORY'].str.extract(r'(\s100|\s\d{1})(\.\d+)+%')


news.to_csv('news.csv')
</code></pre>

<p>The code to extract the year, seemed to work but, it also extract ordinary digits, and only extract one of the years.</p>

<p>My CSV file sample</p>

<pre><code>ID  STORY                                                            
1   There are a total of 2,070 people died in 2001 due to the virus                         
2   20% of people in the village have diabetes in 2007                        
3   About 70 percent of them still believe the rumor                            
4  In 2003 and 2020, the pneumonia pandemic spread in the world
</code></pre>

<p>Below are the outputs I want:</p>

<pre><code>ID  STORY                                                            existyear  year    existpercentage  percentage
1   There are a total of 2,070 people died in 2001 due to the virus    1        2001      0              -
2   20% of people in the village have diabetes in 2007                 1        2007      1              20%
3   About 70 percent of them still believe the rumor                   0         -        1              70
4  In 2003 and 2020, the pneumonia pandemic spread in the world        1       2003,2020  0              -
</code></pre>
"
61092677,"<p>I have been trying to add the JSON data from this <a href=""https://api.covid19api.com/summary"" rel=""nofollow noreferrer"">API</a> to a pandas data frame. Here is the code I have tried: </p>

<pre><code>url = 'https://api.covid19api.com/summary'
df = pd.read_json(url)

print(df.head())
</code></pre>

<p>When running this code, I receive the following error:  </p>

<blockquote>
  <p>ValueError: Mixing dicts with non-Series may lead to ambiguous
  ordering.</p>
</blockquote>

<p>Any advice on this would be helpful. Thanks in advance.  </p>
"
60049059,"<p>i am trying to run linear regression and i am having issues with data type i think. I have tested line by line and everything works until i reach last line where i get the issue TypeError: invalid Type promotion. Based on my research i think it is due to date format.<br>
Here is my code:</p>

<pre><code>import pandas as pd
import numpy as np  
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression
data=pd.read_excel('C:\\Users\\Proximo\\PycharmProjects\Counts\\venv\\Counts.xlsx')  
data['DATE'] = pd.to_datetime(data['DATE'])
data.plot(x = 'DATE', y = 'COUNT', style = 'o')
plt.title('Corona Spread Over the Time')
plt.xlabel('Date')
plt.ylabel('Count')
plt.show()

X=data['DATE'].values.reshape(-1,1)
y=data['COUNT'].values.reshape(-1,1)
X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size=.2,random_state=0)
regressor = LinearRegression()  
regressor.fit(X_train,Y_train)
y_pre = regressor.predict(X_test)
</code></pre>

<p>When i run it this is the full error i get:</p>

<pre><code>    ---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

&lt;ipython-input-21-c9e943251026&gt; in &lt;module&gt;
----&gt; 1 y_pre = regressor.predict(X_test)
      2 

c:\users\slavi\pycharmprojects\coronavirus\venv\lib\site-packages\sklearn\linear_model\_base.py in predict(self, X)
    223             Returns predicted values.
    224         """"""
--&gt; 225         return self._decision_function(X)
    226 
    227     _preprocess_data = staticmethod(_preprocess_data)

c:\users\slavi\pycharmprojects\coronavirus\venv\lib\site-packages\sklearn\linear_model\_base.py in _decision_function(self, X)
    207         X = check_array(X, accept_sparse=['csr', 'csc', 'coo'])
    208         return safe_sparse_dot(X, self.coef_.T,
--&gt; 209                                dense_output=True) + self.intercept_
    210 
    211     def predict(self, X):

c:\users\Proximo\pycharmprojects\Count\venv\lib\site-packages\sklearn\utils\extmath.py in safe_sparse_dot(a, b, dense_output)
    149             ret = np.dot(a, b)
    150     else:
--&gt; 151         ret = a @ b
    152 
    153     if (sparse.issparse(a) and sparse.issparse(b)

TypeError: invalid type promotion
</code></pre>

<p>My date format which looks like this:</p>

<pre><code>array([['2020-01-20T00:00:00.000000000'],
   ['2020-01-21T00:00:00.000000000'],
   ['2020-01-22T00:00:00.000000000'],
   ['2020-01-23T00:00:00.000000000'],
   ['2020-01-24T00:00:00.000000000'],
   ['2020-01-25T00:00:00.000000000'],
   ['2020-01-26T00:00:00.000000000'],
   ['2020-01-27T00:00:00.000000000'],
   ['2020-01-28T00:00:00.000000000'],
   ['2020-01-29T00:00:00.000000000'],
   ['2020-01-30T00:00:00.000000000'],
   ['2020-01-31T00:00:00.000000000'],
   ['2020-02-01T00:00:00.000000000'],
   ['2020-02-02T00:00:00.000000000']], dtype='datetime64[ns]')
</code></pre>

<p>Any suggestion on how to resolve this issue?</p>
"
61242760,"<p>I got my python script to run the way I want it, but for some reason I am getting some info showing up that I do not want. <a href=""https://i.stack.imgur.com/bXMJZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bXMJZ.png"" alt=""enter image description here""></a></p>

<p>In this image, I dont want anything printed before the word ""Acute"". My python code is getting a wikipedia article, summarizing it, and printing the best sentences. However, no where do I have code to print the other stuff that is showing up. Once the generate button is clicked (which in this case it is)</p>

<p>Here is my code:
urls:</p>

<pre><code>    from django.conf.urls import url
    from django.contrib import admin
    from django.conf import settings
    from django.conf.urls.static import static
    from django.conf.urls import url, include
    from django.urls import path
    from . import views
    urlpatterns = [
        url(r'^admin/', admin.site.urls),
        url(r'^$',views.button),
        url(r'^output',views.output,name=""script""),
        url(r'^external',views.external),
    ]
</code></pre>

<p>Views.py</p>

<pre><code>from django.shortcuts import render
import requests
from subprocess import run,PIPE
import sys

def button(request):
    return render(request,'index.html')
def output(request):
    data=requests.get(""https://regres.in/api/users"")
    print(data.text)
    data=data.text
    return render(request,'index.html',{'data':data})
def external(request):
    out=run([sys.executable,'textSummary.py'],shell=False,stdout=PIPE)
    print(out)

    return render(request,'index.html',{'data1':out})
</code></pre>

<p>index.html</p>

<pre><code>{% load static %}
&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
&lt;head&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
    &lt;title&gt;Card layout&lt;/title&gt;
    &lt;link rel=""stylesheet"" type=""text/css"" href=""{% static 'css/styles.css' %}""/&gt;
    &lt;link href=""https://fonts.googleapis.com/css2?family=Dancing+Script&amp;display=swap"" rel=""stylesheet""&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h1 class=""StorySpinner""&gt;&lt;u&gt;Story Spinner&lt;/u&gt;&lt;/h1&gt;
    &lt;main&gt;
        &lt;div class=""container""&gt;
        &lt;/div&gt;
        &lt;section class=""cards""&gt;
            &lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;form action=""/external/"" method=""post""&gt;
                            {% csrf_token %}
                            {{data1}}
                            &lt;br&gt;&lt;br&gt;
                            &lt;input type=""submit"" value=""Generate""&gt;
                        &lt;/form&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
            &lt;/div&gt;
        &lt;/section&gt;
        &lt;/main&gt;
    &lt;/main&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>textSummary.py</p>

<pre><code>import bs4 as bs
import urllib.request
import re
import nltk
import heapq

source = urllib.request.urlopen('https://en.wikipedia.org/wiki/Coronavirus')
soup = bs.BeautifulSoup(source,'lxml')
maxWordsAllowed=15#no sentence should have more words than this many
maxSentencesAllowed=2#no more than this many sentences allowed
#getting all paragraphs in the html
text = """"
for paragraph in soup.find_all('p'):
    text += paragraph.text

#formatting the sentences
text = re.sub(r'\[[0-9]*\]',' ',text)
text = re.sub(r'\s+',' ',text)
#we want a clean text that has no periods commas etc as it would mess up our sentences
clean_text = text.lower()
clean_text = re.sub(r'\W',' ', clean_text)
clean_text = re.sub(r'\d',' ', clean_text)
clean_text = re.sub(r'\s+',' ', clean_text)

#tokenizing the text
sentences = nltk.sent_tokenize(text)
stop_words = nltk.corpus.stopwords.words('english')


word2count = {}#used for tracking score of the words
for word in nltk.word_tokenize(clean_text):#tokenize the words
    if word not in stop_words:#if it is not a stop word
        if word not in word2count.keys():#check to see if word is in the keys yet or not
            word2count[word] = 1#new word
        else:
            word2count[word] += 1#inc this frequency by one

for key in word2count.keys():#going through the keys 
    word2count[key] = word2count[key]/max(word2count.values())#dividing this specific word's frequency by the max numbers frequency

sent2score = {}#used for sentence score
for sentence in sentences:#go through the sentences 
    for word in nltk.word_tokenize(sentence.lower()):#lowercase the words
        if word in word2count.keys():#if the word is in 
            if len(sentence.split(' '))&lt;maxWordsAllowed:#checks to see if the sentence is less than the specified
                if sentence not in sent2score.keys():#if sentence is not in the list
                    sent2score[sentence] = word2count[word]#add the words frequency score to sent2score
                else:
                    sent2score[sentence] += word2count[word]#sentence already in the list so we want to add the words score and update it

best_sentences = heapq.nlargest(maxSentencesAllowed,sent2score,key=sent2score.get)#this will specify how many sentences allowed, get the sentences with the best scores and use those
newString = """"
for sentence in best_sentences:#printing the best sentences
    newString += sentence

print(newString)
</code></pre>
"
61241871,"<p>I am trying to run python code with a click of an html button and have it run a python script. I would prefer to just use a normal button rather than using a form to create a ""submit"" button (like I have it for my first card I created in <code>index.html</code>), but with the tutorial I followed, that's how it was done and couldn't find a way around it. All I want to do is run a script that I created with a click of a button. I am trying to do it with Django, but cant seem to fix this error.</p>

<pre><code>TypeError at /external/
bufsize must be an integer
Request Method: POST
Request URL:    http://127.0.0.1:8002/external/
Django Version: 3.0.5
Exception Type: TypeError
Exception Value:    
bufsize must be an integer
Exception Location: C:\Users\12673\anaconda3\lib\subprocess.py in __init__, line 702
Python Executable:  C:\Users\12673\anaconda3\python.exe
</code></pre>

<p>urls:</p>

<pre><code>    from django.conf.urls import url
    from django.contrib import admin
    from django.conf import settings
    from django.conf.urls.static import static
    from django.conf.urls import url, include
    from django.urls import path
    from . import views
    urlpatterns = [
        url(r'^admin/', admin.site.urls),
        url(r'^$',views.button),
        url(r'^output',views.output,name=""script""),
        url(r'^external',views.external),
    ]
</code></pre>

<p>Views.py</p>

<pre><code>from django.shortcuts import render
import requests
from subprocess import run,PIPE
import sys

def button(request):
    return render(request,'index.html')
def output(request):
    data=requests.get(""https://regres.in/api/users"")
    print(data.text)
    data=data.text
    return render(request,'index.html',{'data':data})
def external(request):
    out=run(sys.executable,['//c//Users//12673//desktop//project-04-story-spinner//djangoOutput//textSummary.py'],shell=False,stdout=PIPE)
    print(out)

    return render(request,'index.html',{'data1':out})
</code></pre>

<p>index.html</p>

<pre><code>{% load static %}
&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
&lt;head&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0""&gt;
    &lt;title&gt;Card layout&lt;/title&gt;
    &lt;link rel=""stylesheet"" type=""text/css"" href=""{% static 'css/styles.css' %}""/&gt;
    &lt;link href=""https://fonts.googleapis.com/css2?family=Dancing+Script&amp;display=swap"" rel=""stylesheet""&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h1 class=""StorySpinner""&gt;&lt;u&gt;Story Spinner&lt;/u&gt;&lt;/h1&gt;
    &lt;main&gt;
        &lt;div class=""container""&gt;
        &lt;/div&gt;
        &lt;section class=""cards""&gt;
            &lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;form action=""/external/"" method=""post""&gt;
                            {% csrf_token %}
                            {{data1}}
                            &lt;br&gt;&lt;br&gt;
                            &lt;input type=""submit"" value=""Generate""&gt;
                        &lt;/form&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
                &lt;div class=""card__image-container""&gt;
                    &lt;img src=""https://images.unsplash.com/photo-1528561156510-aba26bedef10?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=1200&amp;q=80""/&gt;
                &lt;/div&gt;
                &lt;div class=""card__content""&gt;
                    &lt;p class=""card__title text--medium""&gt;
                        Watermelon Bicycle 
                    &lt;/p&gt;
                    &lt;div class card=""card__info""&gt;
                        &lt;button class=""card__price text--medium""&gt;Select&lt;/button&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;&lt;div class=""card""&gt;
            &lt;/div&gt;
        &lt;/section&gt;
        &lt;/main&gt;
    &lt;/main&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>textSummary.py</p>

<pre><code>import bs4 as bs
import urllib.request
import re
import nltk
import heapq

source = urllib.request.urlopen('https://en.wikipedia.org/wiki/Coronavirus')
soup = bs.BeautifulSoup(source,'lxml')
maxWordsAllowed=15#no sentence should have more words than this many
maxSentencesAllowed=2#no more than this many sentences allowed
#getting all paragraphs in the html
text = """"
for paragraph in soup.find_all('p'):
    text += paragraph.text

#formatting the sentences
text = re.sub(r'\[[0-9]*\]',' ',text)
text = re.sub(r'\s+',' ',text)
#we want a clean text that has no periods commas etc as it would mess up our sentences
clean_text = text.lower()
clean_text = re.sub(r'\W',' ', clean_text)
clean_text = re.sub(r'\d',' ', clean_text)
clean_text = re.sub(r'\s+',' ', clean_text)

#tokenizing the text
sentences = nltk.sent_tokenize(text)
stop_words = nltk.corpus.stopwords.words('english')


word2count = {}#used for tracking score of the words
for word in nltk.word_tokenize(clean_text):#tokenize the words
    if word not in stop_words:#if it is not a stop word
        if word not in word2count.keys():#check to see if word is in the keys yet or not
            word2count[word] = 1#new word
        else:
            word2count[word] += 1#inc this frequency by one

for key in word2count.keys():#going through the keys 
    word2count[key] = word2count[key]/max(word2count.values())#dividing this specific word's frequency by the max numbers frequency

sent2score = {}#used for sentence score
for sentence in sentences:#go through the sentences 
    for word in nltk.word_tokenize(sentence.lower()):#lowercase the words
        if word in word2count.keys():#if the word is in 
            if len(sentence.split(' '))&lt;maxWordsAllowed:#checks to see if the sentence is less than the specified
                if sentence not in sent2score.keys():#if sentence is not in the list
                    sent2score[sentence] = word2count[word]#add the words frequency score to sent2score
                else:
                    sent2score[sentence] += word2count[word]#sentence already in the list so we want to add the words score and update it

best_sentences = heapq.nlargest(maxSentencesAllowed,sent2score,key=sent2score.get)#this will specify how many sentences allowed, get the sentences with the best scores and use those
newString = """"
for sentence in best_sentences:#printing the best sentences
    newString += sentence

print(newString)
</code></pre>
"
61697379,"<pre><code>import http.client
import mimetypes
today = datetime.today()
today = today.isoformat()

conn = http.client.HTTPSConnection(""api.covid19api.com"")
payload = ''
headers = {}
conn.request(""GET"", ""/live/country/qatar/status/confirmed/date/"",today, payload, headers)
res = conn.getresponse()
data = res.read()
print(data.decode(""utf-8""))
</code></pre>

<p>I'm trying to make it so that it would send a get request to the api every day as an update, but i keep getting this error after adding the today variable 
<code>TypeError: request() takes from 3 to 5 positional arguments but 6 were given</code></p>
"
61667390,"<p>i have been trying to use tweepy to gather some data concerning the coronavirus, i am using python 3.8 and apparently as i have been reading there is a problem concerning bytes type that was not present in python 2. My error is in this line:</p>

<p><strong>w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])</strong></p>

<p>If anyone can help me modify the code so it works i would be grateful. PS:First time posting a question on stackoverflow be gentle :)</p>

<p>Code:</p>

<pre><code>def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, 
hashtag_phrase):

#create authentication for accessing Twitter
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)

#initialize Tweepy API
api = tweepy.API(auth)

#get the name of the spreadsheet we will write to
fname = '_'.join(re.findall(r""#(\w+)"", hashtag_phrase))

#open the spreadsheet we will write to
with open('%s.csv' % (fname), 'wb') as file:

    w = csv.writer(file)

    #write header row to spreadsheet
    w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])

    #for each tweet matching our hashtags, write relevant info to the spreadsheet
    for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \
                               lang=""en"", tweet_mode='extended').items(100):
        w.writerow([tweet.created_at, tweet.full_text.replace('\n',' ').encode('utf-8'), 
    tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])
if __name__ == '__main__':
search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase)
</code></pre>
"
61284357,"<p>So I'm building a dash app and using Heroku to host. 
You can view my code here: <a href=""https://github.com/CoderHahs/ml-training/tree/master/Projects/covid-app-nogit"" rel=""nofollow noreferrer"">My code</a></p>

<p>The site can be found here: <a href=""https://covid19-report.herokuapp.com"" rel=""nofollow noreferrer"">covid19-report.herokuapp.com</a>
(thought I'd make a covid19 dashboard just to practise data analytics with plotly dash)</p>

<p>Basically I followed the Dash deployment documentation for heroku found here: <a href=""https://dash.plotly.com/deployment"" rel=""nofollow noreferrer"">Dash Deployment Documentation</a></p>

<p>The app runs fine locally, but I'm really not sure why its failing on Heroku.</p>

<p>Below is the error message. It looks like some JSON error, but again it runs fine locally. Some insight into this would help. Thank you!</p>

<pre><code>2020-04-18T04:31:17.714587+00:00 heroku[web.1]: State changed from crashed to starting
2020-04-18T04:31:27.701650+00:00 app[web.1]: [2020-04-18 04:31:27 +0000] [4] [INFO] Starting gunicorn 20.0.4
2020-04-18T04:31:27.702418+00:00 app[web.1]: [2020-04-18 04:31:27 +0000] [4] [INFO] Listening at: http://0.0.0.0:55039 (4)
2020-04-18T04:31:27.702566+00:00 app[web.1]: [2020-04-18 04:31:27 +0000] [4] [INFO] Using worker: sync
2020-04-18T04:31:27.708762+00:00 app[web.1]: [2020-04-18 04:31:27 +0000] [10] [INFO] Booting worker with pid: 10
2020-04-18T04:31:27.785970+00:00 app[web.1]: [2020-04-18 04:31:27 +0000] [11] [INFO] Booting worker with pid: 11
2020-04-18T04:31:29.269562+00:00 heroku[web.1]: State changed from starting to up
2020-04-18T04:31:45.266825+00:00 app[web.1]: [2020-04-18 04:31:45 +0000] [10] [ERROR] Exception in worker process
2020-04-18T04:31:45.266850+00:00 app[web.1]: Traceback (most recent call last):
2020-04-18T04:31:45.266851+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", lin
e 583, in spawn_worker
2020-04-18T04:31:45.266852+00:00 app[web.1]: worker.init_process()
2020-04-18T04:31:45.266852+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py""
, line 119, in init_process

2020-04-18T04:31:45.266853+00:00 app[web.1]: self.load_wsgi()
2020-04-18T04:31:45.266853+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py""
, line 144, in load_wsgi
2020-04-18T04:31:45.266853+00:00 app[web.1]: self.wsgi = self.app.wsgi()
2020-04-18T04:31:45.266854+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", li
ne 67, in wsgi
2020-04-18T04:31:45.266854+00:00 app[web.1]: self.callable = self.load()
2020-04-18T04:31:45.266855+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"",
 line 49, in load
2020-04-18T04:31:45.266855+00:00 app[web.1]: return self.load_wsgiapp()
2020-04-18T04:31:45.266855+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"",
 line 39, in load_wsgiapp
2020-04-18T04:31:45.266855+00:00 app[web.1]: return util.import_app(self.app_uri)
2020-04-18T04:31:45.266856+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/util.py"", line 3
58, in import_app
2020-04-18T04:31:45.266856+00:00 app[web.1]: mod = importlib.import_module(module)
2020-04-18T04:31:45.266857+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/importlib/__init__.py"", line 126, in im
port_module
2020-04-18T04:31:45.266857+00:00 app[web.1]: return _bootstrap._gcd_import(name[level:], package, level)
2020-04-18T04:31:45.266858+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 994, in _gcd_import
2020-04-18T04:31:45.266858+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 971, in _find_and_load
2020-04-18T04:31:45.266858+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 955, in _find_and_load_unlocked
2020-04-18T04:31:45.266858+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 665, in _load_unlocked
2020-04-18T04:31:45.266859+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap_external&gt;"", line 678, in exec_module
2020-04-18T04:31:45.266859+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 219, in _call_with_frames_removed
2020-04-18T04:31:45.266859+00:00 app[web.1]: File ""/app/app.py"", line 42, in &lt;module&gt;
2020-04-18T04:31:45.266860+00:00 app[web.1]: initial_data = pd.DataFrame(r.json())[['Date', 'Confirmed', 'Deaths', 'Recovere
d']].groupby('Date').sum().reset_index()
2020-04-18T04:31:45.266860+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/requests/models.py"", line
 898, in json
2020-04-18T04:31:45.266861+00:00 app[web.1]: return complexjson.loads(self.text, **kwargs)

2020-04-18T04:31:45.266861+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/json/__init__.py"", line 354, in loads
2020-04-18T04:31:45.266861+00:00 app[web.1]: return _default_decoder.decode(s)
2020-04-18T04:31:45.266862+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/json/decoder.py"", line 339, in decode
2020-04-18T04:31:45.266862+00:00 app[web.1]: obj, end = self.raw_decode(s, idx=_w(s, 0).end())
2020-04-18T04:31:45.266862+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/json/decoder.py"", line 357, in raw_deco
de
2020-04-18T04:31:45.266863+00:00 app[web.1]: raise JSONDecodeError(""Expecting value"", s, err.value) from None
2020-04-18T04:31:45.266871+00:00 app[web.1]: json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2020-04-18T04:31:45.267475+00:00 app[web.1]: [2020-04-18 04:31:45 +0000] [10] [INFO] Worker exiting (pid: 10)
2020-04-18T04:31:45.306244+00:00 app[web.1]: [2020-04-18 04:31:45 +0000] [11] [ERROR] Exception in worker process
2020-04-18T04:31:45.306250+00:00 app[web.1]: Traceback (most recent call last):
2020-04-18T04:31:45.306251+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", lin
e 583, in spawn_worker
2020-04-18T04:31:45.306252+00:00 app[web.1]: worker.init_process()
2020-04-18T04:31:45.306252+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py""
, line 119, in init_process
2020-04-18T04:31:45.306253+00:00 app[web.1]: self.load_wsgi()
2020-04-18T04:31:45.306253+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py""
2020-04-18T04:31:45.306253+00:00 app[web.1]: self.load_wsgi()
2020-04-18T04:31:45.306253+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py""
, line 144, in load_wsgi
2020-04-18T04:31:45.306253+00:00 app[web.1]: self.wsgi = self.app.wsgi()
2020-04-18T04:31:45.306254+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", li
ne 67, in wsgi
2020-04-18T04:31:45.306254+00:00 app[web.1]: self.callable = self.load()
2020-04-18T04:31:45.306255+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"",
 line 49, in load
2020-04-18T04:31:45.306255+00:00 app[web.1]: return self.load_wsgiapp()
2020-04-18T04:31:45.306255+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"",
 line 39, in load_wsgiapp
2020-04-18T04:31:45.306256+00:00 app[web.1]: return util.import_app(self.app_uri)
2020-04-18T04:31:45.306256+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/util.py"", line 3

58, in import_app
2020-04-18T04:31:45.306256+00:00 app[web.1]: mod = importlib.import_module(module)
2020-04-18T04:31:45.306257+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/importlib/__init__.py"", line 126, in im
port_module
2020-04-18T04:31:45.306258+00:00 app[web.1]: return _bootstrap._gcd_import(name[level:], package, level)
2020-04-18T04:31:45.306258+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 994, in _gcd_import
2020-04-18T04:31:45.306259+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 971, in _find_and_load
2020-04-18T04:31:45.306259+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 955, in _find_and_load_unlocked
2020-04-18T04:31:45.306259+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 665, in _load_unlocked
2020-04-18T04:31:45.306260+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap_external&gt;"", line 678, in exec_module
2020-04-18T04:31:45.306260+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 219, in _call_with_frames_removed
2020-04-18T04:31:45.306260+00:00 app[web.1]: File ""/app/app.py"", line 42, in &lt;module&gt;
2020-04-18T04:31:45.306261+00:00 app[web.1]: initial_data = pd.DataFrame(r.json())[['Date', 'Confirmed', 'Deaths', 'Recovere
d']].groupby('Date').sum().reset_index()
2020-04-18T04:31:45.306262+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/requests/models.py"", line
 898, in json
2020-04-18T04:31:45.306262+00:00 app[web.1]: return complexjson.loads(self.text, **kwargs)
2020-04-18T04:31:45.306262+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/json/__init__.py"", line 354, in loads
2020-04-18T04:31:45.306262+00:00 app[web.1]: return _default_decoder.decode(s)
2020-04-18T04:31:45.306263+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/json/decoder.py"", line 339, in decode
2020-04-18T04:31:45.306263+00:00 app[web.1]: obj, end = self.raw_decode(s, idx=_w(s, 0).end())
2020-04-18T04:31:45.306264+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/json/decoder.py"", line 357, in raw_deco
de
2020-04-18T04:31:45.306264+00:00 app[web.1]: raise JSONDecodeError(""Expecting value"", s, err.value) from None
2020-04-18T04:31:45.306273+00:00 app[web.1]: json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
2020-04-18T04:31:45.307523+00:00 app[web.1]: [2020-04-18 04:31:45 +0000] [11] [INFO] Worker exiting (pid: 11)
2020-04-18T04:31:45.664281+00:00 app[web.1]: [2020-04-18 04:31:45 +0000] [4] [INFO] Shutting down: Master
2020-04-18T04:31:45.664592+00:00 app[web.1]: [2020-04-18 04:31:45 +0000] [4] [INFO] Reason: Worker failed to boot.
2020-04-18T04:31:45.805719+00:00 heroku[web.1]: State changed from up to crashed
2020-04-18T04:38:59.314463+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covid19-repor
t.herokuapp.com request_id=b48e8c2e-9724-47fd-9a55-e786cb0c1508 fwd=""209.17.96.74"" dyno= connect= service= status=503 bytes=
 protocol=https

</code></pre>
"
61560784,"<p>I am trying to create a bubble map in gmaps, with size of bubble based on values in a column in a pandas dataframe. I am getting the error 
<em>'TraitError: The 'scale' trait of a Symbol instance must be an int, but a value of 2335  was specified.'</em></p>

<p>My dataset is this:</p>

<p><a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv</a></p>

<p>I am naming the dataframe 'cgr' and then my code is this:</p>

<pre><code>data_layer = gmaps.symbol_layer(
cgr[['Lat','Long']], fill_color='green', stroke_color='green', scale=cgr['5/1/20']
)

fig = gmaps.figure()

fig.add_layer(data_layer)

fig
</code></pre>

<p>I don't understand why gmaps is not recognising the numpy.int64 numbers as ints, and I cannot convert them to native python ints. Any ideas?</p>

<p>Here is the full Traceback</p>

<pre><code>TraitError                                Traceback (most recent call last)
&lt;ipython-input-7-202e1cec5d37&gt; in &lt;module&gt;
      1 data_layer = gmaps.symbol_layer(
----&gt; 2 cgr[['Lat','Long']], fill_color='green', stroke_color='green', scale=cgr['5/1/20']
      3 )
      4 fig = gmaps.figure()
      5 fig.add_layer(data_layer)

~\anaconda3\lib\site-packages\gmaps\marker.py in symbol_layer(locations, hover_text, fill_color, fill_opacity, stroke_color, stroke_opacity, scale, info_box_content, display_info_box)
    479         fill_opacity, stroke_color, stroke_opacity, scale,
    480         info_box_content, display_info_box)
--&gt; 481     symbols = [Symbol(**option) for option in options]
    482     return Markers(markers=symbols)
    483 

~\anaconda3\lib\site-packages\gmaps\marker.py in &lt;listcomp&gt;(.0)
    479         fill_opacity, stroke_color, stroke_opacity, scale,
    480         info_box_content, display_info_box)
--&gt; 481     symbols = [Symbol(**option) for option in options]
    482     return Markers(markers=symbols)
    483 

~\anaconda3\lib\site-packages\gmaps\marker.py in __init__(self, location, **kwargs)
    162         kwargs = _resolve_info_box_kwargs(**kwargs)
    163         kwargs['location'] = location
--&gt; 164         super(Symbol, self).__init__(**kwargs)
    165 
    166 

~\anaconda3\lib\site-packages\ipywidgets\widgets\widget.py in __init__(self, **kwargs)
    410         """"""Public constructor""""""
    411         self._model_id = kwargs.pop('model_id', None)
--&gt; 412         super(Widget, self).__init__(**kwargs)
    413 
    414         Widget._call_widget_constructed(self)

~\anaconda3\lib\site-packages\traitlets\traitlets.py in __init__(self, *args, **kwargs)
    995             for key, value in kwargs.items():
    996                 if self.has_trait(key):
--&gt; 997                     setattr(self, key, value)
    998                 else:
    999                     # passthrough args that don't set traits to super

~\anaconda3\lib\site-packages\traitlets\traitlets.py in __set__(self, obj, value)
    583             raise TraitError('The ""%s"" trait is read-only.' % self.name)
    584         else:
--&gt; 585             self.set(obj, value)
    586 
    587     def _validate(self, obj, value):

~\anaconda3\lib\site-packages\traitlets\traitlets.py in set(self, obj, value)
    557 
    558     def set(self, obj, value):
--&gt; 559         new_value = self._validate(obj, value)
    560         try:
    561             old_value = obj._trait_values[self.name]

~\anaconda3\lib\site-packages\traitlets\traitlets.py in _validate(self, obj, value)
    589             return value
    590         if hasattr(self, 'validate'):
--&gt; 591             value = self.validate(obj, value)
    592         if obj._cross_validation_lock is False:
    593             value = self._cross_validate(obj, value)

~\anaconda3\lib\site-packages\traitlets\traitlets.py in validate(self, obj, value)
   1868     def validate(self, obj, value):
   1869         if not isinstance(value, int):
-&gt; 1870             self.error(obj, value)
   1871         return _validate_bounds(self, obj, value)
   1872 

~\anaconda3\lib\site-packages\traitlets\traitlets.py in error(self, obj, value)
    623             e = ""The '%s' trait must be %s, but a value of %r was specified."" \
    624                 % (self.name, self.info(), repr_type(value))
--&gt; 625         raise TraitError(e)
    626 
    627     def get_metadata(self, key, default=None):

TraitError: The 'scale' trait of a Symbol instance must be an int, but a value of 2335 &lt;class 'numpy.int64'&gt; was specified.
</code></pre>
"
60916612,"<pre><code>import pandas as pd
from bokeh.plotting import figure, show
from bokeh.io import output_notebook
output_notebook()
df = pd.read_csv(""covid_19_india.csv"")
melted_df = pd.melt(df, id_vars=['Date'], value_vars=['ConfirmedIndianNational', 'Deaths'])
melted_df.head()
p = Bar(melted_df, label=""Date"", values=""value"", group=""variable"", legend=""top_left"",ylabel='Values')
</code></pre>

<p>I tried this code  and getting a error 
NameError: name 'Bar' is not defined</p>

<p>How to solve this</p>
"
61491302,"<p>I am trying to build a Keras NN off of the tensor flow specifications. However I am running into problems with my lstm_input where I get the error ""</p>

<p>ValueError: Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (None, 1) ""</p>

<p>I am relatively new to using Keras for time series, so any help would be GREATLY appreciated. I am trying to predict/forecast for confirmed cases and fatalities of COVID19 in New York.</p>

<p>My adapted code:</p>

<pre><code>    import tensorflow as tf

    import matplotlib as mpl
    import matplotlib.pyplot as plt
    import numpy as np
    import os

    import pandas as pd

    mpl.rcParams['figure.figsize'] = (8, 6)
    mpl.rcParams['axes.grid'] = False

    df = USARate[USARate['Province_State'] == 'New York' ]
    df.drop('Province_State', axis = 1, inplace = True)
    TRAIN_SPLIT = 60
    tf.random.set_seed(13)
    features_considered = ['ConfirmedCases', 'Fatalities']
    features = df[features_considered]
    features.index = df['Date']
    features.head()

    ConfirmedCases  Fatalities
    Date        
    2020-01-22  0   0
    2020-01-23  0   0
    2020-01-24  0   0
    2020-01-25  0   0
    2020-01-26  0   0
    dataset = features.values
    data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)
    data_std = dataset[:TRAIN_SPLIT].std(axis=0)


    def multivariate_data(dataset, target, start_index, end_index,  history_size,
                      target_size, step, single_step=False):
    data = []
    labels = []

    start_index = start_index + history_size
    if end_index is None:
      end_index = len(dataset) - target_size

    for i in range(start_index, end_index):
     indices = range(i-history_size, i, step)
     data.append(dataset[indices])

    if single_step:
      labels.append(target[i+target_size])
    else:
      labels.append(target[i:i+target_size])

    return np.array(data), np.array(labels)


    BATCH_SIZE = 20
    BUFFER_SIZE = 100

    past_history = 59
    future_target = 1
    STEP = 1

    x_train_single, y_train_single = multivariate_data(dataset, dataset[:, 1], 0,
                                                   TRAIN_SPLIT, past_history,
                                                   future_target, STEP,
                                                   single_step=True)
    x_val_single, y_val_single = multivariate_data(dataset, dataset[:, 1],
                                               TRAIN_SPLIT, None, past_history,
                                               future_target, STEP,
                                               single_step=True)
    print ('Single window of past history : {}'.format(x_train_single[0].shape))

    train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))
    train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()

    val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))
    val_data_single = val_data_single.batch(BATCH_SIZE).repeat()

    single_step_model = tf.keras.models.Sequential()
    single_step_model.add(tf.keras.layers.LSTM(8,
                                  input_shape=x_train_single.shape[-2:]))

    single_step_model.add(tf.keras.layers.Dense(1))
                         single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')


    EPOCHS = 10
    EVALUATION_INTERVAL = 1

    single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,
                                                    steps_per_epoch=EVALUATION_INTERVAL,
                                             validation_data=val_data_single,
                                            validation_steps=50)

</code></pre>

<p>errors above on single_step_history ^^^^
please excuse the indent error on model.compile, I couldn't tailor it back in the interface here.</p>
"
61160728,"<p>I'm trying to run the following and gives me an error message.</p>

<pre><code>data &lt;- c(""Who said we cant have a lil dance party while were stuck in Quarantine? Happy Friday Cousins!! We got through another week of Quarantine. Lets continue to stay safe, healthy and make the best of the situation.  . . Video:  . . -  #blackgirlstraveltoo #everydayafrica #travelnoire #blacktraveljourney #essencetravels #africanculture #blacktravelfeed #blacktravel #melanintravel #ethiopia #representationmatters #blackcommunity #Moyoafrika #browngirlbloggers #travelafrica #blackgirlskillingit #passportstamps #blacktravelista #blackisbeautiful #weworktotravel #blackgirlsrock #mytravelcrush #blackandabroad #blackgirlstravel #blacktravel #africanamerican #africangirlskillingit #africanmusic #blacktravelmovement #blacktravelgram"",
      ""#Copingwiththelockdown... Festac town, Lagos.  #covid19 #streetphotography #urbanphotography #copingwiththelockdown #documentaryphotography #hustlingandbustling #cityscape #coronavirus #busyroad #everydaypeople #everydaylife #commute #lagosroad #lagosmycity #nigeria #africa #westafrica #lagos #hustle #people #strength #faith #nopoverty #everydayeverywhere #everydayafrica #everydaylagos #nohunger #chroniclesofonyinye"",
      ""Peace Everywhere. Amani Kila Pahali. Photo by Adan Galma  . * * * * * * #matharestories #mathare #adangalma #everydaymathare #everydayeverywhere #everydayafrica #peace #amani #knowmathare #streets #spi_street #mathareslums"")
data_df &lt;- as.data.frame(data)
remove_reg &lt;- ""&amp;amp;|&amp;lt;|&amp;gt;""
tidy_data &lt;- data_df %&gt;% 
mutate(text = str_remove_all(text, remove_reg)) %&gt;%
unnest_tokens(word, text, token = ""data_df"") %&gt;%
filter(!word %in% stop_words$word,
     !word %in% str_remove_all(stop_words$word, ""'""),
     str_detect(word, ""[a-z]""))
</code></pre>

<p>It gives me the following error message:</p>

<blockquote>
  <p>Error in stri_replace_all_regex(string, pattern, fix_replacement(replacement),  : 
    argument <code>str</code> should be a character vector (or an object coercible to)""</p>
</blockquote>

<p>How can I fix it?</p>
"
61068639,"<p>In my case I load the following csv data (<a href=""https://ourworldindata.org/coronavirus-source-data"" rel=""nofollow noreferrer"">https://ourworldindata.org/coronavirus-source-data</a>) by using the CSV module and importing it like that:</p>

<pre><code>using DataFrames
using CSV

raw = CSV.read(""data.csv"")
</code></pre>

<p>Then I want to set a string column by indexing it like that:</p>

<pre><code>raw[1, :location] = ""AA""
</code></pre>

<p>and I get the following error:</p>

<pre><code>setindex! not defined for CSV.Column{String,PooledString}

Stacktrace:
 [1] error(::String, ::Type) at ./error.jl:42
 [2] error_if_canonical_setindex(::IndexLinear, ::CSV.Column{String,PooledString}, ::Int64) at ./abstractarray.jl:1006
 [3] setindex!(::CSV.Column{String,PooledString}, ::String, ::Int64) at ./abstractarray.jl:997
 [4] insert_single_entry!(::DataFrame, ::String, ::Int64, ::Symbol) at /home/chris/.julia/packages/DataFrames/S3ZFo/src/dataframe/dataframe.jl:452
 [5] setindex!(::DataFrame, ::String, ::Int64, ::Symbol) at /home/chris/.julia/packages/DataFrames/S3ZFo/src/dataframe/dataframe.jl:491
 [6] top-level scope at In[31]:1
</code></pre>

<p>Has this something to do with my types or am I doing something wrong completely? For a simple example it seems to works that way:</p>

<pre><code>df=DataFrames.DataFrame(A=[1,2],B=[3,4])

df[2,:A]=7
</code></pre>
"
60585565,"<p>I am running my scraping project in Jupyter Notebooks on my server using python3. For some reason  Tabula-py / Tabula errors when running Tabula.read_pdf and returns TypeError: expected str, bytes or os.PathLike object, not builtin_function_or_method. How do I make it work? I am passing actual PDF file. </p>

<p><strong>My code that errors</strong></p>

<pre><code>import tabula
df = tabula.read_pdf(""20200125-sitrep-5-2019-ncov.pdf"", pages=all)
</code></pre>

<p><strong>My error</strong></p>

<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-20-4f86b7402956&gt; in &lt;module&gt;
----&gt; 1 df = tabula.read_pdf(""20200125-sitrep-5-2019-ncov.pdf"", pages=all)

/usr/local/lib/python3.7/dist-packages/tabula/io.py in read_pdf(input_path, output_format,       encoding, java_options, pandas_options, multiple_tables, user_agent, **kwargs)
320 
321     try:
--&gt; 322         output = _run(java_options, kwargs, path, encoding)
323     finally:
324         if temporary:

/usr/local/lib/python3.7/dist-packages/tabula/io.py in _run(java_options, options, path, encoding)
 83             stderr=subprocess.PIPE,
 84             stdin=subprocess.DEVNULL,
---&gt; 85             check=True,
 86         )
 87         if result.stderr:

/usr/lib/python3.7/subprocess.py in run(input, capture_output, timeout, check, *popenargs, **kwargs)
470         kwargs['stderr'] = PIPE
471 
--&gt; 472     with Popen(*popenargs, **kwargs) as process:
473         try:
474             stdout, stderr = process.communicate(input, timeout=timeout)

/usr/lib/python3.7/subprocess.py in __init__(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)
773                                 c2pread, c2pwrite,
774                                 errread, errwrite,
--&gt; 775                                 restore_signals, start_new_session)
776         except:
777             # Cleanup if the child failed starting.

/usr/lib/python3.7/subprocess.py in _execute_child(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)
1451                             errread, errwrite,
1452                             errpipe_read, errpipe_write,
-&gt; 1453                             restore_signals, start_new_session, preexec_fn)
1454                     self._child_created = True
1455                 finally:

TypeError: expected str, bytes or os.PathLike object, not builtin_function_or_method
</code></pre>

<p>My PDF is named 20200125-sitrep-5-2019-ncov.pdf. This is the pdf that I scraped - <a href=""https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200125-sitrep-5-2019-ncov.pdf?sfvrsn=429b143d_8"" rel=""nofollow noreferrer"">https://www.who.int/docs/default-source/coronaviruse/situation-reports/20200125-sitrep-5-2019-ncov.pdf?sfvrsn=429b143d_8</a></p>

<p><a href=""https://i.stack.imgur.com/9xtWx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9xtWx.png"" alt=""enter image description here""></a></p>
"
60703052,"<p>I have been working with the Corona Virus Dataset from <a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"" rel=""nofollow noreferrer"">CSSEGISandData/COVID-19</a>.
I have summed up different province data into one under single country names. But, I need two columns of Latitude and Longitude against countries. </p>

<p>I tried <a href=""https://amaral.northwestern.edu/blog/getting-long-lat-list-cities"" rel=""nofollow noreferrer"">OpenCageGeocodes</a> but, didn't work well. I have attached the code sample I have implemented with the error I am getting.</p>

<pre><code>from opencage.geocoder import OpenCageGeocode

key = 'MY_API'                    #I have inserted my API Key here
geocoder = OpenCageGeocode(key)

list_lat = []   # create empty lists

list_long = []


for index, row in df_main.iterrows(): # iterate over rows in dataframe

    Country = row['Country/Region']       
    query = str(Country)

    results = geocoder.geocode(query)   
    lat = results[0]['geometry']['lat']
    long = results[0]['geometry']['lng']

    list_lat.append(lat)
    list_long.append(long)


    # create new columns from lists    

    df_main['lat'] = list_lat   

    df_main['lon'] = list_long
</code></pre>

<p><strong>The Error Message is:</strong> KeyError: 'Country/Region' </p>

<p><strong>The data frame I'm working on</strong>
<a href=""https://i.stack.imgur.com/CEuBR.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CEuBR.png"" alt=""enter image description here""></a></p>
"
61025574,"<p>I was trying to deploy an XGBoost model with Flask and Heroku and followed <a href=""https://blog.cambridgespark.com/deploying-a-machine-learning-model-to-the-web-725688b851c7"" rel=""nofollow noreferrer"">this tutorial</a> on Medium. After getting the app successfully running on my local machine, I couldn't deploy it on Heroku without incurring ""Application Error"". (I tried to deploy the tutorial author's code and ran into exactly the same issue.)</p>

<p>Below is code in all relevant files and the error message. Would appreciate it if anyone has a clue about how to solve this issue?</p>

<p>Code in <code>app.py</code>:</p>

<pre><code>import pickle
import pandas as pd
import flask 

# Load two pre-trained models
with open(f""model/classifier.pkl"", ""rb"") as f:
    model = pickle.load(f)

with open(f""model/age_scaler.pkl"", ""rb"") as f:
    scaler = pickle.load(f)

# Initialize the Flask app
app = flask.Flask(__name__, template_folder=""templates"")

# Set up the main route
@app.route(""/"", methods=[""GET"", ""POST""])
def main():
    if flask.request.method == ""GET"":
        # Just render the initial form, to get input
        return flask.render_template(""main.html"")

    if flask.request.method == ""POST"":
        # Extract the input
        age = flask.request.form[""age""]
        sex = flask.request.form[""sex""]
        preconition = flask.request.form[""chronic_disease_binary""]
        hypertension = flask.request.form[""hypertension""]
        diabetes = flask.request.form[""diabetes""]
        heart = flask.request.form[""heart""]
        fever = flask.request.form[""fever""]
        cough = flask.request.form[""cough""]
        fatigue = flask.request.form[""fatigue""]
        sore_throat = flask.request.form[""sore_throat""]

        # Make DataFrame for model
        input_variables = pd.DataFrame(
            [
                [
                    scaler.transform([[age]])[0][0],
                    sex,
                    preconition,
                    hypertension,
                    diabetes,
                    heart,
                    fever,
                    cough,
                    fatigue,
                    sore_throat,
                ]
            ],
            columns=[
                ""age"",
                ""sex"",
                ""chronic_disease_binary"",
                ""hypertension"",
                ""diabetes"",
                ""heart"",
                ""fever"",
                ""cough"",
                ""fatigue"",
                ""sore throat"",
            ],
            dtype=float,
            index=[""input""],
        )

        # Get the model's prediction
        prediction = model.predict_proba(input_variables)[0][1]

        # Render the form again, but add in the prediction and remind user
        # of the values they input before
        return flask.render_template(
            ""main.html"",
            original_input={
                ""Age"": age,
                ""Sex"": sex,
                ""Precondition"": preconition,
                ""Hypertension"": hypertension,
                ""Diabetes"": diabetes,
                ""Heart disease"": heart,
                ""Fever"": fever,
                ""Cough"": cough,
                ""Fatigue"": fatigue,
                ""Sore throat"": sore_throat,
            },
            result= ""{} %"".format(round(float(prediction), 2) * 100)
        )


if __name__ == ""__main__"":
    app.debug = True
    app.run()
</code></pre>

<p>Code in <code>Procfile</code>:</p>

<pre><code>web: gunicorn app:app

</code></pre>

<p>Code in <code>requirements.txt</code></p>

<pre><code>flask
pandas
gunicorn
xgboost
sklearn
</code></pre>

<p><code>heroku logs</code>:</p>

<pre><code>(base) MacBook-Pro-2:covid19-app apple$ heroku logs --tail
2020-04-04T08:18:12.896599+00:00 app[web.1]: [bt] (5) /app/.heroku/python/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x4cd) [0x7f06a8e52e1d]
2020-04-04T08:18:12.896599+00:00 app[web.1]: [bt] (6) /app/.heroku/python/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x8ba7) [0x7f06a8e49ba7]
2020-04-04T08:18:12.896599+00:00 app[web.1]: [bt] (7) /app/.heroku/python/bin/python(_PyObject_FastCallDict+0xb3) [0x55d8fdde2bc3]
2020-04-04T08:18:12.896600+00:00 app[web.1]: [bt] (8) /app/.heroku/python/bin/python(+0x1890f0) [0x55d8fdedc0f0]
2020-04-04T08:18:12.896600+00:00 app[web.1]: 
2020-04-04T08:18:12.896607+00:00 app[web.1]: 
2020-04-04T08:18:12.896917+00:00 app[web.1]: [2020-04-04 08:18:12 +0000] [10] [ERROR] Exception in worker process
2020-04-04T08:18:12.896918+00:00 app[web.1]: Traceback (most recent call last):
2020-04-04T08:18:12.896918+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 583, in spawn_worker
2020-04-04T08:18:12.896919+00:00 app[web.1]: worker.init_process()
2020-04-04T08:18:12.896919+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py"", line 119, in init_process
2020-04-04T08:18:12.896920+00:00 app[web.1]: self.load_wsgi()
2020-04-04T08:18:12.896920+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py"", line 144, in load_wsgi
2020-04-04T08:18:12.896920+00:00 app[web.1]: self.wsgi = self.app.wsgi()
2020-04-04T08:18:12.896921+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 67, in wsgi
2020-04-04T08:18:12.896921+00:00 app[web.1]: self.callable = self.load()
2020-04-04T08:18:12.896922+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 49, in load
2020-04-04T08:18:12.896922+00:00 app[web.1]: return self.load_wsgiapp()
2020-04-04T08:18:12.896922+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 39, in load_wsgiapp
2020-04-04T08:18:12.896923+00:00 app[web.1]: return util.import_app(self.app_uri)
2020-04-04T08:18:12.896923+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/util.py"", line 358, in import_app
2020-04-04T08:18:12.896923+00:00 app[web.1]: mod = importlib.import_module(module)
2020-04-04T08:18:12.896924+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/importlib/__init__.py"", line 126, in import_module
2020-04-04T08:18:12.896924+00:00 app[web.1]: return _bootstrap._gcd_import(name[level:], package, level)
2020-04-04T08:18:12.896924+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 994, in _gcd_import
2020-04-04T08:18:12.896925+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 971, in _find_and_load
2020-04-04T08:18:12.896925+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 955, in _find_and_load_unlocked
2020-04-04T08:18:12.896925+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 665, in _load_unlocked
2020-04-04T08:18:12.896926+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap_external&gt;"", line 678, in exec_module
2020-04-04T08:18:12.896926+00:00 app[web.1]: File ""&lt;frozen importlib._bootstrap&gt;"", line 219, in _call_with_frames_removed
2020-04-04T08:18:12.896926+00:00 app[web.1]: File ""/app/app.py"", line 7, in &lt;module&gt;
2020-04-04T08:18:12.896927+00:00 app[web.1]: model = pickle.load(f)
2020-04-04T08:18:12.896927+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/xgboost/core.py"", line 1094, in __setstate__
2020-04-04T08:18:12.896927+00:00 app[web.1]: _LIB.XGBoosterUnserializeFromBuffer(handle, ptr, length))
2020-04-04T08:18:12.896928+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/xgboost/core.py"", line 189, in _check_call
2020-04-04T08:18:12.896928+00:00 app[web.1]: raise XGBoostError(py_str(_LIB.XGBGetLastError()))
2020-04-04T08:18:12.896929+00:00 app[web.1]: xgboost.core.XGBoostError: [08:18:12] /workspace/src/learner.cc:682: Check failed: header == serialisation_header_:
2020-04-04T08:18:12.896956+00:00 app[web.1]: 
2020-04-04T08:18:12.896956+00:00 app[web.1]: If you are loading a serialized model (like pickle in Python) generated by older
2020-04-04T08:18:12.896956+00:00 app[web.1]: XGBoost, please export the model by calling `Booster.save_model` from that version
2020-04-04T08:18:12.896957+00:00 app[web.1]: first, then load it back in current version.  There's a simple script for helping
2020-04-04T08:18:12.896957+00:00 app[web.1]: the process. See:
2020-04-04T08:18:12.896957+00:00 app[web.1]: 
2020-04-04T08:18:12.896957+00:00 app[web.1]: https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html
2020-04-04T08:18:12.896958+00:00 app[web.1]: 
2020-04-04T08:18:12.896958+00:00 app[web.1]: for reference to the script, and more details about differences between saving model and
2020-04-04T08:18:12.896958+00:00 app[web.1]: serializing.
2020-04-04T08:18:12.896958+00:00 app[web.1]: 
2020-04-04T08:18:12.896958+00:00 app[web.1]: 
2020-04-04T08:18:12.896959+00:00 app[web.1]: Stack trace:
2020-04-04T08:18:12.896959+00:00 app[web.1]: [bt] (0) /app/.heroku/python/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x54) [0x7f066f73b614]
2020-04-04T08:18:12.896959+00:00 app[web.1]: [bt] (1) /app/.heroku/python/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(xgboost::LearnerImpl::Load(dmlc::Stream*)+0x661) [0x7f066f82dc71]
2020-04-04T08:18:12.896960+00:00 app[web.1]: [bt] (2) /app/.heroku/python/lib/python3.6/site-packages/xgboost/./lib/libxgboost.so(XGBoosterUnserializeFromBuffer+0x4e) [0x7f066f72b8be]
2020-04-04T08:18:12.896960+00:00 app[web.1]: [bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f06a8c3edae]
2020-04-04T08:18:12.896961+00:00 app[web.1]: [bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x22f) [0x7f06a8c3e71f]
2020-04-04T08:18:12.896961+00:00 app[web.1]: [bt] (5) /app/.heroku/python/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x4cd) [0x7f06a8e52e1d]
2020-04-04T08:18:12.896961+00:00 app[web.1]: [bt] (6) /app/.heroku/python/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x8ba7) [0x7f06a8e49ba7]
2020-04-04T08:18:12.896961+00:00 app[web.1]: [bt] (7) /app/.heroku/python/bin/python(_PyObject_FastCallDict+0xb3) [0x55d8fdde2bc3]
2020-04-04T08:18:12.896962+00:00 app[web.1]: [bt] (8) /app/.heroku/python/bin/python(+0x1890f0) [0x55d8fdedc0f0]
2020-04-04T08:18:12.896962+00:00 app[web.1]: 
2020-04-04T08:18:12.896966+00:00 app[web.1]: 
2020-04-04T08:18:12.897433+00:00 app[web.1]: [2020-04-04 08:18:12 +0000] [11] [INFO] Worker exiting (pid: 11)
2020-04-04T08:18:12.898007+00:00 app[web.1]: [2020-04-04 08:18:12 +0000] [10] [INFO] Worker exiting (pid: 10)
2020-04-04T08:18:13.038533+00:00 app[web.1]: Traceback (most recent call last):
2020-04-04T08:18:13.038540+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 209, in run
2020-04-04T08:18:13.038884+00:00 app[web.1]: self.sleep()
2020-04-04T08:18:13.038887+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 357, in sleep
2020-04-04T08:18:13.039274+00:00 app[web.1]: ready = select.select([self.PIPE[0]], [], [], 1.0)
2020-04-04T08:18:13.039295+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 242, in handle_chld
2020-04-04T08:18:13.039585+00:00 app[web.1]: self.reap_workers()
2020-04-04T08:18:13.039616+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 525, in reap_workers
2020-04-04T08:18:13.039988+00:00 app[web.1]: raise HaltServer(reason, self.WORKER_BOOT_ERROR)
2020-04-04T08:18:13.040026+00:00 app[web.1]: gunicorn.errors.HaltServer: &lt;HaltServer 'Worker failed to boot.' 3&gt;
2020-04-04T08:18:13.040027+00:00 app[web.1]: 
2020-04-04T08:18:13.040027+00:00 app[web.1]: During handling of the above exception, another exception occurred:
2020-04-04T08:18:13.040027+00:00 app[web.1]: 
2020-04-04T08:18:13.040028+00:00 app[web.1]: Traceback (most recent call last):
2020-04-04T08:18:13.040043+00:00 app[web.1]: File ""/app/.heroku/python/bin/gunicorn"", line 8, in &lt;module&gt;
2020-04-04T08:18:13.040152+00:00 app[web.1]: sys.exit(run())
2020-04-04T08:18:13.040154+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 58, in run
2020-04-04T08:18:13.040274+00:00 app[web.1]: WSGIApplication(""%(prog)s [OPTIONS] [APP_MODULE]"").run()
2020-04-04T08:18:13.040276+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 228, in run
2020-04-04T08:18:13.040433+00:00 app[web.1]: super().run()
2020-04-04T08:18:13.040435+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 72, in run
2020-04-04T08:18:13.040552+00:00 app[web.1]: Arbiter(self).run()
2020-04-04T08:18:13.040567+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 229, in run
2020-04-04T08:18:13.040777+00:00 app[web.1]: self.halt(reason=inst.reason, exit_status=inst.exit_status)
2020-04-04T08:18:13.040801+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 342, in halt
2020-04-04T08:18:13.041161+00:00 app[web.1]: self.stop()
2020-04-04T08:18:13.041180+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 393, in stop
2020-04-04T08:18:13.041558+00:00 app[web.1]: time.sleep(0.1)
2020-04-04T08:18:13.041578+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 242, in handle_chld
2020-04-04T08:18:13.041859+00:00 app[web.1]: self.reap_workers()
2020-04-04T08:18:13.041880+00:00 app[web.1]: File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 525, in reap_workers
2020-04-04T08:18:13.042432+00:00 app[web.1]: raise HaltServer(reason, self.WORKER_BOOT_ERROR)
2020-04-04T08:18:13.042469+00:00 app[web.1]: gunicorn.errors.HaltServer: &lt;HaltServer 'Worker failed to boot.' 3&gt;
2020-04-04T08:18:13.123367+00:00 heroku[web.1]: State changed from up to crashed
2020-04-04T08:18:27.000000+00:00 app[api]: Build succeeded
2020-04-04T08:20:32.245127+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covid19-risk.herokuapp.com request_id=a884e87f-799a-43ef-8ef3-17eb50f3a899 fwd=""69.209.23.53"" dyno= connect= service= status=503 bytes= protocol=https
2020-04-04T08:20:32.831232+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=covid19-risk.herokuapp.com request_id=bf0f70e0-890a-4809-b861-77efcf2d0d7c fwd=""69.209.23.53"" dyno= connect= service= status=503 bytes= protocol=https

</code></pre>

<p>I suspect this issue has something to do Heroku and my local machine using different versions of XGBoost so the pickle file didn't run properly. If that's the case, what other ways can I use a trained model in Flask? Thanks!</p>
"
60831307,"<p>I am using selenium to parse from </p>

<p><a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a></p>

<p>and doing as the following, I get attribute error and the table variable remains empty, what is the reason ?</p>

<p>I use Chrome 80. Are the tags right ?</p>

<blockquote>
  <p>AttributeError: 'NoneType' object has no attribute 'tbody'</p>
</blockquote>

<pre><code>from selenium import webdriver
import bs4
browser = webdriver.Chrome()

browser.get(""https://www.worldometers.info/coronavirus/"")
html = bs4.BeautifulSoup(browser.page_source, ""html.parser"") 
table = html.find(""table"",class_=""table table-bordered table-hover main_table_countries dataTable no-footer"") # 
</code></pre>
"
60840568,"<p>How do I deal with nan values in a table from a website that updates periodically and some table values sometimes get nan</p>

<p>I am talking about coronavirus website table of cases.
I am having problem in the for loop :this is the error</p>

<blockquote>
<pre><code>if '+' in table.loc[k,'NewCases'] and table.loc[k,'NewCases'] is not 'nan' :
</code></pre>
  
  <p>TypeError: argument of type 'float' is not iterable</p>
</blockquote>

<pre><code>import pandas as pd
import time
import re
from datetime import datetime
print(datetime.now())

import pandas as pd 

def dateformat(t):

    data = pd.DataFrame({'Date':[t]})

    data['Dates'] = pd.to_datetime(data['Date'], format='%Y:%M:%D').dt.date
    data['Hours'] = pd.to_datetime(data['Date'], format='%Y:%M:%D').dt.time
    return data['Dates'],data['Hours']
    return 
i=1
times=[],dates=[]
while True:

    t=datetime.now()
    date,hour= dateformat(t)
    times.append(hour)
    dates.append(date)
    url = 'https://www.worldometers.info/coronavirus/'
    table = pd.read_html(url)[1]
    row2ad=[];
    for k in table.index:

        if '+' in table.loc[k,'NewCases'] and table.loc[k,'NewCases'] is not 'nan' :
            c= table.loc[k,'NewCases']
    #        dfcycles.loc[k,'NewCases']=1e3*int(''.join(filter(str.isdigit, c)))
            c1=re.findall('\d*\.?\d+',c)
            table.loc[k,'NewCases']=float(c1[0])
            row2ad.append(table.loc[k,'NewCases'])
        elif table.loc[k,'NewCases'] is  'nan' and i==1:
            c= table.loc[k,'NewCases']

            table.loc[k,'NewCases']=0
            row2ad.append(table.loc[k,'NewCases'])

        elif table.loc[k,'NewCases'] is  'nan' and i!=1:



            time.sleep(600)
</code></pre>

<p>Apart from the above error: what I need to do is to get all the values in the table, remove the + from the numbers, also to keep the nan values that appear in some cells in some website updates, but I need to replace them with the previously exsisting value, but so far a good strategy did not come to my mind how this is possible in a dynamic update from the website</p>
"
61279808,"<p>I am trying to download a file automatically and save it. It is suppossed to be easy but I am founding some difficulties.</p>

<p>In theory is supposed to be easy <a href=""http://url%20="" rel=""nofollow noreferrer"" title=""https://www.gov.scot/binaries/content/documents/govscot/publications/statistics/2020/04/trends-in-number-of-people-in-hospital-with-confirmed-or-suspected-covid-19/documents/trends-in-number-of-people-in-hospital-with-confirmed-or-suspected-covid-19/trends-in-number-of-people-in-hospital-with-confirmed-or-suspected-covid-19/govscot%3Adocument/HSCA%2B-%2BSG%2BWebsite%2B-%2BIndicator%2BTrends%2Bfor%2Bdaily%2Bdata%2Bpublication.xlsx"">here</a>, you click automatically you download the file.</p>

<p>I have try different ways (as found in diffeent posts such as <a href=""https://stackoverflow.com/questions/25415405/downloading-an-excel-file-from-the-web-in-python"">here</a> or <a href=""https://stackoverflow.com/questions/44699682/how-to-save-a-file-downloaded-from-requests-to-another-directory"">enter link description here</a>). Here a couple of example of mhy current code:</p>

<p>Option A) </p>

<pre><code>url = ""https://www.gov.scot/binaries/content/documents/govscot/publications/statistics/2020/04/trends-in-number-of-people-in-hospital-with-confirmed-or-suspected-covid-19/documents/trends-in-number-of-people-in-hospital-with-confirmed-or-suspected-covid-19/trends-in-number-of-people-in-hospital-with-confirmed-or-suspected-covid-19/govscot%3Adocument/HSCA%2B-%2BSG%2BWebsite%2B-%2BIndicator%2BTrends%2Bfor%2Bdaily%2Bdata%2Bpublication.xlsx""

response = requests.get(url,stream=False)
with open(dowload_folder_name, 'wb') as out_file:
    shutil.copyfileobj(response.raw, out_file)
</code></pre>

<p>Option B)</p>

<pre><code>xl_df = pd.read_excel(url,
                       sheet_name='Table 5 - Testing',
                       skiprows=range(5),
                       skipfooter=0)
</code></pre>

<p>In both cases I just get</p>

<p><code>urllib.error.URLError: &lt;urlopen error [Errno 60] Operation timed out&gt;</code></p>

<p>Any suggestion, please?
Many thanks!</p>
"
61133607,"<p>I’m collecting tweets for research with python and package “TwitterAPI”. It worked well yesterday, but not today. I don’t know where I changed wrongfully today.</p>

<pre><code>tweets = api.request('tweets/search/30day/:covidsearch', {'query' : 'gook','fromDate': '202003090000','toDate': '202003100000'}) 
for t in tweets:
    print (t['text'])
</code></pre>

<p>and it returns:</p>

<pre><code>---------------------------------------------------------------------------
TwitterRequestError                       Traceback (most recent call last)
&lt;ipython-input-46-cf0d843438dd&gt; in &lt;module&gt;
----&gt; 1 for t in tweets:
      2     print (t['text'])

~/.local/lib/python3.6/site-packages/TwitterAPI/TwitterAPI.py in __iter__(self)
    218         :raises: TwitterConnectionError, TwitterRequestError
    219         """"""
--&gt; 220         return self.get_iterator()
    221 
    222     def get_quota(self):

~/.local/lib/python3.6/site-packages/TwitterAPI/TwitterAPI.py in get_iterator(self)
    205         """"""
    206         if self.response.status_code != 200:
--&gt; 207             raise TwitterRequestError(self.response.status_code)
    208 
    209         if self.stream:

TwitterRequestError: Twitter request failed (422)
</code></pre>

<p>anybody knows why? HELP!</p>
"
61431873,"<p>I'm trying to get Total Confirmed Cases for Global from <a href=""https://api.covid19api.com/summary"" rel=""nofollow noreferrer"">here</a> , but i get <code>TypeError: string indices must be integers</code> when i try to run this function:</p>

<pre><code>def getstats():
    api_url = urllib.request.urlopen('https://api.covid19api.com/summary')
    data = json.load(api_url)
    for item in data[""Global""]:
        print(item[""TotalConfirmed""])
</code></pre>
"
60704609,"<p>A friend and I wrote a Python app to plot the number of Covid-19 cases by country on a world map. </p>

<p>Here is our code:</p>

<pre><code>#!/usr/bin/env python3
# -*- coding: utf-8 -*-
""""""
Created on Sun Mar 15 17:01:50 2020

@author: sheldon
""""""

import os 
import pandas as pd
import folium
from folium import plugins
import rasterio as rio
from rasterio.warp import calculate_default_transform, reproject, Resampling
import earthpy as et
import pdb 
import flask
from flask import Flask




class CovidDF:
    def __init__(self, url):
        self.url = url
        self.raw = None
        self.aggregated = None

    def reload(self, date):
        self.raw = pd.read_csv(self.url)
        self.group_by_regions(date)

    def group_by_regions(self,date):
          df=self.raw[['Province/State','Country/Region','Lat','Long',date]]
          self.aggregated=df.groupby(['Country/Region']).agg({'Lat':'mean',
                              'Long':'mean',
                              date: 'sum'})
          self.aggregated.at['France','Lat']=46.2276
          self.aggregated.at['France','Long']=2.2137


class CovidData(object):

    def __init__(self):
        self.confirmed_cases = CovidDF('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv')
        self.deaths = CovidDF('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv')
        self.recoveries = CovidDF('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv')
        self.loaded = False
        self.map = folium.Map(location=[0,0],
              tiles = 'Stamen Terrain',
              zoom_start=2)

    def populate(self, date):
        if not self.loaded:
             self.confirmed_cases.reload(date)
             self.deaths.reload(date)
             self.recoveries.reload(date)
             self.loaded=True

    def plot_number_of_cases(self,df,date,custom_color):
          dc=df.iloc[df[date].to_numpy().nonzero()]
          latitude = dc.Lat.values.astype('float')
          longitude = dc.Long.values.astype('float')
          radius = dc[date].values.astype('float')

          for la,lo,ra in zip(latitude,longitude,radius):
              folium.Circle(
                  location=[la,lo],
                  radius=ra*10,
                  fill=True,
                  color=custom_color,
                  fill_color=custom_color,
                  fill_opacity=0.5
              ).add_to(self.map)

    def plot_number_of_cases_for_all_dataframes(self,date):
          self.plot_number_of_cases(self.confirmed_cases.aggregated,date,'blue')
          self.plot_number_of_cases(self.deaths.aggregated,date,'red')
          self.plot_number_of_cases(self.recoveries.aggregated,date,'green')




my_date='3/14/20'
covid_data=CovidData()
covid_data.populate(my_date)
covid_data.plot_number_of_cases_for_all_dataframes(my_date)
#covid_data.map.save(""./mytest.html"")

app = Flask(__name__)
@app.route(""/"")
def display_map():
     return covid_data.map._repr_html_()
</code></pre>

<p>The app builds fine on Heroku, but we are getting an application error when trying to open it.
Checking the logs yields the following error messages:</p>

<blockquote>
  <p>2020-03-16T10:37:49.600873+00:00 heroku[web.1]: Error R10 (Boot timeout) -> Web process failed to bind to $PORT within 60 seconds of launch</p>
  
  <p>2020-03-16T10:37:49.600972+00:00 heroku[web.1]: Stopping process with SIGKILL</p>
  
  <p>2020-03-16T10:37:49.697252+00:00 heroku[web.1]: Process exited with status 137</p>
  
  <p>2020-03-16T10:41:33.514461+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covid19-viz.herokuapp.com request_id=2e0727f9-d3eb-4966-8252-92a871deaa41 fwd=""77.150.72.89"" dyno= connect= service= status=503 bytes= protocol=https</p>
</blockquote>

<p>I have checked <a href=""https://stackoverflow.com/questions/22002440/heroku-app-crashes-immediately-with-r10-and-h10-errors"">this other post</a> and understand that the error is related to a port specification issue but I do not know how to fix it. Any help will be appreciated!</p>
"
61617952,"<p>I have been working on COVID19 analysis for a <a href=""https://covid19analysis.live"" rel=""nofollow noreferrer"">dashboard</a> and am using a JSON data source. I have converted the json to dataframe. I am working on plotting bar chart for ""Days to reach  deaths"" over a ""States"" x-axis (categorical values). I am trying to use a function to update the slider.value. Upon running the bokeh serve with --log-level=DEBUG, I am getting a following error:</p>

<p><a href=""https://i.stack.imgur.com/Ll1uN.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ll1uN.png"" alt=""enter image description here""></a></p>

<p>Can someone provide me with any direction or help with what might be causing the issue as I am new to Python and any help is appreciated? Or if there's any other alternative.</p>

<p>Please find the code below:</p>

<pre><code>cases_summary = requests.get('https://api.rootnet.in/covid19-in/stats/history')

json_data = cases_summary.json()

#Data Cleaning
cases_summary=pd.json_normalize(json_data['data'], record_path='regional', meta='day')

cases_summary['loc']=np.where(cases_summary['loc']=='Nagaland#', 'Nagaland', cases_summary['loc'])
cases_summary['loc']=np.where(cases_summary['loc']=='Madhya Pradesh#', 'Madhya Pradesh', cases_summary['loc'])
cases_summary['loc']=np.where(cases_summary['loc']=='Jharkhand#', 'Jharkhand', cases_summary['loc'])

#Calculate cumulative days since 1st case for each state
cases_summary['day_count']=(cases_summary['day'].groupby(cases_summary['loc']).cumcount())+1

#Initial plot for default slider value=35 
days_reach_death_count=cases_summary.loc[(cases_summary['deaths']&gt;=35)].groupby(cases_summary['loc']).head(1).reset_index()

slider = Slider(start=10, end=max(cases_summary['deaths']), value=35, step=10, title=""Total Deaths"")

source = ColumnDataSource(data=dict(days_reach_death_count[['loc','day_count', 'deaths']]))

q = figure(x_range=days_reach_death_count['loc'], plot_width=1200, plot_height=600, sizing_mode=""scale_both"")


q.title.align = 'center'
q.title.text_font_size = '17px'
q.xaxis.axis_label = 'State'
q.yaxis.axis_label = 'Days since 1st Case'
q.xaxis.major_label_orientation = math.pi/2

q.vbar('loc', top='day_count', width=0.9, source=source)

deaths = slider.value
q.title.text = 'Days to reach %d Deaths' % deaths

hover = HoverTool(line_policy='next')
hover.tooltips = [('State', '@loc'),
                  ('Days since 1st Case', '@day_count'),  # @$name gives the value corresponding to the legend
                  ('Deaths', '@deaths')
                  ]
q.add_tools(hover)

def update(attr, old, new):
    days_death_count = cases_summary.loc[(cases_summary['deaths'] &gt;= slider.value)].groupby(cases_summary['loc']).head(1).reindex()
    source.data = [ColumnDataSource().from_df(days_death_count)]

slider.on_change('value', update)

layout = row(q, slider)
tab = Panel(child=layout, title=""New Confirmed Cases since Day 1"")
tabs= Tabs(tabs=[tab])

curdoc().add_root(tabs)

</code></pre>
"
61227932,"<p>The goal is to test creating a new custom user using <a href=""https://www.django-rest-framework.org/api-guide/testing/#api-test-cases"" rel=""nofollow noreferrer"">APITestCase</a>.</p>

<p>In models.py got two new classes inheriting from <a href=""https://docs.djangoproject.com/en/3.0/topics/auth/customizing/#django.contrib.auth.models.AbstractBaseUser"" rel=""nofollow noreferrer"">AbstractBaseUser</a> and <a href=""https://docs.djangoproject.com/en/3.0/topics/auth/customizing/#django.contrib.auth.models.BaseUserManager"" rel=""nofollow noreferrer"">BaseUserManager</a>, respectively</p>

<pre><code>class MyUser(AbstractBaseUser):
    objects = MyUserManager()
    class Meta:
        db_table = 'user_entity'

    user_id = models.AutoField(primary_key=True)
    #username = models.CharField(max_length=USERNAME_MAX_LENGTH, unique=True, validators=[validators.validate_username])
    username = models.CharField(max_length=20, unique=True)
    password = models.CharField(max_length=256)
    first_name = models.CharField(max_length=25)
    last_name = models.CharField(max_length=25)
    email = models.EmailField(verbose_name='email', max_length=100, unique=True)
    last_access = models.DateField(default=datetime.date.today)
    creation_date = models.DateTimeField(default=timezone.now)
    last_update = models.DateField(default=datetime.date.today)
    user_type = models.IntegerField()
    is_staff = models.BooleanField(default=False)
    is_active = models.BooleanField(default=True)

    USERNAME_FIELD = 'email'
    EMAIL_FIELD = 'email'
    REQUIRED_FIELDS = ['username', 'first_name', 'last_name', 'user_type']

    def __str__(self):
        return str(self.user_id) + "" (%s)"" % str(self.email)

    def has_perm(self, perm, obj=None):
        return self.user_type == 0

    def has_module_perms(self, app_label):
        return True
</code></pre>

<p>and</p>

<pre><code>class MyUserManager(BaseUserManager):
    def _create_generic_user(self, email, username, password, first_name, last_name, user_type):
        if not username:
            raise ValueError(""Username cannot be empty"")
        if not email:
            raise ValueError(""Email cannot be empty"")
        if not first_name:
            raise ValueError(""First name cannot be empty"")
        if not last_name:
            raise ValueError(""Last name cannot be empty"")
        if not password:
            raise ValueError(""Password cannot be empty"")

        user = self.model(
            username=username,
            first_name=first_name,
            last_name=last_name,
            email=self.normalize_email(email),
            user_type=user_type,
            is_staff=user_type == 0,
            is_active=False
        )
        user.set_password(password)
        user.save(user=self._db)
        return user

    def create_user(self, email, username, password, first_name, last_name):
        return self._create_generic_user(email, username, password, first_name, last_name, 2)

    def create_admin(self, email, username, password, first_name, last_name):
        return self._create_generic_user(email, username, password, first_name, last_name, 0)
</code></pre>

<p>Then, in serializers.py created a MyUserSerializer for DRF inheriting from a <a href=""https://www.django-rest-framework.org/api-guide/serializers/#modelserializer"" rel=""nofollow noreferrer"">ModelSerializer</a></p>

<pre><code>class MyUserSerializer(serializers.ModelSerializer):
    email = serializers.EmailField(
            required=True, # make sure email is provided
            validators=[UniqueValidator(queryset=MyUser.objects.all())] # make sure email is unique
            )
    username = serializers.CharField(
            required=True,
            validators=[UniqueValidator(queryset=MyUser.objects.all())],
            min_length=5,
            max_length=20
            )
    password = serializers.CharField(
            write_only=True,
            required=True,
            max_length=256
            )
    first_name = serializers.CharField(
            required=True,
            max_length=25
            )
    last_name = serializers.CharField(
            required=True,
            max_length=25
            )

    def create(self, validated_data):
        user = MyUser.objects.create_user(validated_data['email'], validated_data['username'], validated_data['password'],
        validated_data['first_name'], validated_data['last_name'])
        return user


    class Meta:
        model = MyUser
        fields = ('user_id', 'email', 'username', 'password', 'first_name', 'last_name')
</code></pre>

<p>a view with APIView</p>

<pre><code>class MyUserCreate(APIView):
    """""" 
    Creates the user. 
    """"""

    def post(self, request, format='json'):
        serializer = MyUserSerializer(data=request.data)
        if serializer.is_valid():
            user = serializer.save()
            if user:
                return Response(serializer.data, status=status.HTTP_201_CREATED)
</code></pre>

<p>and urls</p>

<pre><code>urlpatterns = [
    url(r'api/users^$', views.MyUserCreate.as_view(), name='user-create'),
]
</code></pre>

<p>From this, then went on to create a simple test of creating users</p>

<pre><code>class MyUserTest(APITestCase):
    def setUp(self):
        # Create a user
        self.test_user = MyUser.objects.create_user('tiagomartinsperes@gmail.com', 'tiagoperes', 'EWFdfew45te!sadf32', 'Tiago', 'Peres')

        # URL for creating user
        self.create_url = reverse('user-create')

    def test_create_user(self):
        """"""
        Ensure we can create a new user and a valid token is created with it.
        """"""
        data = {
            'email': 'cnf32344@zzrgg.com',
            'username': 'andresantos',
            'password': 'test',
            'first_name': 'André',
            'last_name': 'Santos'
        }

        response = self.client.post(self.create_url , data, format='json')

        # Make sure we have two users in the database
        self.assertEqual(MyUser.objects.count(), 2)
        # Return 201
        self.assertEqual(response.status_code, status.HTTP_201_CREATED)
        # Return the username and email upon successful creation
        self.assertEqual(response.data['email'], data['email'])
        self.assertEqual(response.data['username'], data['username'])
        self.assertFalse('password' in response.data)
        self.assertEqual(response.data['first_name'], data['first_name'])
        self.assertEqual(response.data['last_name'], data['last_name'])
</code></pre>

<p>Thing is, running</p>

<pre><code>python manage.py test
</code></pre>

<p>gets the following error:</p>

<blockquote>
  <p>Creating test database for alias 'default'... System check identified
  no issues (0 silenced). E
  ====================================================================== ERROR: test_create_user (user.tests.MyUserTest) Ensure we can create a
  new user and a valid token is created with it.
  ---------------------------------------------------------------------- Traceback (most recent call last):   File
  ""C:\Users\tiago\Desktop\letsgo\COVID19-be\django_server\user\tests.py"",
  line 10, in setUp
      self.test_user = MyUser.objects.create_user('tiagomartinsperes@gmail.com',
  'tiagoperes', 'EWFdfew45te!sadf32', 'Tiago', 'Peres')   File
  ""C:\Users\tiago\Desktop\letsgo\COVID19-be\django_server\user\models.py"",
  line 38, in create_user
      return self._create_generic_user(email, username, password, first_name, last_name, 2)   File
  ""C:\Users\tiago\Desktop\letsgo\COVID19-be\django_server\user\models.py"",
  line 34, in _create_generic_user
      user.save(user=self._db)   File ""C:\Users\tiago\Desktop\letsgo\unstable\lib\site-packages\django\contrib\auth\base_user.py"",
  line 66, in save
      super().save(*args, **kwargs) TypeError: save() got an unexpected keyword argument 'user'</p>
  
  <p>---------------------------------------------------------------------- Ran 1 test in 0.172s</p>
  
  <p>FAILED (errors=1) Destroying test database for alias 'default'...</p>
</blockquote>

<p>and no users are being created. What can I do to solve it?</p>
"
61259677,"<p>I am using the Folium package to build a ""Choropleth"" map with python. The data that is displayed is pulled from an API that keeps track of the most recent Covid-19 infected rates per country. A column shared between the countries.geojson file (a json file of a world map) and the data that I pulled is the name of the country. Most of the countries are shaded in with color (successfully), while some of the countries are not identical and therefore is shaded with grey, for example ""US"" in the pandas dataframe and ""United States of America"" in the .geojson file doesnt match, and therefore doesn't display their data on the map.</p>

<pre><code>covid_data = requests.get('https://covid2019-api.herokuapp.com/v2/current')
covid_data = covid_data.json()
covid_data = pd.DataFrame.from_dict(covid_data['data'])
</code></pre>

<pre><code>location  confirmed  deaths  recovered  active
US     636350   28326      52096  555928
Spain     177644   18708      70853   88083
</code></pre>

<p>The way I'm storing the API data is within a pandas DataFrame, because it works best with Folium. My hacky way of transforming the data from the country names that arent identical is with the code:
<code>covid_data.location[covid_data.location=='US'] = 'United States of America'</code></p>

<p>By doing this, the country name is now the same on both the .geojson file and the DataFrame</p>

<pre><code>location  confirmed  deaths  recovered  active
United States of America     636350   28326      52096  555928
Spain     177644   18708      70853   88083
</code></pre>

<p>is now the same as</p>

<pre><code>{ ""type"": ""Feature"", ""properties"": { ""ADMIN"": ""United States of America"", ""ISO_A3"": ""USA""} ""geometry"": {}}     (countries.geojson)
</code></pre>

<p>Before editing the dataframe, the map was rendered, but when US is changed to United States of America, it throws an error</p>

<blockquote>
  <p>return color_range[color_idx], fill_opacity
      IndexError: list index out of range</p>
</blockquote>

<p>So that means that im setting the Choropleth threshold_scale to 636,360 (which is the highest # in the 'confirmed' column) but theres no data to match that # to. Therefore if I change the threshold_scale down to the next highest number, 177,644 (which is Italy) I get the error</p>

<blockquote>
  <p>ValueError: All values are expected to fall into one of the provided bins (or to be Nan). Please check > the <code>bins</code> parameter and/or your data.</p>
</blockquote>

<p>Heres the rest of the code to help resolve this issue,</p>

<pre><code>#this variable is to get the highest value of the rates as the max threshold used for coloring
covid_data_max = covid_data['confirmed'].max()
covid_data_max = covid_data_max.item()
world_geo = r'countries.geojson'
world_map = folium.Map(location=[4.68, 8.33],
                    tiles='Mapbox Bright', zoom_start=3)
world_map = folium.Choropleth(
    geo_data=world_geo,
    name='choropleth',
    data=covid_data,
    columns=['location','confirmed'],
    key_on='properties.ADMIN',
    threshold_scale = [0,int((covid_data_max/15)),int((covid_data_max/10)),int((covid_data_max/4)),covid_data_max],
    fill_color='BuPu',
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name='Number of deaths per country',
    highlight=True,
    line_color='black'
    ).add_to(world_map)

folium.LayerControl().add_to(world_map)
world_map.save(r'./templates/map.html')
</code></pre>

<p>You can see the image of the map (for some reason the threshold includes the USA #'s):</p>

<p><a href=""https://i.stack.imgur.com/HunO0.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HunO0.png"" alt=""enter image description here""></a></p>

<p>Let me know if theres anything else I can provide!</p>
"
61469188,"<p>Title may not be clear, but here is the scenario:</p>

<ul>
<li>I have a pre-trained model,</li>
<li>I am packaging everything to act as a service with a listener that will get CloudEvents (to simplify: messages) that give the name of an image to analyze,</li>
<li>As the model is quite heavy (>1GB), I want to load it at initialization and make predictions as events come in.</li>
</ul>

<p>Here is a simplified code:</p>

<pre><code>import http.server
import io
import json
import logging
import socketserver
import sys

import cv2
import numpy as np
import tensorflow as tf

from cloudevents.sdk import marshaller
from cloudevents.sdk.event import v02

# Set logging
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)


mapping = {'normal': 0, 'pneumonia': 1, 'COVID-19': 2}
inv_mapping = {0: 'normal', 1: 'pneumonia', 2: 'COVID-19'}

meta_url = './COVIDNet-CXR-Large/model.meta'
ckpt_url = './COVIDNet-CXR-Large/model-8485'


# Events listener
m = marshaller.NewDefaultHTTPMarshaller()

class ForkedHTTPServer(socketserver.ForkingMixIn, http.server.HTTPServer):
    """"""Handle requests with fork.""""""


class CloudeventsServer(object):
    """"""Listen for incoming HTTP cloudevents requests.
    cloudevents request is simply a HTTP Post request following a well-defined
    of how to pass the event data.
    """"""
    def __init__(self, port=8888):
        self.port = port

    def start_receiver(self, func):
        """"""Start listening to HTTP requests
        :param func: the callback to call upon a cloudevents request
        :type func: cloudevent -&gt; none
        """"""
        class BaseHttp(http.server.BaseHTTPRequestHandler):
            def do_POST(self):
                logging.info('POST received')
                content_type = self.headers.get('Content-Type')
                content_len = int(self.headers.get('Content-Length'))
                headers = dict(self.headers)
                data = self.rfile.read(content_len)
                data = data.decode('utf-8')
                logging.info(content_type)
                logging.info(data)

                if content_type != 'application/json':
                    logging.info('Not JSON')
                    data = io.StringIO(data)

                try:
                    event = v02.Event()
                    event = m.FromRequest(event, headers, data, json.loads)
                except Exception as e:
                    logging.error(f""Event error: {e}"")
                    raise   

                logging.info(event)

                # Send ack first to free connection
                self.send_response(204)
                self.end_headers()

                func(event)

                return

        socketserver.TCPServer.allow_reuse_address = True
        with ForkedHTTPServer(("""", self.port), BaseHttp) as httpd:
            try:
                logging.info(""serving at port {}"".format(self.port))
                httpd.serve_forever()
            except:
                httpd.server_close()
                raise

class Model(object):

    def __init__(self,meta_url,ckpt_url):
        self.sess = tf.Session()
        tf.get_default_graph()

        saver = tf.train.import_meta_graph(meta_url)
        saver.restore(self.sess,ckpt_url)

        graph = tf.compat.v1.get_default_graph()

        self.image_tensor = graph.get_tensor_by_name(""input_1:0"")
        self.pred_tensor = graph.get_tensor_by_name(""dense_3/Softmax:0"")


    def prediction(self,key):
        logging.info('start prediction')

        x = cv2.imread(key)

        h, w, c = x.shape
        x = x[int(h/6):, :]
        x = cv2.resize(x, (224, 224))
        x = x.astype('float32') / 255.0

        # Make prediction
        logging.info('make prediction')
        pred = self.sess.run(self.pred_tensor, feed_dict={self.image_tensor: np.expand_dims(x, axis=0)})
        logging.info('prediction made')
        # Format data
        data = {'prediction':inv_mapping[pred.argmax(axis=1)[0]],'confidence':'Normal: {:.3f}, Pneumonia: {:.3f}, COVID-19: {:.3f}'.format(pred[0][0], pred[0][1], pred[0][2])}
        logging.info(data)

        return data

# Extract data from incoming event
def extract_data(msg):
    return msg['data']

# Run this when a new event has been received
def run_event(event):
    logging.info(event.Data())

    # Retrieve info from notification
    extracted_data = extract_data(event.Data())
    uid = extracted_data['uid']
    img_key = extracted_data['image_name']
    logging.info('Analyzing: ' + img_key + ' for uid: ' + uid)


    # Make prediction
    result = model.prediction(img_key)

    logging.info('result=' + result['prediction'])

# Load model
model = Model(meta_url,ckpt_url)
logging.info('model initialized')

# Start event listener
client = CloudeventsServer()
client.start_receiver(run_event)
#result = model.prediction('1-s2.0-S0140673620303706-fx1_lrg.jpg')
</code></pre>

<p>What works:</p>

<ul>
<li>At start the model is loaded,</li>
<li>The event listener/parser works, I can retrieve the values coming in,</li>
<li>If I directly make a prediction (last line, commented) without starting the listener (or make it before starting the listener) it works. Proof that the model is well loaded (yeah!).</li>
</ul>

<p>What does not work:</p>

<ul>
<li>When trying to call the model instance from the function invoked by the listener (which works, as it gets to the prediction function), I get:</li>
</ul>

<pre><code>terminate called after throwing an instance of 'std::system_error'
  what():  No such process
</code></pre>

<p>So it seems that the Model instance is there (because the prediction function is launched) but that I kind of lose the tf session in the listener->run_event->prediction pipeline... At least that's what I understand.</p>

<p>What am I missing? Is there a better way to do this?</p>
"
60912984,"<p>I am attempting to get the table appearing in <a href=""https://covid19.isciii.es/"" rel=""nofollow noreferrer"">https://covid19.isciii.es/</a> using bs4 + Python3.</p>

<p><img src=""https://i.stack.imgur.com/HXZAr.png"" alt=""table to be extracted""></p>

<p>When I inspect the values with my browser, the website shows up the same values</p>

<p><img src=""https://i.stack.imgur.com/cEMNo.png"" alt=""inspect table""></p>

<p>But the code shows me up different values [i.e., (71,0,0) for Andalucia instead of the current one (4682,405,50.45) ]</p>

<pre><code>url_base = 'https://covid19.isciii.es/'
response = get(url_base)
print(response)
if response.status_code == 200:
    html_soup = BeautifulSoup(get(url_base).text, 'html.parser').findAll(""td"")
    print(html_soup) 
</code></pre>

<p><img src=""https://i.stack.imgur.com/EEf3G.png"" alt=""execution result""></p>

<p>Why is this happening? How can I solve this with bs4?</p>

<p>Thanks in advance</p>
"
60763498,"<p>I have installed NLTK and TextBlob on Python3 on WSL. No matter what I do, I always obtain the same error. Indeed, trying to install shows that all packages are installed</p>

<pre><code>$ sudo pip3 install -U textblob
The directory '/home/jlchulilla/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
The directory '/home/jlchulilla/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.
Requirement already up-to-date: textblob in /usr/local/lib/python3.6/dist-packages
Requirement already up-to-date: nltk&gt;=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob)
Requirement already up-to-date: six in /usr/local/lib/python3.6/dist-packages (from nltk&gt;=3.1-&gt;textblob)
</code></pre>

<p>But when I try to update corpora or use <code>from textblob import TextBlob</code>, this is the error message:</p>

<pre><code>$ python3 -m textblob.download_corpora
Traceback (most recent call last):
  File ""/usr/lib/python3.6/subprocess.py"", line 140, in &lt;module&gt;
    import threading
  File ""/usr/lib/python3.6/threading.py"", line 7, in &lt;module&gt;
    from traceback import format_exc as _format_exc
  File ""/usr/lib/python3.6/traceback.py"", line 5, in &lt;module&gt;
    import linecache
  File ""/usr/lib/python3.6/linecache.py"", line 11, in &lt;module&gt;
    import tokenize
  File ""/mnt/c/Users/jlchu/Dropbox/oando/COVID-19/Supermercados online y covid_csv/prácticas NLTK/tokenize.py"", line 1, in &lt;module&gt;
    from textblob import textblob
ImportError: cannot import name 'textblob'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.6/runpy.py"", line 183, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File ""/usr/lib/python3.6/runpy.py"", line 109, in _get_module_details
    __import__(pkg_name)
  File ""/usr/local/lib/python3.6/dist-packages/textblob/__init__.py"", line 2, in &lt;module&gt;
    from .blob import TextBlob, Word, Sentence, Blobber, WordList
  File ""/usr/local/lib/python3.6/dist-packages/textblob/blob.py"", line 28, in &lt;module&gt;
    import nltk
  File ""/usr/local/lib/python3.6/dist-packages/nltk/__init__.py"", line 99, in &lt;module&gt;
    from nltk.internals import config_java
  File ""/usr/local/lib/python3.6/dist-packages/nltk/internals.py"", line 11, in &lt;module&gt;
    import subprocess
  File ""/usr/lib/python3.6/subprocess.py"", line 142, in &lt;module&gt;
    import dummy_threading as threading
  File ""/usr/lib/python3.6/dummy_threading.py"", line 45, in &lt;module&gt;
    import threading
  File ""/usr/lib/python3.6/threading.py"", line 7, in &lt;module&gt;
    from traceback import format_exc as _format_exc
  File ""/usr/lib/python3.6/traceback.py"", line 5, in &lt;module&gt;
    import linecache
  File ""/usr/lib/python3.6/linecache.py"", line 11, in &lt;module&gt;
    import tokenize
  File ""/mnt/c/Users/jlchu/Dropbox/oando/COVID-19/Supermercados online y covid_csv/prácticas NLTK/tokenize.py"", line 1, in &lt;module&gt;     
    from textblob import textblob
ImportError: cannot import name 'textblob'
Error in sys.excepthook:
Traceback (most recent call last):
  File ""/usr/lib/python3.6/subprocess.py"", line 140, in &lt;module&gt;
    import threading
  File ""/usr/lib/python3.6/threading.py"", line 7, in &lt;module&gt;
    from traceback import format_exc as _format_exc
ImportError: cannot import name 'format_exc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3/dist-packages/apport_python_hook.py"", line 62, in apport_excepthook
    import re, traceback
  File ""/usr/lib/python3.6/traceback.py"", line 5, in &lt;module&gt;
    import linecache
  File ""/usr/lib/python3.6/linecache.py"", line 11, in &lt;module&gt;
    import tokenize
  File ""/mnt/c/Users/jlchu/Dropbox/oando/COVID-19/Supermercados online y covid_csv/prácticas NLTK/tokenize.py"", line 1, in &lt;module&gt;     
    from textblob import textblob
  File ""/usr/local/lib/python3.6/dist-packages/textblob/__init__.py"", line 2, in &lt;module&gt;
    from .blob import TextBlob, Word, Sentence, Blobber, WordList
  File ""/usr/local/lib/python3.6/dist-packages/textblob/blob.py"", line 28, in &lt;module&gt;
    import nltk
  File ""/usr/local/lib/python3.6/dist-packages/nltk/__init__.py"", line 99, in &lt;module&gt;
    from nltk.internals import config_java
  File ""/usr/local/lib/python3.6/dist-packages/nltk/internals.py"", line 11, in &lt;module&gt;
    import subprocess
  File ""/usr/lib/python3.6/subprocess.py"", line 142, in &lt;module&gt;
    import dummy_threading as threading
  File ""/usr/lib/python3.6/dummy_threading.py"", line 45, in &lt;module&gt;
    import threading
  File ""/usr/lib/python3.6/threading.py"", line 7, in &lt;module&gt;
    from traceback import format_exc as _format_exc
ImportError: cannot import name 'format_exc'

Original exception was:
Traceback (most recent call last):
  File ""/usr/lib/python3.6/subprocess.py"", line 140, in &lt;module&gt;
    import threading
  File ""/usr/lib/python3.6/threading.py"", line 7, in &lt;module&gt;
    from traceback import format_exc as _format_exc
  File ""/usr/lib/python3.6/traceback.py"", line 5, in &lt;module&gt;
    import linecache
  File ""/usr/lib/python3.6/linecache.py"", line 11, in &lt;module&gt;
    import tokenize
  File ""/mnt/c/Users/jlchu/Dropbox/oando/COVID-19/Supermercados online y covid_csv/prácticas NLTK/tokenize.py"", line 1, in &lt;module&gt;     
    from textblob import textblob
ImportError: cannot import name 'textblob'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.6/runpy.py"", line 183, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File ""/usr/lib/python3.6/runpy.py"", line 109, in _get_module_details
    __import__(pkg_name)
  File ""/usr/local/lib/python3.6/dist-packages/textblob/__init__.py"", line 2, in &lt;module&gt;
    from .blob import TextBlob, Word, Sentence, Blobber, WordList
  File ""/usr/local/lib/python3.6/dist-packages/textblob/blob.py"", line 28, in &lt;module&gt;
    import nltk
  File ""/usr/local/lib/python3.6/dist-packages/nltk/__init__.py"", line 99, in &lt;module&gt;
    from nltk.internals import config_java
  File ""/usr/local/lib/python3.6/dist-packages/nltk/internals.py"", line 11, in &lt;module&gt;
    import subprocess
  File ""/usr/lib/python3.6/subprocess.py"", line 142, in &lt;module&gt;
    import dummy_threading as threading
  File ""/usr/lib/python3.6/dummy_threading.py"", line 45, in &lt;module&gt;
    import threading
  File ""/usr/lib/python3.6/threading.py"", line 7, in &lt;module&gt;
    from traceback import format_exc as _format_exc
  File ""/usr/lib/python3.6/traceback.py"", line 5, in &lt;module&gt;
    import linecache
  File ""/usr/lib/python3.6/linecache.py"", line 11, in &lt;module&gt;
    import tokenize
  File ""/mnt/c/Users/jlchu/Dropbox/oando/COVID-19/Supermercados online y covid_csv/prácticas NLTK/tokenize.py"", line 1, in &lt;module&gt;     
    from textblob import textblob
ImportError: cannot import name 'textblob'
</code></pre>

<p>I cannot understand where is the problem. Any help would be really appreciated</p>

<p>Edit: When I try to import any other module of NLTK library, same error happens. It's like if previous calling to 'tokenize' would have blocked the module or something</p>

<pre><code>$ python3
Python 3.6.7 (default, Oct 22 2018, 11:32:17) 
[GCC 8.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
&gt;&gt;&gt; from nltk.stem.porter import PorterStemmer
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/usr/local/lib/python3.6/dist-packages/nltk/__init__.py"", line 99, in &lt;module&gt;
    from nltk.internals import config_java
  File ""/usr/local/lib/python3.6/dist-packages/nltk/internals.py"", line 11, in &lt;module&gt;
    import subprocess
  File ""/usr/lib/python3.6/subprocess.py"", line 140, in &lt;module&gt;
    import threading
  File ""/usr/lib/python3.6/threading.py"", line 7, in &lt;module&gt;
    from traceback import format_exc as _format_exc
  File ""/usr/lib/python3.6/traceback.py"", line 5, in &lt;module&gt;
    import linecache
  File ""/usr/lib/python3.6/linecache.py"", line 11, in &lt;module&gt;
    import tokenize
  File ""/mnt/c/Users/jlchu/Dropbox/oando/COVID-19/Supermercados online y covid_csv/prácticas NLTK/tokenize.py"", line 1, in &lt;module&gt;
    from textblob import TextBlob
  File ""/usr/local/lib/python3.6/dist-packages/textblob/__init__.py"", line 2, in &lt;module&gt;
    from .blob import TextBlob, Word, Sentence, Blobber, WordList
  File ""/usr/local/lib/python3.6/dist-packages/textblob/blob.py"", line 35, in &lt;module&gt;
    from textblob.base import (BaseNPExtractor, BaseTagger, BaseTokenizer,
  File ""/usr/local/lib/python3.6/dist-packages/textblob/base.py"", line 44, in &lt;module&gt;
    class BaseTokenizer(with_metaclass(ABCMeta), nltk.tokenize.api.TokenizerI):
AttributeError: module 'nltk' has no attribute 'tokenize'
Error in sys.excepthook:
Traceback (most recent call last):
  File ""/usr/lib/python3.6/subprocess.py"", line 140, in &lt;module&gt;
    import threading
  File ""/usr/lib/python3.6/threading.py"", line 7, in &lt;module&gt;
    from traceback import format_exc as _format_exc
ImportError: cannot import name 'format_exc'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3/dist-packages/apport_python_hook.py"", line 62, in apport_excepthook
    import re, traceback
  File ""/usr/lib/python3.6/traceback.py"", line 5, in &lt;module&gt;
    import linecache
  File ""/usr/lib/python3.6/linecache.py"", line 11, in &lt;module&gt;
    import tokenize
  File ""/mnt/c/Users/jlchu/Dropbox/oando/COVID-19/Supermercados online y covid_csv/prácticas NLTK/tokenize.py"", line 1, in &lt;module&gt;     
    from textblob import TextBlob
  File ""/usr/local/lib/python3.6/dist-packages/textblob/__init__.py"", line 2, in &lt;module&gt;
    from .blob import TextBlob, Word, Sentence, Blobber, WordList
  File ""/usr/local/lib/python3.6/dist-packages/textblob/blob.py"", line 28, in &lt;module&gt;
    import nltk
  File ""/usr/local/lib/python3.6/dist-packages/nltk/__init__.py"", line 99, in &lt;module&gt;
    from nltk.internals import config_java
  File ""/usr/local/lib/python3.6/dist-packages/nltk/internals.py"", line 11, in &lt;module&gt;
    import subprocess
  File ""/usr/lib/python3.6/subprocess.py"", line 142, in &lt;module&gt;
    import dummy_threading as threading
  File ""/usr/lib/python3.6/dummy_threading.py"", line 45, in &lt;module&gt;
    import threading
  File ""/usr/lib/python3.6/threading.py"", line 7, in &lt;module&gt;
    from traceback import format_exc as _format_exc
ImportError: cannot import name 'format_exc'

Original exception was:
Traceback (most recent call last):
  File ""&lt;stdin&gt;"", line 1, in &lt;module&gt;
  File ""/usr/local/lib/python3.6/dist-packages/nltk/__init__.py"", line 99, in &lt;module&gt;
    from nltk.internals import config_java
  File ""/usr/local/lib/python3.6/dist-packages/nltk/internals.py"", line 11, in &lt;module&gt;
    import subprocess
  File ""/usr/lib/python3.6/subprocess.py"", line 140, in &lt;module&gt;
    import threading
  File ""/usr/lib/python3.6/threading.py"", line 7, in &lt;module&gt;
    from traceback import format_exc as _format_exc
  File ""/usr/lib/python3.6/traceback.py"", line 5, in &lt;module&gt;
    import linecache
  File ""/usr/lib/python3.6/linecache.py"", line 11, in &lt;module&gt;
    import tokenize
  File ""/mnt/c/Users/jlchu/Dropbox/oando/COVID-19/Supermercados online y covid_csv/prácticas NLTK/tokenize.py"", line 1, in &lt;module&gt;     
    from textblob import TextBlob
  File ""/usr/local/lib/python3.6/dist-packages/textblob/__init__.py"", line 2, in &lt;module&gt;
    from .blob import TextBlob, Word, Sentence, Blobber, WordList
  File ""/usr/local/lib/python3.6/dist-packages/textblob/blob.py"", line 35, in &lt;module&gt;
    from textblob.base import (BaseNPExtractor, BaseTagger, BaseTokenizer,
  File ""/usr/local/lib/python3.6/dist-packages/textblob/base.py"", line 44, in &lt;module&gt;
    class BaseTokenizer(with_metaclass(ABCMeta), nltk.tokenize.api.TokenizerI):
AttributeError: module 'nltk' has no attribute 'tokenize'
</code></pre>
"
61016616,"<p>I have a python script I created to get data from Github and import it into a Sqlite database, which works well. I now want to modify the script to import the data into a SQL Server Express database that is local on my machine and using Windows Authentication for the username/password. Here is the relevant script:</p>

<pre><code>import sqlalchemy as sa
import pyobdc

conn = sa.create_engine('mssql+pyobdc://@localhost\\SQLEXPRESS/COVID19?trusted_connection=yes&amp;driver=ODBC+Driver+13+for+SQL+Server')
cur = conn.cursor()
</code></pre>

<p>When I run this, I get the following message:</p>

<blockquote>
  <p>Traceback (most recent call last):   File ""COVIDtoDB.py"", line 4, in
  
      import pyobdc ModuleNotFoundError: No module named 'pyobdc'</p>
</blockquote>

<p>I've done much searching on the Internet and have tried many different things to resolve this, including:</p>

<ul>
<li>updating Python to 3.8.2</li>
<li>verifying only one version of Python is installed</li>
<li>adding Python location to PATH variable</li>
<li>verifying that pyodbc is installed in the same location as Python</li>
<li>verifying that pyodbc is the latest version</li>
</ul>

<p>I thought perhaps it was due to how I constructed my connection string. I would appreciate it if someone would review it to see if it's correct.</p>

<p>If the connection string is correct, any other thoughts on what I should try to fix this problem?</p>

<p>Thanks!</p>
"
61432045,"<p>I successfully got layers to work in faceted charts and rolling average to work in layered charts. I now want to sort of combine the two i.e have a rolling average in a layered faceted chart. </p>

<p>Intuitively combining the two gives me an error -</p>

<pre><code>Javascript Error: Cannot read property 'concat' of undefined
This usually means there's a typo in your chart specification. See the javascript console for the full traceback.
</code></pre>

<p><strong>Code</strong> (gives the above error):</p>

<pre class=""lang-py prettyprint-override""><code># Data Preparation
df = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')
idf = df[df['Country/Region'] == 'India']
idf = idf[df.columns[4:]]
idf = idf.T
idf = idf.reset_index()
idf.columns = ['day', 'case']
idf['country'] = 'india'

gdf = df[df['Country/Region'] == 'Germany']
gdf = gdf[df.columns[4:]]
gdf = gdf.T
gdf = gdf.reset_index()
gdf.columns = ['day', 'case']
gdf['country'] = 'germany'

fdf = pd.concat([idf,gdf])

# Charting
a = alt.Chart().mark_bar(opacity=0.5).encode(
    x='day:T',
    y='case:Q'
)

c = alt.Chart().mark_line().transform_window(
    rolling_mean='mean(case:Q)',
    frame=[-7, 0]
).encode(
    x='day:T',
    y='rolling_mean:Q'
)

alt.layer(a, c, data=fdf).facet(alt.Column('country', sort=alt.EncodingSortField('case', op='max', order='descending')))
</code></pre>

<p>If you remove the <code>transform_window</code> and replace <code>y='rolling_mean:Q'</code> with <code>y='case:Q'</code>, you'd get a layered faceted chart. It is this chart on which I want a 7 day rolling average.</p>
"
60874294,"<p>Premise:
I have a macbook-pro with Catalina (10.15.4), I have installed: python 3.7 and the GDAL 2.4 and Qgis 3.12 library. (I don't use anaconda or miniconda and I installed homebrew)</p>

<p>Everything stems from the difficulty of executing a particular project that takes data on Corona Virus Italia from Github and processes them daily with Qgis (<a href=""https://github.com/pigreco/COVID-19_ITA"" rel=""nofollow noreferrer"">https://github.com/pigreco/COVID-19_ITA</a>).</p>

<p>As you can see, the project was made for both windows and OSX, in order to run it you need to install the DataPloty plugin.</p>

<p>The problem with Python 3.7</p>

<p>I have been trying for many days to understand this problem with python3 when I try to install gdal, which does not allow me to view the graphics processing :</p>

<pre><code>    pip3 install gdal
Collecting gdal
  Using cached GDAL-3.0.4.tar.gz (577 kB)
Installing collected packages: gdal
    Running setup.py install for gdal ... error
    ERROR: Command errored out with exit status 1:
     command: /Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/pip-install-on9vchph/gdal/setup.py'""'""'; __file__='""'""'/private/var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/pip-install-on9vchph/gdal/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/pip-record-z5yq4g0d/install-record.txt --single-version-externally-managed --compile --install-headers /Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m/gdal
         cwd: /private/var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/pip-install-on9vchph/gdal/
    Complete output (84 lines):
    running install
    running build
    running build_py
    creating build
    creating build/lib.macosx-10.6-intel-3.7
    copying gdal.py -&gt; build/lib.macosx-10.6-intel-3.7
    copying ogr.py -&gt; build/lib.macosx-10.6-intel-3.7
    copying osr.py -&gt; build/lib.macosx-10.6-intel-3.7
    copying gdalconst.py -&gt; build/lib.macosx-10.6-intel-3.7
    copying gdalnumeric.py -&gt; build/lib.macosx-10.6-intel-3.7
    creating build/lib.macosx-10.6-intel-3.7/osgeo
    copying osgeo/gnm.py -&gt; build/lib.macosx-10.6-intel-3.7/osgeo
    copying osgeo/__init__.py -&gt; build/lib.macosx-10.6-intel-3.7/osgeo
    copying osgeo/gdalnumeric.py -&gt; build/lib.macosx-10.6-intel-3.7/osgeo
    copying osgeo/osr.py -&gt; build/lib.macosx-10.6-intel-3.7/osgeo
    copying osgeo/gdal.py -&gt; build/lib.macosx-10.6-intel-3.7/osgeo
    copying osgeo/ogr.py -&gt; build/lib.macosx-10.6-intel-3.7/osgeo
    copying osgeo/gdal_array.py -&gt; build/lib.macosx-10.6-intel-3.7/osgeo
    copying osgeo/gdalconst.py -&gt; build/lib.macosx-10.6-intel-3.7/osgeo
    Fixing build/lib.macosx-10.6-intel-3.7/gdal.py build/lib.macosx-10.6-intel-3.7/ogr.py build/lib.macosx-10.6-intel-3.7/osr.py build/lib.macosx-10.6-intel-3.7/gdalconst.py build/lib.macosx-10.6-intel-3.7/gdalnumeric.py build/lib.macosx-10.6-intel-3.7/osgeo/gnm.py build/lib.macosx-10.6-intel-3.7/osgeo/__init__.py build/lib.macosx-10.6-intel-3.7/osgeo/gdalnumeric.py build/lib.macosx-10.6-intel-3.7/osgeo/osr.py build/lib.macosx-10.6-intel-3.7/osgeo/gdal.py build/lib.macosx-10.6-intel-3.7/osgeo/ogr.py build/lib.macosx-10.6-intel-3.7/osgeo/gdal_array.py build/lib.macosx-10.6-intel-3.7/osgeo/gdalconst.py
    Skipping optional fixer: ws_comma
    Fixing build/lib.macosx-10.6-intel-3.7/gdal.py build/lib.macosx-10.6-intel-3.7/ogr.py build/lib.macosx-10.6-intel-3.7/osr.py build/lib.macosx-10.6-intel-3.7/gdalconst.py build/lib.macosx-10.6-intel-3.7/gdalnumeric.py build/lib.macosx-10.6-intel-3.7/osgeo/gnm.py build/lib.macosx-10.6-intel-3.7/osgeo/__init__.py build/lib.macosx-10.6-intel-3.7/osgeo/gdalnumeric.py build/lib.macosx-10.6-intel-3.7/osgeo/osr.py build/lib.macosx-10.6-intel-3.7/osgeo/gdal.py build/lib.macosx-10.6-intel-3.7/osgeo/ogr.py build/lib.macosx-10.6-intel-3.7/osgeo/gdal_array.py build/lib.macosx-10.6-intel-3.7/osgeo/gdalconst.py
    Skipping optional fixer: ws_comma
    running build_ext
    gcc -fno-strict-aliasing -Wsign-compare -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch i386 -arch x86_64 -g -I/usr/local/opt/openssl@1.1/include -I../../port -I../../gcore -I../../alg -I../../ogr/ -I../../ogr/ogrsf_frmts -I../../gnm -I../../apps -I/Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m -I/Users/tony/Library/Python/3.7/lib/python/site-packages/numpy/core/include -I/Library/Frameworks/GDAL.framework/Versions/2.4/include -c gdal_python_cxx11_test.cpp -o gdal_python_cxx11_test.o
    gcc -fno-strict-aliasing -Wsign-compare -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch i386 -arch x86_64 -g -I/usr/local/opt/openssl@1.1/include -I../../port -I../../gcore -I../../alg -I../../ogr/ -I../../ogr/ogrsf_frmts -I../../gnm -I../../apps -I/Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m -I/Users/tony/Library/Python/3.7/lib/python/site-packages/numpy/core/include -I/Library/Frameworks/GDAL.framework/Versions/2.4/include -c gdal_python_cxx11_test.cpp -o gdal_python_cxx11_test.o -std=c++11
    creating var
    creating var/folders
    creating var/folders/6v
    creating var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn
    creating var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T
    gcc -fno-strict-aliasing -Wsign-compare -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch i386 -arch x86_64 -g -I/usr/local/opt/openssl@1.1/include -I../../port -I../../gcore -I../../alg -I../../ogr/ -I../../ogr/ogrsf_frmts -I../../gnm -I../../apps -I/Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m -I/Users/tony/Library/Python/3.7/lib/python/site-packages/numpy/core/include -I/Library/Frameworks/GDAL.framework/Versions/2.4/include -c /var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmpvdsuhy2e.cpp -o var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmpvdsuhy2e.o -Wno-error=unused-command-line-argument-hard-error-in-future
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    gcc -fno-strict-aliasing -Wsign-compare -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch i386 -arch x86_64 -g -I/usr/local/opt/openssl@1.1/include -I../../port -I../../gcore -I../../alg -I../../ogr/ -I../../ogr/ogrsf_frmts -I../../gnm -I../../apps -I/Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m -I/Users/tony/Library/Python/3.7/lib/python/site-packages/numpy/core/include -I/Library/Frameworks/GDAL.framework/Versions/2.4/include -c /var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmp64x28hgt.cpp -o var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmp64x28hgt.o -Wno-error=unused-command-line-argument-hard-error-in-future
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    gcc -fno-strict-aliasing -Wsign-compare -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch i386 -arch x86_64 -g -I/usr/local/opt/openssl@1.1/include -I../../port -I../../gcore -I../../alg -I../../ogr/ -I../../ogr/ogrsf_frmts -I../../gnm -I../../apps -I/Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m -I/Users/tony/Library/Python/3.7/lib/python/site-packages/numpy/core/include -I/Library/Frameworks/GDAL.framework/Versions/2.4/include -c /var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmp99_tg082.cpp -o var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmp99_tg082.o -Wno-error=unused-command-line-argument-hard-error-in-future
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    gcc -fno-strict-aliasing -Wsign-compare -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch i386 -arch x86_64 -g -I/usr/local/opt/openssl@1.1/include -I../../port -I../../gcore -I../../alg -I../../ogr/ -I../../ogr/ogrsf_frmts -I../../gnm -I../../apps -I/Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m -I/Users/tony/Library/Python/3.7/lib/python/site-packages/numpy/core/include -I/Library/Frameworks/GDAL.framework/Versions/2.4/include -c /var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmpv4ct3en1.cpp -o var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmpv4ct3en1.o -Wno-error=unused-command-line-argument-hard-error-in-future
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    gcc -fno-strict-aliasing -Wsign-compare -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch i386 -arch x86_64 -g -I/usr/local/opt/openssl@1.1/include -I../../port -I../../gcore -I../../alg -I../../ogr/ -I../../ogr/ogrsf_frmts -I../../gnm -I../../apps -I/Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m -I/Users/tony/Library/Python/3.7/lib/python/site-packages/numpy/core/include -I/Library/Frameworks/GDAL.framework/Versions/2.4/include -c /var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmpcxsk3ylh.cpp -o var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmpcxsk3ylh.o -Wno-error=unused-command-line-argument-hard-error-in-future
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    gcc -fno-strict-aliasing -Wsign-compare -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch i386 -arch x86_64 -g -I/usr/local/opt/openssl@1.1/include -I../../port -I../../gcore -I../../alg -I../../ogr/ -I../../ogr/ogrsf_frmts -I../../gnm -I../../apps -I/Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m -I/Users/tony/Library/Python/3.7/lib/python/site-packages/numpy/core/include -I/Library/Frameworks/GDAL.framework/Versions/2.4/include -c /var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmpxeugvpxr.cpp -o var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/tmpxeugvpxr.o -Wno-error=unused-command-line-argument-hard-error-in-future
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    2 warnings generated.
    building 'osgeo._gdal' extension
    creating build/temp.macosx-10.6-intel-3.7
    creating build/temp.macosx-10.6-intel-3.7/extensions
    gcc -fno-strict-aliasing -Wsign-compare -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -arch i386 -arch x86_64 -g -I/usr/local/opt/openssl@1.1/include -I../../port -I../../gcore -I../../alg -I../../ogr/ -I../../ogr/ogrsf_frmts -I../../gnm -I../../apps -I/Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m -I/Users/tony/Library/Python/3.7/lib/python/site-packages/numpy/core/include -I/Library/Frameworks/GDAL.framework/Versions/2.4/include -c extensions/gdal_wrap.cpp -o build/temp.macosx-10.6-intel-3.7/extensions/gdal_wrap.o -std=c++11 -Wno-error=unused-command-line-argument-hard-error-in-future -I/Library/Frameworks/GDAL.framework/Versions/2.4/Headers
    warning: unknown warning option '-Werror=unused-command-line-argument-hard-error-in-future'; did you mean '-Werror=unused-command-line-argument'? [-Wunknown-warning-option]
    warning: include path for stdlibc++ headers not found; pass '-stdlib=libc++' on the command line to use the libc++ standard library instead [-Wstdlibcxx-not-found]
    extensions/gdal_wrap.cpp:3096:10: fatal error: 'stdexcept' file not found
    #include &lt;stdexcept&gt;
             ^~~~~~~~~~~
    2 warnings and 1 error generated.
    error: command 'gcc' failed with exit status 1
    ----------------------------------------
ERROR: Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.7/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/pip-install-on9vchph/gdal/setup.py'""'""'; __file__='""'""'/private/var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/pip-install-on9vchph/gdal/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /private/var/folders/6v/3ynq2r2d2f7gtj6rvb0kw2s00000gn/T/pip-record-z5yq4g0d/install-record.txt --single-version-externally-managed --compile --install-headers /Library/Frameworks/Python.framework/Versions/3.7/include/python3.7m/gdal Check the logs for full command output
</code></pre>
"
61035662,"<p>I have the following code that analyzes the recent COVID19 data and finds cumulative confirmed cases for selected countries, which works fine. </p>

<pre><code>import pandas as pd
import matplotlib.pyplot as plt

url=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv""
df=pd.read_csv(url)

print(df.head())

print('Dropping province, latitude and longitude')
df = df.drop(['Province/State', 'Lat', 'Long'], axis = 1)
print(df.head())

print('Selecting the countries of interest')
countries=['Italy','Netherlands']
s1=df.loc[df['Country/Region'].isin(countries)]    
print('s1=\n',s1.head())

print('Summing all provinces for the same country')
df_gr = s1.groupby('Country/Region').sum()#.reset_index() 
print(df_gr.head())
</code></pre>

<p>The above gives me at the end:</p>

<pre><code>Summing all provinces for the same country
                1/22/20  1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  1/28/20  1/29/20  1/30/20  ...  3/26/20  3/27/20  3/28/20  3/29/20  3/30/20  3/31/20  4/1/20  4/2/20  4/3/20
Country/Region                                                                                   ...
Italy                 0        0        0        0        0        0        0        0        0  ...    80589    86498    92472    97689   101739   105792  110574  115242  119827
Netherlands           0        0        0        0        0        0        0        0        0  ...     7468     8647     9819    10930    11817    12667   13696   14788   15821
</code></pre>

<p>Now I do <code>groupby</code> first and then do <code>isin</code> to select two countries' data and expect to obtain the same result:</p>

<pre><code>import pandas as pd
import matplotlib.pyplot as plt

url=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv""
df=pd.read_csv(url)

print(df.head())

print('Dropping province, latitude and longitude')
df = df.drop(['Province/State', 'Lat', 'Long'], axis = 1)
print(df.head())


print('Summing all provinces for the same country')
df_gr = df.groupby('Country/Region').sum()#.reset_index() 
print(df.head())

print('Selecting the countries of interest')
countries=['Italy','Netherlands']
s1=df_gr.loc[df_gr['Country/Region'].isin(countries)]
print('s1=\n',s1.head())
</code></pre>

<p>However, I get the following error:</p>

<pre><code>Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2646, in get_loc
    return self._engine.get_loc(key)
  File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc
  File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc
  File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Country/Region'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""dr2.py"", line 27, in &lt;module&gt;
    s1=df_gr.loc[df_gr['Country/Region'].isin(countries)]
  File ""/usr/local/lib/python3.7/site-packages/pandas/core/frame.py"", line 2800, in __getitem__
    indexer = self.columns.get_loc(key)
  File ""/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py"", line 2648, in get_loc
    return self._engine.get_loc(self._maybe_cast_indexer(key))
  File ""pandas/_libs/index.pyx"", line 111, in pandas._libs.index.IndexEngine.get_loc
  File ""pandas/_libs/index.pyx"", line 138, in pandas._libs.index.IndexEngine.get_loc
  File ""pandas/_libs/hashtable_class_helper.pxi"", line 1619, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File ""pandas/_libs/hashtable_class_helper.pxi"", line 1627, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Country/Region'
</code></pre>

<p>Any explanation or remedy?</p>
"
60767126,"<p>I have <a href=""https://github.com/paulobfsilva123/covidoff-web/tree/tracker"" rel=""nofollow noreferrer"">this rep</a> with a Django app and Docker, but <code>docker-compose up</code> is not working. This is my output:</p>

<pre><code>Starting covidoff-web_db_1 ... done
Starting covidoff-web_webapp_1 ... done
Starting covidoff-web_webserver_1 ... done
Attaching to covidoff-web_db_1, covidoff-web_webapp_1, covidoff-web_webserver_1
db_1         | 2020-03-20 00:50:54.601 UTC [1] LOG:  listening on IPv4 address ""0.0.0.0"", port 5432
db_1         | 2020-03-20 00:50:54.601 UTC [1] LOG:  listening on IPv6 address ""::"", port 5432
webapp_1     | HOST: db:5432, DB: None, USER: postgres
db_1         | 2020-03-20 00:50:54.605 UTC [1] LOG:  listening on Unix socket ""/var/run/postgresql/.s.PGSQL.5432""
webapp_1     | ==&gt; Django setup, executing: flush
db_1         | 2020-03-20 00:50:54.620 UTC [24] LOG:  database system was interrupted; last known up at 2020-03-20 00:25:37 UTC
db_1         | 2020-03-20 00:50:54.802 UTC [24] LOG:  database system was not properly shut down; automatic recovery in progress
db_1         | 2020-03-20 00:50:54.804 UTC [24] LOG:  invalid record length at 0/16538C0: wanted 24, got 0
db_1         | 2020-03-20 00:50:54.804 UTC [24] LOG:  redo is not required
db_1         | 2020-03-20 00:50:54.817 UTC [1] LOG:  database system is ready to accept connections
webapp_1     | ==&gt; Django setup, executing: migrate
webapp_1     | Operations to perform:
webapp_1     |   Apply all migrations: admin, announcements, auth, contenttypes, sessions, tracker
webapp_1     | Running migrations:
webapp_1     |   No migrations to apply.
webapp_1     | ==&gt; Django setup, executing: collectstatic
webapp_1     | Skipping 'admin/fonts/README.txt' (not modified)
webapp_1     | Skipping 'admin/fonts/Roboto-Light-webfont.woff' (not modified)
webapp_1     | Skipping 'admin/fonts/Roboto-Regular-webfont.woff' (not modified)
webapp_1     | Skipping 'admin/fonts/LICENSE.txt' (not modified)
webapp_1     | Skipping 'admin/fonts/Roboto-Bold-webfont.woff' (not modified)
webapp_1     | Skipping 'admin/js/prepopulate.js' (not modified)
webapp_1     | Skipping 'admin/js/inlines.js' (not modified)
webapp_1     | Skipping 'admin/js/urlify.js' (not modified)
webapp_1     | Skipping 'admin/js/actions.min.js' (not modified)
webapp_1     | Skipping 'admin/js/autocomplete.js' (not modified)
webapp_1     | Skipping 'admin/js/cancel.js' (not modified)
webapp_1     | Skipping 'admin/js/actions.js' (not modified)
webapp_1     | Skipping 'admin/js/prepopulate.min.js' (not modified)
webapp_1     | Skipping 'admin/js/collapse.min.js' (not modified)
webapp_1     | Skipping 'admin/js/SelectBox.js' (not modified)
webapp_1     | Skipping 'admin/js/change_form.js' (not modified)
webapp_1     | Skipping 'admin/js/popup_response.js' (not modified)
webapp_1     | Skipping 'admin/js/jquery.init.js' (not modified)
webapp_1     | Skipping 'admin/js/prepopulate_init.js' (not modified)
webapp_1     | Skipping 'admin/js/core.js' (not modified)
webapp_1     | Skipping 'admin/js/inlines.min.js' (not modified)
webapp_1     | Skipping 'admin/js/collapse.js' (not modified)
webapp_1     | Skipping 'admin/js/calendar.js' (not modified)
webapp_1     | Skipping 'admin/js/SelectFilter2.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/jquery/jquery.min.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/jquery/LICENSE.txt' (not modified)
webapp_1     | Skipping 'admin/js/vendor/jquery/jquery.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/xregexp/xregexp.min.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/xregexp/xregexp.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/xregexp/LICENSE.txt' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/select2.full.min.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/select2.full.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/LICENSE.md' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/ko.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/ms.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/ca.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/ja.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/sv.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/hi.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/it.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/da.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/vi.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/hy.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/et.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/eu.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/fa.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/dsb.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/he.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/gl.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/lt.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/nl.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/th.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/sr-Cyrl.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/de.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/pt-BR.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/af.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/tr.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/sl.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/mk.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/sk.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/km.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/sq.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/es.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/hsb.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/fi.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/id.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/tk.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/pt.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/en.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/hu.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/is.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/bg.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/hr.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/sr.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/ne.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/ro.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/ru.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/az.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/pl.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/lv.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/bn.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/uk.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/bs.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/cs.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/ar.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/fr.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/ka.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/zh-CN.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/el.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/nb.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/zh-TW.js' (not modified)
webapp_1     | Skipping 'admin/js/vendor/select2/i18n/ps.js' (not modified)
webapp_1     | Skipping 'admin/js/admin/RelatedObjectLookups.js' (not modified)
webapp_1     | Skipping 'admin/js/admin/DateTimeShortcuts.js' (not modified)
webapp_1     | Skipping 'admin/img/calendar-icons.svg' (not modified)
webapp_1     | Skipping 'admin/img/README.txt' (not modified)
webapp_1     | Skipping 'admin/img/icon-calendar.svg' (not modified)
webapp_1     | Skipping 'admin/img/search.svg' (not modified)
webapp_1     | Skipping 'admin/img/icon-unknown-alt.svg' (not modified)
webapp_1     | Skipping 'admin/img/icon-clock.svg' (not modified)
webapp_1     | Skipping 'admin/img/selector-icons.svg' (not modified)
webapp_1     | Skipping 'admin/img/icon-changelink.svg' (not modified)
webapp_1     | Skipping 'admin/img/icon-yes.svg' (not modified)
webapp_1     | Skipping 'admin/img/LICENSE' (not modified)
webapp_1     | Skipping 'admin/img/icon-alert.svg' (not modified)
webapp_1     | Skipping 'admin/img/icon-deletelink.svg' (not modified)
webapp_1     | Skipping 'admin/img/tooltag-add.svg' (not modified)
webapp_1     | Skipping 'admin/img/tooltag-arrowright.svg' (not modified)
webapp_1     | Skipping 'admin/img/sorting-icons.svg' (not modified)
webapp_1     | Skipping 'admin/img/inline-delete.svg' (not modified)
webapp_1     | Skipping 'admin/img/icon-no.svg' (not modified)
webapp_1     | Skipping 'admin/img/icon-unknown.svg' (not modified)
webapp_1     | Skipping 'admin/img/icon-addlink.svg' (not modified)
webapp_1     | Skipping 'admin/img/icon-viewlink.svg' (not modified)
webapp_1     | Skipping 'admin/img/gis/move_vertex_on.svg' (not modified)
webapp_1     | Skipping 'admin/img/gis/move_vertex_off.svg' (not modified)
webapp_1     | Skipping 'admin/css/changelists.css' (not modified)
webapp_1     | Skipping 'admin/css/login.css' (not modified)
webapp_1     | Skipping 'admin/css/dashboard.css' (not modified)
webapp_1     | Skipping 'admin/css/fonts.css' (not modified)
webapp_1     | Skipping 'admin/css/responsive_rtl.css' (not modified)
webapp_1     | Skipping 'admin/css/widgets.css' (not modified)
webapp_1     | Skipping 'admin/css/responsive.css' (not modified)
webapp_1     | Skipping 'admin/css/rtl.css' (not modified)
webapp_1     | Skipping 'admin/css/autocomplete.css' (not modified)
webapp_1     | Skipping 'admin/css/base.css' (not modified)
webapp_1     | Skipping 'admin/css/forms.css' (not modified)
webapp_1     | Skipping 'admin/css/vendor/select2/select2.min.css' (not modified)
webapp_1     | Skipping 'admin/css/vendor/select2/LICENSE-SELECT2.md' (not modified)
webapp_1     | Skipping 'admin/css/vendor/select2/select2.css' (not modified)
webapp_1     | 
webapp_1     | 0 static files copied to '/srv/starter/static', 130 unmodified.
webapp_1     | ==&gt; Starting uWSGI ...
webapp_1     | *** Starting uWSGI 2.0.17.1 (64bit) on [Fri Mar 20 00:50:56 2020] ***
webapp_1     | compiled with version: 8.3.0 on 19 March 2020 23:41:29
webapp_1     | os: Linux-4.19.76-linuxkit #1 SMP Thu Oct 17 19:31:58 UTC 2019
webapp_1     | nodename: 4eb039cc2359
webapp_1     | machine: x86_64
webapp_1     | clock source: unix
webapp_1     | pcre jit disabled
webapp_1     | detected number of CPU cores: 4
webapp_1     | current working directory: /
webapp_1     | detected binary path: /usr/local/bin/uwsgi
webapp_1     | uWSGI running as root, you can use --uid/--gid/--chroot options
webapp_1     | *** WARNING: you are running uWSGI as root !!! (use the --uid flag) *** 
webapp_1     | *** WARNING: you are running uWSGI without its master process manager ***
webapp_1     | your memory page size is 4096 bytes
webapp_1     | detected max file descriptor number: 1048576
webapp_1     | *** starting uWSGI Emperor ***
webapp_1     | *** has_emperor mode detected (fd: 5) ***
webapp_1     | [uWSGI] getting INI configuration from /etc/uwsgi/django-uwsgi.ini
webapp_1     | *** Starting uWSGI 2.0.17.1 (64bit) on [Fri Mar 20 00:50:57 2020] ***
webapp_1     | compiled with version: 8.3.0 on 19 March 2020 23:41:29
webapp_1     | os: Linux-4.19.76-linuxkit #1 SMP Thu Oct 17 19:31:58 UTC 2019
webapp_1     | nodename: 4eb039cc2359
webapp_1     | machine: x86_64
webapp_1     | clock source: unix
webapp_1     | pcre jit disabled
webapp_1     | detected number of CPU cores: 4
webapp_1     | current working directory: /
webapp_1     | detected binary path: /usr/local/bin/uwsgi
webapp_1     | setgid() to 102
webapp_1     | setuid() to 101
webapp_1     | chdir() to /srv/starter/
webapp_1     | your memory page size is 4096 bytes
webapp_1     |  *** WARNING: you have enabled harakiri without post buffering. Slow upload could be rejected on post-unbuffered webservers *** 
webapp_1     | detected max file descriptor number: 1048576
webapp_1     | lock engine: pthread robust mutexes
webapp_1     | thunder lock: disabled (you can enable it with --thunder-lock)
webapp_1     | uwsgi socket 0 bound to TCP address :8000 fd 3
webapp_1     | Python version: 3.7.7 (default, Mar 11 2020, 00:27:03)  [GCC 8.3.0]
webapp_1     | Python main interpreter initialized at 0x55da2c534200
webapp_1     | python threads support enabled
webapp_1     | your server socket listen backlog is limited to 100 connections
webapp_1     | your mercy for graceful operations on workers is 60 seconds
webapp_1     | mapped 1315008 bytes (1284 KB) for 64 cores
webapp_1     | *** Operational MODE: preforking+threaded ***
webapp_1     | *** uWSGI is running in multiple interpreter mode ***
webapp_1     | spawned uWSGI master process (pid: 11)
webapp_1     | Fri Mar 20 00:50:57 2020 - [emperor] vassal /etc/uwsgi/django-uwsgi.ini has been spawned
webapp_1     | spawned uWSGI worker 1 (pid: 12, cores: 8)
webapp_1     | spawned uWSGI worker 2 (pid: 13, cores: 8)
webapp_1     | spawned uWSGI worker 3 (pid: 14, cores: 8)
webapp_1     | spawned uWSGI worker 4 (pid: 15, cores: 8)
webapp_1     | spawned uWSGI worker 5 (pid: 16, cores: 8)
webapp_1     | spawned uWSGI worker 6 (pid: 17, cores: 8)
webapp_1     | spawned uWSGI worker 7 (pid: 18, cores: 8)
webapp_1     | spawned uWSGI worker 8 (pid: 19, cores: 8)
webapp_1     | unable to stat() /etc/uwsgi/reload-uwsgi.ini, events will be triggered as soon as the file is created
webapp_1     | ModuleNotFoundError: No module named 'starter'
webapp_1     | unable to load app 0 (mountpoint='') (callable not found or import error)
webapp_1     | *** no app loaded. going in full dynamic mode ***
webapp_1     | ModuleNotFoundError: No module named 'starter'
webapp_1     | unable to load app 0 (mountpoint='') (callable not found or import error)
webapp_1     | *** no app loaded. going in full dynamic mode ***
webapp_1     | ModuleNotFoundError: No module named 'starter'
webapp_1     | unable to load app 0 (mountpoint='') (callable not found or import error)
webapp_1     | *** no app loaded. going in full dynamic mode ***
webapp_1     | ModuleNotFoundError: No module named 'starter'
webapp_1     | unable to load app 0 (mountpoint='') (callable not found or import error)
webapp_1     | *** no app loaded. going in full dynamic mode ***
webapp_1     | ModuleNotFoundError: No module named 'starter'
webapp_1     | unable to load app 0 (mountpoint='') (callable not found or import error)
webapp_1     | *** no app loaded. going in full dynamic mode ***
webapp_1     | Fri Mar 20 00:50:57 2020 - [emperor] vassal /etc/uwsgi/django-uwsgi.ini is ready to accept requests
webapp_1     | ModuleNotFoundError: No module named 'starter'
webapp_1     | unable to load app 0 (mountpoint='') (callable not found or import error)
webapp_1     | *** no app loaded. going in full dynamic mode ***
webapp_1     | ModuleNotFoundError: No module named 'starter'
webapp_1     | unable to load app 0 (mountpoint='') (callable not found or import error)
webapp_1     | *** no app loaded. going in full dynamic mode ***
webapp_1     | ModuleNotFoundError: No module named 'starter'
webapp_1     | unable to load app 0 (mountpoint='') (callable not found or import error)
webapp_1     | *** no app loaded. going in full dynamic mode ***
</code></pre>

<p>It appears as if the problem could be here:</p>

<pre><code># the base directory (full path)
chdir = /srv/$(DJANGO_PROJECT_NAME)/

# Django's wsgi file (path starting from chdir/)
module = $(DJANGO_PROJECT_NAME).wsgi:application
</code></pre>

<p>Here's the thing: I created the project without docker, called <code>covidoff</code>, and asked this guy to do the Docker integration. It looks like <code>DJANGO_PROJECT_NAME</code> is <code>starter</code>. Is that wrong?</p>
"
61349245,"<p>Eager tensors don't support assignment.  I need to do assignment.  </p>

<pre><code>a = tf.convert_to_tensor(np.random.choice(10, size = 12).reshape(3,4))
b = tf.convert_to_tensor(np.array([2,3]))
a[:,b] *= -1
Traceback (most recent call last):

  File ""&lt;ipython-input-15-516f7e5d5213&gt;"", line 3, in &lt;module&gt;
    a[:,b] *= -1

  File ""/opt/anaconda3/envs/covid_timeseries/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 777, in _slice_helper
    _check_index(s)

  File ""/opt/anaconda3/envs/covid_timeseries/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 666, in _check_index
    raise TypeError(_SLICE_TYPE_ERROR + "", got {!r}"".format(idx))

TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got &lt;tf.Tensor: id=3, shape=(2,), dtype=int64, numpy=array([2, 3])&gt;
</code></pre>

<p>There is a suggestion <a href=""https://github.com/tensorflow/tensorflow/issues/14132#issuecomment-483002522"" rel=""nofollow noreferrer"">here</a> for how to do a workaround:</p>

<pre><code>new = original * mask + other * (1 - mask)
</code></pre>

<p>I'm having trouble making this work, because I can't figure out a way to create a mask that doesn't itself involve assignment!</p>

<p>I'd greatly appreciate some guidance that'd help me to implement this high-level approach, maybe something like this:</p>

<pre><code>def tf_assign_workaround(tensor, index, newvals):
    ??
    return tensor_with_index_assigned_to_newvals
</code></pre>

<p>EDIT:  Here's the original, simpler example</p>

<pre><code>a = tf.convert_to_tensor(np.random.choice(10, size = 12).reshape(3,4))
a[:,1] *= -1
Traceback (most recent call last):

  File ""&lt;ipython-input-35-f8973c287624&gt;"", line 2, in &lt;module&gt;
    a[:,1] *= -1

TypeError: 'tensorflow.python.framework.ops.EagerTensor' object does not support item assignment
</code></pre>
"
61143920,"<p>I am trying to display console output of a python script in a QplainTextEdit widget in PyQt5.</p>

<p>I am getting this error: </p>

<blockquote>
  <p>TypeError: Error when calling the metaclass bases
      metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases</p>
</blockquote>

<p>I have defined my objects in the pyqt GUI file and I believe that I have all the imports.</p>

<h2>Update</h2>

<p>I have amended the code in this question:</p>

<pre><code>from PyQt5.QtCore import QRectF, Qt
from PyQt5.QtWidgets import QFileDialog, QPlainTextEdit
from PyQt5 import QtCore, QtGui, QtWidgets
from PIL import Image, ImageQt, ImageEnhance
# from PyQt5.QtGui import Qt
from pyqtgraph.examples.text import text

from covid19gui_V3 import Ui_MainWindow
import os
import sys

input_img = Image.open(""/home/ironmantis7x/Documents/Maverick_AI/Python/keras-covid-19/maverickAI30k.png"")
text_edit = QPlainTextEdit()

class EmittingStream(QtCore.QObject):

    textWritten = QtCore.pyqtSignal(str)
    def write(self, text):
        self.textWritten.emit(str(text))

class MainWindow(QtWidgets.QMainWindow, Ui_MainWindow):
    textWritten = QtCore.pyqtSignal(str)
    def __init__(self, parent=None, **kwargs):
        super(MainWindow, self).__init__(parent)
        self.setupUi(self)
        self.ShowIButton.clicked.connect(self.do_test)
        self.chooseStudy.clicked.connect(self.do_choosestudy)
        self.RunButton_3.clicked.connect(self.do_runstudy)
        self.scene = QtWidgets.QGraphicsScene(self)
        self.graphicsView.setScene(self.scene)
        w, h = input_img.size
        self.pixmap_item = self.scene.addPixmap(QtGui.QPixmap())
        # self.graphicsView.fitInView(QRectF(0, 0, w, h), Qt.KeepAspectRatio)
        self.graphicsView.update()
        self.plainTextEdit.update()
        self.level = 1
        self.enhancer = None
        self.timer = QtCore.QTimer(interval=500, timeout=self.on_timeout)
        sys.stdout = EmittingStream(textWritten=self.normalOutputWritten)

    def write(self, text):
        self.textWritten.emit(str(text))

    @QtCore.pyqtSlot()
    def do_test(self):
        # input_img = Image.open(""/home/ironmantis7x/Documents/Maverick_AI/Python/keras-covid-19/maverickAI30k.png"")
        self.enhancer = ImageEnhance.Brightness(input_img)
        self.timer.start()
        self.ShowIButton.setDisabled(True)

    @QtCore.pyqtSlot()
    def on_timeout(self):
        if self.enhancer is not None:
            result_img = self.enhancer.enhance(self.level)
            qimage = ImageQt.ImageQt(result_img)
            self.pixmap_item.setPixmap(QtGui.QPixmap.fromImage(qimage))
        if self.level &gt; 7:
            self.timer.stop()
            self.enhancer = None
            self.level = 0
            self.ShowIButton.setDisabled(False)
        self.level = 1
        self.ShowIButton.setDisabled(False)

    @QtCore.pyqtSlot()
    def do_choosestudy(self):
        dlg = QFileDialog()
        dlg.setFileMode(QFileDialog.AnyFile)
        if dlg.exec_():
            filenames = dlg.selectedFiles()
            f = open(filenames[0], 'r')

    @QtCore.pyqtSlot()
    def do_runstudy(self):
        os.system(""df -h"")
        # filetext = open('screenout.txt').read()
        # filetext.close()
        # textViewValue = self.plainTextEdit.toPlainText()
        # QPlainTextEdit.appendPlainText(self, str(textViewValue))
        # sys.stdout = self(textWritten=self.textWritten)
        self.normalOutputWritten(text_edit)

    def __del__(self):
        # Restore sys.stdout
        sys.stdout = sys.__stdout__

    def normalOutputWritten(self, text_edit):
        #cursor = self.plainTextEdit.textCursor()
        #cursor.movePosition(QtGui.QTextCursor.End)
        #cursor.insertText(text_edit)
        self.plainTextEdit.appendPlainText(text_edit)
        #self.plainTextEdit.ensureCursorVisible()

if __name__ == ""__main__"":
    import sys
    app = QtWidgets.QApplication(sys.argv)
    w = MainWindow()
    w.show()
    sys.exit(app.exec_())
</code></pre>

<p>How can I make this work correctly?</p>

<h2>Update 2</h2>

<p>I indeed DID do research into the topic and this is one of the main resources I used to try to solve the issue before I posted my question: <a href=""https://stackoverflow.com/questions/8356336/how-to-capture-output-of-pythons-interpreter-and-show-in-a-text-widget"">How to capture output of Python&#39;s interpreter and show in a Text widget?</a></p>

<h2>Update 3</h2>

<p>I have revised my code in the post to reflect code suggestions in the link I used to help me with my issue.</p>

<p>I am still unable to get this to run correctly. I now get this error:</p>

<blockquote>
  <p>self.plainTextEdit.appendPlainText(text_edit) TypeError:
  appendPlainText(self, str): argument 1 has unexpected type
  'QPlainTextEdit'</p>
</blockquote>
"
61311755,"<p>I'm trying to calculate the <code>Pearson Correlation</code> based on the gist provided <a href=""https://gist.github.com/MLWhiz/3efc62d1805bcbc85092ced20c807a65#file-correlation-py"" rel=""nofollow noreferrer"">here</a>. Oddly getting <code>ValueError: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 52 and the array at index 1 has size 1</code> error (the data frame has 52 records). </p>

<p>Here is the provided function:</p>

<pre><code>def cor_selector(X, y, num_feats):
    cor_list = []
    feature_name = X.columns.tolist()
    # calculate the correlation with y for each feature
    for i in X.columns.tolist():
        cor = np.corrcoef(X[i], y)[0, 1] # error happens during the 2nd call to here
        cor_list.append(cor)
    # replace NaN with 0
    cor_list = [0 if np.isnan(i) else i for i in cor_list]
    # feature name
    cor_feature = X.iloc[:, np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()
    # feature selection? 0 for not select, 1 for select
    cor_support = [True if i in cor_feature else False for i in feature_name]
    return cor_support, cor_feature
</code></pre>

<p>Here is my script:</p>

<pre><code>df = pd.read_csv(DATA_CSV) # shape: (52, 5)
X = df[['a', 'b', 'c']]
y = df[['d']]
num_feats = 3
cor_support, cor_feature = cor_selector(X, y, num_feats)
print(str(len(cor_feature)), 'selected features')
</code></pre>

<p>Full stack trace:</p>

<pre><code>Traceback (most recent call last):
  File ""/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/pydevd.py"", line 1438, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File ""/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""/Users/talha/PycharmProjects/covid19/store_data.py"", line 275, in &lt;module&gt;
    cor_support, cor_feature = cor_selector(X, y, num_feats)
  File ""/Users/talha/PycharmProjects/covid19/store_data.py"", line 254, in cor_selector
    cor = np.corrcoef(X[i], y)[0, 1]
  File ""&lt;__array_function__ internals&gt;"", line 6, in corrcoef
  File ""/Users/talha/.local/share/virtualenvs/covid19-g87yyZJK/lib/python3.7/site-packages/numpy/lib/function_base.py"", line 2526, in corrcoef
    c = cov(x, y, rowvar)
  File ""&lt;__array_function__ internals&gt;"", line 6, in cov
  File ""/Users/talha/.local/share/virtualenvs/covid19-g87yyZJK/lib/python3.7/site-packages/numpy/lib/function_base.py"", line 2390, in cov
    X = np.concatenate((X, y), axis=0)
  File ""&lt;__array_function__ internals&gt;"", line 6, in concatenate
</code></pre>
"
60812356,"<p>My code works well but I'd like to increase the number of dates in the x-axis.</p>

<pre><code>covid19=pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv')
top=covid19.groupby('Country/Region').sum().reset_index()
latest=top.columns.values[-1]
df=top.sort_values(latest,ascending=False).head(30).drop(['Lat', 'Long'],axis=1).set_index(""Country/Region"").T
fig = plt.figure()
ax = fig.add_subplot(1, 1, 1)
df.plot(ax=ax,figsize=(15,15),title='COVID-19')
plt.xlabel('Date')
plt.ylabel('Number')
plt.xticks(df.index.values)
fig.autofmt_xdate() # make space for and rotate the x-axis tick labels
plt.legend(loc=2)
plt.show()
</code></pre>

<p>The following graph gives only six dates in the x-axis.</p>

<p><a href=""https://i.stack.imgur.com/Wfjpw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Wfjpw.png"" alt=""enter image description here""></a></p>

<p>If I add this it returns an error.</p>

<pre><code>plt.xticks(df.index.values)
</code></pre>

<blockquote>
  <p>ConversionError: Failed to convert value(s) to axis units:
  array(['1/22/20', '1/23/20', '1/24/20', '1/25/20', '1/26/20',
  '1/27/20',
         '1/28/20', '1/29/20', '1/30/20', '1/31/20', '2/1/20', '2/2/20',
         ....
         '3/10/20', '3/11/20', '3/12/20', '3/13/20', '3/14/20', '3/15/20',
         '3/16/20', '3/17/20'], dtype=object)</p>
</blockquote>

<p>How can I increse the number of x-ticks?</p>
"
60999030,"<p>Currently in development it works just fine... <code>localhost:4200</code> for the front-end and <code>localhost:8080</code> for the back-end</p>

<p>However, I just deployed it and the front-end get displayed, but isn't getting the data from the API because in my <code>app.service.ts</code> I'm doing the following:</p>

<pre><code>import { Injectable } from '@angular/core';
import { HttpClient } from '@angular/common/http';

@Injectable({
  providedIn: 'root'
})
export class ApiService {
  private apiUrl = 'http://localhost:8080/api'

  constructor(private http: HttpClient) { }

  public getNews() {
    return this.http.get(`${this.apiUrl}/countries`)
  }
}
</code></pre>

<p>As you can see, I'm hardcoding the <code>localhost:8080</code> and it works fine in development, but when it comes to production Heroku does not assign me the <code>port 8080</code>, it assigns me another one.</p>

<p>That being said... How can I tweak this in order to read the port Heroku gives me?</p>

<p>This is my app.js file</p>

<pre><code>const express = require('express');
const app = express();
const scrapper = require('./backend/scrapper')

// Create link to Angular build directory
var distDir = __dirname + ""/dist/covid19"";
app.use(express.static(distDir));

app.use((req, res, next) =&gt; {
    res.setHeader(""Access-Control-Allow-Origin"", ""*"");
    res.setHeader(
        ""Access-Control-Allow-Headers"",
        ""Origin, X-Requested-With, Content-Type, Accept, Authorization""
    );
    res.setHeader(
        ""Access-Control-Allow-Methods"",
        ""GET, POST, PATCH, PUT, DELETE, OPTIONS""
    );
    next();
});

app.use(""/api/countries"", async (req, res, next) =&gt; {
    const data = await scrapper.getCountries()
    res.status(200).json(data)
})

const port = process.env.PORT || 8080;
app.listen(port, () =&gt; {
    console.log(`API listening on port ${port}...`);
});

module.exports = app;
</code></pre>

<p>As you can see I'm declaring my port to be <code>process.env.PORT || 8080</code>, but this is for the backend... How can achieve this but in my API call in the <code>service.ts</code> file?</p>
"
61088763,"<p>I'm currently trying to get COVID-19 from the <code>Covid Data Repository by Johns Hopkins.</code> <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19</a> </p>

<p>The repo get updated with new data every 24h, and they upload the data in <code>.csv</code> files daily.</p>

<p>My question would be: How to get access to the latest data from my Web App with Nodejs? Scrapping or there's an easy way that I'm missing?</p>

<p>MERN Stack</p>
"
61170580,"<p>I have deployed my React App on Github pages but the routes are not working on Github pages.</p>

<p><strong>Only the base URL is working</strong>. If I navigate to any other page then I get error 404.</p>

<p>App.js</p>

<pre><code>&lt;Router&gt;

        &lt;nav role=""navigation"" id=""nav_bar_hamburger""&gt;
          &lt;div id=""menuToggle""&gt;
            &lt;input type=""checkbox"" /&gt;
            &lt;span&gt;&lt;/span&gt;
            &lt;span&gt;&lt;/span&gt;
            &lt;span&gt;&lt;/span&gt;

            &lt;ul id=""menu""&gt;
              &lt;a href=""/covid19-tracker""&gt;&lt;li&gt;Worldwide&lt;/li&gt;&lt;/a&gt;
              &lt;a href=""/india-statewise""&gt;&lt;li&gt;India-Statewise&lt;/li&gt;&lt;/a&gt;
              &lt;a href=""/coming-soon""&gt;&lt;li&gt;Coming Soon&lt;/li&gt;&lt;/a&gt;
            &lt;/ul&gt;
          &lt;/div&gt;
        &lt;/nav&gt;



        &lt;div className=""routingContainer""&gt;

          &lt;Switch&gt;
            &lt;Route path=""/covid19-tracker"" component={WorldwideContainer} /&gt;
            &lt;Route path=""/india-statewise"" component={IndianStateWise} /&gt;
            &lt;Route path=""/coming-soon"" component={temp} /&gt;
          &lt;/Switch&gt;
          &lt;hr /&gt;
        &lt;/div&gt;
 &lt;/Router&gt;
</code></pre>

<p>Does BrowserRouter works differently after deploying to Github pages? What's the ideal solution for this?</p>
"
61246585,"<p>I have created a areaspline chart using highcharts library and making it animated with play/pause button transition between weeks of data </p>

<p>Ref. <a href=""https://www.highcharts.com/blog/tutorials/176-charts-in-motion/"" rel=""nofollow noreferrer"">https://www.highcharts.com/blog/tutorials/176-charts-in-motion/</a></p>

<p>jsfiddle Ref. <a href=""https://jsfiddle.net/larsac07/wkev75nL/?utm_source=website&amp;utm_medium=embed&amp;utm_campaign=wkev75nL"" rel=""nofollow noreferrer"">https://jsfiddle.net/larsac07/wkev75nL/?utm_source=website&amp;utm_medium=embed&amp;utm_campaign=wkev75nL</a></p>

<p>in the above example, we are animating the chart week wise </p>

<p>dataSet used : </p>

<pre><code>dataSequence = [
        {
            name: 'Week 1',
            data: [1, 2, 2, 1, 1, 2, 2]
        }, {
            name: 'Week 2',
            data: [6, 12, 2, 3, 3, 2, 2]
        }, {
            name: 'Week 3',
            data: [4, 5, 6, 5, 5, 4, 9]
        }, {
            name: 'Week 4',
            data: [5, 5, 6, 6, 5, 6, 6]
        }, {
            name: 'Week 5',
            data: [6, 7, 7, 6, 6, 6, 7]
        }, {
            name: 'Week 6',
            data: [8, 9, 9, 8, 8, 8, 9]
        }, {
            name: 'Week 7',
            data: [9, 10, 4, 10, 9, 9, 9]
        }, {
            name: 'Week 8',
            data: [1, 10, 10, 10, 10, 11, 11]
        }, {
            name: 'Week 9',
            data: [11, 11, 12, 12, 12, 11, 11]
        }
    ]
</code></pre>

<p>I don't want change chart 
on play button click I want animate the data points 11 data point for week1 to same data point but different value on y axis for week2</p>

<pre><code>xAxis = [""week1"", ""Week2"", ..... ],
yAxis = [[1,2,3,4,5,6,7,8,9,10,11], [3,5,7,8,2,1,5,7,6,1,10], ....]
</code></pre>

<p>on the play button it would transit between <code>week1</code> then will go to <code>week 2</code> and so till last week number available.</p>

<p>Trying to have something like this Ref. <a href=""https://aatishb.com/covidtrends/"" rel=""nofollow noreferrer"">https://aatishb.com/covidtrends/</a></p>

<p><img src=""https://i.ibb.co/JnN65ZF/Screen-Shot-2020-04-16-at-4-20-55-PM.png"" alt=""static chart""></p>

<p>this chart is plotted using this dataset for series </p>

<pre><code>Highcharts.chart(""container"", {
      chart: {
        type: ""areaspline""
      },
      tooltip: {
        shared: true,
        valueSuffix: "" units""
      },
      xAxis: {
        categories: [
          ""Week 1"",
          ""Week 2"",
          ""Week 3"",
          ""Week 4"",
          ""Week 5"",
          ""Week 6"",
          ""Week 7""
        ]
      },
      yAxis: {
        title: {
          text: ""Efficiency Index""
        }
      },
      legend: {
        layout: ""horizontal"",
        align: ""right"",
        verticalAlign: ""top"",
        x: 50,
        y: 50,
        floating: true,
        borderWidth: 1,
        backgroundColor:
          (Highcharts.theme &amp;&amp; Highcharts.theme.legendBackgroundColor) ||
          ""#FFFFFF""
      },
      plotOptions: {
        areaspline: {
          fillOpacity: 0.5
        }
      },
      credits: {
        enabled: false
      },
      series: [
        {
          name: ""By week"",
          data: dataSequence[value].data.slice()
        },
        {
          type: ""spline"",
          name: ""Topic 1"",
          data: [3, 2, 1, 3, 4, 7, 8]
        },
        {
          type: ""spline"",
          name: ""Topic 2"",
          data: [1, 5, 1, 3, 4, 7, 8]
        },
        {
          type: ""spline"",
          name: ""Topic 3"",
          data: [3, 7, 1, 3, 4, 7, 8]
        },
        {
          type: ""spline"",
          name: ""Topic 4"",
          data: [5, 1, 1, 3, 4, 7, 8]
        },
        {
          type: ""spline"",
          name: ""Topic 5"",
          data: [7, 3, 1, 3, 4, 7, 8]
        },
        {
          type: ""spline"",
          name: ""Topic 6"",
          data: [9, 2, 1, 3, 4, 7, 8]
        },
        {
          type: ""spline"",
          name: ""Topic 7"",
          data: [11, 8, 1, 3, 4, 7, 8]
        },
        {
          type: ""spline"",
          name: ""Topic 8"",
          data: [13, 11, 1, 3, 4, 7, 8]
        },
        {
          type: ""spline"",
          name: ""Topic 9"",
          data: [15, 7, 1, 3, 4, 7, 8]
        },
        {
          type: ""spline"",
          name: ""Topic 10"",
          data: [7, 5, 1, 3, 4, 7, 8]
        }
      ],
      title: {
        text: """"
      },
      subtitle: {
        text: ""Efficiency Index of Topics""
      }
    });
</code></pre>

<p>this my update function in react</p>

<pre><code>update(increment) {
    var input = $(""#play-range"")[0];
    var output = $(""#play-output"")[0];

    if (increment) {
      input.value = parseInt(input.value) + increment;
    }
    output.innerHTML = this.state.dataSequence[input.value].name;
    this.setState({
      value: input.value
    });
    if (input.value &gt;= input.max) {
      // Auto-pause
      this.pause();
      this.setState(
        {
          value: 0
        },
        () =&gt; {
          output.innerHTML = this.state.dataSequence[0].name;
        }
      );
    }
  }
</code></pre>

<p>the whole chart is plotted at once, I need something that it should transit 
first, it plots all data points for week1 then week 2 after that week 3 when I click on the play button </p>
"
61329922,"<p>Hello I am messing around with some public Covid_19 datasets and I am trying to create a visualization of the world countries and their respective confirmed cases, deaths, and recovered stats. I am using mapbox to generate a map and .addSource to add a geoJson layer of the countries. Right now that layer is all one color because inside of the .addLayer part it only accepts one color: </p>

<pre><code>map.addLayer({
      'id': 'world_countries_fill',
      'type': 'fill',
      'source': 'world_countries',
      'paint': {
           'fill-color': '#f08', // &lt;&lt;&lt;
           'fill-opacity': 0.4
      }
</code></pre>

<p>is it possible to use a function that returns a color based off say the number of deaths for that single country in mapbox .addLayer()?</p>

<p>Or should i look to use leaflet and turf.js featureCollection?</p>

<p>here is my full js file:</p>

<pre><code>function Country(name, death, recovered, confirmed) {
    this.name = name;
    this.death = death;
    this.recovered = recovered;
    this.confirmed = confirmed;
}

var countryArray = []; //array of country objects

function init() {
    get_data();

    console.log(countryArray);

    mapboxgl.accessToken = '***';
    var map = new mapboxgl.Map({
        container: 'map_area',
        style: 'mapbox://styles/mapbox/dark-v10',
        center: [4.899, 52.372],
        zoom: 2,
    });

    map.scrollZoom.disable();


    map.on('load', function() {
            map.addSource('world_countries', {
                type: 'geojson',
                data: 'world.geojson'
            });

            map.addLayer({
                'id': 'world_countries_fill',
                'type': 'fill',
                'source': 'world_countries',
                'paint': {
                    'fill-color': '#f08',
                    'fill-opacity': 0.4
                }
                //color function here
                /*
                'fill-color': function() {
                    let length = countryArray.length;

                    for(let i = 0; i &lt; length; i++) {
                        let country = countryArray[i];
                        let color = getColorDeaths(country.deaths)
                    }
                    return color;
                },
                */
            });
    });


}

function getColorDeaths(d) {
    return d &gt; 500000 ? '#800026' :
            d &gt; 350000  ? '#BD0026' :
            d &gt; 150000  ? '#E31A1C' :
            d &gt; 85000  ? '#FC4E2A' :
            d &gt; 25000   ? '#FD8D3C' :
            d &gt; 8500   ? '#FEB24C' :
            d &gt; 950   ? '#FED976' :
                        '#FFEDA0';
}

//fetchs data from the source and calls load_country_data on the json file
function get_data() {
    fetch(""https://pomber.github.io/covid19/timeseries.json"")
        .then(response =&gt; response.json())
        .then(data =&gt; {
            //console.log(data); //will print the json object
            load_country_data(data);
        })
        .catch(err =&gt; console.error(err));
}

//creates a Country object from each key in the json data fetched and appends the object to an array.
function load_country_data(data) {
    let json_Length = Object.keys(data).length; //amount of countrys
    let c_keys = Object.keys(data); //list of the keys
    //console.log(json_Length);

    for(let i = 0; i &lt; json_Length; i++) {
        let tmp = new Country(); // create new Country object for each country
        let name = c_keys[i] //get the name of the country
        let length = data[name].length; //get the length from inside the country

        let tmp_deaths = 0;
        let tmp_recovered = 0;
        let tmp_confirmed = 0;

        //console.log(test[i]); // &lt;this is how you would get the name of each country as a string
        //console.log(data['Angola']); // &lt;this is how you get to each country

        //console.log(data[name][4]);
        //console.log(data[name][4].deaths);

        for(let i = 0; i &lt; length; i++) {
            tmp_deaths += data[name][i].deaths;
            tmp_recovered += data[name][i].recovered;
            tmp_confirmed += data[name][i].confirmed;
        }

        //fill in the country object with the data!
        tmp.name = name;
        tmp.death = tmp_deaths;
        tmp.confirmed = tmp_confirmed;
        tmp.recovered = tmp_recovered;

        countryArray.push(tmp); //add the new object to an array to keep track
    }
}



window.onload = init;
</code></pre>
"
60734586,"<p>I have a simple app for displaying data. The state changes from a select. However I want the default select option to be united kingdom. Currently the option defaults to Afghanistan as it's the first in the alphabet. </p>

<pre class=""lang-js prettyprint-override""><code>export default function CountrySelect() {
  const [country, setCountry] = useState('GBR');
  const countries = useFetch('https://covid19.mathdro.id/api/countries');

  if (!countries) return null;

  const countryArr = Object.entries(countries.countries).map(([key, value]) =&gt; {
    return {
      name: `${key}`,
      code: `${value}`
    };
  });

  return (
    &lt;div&gt;
      &lt;h2&gt;Showing: {country}&lt;/h2&gt;
      &lt;select
        onChange={(event) =&gt; setCountry(event.target.value)}
        defaultValue={country}&gt;
        {countryArr.map((country) =&gt; (
          &lt;option value={country.code} key={country.name}&gt;
            {country.name}
          &lt;/option&gt;
        ))}
      &lt;/select&gt;
      &lt;Info url={`https://covid19.mathdro.id/api/countries/${country}`}&gt;&lt;/Info&gt;
    &lt;/div&gt;
  );
}
</code></pre>

<p>To clarify the country state is 'GBR' and data from 'GBR' or United Kingdom is displayed. It's the  tag  which I'm having the issue with.</p>
"
61549150,"<p>I'm developing a dashboard for use with covid19. And I tried to use <code>charts.js</code> but when using <code>charts.js</code>, it works fine with numeric data, but it doesn't work when I pass the variable names of those numeric values.</p>

<p>What is the solution?</p>

<pre><code>import { Component, OnInit } from '@angular/core';
import { Idetails } from './classes/Idetails';
import { Services } from './Services/services.component';
import { from } from 'rxjs';
import { Key } from 'protractor';
import { ValueShaper } from '../app/shared/valueShaper.component';
import { Chart } from 'node_modules/chart.js';

@Component({
  selector: 'app-root',
  templateUrl: './app.component.html',
  styleUrls: ['./app.component.css']
})
export class AppComponent implements OnInit {
  title = 'covidDashboard';
  Details: Idetails[];
  errorMessage: string;
  filteredData: Idetails[];
  localNewCases: any;
  localActiveCases: any;
  localTotalCases: any;
  localDeaths: any;
  localRecovered: any;
  localTotalIndividualsHospitals: any;
  globalNewCases: any;
  globalTotalCases: any;
  totalGlobalDeaths: any;
  globalNewDeaths: any;
  globalRecovered: any;
  updatedTime: any;
</code></pre>

<p>Here I have declared the values used for the chart</p>

<pre><code>  val1: string;
  val2: string;
  intVal1: number;
  intVal2: number;

  constructor(private serviceInstance: Services, private pipeInstance: ValueShaper) 
  {
  }

  ngOnInit() {
    this.serviceInstance.getData().subscribe({
      next: Data =&gt; {
        this.Details = Data;
        this.filteredData = Object.keys(Data).map(key =&gt; Data[key]);

        this.localNewCases = this.filteredData.map(a =&gt; a.local_new_cases);
        this.localActiveCases = this.filteredData.map(a =&gt; a.local_active_cases);
        this.localTotalCases = this.filteredData.map(a =&gt; a.local_total_cases);
        this.localDeaths = this.filteredData.map(a =&gt; a.local_deaths);
        this.localRecovered = this.filteredData.map(a =&gt; a.local_recovered);
        this.localTotalIndividualsHospitals = this.filteredData.map(a =&gt; a.local_total_number_of_individuals_in_hospitals);
        this.globalNewCases = this.filteredData.map(a =&gt; a.global_new_cases);
        this.globalTotalCases = this.filteredData.map(a =&gt; a.global_total_cases);
        this.totalGlobalDeaths = this.filteredData.map(a =&gt; a.global_deaths);
        this.globalNewDeaths = this.filteredData.map(a =&gt; a.global_new_deaths);
        this.globalRecovered = this.filteredData.map(a =&gt; a.global_recovered);
        this.updatedTime = this.filteredData.map(a =&gt; a.update_date_time);
</code></pre>

<p>Values are assigned to the variables</p>

<pre><code>    this.val1 = this.pipeInstance.transform(this.localTotalCases);
    this.val2 = this.pipeInstance.transform(this.localRecovered);
    this.intVal1 = parseInt(this.val1, 10);
    this.intVal2 = parseInt(this.val2, 10);
    console.log(this.intVal1); //prints the numeric values
    console.log(this.intVal2); //prints the numeric values

      },
      error: err =&gt; this.errorMessage = err
    }
    );   

    var myChart = new Chart(""myChart"", {
      type: 'pie',
      data: {
        labels: ['Total Cases', 'Recovered Count'],
        datasets: [{
          label: '# of Votes',
</code></pre>

<p>Here I have tried to use the variable names.</p>

<pre><code> data: [this.intVal1, this.intVal2],
          backgroundColor: [
            'rgba(255, 99, 132, 0.2)',
            'rgba(54, 162, 235, 0.2)'
          borderColor: [
            'rgba(255, 99, 132, 1)',
            'rgba(54, 162, 235, 1)'
          borderWidth: 1
        }]
      },
      options: {
        scales: {
          yAxes: [{
            ticks: {
              beginAtZero: true
            }
          }]
        }
      }
    });
  }

}
</code></pre>
"
60712900,"<p>I have scraped/requested data from a website with the <code>table-scraper</code>.</p>

<pre><code>const scraper = require ('table-scraper');

const getData = async () =&gt; {
    scraper
  .get('https://www.mags.nrw/coronavirus-fallzahlen-nrw')
  .then(function(tableData) {
      console.log(tableData);    
  });
}

test = getData();
console.log(test)

exports.handler = async (event) =&gt; {
    const csv = await getData();
    return {
        statusCode: 200,
        body: csv
    };
}
</code></pre>

<p>The output I get are json object from a table.</p>

<p><a href=""https://www.mags.nrw/coronavirus-fallzahlen-nrw"" rel=""nofollow noreferrer"">https://www.mags.nrw/coronavirus-fallzahlen-nrw</a></p>

<p>How can I transfer the json objects into a csv. My final goal is to have the csv data in an endpoint.</p>
"
60689242,"<p>I have tbody that have a list, </p>

<p>here's the website: <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a></p>

<p><a href=""https://i.stack.imgur.com/uv5uG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uv5uG.png"" alt=""enter image description here""></a></p>

<p>the child number change every some hours</p>

<p>i tried to search for the word that is in tr</p>

<pre><code>var word = ""Tunisia"",
    queue = [document.body],
    curr
;
while (curr = queue.pop()) {
    if (!curr.textContent.match(word)) continue;
    for (var i = 0; i &lt; curr.childNodes.length; ++i) {
        switch (curr.childNodes[i].nodeType) {
            case Node.TEXT_NODE : // 3
                if (curr.childNodes[i].textContent.match(word)) {
                    console.log(""Found!"");
                    console.log(curr);
                    // you might want to end your search here.
                }
                break;
            case Node.ELEMENT_NODE : // 1
                queue.push(curr.childNodes[i]);
                if (curr.childNodes[i].textContent.match(word)) {
 }
                break;
        }
    }
}
</code></pre>

<p>but i don't know how to find the child number after i found the line</p>

<p>for now, it's 81</p>

<p>for exemple:</p>

<pre><code>document.querySelector(""#main_table_countries &gt; tbody:nth-child(2) &gt; tr:nth-child(81) &gt; td:nth-child(3)"").innerText
</code></pre>

<p>Sorry, for the bad english and explantation !</p>
"
61705944,"<p>I am making a basic coronavirus tracker application where my incoming data looks like this: </p>

<pre><code>    [
{
""provinceName"": ""Canada"",
""confirmedCases"": ""66,780"",
""probableCases"": ""0"",
""deaths"": ""4,628""
},
{
""provinceName"": ""Newfoundland and Labrador"",
""confirmedCases"": ""261"",
""probableCases"": ""0"",
""deaths"": ""3""
},
{
""provinceName"": ""Prince Edward Island"",
""confirmedCases"": ""27"",
""probableCases"": ""0"",
""deaths"": ""0""
},
{
""provinceName"": ""Nova Scotia"",
""confirmedCases"": ""1,008"",
""probableCases"": ""0"",
""deaths"": ""46""
},
{
""provinceName"": ""New Brunswick"",
""confirmedCases"": ""120"",
""probableCases"": ""0"",
""deaths"": ""0""
},
{
""provinceName"": ""Quebec"",
""confirmedCases"": ""36,150"",
""probableCases"": ""0"",
""deaths"": ""2,725""
},
{
""provinceName"": ""Ontario"",
""confirmedCases"": ""19,944"",
""probableCases"": ""0"",
""deaths"": ""1,599""
},
{
""provinceName"": ""Manitoba"",
""confirmedCases"": ""284"",
""probableCases"": ""0"",
""deaths"": ""7""
},
{
""provinceName"": ""Saskatchewan"",
""confirmedCases"": ""544"",
""probableCases"": ""0"",
""deaths"": ""6""
},
{
""provinceName"": ""Alberta"",
""confirmedCases"": ""6,098"",
""probableCases"": ""0"",
""deaths"": ""115""
},
{
""provinceName"": ""British Columbia"",
""confirmedCases"": ""2,315"",
""probableCases"": ""0"",
""deaths"": ""127""
},
{
""provinceName"": ""Yukon"",
""confirmedCases"": ""11"",
""probableCases"": ""0"",
""deaths"": ""0""
},
{
""provinceName"": ""Northwest Territories"",
""confirmedCases"": ""5"",
""probableCases"": ""0"",
""deaths"": ""0""
},
{
""provinceName"": ""Nunavut"",
""confirmedCases"": ""0"",
""probableCases"": ""0"",
""deaths"": ""0""
},
{
""provinceName"": ""Repatriated travellers"",
""confirmedCases"": ""13"",
""probableCases"": ""0"",
""deaths"": ""0""
}
]
</code></pre>

<p>I am rendering it to a React svg map where i am expecting the data as multiple arrays inside one array like this: </p>

<pre><code>data: [
  [""PE"", 67],
  [""MB"", 75],
  [""SK"", 43],
  [""AB"", 50],
  [""BC"", 88],
  [""NU"", 21],
  [""NT"", 43],
  [""YT"", 21],
  [""QC"", 60],
  [""ON"", 19],
  [""NB"", 4],
  [""NS"", 44],
  [""NF"", 38],
],`enter code here`
</code></pre>

<p>I am trying to update the state data after i fetch the json from axios, i am trying to process it in componentDidUpdate to get it in the desired format. But when i am trying to set the state inside componentDidUpdate() it os not working, I want the fetched data in the above mentioned format.
How can i set the dataArray to data(state)?</p>

<p>Here is the React class</p>

<pre><code>import React, { Component } from ""react"";
import ChoroplethMap from ""../ChoroplethMap"";
import axios from ""axios"";

class Canada extends Component {
  state = {
    data: [
      // [""PE"", 67],
      // [""MB"", 75],
      // [""SK"", 43],
      // [""AB"", 50],
      // [""BC"", 88],
      // [""NU"", 21],
      // [""NT"", 43],
      // [""YT"", 21],
      // [""QC"", 60],
      // [""ON"", 19],
      // [""NB"", 4],
      // [""NS"", 44],
      // [""NF"", 38],
    ],
    isLoaded: false,
    rawdata: [],
    isDataSet: false,
  };
  getData() {
    axios
      .get(""http://localhost:8080/h3"")
      .then(response =&gt;
        response.data.map(data =&gt; ({
          provinceName: `${data.provinceName}`,
          confirmedCases: `${data.confirmedCases}`,
          probableCases: `${data.probableCases}`,
          deaths: `${data.deaths}`
        }))
      )
      .then(rawdata =&gt; {
        this.setState({
          rawdata,
          isLoaded: true
        });
      })
      .catch(err =&gt; {
        console.log(err);
      });

  }

  componentDidMount() {
    this.getData();
  }
  componentDidUpdate() {
    if (this.state.isLoaded === true) {
      let dataArray = [];
      let insideArray;
      this.state.rawdata.forEach(element =&gt; {
        if (element.provinceName !== ""Canada"") {
          insideArray = new Array();
          var sexy = parseInt(element.confirmedCases.replace("","", """"));
          var provinceName = element.provinceName;
          if (provinceName === ""New Brunswick"") {
            insideArray.push(""NB"");
            insideArray.push(sexy);
          } else if (provinceName === ""Manitoba"") {
            insideArray.push(""MB"");
            insideArray.push(sexy);
          } else if (provinceName === ""Newfoundland and Labrador"") {
            insideArray.push(""NF"");
            insideArray.push(sexy);
          } else if (provinceName === ""Nova Scotia"") {
            insideArray.push(""NS"");
            insideArray.push(sexy);
          } else if (provinceName === ""Saskatchewan"") {
            insideArray.push(""SK"");
            insideArray.push(sexy);
          } else if (provinceName === ""Alberta"") {
            insideArray.push(""AB"");
            insideArray.push(sexy);
          } else if (provinceName === ""Prince Edward Island"") {
            insideArray.push(""PE"");
            insideArray.push(sexy);
          } else if (provinceName === ""Quebec"") {
            insideArray.push(""QC"");
            insideArray.push(sexy);
          } else if (provinceName === ""Ontario"") {
            insideArray.push(""ON"");
            insideArray.push(sexy);
          } else if (provinceName === ""British Columbia"") {
            insideArray.push(""BC"");
            insideArray.push(sexy);
          } else if (provinceName === ""Yukon"") {
            insideArray.push(""YT"");
            insideArray.push(sexy);
          } else if (provinceName === ""Northwest Territories"") {
            insideArray.push(""NT"");
            insideArray.push(sexy);
          } else if (provinceName === ""Nunavut"") {
            insideArray.push(""NU"");
            insideArray.push(sexy);
          } else if (provinceName === ""Northwest Territories"") {
            insideArray.push(""NT"");
            insideArray.push(sexy);
          }
          dataArray.push(insideArray);
        }
      });
      dataArray.pop();
      if (this.state.isDataSet == false) {

        this.setState({
          data: [...this.state.data, ...dataArray],
          isDataSet: true,
        });
      }
    }
  }

  render() {
    return (
      &lt;div
        style={{
          height: ""100vh"",
          width: ""100vw""
        }}
      &gt;
        &lt;ChoroplethMap data={this.state.data} /&gt;
      &lt;/div&gt;
    );
  }
}

export default Canada;
</code></pre>
"
60823697,"<p>I'm trying to make a database (that is bot-protected) that people submit bizarre and crazy news headlines about COVID-19. However, I have yet to find a way to make sure that the content that people submit is not naughty and is genuine content. I need a way (programatically) to make sure a link is a news article. Is there any way to do this? Thank you.</p>
"
60755202,"<p>I'm trying to scrape data from a table <a href=""https://www.ochealthinfo.com/phs/about/epidasmt/epi/dip/prevention/novel_coronavirus"" rel=""nofollow noreferrer"">listed on this website.</a> I am able to scrape the <code>updateDate</code>, but I'm having an issue with columns and rows.</p>

<p>The table I am trying to scrape is nested in a <code>td</code> with an id of <code>col2</code>.</p>

<p><strong>My Issue:</strong></p>

<p>I can't seem to figure out how to correctly query the rows, so I can get all of the numbers data (Each row an array of strings);</p>

<p><a href=""https://i.stack.imgur.com/wM8nW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wM8nW.png"" alt=""enter image description here""></a></p>

<p><strong>Table (From Inspector):</strong></p>

<p><a href=""https://i.stack.imgur.com/04rPk.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/04rPk.png"" alt=""enter image description here""></a></p>

<p><strong>My Code:</strong></p>

<pre><code>// Find Table Rows
console.log('Searching for COVID-19 Data from Orange County');

// Table Rows
let tableRows = await page.$$('#col2 &gt; div &gt; table &gt; tbody &gt; tr');
// console.log(tableRows);

// Check For Table Rows
if (tableRows.length &gt; 0) {
  console.log('Table Rows found');

  // Update Date (Length: 10)
  if (await tableRows[2].$$('tr &gt; td')) {
    // Assign Element (First Row)
    let updateField = String(await tableRows[2].$eval('tr &gt; td', td =&gt; td.innerText.trim()));

    // Check If Matches
    if (updateField.match(/(as of [0-9][0-9]\/[0-9][0-9]\/[0-9][0-9][0-9][0-9])/)) {
      const updateDate = updateField.slice(51, updateField.length - 1).trim();
      console.log(`Update Date: ${updateDate}`);
    }
    else {
      throw error('Error: Update Date doesn\'t match format');
    } 
  }

  // Cases
  if (await tableRows[5].$$('tr &gt; td')) {
    // Assign Element (First Row)
    let totalCasesField = String(await tableRows[5].$eval('tr &gt; td', td =&gt; td.innerText.trim()));
    console.log(totalCasesField);
  }
</code></pre>
"
60991615,"<p>when we try to post some messages/photos on the Facebook group, we are able to tag up to five topics on Facebook.</p>

<p>The same we can able to see on the right pane under the topics section as <strong>""see all topics"", ""popular topics"", ""other topics""</strong></p>

<p>How can I get that information through graph API?</p>

<p>at least for a single post, we need to get the tagged info right?</p>

<p>I am trying for a single post to get the topic tag information. I tried searching for all the developer docs. But I am left helpless</p>

<h2>sample format:</h2>

<p><em>Message</em>: <strong>The world is under panic of COVID 19</strong>  </p>

<p><em>Message topic tag</em>: <strong>COVID 19, panic, virus</strong></p>

<p>How can we get those tags using graph API?</p>

<h2>tried the following:</h2>

<p><code>https://graph.facebook.com/v6.0/{group-id}/feed</code><br>
<code>https://graph.facebook.com/v6.0/{group-id_feed-id}?field = action,messagetag,message,placetag,palce</code>
<code>https://graph.facebook.com/v6.0/{photo-id}/tags</code><br>
<code>https://graph.facebook.com/v6.0/{group-id}/sponsor_tags</code><br>
<code>https://graph.facebook.com/v6.0/{group-id_feed-id}/attachments</code></p>
"
60877550,"<p>With the wake of the pandemic causing schools to go to distance learning, many classes take attendance by using a simple google form sent out to students to complete for each class everyday. While this seems like a simple solution, it is a pain for students to complete and keep track of. One way that I thought I could make this easier would be to keep track of which forms I have submitted everyday. </p>

<p>As of now, my problem is that I need a way to subscribe to the submit of a google form (based on a link). When that google form is submitted all I need to do is find a way to convey that to a program. What I do not understand is how I would be able to do that without having ownership of the form or make a teacher recreate the form. Is there a way that I can check if a google form has been submitted?</p>

<p>A couple of ideas I have had would be to sniff network traffic for a post request from a google form and get that link and compare it to other links in the program to see which one was submitted, but I would think there is an easier way to do this. Any ideas or code is welcomed. </p>

<p><em>I  understand stack overflow is for already written code so if you do not agree with this post either ignore it or point me to the correct place where this should be posted. Thank you.</em></p>
"
61465295,"<p>i just installed a new react project with <code>npx create-react-app</code> when i start dev server the first time i make a change on app.js file it reloads on the browser but after that nothing auto reloads and even when i manualy refresh the page nothing changes. i also installed axios react-countup and react-charts-2 if it matters somehow
my package.json file: </p>

<pre><code> {
  ""name"": ""covid19"",
  ""version"": ""0.1.0"",
  ""private"": true,
  ""dependencies"": {
    ""axios"": ""^0.19.2"",
    ""classnames"": ""^2.2.6"",
    ""react"": ""^16.13.1"",
    ""react-chartjs-2"": ""^2.9.0"",
    ""react-countup"": ""^4.3.3"",
    ""react-dom"": ""^16.13.1"",
    ""react-scripts"": ""0.9.5""
  },
  ""devDependencies"": {},
  ""scripts"": {
    ""start"": ""react-scripts start"",
    ""build"": ""react-scripts build"",
    ""test"": ""react-scripts test --env=jsdom"",
    ""eject"": ""react-scripts eject""
  }
}
</code></pre>
"
61300071,"<p>Guys i know this already asked many times, but i still don't get how to solve my problem. So what i want to do is display some nested JSON data to HTML table. </p>

<p>So <a href=""https://api.covid19api.com/summary"" rel=""nofollow noreferrer"">this</a> is the JSON i fetch.  </p>

<p>and this is my reactjs code:</p>

<pre><code> var [infectionData, setInfectionData] = useState({
    response: []

  });

 var [isLoaded, setLoaded] = useState(false);

 useEffect(() =&gt; {

    var fetchData = async () =&gt; {
        var url = ""https://api.covid19api.com/summary"";

        var result = await axios.get(url);
        var response = result.data

        response = Array(response);

        setInfectionData({ response: response });

        console.log(infectionData.response);

    }

    fetchData();
    setLoaded(true);

});
</code></pre>

<p>and this is the HTML table: </p>

<pre><code>            &lt;Table bordered hover className=""mt-3 w-75""&gt;
                &lt;thead&gt;
                    &lt;tr&gt;
                        &lt;th&gt;Country&lt;/th&gt;
                        &lt;th&gt;Total Infection&lt;/th&gt;
                        &lt;th&gt;New Deaths&lt;/th&gt;
                    &lt;/tr&gt;
                &lt;/thead&gt;
                &lt;tbody&gt;
                    {
                        infectionData.response.Countries.map((item) =&gt; (
                            &lt;tr&gt;
                                &lt;td&gt;{item.Country}&lt;/td&gt;
                                &lt;td&gt;{item.TotalConfirmed}&lt;/td&gt;
                                &lt;td&gt;{item.NewDeaths}&lt;/td&gt;
                            &lt;/tr&gt;


                        ))
                    } 
                &lt;/tbody&gt;

            &lt;/Table&gt;
</code></pre>

<p>Any idea how to solve this ?</p>
"
61281430,"<p>Me and my friends are working in a map of Acre (Brazil state) to show informations about covid-19.
We are using React with Material Ui.
You can access the github repository: <a href=""https://github.com/arkanttus/Covid-Acre"" rel=""nofollow noreferrer"">https://github.com/arkanttus/Covid-Acre</a></p>

<p>The map is a svg file. We were trying to put the name of each city in the map, but we still haven't been successful.
The specific files that run map is <a href=""https://github.com/arkanttus/Covid-Acre/blob/master/front/src/components/Cities.js"" rel=""nofollow noreferrer"">Cities.js</a> and <a href=""https://github.com/arkanttus/Covid-Acre/blob/master/front/src/components/Mapa.js"" rel=""nofollow noreferrer"">Mapa.js</a></p>

<p>If anyone can help us show a simple code example, we would be grateful</p>
"
60685914,"<p>Recently with coronavirus, school is cancelled so I made a discord server for my class. People are not very familiar with Discord so I want a command that can selfmute people so that the course can start. I want everyone to be able to unmute if they want to ask a question to the teacher, hence the self-mute and not the server-mute.
I have tried this code but it's not working because the <em>.selfmute(true)</em> is made for the bot.</p>

<pre><code>const Discord = require('discord.js');
const client = new Discord.Client();
const config = require(""./config.json"");

const prefix = ""!"";
client.on(""message"", (message) =&gt; {
if (!message.content.startsWith(prefix)) return;

if (message.content.startsWith(prefix + ""mute"")) {
    let channel = message.member.voice.channel;
    for (let member of channel.members) {
        member[1].voice.setSelfMute(true);
    }
}
});

client.login(config.token);
</code></pre>

<p>Does anyone know how to do this ? Thanks for the help.</p>

<p>PS: sorry for my english, it's not my native language.</p>
"
61106163,"<p>The map renders and the color fill happens too, but only when a mouse enter event happens. 
How do I trigger it on load?
I am using react-simple-maps, the JSON data is valid as it loads the map when mouse enters.
Here is the source code - <a href=""https://github.com/pramanikriju/covid-19-tracker-india"" rel=""nofollow noreferrer"">Github</a></p>

<pre><code>  const [tooltipContent, setTooltipContent] = useState("""");

  const colorScale = scaleQuantile()
    .domain(props.data.map((d) =&gt; d.value))
    .range(COLOR_RANGE);

  const onMouseEnter = (geo, current = { value: ""NA"" }) =&gt; {
    return () =&gt; {
      setTooltipContent(`${geo.properties.name}: ${current.value}`);
    };
  };

  const onMouseLeave = () =&gt; {
    setTooltipContent("""");
  };
  return (
    &lt;div&gt;
      &lt;ReactTooltip&gt;{tooltipContent}&lt;/ReactTooltip&gt;

      &lt;ComposableMap
        projectionConfig={PROJECTION_CONFIG}
        projection=""geoMercator""
        width={700}
        height={600}
        data-tip=""""
      &gt;
        &lt;Geographies geography={INDIA_TOPO_JSON}&gt;
          {({ geographies }) =&gt;
            geographies.map((geo) =&gt; {
              const current = props.data.find((s) =&gt; {
                return s.id === geo.id;
              });
              return (
                &lt;Geography
                  key={geo.rsmKey}
                  geography={geo}
                  fill={current ? colorScale(current.value) : DEFAULT_COLOR}
                  style={geographyStyle}
                  onMouseEnter={onMouseEnter(geo, current)}
                  onMouseLeave={onMouseLeave}
                /&gt;
              );
            })
          }
        &lt;/Geographies&gt;
      &lt;/ComposableMap&gt;
    &lt;/div&gt;
  );
}
</code></pre>
"
61508826,"<p>I'm currently making use of the Vision API provided by Azure, and the output data that I get from the OCR Api looks like this....</p>

<pre><code>enter code here
</code></pre>

<p>{
  ""language"": ""es"",
  ""textAngle"": 0.0,
  ""orientation"": ""Up"",
  ""regions"": [{
    ""boundingBox"": ""11,14,437,515"",
    ""lines"": [{
      ""boundingBox"": ""12,14,394,17"",
      ""words"": [{
        ""boundingBox"": ""12,15,27,12"",
        ""text"": ""Con""
      }, {
        ""boundingBox"": ""44,18,26,9"",
        ""text"": ""una""
      }, {
        ""boundingBox"": ""75,16,43,11"",
        ""text"": ""careta""
      }, {
        ""boundingBox"": ""122,16,91,14"",
        ""text"": ""transparente""
      }, {
        ""boundingBox"": ""217,18,8,13"",
        ""text"": ""y""
      }, {
        ""boundingBox"": ""229,15,57,15"",
        ""text"": ""cargado""
      }, {
        ""boundingBox"": ""291,18,16,9"",
        ""text"": ""en""
      }, {
        ""boundingBox"": ""313,14,20,13"",
        ""text"": ""los""
      }, {
        ""boundingBox"": ""338,14,47,13"",
        ""text"": ""brazos""
      }, {
        ""boundingBox"": ""389,14,17,13"",
        ""text"": ""de""
      }]
    }, {
      ""boundingBox"": ""12,37,431,15"",
      ""words"": [{
        ""boundingBox"": ""12,37,44,14"",
        ""text"": ""Pedro,""
      }, {
        ""boundingBox"": ""61,40,16,9"",
        ""text"": ""su""
      }, {
        ""boundingBox"": ""82,37,43,15"",
        ""text"": ""padre,""
      }, {
        ""boundingBox"": ""129,37,35,12"",
        ""text"": ""José""
      }, {
        ""boundingBox"": ""169,37,31,14"",
        ""text"": ""Luis,""
      }, {
        ""boundingBox"": ""204,37,12,12"",
        ""text"": ""el""
      }, {
        ""boundingBox"": ""221,37,34,12"",
        ""text"": ""bebé""
      }, {
        ""boundingBox"": ""260,38,73,14"",
        ""text"": ""prematuro""
      }, {
        ""boundingBox"": ""337,40,26,9"",
        ""text"": ""con""
      }, {
        ""boundingBox"": ""368,40,25,9"",
        ""text"": ""una""
      }, {
        ""boundingBox"": ""398,37,45,12"",
        ""text"": ""madre""
      }]
    }, {
      ""boundingBox"": ""12,59,382,16"",
      ""words"": [{
        ""boundingBox"": ""12,59,78,16"",
        ""text"": ""contagiada""
      }, {
        ""boundingBox"": ""95,59,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""117,59,64,12"",
        ""text"": ""Covid-19""
      }, {
        ""boundingBox"": ""186,62,7,13"",
        ""text"": ""y""
      }, {
        ""boundingBox"": ""198,59,38,16"",
        ""text"": ""quien""
      }, {
        ""boundingBox"": ""240,59,52,12"",
        ""text"": ""falleció""
      }, {
        ""boundingBox"": ""297,59,59,16"",
        ""text"": ""después""
      }, {
        ""boundingBox"": ""361,59,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""383,59,11,12"",
        ""text"": ""la""
      }]
    }, {
      ""boundingBox"": ""12,81,227,16"",
      ""words"": [{
        ""boundingBox"": ""12,81,59,14"",
        ""text"": ""cesárea,""
      }, {
        ""boundingBox"": ""75,81,33,12"",
        ""text"": ""salió""
      }, {
        ""boundingBox"": ""113,81,20,12"",
        ""text"": ""del""
      }, {
        ""boundingBox"": ""138,81,50,16"",
        ""text"": ""Seguro""
      }, {
        ""boundingBox"": ""192,81,47,12"",
        ""text"": ""Social.""
      }]
    }, {
      ""boundingBox"": ""12,122,425,17"",
      ""words"": [{
        ""boundingBox"": ""12,123,49,12"",
        ""text"": ""Debido""
      }, {
        ""boundingBox"": ""66,126,8,9"",
        ""text"": ""a""
      }, {
        ""boundingBox"": ""78,126,26,13"",
        ""text"": ""que""
      }, {
        ""boundingBox"": ""109,123,47,12"",
        ""text"": ""estaba""
      }, {
        ""boundingBox"": ""161,126,30,13"",
        ""text"": ""muy""
      }, {
        ""boundingBox"": ""196,126,38,13"",
        ""text"": ""grave""
      }, {
        ""boundingBox"": ""239,126,49,13"",
        ""text"": ""porque""
      }, {
        ""boundingBox"": ""292,122,40,13"",
        ""text"": ""sufrió""
      }, {
        ""boundingBox"": ""337,123,87,16"",
        ""text"": ""preclampsia""
      }, {
        ""boundingBox"": ""429,128,8,2"",
        ""text"": ""—""
      }]
    }, {
      ""boundingBox"": ""12,145,413,16"",
      ""words"": [{
        ""boundingBox"": ""12,145,111,15"",
        ""text"": ""complicaciones""
      }, {
        ""boundingBox"": ""128,148,46,13"",
        ""text"": ""graves""
      }, {
        ""boundingBox"": ""179,148,16,9"",
        ""text"": ""en""
      }, {
        ""boundingBox"": ""200,145,12,12"",
        ""text"": ""el""
      }, {
        ""boundingBox"": ""217,145,70,12"",
        ""text"": ""embarazo""
      }, {
        ""boundingBox"": ""292,148,23,12"",
        ""text"": ""por""
      }, {
        ""boundingBox"": ""319,145,52,16"",
        ""text"": ""presión""
      }, {
        ""boundingBox"": ""376,145,49,12"",
        ""text"": ""arterial""
      }]
    }, {
      ""boundingBox"": ""12,166,425,16"",
      ""words"": [{
        ""boundingBox"": ""12,167,68,14"",
        ""text"": ""elevada—,""
      }, {
        ""boundingBox"": ""85,167,11,12"",
        ""text"": ""la""
      }, {
        ""boundingBox"": ""101,167,45,12"",
        ""text"": ""madre""
      }, {
        ""boundingBox"": ""150,166,23,13"",
        ""text"": ""fue""
      }, {
        ""boundingBox"": ""178,167,48,12"",
        ""text"": ""llevada""
      }, {
        ""boundingBox"": ""231,167,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""253,167,60,15"",
        ""text"": ""urgencia""
      }, {
        ""boundingBox"": ""318,167,43,12"",
        ""text"": ""desde""
      }, {
        ""boundingBox"": ""366,167,71,14"",
        ""text"": ""Monclova,""
      }]
    }, {
      ""boundingBox"": ""12,189,369,16"",
      ""words"": [{
        ""boundingBox"": ""12,189,44,12"",
        ""text"": ""donde""
      }, {
        ""boundingBox"": ""61,189,49,14"",
        ""text"": ""residía,""
      }, {
        ""boundingBox"": ""114,192,8,13"",
        ""text"": ""y""
      }, {
        ""boundingBox"": ""127,192,25,12"",
        ""text"": ""que""
      }, {
        ""boundingBox"": ""157,192,16,9"",
        ""text"": ""es""
      }, {
        ""boundingBox"": ""178,189,66,15"",
        ""text"": ""epicentro""
      }, {
        ""boundingBox"": ""248,189,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""270,189,11,12"",
        ""text"": ""la""
      }, {
        ""boundingBox"": ""286,189,70,16"",
        ""text"": ""pandemia""
      }, {
        ""boundingBox"": ""361,189,20,12"",
        ""text"": ""del""
      }]
    }, {
      ""boundingBox"": ""12,211,176,12"",
      ""words"": [{
        ""boundingBox"": ""12,211,84,12"",
        ""text"": ""coronavirus""
      }, {
        ""boundingBox"": ""101,214,16,9"",
        ""text"": ""en""
      }, {
        ""boundingBox"": ""122,211,66,12"",
        ""text"": ""Coahuila.""
      }]
    }, {
      ""boundingBox"": ""12,252,430,17"",
      ""words"": [{
        ""boundingBox"": ""12,252,17,13"",
        ""text"": ""\""El""
      }, {
        ""boundingBox"": ""35,252,51,15"",
        ""text"": ""infante,""
      }, {
        ""boundingBox"": ""91,253,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""113,256,58,9"",
        ""text"": ""escasos""
      }, {
        ""boundingBox"": ""176,253,17,12"",
        ""text"": ""18""
      }, {
        ""boundingBox"": ""198,252,29,13"",
        ""text"": ""días""
      }, {
        ""boundingBox"": ""232,252,17,13"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""253,252,51,15"",
        ""text"": ""nacido,""
      }, {
        ""boundingBox"": ""308,256,16,9"",
        ""text"": ""es""
      }, {
        ""boundingBox"": ""329,253,11,12"",
        ""text"": ""el""
      }, {
        ""boundingBox"": ""346,253,45,15"",
        ""text"": ""primer""
      }, {
        ""boundingBox"": ""396,252,24,17"",
        ""text"": ""hijo""
      }, {
        ""boundingBox"": ""425,253,17,12"",
        ""text"": ""de""
      }]
    }, {
      ""boundingBox"": ""12,274,432,17"",
      ""words"": [{
        ""boundingBox"": ""12,278,25,9"",
        ""text"": ""una""
      }, {
        ""boundingBox"": ""42,275,45,12"",
        ""text"": ""madre""
      }, {
        ""boundingBox"": ""92,274,65,13"",
        ""text"": ""infectada""
      }, {
        ""boundingBox"": ""162,278,25,9"",
        ""text"": ""con""
      }, {
        ""boundingBox"": ""192,275,83,12"",
        ""text"": ""coronavirus""
      }, {
        ""boundingBox"": ""280,278,16,9"",
        ""text"": ""en""
      }, {
        ""boundingBox"": ""301,275,11,12"",
        ""text"": ""el""
      }, {
        ""boundingBox"": ""318,275,29,16"",
        ""text"": ""país""
      }, {
        ""boundingBox"": ""351,278,8,13"",
        ""text"": ""y""
      }, {
        ""boundingBox"": ""363,275,11,12"",
        ""text"": ""él""
      }, {
        ""boundingBox"": ""379,275,30,12"",
        ""text"": ""está""
      }, {
        ""boundingBox"": ""414,275,30,12"",
        ""text"": ""libre""
      }]
    }, {
      ""boundingBox"": ""12,297,413,16"",
      ""words"": [{
        ""boundingBox"": ""12,297,20,12"",
        ""text"": ""del""
      }, {
        ""boundingBox"": ""37,297,43,14"",
        ""text"": ""virus\"",""
      }, {
        ""boundingBox"": ""84,297,57,12"",
        ""text"": ""destacó""
      }, {
        ""boundingBox"": ""146,297,11,12"",
        ""text"": ""la""
      }, {
        ""boundingBox"": ""162,297,77,16"",
        ""text"": ""delegación""
      }, {
        ""boundingBox"": ""244,297,20,12"",
        ""text"": ""del""
      }, {
        ""boundingBox"": ""270,297,57,12"",
        ""text"": ""Instituto""
      }, {
        ""boundingBox"": ""332,297,68,12"",
        ""text"": ""Mexicano""
      }, {
        ""boundingBox"": ""405,297,20,12"",
        ""text"": ""del""
      }]
    }, {
      ""boundingBox"": ""12,318,366,17"",
      ""words"": [{
        ""boundingBox"": ""12,319,49,16"",
        ""text"": ""Seguro""
      }, {
        ""boundingBox"": ""66,319,42,12"",
        ""text"": ""Social""
      }, {
        ""boundingBox"": ""114,318,51,17"",
        ""text"": ""(IMSS),""
      }, {
        ""boundingBox"": ""170,322,16,9"",
        ""text"": ""en""
      }, {
        ""boundingBox"": ""191,322,17,9"",
        ""text"": ""un""
      }, {
        ""boundingBox"": ""213,319,87,12"",
        ""text"": ""comunicado""
      }, {
        ""boundingBox"": ""305,319,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""327,322,51,13"",
        ""text"": ""prensa.""
      }]
    }, {
      ""boundingBox"": ""11,360,406,17"",
      ""words"": [{
        ""boundingBox"": ""11,361,55,15"",
        ""text"": ""Aunque""
      }, {
        ""boundingBox"": ""70,360,11,13"",
        ""text"": ""el""
      }, {
        ""boundingBox"": ""87,364,45,9"",
        ""text"": ""menor""
      }, {
        ""boundingBox"": ""136,362,47,11"",
        ""text"": ""estuvo""
      }, {
        ""boundingBox"": ""188,364,30,13"",
        ""text"": ""muy""
      }, {
        ""boundingBox"": ""222,364,42,13"",
        ""text"": ""grave,""
      }, {
        ""boundingBox"": ""268,360,23,13"",
        ""text"": ""fue""
      }, {
        ""boundingBox"": ""295,361,35,12"",
        ""text"": ""dado""
      }, {
        ""boundingBox"": ""335,361,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""356,360,26,13"",
        ""text"": ""alta""
      }, {
        ""boundingBox"": ""387,362,30,11"",
        ""text"": ""este""
      }]
    }, {
      ""boundingBox"": ""12,382,422,17"",
      ""words"": [{
        ""boundingBox"": ""12,384,50,11"",
        ""text"": ""martes""
      }, {
        ""boundingBox"": ""66,383,15,12"",
        ""text"": ""21""
      }, {
        ""boundingBox"": ""88,383,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""110,383,29,12"",
        ""text"": ""abril""
      }, {
        ""boundingBox"": ""145,383,20,12"",
        ""text"": ""del""
      }, {
        ""boundingBox"": ""170,383,58,16"",
        ""text"": ""Hospital""
      }, {
        ""boundingBox"": ""234,383,53,12"",
        ""text"": ""General""
      }, {
        ""boundingBox"": ""292,383,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""313,383,35,12"",
        ""text"": ""Zona""
      }, {
        ""boundingBox"": ""353,382,42,17"",
        ""text"": ""(HGZ)""
      }, {
        ""boundingBox"": ""400,383,24,12"",
        ""text"": ""No.""
      }, {
        ""boundingBox"": ""429,383,5,12"",
        ""text"": ""1""
      }]
    }, {
      ""boundingBox"": ""12,404,135,13"",
      ""words"": [{
        ""boundingBox"": ""12,404,17,13"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""34,405,36,12"",
        ""text"": ""IMSS""
      }, {
        ""boundingBox"": ""75,408,16,9"",
        ""text"": ""en""
      }, {
        ""boundingBox"": ""96,405,51,12"",
        ""text"": ""Saltillo.""
      }]
    }, {
      ""boundingBox"": ""12,447,415,16"",
      ""words"": [{
        ""boundingBox"": ""12,447,24,12"",
        ""text"": ""Por""
      }, {
        ""boundingBox"": ""40,450,16,9"",
        ""text"": ""su""
      }, {
        ""boundingBox"": ""62,448,39,14"",
        ""text"": ""parte,""
      }, {
        ""boundingBox"": ""106,450,16,9"",
        ""text"": ""su""
      }, {
        ""boundingBox"": ""127,447,43,15"",
        ""text"": ""padre,""
      }, {
        ""boundingBox"": ""174,450,26,12"",
        ""text"": ""que""
      }, {
        ""boundingBox"": ""205,447,44,15"",
        ""text"": ""quedó""
      }, {
        ""boundingBox"": ""253,447,41,14"",
        ""text"": ""viudo,""
      }, {
        ""boundingBox"": ""299,450,25,9"",
        ""text"": ""con""
      }, {
        ""boundingBox"": ""329,450,26,9"",
        ""text"": ""una""
      }, {
        ""boundingBox"": ""360,447,24,16"",
        ""text"": ""hija""
      }, {
        ""boundingBox"": ""389,447,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""411,447,16,12"",
        ""text"": ""IO""
      }]
    }, {
      ""boundingBox"": ""12,468,403,17"",
      ""words"": [{
        ""boundingBox"": ""12,469,37,14"",
        ""text"": ""años,""
      }, {
        ""boundingBox"": ""54,469,30,12"",
        ""text"": ""está""
      }, {
        ""boundingBox"": ""89,469,98,15"",
        ""text"": ""desempleado,""
      }, {
        ""boundingBox"": ""192,472,31,12"",
        ""text"": ""pero""
      }, {
        ""boundingBox"": ""228,469,70,16"",
        ""text"": ""agradeció""
      }, {
        ""boundingBox"": ""303,469,19,12"",
        ""text"": ""las""
      }, {
        ""boundingBox"": ""327,470,66,11"",
        ""text"": ""muestras""
      }, {
        ""boundingBox"": ""398,468,17,13"",
        ""text"": ""de""
      }]
    }, {
      ""boundingBox"": ""12,491,436,16"",
      ""words"": [{
        ""boundingBox"": ""12,491,44,12"",
        ""text"": ""cariño""
      }, {
        ""boundingBox"": ""60,491,20,12"",
        ""text"": ""del""
      }, {
        ""boundingBox"": ""86,491,60,15"",
        ""text"": ""personal""
      }, {
        ""boundingBox"": ""151,491,17,12"",
        ""text"": ""de""
      }, {
        ""boundingBox"": ""173,491,11,12"",
        ""text"": ""la""
      }, {
        ""boundingBox"": ""190,491,72,12"",
        ""text"": ""institución""
      }, {
        ""boundingBox"": ""267,494,26,13"",
        ""text"": ""que""
      }, {
        ""boundingBox"": ""298,491,38,12"",
        ""text"": ""cuidó""
      }, {
        ""boundingBox"": ""341,494,8,9"",
        ""text"": ""a""
      }, {
        ""boundingBox"": ""354,494,16,9"",
        ""text"": ""su""
      }, {
        ""boundingBox"": ""375,491,61,16"",
        ""text"": ""pequeño""
      }, {
        ""boundingBox"": ""440,494,8,13"",
        ""text"": ""y""
      }]
    }, {
      ""boundingBox"": ""12,513,179,16"",
      ""words"": [{
        ""boundingBox"": ""12,513,12,12"",
        ""text"": ""lo""
      }, {
        ""boundingBox"": ""29,513,60,16"",
        ""text"": ""despidió""
      }, {
        ""boundingBox"": ""93,516,26,9"",
        ""text"": ""con""
      }, {
        ""boundingBox"": ""124,513,67,16"",
        ""text"": ""aplausos.""
      }]
    }]
  }]
}</p>

<p>However, I have tried a dozen different ways to only parse the values from the ""text"" object and place it onto a single variable string.</p>

<p>trying to get the data like this is just not possible. </p>

<pre><code>var text = data.regions[0].lines[0].words[0].text;
        console.log('text: '+text);
</code></pre>

<p>Almost like parsing a line at a time. Makes no sense.</p>

<p>I used to have a ""needle in the stack"" script which did the job, but their PHP sdk was left or abandoned in Github, so do you kindle know a way to get only the values I want using javascript or jquery?</p>

<p>thanks so much and stay safe.</p>

<p>NOTE: By the way, this API works great for texts in Spanish, whereas other services don't recognize the accented latin characters. Thanks.</p>
"
60606949,"<p>I am trying to <strong>scrape data from a table in a website which has constantly changing values</strong>. So each row can vary day to day but I want to be able to scrape the correct data. I am using the Cheerio library at the moment and I am not familiar with it but here's what I have:</p>

<pre><code>const rp = require(""request-promise"");
const cheerio = require(""cheerio"");

let Italy = """";

async function main() {
    const result = await rp.get(""https://www.worldometers.info/coronavirus/"");
    const $ = cheerio.load(result);

    $(""#main_table_countries &gt; tbody:nth-child(2) &gt; tr:nth-child(2)"").each((i,el) =&gt; {
        const item = $(el).text();
        Italy = item;
    });
}
</code></pre>

<p>So, as you can see this scrapes data from the worldometer website for the coronavirus cases in Italy. Italy's position however has been changing between 2 and 3 over the past few days. This has resulted in my program fetching the wrong information. This is what I would like to fix.</p>

<p>Here's the link to the worldometer website:
<a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a></p>

<p>Thanks,
Karthik</p>
"
60792548,"<p>I'm working on making an interactive SVG map like the one on <a href=""https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/cases-in-us.html"" rel=""nofollow noreferrer"">this CDC page</a>. Within my SVG map component I have several path elements that each have a <code>name</code> attribute corresponding to the name of the state they represent, as well as a bound class function that I want to compute for that state, like as follows:</p>

<pre class=""lang-html prettyprint-override""><code>&lt;template&gt;
  &lt;svg&gt;
    &lt;path name=""New York"" :class=""computeClass"" /&gt;
    &lt;path name=""California"" :class=""computeClass"" /&gt;
    &lt;!-- etc --&gt;
  &lt;/svg&gt;
&lt;/template&gt;
</code></pre>

<p>This is probably trivial but is there a way I can pass the <code>name</code> attribute of the element as a parameter into the function <code>computeClass()</code> it calls? Like</p>

<pre class=""lang-html prettyprint-override""><code>&lt;path name=""New York"" :class=""computeClass(this.name)"" /&gt;
</code></pre>

<p>or something along those lines?</p>

<p>Thank you!</p>
"
60780363,"<p>I am attempting to customize the color of default <a href=""https://datatables.net/"" rel=""nofollow noreferrer"">Datatables</a>. I managed to change the color of the header as i desire and the font but I am not change color of each column. For instance I have column that reports total deaths and I want it to be red. At the same time i want to make sure my header color stays fixed.</p>

<p>MY HTML CODE</p>

<pre><code>&lt;table id=""myTable""&gt;&lt;/table&gt;
    &lt;div id=""loadingLabel""&gt;Loading...&lt;/div
</code></pre>

<p>JS CODE</p>

<pre><code>const getNewCases = async() =&gt; {
  const response = await fetch('https://covid19.mathdro.id/api/daily/3-18-2020');
  const data = await response.json();
  let usa = data.filter(val =&gt; {
    return val.countryRegion === 'US';
  });
  $('#loadingLabel').hide();
  $('#myTable').DataTable({
    data: usa,
    bLengthChange: false,
    bPaginate: false,
    scrollY:        '50vh',
    columns: [
      { data: 'provinceState', title: 'State' },
      { data: 'countryRegion', title: 'Country' },
      { data: 'lastUpdate', title: 'Last Update' },
      { data: 'confirmed', title: 'Confirmed' },
      { data: 'deaths', title: 'Deaths' },
      { data: 'recovered', title: 'Recovered' }
    ]
  });
};
getNewCases();
</code></pre>

<p>CSS Code</p>

<pre><code>thead {
  background-color: #2c3e4f;
  font-family: monospace;
  font-size: 20px;
  color: wheat;
}
</code></pre>

<p>Here is my <a href=""https://jsfiddle.net/4qa3502L/1/"" rel=""nofollow noreferrer"">JSFIDDLE</a>.</p>
"
60781863,"<p><strong>Background</strong></p>

<p>I am using <a href=""/questions/tagged/datatables"" class=""post-tag"" title=""show questions tagged &#39;datatables&#39;"" rel=""tag"">datatables</a> to fetch data from an api and display it. 
I want to add a column on the fly that is a sum of two other columns.
For instance say i want to create a column called ""random"" that adds up data from
column confirmed and death how would i do it?</p>

<p><strong>HTML CODE</strong></p>

<pre><code>&lt;table id=""myTable""&gt;&lt;/table&gt;
    &lt;div id=""loadingLabel""&gt;Loading...&lt;/div&gt;
</code></pre>

<p><strong>JS CODE</strong></p>

<pre><code>const getNewCases = async() =&gt; {
  const response = await fetch('https://covid19.mathdro.id/api/daily/3-18-2020');
  const data = await response.json();
  let usa = data.filter(val =&gt; {
    return val.countryRegion === 'US';
  });
  $('#loadingLabel').hide();
  $('#myTable').DataTable({
    data: usa,
    bLengthChange: false,
    bPaginate: false,
    scrollY:        '50vh',
    columns: [
      { data: 'provinceState', title: 'State' },
      { data: 'countryRegion', title: 'Country' },
      { data: 'lastUpdate', title: 'Last Update' },
      { data: 'confirmed', title: 'Confirmed' },
      { data: 'deaths', title: 'Deaths' },
      { data: 'recovered', title: 'Recovered' }
    ]
  });
};
getNewCases();
</code></pre>

<p>Here is <a href=""https://jsfiddle.net/x3742vrn/"" rel=""nofollow noreferrer"">JSFIDDLE</a></p>
"
60823804,"<p>I am trying to adjust the width of my header and columns because i plan to show the table on a mobile device. The column definitely got smaller by using the following:</p>

<pre><code>columns: [
  { data: 'provinceState', title: 'State', width: '2px' },
  { data: 'countryRegion', title: 'Country', width: '2px' }
]
</code></pre>

<p>MY JS CODE</p>

<pre><code>const getNewCases = async() =&gt; {
  const response = await fetch('https://covid19.mathdro.id/api/daily/3-18-2020');
  const data = await response.json();
  let usa = data.filter(val =&gt; {
    return val.countryRegion === 'US';
  });
  $('#loadingLabel').hide();
  $('#myTable').DataTable({
    data: usa,
    bLengthChange: false,
    bPaginate: false,
    scrollY:        '50vh',
    columns: [
      { data: 'provinceState', title: 'State', width: '2px' },
      { data: 'countryRegion', title: 'Country', width: '2px' }
    ]
  });
};
getNewCases();
</code></pre>

<p>As you can see in my <a href=""https://jsfiddle.net/0rc4gkx3/"" rel=""nofollow noreferrer"">FIDDLE</a> my datatable body has gotten smaller but the headers have not. Is there a proper way to ensure that both get smaller? Am i doing something wrong?</p>

<p>FYI I also tried the accepted answer in this <a href=""https://stackoverflow.com/questions/17237812/datatable-jquery-table-header-width-not-aligned-with-body-width"">stackoverflow</a> Post</p>
"
61083471,"<p>I want to fix datatable header when scrolling page without using scrollY property just like <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a> datatable.</p>

<p>Do anyone know about this ?</p>
"
61687447,"<p>I'm building a chart with infected cases COVID-19 from Peru but I'm having trouble with sort the content of my tooltip. I mean, I need change the cities by descendent cases order, but in the image you can see that is not in order, so is difficult associate the lines with the content of tooltip. If you know how I could sort cities by cases in every point of the chart, I would read you.</p>

<p>This is the code I'm using:</p>

<pre><code> var cities = new Array()
    var values = new Array();
    // console.log(linetext)

    focus
      .select("".lineHover"")
      .attr(""transform"", ""translate("" + x(d.date) + "","" + height + "")"");

    focus
      .select("".lineHoverDate"")
      .attr(
        ""transform"",
        ""translate("" + x(d.date) + "","" + (height + margin.bottom) + "")""
      )
      .text(formatDate(d.date));

    focus
      .selectAll("".hoverCircle"")
      .attr(""cy"", e =&gt; y(d[e]))
      .attr(""cx"", x(d.date));

    focus
      .selectAll("".lineHoverText"")
      .attr(
        ""transform"",
        ""translate("" + x(d.date) + "","" + height / 7.5 + "")""
      )
      .text(function(e) {
        if (d[e] &gt; 0) {
          console.log(e, d[e])
          values.push(d[e]) //is the values one by one, I tried to push in an array
          cities.push(e) //is the cities in another array
          var a = 0
          //This is my failed try
          for (i in values){
            if(values[i] == d[e]){
              if (d[e]&gt;a){
                a = d[e]
                return e.replace(/_cases|_deaths/, """") + "": "" + formatValue(a);
              }
            }
          }
          //values.sort(function(a, b){return b-a});
          console.log(cities, values, a)

        } else {
          return """";
        }
      });
</code></pre>

<p><a href=""https://i.stack.imgur.com/MpXC2.png"" rel=""nofollow noreferrer""></a></p>
"
61593369,"<p>I'm making a tooltip containing a bar chart on different sectors of industry and their percentage increase and decrease. At the moment I currently have implemented a tooltip containing the data for each industry within one country, but I also want to be able to compare this data to the world average for each industry. Currently the tooltip on the map looks like:<a href=""https://i.stack.imgur.com/ZgaTS.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ZgaTS.png"" alt=""enter image description here""></a></p>

<p>... and a closer look...
<a href=""https://i.stack.imgur.com/Dh0w2.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Dh0w2.png"" alt=""enter image description here""></a></p>

<p>The tooltip data comes from an array with 6 values, there's also an array containing 6 integer values with the world average data. The world average data can be found in an array worldAvg. For example's sake say the world averages are: [-20,-30,-40,-10,10,20].</p>

<p>How can I change my current implementation to compare the sector increase decrease compared to the world average increase decrease? I imagine the world average data could be coloured in red, for example. I wish to implement something like the following chart, but with different coloured bars and containing negative values too:</p>

<p><a href=""https://i.stack.imgur.com/nmqDs.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nmqDs.png"" alt=""enter image description here""></a></p>

<p>so, for example, the bar chart would show the retail % increase and decrease of the country beside the world % increase and decrease, and then there be a little space to show a grouping of this data, and then the grocery % increase...etc.</p>

<p>Any help would be appreciated. I am a total D3 newbie and just trying to come to terms with it.
This is the current code:</p>

<pre><code>  // draw maps and tooltips
  const drawMap = (svg, geoJson, geoPath, covid, key, impact) =&gt; {
    // clear svgs
    svg.select('g').remove();

    const g = svg.append('g');
    g
      .selectAll('path')
      .data(geoJson.features)
      .enter()
      .append('path')
      .attr('d', geoPath)
      .attr('class', (d) =&gt; {
        const mobilityData = covid.data[d.properties[key]] || {};
        const { leastHitName, mostHitName } = getData(mobilityData);
        const filterType = getFilterType(impact);
        if (filterType === 'least-impacted') {
          return `county ${leastHitName}`;
        }
        return `county ${mostHitName}`;
      })
      .on('mouseover', ({ properties }) =&gt; {
        // get county data
        const mobilityData = covid.data[properties[key]] || {};


        //GET AVERAGES - IMPLEMENT LATER
      // const {
      //   retailAverage,
      //   groceryAverage,
      //   parksAverage,
      //   transitAverage,
      //   workplaceAverage,
      //   residentialAverage,
      // } = getAverage(covid1);
      //

        //Theoretical averages for testing
      let avgArray = [-20,-30,-40,-10,10,20];

        // create tooltip
        div = d3.select('body')
          .append('div')
          .attr('class', 'tooltip')
          .style('opacity', 0);

        div.html(properties[key]);

        div.transition()
          .duration(200)
          .style('opacity', 0.9);

        // calculate bar graph data for tooltip
        const barData = [];

        Object.keys(mobilityData).forEach((industry) =&gt; {
          const stringMinusPercentage = mobilityData[industry].slice(0, -1);
          barData.push(+stringMinusPercentage); // changing it to an integer value, from string
        });
        // barData = barData.sort(function (a, b) {  return a - b;  });
        // sort into ascending ^ keeping this in case we need it later
        const height2 = 220;
        const width2 = 250;
        const margin = {
          left: 50, right: 10, top: 20, bottom: 15,
        };

        // create bar chart svg
        const svgA = div.append('svg')
          .attr('height', height2)
          .attr('width', width2)
          .style('border', '1px solid')
          .append('g')
        // apply the margins:
          .attr('transform', `translate(${[`${margin.left},${margin.top}`]})`);

        const barWidth = 30; // Width of the bars

        // plot area is height - vertical margins.
        const chartHeight = height2 - margin.top - margin.left;

        // set the scale:
        const yScale = d3.scaleLinear()
          .domain([-100, 100])
          .range([chartHeight, 0]);

        // draw some rectangles:
        svgA
          .selectAll('rect')
          .data(barData)
          .enter()
          .append('rect')
          .attr('x', (d, i) =&gt; i * barWidth)
          .attr('y', (d) =&gt; {
            if (d &lt; 0) {
              return yScale(0); // if the value is under zero, the top of the bar is at yScale(0);
            }

            return yScale(d); // otherwise the rectangle top is above yScale(0) at yScale(d);
          })
          .attr('height', (d) =&gt; Math.abs(yScale(0) - yScale(d))) // the height of the rectangle is the difference between the scale value and yScale(0);
          .attr('width', barWidth)
          .style('fill', (d, i) =&gt; colours[i % 6]) // colour the bars depending on index
          .style('stroke', 'black')
          .style('stroke-width', '1px');

        // Labelling the Y axis
        const yAxis = d3.axisLeft(yScale);
        svgA.append('text')
          .attr('class', 'y label')
          .attr('text-anchor', 'end')
          .attr('x', -15)
          .attr('y', -25)
          .attr('dy', '-.75em')
          .attr('transform', 'rotate(-90)')
          .text('Percentage Change (%)');

        svgA.append('g')
          .call(yAxis);
      })
      .on('mouseout', () =&gt; {
        div.style('opacity', 0);
        div.remove();
      })
      .on('mousemove', () =&gt; div
        .style('top', `${d3.event.pageY - 140}px`)
        .style('left', `${d3.event.pageX + 15}px`));

    svg.append('g')
      .attr('transform', 'translate(25,25)')
      .call(colorLegend, {
        colorScale,
        circleRadius: 10,
        spacing: 30,
        textOffset: 20,
      });
  };

  drawMap(svg1, geoJson1, geoPath1, covid1, key1, 'impact1');
  drawMap(svg2, geoJson2, geoPath2, covid2, key2, 'impact2');
};


</code></pre>
"
61262375,"<p>I just want to make a simple GET request to this URL: </p>

<pre><code>https://services.arcgis.com/pGfbNJoYypmNq86F/arcgis/rest/services/COVID19_Public_Health_Status_by_County/FeatureServer/0/query?where=1%3D1&amp;outFields=*&amp;outSR=4326&amp;f=json 
</code></pre>

<p>And get the associated JSON data. The problem is this resource returns only 1000 records. I believe there are about 3000+ counties in the US. You can see more info about this API here: </p>

<pre><code>https://coronavirus-resources.esri.com/datasets/97792521be744711a291d10ecef33a61/geoservice?geometry=6.433%2C-16.701%2C-38.567%2C72.161&amp;showData=true
</code></pre>

<p>I am getting lost in a sea of documentation for what should be a pretty straightforward operation. Do I need to create an application and authenticate, then send that token along with the GET request? How should the headers be formatted if thats the case? I checked both authentication and Rest API feature level tutorials, there was no mention of how to authenticate a request in either of them. If anyone at Esri is reading this please fix that. </p>

<p>In summary, I just need to make sure I get all the data from the API request. Right now it's only 1000 counties. I need all 3000+. Thanks. </p>
"
60749998,"<p>how would I download the latest file that is uploaded to some Github repo in a particular folder? I am using Node.js with cron job to download the file, but I need to get the fresh file every day.</p>

<p>This is the repo if anyone is interested: <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19</a></p>
"
60850999,"<p>I'm trying to visualise covid19 data using amcharts4 geo map in Angular - similar to this <a href=""https://www.amcharts.com/demos/corona-virus-animated-dashboard/"" rel=""nofollow noreferrer"">demo</a></p>

<p>But prefer to only use hover to display data in map (timeline not necessary) - using 'polygonSeries.tooltipText' instead of the bubble. This is my api source <a href=""https://covid19.mathdro.id/api/confirmed"" rel=""nofollow noreferrer"">Rest Api</a></p>

<p>All I get in the tooltip is the name, but no confirmed cases value. Screenshot <a href=""https://i.stack.imgur.com/SM52d.png"" rel=""nofollow noreferrer"">geomaps</a></p>

<ul>
<li>Generated service works fine</li>
<li>Getting rest api data is fine</li>
</ul>

<p>This is what i use in geomaps.component.ts</p>

<pre><code>import { Component, OnInit, NgZone, AfterViewInit } from '@angular/core';
import * as am4core from '@amcharts/amcharts4/core';
import * as am4maps from ""@amcharts/amcharts4/maps"";
import am4geodata_worldLow from '@amcharts/amcharts4-geodata/worldLow';
import am4themes_animated from '@amcharts/amcharts4/themes/animated';
import { MapServiceService } from '../service/map-service.service';
// Themes begin
am4core.useTheme(am4themes_animated);
// Themes end

@Component({
  selector: 'app-geomaps',
  templateUrl: './geomaps.component.html',
  styleUrls: ['./geomaps.component.css']
})

export class GeomapsComponent implements OnInit, AfterViewInit {
  public caseData = [];

  private mapChart: am4maps.MapChart;

  constructor(private zone: NgZone, private mapsService: MapServiceService) { }

  // Inject NgZone service and add ngAfterViewInit method which will create our chart
  ngAfterViewInit() {
    this.zone.runOutsideAngular(() =&gt; {

      // Declare our chart to display to html id='chartdiv' map instance
      let mapChart = am4core.create(""chartdiv"", am4maps.MapChart);

      // Low-detail map - set map definition
      mapChart.geodata = am4geodata_worldLow;

      // set projection
      mapChart.projection = new am4maps.projections.Miller();

      //  polygon represented by objects map areas (defines how country look and behave)
      let polygonSeries = mapChart.series.push(new am4maps.MapPolygonSeries());
      polygonSeries.data = this.caseData; // Our case data
      polygonSeries.useGeodata = true;

      // Bind our properties to data
      // polygonSeries.data = 
      // [{
      //   ""id"": ""US"",
      //   ""name"": ""United States"",
      //   ""value"": 100,
      //   ""fill"": am4core.color(""#F05C5C"")
      // }, {
      //   ""id"": ""FR"",
      //   ""name"": ""France"",
      //   ""value"": 50,
      //   ""fill"": am4core.color(""#5C5CFF"")
      // }];

      // configure series
      let polygonTemplate = polygonSeries.mapPolygons.template;
      polygonTemplate.tooltipText = ""{name}: {value}""; // TooltipText
      polygonTemplate.fill = am4core.color(""#74B266"");

      // Create hover state and set alternative fill color
      let hs = polygonTemplate.states.create(""hover"");
      hs.properties.fill = am4core.color(""#003399"");

      // Exclude antartica iso-2=""AQ""
      polygonSeries.exclude = [""AQ""];

      mapChart.smallMap = new am4maps.SmallMap();
      mapChart.smallMap.series.push(polygonSeries);

    });
  }

  ngOnDestroy() {
    this.zone.runOutsideAngular(() =&gt; {
      if (this.mapChart) {
        this.mapChart.dispose();
      }
    });
  }

  ngOnInit() {
    this.getCasesData();
  }

  getCasesData() {
    this.mapsService.getAll().subscribe(data =&gt; {
      for (const d of (data as any)) {
        this.caseData.push({
          id: d.iso2,
          name: d.countryRegion,
          provinceState: d.provinceState,
          value: d.confirmed
        });
      }
      console.log(this.caseData);
      // return this.caseData;
    });
  }
}
</code></pre>

<p>When console logging getCasesData, my results return as follows:</p>

<pre><code>[0 … 99]
    0: {multiPolygon: Array(1), id: ""TV"", madeFromGeoData: true, name: ""Tuvalu""}
    1: {multiPolygon: Array(1), id: ""BV"", madeFromGeoData: true, name: ""Bouvet Island""}...
</code></pre>

<p>further down the line:</p>

<pre><code>[300 … 399]
    300: {id: ""SA"", name: ""Saudi Arabia"", provinceState: null, value: 900}
    301: {id: ""FI"", name: ""Finland"", provinceState: null, value: 880}
    302: {id: ""US"", name: ""US"", provinceState: ""Michigan"", value: 876}...
</code></pre>

<p>I appreciate anyone who can point me in the right direction. Thanks</p>
"
61577921,"<p>I am trying to make a google apps script to show covid related graphs.
I can download data from cdc, and put them in a spreadsheet where there is a graph and it works just fine but I have a problem with axis scale.
When you try to compare a countries sum of cases to the sum of deaths for example, deaths are too few and the graph isn't right. So I am trying to find a way to add deaths in this example but have them show in secondary (right) vertical axis.
Is there a way to to this?</p>

<p>Edit: to be more precise
My script gets the data from ecdc, puts it in sheets, shorts it to be usable and then puts it in a sheet with a premade chart, changing the data. Number of columns isn't always constant, some may be blank.
Works fine for one category of data.
What I need is to be able to add another set of data to be able to add a range as series in the chart but in a secondary axis. </p>

<p>My ""code"" looks like this</p>

<pre><code>    chart = chart.modify()
  .setOption(""series"",{0:{targetAxisIndex:0}})
  .setOption(""series"",{1:{targetAxisIndex:0}})
  .setOption(""series"",{2:{targetAxisIndex:0}})
  .setOption(""series"",{3:{targetAxisIndex:0}})
  .setOption(""series"",{4:{targetAxisIndex:1}})
  .setOption(""series"",{5:{targetAxisIndex:1}})

  .build()
  sheet.updateChart(chart)
</code></pre>

<p>2 problems here. 
1 It works when I change one series to right vaxis, but as soon as I do a second, first reverts to left axis.
2 I don't know how to get a list of series in the chart with their index so that even if I make it to work I must guess which series have what data</p>

<p>Edit: I changed the code and it now holds the changes but I still want to get a list of series in the chart with id's and series header so I know what to change.
here is an example
<a href=""https://docs.google.com/spreadsheets/d/1_bTj8e3FZpbhdENwN9CdLYsqkJeqp313CGCJmPNtrr4/edit?usp=sharing"" rel=""nofollow noreferrer"">https://docs.google.com/spreadsheets/d/1_bTj8e3FZpbhdENwN9CdLYsqkJeqp313CGCJmPNtrr4/edit?usp=sharing</a></p>
"
60820845,"<p>I am trying to learn some better JS and React and today I started a new project. So as you can see in the code, I make an HTTP request to get some data, and then I want to use these data to create some charts using React-Chart.js-2. The thing is that the data from the HTTP request are only available inside the xhr.onload anonymous function. I am trying to figure a way to make these data available outside of this function scope, so I can use them inside a React-Chart.js-2 component.</p>

<p>Here is the code of the whole file:</p>

<pre><code>import React, { Component } from 'react';
import { Bar, Line, Pie, Doughnut, Polar } from 'react-chartjs-2';

let currentData = [0, 0, 0];

//HTTP REQUEST
const xhr = new XMLHttpRequest();

xhr.open('GET', 'https://coronavirus-tracker-api.herokuapp.com/v2/locations');
xhr.responseType = 'json';
xhr.onload = function() {
const data = xhr.response;

   currentData =  [
        data.latest.confirmed,
        data.latest.recovered,
        data.latest.deaths
    ];
};
xhr.send();

//CHART COMPONENT
class Chart extends Component {
    constructor(props) {
        super(props);
        this.state = {
            chartData: {
                labels: [
                    'Confirmed Cases',
                    'Recovered',
                    'Deaths'
                ],
                datasets:[ {
                    label: 'Population',
                    data: currentData,
                    backgroundColor: [
                        'rgba(255, 99, 132, 0.6)',
                        'rgba(54, 162, 235, 0.6)',
                        'rgba(52, 100, 255, 0.6)'
                    ]
                }
            ]
            }
        }
    }


    render() {
        return (
            &lt;div className='chart'&gt;

&lt;Polar
    width={400}
    height={400}
    data={this.state.chartData}
    options={{
        maintainAspectRatio: false
    }}

/&gt;
            &lt;/div&gt;
        )
    }
}

export default Chart;
</code></pre>

<p>How can I make these data available to the global scope so then I can use them with Chart.js?</p>
"
60974738,"<p>I have 2 related questions:
I want to add a table of data from a csv file below a map. Both are functioning correctly. The map appears in the content but the table appears below the footer of the Drupal page. Can anyone suggest how I can adjust its position? 
Also the table is the entire width of the screen. I can adjust the relative widths of the columns in the table but not the full width of the screen. What controls this?</p>

<pre><code>function process_table (canada) {
 // get the data from the csv file
 data=d3.csv(dataCases, function(data) {

 data.forEach(function(d) {
  d.code=d.Geo_Code,    
  d.prov=d.Prov_Name,   
  d.cumulative=d.Cumulative,    
  d.population=d.Population,    
  d.percapita=d.Percapita
});

// The table generation function
function tabulate(data, columns) {
var table = d3.select(""body"")
     .append(""table"")
     .attr(""style"", ""margin-left: 60px""),
        thead = table.append(""thead""),
        tbody = table.append(""tbody"");

// append the header row
thead.append(""tr"")
    .selectAll(""th"")
    .data(columns)
    .enter()
    .append(""th"")
    .text(function(column) { 
       return column; 
    }); 

// create a row for each object in the data
var rows=tbody.selectAll(""tr"")
   .data(data)
   .enter()
   .append(""tr"");

// create a cell in each row for each column
var cells=rows.selectAll(""td"")
   .data(function(row) {
        return columns.map(function(column) {
            return {column: column, value: row[column]};
        });
    })
  .enter()
  .append(""td"")
  .attr(""style"", ""font-size: 12px"") // sets the font style
  .html(function(d) { return d.value; });

   return table;
}

var covidTable = tabulate(data,[""prov"",""cumulative"",""population"",""percapita""]);
});
} // end process_table
</code></pre>
"
61496227,"<p>Hi there I wanting to implement typeahead text highlighting. Just wondering how I would do that with my current code - considering my results are showing in another div not inside the <code>tt-dropdown-menu</code> . Would I need to use bloodhound to do this? Thanks</p>

<pre><code>$("".global-search"").typeahead(
    {
        hint: false,
        highlight: true,
        minLength: 2,
    },
    {
        name: ""search"",
        source: function (str, async) {
            restCall(str, async);
        },
    }
);
// The function that will make the REST call and return the data
function restCall(str, async) {
    return $.ajax(""http://localhost:5000/search?term="" + str, {
        headers: {
            ""Content-Type"": ""application/json"",
        },
        // response
        success: function (res) {
            $("".search-modal"").fadeIn().css({ display: ""flex"" });
            //return async(res.data);
            if (res.recentSearches) {
                $(""#api-recent-search"").empty();
                var data = res.recentSearches;
                $.each(data, function (key, value) {
                    $(""#api-recent-search"").append(
                        $(
                            ""&lt;li&gt;&lt;a href='"" +
                                value.url +
                                ""'&gt;"" +
                                value.title +
                                ""&lt;/a&gt;&lt;/li&gt;""
                        )
                    );
                });
            }
            if (res.popularArticles) {
                $(""#api-popular-search"").empty();
                var data = res.popularArticles;
                $.each(data, function (key, value) {
                    $(""#api-popular-search"").append(
                        $(
                            ""&lt;li&gt;&lt;a href='"" +
                                value.url +
                                ""'&gt;"" +
                                value.title +
                                ""&lt;/a&gt;&lt;/li&gt;""
                        )
                    );
                });
            }
            if (res.keywordResults) {
                var data = res.keywordResults.filter(function (obj) {
                    var title = obj.title.toLowerCase();
                    var matchTitle = title.includes(str.toLowerCase());
                    if (!matchTitle) {
                        $(""#api-keyword-search"").html(
                            '&lt;div class=""no-results""&gt;No Results&lt;/div&gt;'
                        );
                    }
                    return matchTitle;
                });

                $.each(data, function (key, value) {
                    $("".no-results"").remove();
                    $(""#api-keyword-search"").append(
                        $(
                            ""&lt;li&gt;&lt;a href='"" +
                                value.url +
                                ""'&gt;"" +
                                value.title +
                                ""&lt;/a&gt;&lt;/li&gt;""
                        )
                    );
                });
            }
        },
    });
}
</code></pre>

<p>JSON</p>

<pre><code>{
""recentSearches"": [
    {
        ""id"": ""1"",
        ""title"": ""coronavirus"",
        ""url"": ""http://google.com""
    },
    {
        ""id"": ""2"",
        ""title"": ""covid-19"",
        ""url"": ""http://google.com""
    },
    {
        ""id"": ""3"",
        ""title"": ""keep active"",
        ""url"": ""http://google.com""
    },
    {
        ""id"": ""4"",
        ""title"": ""get covid advice"",
        ""url"": ""http://google.com""
    }
],
""popularArticles"": [
    {
        ""id"": ""1"",
        ""title"": ""Covid-19 Health Update 25 March 2020"",
        ""url"": ""http://google.com""
    },
    {
        ""id"": ""2"",
        ""title"": ""Mental Wellbeing Resources about Coronavirus"",
        ""url"": ""http://google.com""
    },
    {
        ""id"": ""3"",
        ""title"": ""Social Distancing is purely physical"",
        ""url"": ""http://google.com""
    },
    {
        ""id"": ""4"",
        ""title"": ""What is Physical distancing? (aka `social` distancing)"",
        ""url"": ""http://google.com""
    }
],
""keywordResults"": [
    {
        ""id"": ""1"",
        ""title"": ""Covid-19 Health Update 25 March 2020"",
        ""url"": ""http://google.com""
    },
    {
        ""id"": ""2"",
        ""title"": ""Mental Wellbeing Resources about Coronavirus"",
        ""url"": ""http://google.com""
    },
    {
        ""id"": ""3"",
        ""title"": ""Social Distancing is purely physical"",
        ""url"": ""http://google.com""
    },
    {
        ""id"": ""4"",
        ""title"": ""What is Physical distancing? (aka `social` distancing)"",
        ""url"": ""http://google.com""
    }
]
}
</code></pre>
"
61502651,"<p>For descreasing the size of out put I serialize array of <code>x,y</code> to <code>base64</code> string in back end and pass the string to client side, in client side I want to desrialize <code>base64</code> of two-dimensional <code>short[,]</code> array in JavaScript.<br>
Implementation:  </p>

<pre><code>public class DiagnosisSpec
{
    public int Covid { get; set; }
    public int Infection { get; set; }
    public int Other { get; set; }
    public ImagesSpec[] Images { get; set; }
}

[Serializable]
public class Contour
{
    public short X { get; set; }
    public short Y { get; set; }
} 
</code></pre>

<p>and <code>ImagesSpec</code> impementation is look like following below:</p>

<pre><code>public class ImagesSpec
{
    string _strContour; 
    public int Index { get; set; }
    string GetContourAsBase64()
    {
        Contour[] _contour = (JsonConvert.DeserializeObject&lt;List&lt;short[]&gt;&gt;((string)_strContour) as List&lt;short[]&gt;)
                    .Select(x =&gt; new Contour
                    {
                        X = x[0],
                        Y = x[1]
                    }).ToArray();
        byte[] contourByte;
        BinaryFormatter bf = new BinaryFormatter();
        using (var ms = new MemoryStream())
        {
            bf.Serialize(ms, _contour);
            contourByte = ms.ToArray();
        } 
        string contourAsBase64 = Convert.ToBase64String(contourByte); 
        return contourAsBase64;
    }
    public string Contour
    {
        get
        {
            return GetContourAsBase64();
        }
        set
        {
            _strContour = value;
        }
    }
}
</code></pre>

<p>is there a way to deserialize each element of <code>Images</code> to <code>List&lt;Contour&gt;</code> in JavaScript something like:</p>

<pre><code>result.Images.forEach(function (item, index, arr) { 
    var binary_string = window.atob(item.Contour);
    var len = binary_string.length;
    var bytes = new Uint8Array(len);
    for (var i = 0; i &lt; len; i++) {
        bytes[i] = binary_string.charCodeAt(i);
    }
    console.log( bytes.buffer ); 
});
</code></pre>

<p><code>base64</code> string is look like:
<code>""AAEAAAD/////AQAAAAAAAAAMAgAAAFVNQVJDTy5XZWIuQXBwbGljYXRpb24uTkdXZWIsIFZlcnNpb249OS44LjY0LjI5NSwgQ3VsdHVyZT1uZXV0cmFsLCBQdWJsaWNLZXlUb2tlbj1udWxsBwEAAAAAAQAAADoAAAAEKk1BUkNPLldlYi5BcHBsaWNhdGlvbi5OR1dlYi5Nb2RlbHMuQ29udG91cgIAAAAJAwAAAAkEAAAACQUAAAAJBgAAAAkHAAAACQgAAAAJCQAAAAkKAAAACQsAAAAJDAAAAAkNAAAACQ4AAAAJDwAAAAkQAAAACREAAAAJEgAAAAkTAAAACRQAAAAJFQAAAAkWAAAACRcAAAAJGAAAAAkZAAAACRoAAAAJGwAAAAkcAAAACR0AAAAJHgAAAAkfAAAACSAAAAAJIQAAAAkiAAAACSMAAAAJJAAAAAklAAAACSYAAAAJJwAAAAkoAAAACSkAAAAJKgAAAAkrAAAACSwAAAAJLQAAAAkuAAAACS8AAAAJMAAAAAkxAAAACTIAAAAJMwAAAAk0AAAACTUAAAAJNgAAAAk3AAAACTgAAAAJOQAAAAk6AAAACTsAAAAJPAAAAAUDAAAAKk1BUkNPLldlYi5BcHBsaWNhdGlvbi5OR1dlYi5Nb2RlbHMuQ29udG91cgIAAAASPFg+a19fQmFja2luZ0ZpZWxkEjxZPmtfX0JhY2tpbmdGaWVsZAAABwcCAAAAqADGAAEEAAAAAwAAAKgAxwABBQAAAAMAAACoAMgAAQYAAAADAAAAqADJAAEHAAAAAwAAAKgAygABCAAAAAMAAACpAMYAAQkAAAADAAAAqQDKAAEKAAAAAwAAAKoAxgABCwAAAAMAAACqAMoAAQwAAAADAAAAqwDGAAENAAAAAwAAAKsAxwABDgAAAAMAAACrAMkAAQ8AAAADAAAAqwDKAAEQAAAAAwAAAKwAxwABEQAAAAMAAACsAMgAARIAAAADAAAArADJAAETAAAAAwAAAK4ALAEBFAAAAAMAAACuAC0BARUAAAADAAAArgAuAQEWAAAAAwAAAK4ALwEBFwAAAAMAAACuADABARgAAAADAAAArwArAQEZAAAAAwAAAK8ALAEBGgAAAAMAAACvADABARsAAAADAAAAsAAqAQEcAAAAAwAAALAAKwEBHQAAAAMAAACwAC8BAR4AAAADAAAAsAAwAQEfAAAAAwAAALEAKQEBIAAAAAMAAACxACoBASEAAAADAAAAsQAtAQEiAAAAAwAAALEALgEBIwAAAAMAAACxAC8BASQAAAADAAAAsgAoAQElAAAAAwAAALIAKQEBJgAAAAMAAACyACwBAScAAAADAAAAsgAtAQEoAAAAAwAAALMAKAEBKQAAAAMAAACzACsBASoAAAADAAAAswAsAQErAAAAAwAAALQAKAEBLAAAAAMAAAC0ACkBAS0AAAADAAAAtAAqAQEuAAAAAwAAALQAKwEBLwAAAAMAAAAcAdQAATAAAAADAAAAHAHVAAExAAAAAwAAABwB1gABMgAAAAMAAAAcAdcAATMAAAADAAAAHAHYAAE0AAAAAwAAAB0B1AABNQAAAAMAAAAdAdgAATYAAAADAAAAHgHUAAE3AAAAAwAAAB4B1QABOAAAAAMAAAAeAdgAATkAAAADAAAAHwHVAAE6AAAAAwAAAB8B1gABOwAAAAMAAAAfAdcAATwAAAADAAAAHwHYAAs=""</code>  </p>

<p>thanks in advance.</p>
"
61493804,"<p>I'm trying to read an <a href=""https://covidtracking.com/api"" rel=""nofollow noreferrer"">external API</a> which gives the following definitions for each historical date:</p>

<pre><code>state - State or territory postal code abbreviation.
positive - Total cumulative positive test results.
positiveIncrease - Increase from the day before.
negative - Total cumulative negative test results.
negativeIncrease - Increase from the day before.
pending - Tests that have been submitted to a lab but no results have been reported yet.
totalTestResults - Calculated value (positive + negative) of total test results.
totalTestResultsIncrease - Increase from the day before.
hospitalized - Total cumulative number of people hospitalized.
hospitalizedIncrease - Increase from the day before.
death - Total cumulative number of people that have died.
deathIncrease - Increase from the day before.
dateChecked - ISO 8601 date of the time we saved visited their website
hospitalizedCurrently - Number of individuals currently hospitalized.
hospitalizedCumulative - Total number of individuals that have been hospitalized, including those that have been discharged.
inIcuCurrently - Number of individuals currently in an ICU.
inIcuCumulative - Total number of individuals that have been in the ICU.
onVentilatorCurrently - Number of individuals currently on a ventilator.
onVentilatorCumulative - Total number of individuals that have been on a ventilator.
recovered - Total number of individuals that have tested negative after a previous positive test.
total - DEPRECATED Will be removed in the future. (positive + negative + pending). Pending has been an unstable value and should not count in any totals.
</code></pre>

<p>Now I am looping all dates and I am trying to know the total for a given time period, so let's say we want to have the total from date 1 until the last date, I do:</p>

<pre><code>function updateUI(filtererdData, dateStart, dateEnd, firstRunMap) {

    // new state
    deaths = 0;
    hospitalized = 0;
    recovered = 0;
    positive = 0;
    hospitalizedCumulative = 0;
    inIcuCumulative = 0;
    onVentilatorCumulative = 0;
    pending = 0;
    negative = 0;
    tests = 0;
    hospitalisedNow = 0;
    intensiveCareNow = 0;
    onVentilatorNow = 0;
    name = 0;
    cases = 0;
    var totalDeaths = 0;

    // filtererdData has now STATE data, and not only 1 state

    filtererdData.forEach(state =&gt; {

        var stateName = state.name;

        // ""state.data"" will have an array of all dates in between
        state.data.forEach(stateDataPerDay =&gt; {
            if(stateDataPerDay.death) deaths += stateDataPerDay.deathIncrease;
            if(stateDataPerDay.hospitalized) hospitalized += stateDataPerDay.hospitalizedIncrease;
            if(stateDataPerDay.recovered) recovered += stateDataPerDay.recovered;
            if(stateDataPerDay.positive) positive += stateDataPerDay.positiveIncrease;
            if(stateDataPerDay.negative) negative += stateDataPerDay.negativeIncrease;
            if(stateDataPerDay.totalTestResults) tests += stateDataPerDay.totalTestResultsIncrease;
            if(stateDataPerDay.hospitalizedCumulative) hospitalisedNow += stateDataPerDay.hospitalizedCurrently;
            if(stateDataPerDay.inIcuCumulative) intensiveCareNow += stateDataPerDay.inIcuCurrently;
            if(stateDataPerDay.onVentilatorCumulative) onVentilatorNow += stateDataPerDay.onVentilatorCurrently;
            cases += positive + negative;
            // WRONG
            if(stateDataPerDay.length - 1) {
                console.log(stateDataPerDay.death);
            }
        });

        // end each state data to save

        // let's append the total to each state as well
        // deaths &amp; hospitalized are the sum of all selected days
        state.totalDeaths = deaths;
        state.totalHospitalized = hospitalized;
        state.totalRecovered = recovered;
        state.totalPositive = positive;
</code></pre>

<p>But I am doing this wrong, the totals I am having are just wrong. I am confused if to have the <code>death</code> totals I should be using <code>.death</code> or <code>.deathIncrease</code> and how this should be added within the loop to use that total value later on in the code. And do this for <code>deaths</code>, <code>recovered</code>, <code>tests</code>.</p>

<p>Another question in regards of this data is: How do I know the total cases? Is it <code>positive + negative</code>? And if so, how would I do the total for each state to use it later?</p>

<p>For some of the data I don't want to display its total as I will show it in a graph trend but for deaths, recovered, cases and tests I do.</p>
"
61194054,"<p>I have written a conversion program (C#) that takes as inputs the state-level data for COVID-19 cases in the United States from The New York Times on GitHub and the us-states.js file from the Leaflet Interactive Choropleth Map. The program produces a JSON file that contains </p>

<pre><code>{
 ""type"":""Feature"",
 ""id"":""01"",
 ""properties"":{
               ""name"":""Alabama"",
               ""start"":""01/21/2020"",
               ""count"":81,
               ""cases"":[0,0,0,...]
              },
 ""geometry"":{...}
},...
</code></pre>

<p>where the density of the state, in the original data, was replaced by start and count values, and the cases array. Where cases for a particular state do not start on the same date as does Washington State (01/21/2020), the missing dates cases are represented by zero. This allows the cases array to be accessed by an index that represents a specific day across all dates. Now it is possible to map the COVID-19 cases as the spread throughout the US. For the mapping, I decided to use the same Leaflet Interactive Choropleth Map software as a template (I have no experience with current mapping software so I pretty much copied the Leaflet code). The final intent is to have a setInterval timer trigger the revision to the map. The code follows.</p>

<pre><code>&lt;!DOCTYPE html&gt;
&lt;!-- from https://leafletjs.com/examples/choropleth/ --&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;By State COVID-19 Spread&lt;/title&gt;
    &lt;meta name='viewport' content='initial-scale=1,maximum-scale=1,user-scalable=no' /&gt;
    &lt;link rel='stylesheet' href='Leaflet-1.6.0/dist/leaflet.css' /&gt;
    &lt;script src='Leaflet-1.6.0/dist/leaflet.js'&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div id='map' style='width:700px;height:500px'&gt;&lt;/div&gt;
    &lt;div style='display:table-cell;margin-top:100px;'&gt;
      &lt;button type='button' onclick='update()'&gt;Update&lt;/button&gt; 
      &lt;label for='day_number' style='height:12pt;margin-left:30px;'&gt;Day Number:&lt;/label&gt;
      &lt;span id='day_number' style='height:12pt; margin-left:5px;'&gt;&lt;/span&gt;
    &lt;/div&gt;
  &lt;script src='cases-by-us-state.js'&gt;&lt;/script&gt;
  &lt;script&gt;
    var case_index = 67;
    document.getElementById('day_number').innerHTML = case_index; 
    var maximum_cases = statesData.features[0].properties.count;
    var mapboxAccessToken = 'pk.eyJ1IjoiZ2dndXN0YWZzb24iLCJhIjoiY2s4a2RlOW42MDByYzNucGgxc2I0d2RqeCJ9.bB2UhdKKupjIXEV54N70pQ';
    var map = L.map('map').setView([37.8, -96], 4);

    function getColor ( d ) 
      {
      // colors from https://colorbrewer2.org
      return d &gt; 10000 ? '#99000d' :
             d &gt; 5000  ? '#cb181d' :
             d &gt; 2000  ? '#ef3b2c' :
             d &gt; 1000  ? '#fb6a4a' :
             d &gt; 500   ? '#fc9272' :
             d &gt; 200   ? '#fcbba1' :
             d &gt; 100   ? '#fee0d2' :
                         '#fff5f0';
      }

    function style ( feature ) 
      {

      return {
        fillColor: getColor ( feature.properties.cases[case_index] ),
        weight: 2,
        opacity: 1,
        color: 'black',
        fillOpacity: 0.7
        };
      }

    L.tileLayer ( 
      'https://api.mapbox.com/styles/v1/{id}/tiles/{z}/{x}/{y}?access_token=' + mapboxAccessToken, 
        {
        id: 'us_states_cases',
        attribution: '&lt;a https://github.com/nytimes/covid-19-dataMap&gt;NY Times&lt;/a&gt;',
        tileSize: 512,
        zoomOffset: -1
        } ).addTo ( map );

    L.geoJson ( statesData, { style: style } ).addTo ( map );

    function update ( )
      {
      if ( case_index &lt; ( maximum_cases - 1 ) )
        {
        case_index++; 
        }
      else 
        {
        case_index = 0;
        }
      document.getElementById('day_number').innerHTML = case_index; 
      map.invalidateSize()
      }
  &lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>

<p>My problem occurs in the update function. It doesn't update the graphic! Whenever the Update button is clicked, the Day Number increments but the graphic for the data for that day number does not paint. Thoughts?</p>

<p>Stay Safe.</p>
"
61179987,"<p>I've got a <a href=""https://latencyzero.github.io/COVID/"" rel=""nofollow noreferrer"">page</a> with stacked line charts. One of the goals is for the x-axis values to always be in sync, regardless of the zoom or hidden series in any given chart.</p>

<p>Is there any way to listen for changes in one chart (so that I can propagate them to another)? For example, if the user zooms one chart with the mouse scroll wheel, I'd like to zoom the other charts to match.</p>

<p>If the user hides a series in one chart, I'd like to hide that series in the others (maybe; I wish I could give them the option).</p>
"
61025253,"<p>I have created <a href=""https://cutting.scot/covid-19"" rel=""nofollow noreferrer"">this</a> graph that simply shows the number of deaths against the days since the first death.</p>

<p>What I think would be interesting was to show the rate of change for each country but I'm struggling as to how to do this with the data.</p>

<p>An example of one country's data is below:</p>

<pre><code>{
  ""gb"": {
    ""data"": [
      // last 4 records
      {
        ""x"": 26,
        ""date"": ""31/03/2020"",
        ""y"": 1793,
        ""country"": ""GBR"",
        ""delta"": 382
      },
      {
        ""x"": 27,
        ""date"": ""01/04/2020"",
        ""y"": 2357,
        ""country"": ""GBR"",
        ""delta"": 564
      },
      {
        ""x"": 28,
        ""date"": ""02/04/2020"",
        ""y"": 2926,
        ""country"": ""GBR"",
        ""delta"": 569
      },
      {
        ""x"": 29,
        ""date"": ""03/04/2020"",
        ""y"": 3611,
        ""country"": ""GBR"",
        ""delta"": 685
      }
    ]
  }
</code></pre>

<p>The delta is simply the difference from the day before.</p>

<p>I do remember from maths that the rate of change was <code>dy/dx</code>.</p>

<p>My first step would be to get the equation of a curve given.</p>

<p>I know how to do the rest but how can I get the equation of a line given a set of coordinates in javascript? </p>
"
60896891,"<p>I am importing data from two different websites - <a href=""https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/"" rel=""nofollow noreferrer"">Quebec.ca</a> and <a href=""https://www.ontario.ca/page/2019-novel-coronavirus#section-0"" rel=""nofollow noreferrer"">Ontario.ca</a> - into this <a href=""https://docs.google.com/spreadsheets/d/1yb7Bc_L1mDzE7aDYfkN2dvTIUUNnvKpqCpWHhIiW780/"" rel=""nofollow noreferrer"">googlesheets</a>. </p>

<p>For Quebec's website, I used the following code to import Quebec's cities' data and it worked easily:</p>

<pre><code>=IMPORTHTML(""https://www.quebec.ca/en/health/health-issues/a-z/2019-coronavirus/situation-coronavirus-in-quebec/"",""table"",1)
</code></pre>

<p>For Ontario's site, it's not that easy because website is javascript-enabled, hence IMPORTXML isn't going to work. So, I stumbled upon Puppeteer. This is my first experience with Puppeteer.</p>

<p>Here's what I'm trying to achieve:</p>

<ol>
<li>Run Puppeteer after every 10 minutes to fetch updated data. </li>
<li>Data is saved in Static page with similar formatting</li>
<li>Googlesheets import data from that HTML using either IMPORTXML or IMPORTHTML feature.</li>
</ol>

<p>I only want to import the following section from the website ():
<a href=""https://i.stack.imgur.com/7eCpi.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/7eCpi.png"" alt=""enter image description here""></a></p>

<p><a href=""https://pastebin.com/p94ackAu"" rel=""nofollow noreferrer"">Source Code</a></p>

<p>These are <a href=""https://pastebin.com/tqq5Dkws"" rel=""nofollow noreferrer"">Xpath-Queries</a> I only wish to import. </p>

<p>So, I was able to install Puppeteer and Node.js in my VPS successfully. After debugging, I am able to use the following code:</p>

<pre><code>const puppeteer = require('puppeteer');

(async () =&gt; {
  const browser = await puppeteer.launch({args: ['--no-sandbox']});
  const page = await browser.newPage();
  await page.goto('https://www.ontario.ca/page/2019-novel-coronavirus', {waitUntil: 'networkidle2'});

     const data = await page.evaluate(()=&gt;{
            const tds = Array.from(document.querySelectorAll('tbody tr td'));
            return tds.map(td =&gt; td.innerText);
        });
        console.log(data)
    await page.pdf({path: 'ha.pdf', format: 'A4'});

  await browser.close();
})();
</code></pre>

<p>Following result was generated:</p>

<p><a href=""https://i.stack.imgur.com/QD1wb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QD1wb.png"" alt=""enter image description here""></a></p>

<p>This is somewhat the tabular data I wish to use, however I want to include more data shown in <a href=""https://pastebin.com/p94ackAu"" rel=""nofollow noreferrer"">Source Code</a> particularly <a href=""https://pastebin.com/tqq5Dkws"" rel=""nofollow noreferrer"">these ones</a>.</p>

<p>Now, how can I make this data exported regularly into static page format for googlesheets to easily import it?</p>
"
61245347,"<p>I'm using amcharts version 3 to draw a multiple line charts as given below , I'm showing the label on each point . </p>

<p>The code is here : </p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code> var chart = AmCharts.makeChart(""MultiAxisCovidChartDiv"", {
    ""type"": ""serial"",
    ""theme"": ""none"",
    ""dataProvider"": [{""Deaths"":7,""ForDate"":""2020-03-24"",""NewDailyConfirmed"":205,""NewDailyRecovered"":8,""RowNo"":1},{""Deaths"":3,""ForDate"":""2020-03-26"",""NewDailyConfirmed"":112,""NewDailyRecovered"":1,""RowNo"":1},{""Deaths"":3,""ForDate"":""2020-03-27"",""NewDailyConfirmed"":92,""NewDailyRecovered"":4,""RowNo"":1},{""Deaths"":4,""ForDate"":""2020-03-28"",""NewDailyConfirmed"":99,""NewDailyRecovered"":2,""RowNo"":1},{""Deaths"":8,""ForDate"":""2020-03-29"",""NewDailyConfirmed"":96,""NewDailyRecovered"":2,""RowNo"":1},{""Deaths"":8,""ForDate"":""2020-03-30"",""NewDailyConfirmed"":154,""NewDailyRecovered"":29,""RowNo"":1},{""Deaths"":10,""ForDate"":""2020-03-31"",""NewDailyConfirmed"":110,""NewDailyRecovered"":49,""RowNo"":1},{""Deaths"":16,""ForDate"":""2020-04-01"",""NewDailyConfirmed"":157,""NewDailyRecovered"":50,""RowNo"":1},{""Deaths"":21,""ForDate"":""2020-04-02"",""NewDailyConfirmed"":165,""NewDailyRecovered"":99,""RowNo"":1},{""Deaths"":25,""ForDate"":""2020-04-03"",""NewDailyConfirmed"":154,""NewDailyRecovered"":64,""RowNo"":1},{""Deaths"":29,""ForDate"":""2020-04-04"",""NewDailyConfirmed"":140,""NewDailyRecovered"":69,""RowNo"":1},{""Deaths"":34,""ForDate"":""2020-04-05"",""NewDailyConfirmed"":223,""NewDailyRecovered"":68,""RowNo"":1},{""Deaths"":38,""ForDate"":""2020-04-06"",""NewDailyConfirmed"":121,""NewDailyRecovered"":63,""RowNo"":1},{""Deaths"":41,""ForDate"":""2020-04-07"",""NewDailyConfirmed"":272,""NewDailyRecovered"":64,""RowNo"":1},{""Deaths"":41,""ForDate"":""2020-04-08"",""NewDailyConfirmed"":137,""NewDailyRecovered"":16,""RowNo"":1},{""Deaths"":44,""ForDate"":""2020-04-09"",""NewDailyConfirmed"":355,""NewDailyRecovered"":35,""RowNo"":1},{""Deaths"":47,""ForDate"":""2020-04-10"",""NewDailyConfirmed"":364,""NewDailyRecovered"":19,""RowNo"":1},{""Deaths"":52,""ForDate"":""2020-04-11"",""NewDailyConfirmed"":382,""NewDailyRecovered"":35,""RowNo"":1},{""Deaths"":59,""ForDate"":""2020-04-12"",""NewDailyConfirmed"":429,""NewDailyRecovered"":41,""RowNo"":1}],
    ""synchronizeGrid"":true,
    ""valueAxes"": [{
        ""id"":""v1"",
        //""axisColor"": ""#ee7b0b"",
        ""autoGridCount"": false,
        ""labelOffset"": 15,
        ""minHorizontalGap"": 100,
        ""gridCount"": 8,
        ""minorGridEnabled"": false,
        ""position"": ""left"",
        ""inside"": false,
    }, {
        ""id"":""v2"",
        //""axisColor"": ""#FF0000"",
            ""autoGridCount"": false,
            ""labelOffset"": 15,
            ""minHorizontalGap"": 100,
            ""gridCount"": 8,
            ""minorGridEnabled"": false,
            ""position"": ""right"",
            ""inside"": false,
    }, {
        ""id"":""v3"",
        ""autoGridCount"": false,
        ""labelOffset"": 15,
        ""minHorizontalGap"": 100,
        ""gridCount"": 8,
        ""minorGridEnabled"": false,
        ""position"": ""right"",
        ""inside"": false,
    }],
    ""graphs"": [{
        ""valueAxis"": ""v1"",
        ""type"": ""smoothedLine"",
        ""labelOffset"" : 5,
        ""lineColor"": ""#ee7b0b"",
        ""bullet"": ""round"",
        ""bulletBorderThickness"": 1,
        ""lineThickness"": 3,
        'balloonText': '[[category]]&lt;br&gt;&lt;b&gt;&lt;span style=font-size:14px;&gt;[[value]]&lt;/span&gt;&lt;/b&gt;',
        ""title"": ""NewDailyConfirmed"",
        ""labelText"" : ""[[value]]"",
        ""valueField"": ""NewDailyConfirmed"",
    ""fillAlphas"": 0
    }, {
         ""valueAxis"": ""v1"",
            ""lineColor"": ""#FF0000"",
            ""type"": ""smoothedLine"",
            ""bullet"": ""square"",
            'balloonText': '[[category]]&lt;br&gt;&lt;b&gt;&lt;span style=font-size:14px;&gt;[[value]]&lt;/span&gt;&lt;/b&gt;',
        ""bulletBorderThickness"": 1,
            ""lineThickness"": 3,
            ""labelOffset"": 5,
           ""labelPosition"" : ""bottom"",
            ""title"": ""Deaths"",
            ""labelText"": ""[[value]]"",
        ""valueField"": ""Deaths"",
    ""fillAlphas"": 0
    }, {
        ""valueAxis"": ""v1"",
            ""lineColor"": ""#7CB5EC"",
            ""type"": ""smoothedLine"",
        ""bullet"": ""triangleUp"",
            ""bulletBorderThickness"": 1,
            'balloonText': '[[category]]&lt;br&gt;&lt;b&gt;&lt;span style=font-size:14px;&gt;[[value]]&lt;/span&gt;&lt;/b&gt;',
            ""lineThickness"": 3,
            ""labelOffset"": 10,
            ""title"": ""NewDailyRecovered"",
            ""labelText"": ""[[value]]"",
            ""valueField"": ""NewDailyRecovered"",
    ""fillAlphas"": 0
    }],
    ""chartCursor"": {
        'cursorAlpha': 0,
        'valueLineEnabled': true,
        'valueLineBalloonEnabled': true,
        'valueLineAlpha': 0.5,
        'categoryBalloonColor': '#E2EEF6',
        'color': '#000'
    },
    ""categoryField"": ""ForDate"",
        ""categoryAxis"": {
            'parseDates': false,
            'minHorizontalGap': 110,
            'labelsEnabled': false,

            'axisColor': '#fff', 'minorGridEnabled': false, 'autoGridCount': false, 'gridCount': 8, 'labelOffset': 10
        },
        ""legend"": {
            ""useGraphSettings"": true,
            ""position"": ""bottom"",
        },
});</code></pre>
<pre class=""snippet-code-css lang-css prettyprint-override""><code> #MultiAxisCovidChartDiv {
        width: 100%;
        height: 400px;
    }</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;div id=""MultiAxisCovidChartDiv"" class=""multiple_covid_charts""&gt;&lt;/div&gt;
&lt;script src=""https://www.amcharts.com/lib/3/amcharts.js""&gt;&lt;/script&gt;
&lt;script src=""https://www.amcharts.com/lib/3/serial.js""&gt;&lt;/script&gt;
&lt;script src=""https://www.amcharts.com/lib/3/plugins/export/export.min.js""&gt;&lt;/script&gt;
&lt;link rel=""stylesheet"" href=""https://www.amcharts.com/lib/3/plugins/export/export.css"" type=""text/css"" media=""all"" /&gt;</code></pre>
</div>
</div>
</p>

<p>Now You can see the each label on top of each point , I want to show a label after certain gap of points , like after 3 points I want to show label . is it possible if yes then how ? </p>
"
61241594,"<p>I'm trying to create a website for personal use that gathers Coronavirus data. It will track the global percentage rate of people infected, total global cases, total United States cases, and total cases by state. As you know, getting data from all 50 states + territories every time I want to update it is a nightmare. I've learned that this is possible with AJAX. Only problem is, I don't know how to make the code to do that. Is this possible? If so, could you help me make the code?</p>
"
61310424,"<p>I want to switch from main (home) section to, for instance, about section. I want to just replace my main content with new about section (whole bootstrap container). I want to make it fade out while about section comes in. Of course, without refreshing the page. Like on this website (try switching sections): <a href=""https://covid19stats.live/"" rel=""nofollow noreferrer"">https://covid19stats.live/</a></p>

<p>How can I do it?</p>
"
61131072,"<p>I want to inverse two columns position when an event come, the right be the left and Vice versa; </p>

<pre><code>  &lt;div class=""row""&gt;
          &lt;div class=""col-6 d-flex align-items-center justify-content-center ""&gt;
            &lt;div class=""logo-centered"" id=""logo_auth""&gt;
              &lt;a href=""#default""&gt;
                &lt;img src=""assets/img/baladiaty-t.svg"" alt=""logo""&gt;
              &lt;/a&gt;
            &lt;/div&gt;
          &lt;/div&gt;
          &lt;div class=""col-6 d-flex align-items-center justify-content-center""&gt;
            &lt;div class=""v1-slogan"" id=""v1_slogan""&gt;
              &lt;h3&gt;Spécial covid-19&lt;/h3&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
</code></pre>

<hr>

<pre><code>.logo-centered{
  width: auto !important;
}
</code></pre>
"
61058618,"<p>How do I make it possible to choose a country in the drop down menu and get the data of that country?
Country codes:</p>

<pre><code>Netherlands 169

Germany 120

France 116

Spain 225

Italy 137

Russia 187

South-Korea 143

USA 201
</code></pre>

<p>(The country code for the Netherlands is 169 in the fetch function, should be 120 for Germany etc.)</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>window.onload = function() {
	getCovidStats();
}

function getCovidStats() {
	fetch('https://coronavirus-tracker-api.herokuapp.com/v2/locations/169')
	.then(function(resp) { return resp.json() })
	.then(function(data) {
		let population = data.location.country_population;
		let update = data.location.last_updated;
		let confirmedCases = data.location.latest.confirmed;
		let deaths = data.location.latest.deaths;

		document.getElementById('population').innerHTML = population.toLocaleString('en');
		document.getElementById('update').innerHTML = update.substr(0, 10);
		document.getElementById('cases').innerHTML = confirmedCases.toLocaleString('en');
		document.getElementById('deaths').innerHTML = deaths.toLocaleString('en');
		document.getElementById('percent').innerHTML = ((Number(deaths)/Number(confirmedCases))*100).toLocaleString(""en"", {minimumFractionDigits: 2, maximumFractionDigits: 2}) + ""%"";




	})
	.catch(function() {
		console.log(""error"");
	})
	setTimeout(getCovidStats, 43200000) // update every 12 hours
}</code></pre>
<pre class=""snippet-code-css lang-css prettyprint-override""><code>* {
	margin: 0;
	padding: 0;
}

html {
	height: 100%;
	width: 100%;
}
h1, h2 {
	font-family: 'Roboto', sans-serif;
	font-weight: 300;
	text-align: center;
	padding-bottom: 20px;
	font-size: 250%;
}

.title {
	background: linear-gradient(to right, #feb47b, #ff7e5f);
	padding: 20px;
}

.subtitle {
	padding: 20px;
	font-size: 150%;
}

div {
	padding: 20px;
}

.stats-container {
	text-align: center;
	float: right;
	display: inline-block;
}
.location-container {
	display: inline-block;
}
.data-container {
	border: 2px solid #feb47b;
	margin-right: 30%;
	margin-left: 30%;

}
h4 {
	font-size: 85%;
 	color: gray;
 	font-family: 'Roboto', sans-serif;
 	font-weight: 300;
 	text-align: center;
 	padding-top: 20px;
 	padding-left: 20px;
 	padding-right: 20px;
 	padding-bottom: 5px;
}
.footer {
	font-family: 'Roboto', sans-serif;
	bottom: 0;
	font-size: 75%;
	padding: 5px;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
	&lt;title&gt;Name&lt;/title&gt;

	&lt;link rel=""shortcut icon"" href=""masker-emoji.png""&gt;
	&lt;link href=""https://fonts.googleapis.com/css?family=Roboto:100,300,400&amp;display=swap"" rel=""stylesheet""&gt;
	&lt;link rel=""stylesheet"" type=""text/css"" href=""styles.css""&gt;
	&lt;script type=""text/javascript"" src=""app.js""&gt;&lt;/script&gt;

&lt;/head&gt;
&lt;body&gt;
	&lt;h1 class=""title""&gt;Coronavirus Stats.&lt;/h1&gt;
	&lt;h2 class=""subtitle""&gt;Subtitle&lt;/h2&gt;
	&lt;div class=""data-container""&gt;
		&lt;div class=""stats-container""&gt;
			&lt;h4&gt;Tested positive&lt;/h4&gt;
			&lt;h1 id=""cases""&gt;&lt;/h1&gt;
			&lt;h4&gt;Deaths&lt;/h4&gt;
			&lt;h1 id=""deaths""&gt;&lt;/h1&gt;
			&lt;h4&gt;Death percentage&lt;/h4&gt;
			&lt;h1 id=""percent""&gt;&lt;/h1&gt;
		&lt;/div&gt;
		&lt;div class=""location-container""&gt;
			&lt;h4&gt;Land&lt;/h4&gt;
			&lt;h1 id=""country""&gt;&lt;label for=""Country""&gt;Country:&lt;/label&gt;
				&lt;select id=""cars""&gt;
				  &lt;option value=""Netherlands""&gt;Netherlands&lt;/option&gt;
				  &lt;option value=""Germany""&gt;Germany&lt;/option&gt;
				  &lt;option value=""France""&gt;France&lt;/option&gt;
				  &lt;option value=""Spain""&gt;Spain&lt;/option&gt;
				  &lt;option value=""Italy""&gt;Italy&lt;/option&gt;
				  &lt;option value=""Russia""&gt;Russia&lt;/option&gt;
				  &lt;option value=""South-Korea""&gt;South-Korea&lt;/option&gt;
				  &lt;option value=""USA""&gt;USA&lt;/option&gt;
				&lt;/select&gt;&lt;/h1&gt;
			&lt;h4&gt;Population&lt;/h4&gt;
			&lt;h1 id=""population""&gt;&lt;/h1&gt;
			&lt;h4&gt;Last update on&lt;/h4&gt;
			&lt;h1 id=""update""&gt;&lt;/h1&gt;
		&lt;/div&gt;
	&lt;/div&gt;
	&lt;h1 class=""footer""&gt;Footer&lt;/h1&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
</div>
</p>
"
61354933,"<p>There is the US json for the current situation in US, yet the json only shows the States while I'd also need the coordinates to place them in a map.</p>

<p><a href=""https://covidtracking.com/api/v1/states/daily.json"" rel=""nofollow noreferrer"">us data</a></p>

<p><a href=""https://developers.google.com/public-data/docs/canonical/states_csv"" rel=""nofollow noreferrer"">On here</a> we have the <code>long</code> and <code>lat</code> for each State, not sure how could I merge the 2 to combine them into a single file adding the coordinates for each State.</p>

<p>US data json is:</p>

<pre><code>[
  {
    ""date"": 20200421,
    ""state"": ""AK"",
    ...
  },
  {
    ""date"": 20200421,
    ""state"": ""AL"",
    ""positive"": 5231,
    ""negative"": 43295,...
</code></pre>

<p>For each state I am looking at adding:</p>

<pre><code>[
  {
    ""date"": 20200421,
    ""state"": ""AK"",
    ""lat"": ""63.588753"",
    ""long"": ""-154.493062"",
</code></pre>

<p>Then be able to download it. Or is there any other way I could programmatically get the coords instead of adding them each time? Not sure how to approach it.</p>

<p><strong>UPDATE</strong></p>

<p>Added <code>php tag</code> too as this could be done via backend.</p>
"
61641069,"<p>I am trying to automatize getting data from <strong><em>Figure 1: Electricity consumption relative to 2019</em></strong> in this <a href=""https://www.bruegel.org/2020/03/covid-19-crisis-electricity-demand-as-a-real-time-indicator/"" rel=""nofollow noreferrer"">article</a>. I have no issues with scraping from a normal page, but this chart is done in JS and I have no clue how to proceed or where to find the data that the chart uses. </p>
"
61157945,"<p>I have a <a href=""https://covid615.com/counties/davidson"" rel=""nofollow noreferrer"">table of integer values and dates</a> showing Covid-19 cases in Nasvhille, TN, and I'm trying to plot each case per day as a line chart with <a href=""https://www.chartjs.org"" rel=""nofollow noreferrer"">Chart.js</a> in Rails. I'd rather not have to use the <a href=""https://github.com/ankane/chartkick"" rel=""nofollow noreferrer"">Chartkick</a> gem, and instead just pass the value directly to Chart.js, but I'm having trouble getting the dates formatted. Chart.js is plotting the integer values, but right now my Chart.js code is just displaying random years on the x-axis for the date. Here's what the chart looks like currently:</p>

<p><a href=""https://i.stack.imgur.com/R6TtD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/R6TtD.png"" alt=""Screenshot of the incorrect chart""></a></p>

<p>How do I pass the date for each integer value to Chart.js and format it like ""March 28, 2020""?</p>

<p>Here's my code that's not working (<a href=""https://github.com/leemcalilly/coronavirus/blob/master/app/views/counties/_charts.html.erb"" rel=""nofollow noreferrer"">_charts.html.erb</a>):</p>

<pre><code>&lt;!-- Chart.js --&gt;
&lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.3/Chart.min.js"" defer&gt;&lt;/script&gt;

&lt;canvas id=""myChart"" width=""400"" height=""400""&gt;&lt;/canvas&gt;
&lt;script&gt;
window.onload = () =&gt; {
  var ctx = document.getElementById('myChart').getContext('2d');

  var myChart = new Chart(ctx, {
      type: 'line',
      data: {
          labels: [
            &lt;%= @county.updates.map {|update| update.date}.join("","") %&gt;
          ],

          datasets: [{
              label: ""Total Cases"",
              data: [
                &lt;%= @county.updates.map {|update| update.total_cases}.join("","") %&gt;
              ],
              backgroundColor: [
                  'rgba(255, 99, 132, 0.2)'
              ],
              borderColor: [
                  'rgba(255, 99, 132, 1)'
              ],
              borderWidth: 1
          }]
      },
      options: {
          scales: {
              yAxes: [{
                  ticks: {
                      beginAtZero: true
                  }
              }]
          }
      }
  });
}
&lt;/script&gt;

&lt;!-- Example of how I'd like the dates to be formatted for reference --&gt;
&lt;%= @county.updates.map {|update| update.date.strftime(""%b %e"")}.join("", "") %&gt;
</code></pre>

<p>I'm simply trying to just embed all of the javascript needed for Chart.js directly into the view to get an initial version working.</p>

<p>You can see <a href=""https://github.com/leemcalilly/coronavirus"" rel=""nofollow noreferrer"">all the code for the app here</a>.</p>
"
61263402,"<p><a href=""https://i.stack.imgur.com/zov02.png"" rel=""nofollow noreferrer"">enter image description here</a>I am doing a side project to React, using Axios to fetch <a href=""https://newsapi.org/"" rel=""nofollow noreferrer"">https://newsapi.org/</a> coronavirus related news. Now I can display the news on the screen. My goal is simple, not only display the news but when clicking the image, it will redirect the user to that specific piece of news. I add React-router to the project, but now I cannot display that specific piece of news. Here is the GitHub, <a href=""https://github.com/xnslx/React-router-practice-fetch-newsapi"" rel=""nofollow noreferrer"">https://github.com/xnslx/React-router-practice-fetch-newsapi</a> </p>

<p><a href=""https://i.stack.imgur.com/RJR3w.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RJR3w.png"" alt=""enter image description here""></a></p>

<p>For the initial data that were fetched, there was no id for each piece of news, then I assign the index for them as 'id'. Is there any other better way to do it? Also, is the project still doable since there is no original id for each piece of news? </p>
"
61668266,"<p>Im trying to separate my data so it can all fit individually in their own discord MessageEmbed fields for a corona info command for my discord bot. This is my first time legitimately doing anything with axios and i cant seem to figure out how to separate variables in the way i was wanting. help is greatly appreciated.</p>

<p>output:</p>

<pre><code>[
  {
    confirmed: 3912421,
    recovered: 1344997,
    critical: 48974,
    deaths: 270065,
    lastChange: '2020-05-07T23:29:58+02:00',
    lastUpdate: '2020-05-07T23:30:02+02:00'
  }
]
</code></pre>

<p>Code:</p>

<pre class=""lang-js prettyprint-override""><code>const axios = require(""axios"");
const Discord = require(""discord.js"");
var http = require(""https"");


module.exports = {
name: 'covid',
description: 'covid info',
},
 module.exports.execute = async(message, args) =&gt; {



var options = {
    ""method"": ""GET"",
    ""hostname"": ""covid-19-data.p.rapidapi.com"",
    ""port"": null,
    ""path"": ""/totals?format=json"",
    ""headers"": {
        ""x-rapidapi-host"": ""covid-19-data.p.rapidapi.com"",
        ""x-rapidapi-key"": ""key removed""
    }
};

var req = http.request(options, function (res) {
    var chunks = [];

    res.on(""data"", function (chunk) {
        chunks.push(chunk);
    });

    res.on(""end"", function () {
        var body = Buffer.concat(chunks);
//var apiResult = JSON.stringify(body.toString());
let api2 = JSON.parse(body.toString());

        console.log(api2);
//console.log(data);
message.channel.send(api2);
const embed = new Discord.MessageEmbed()
.setTitle('CORONA-19 WORLD STATS')
.addFields(
//{ name: 'Confirmed:', value:  api2[0]},
        //{ name: 'Recovered:', value:  api[1]},
        //{ name: 'Critical:', value: api2[2], inline: true },
        //{ name: 'Deaths:', value: api2[3], inline: true },
)
message.channel.send({embed});
    });
});

req.end();


}

</code></pre>
"
61468234,"<p>I have successfully fetched data from API. The fetched data shows in the alert function. However, the properties in the data function such as - 'Recovered' is not updating. I can show the fetched data using Vanilla JS. But I want to update them automatically and want to show them like this {{Recovered}}. 
How can I do it??</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>&lt;template&gt;
    &lt;div class=""container""&gt;

        &lt;h2&gt;Total Recovered: {{Recovered}}&lt;/h2&gt;

    &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
    import axios from 'axios'
    export default {
        name:'CoronaStatus',
        data: function () {
            return {

                    Recovered: '',
                    TotalConfirmed: '',
                    TotalDeaths: '',
                    // test: '30',
                    // test_2: 'maheeb',
                    // componentKey: 0,



            }
        },
        mounted(){
            this.globalStatus();
        },

        methods:{
            globalStatus: function(){
                // const self = this;
                // this.componentKey += 1;
                axios.get('https://api.covid19api.com/summary')

                    .then((response) =&gt; {
                           // this.recovered = response.data.Global.NewConfirmed;
                        this.Recovered= response.data.Global.TotalRecovered;


                        alert(this.Recovered);

                    
                        // document.getElementById('test_5').innerHTML = ""total: "" + this.TotalRecovered;

                }).catch(err=&gt; console.log(err));


            },


        }


    }
&lt;/script&gt;

&lt;style scoped&gt;

&lt;/style&gt;</code></pre>
</div>
</div>
</p>
"
61232576,"<p>I am trying to grab the statistic of the COVID-19 from an API from RapidAPI. I want to grab the stats by date insert the data into a Graph. The problem is the API link can only have a date in it, like this:</p>

<p><code>https://covid-19-data.p.rapidapi.com/report/totals?date-format=undefined&amp;format=undefined&amp;date=2020-04-15</code></p>

<p>What I did is use a for loop to get ten dates and use Axios to retrieve every day's data like so:</p>

<pre><code>const today = new Date();
const dd = String(today.getDate()).padStart(2, '0');
const mm = String(today.getMonth() + 1).padStart(2, '0');

const [labels, setLabels] = useState([])

useEffect(() =&gt; {

    for(let i=dd-10; i&lt;dd; i++) {
        Axios({
            method: 'GET',
            url: `https://covid-19-data.p.rapidapi.com/report/totals?date-format=undefined&amp;format=undefined&amp;date=2020-${mm}-${i}`,
            headers: {
                ""x-rapidapi-host"": ""covid-19-data.p.rapidapi.com"",
                ""x-rapidapi-key"": ""cfb0f14a9fmsh913ae802309e7c9p175585jsn825aebcbd5ac""
            }
        })
        .then(response =&gt; {
            let temp = [...labels]
            temp.push(response.data[0].date)
            setLabels(temp)
        })
        .catch(error =&gt; {
            console.log(error)
        })
    }

}, [])
</code></pre>

<p>And the problem is instead of appending the new date to <code>labels</code> array, the <code>labels</code> change every time Axios retrieves a new date. </p>

<p>I did some research online and people say something like the data is not yet loaded hence when I set the state it sort of set empty stuff and something like that but I don't quite understand what they are saying. </p>

<p>Besides that, when it retrieves data, it doesn't retrieve it in order. For example, today is the 15th of April, it should retrieve the data in order like: <code>05 06 07 08 09 10 11 12 13 14</code> but instead, it just jumps randomly. If I console.log it at .then(), this will appear:</p>

<p><a href=""https://i.stack.imgur.com/WsLYm.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WsLYm.jpg"" alt=""img""></a></p>

<p>As you can see, it is not in order.</p>

<p>Please help me take a look, I'd googled for solutions but to no avail.</p>
"
60926870,"<p>I'm working on a self-assessment feature, that will enable people to know whether they are at risk of having been infected with corona or not hence advising them whether to get tested or not. I have created a number of radio group button to allow the patient to check different symptoms, for each clicked radio button is assigned which is supposed to be added together with other values so as to find a score upon which we can know whether the patient should proceed to covid-19 testing or not. I need help in fixing my code so that I can be able to read and add all the values of each radio button. Here is my code. </p>

<pre><code>if (view is RadioButton) {
        // Is the button now checked?
        val checked = view.isChecked

        // Check which radio button was clicked
        when (view.getId()) {
            R.id.yes_1 -&gt;
                if (checked) {
                    val yes1= 1
                    Toast.makeText(this, ""Yes 1"", Toast.LENGTH_LONG).show()
                }
            R.id.no_1 -&gt;
                if (checked){
                    val no1=0
                    Toast.makeText(this, "" No 1"", Toast.LENGTH_SHORT).show()
                }
            R.id.yes_2 -&gt;
                if (checked) {
                    val yes2= 1
                    Toast.makeText(this, ""Yes 2"", Toast.LENGTH_LONG).show()
                }
            R.id.no_2 -&gt;
                if (checked) {
                    val no2= 0
                    Toast.makeText(this, ""No 2"", Toast.LENGTH_SHORT).show()
                }
            R.id.yes_3 -&gt;
                if (checked) {
                    val yes3=1
                    Toast.makeText(this, ""Yes 3"", Toast.LENGTH_LONG).show()
                }
            R.id.no_3 -&gt;
                if (checked) {
                    val no3=0
                    Toast.makeText(this, ""No 3"", Toast.LENGTH_SHORT).show()
                }
            R.id.yes_4 -&gt;
                if (checked) {
                    val yes4=1
                    Toast.makeText(this, ""Yes 4"", Toast.LENGTH_LONG).show()
                }
            R.id.no_4 -&gt;
                if (checked) {
                    val no4=0
                    Toast.makeText(this, ""No 4"", Toast.LENGTH_SHORT).show()
                }
            R.id.yes_5 -&gt;
                if (checked) {
                    val yes5=5
                    Toast.makeText(this, ""Yes 5"", Toast.LENGTH_LONG).show()
                }
            R.id.no_5 -&gt;
                if (checked) {
                    val no5=0
                    Toast.makeText(this, ""No 5"", Toast.LENGTH_SHORT).show()
                }
            R.id.yes_6 -&gt;
                if (checked) {
                    val yes6=5
                    Toast.makeText(this, ""Yes 6"", Toast.LENGTH_LONG).show()
                }
            R.id.no_6 -&gt;
                if (checked) {
                    val no6=0
                    Toast.makeText(this, ""No 6"", Toast.LENGTH_SHORT).show()
                }
        }
        val assesment_point= yes1 + n01 + yes2 + no2 +yes3 + no3 + yes4 + no4 + yes5 + no5 + yes6 + no6
    }
}
</code></pre>

<p><a href=""https://i.stack.imgur.com/OOIl2.png"" rel=""nofollow noreferrer"">Here is the screenshot of how the app works</a></p>
"
61580247,"<p>I want to fetch data from this file: <a href=""https://api.covid19india.org/state_district_wise.json"" rel=""nofollow noreferrer"">https://api.covid19india.org/state_district_wise.json</a></p>

<pre><code>        final ProgressDialog progressDialog = new ProgressDialog(this);
        progressDialog.setMessage(""Loading data..."");
        progressDialog.show();
        StringRequest stringRequest = new StringRequest(Request.Method.GET,
                ""https://api.covid19india.org/state_district_wise.json"",
                new Response.Listener&lt;String&gt;() {
                    @Override
                    public void onResponse(String response) {
                        try {
                            JSONObject jsonObject = new JSONObject(response);
                            JSONArray jsonArray = jsonObject.getJSONArray(""Jammu and Kashmir"");
                            progressDialog.cancel();
                            for(int i = 0; i &lt; jsonArray.length(); i++) {
                                JSONObject object = jsonArray.getJSONObject(i);
                                // I want get case details of ""Jammu and Kashmir""
                            }
                        } catch (Exception e) {
                        }

                    }
                }, new Response.ErrorListener() {
            @Override
            public void onErrorResponse(VolleyError error) {
                //
            }
        });
        RequestQueue requestQueue = Volley.newRequestQueue(this);
        requestQueue.add(stringRequest);
</code></pre>

<p>What should I use here:</p>

<p>JSONArray jsonArray = jsonObject.getJSONArray(""Jammu and Kashmir"");</p>
"
61277942,"<p>I am trying to work on a wordpress theme custom made by someone else who is no longer available to answer questions about this so I am turning to you all. I have read a lot of articles but seem unable to resolve the issue. The page in question is live and it is here - <a href=""https://fourthwalljobs.com/covid-19-resources-for-artists/"" rel=""nofollow noreferrer"">https://fourthwalljobs.com/covid-19-resources-for-artists/</a> </p>

<p>IF you code inspect, you will see the paragraph about ""unemployment"" is supposed to be a red background in that area but isnt. The pseudo is set but doesnt seem to affect anything. Can anyone help shed light on what the issue that is blocking that from occurring seems to be and how I fix that? I prefer to not have to start overriding things on individual pages using the ""!important"" tag. </p>

<p>Additionally all of the links (which are black and underlined) should be showing as blue color but obviously are not. </p>
"
60798320,"<p>Really struggling with the can't find a definitive answer on this. Trying to help my local community by promoting a list of business that are still operating during the covid-19 outbreak.</p>

<p>My problem is that the table width in mobile view looks awful and basically chops off the last column. Please can you advise any css I could use to correct this?</p>

<p>See <a href=""https://www.larklaneguide.com/delivery-and-takeaway-on-lark-lane-during-covid-19/"" rel=""nofollow noreferrer"">https://www.larklaneguide.com/delivery-and-takeaway-on-lark-lane-during-covid-19/</a></p>

<p>TIA</p>

<p>Clare</p>
"
61663173,"<p>Using githubs GraphQL API, I am trying to get a list of all repos (created after 01/01/2019) whose name contain any of the following strings: [""covid"", ""coronavirus"", ""Wuhan""]. I only really want the name of the repo, the date of creation, and whether it's a fork or not, as I have specified below. Right now I have,</p>

<pre><code> {
  search(query: ""name:coronavirus, created:&gt;2019-01-01"", type: REPOSITORY, first: 5) {
    repositoryCount
    edges {
      node {
        ... on Repository {
          id
          name
          createdAt
          description
          isFork
        }
      }
    }
  }
}

</code></pre>

<p>I'm having trouble figuring out how to use the 'OR' operator in the query name field, or if it is even possible. Any help is appreciated, thanks!</p>
"
60976939,"<p>I'm basically importing both Tables from <a href=""https://santemontreal.qc.ca/en/public/coronavirus-covid-19/"" rel=""nofollow noreferrer"" title=""this"">this</a> website.</p>

<p>Q1. When I'm importing data via IMPORTHTML and sorting out results, some results are showing as ""5 cases or less"". It's making it hard to sort it out. I want these to come after 0. How can I make sure of that? 
<img src=""https://i.imgur.com/04dnX9G.png"" alt=""""></p>

<p>Q2. I wish to import only the numbers from the  element. It's basically a whole phrase. How do I only import the last number, in such case, 1,991?
<img src=""https://i.imgur.com/gDf10pF.png"" alt=""""></p>

<p>Here is my <a href=""https://docs.google.com/spreadsheets/d/18_Dmrd2jCbrDvWnfX-iz4h8LzqBKUj1Cq7UZN_VGlEA/edit#gid=1641564543"" rel=""nofollow noreferrer"" title=""18_Dmrd2jCbrDvWnfX-iz4h8LzqBKUj1Cq7UZN_VGlEA"">Sample Google Sheet</a></p>
"
60820556,"<p>I am trying to do some web scrapping to pull the data tables located on this webpage (<a href=""https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html#g-cases-by-county"" rel=""nofollow noreferrer"">https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html#g-cases-by-county</a>)</p>

<p>Right now, the tables have a collapsible/expandable button (show more). When I try to use the url to pull the tables in r, I only get the rows that are not in the collapsed section. Below is my code. Is there a way to un-collapse the sections so I can get all the data in the tables. </p>

<pre><code> 'https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html#g-cases-by-county' %&gt;%
  read_html() %&gt;%
  html_table()
</code></pre>
"
60821209,"<pre><code>&lt;atom:link rel=""self"" href=""http://www.independent.co.uk/""/&gt;
&lt;item&gt;
&lt;title&gt;
Coronavirus: Why the Covid-19 economic stimulus deal will make it to Trump&amp;apos;s desk
&lt;/title&gt;
&lt;link&gt;
https://www.independent.co.uk/news/world/americas/us-politics/coronavirus-economic-stimulus-deal-covid-19-trump-bill-senate-house-a9419976.html
&lt;/link&gt;
&lt;description&gt;
&lt;![CDATA[
News Analysis: When Senate tries to pass major bills, there's always one day of chaos. Monday appears to be that day.
]]&gt;
&lt;/description&gt;
</code></pre>

<p>For the content above i would like to extract the title, link and description
How can I formulate my regex rule to capture this?</p>

<p>The end goal being to dump the extracted content to a predefined sql db that i created</p>
"
61632247,"<p>I have browsed some of the answers and tried the solutions out but I am still not getting the results. </p>

<p>I want to set a different margin for different breakpoints in bootstrap-for example:</p>

<p><a href=""https://i.stack.imgur.com/UBZyB.png"" rel=""nofollow noreferrer"">Laptop view fix</a>,
<a href=""https://i.stack.imgur.com/Jtxzu.png"" rel=""nofollow noreferrer"">tablet view</a></p>

<p>It probably has something to do with the set widths as well, but I just didn't know how to make everything work in width as well as have margin look good on all screen sizes.</p>

<p>This is my code : </p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-css lang-css prettyprint-override""><code>.container {
  max-width: 25rem;
  text-align: center;
  padding: 0rem;
  margin: 1rem 0.4rem;
}

.table.table.table-borderless {
  margin-bottom: 0rem;
}

.table.table.table-borderless td,
.table.table-dark.table-borderless td {
  padding: 0rem;
}

table.statistic-employment,
table.statistic-requirement {
  width: 24.8rem;
}

.statistic-requirement {
  height: 10 rem;
}

.col-12.col-md-6.col-xl-4 {
  padding: 0rem 0rem;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;meta name=""viewport"" content=""width=device-width, initial-scale=1.0 shrink-to-fit=no""&gt;
&lt;link rel=""stylesheet"" href=""https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"" integrity=""sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh"" crossorigin=""anonymous""&gt;




&lt;div class=""main-container""&gt;
  &lt;div class=""row""&gt;
    &lt;div class=""col-12 col-md-6 col-xl-4 ""&gt;
      &lt;!--Prva kartica--&gt;
      &lt;div class=""container""&gt;
        &lt;table class=""table table-borderless"" style=""background-color: thistle;""&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td style=""font-weight: 400; font-size: 3rem;""&gt;UKUPNO&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;

        &lt;table class=""table table-dark table-borderless""&gt;
          &lt;tbody&gt;
            &lt;tr&gt;
              &lt;td&gt;Zaprimljeno zahtjeva&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td style=""font-size: 5.5rem;""&gt;4979&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;poslano&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;17.4.2020. do 12h&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/tbody&gt;
        &lt;/table&gt;

        &lt;table class=""table table-borderless"" style=""background-color: thistle; font-weight: 700;""&gt;
          &lt;tr&gt;
            &lt;td&gt;Osobna provjera&lt;/td&gt;
            &lt;td&gt;SMS obavijest&lt;/td&gt;
            &lt;td&gt;Kontakt centar&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td style=""font-size: 2.5rem;""&gt;6243&lt;/td&gt;
            &lt;td style=""font-size: 2.5rem;""&gt;2322&lt;/td&gt;
            &lt;td style=""font-size: 2.5rem;""&gt;230&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/table&gt;

        &lt;div class=""statistic-employment"" style=""background-color: rgb(228, 224, 224); height: 11rem;""&gt;
          &lt;h6&gt;Po statusu zaposlenosti&lt;/h6&gt;
          &lt;table class=""statistic-employment""&gt;
            &lt;tr&gt;
              &lt;td&gt;EMPLOYED&lt;/td&gt;
              &lt;td&gt;6308&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;PENSIONER&lt;/td&gt;
              &lt;td&gt;251&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;PENSIONER_EMPLOYED&lt;/td&gt;
              &lt;td&gt;34&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;UNEMPLOYED&lt;/td&gt;
              &lt;td&gt;952&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;UNEMPLOYED_COVID&lt;/td&gt;
              &lt;td&gt;1090&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/table&gt;
        &lt;/div&gt;
        &lt;div class=""statistic-requirement"" style=""background-color: rgb(238, 189, 223); height: 9.8rem;""&gt;

          &lt;h6&gt;Broj upisanih po danu&lt;/h6&gt;

          &lt;table class=""statistic-requirement""&gt;
            &lt;tr&gt;
              &lt;td&gt;datum&lt;/td&gt;
              &lt;td&gt;dan&lt;/td&gt;
              &lt;td&gt;zahtjeva&lt;/td&gt;
            &lt;/tr&gt;

            &lt;tr&gt;
              &lt;td&gt;06.04.&lt;/td&gt;
              &lt;td&gt;ponedjeljak&lt;/td&gt;
              &lt;td&gt;2640&lt;/td&gt;
            &lt;/tr&gt;

            &lt;tr&gt;
              &lt;td&gt;07.04.&lt;/td&gt;
              &lt;td&gt;utorak&lt;/td&gt;
              &lt;td&gt;1205&lt;/td&gt;
            &lt;/tr&gt;

            &lt;tr&gt;
              &lt;td&gt;08.04.&lt;/td&gt;
              &lt;td&gt;srijeda&lt;/td&gt;
              &lt;td&gt;700&lt;/td&gt;
            &lt;/tr&gt;

          &lt;/table&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;


    &lt;div class=""col-12 col-md-6 col-xl-4""&gt;
      &lt;!--Druga kartica--&gt;

      &lt;div class=""container""&gt;
        &lt;table class=""table table-borderless"" style=""background-color: thistle;""&gt;
          &lt;tr&gt;
            &lt;td style=""font-weight: 400; font-size: 3rem;""&gt;UKUPNO&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/table&gt;

        &lt;table class=""table table-dark table-borderless""&gt;
          &lt;tr&gt;
            &lt;td&gt;Zaprimljeno zahtjeva&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td style=""font-size: 5.5rem;""&gt;4979&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td&gt;poslano&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td&gt;17.4.2020. do 12h&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/table&gt;

        &lt;table class=""table table-borderless"" style=""background-color: thistle; font-weight: 700;""&gt;
          &lt;tr&gt;
            &lt;td&gt;Osobna provjera&lt;/td&gt;
            &lt;td&gt;SMS obavijest&lt;/td&gt;
            &lt;td&gt;Kontakt centar&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td style=""font-size: 2.5rem;""&gt;6243&lt;/td&gt;
            &lt;td style=""font-size: 2.5rem;""&gt;2322&lt;/td&gt;
            &lt;td style=""font-size: 2.5rem;""&gt;230&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/table&gt;

        &lt;div class=""statistic-employment"" style=""background-color: rgb(228, 224, 224); height: 11rem;""&gt;
          &lt;h6&gt;Po statusu zaposlenosti&lt;/h6&gt;
          &lt;table class=""statistic-employment""&gt;
            &lt;tr&gt;
              &lt;td&gt;EMPLOYED&lt;/td&gt;
              &lt;td&gt;6308&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;PENSIONER&lt;/td&gt;
              &lt;td&gt;251&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;UNEMPLOYED&lt;/td&gt;
              &lt;td&gt;952&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;UNEMPLOYED_COVID&lt;/td&gt;
              &lt;td&gt;1090&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/table&gt;
        &lt;/div&gt;
        &lt;div class=""statistic-requirement"" style=""background-color: rgb(238, 189, 223);""&gt;

          &lt;h6&gt;Broj upisanih po satu&lt;/h6&gt;

          &lt;table class=""statistic-requirement""&gt;
            &lt;tr&gt;
              &lt;td&gt;datum&lt;/td&gt;
              &lt;td&gt;sat&lt;/td&gt;
              &lt;td&gt;zahtjeva&lt;/td&gt;
            &lt;/tr&gt;

            &lt;tr&gt;
              &lt;td&gt;27.04.&lt;/td&gt;
              &lt;td&gt;06&lt;/td&gt;
              &lt;td&gt;1&lt;/td&gt;
            &lt;/tr&gt;

            &lt;tr&gt;
              &lt;td&gt;27.04.&lt;/td&gt;
              &lt;td&gt;07&lt;/td&gt;
              &lt;td&gt;3&lt;/td&gt;
            &lt;/tr&gt;

            &lt;tr&gt;
              &lt;td&gt;27.04.&lt;/td&gt;
              &lt;td&gt;08&lt;/td&gt;
              &lt;td&gt;11&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;27.04.&lt;/td&gt;
              &lt;td&gt;09&lt;/td&gt;
              &lt;td&gt;26&lt;/td&gt;
            &lt;/tr&gt;

          &lt;/table&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;

    &lt;div class=""col-12 col-md-6 col-xl-4""&gt;
      &lt;!--Treca kartica--&gt;

      &lt;div class=""container""&gt;
        &lt;table class=""table table-borderless"" style=""background-color: thistle;""&gt;
          &lt;tr&gt;
            &lt;td style=""font-weight: 400; font-size: 3rem;""&gt;UKUPNO&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/table&gt;

        &lt;table class=""table table-dark table-borderless""&gt;
          &lt;tr&gt;
            &lt;td style=""padding: 0rem""&gt;Zaprimljeno zahtjeva&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td style=""font-size: 5.5rem; padding: 0rem ""&gt;4979&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td style=""padding: 0rem""&gt;poslano&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td style=""padding: 0rem""&gt;17.4.2020. do 12h&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/table&gt;

        &lt;table class=""table table-borderless"" style=""background-color: thistle
                        ; font-weight: 700;""&gt;
          &lt;tr&gt;
            &lt;td&gt;Osobna provjera&lt;/td&gt;
            &lt;td&gt;SMS obavijest&lt;/td&gt;
            &lt;td&gt;Kontakt centar&lt;/td&gt;
          &lt;/tr&gt;
          &lt;tr&gt;
            &lt;td style=""font-size: 2.5rem;""&gt;6243&lt;/td&gt;
            &lt;td style=""font-size: 2.5rem;""&gt;2322&lt;/td&gt;
            &lt;td style=""font-size: 2.5rem;""&gt;230&lt;/td&gt;
          &lt;/tr&gt;
        &lt;/table&gt;

        &lt;div class=""statistic-employment"" style=""background-color: rgb(228, 224, 224); height: 11rem;""&gt;
          &lt;h6&gt;Po statusu zaposlenosti&lt;/h6&gt;
          &lt;table class=""statistic-employment""&gt;
            &lt;tr&gt;
              &lt;td&gt;EMPLOYED&lt;/td&gt;
              &lt;td&gt;83&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;PENSIONER&lt;/td&gt;
              &lt;td&gt;10&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;UNEMPLOYED&lt;/td&gt;
              &lt;td&gt;25&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;UNEMPLOYED_COVID&lt;/td&gt;
              &lt;td&gt;19&lt;/td&gt;
            &lt;/tr&gt;
          &lt;/table&gt;
        &lt;/div&gt;
        &lt;div class=""statistic-requirement"" style=""background-color: rgb(238, 189, 223);""&gt;

          &lt;h6&gt;Broj upisanih po satu&lt;/h6&gt;

          &lt;table class=""statistic-requirement""&gt;
            &lt;tr&gt;
              &lt;td&gt;datum&lt;/td&gt;
              &lt;td&gt;sat&lt;/td&gt;
              &lt;td&gt;zahtjeva&lt;/td&gt;
            &lt;/tr&gt;

            &lt;tr&gt;
              &lt;td&gt;28.04.&lt;/td&gt;
              &lt;td&gt;00&lt;/td&gt;
              &lt;td&gt;1&lt;/td&gt;
            &lt;/tr&gt;

            &lt;tr&gt;
              &lt;td&gt;28.04.&lt;/td&gt;
              &lt;td&gt;05&lt;/td&gt;
              &lt;td&gt;2&lt;/td&gt;
            &lt;/tr&gt;

            &lt;tr&gt;
              &lt;td&gt;28.04.&lt;/td&gt;
              &lt;td&gt;06&lt;/td&gt;
              &lt;td&gt;1&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
              &lt;td&gt;28.04.&lt;/td&gt;
              &lt;td&gt;08&lt;/td&gt;
              &lt;td&gt;14&lt;/td&gt;
            &lt;/tr&gt;

          &lt;/table&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;!--Row and Main-container--&gt;
  &lt;/div&gt;
&lt;/div&gt;</code></pre>
</div>
</div>
</p>
"
61689774,"<p>I was trying to extract some info inside this url:'<a href=""http://www.saude.ba.gov.br/2020/05/06/bahia-registra-4-301-casos-confirmados-e-160-obitos/"" rel=""nofollow noreferrer"">http://www.saude.ba.gov.br/2020/05/06/bahia-registra-4-301-casos-confirmados-e-160-obitos/</a>' - as show in this piece of code below.</p>

<p>import requests
response = requests.get('<a href=""http://www.saude.ba.gov.br/2020/05/06/bahia-registra-4-301-casos-confirmados-e-160-obitos/"" rel=""nofollow noreferrer"">http://www.saude.ba.gov.br/2020/05/06/bahia-registra-4-301-casos-confirmados-e-160-obitos/</a>')
response.encoding = 'utf-8' # Optional: requests infers this internally
p=response.text</p>

<p>The code did work well. However, I discovered the info I wanted to extract was not updated daily in this url. Instead it was updated in another url address: '<a href=""http://www.saude.ba.gov.br/2020/05/08/bahia-registra-4-745-casos-confirmados-de-covid-19-e-170-obitos/"" rel=""nofollow noreferrer"">http://www.saude.ba.gov.br/2020/05/08/bahia-registra-4-745-casos-confirmados-de-covid-19-e-170-obitos/</a>' .</p>

<p>If you compare url A:<a href=""http://www.saude.ba.gov.br/2020/05/06/bahia-registra-4-301-casos-confirmados-e-160-obitos/"" rel=""nofollow noreferrer"">http://www.saude.ba.gov.br/2020/05/06/bahia-registra-4-301-casos-confirmados-e-160-obitos/</a></p>

<p>with url B:<a href=""http://www.saude.ba.gov.br/2020/05/08/bahia-registra-4-745-casos-confirmados-de-covid-19-e-170-obitos/"" rel=""nofollow noreferrer"">http://www.saude.ba.gov.br/2020/05/08/bahia-registra-4-745-casos-confirmados-de-covid-19-e-170-obitos/</a></p>

<p>you´ll notice that - ' <a href=""http://www.saude.ba.gov.br/"" rel=""nofollow noreferrer"">http://www.saude.ba.gov.br/</a><strong>year/month/day</strong>/bahia-registra-<strong>XYZKP</strong>-casos-confirmados-<strong>XXXXXXXXXXXXXXXXX</strong>/</p>

<p>Using datetime , I can obtain the date of access, but the rest of the url, as they vary, I wonder if there´s a way to requests locate an url address if I put an '*' at the end of this existing addres. </p>
"
61252210,"<p>When I select a concept like ""antibodies"" to build my corpus query within the navigator, is there a way I can see which specific search terms are included?</p>

<p>Is there a way to edit the specific terms associated with a given concept?</p>

<p>Concept search is great, but I need a way to validate the terms employed and possibly tailor them if necessary to find the right content.</p>
"
72166,"<p>I have been doing a COVID-19 related project. Here is the question:</p>

<ul>
<li>N = vector of daily new infected cases</li>
<li>D = vector of daily deaths</li>
<li>E[D] = estimation of daily deaths</li>
</ul>

<p>N is a n-dimensional vector, n is around 60. E[D] is another n-dimensional vector. Under certain assumptions, each entry of E[D] can be calculated as a linear combination of the entries of N.</p>

<p>We want to find the vector N such that the E[D] derived from N has least mean squared error when compared to actual D data. I think a gradient descent algorithm is needed here. However, I am not very familiar with gradient descent.</p>

<p>This seems to be a basic data science problem, but I am kind of lost right now. Does anyone has any idea about which algorithm should I dig into?</p>
"
60907542,"<p>I want to download the files from the URL below every day at 8pm to a certain folder on my desktop. I have zero coding experience, so I have no idea how to accomplish this task whatsoever so I would appreciate the help! </p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19</a></p>
"
61630290,"<p>I have a string and would like to count how often the word ""\par"" occurs. If I use 
<code>count($cleanText['\par')</code>
, I get the value 1, even though \par occurs 19 times in the text. </p>

<p>I also tried <code>translate($cleanText, '\par','')</code> 
and then subtract the characters and divide by 4, but translate cuts out too much. </p>

<p>How can I solve this using XSLT v1 or v2?</p>

<p>Thanks for your help. Enclosed is the text:</p>

<pre><code>{\*\generator Msftedit 5.41.21.2510;}\viewkind4\uc1\pard\f0\fs18 A 98-year-old RAF veteran who says he has been inspired by the fundraising efforts of Tom Moore will undertake a two-mile walk on VE Day in aid of a soldiers\rquote  club in Belgium threatened with financial ruin by the coronavirus.\par
\par
{}\par
\par
George Sutherland, who escaped to Britain when the Germans invaded his native Belgium in 1940, will walk from Lijssenthoek commonwealth war cemetery in Poperinge to Talbot House, a clubhouse for all the ranks founded in 1915 in the Flemish town of Poperinge, or \ldblquote Pops\rdblquote , as British soldiers once called it.\par
\par
{}\par
\par
Moore, who was promoted to colonel last week, raised more than \'a331 million for the NHS by walking a hundred lengths of his 25-metre garden before his 100th birthday.\par
\par
A Go Fund Me appeal to save Talbot House, for which Sutherland is walking, has so far secured \'8069,932 of its \'80100,000 target. The club is facing permanent closure after being forced by the pandemic to shut for the first time since the German occupation of 1940.\par
\par
\ldblquote I\rquote m still a fit man \endash  I used to be a footballer,\rdblquote  Sutherland told the Guardian. \ldblquote I will do it out of respect for all those young men who lost their lives\rdblquote .\par
\par
Simon Louagie, manager of Talbot House, said Sutherland, who lives on the outskirts of Poperinge, would be driven to the cemetery in a mini-van on Friday and then followed by a piper as makes his way to the club.\par
\par
\ldblquote His health is our number one priority \endash  but he insists he can do it,\rdblquote  Louagie said. \ldblquote The bagpiper will play for the last half a kilometre\rdblquote .\par
\par
Leading aircraftman Sutherland, whose father was Scottish and mother Belgian, attended boarding school in Glasgow for two years and worked on mosquito bombers as an air mechanic during the war. He said he would be proud to follow the lead of Moore in an attempt to help Talbot House, a sanctuary for soldiers over two world wars and founded by a chaplain, Philip \ldblquote Tubby\rdblquote  Clayton. \par
}```
</code></pre>
"
61067957,"<p>I've been keeping track and saving the covid19 data, and dashboarding visualizations. Recently I was approached by a web developer to embed my visualization, but I want to improve my dashboards. I came across Deloitte's dashboard and want to do something similar. 
<a href=""https://public.tableau.com/profile/deloitte.visual.analytics#!/vizhome/DeloitteCOVID-19EconomicRecoveryDashboard/DeloitteCOVID-19Analysis"" rel=""nofollow noreferrer"">https://public.tableau.com/profile/deloitte.visual.analytics#!/vizhome/DeloitteCOVID-19EconomicRecoveryDashboard/DeloitteCOVID-19Analysis</a>
This is their dashboard.
Anyone here can guide me through how to make the KPIs and also the status cells at the top I would greatly appreciate it.</p>
"
60702434,"<p>What I want to do is erase everything except <code>\d{4,7}</code> <em>only by replacing</em>.<br>
Any ideas to get this?  </p>

<p>ex)<br>
<code>G-A15239L → 15239</code><br>
(<strong>G-A</strong> and <strong>L</strong> should be selected and replaced by empty strings)<br>
<code>now200316stillcovid19asdf → 200316</code><br>
(<strong>now</strong> and <strong>stillcovid19asdf</strong> should be selected and replaced by empty strings)</p>

<p>Also, replacing text is not limited as empty string.<br>
substitutions such as $1 are possible too.</p>

<p>Using Regex in 'Kustom' apps. (including KLCK, KLWP, KWGT)<br>
I don't know which engine it's using because there are no information about it</p>
"
61094201,"<p>Okay. I am currently looking for ways to tackle a specific challenge. I start off with a PDF file and my goal is to turn this into a JSON object. I used a third party library to turn the PDF file into XML, and now I am trying to parse the XML into JSON. However, I could also just parse the PDF straight into a POJO or JSON without going through the XML step if that would be easier, but I believe that parsing from XML is easier. </p>

<p>I have a complex XML (or PDF) representing research papers, with multiple sections each identified by a title unknown beforehand. This title could be anything. I know what some of the titles are, such as ""Abstract"" and ""Introduction"". These would be easy for me to parse. as we have specific sections for these in our JSON schema. However, we also have a ""full_text"" section that contains the text from the rest of the document. Each paragraph in the ""full_text"" will also have a ""section"" identifier, which shows what section the paragraph belongs to (such as ""Conclusion"" or ""Results"" or ""Discussion""). The very specific need that I have is that each section in the PDF or the XML can have multiple nested subsections. But I do not care for these nested subsection titles -- I only care for the text inside them, as any paragraphs inside the subsections will belong to the top-most section containing them. </p>

<p>In summary, once I find a section, say, Results, I need to get all the text within it and within its subsections and then move on to the next section on the same level as Results. The name of the sections and subsections are unknown to me beforehand, but their names will go into a simple String field called ""section.""</p>

<p>Edit: Looking at the complexity of the xml files, I now believe parsing straight from PDF might even be better. </p>

<pre><code> &lt;abstract&gt;
                &lt;div
                    xmlns=""http://www.tei-c.org/ns/1.0""&gt;
                    &lt;p&gt;The new coronavirus COVID-19, also known as SARS-CoV-2, has infected more than 300,000 patients and become a global health emergency due to the very high risk of spread and impact of COVID-19. There are no specific drugs or vaccines against COVID-19, thus effective antiviral agents are still urgently needed to combat this virus. Herein, the FEP (free energy perturbation)-based screening strategy is newly derived as a rapid protocol to accurately reposition potential agents against COVID-19 by targeting viral proteinase Mpro. Restrain energy distribution (RED) function was derived to optimize the alchemical pathway of FEP, which greatly accelerated the calculations and first made FEP possible in the virtual screening of the FDA-approved drugs database. As a result, fifteen out of twenty-five drugs validated in vitro exhibited considerable inhibitory potencies towards Mpro. Among them, the most potent Mpro inhibitor dipyridamole potentially inhibited NF-B signaling pathway and inflammatory responses, and has just finished the first round clinical trials. Our result demonstrated that the FEP-based screening showed remarkable advantages in prompting drug repositioning against COVID-19.&lt;/p&gt;
                &lt;/div&gt;
            &lt;/abstract&gt;
        &lt;/profileDesc&gt;
    &lt;/teiHeader&gt;
    &lt;text xml:lang=""en""&gt;
        &lt;body&gt;
            &lt;div
                xmlns=""http://www.tei-c.org/ns/1.0""&gt;
                &lt;head n=""1.""&gt;Introduction&lt;/head&gt;
                &lt;p&gt;The novel coronavirus 2019-nCoV (also known as HCoV-19 or SARS-CoV-2) outbreak had emerged from Wuhan, Hubei Province, China in December 2019 
                    &lt;ref type=""bibr"" target=""#b0""&gt;1,&lt;/ref&gt;
                    &lt;ref type=""bibr""&gt;2&lt;/ref&gt; . On March 22, there were 813,00 confirmed COVID-19 cases including 3,253 deaths in China. This virus has also infected more than 220,000 patients in all of the continents and over 180 other countries, such as Italy, Spain, U.S.A, Germany, France, and Iran gradually became a global pandemic due to the very high risk of spread and impact of COVID-19. To date, there is no specific treatment or vaccine against COVID-19, thus it is urgently need to repositioning potential agents against COVID-19. 
                    &lt;ref type=""bibr"" target=""#b2""&gt;3&lt;/ref&gt; The COVID-19's replicase gene encodes two over-lapping translation products, polyproteins 1a and 1ab (pp1a and pp1ab), which mediate all of the functions required for viral replication. Mpro, as the key enzyme in proteolytic processing of viral replication, is initially released by the auto-cleavage of pp1a and pp1ab. Then Mpro in turn cleaves pp1a and pp1ab to release functional proteins necessary for viral replication. 
                    &lt;ref type=""bibr"" target=""#b3""&gt;4&lt;/ref&gt; In the view of essential functions of Mpro in viral life cycle and its high conservatism, it is an attractive target for the discovery of anti-COVID-19 agents.
                &lt;/p&gt;
                &lt;p&gt;Great efforts from various research groups have been done to discover new agents from several databases by targeting the target Mpro via several virtual screening strategy, 
                    &lt;ref type=""bibr"" target=""#b4""&gt;5,&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b5""&gt;6&lt;/ref&gt; which consists of pharmacophore, molecule docking, and molecular simulations approaches. As a result, six drugs inhibited Mpro with IC50 values ranging from 0.67 to 21.4 μM. 
                    &lt;ref type=""bibr"" target=""#b4""&gt;5&lt;/ref&gt; These drug design methods contributed considerably to the lead discovery, but the computational accuracy and efficiency need to be improved especially when dealing with emergency situations such as the COVID-19 outbreak. Free energy perturbation (FEP) method is a promising method with satisfactory accuracy 
                    &lt;ref type=""bibr"" target=""#b6""&gt;[7]&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b7""&gt;[8]&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b8""&gt;[9]&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b9""&gt;[10]&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b10""&gt;[11]&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b11""&gt;[12]&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b12""&gt;[13]&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b13""&gt;[14]&lt;/ref&gt; , but their actual applications to drug design are still limited to simulate minor structural changes of the ligands, thus predicting the relative binding free energy (RBFE). 
                    &lt;ref type=""bibr"" target=""#b6""&gt;7,&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b13""&gt;14&lt;/ref&gt; In order to perform virtual screening of a large molecule database, the absolute binding free energy (ABFE) calculation must be performed for each ligand without using of a reference ligand structure. The FEP approach has an advantage in predicting the affinities more precisely between drugs and their targets than conventional methods, such as pharmacophore, molecule docking, and molecular simulations. However, the FEP-ABFE approaches are extremely expensive/time-consumpting and therefore not used for virtual screening purpose. 
                    &lt;ref type=""bibr"" target=""#b14""&gt;15,&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b15""&gt;16&lt;/ref&gt; To accelerate the discovery of Mpro inhibitors from the small molecule database to combat COVID- 
                    &lt;ref type=""bibr"" target=""#b18""&gt;19&lt;/ref&gt;, we represent a newly derived FEP-ABFE-accelerated screening strategy together with bioassay validation to rapidly reposition potential agents against COVID-19 by targeting viral proteinase Mpro.
                &lt;/p&gt;
                &lt;p&gt;As a result, fifteen of twenty-five drugs were validated in vitro to exhibit considerable inhibitory potencies towards Mpro. Among them, the most potent and representative Mpro inhibitor dipyridamole just finished its first-round clinical trials, and showed significant clinical outcomes. 
                    &lt;ref type=""bibr"" target=""#b16""&gt;17&lt;/ref&gt; In short, this is the first report to screen the FDA-approved database by using the FEP-ABFE approach, and this FEP-based method showed significant advantages by means of improving the hit rates and repositioning more potent leads.
                &lt;/p&gt;
            &lt;/div&gt;
            &lt;div
                xmlns=""http://www.tei-c.org/ns/1.0""&gt;
                &lt;head n=""2.""&gt;Methods&lt;/head&gt;
            &lt;/div&gt;
            &lt;div
                xmlns=""http://www.tei-c.org/ns/1.0""&gt;
                &lt;head n=""2.1""&gt;Molecular docking&lt;/head&gt;
                &lt;p&gt;The crystal structure of viral proteinase Mpro (PDB ID: 6LU7) 
                    &lt;ref type=""bibr"" target=""#b17""&gt;18&lt;/ref&gt; for COVID-19 was used for the molecule docking purpose. Based on the crystal structure, more than 2500 small molecules in the FDAapproved drug database were first screened by using molecular docking program Glide 
                    &lt;ref type=""bibr"" target=""#b18""&gt;19&lt;/ref&gt; . Considering
                &lt;/p&gt;
                &lt;p&gt;Mpro being a protease, Cys145-His41/Ser144-His163 can act as the nucleophilic agent and acid that assist the hydrolysis reaction of the substrate proteins, and Gly143 and Gln166 can form hydrogen bonds with the ""CO-NH-Cα-CO-NH-Cα"" structure of the backbone of the substrate protein. Thus, these 6 residues were considered as the key residues of Mpro in the screening. After docking, the binding modes of all the ligands were carefully checked, and 100 molecules with specific interaction with the key residues and relatively high docking scores were selected for further FEP studies to evaluate their ABFE.&lt;/p&gt;
            &lt;/div&gt;
            &lt;div
                xmlns=""http://www.tei-c.org/ns/1.0""&gt;
                &lt;head n=""2.2""&gt;Free energy perturbation (FEP)&lt;/head&gt;
            &lt;/div&gt;
            &lt;div
                xmlns=""http://www.tei-c.org/ns/1.0""&gt;
                &lt;head n=""2.2.1""&gt;Preliminary MD simulations.&lt;/head&gt;
                &lt;p&gt;All the 100 ligands selected by molecular docking were further evaluated by FEP calculations carried out in Gromacs-2019 
                    &lt;ref type=""bibr"" target=""#b19""&gt;20,&lt;/ref&gt;
                    &lt;ref type=""bibr"" target=""#b20""&gt;21&lt;/ref&gt; . Before FEP calculations, 4 ns preliminary MD simulations were performed for each receptor-ligand complex to improve the fit of the ligand into the binding pocket. All the ligands are parameterized by the general AMBER force field (GAFF) 
                    &lt;ref type=""bibr"" target=""#b21""&gt;22&lt;/ref&gt; . Restrained electrostatic potential (RESP) charges calculation of relative ligand was performed with Gaussian 03 program 
                    &lt;ref type=""bibr"" target=""#b22""&gt;23&lt;/ref&gt; at the HF/6-31G* level. The parameters of protein were described by the AMBER FF14SB force field 24 . The TIP3P model 
                    &lt;ref type=""bibr"" target=""#b24""&gt;25&lt;/ref&gt; was used for water molecules.
                &lt;/p&gt;
                &lt;p&gt;The systems were neutralized by adding counter ions (either Na + or Cl ions). The systems were first minimized by using steepest descent method for 5000 cycles and then heated from 0 to 298 K in an NVT ensemble within 100 ps. The systems were then equilibrated in an NPT ensemble with weak restraints of 1000 kJ/mol/nm 2 for 500 ps followed by a 4 ns unconstrained production simulation. The last snapshot of the MD simulations was used for the following FEP calculations, and the trajectory of the last 2 ns was analyzed to get the parameters for adding restraints between receptors and ligands.&lt;/p&gt;
            &lt;/div&gt;
            &lt;div
                xmlns=""http://www.tei-c.org/ns/1.0""&gt;
                &lt;head n=""2.2.3""&gt;Protocol for automatically adding restraints.&lt;/head&gt;
                &lt;p&gt;Based on the preliminary MD simulations results, the FEP-ABFE calculations were carried based on the thermodynamic cycle given in 
                    &lt;ref type=""figure""&gt;Figure 1&lt;/ref&gt;. As shown in the thermodynamic cycle, a restraint should be added to the receptor and ligand for each FEP calculation. The strategy of adding restraints first reported by Boresch et al. 
                    &lt;ref type=""bibr"" target=""#b25""&gt;26&lt;/ref&gt; was used in this study, which consists of one distance, two angles, and three dihedrals harmonic potentials with a force constant of 10 kcal/mol/Å 2 [rad 
                    &lt;ref type=""bibr""&gt;2&lt;/ref&gt; ]. The contribution of the restraints to the Lig (∆ ) system was calculated analytically, and the contribution of the restraint to the Rec-Lig system (∆ ) was calculated by FEP. According to the strategy, three atoms of the ligand and three atoms of the receptor will be selected to add the restraint. In order to add the restraints at the equilibrium position, a program was designed to automatically detect the required parameters and select the three ligand atoms and the three receptors atoms. For ligand, the heavy atom which is closest to the geometry center was selected as the first atom; the heavy atom which is most distant from the first atom was selected as the second atom; the heavy atom forms an angle that is larger than 90 degrees with the first two atoms and most distant from the first atom is selected as the third atom. For the receptor, based on the last 2 ns trajectory of the 4 ns preliminary MD simulations, the distances, angles, dihedrals between the three ligand atoms and Cα, Cc (carbon of the carboxyl group) and N (N atom of the amino group) atoms of all the residues within 5 Å of the ligand were calculated along the MD trajectory. Cα, Cc and N atoms from the same residue with the most stable (lowest standard deviation) distances, angles, and dihedrals values were selected as the three receptor atoms. The determined mean values of distance, angles, and dihedrals were used for adding the restraints between the three ligand atoms and the three receptor atoms.
                &lt;/p&gt;
            &lt;/div&gt;
</code></pre>
"
60700877,"<p>I was wondering how to get the table from the following <a href=""https://www.gob.cl/coronavirus/casosconfirmados/?fbclid=IwAR16iax-OFCsokwTjvZa8DS8QD5B6qZRVqBRDLlqH5Wqj7AGfY_Yj6p_8UY"" rel=""nofollow noreferrer"">webpage</a>. I imagine that is possible using <code>importHTML</code> function, but it was not possible to identify the path. I think that is masked or is not accessible.</p>

<p>Does someone know how to get the correct path or how to import this table?
Thank you</p>
"
61298156,"<p>the following is my activity_scrolling.xml</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;androidx.coordinatorlayout.widget.CoordinatorLayout 
xmlns:android=""http://schemas.android.com/apk/res/android""
xmlns:app=""http://schemas.android.com/apk/res-auto""
xmlns:tools=""http://schemas.android.com/tools""
android:layout_width=""match_parent""
android:layout_height=""match_parent""
android:fitsSystemWindows=""true""
tools:context="".ScrollingActivity""&gt;

&lt;com.google.android.material.appbar.AppBarLayout
    android:id=""@+id/app_bar""
    android:layout_width=""match_parent""
    android:layout_height=""@dimen/app_bar_height""
    android:fitsSystemWindows=""true""
    android:theme=""@style/AppTheme.AppBarOverlay""&gt;

    &lt;com.google.android.material.appbar.CollapsingToolbarLayout
        android:id=""@+id/toolbar_layout""
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:fitsSystemWindows=""true""
        app:contentScrim=""?attr/colorPrimary""
        app:layout_scrollFlags=""scroll|exitUntilCollapsed""
        app:toolbarId=""@+id/toolbar""&gt;

        &lt;androidx.appcompat.widget.Toolbar
            android:id=""@+id/toolbar""
            android:layout_width=""match_parent""
            android:layout_height=""?attr/actionBarSize""
            app:layout_collapseMode=""pin""
            app:popupTheme=""@style/AppTheme.PopupOverlay"" /&gt;

    &lt;/com.google.android.material.appbar.CollapsingToolbarLayout&gt;
&lt;/com.google.android.material.appbar.AppBarLayout&gt;
&lt;fragment
    android:id=""@+id/map""
    android:name=""com.google.android.gms.maps.SupportMapFragment""
    android:layout_width=""match_parent""
    android:layout_height=""300dp""
    android:fitsSystemWindows=""true""
    tools:context=""com.example.visualcovid_19.ScrollingActivity""
    app:layout_behavior=""@string/appbar_scrolling_view_behavior""/&gt;

&lt;include layout=""@layout/content_scrolling"" /&gt;

&lt;/androidx.coordinatorlayout.widget.CoordinatorLayout&gt;
</code></pre>

<p>The following is my content_scrolling.xml</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""utf-8""?&gt;
&lt;ScrollView xmlns:android=""http://schemas.android.com/apk/res/android""
xmlns:app=""http://schemas.android.com/apk/res-auto""
xmlns:tools=""http://schemas.android.com/tools""
android:layout_width=""match_parent""
android:layout_height=""match_parent""
android:orientation=""vertical""
app:layout_behavior=""@string/appbar_scrolling_view_behavior""
tools:context="".ScrollingActivity""
tools:showIn=""@layout/activity_scrolling""&gt;

&lt;LinearLayout
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""
    android:orientation=""vertical""&gt;

    &lt;include
        layout=""@layout/country_card_fragment""
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content"" /&gt;

    &lt;include
        layout=""@layout/country_card_fragment""
        android:layout_width=""match_parent""
        android:layout_height=""wrap_content"" /&gt;
&lt;/LinearLayout&gt;
&lt;/ScrollView&gt;
</code></pre>

<p>But, I end up getting the scroll view overlapped on map fragment and right below <code>AppBarLayout</code>
a screenshot is attached below.</p>

<p><a href=""https://i.stack.imgur.com/X6kkH.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/X6kkH.png"" alt=""enter image description here""></a></p>

<p>I want the scroll view to start at the end of the map fragment and the initial scroll should take the <code>AppBarLayout</code> and the fragment below it to the top as usual and the rest scroll view should be able to scroll. 
I am really stuck here. can anyone help, please? </p>
"
61285766,"<p>I built a small application that gives real time update on coronavirus cases in my country.</p>

<p>Just recently, the API which I used to get the number of cases, deaths etc changed their endpoints
e.g from</p>

<pre><code>https://covid19.com/corona/country
</code></pre>

<p>to</p>

<pre><code>https://covid19.com/v2/corona/country
</code></pre>

<p>Due to strict restictions by Google on apps relating to covid19,  I couldnt upload to playstore but I built an APK and shared the link to many people to download.</p>

<p>Now, they cant access the number of cases in the app due to a change in the API endpoints.</p>

<p>Please, how do I change just that string URL from my end to have effect on everyone who has the app already without needing to build another apk and making people to download the app again.</p>

<p>I discovered <strong>Firebase Remote Config</strong>, I tried it on my android studio, run the app on my phone, and yes it was working on my device, but How do I get it to work on other people devices with the app already installed.??</p>
"
73347,"<p>I Want to know how can I identify that is the customer is in financial distress due to the COVID situation using its credit card transactions.</p>

<p>I have a daily transaction of customers till current date,
Any thoughts or ideas would be really helpful.</p>

<p>For example, my thoughts that if sudden increment in credit card utilization then it can be an indicator that person in financial distress as could be a flag to potential lenders or creditors that  having trouble managing your finances.</p>
"
61144472,"<p>Google Classroom API lists several code examples for adding a teacher to courses based on courseId and teacher email. But none of the <a href=""https://developers.google.com/classroom/guides/manage-users"" rel=""nofollow noreferrer"">examples</a> are in Google Apps Script.</p>

<p>Our school admin does not code, so I'd like to provide him a turn-key solution in GAS (that I understand) but can't test because I'm not admin.</p>

<p>The end goal is to add the same teacher account to all classrooms so we can use that to pull assignment data and support students by helping them stay organized, especially now that we're all online due to Covid19.</p>

<p>If I loop over this and provide an error catch, will <a href=""https://stackoverflow.com/questions/41338949/google-classroom-add-students-using-apps-script"">this</a> work, if run from an admin account?</p>

<pre><code>function addTeachers() {
  Classroom.Courses.Teachers.create({
    userId: ""teacher@ourdomain.org"",
  }, ""123456789"");
}
</code></pre>
"
61445218,"<p>I'm working with a Covid-19 dataset (<a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">this one</a>) but it seems harder work because the daily totals are cumulative totals rather than 'new cases' each day. </p>

<p>I've been trying to get an accurate figure for daily new cases based on the running total for each country but I can't get it right - is anyone able to offer any advice on how best to do this please? </p>
"
60749447,"<p>We have a Slack workspace within a small (~400) scientific community who are discussing multiple ideas (to help solve the current COVID-19 crisis, so lots of conversations and topics. :-)  Currently using one channel and wouldn't want to create 50.</p>

<p>What's the best way to spin off discussions into sub-topics.  Slack doesn't support sub-channels (yet) does it?
Would a task management plug-in to Slack help here? Want to separate and localize topics and discussions, not track individual responsibility, so ""task management"" might not be the right paradigm.
Other suggestions?</p>
"
61155544,"<p>Plotting some covid19 data with gnuplot, I am trying to find a way to pick a raw in my dataset to use it as a starting point.</p>

<p>E. g. I have something like:</p>

<pre><code>#date       #cases
2010-03-01  11
2010-03-02  13
2020-03-03  17
2020-03-04  20
2020-03-05  29
2020-03-06  38
2020-03-07  50
2020-03-08  63
2020-03-09  82
2020-03-10  105
2020-03-11  140
2020-03-12  180
2020-03-13  240
...
</code></pre>

<p>Now I want to find the date when the number of cases became greater than 100 and use this date to adjust/normalise/whatever all my plots.</p>

<p>So I what to somehow find the ""2020-03-10  105"" row and set two variables </p>

<pre><code>start_date = '2020-03-10'
start_index = 11
</code></pre>

<p>to be able to do things like </p>

<pre><code>stats &lt;datafile&gt; every ::start_index
set xrange [start_date:]
...
</code></pre>

<p>etc etc to basically ignore everything before the date of >100 cases.</p>

<p>I suppose, it can be possible using some basic for+if loop over the raws of my datafile but I am a bit stuck with his as I can't find a good example/explanation of how to iterate through datafile raws.</p>

<p>P. S. Of course, I could do this with external tools but I'd prefer to not as I'm doing some batch plotting with quite some scripting around to gather the data, and would like to keep all the plotting logic inside my gnuplot jinja2 template to not over-complicate the whole stuff.</p>
"
61064663,"<p>I am looking for a rest way to get more information out of a COVID19 map.</p>

<p>I noticed that arcgis provides plenty of topics and tutorials for developers.</p>

<p>I just don't know which tutorials are helping me to understand the FeatureServer.</p>

<p>I had two questions, can I query the below table with the rest api?</p>

<p>Like finding out what fields are in it, and what data.</p>

<p>If I have access to a serviceItemId - can I do anything useful with it?</p>

<pre><code> ""tables"" : [
    {
      ""id"" : 0,
      ""name"" : ""RKI_COVID19"",
      ""parentLayerId"" : -1,
      ""defaultVisibility"" : true,
      ""subLayerIds"" : null,
      ""minScale"" : 0,
      ""maxScale"" : 0
    }
  ]
</code></pre>
"
61411223,"<p>There is a CSV data source online that publishes the latest data on COVID-19 cases in Austria.</p>

<p><a href=""https://www.data.gv.at/katalog/dataset/2809273e-d0bc-4eb3-a7d3-d01ef2168809"" rel=""nofollow noreferrer"">https://www.data.gv.at/katalog/dataset/2809273e-d0bc-4eb3-a7d3-d01ef2168809</a></p>

<p>The CSV file consists of one row with the latest number (cases, recovered, hospitalized, deaths, etc). I would like to take the data each time that the CSV file is updated, and add the new data to a new row in a table so that I have a complete set of data. Alternatively, is there a way for me to grab all the data from the source (not just a one row latest update)? From the website, it appears they only make the latest row available. The data is updated approximately 2-3 times a day.</p>

<p>I have searched extensively online and cannot seem to find an answer. I have set up the CSV file as a data source. I also copied and pasted the data into a new query, which can serve as my complete data source. So I have two tables (AllgemeinDaten and Old Data). </p>

<p>I create a new query appending the source (AllgemeinDaten) with Old Data, but it doesn't create a new row keeping the old data from AllgemeinDaten and the new changed data from AllgemeinDaten. </p>
"
60765877,"<p>I have a Linked-List of <code>LogEntries</code>. Each entry has a date. Every user has exactly 1 Log.</p>

<p>What's the best way to splice in a new log entry if I receive a date in the past?</p>

<pre><code>(log:Log)
(e1:LogEntry {date: Date('2020-03-19')})
(e2:LogEntry {date: Date('2020-03-17')})
…

CREATE (log)-[:PREV_ENTRY]-&gt;(e1)
CREATE (e1)-[:PREV_ENTRY]-&gt;(e2)
CREATE (e2)-[:PREV_ENTRY]-&gt;(e3)
CREATE (e3)-[:PREV_ENTRY]-&gt;(e4)
</code></pre>

<p>I'm building a public graphql API to trace contact of COVID-19 case:
<a href=""https://github.com/mmmoli/contacttracing.app-graphql-api/blob/master/src/appConfigs/schema.ts#L55"" rel=""nofollow noreferrer"">https://github.com/mmmoli/contacttracing.app-graphql-api/blob/master/src/appConfigs/schema.ts#L55</a></p>

<p>Any help would be awesome!</p>

<p>Inspiration from Max's Fraud post:
<a href=""https://maxdemarzi.com/2019/08/19/finding-fraud/"" rel=""nofollow noreferrer"">https://maxdemarzi.com/2019/08/19/finding-fraud/</a></p>

<p>🙏🏻</p>
"
60860443,"<p>What I want to achieve is, to find all associated, similar, synonym, related words to given word.
For example, if I give word: </p>

<p><code>virus</code> expected result might be <code>bacteria, medicine, illnes, coronavirus</code> etc..</p>

<p>Basically everything that comes to mind when you think about that word. </p>

<p>Is there any AI based API, maybe AWS or Google Cloud engine service that I can achieve this result with? or an open source database and or tool?</p>
"
61228499,"<p>Recently our app has been suspended by the play store because it contained the ""coronavirus"" keyword in the store listing, no mentions of the virus in the app, just the store listing.</p>

<p>We offer a service to avoid queues outside places by obtaining a virtual ticket so the user can go to the place when her turn comes, our government endorsed us because we avoid gatherings, we're offering the service for free for the time being to help population.</p>

<p>The suspension was a misunderstanding and we've been brought back online on the play store in 
matter of hours, after deleting the ""coronavirus"" word from the store listing, however, we've rolled an update and, although the google play console communicates a 100% rollout (it was a staged rollout from 20% to 40% and then to 100%), the users aren't able to download the latest version, but just the one before the app suspension.</p>

<p>There's a big popup saying to expect 7 days or more of review time due to the coronavirus outbreak, so I'm starting to think that even if the google play console says so, we've not actually rolled out our update, but are instead in a queue, waiting for manual review and approval, because we might have been somehow ""blacklisted"" for the previous (erroneous) suspension.</p>

<p>All the other apps we own get released right away, it's just the suspended one that doesn't go live (despite what the google play console says). We've already contacted support to know what's going on, and I'll update with an answer as soon as we receive one, but in the meantime I'd like to know if there is a way to tell if our app, which previously didn't require manual review, is in some sort of manual review list.</p>
"
61294586,"<p>I'm talking about this sort of pop-up, which appears when you click on a store (etc.) in Google Maps:</p>

<p><a href=""https://i.stack.imgur.com/j9NNF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/j9NNF.png"" alt=""Google Maps popup""></a></p>

<p>In my case (a covid-related volunteer project) we want replace the View on Google Maps CTA with a link to a page in our web app, with the store information pre-filled. That may be impossible (pointers welcome if not), but knowing how/whether you can customize the popup at all is the first thing.</p>
"
61075386,"<p>I have created <a href=""https://cutting.scot/covid-19"" rel=""nofollow noreferrer"">this chart</a> but I'm not sure what value I should use for the <code>y</code> axis.</p>

<p>At the moment I am using the delta from the day before that I plot in <a href=""https://cutting.scot/covid-19/increase-in-deaths"" rel=""nofollow noreferrer"">this graph</a> and then using <a href=""https://github.com/Tom-Alexander/regression-js"" rel=""nofollow noreferrer"">this package</a> to get a best fit.</p>

<p>But I'm not sure what the <code>y</code> value should be to give a feel if things are improving.</p>
"
61129527,"<p>I am using PHP to read an <em>ini</em> file using <em>parse_ini_file</em>, which I store as <code>$iniData</code>. I read keys using a function that returns the result of <code>$iniData[$section][$key]</code></p>

<p>My problem is when I try to remove a section - <code>uset($iniData,$section)</code> appears to remove the offending section, but when I re-read the file the 'deleted' section is still there. </p>

<p>I guess that my problem is that I am not saving the file correctly. How should I save <code>$iniData</code> back to my file so that I can still maintain my [section] key format?</p>

<p><em>ini</em> file looks like example below - I want to remove the section called [covid19]:</p>

<pre><code>[global]
phone=123456
email=stack@overflow.com
[covid19]
days-at-home=31
</code></pre>

<p>How should I be saving <code>$iniData</code>?</p>
"
60845551,"<p>how to echo them one by one</p>

<pre><code>Array
(
    [Afghanistan] =&gt; Array
        (
            [53] =&gt; Array
                (
                    [date] =&gt; 2020-3-15
                    [confirmed] =&gt; 16
                    [deaths] =&gt; 0
                    [recovered] =&gt; 0
                )

        )

    [Albania] =&gt; Array
        (
            [53] =&gt; Array
                (
                    [date] =&gt; 2020-3-15
                    [confirmed] =&gt; 42
                    [deaths] =&gt; 1
                    [recovered] =&gt; 0
                )

        ) 
)
</code></pre>

<p>how to echo country name and its confirmed, deaths , recovered using a loop</p>

<p>like afganistan , confirmed , deaths , recovered.</p>

<p>My code:</p>

<pre><code>&lt;?php
    $date = date('Y-n-d', strtotime(""-10 days""));
    $json = file_get_contents('pomber.github.io/covid19/timeseries.json', false);
    $arr = json_decode($json, true); // array to store all items with date specified
    $collection = [];
    foreach ($arr as $country =&gt; $dates) {
        $filtered = array_filter($dates, fn($obj) =&gt; $obj['date'] === $date);
        $collection = array_merge($collection, [$country =&gt; $filtered]);
    }
    echo ""&lt;pre&gt;"";
    print_r($collection);
?&gt;
</code></pre>
"
61486633,"<p>I'm trying to use a finhub.io api to retrieve news and format it on my page. The documentation page offers a CURL address with an example of the return feed:</p>

<p><a href=""https://finnhub.io/docs/api#general-news"" rel=""nofollow noreferrer"">Finhub documentation page</a></p>

<p>The sample of the response to expect is:</p>

<pre><code>[
{
""category"": ""technology"",
""datetime"": 1567054115,
""headline"": ""Facebook acknowledges flaw in Messenger Kids app"",
""id"": 25040,
""image"": ""https://s3.reutersmedia.net/resources/r/?m=02\u0026d=20190829\u0026t=2\u0026i=1423882334\u0026w=1200\u0026r=LYNXNPEF7S07O"",
""related"": """",
""source"": ""Reuters"",
""summary"": ""Facebook Inc  acknowledged a flaw in its Messenger Kids app, weeks after two U.S. senators raised privacy concerns about the application, and said that it spoke to the U.S. Federal Trade Commission about the matter."",
""url"": ""https://www.reuters.com/article/us-facebook-privacy/facebook-acknowledges-flaw-in-messenger-kids-app-idUSKCN1VJ08X""
},{
""category"": ""top news"",
""datetime"": 1567053948,
""headline"": ""Swedish teen climate activist arrives in New York by boat for U.N. summit"",
""id"": 25060,
""image"": ""https://s3.reutersmedia.net/resources/r/?m=02\u0026d=20190828\u0026t=2\u0026i=1423796908\u0026w=1200\u0026r=LYNXNPEF7R24P"",
""related"": """",
""source"": ""Reuters"",
""summary"": ""Teenage climate activist Greta Thunberg sailed into New York Harbor on Wednesday in a zero-carbon emissions vessel, completing her nearly 14-day journey from England to take part in a United Nations climate summit."",
""url"": ""https://www.reuters.com/article/us-global-climate-thunberg/swedish-teen-climate-activist-arrives-in-new-york-by-boat-for-u-n-summit-idUSKCN1VI1F1""
}]
</code></pre>

<p>I have managed to put together the code to process it which looks like this:</p>

<pre><code>function news(){
$response = get_web_page(""https://finnhub.io/api/v1/news?category=general&amp;token=bqiarn7rh5rcatj3vgi0"");
$resArr = array();
$resArr = json_decode($response);
//print_r($resArr);

echo ""&lt;pre&gt;""; print_r($resArr); echo ""&lt;/pre&gt;"";
}
function get_web_page($url) {
$options = array(
    CURLOPT_RETURNTRANSFER =&gt; true,   // return web page
    CURLOPT_HEADER         =&gt; false,  // don't return headers
    CURLOPT_FOLLOWLOCATION =&gt; true,   // follow redirects
    CURLOPT_MAXREDIRS      =&gt; 10,     // stop after 10 redirects
    CURLOPT_ENCODING       =&gt; """",     // handle compressed
    CURLOPT_USERAGENT      =&gt; ""test"", // name of client
    CURLOPT_AUTOREFERER    =&gt; true,   // set referrer on redirect
    CURLOPT_CONNECTTIMEOUT =&gt; 120,    // time-out on connect
    CURLOPT_TIMEOUT        =&gt; 120,    // time-out on response
); 

$ch = curl_init($url);
curl_setopt_array($ch, $options);

$content  = curl_exec($ch);

curl_close($ch);

return $content;
}
</code></pre>

<p>The output looks like this when I call the function news()</p>

<pre><code>Array(
[0] =&gt; stdClass Object
    (
        [category] =&gt; company news
        [datetime] =&gt; 1588093445
        [headline] =&gt; UPDATE 3-Pfizer plans expanded coronavirus vaccine trials, sees 'negligible' hit from outbreak
        [id] =&gt; 3596983
        [image] =&gt; https://s4.reutersmedia.net/resources/r/?m=02&amp;d=20200428&amp;t=2&amp;i=1516759737&amp;w=1200&amp;r=LYNXNPEG3R1VZ
        [related] =&gt; 
        [source] =&gt; Reuters
        [summary] =&gt; Pfizer Inc on Tuesday said it expects its experimental coronavirus vaccine to move into expanded clinical trials by October that could allow for emergency use or accelerated approval, as it ramps up efforts to combat the pandemic.
        [url] =&gt; https://www.reuters.com/article/us-pfizer-results/pfizer-plans-expanded-coronavirus-vaccine-trials-sees-negligible-hit-from-outbreak-idUSKCN22A1M0
    )
[1] =&gt; stdClass Object
    (
        [category] =&gt; top news
        [datetime] =&gt; 1588093312
        [headline] =&gt; Trump says will sign order on virus-related liability problems
        [id] =&gt; 3596993
        [image] =&gt; https://image.cnbcfm.com/api/v1/image/106509962-15880889172020-04-28t154424z_1743814945_rc2rdg9nmwqx_rtrmadp_0_health-coronavirus-usa.jpeg?v=1588089010
        [related] =&gt; 
        [source] =&gt; CNBC
        [summary] =&gt; U.S. President Donald Trump said on Tuesday he will sign an executive order later in the day that addresses employer liability issues that have arisen from the coronavirus outbreak.
        [url] =&gt; https://www.cnbc.com/2020/04/28/trump-says-will-sign-order-on-virus-related-liability-problems.html
    )
)
</code></pre>

<p>I'm now stuck on how to access each sub-associative array to format and use within a loop of the outer main array.</p>

<p>Can someone assist?</p>
"
59914996,"<p>I'm trying to create a basic concordance script that will print the ten words before and after the value found inside an array. I did this by splitting the text into an array, identifying the position of the value, and then printing -10 and +10 with the searched value in the middle. However, this only presents the first such occurrence. I know I can find the others by using <em>array_keys</em> (found in positions 52, 78, 80), but I'm not quite sure how to cycle through the matches, since <em>array_keys</em> also results in an array. Thus, using $matches (with <em>array_keys</em>) in place of $location below doesn't work, since you cannot use the same operands on an array as an integer. Any suggestions? Thank you!!</p>

<pre><code>&lt;?php

$text = &lt;&lt;&lt;EOD
The spread of a deadly new virus is accelerating, Chinese President Xi Jinping warned, after holding a special government meeting on the Lunar New Year public holiday.
The country is facing a ""grave situation"" Mr Xi told senior officials.
The coronavirus has killed at least 42 people and infected some 1,400 since its discovery in the city of Wuhan.
Meanwhile, UK-based researchers have warned of a real possibility that China will not be able to contain the virus.
Travel restrictions have come in place in several affected cities. From Sunday, private vehicles will be banned from central districts of Wuhan, the source of the outbreak.
EOD;

$new = explode("" "", $text);
$location = array_search(""in"", $new, FALSE);
$concordance = 10;

$top_range = $location + $concordance;
$bottom_range = $location - $concordance;

while($bottom_range &lt;= $top_range) {
    echo $new[$bottom_range] . "" "";
    $bottom_range++;
}

?&gt;
</code></pre>
"
61142369,"<p>I'm working on AWS Elastic Search. I've come across one situation in my project where in my reports i have to search keywords like ""corona virus"".</p>

<p>But result should come with containing keywords like ""Corona virus"" and ""corona"" and ""virus"" and ""coronavirus"".</p>

<p>Please guide me how i should build my query DSL.</p>

<p>Note: Working on PHP language. </p>

<p>Appreciate your help.</p>

<p>//Amit</p>
"
60776830,"<p>I'm trying to count integer value from JSON: <a href=""https://pomber.github.io/covid19/timeseries.json"" rel=""nofollow noreferrer"">https://pomber.github.io/covid19/timeseries.json</a> but I got 1 for each key. What I expect is to count the total 'confirmed' from all countries by date as a key.</p>

<p>Here's my controller:</p>

<pre><code>$client = new Client();$request = $client-&gt;get('https://pomber.github.io/covid19/timeseries.json');
$response = $request-&gt;getBody()-&gt;getContents();
$posts_dates = json_decode($response, true);

$confirmed_array = array();

if ( ! empty( $posts_dates ) ) {
    foreach ( $posts_dates as $key =&gt; $val ) { 
        foreach ( ((array)$posts_dates)[$key] as $data ) {
            $date_confirmed = new \DateTime( $data['date'] );
            $day = $date_confirmed-&gt;format( 'd M y' );
            $confirmed = count((array)$data['confirmed']);
            $confirmed_array [ $day ] = $confirmed;
        }

    } 
}
return $confirmed_array;
</code></pre>

<p>Here's the result:</p>

<pre><code>{
""22 Jan 20"": 1,
""23 Jan 20"": 1,
""24 Jan 20"": 1,
""25 Jan 20"": 1,
""26 Jan 20"": 1,
""27 Jan 20"": 1,
""28 Jan 20"": 1,
""29 Jan 20"": 1,
""30 Jan 20"": 1,
""31 Jan 20"": 1,
....
}
</code></pre>

<p><strong>UPDATE</strong></p>

<p>I want to get the output to looks like below:</p>

<pre><code>{
  ""date"": [
     ""22 Jan 20"",
     ""23 Jan 20"",
     ""24 Jan 20"",
     ""25 Jan 20"",
     .....
   ],
  ""total_confirmed"": [
     555,
     653,
     941,
     1434,
     .....
   ],
   ""max_value_of_total_confirmed"": 12214
}
</code></pre>

<p>Any help would be appreciated :)</p>
"
60785532,"<p>I'm trying to count integer value from JSON: <a href=""https://pomber.github.io/covid19/timeseries.json"" rel=""nofollow noreferrer"">https://pomber.github.io/covid19/timeseries.json</a> and got what I expected.</p>

<pre><code>{
""date"": [
""22 Jan"",
""23 Jan"",
""24 Jan"",
""25 Jan"",
....
],
""total_confirmed"": [
555,
653,
941,
1434,
....
],
""total_deaths"": [
17,
18,
26,
42,
....
],
""total_recovered"": [
28,
30,
36,
39,
....
],
""max_value_of_total_confirmed"": 272166
}
</code></pre>

<p>Here's my controller:</p>

<pre><code>$client = new Client();$request = $client-&gt;get('https://pomber.github.io/covid19/timeseries.json');
$response = $request-&gt;getBody()-&gt;getContents();
$posts_dates = json_decode($response, true);

$confirmed_array = array();
$deaths_array = array();
$recovered_array = array();

if ( ! empty( $posts_dates ) ) {
    foreach ( $posts_dates as $country =&gt; $data )   {
        foreach ( $data as $dataKey =&gt; $dateData )    {

            $date = new \DateTime( $dateData['date'] );
            $day = $date-&gt;format( 'd M' );

            if ( !isset($confirmed_array[$day]) )  {
                $confirmed_array[$day] = 0;
            }
            $confirmed_array[$day] += $dateData['confirmed'];
        }
        foreach ( $data as $dataKey =&gt; $dateData )    {

            $date = new \DateTime( $dateData['date'] );
            $day = $date-&gt;format( 'd M' );

            if ( !isset($deaths_array[$day]) )  {
                $deaths_array[$day] = 0;
            }
            $deaths_array[$day] += $dateData['deaths'];
        }
        foreach ( $data as $dataKey =&gt; $dateData )    {

            $date = new \DateTime( $dateData['date'] );
            $day = $date-&gt;format( 'd M' );

            if ( !isset($recovered_array[$day]) )  {
                $recovered_array[$day] = 0;
            }
            $recovered_array[$day] += $dateData['recovered'];
        }
    }
}

$output = [
            ""date"" =&gt; array_keys($confirmed_array),
            ""total_confirmed"" =&gt; array_values($confirmed_array),
            ""total_deaths"" =&gt; array_values($deaths_array),
            ""total_recovered"" =&gt; array_values($recovered_array),
            ""max_value_of_total_confirmed"" =&gt; max($confirmed_array)
        ];

return $output;
</code></pre>

<p>What I'm trying to get is grouping those data not by date, but by week of the month (W3 Jan, W4 Jan, W1 Feb, W2 Feb, etc). Any help would be appreciated :)</p>

<p>Thank you.</p>
"
61640195,"<p>I have a series of csv i need to grab from a url, they have different namings but the same extention .csv and the same exact format. </p>

<p><strong><em>Then convert it to json.</em></strong></p>

<p>The following is what i use for one but how to loop for any .csv? </p>

<p>Also once downloaded them how to merge them? So let's say we have different dates, we should expect a merge like:</p>

<pre><code> {
    ""date"": 2/4/20,
    ""state"": ""AK"",...
},
 {
    ""date"": 3/4/20,
    ""state"": ""AK""...
</code></pre>

<p>This is the php I am using for a single csv</p>

<pre><code>header('Content-Type: application/json');

if (($handle = fopen(""example.com/NAME.csv"", ""r"")) !== FALSE) {
    $csvs = [];
    while(! feof($handle)) {
        $csvs[] = fgetcsv($handle);
    }
    $datas = [];
    $column_names = [];
    foreach ($csvs[0] as $single_csv) {
        $column_names[] = $single_csv;
    }
    foreach ($csvs as $key =&gt; $csv) {
        if ($key === 0) {
            continue;
        }
        foreach ($column_names as $column_key =&gt; $column_name) {
            $datas[$key-1][$column_name] = $csv[$column_key];
        }
    }
    $json = json_encode($datas, JSON_PRETTY_PRINT);
    fclose($handle);
    print_r($json);
}
</code></pre>

<p>What if we have</p>

<pre><code>example.com/NAME.csv

example.com/NAME2.csv

example.com/NAME3.csv
</code></pre>

<p><strong>UPDATE</strong></p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports_us"" rel=""nofollow noreferrer"">This is the series of csv and its data</a></p>
"
61713102,"<p>I am downloding some json and merging them, but while doing that it creates</p>

<pre><code>    }
][
    {
</code></pre>

<p>I'd simply would like to replace that with a comma in order to have a valide json</p>

<p>I tried soemthign like this but it's not working:</p>

<pre><code>$datas = array();
$json = str_replace(""]["","","", $datas);
$json = json_encode($json, JSON_PRETTY_PRINT);
print_r($json);
</code></pre>

<p>If I can manage to do that I'd use the same to replace columns name (I'm actually building this json from a csv) if possible</p>

<p><strong>UPDATE</strong></p>

<p>To clearify I have multiple csvs from which I am then bulding a single json</p>

<p><strong>FULL CODE</strong></p>

<pre><code>header('Content-Type: application/json');

$arr = array(""04-12-2020"",
    ""04-13-2020"",
    ""04-14-2020"",
    ""04-15-2020"",
    ""04-16-2020"",
    ""04-17-2020"",
    ""04-18-2020"",
    ""04-19-2020"",
    ""04-20-2020"",
    ""04-21-2020"",
    ""04-22-2020"",
    ""04-23-2020"",
    ""04-24-2020"",
    ""04-25-2020"",
    ""04-26-2020"",
    ""04-27-2020"",
    ""04-28-2020"",
    ""04-29-2020"",
    ""04-30-2020"",
    ""05-01-2020"",
    ""05-02-2020"",
    ""05-03-2020"",
    ""05-04-2020"",
    ""05-05-2020"",
    ""05-06-2020"",
    ""05-07-2020"",
    ""05-08-2020"",
    ""05-09-2020"",
);

foreach($arr as $date) {

    $url = ""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/"".$date."".csv"";

    if (($handle = fopen($url, ""r"")) !== FALSE) {

        $csvs = [];
        while(! feof($handle)) {
            $csvs[] = fgetcsv($handle);
        }
        $datas = [];
        $column_names = [];
        foreach ($csvs[0] as $single_csv) {
            $column_names[] = $single_csv;
        }
        foreach ($csvs as $key =&gt; $csv) {
            if ($key === 0) {
                continue;
            }
            foreach ($column_names as $column_key =&gt; $column_name) {
                $datas[$key-1][$column_name] = $csv[$column_key];
            }
        }
        $json = json_encode($datas, JSON_PRETTY_PRINT);
        fclose($handle);
        print_r($json);
    }
}
</code></pre>
"
61015848,"<p>I want to publish some data in my wordpress blog post from particular API(URL).I crated some code and I don't know how to put those data(from API) into my blog post separately. </p>

<p>Here is my API source :
<a href=""https://www.hpb.health.gov.lk/en/api-documentation"" rel=""nofollow noreferrer"">https://www.hpb.health.gov.lk/en/api-documentation</a></p>

<p>It's data:(scroll down and look COVID-19 Situation Report)
<a href=""https://www.hpb.health.gov.lk/en"" rel=""nofollow noreferrer"">https://www.hpb.health.gov.lk/en</a></p>

<p>Here is my code</p>

<pre><code>var data="""";
$(document).ready(function() {
  getHealthData();
});

function getHealthData() {
  $.ajax({
    type: ""GET"",
    dataType: ""json"",
    url: ""https://www.hpb.health.gov.lk/api/get-current-statistical"",
    data: {
      action: ""get_data""
    },
    success: function(response) {
         //getting value from server
        var value=  response.data;

  data=
        ""update date time : ""+value['update_date_time']+""&lt;br/&gt; local Ttotal_cases : ""+value['local_total_cases']+""&lt;br/&gt; local_deaths : ""+value['local_deaths']+""&lt;br/&gt;local_new_deaths : ""+value['local_new_deaths']+""&lt;br/&gt;local_recovered :  ""+value['local_recovered']+""&lt;br/&gt;local_new_cases : ""+value['local_new_cases'];

 //adding value separately 
      $(""#something"").text(""No. of Local Total Cases :"" + value['local_total_cases'])
    }
  });
}
</code></pre>

<p>Html output</p>

<pre><code>&lt;div id=""something""&gt;&lt;/div&gt;  
</code></pre>

<p>please help me to display above detials in wordpress blog post ...</p>
"
60804257,"<p>I know the WebTable activity can get tables from the web page, but I need something a bit more complex than a table. I managed to download the web page in HTML format and store it in Azure blob storage, but I don't know how to read the HTML and continue the process. </p>

<p>The HTML doesn't match the regular data source types, such as CSV, parquet and so on, so it's not easy to use it as a source. It can be a binary source of a copy activity, but the activities I can make over a binary source are very limited.</p>

<p>Using Power Query, what I'm trying to achieve can be done using this simple M code:</p>

<pre><code>let
Source = 
 Web.BrowserContents(""https://www.who.int/emergencies/diseases/novel-coronavirus-2019/situation-reports""),
Links = 
 Html.Table(
  Source, 
  {{
   ""Link"", 
   ""a[href^=""""/docs""""]"", 
   each [Attributes][href]}})
in
   Links
</code></pre>

<p>I tried this code as well with a wrangling dataflow, but it doesn't recognize the ""Web"" and ""HTML"" objects.</p>

<p>I'm concerned that a simple task for power query can be so much more difficult in data factory. How can I solve this problem?</p>

<p>Thank you in advance!</p>

<p>Dennes</p>
"
61019649,"<p>I'm working with BeautifulSoup and in a website </p>

<blockquote>
  <p>""<a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a>"", </p>
</blockquote>

<p>I have a div element without ID and I want to get the contents inside the Div and store it in a variable</p>

<pre><code>Eg: ""Last updated: April 03, 2020, 03:34 GMT""
</code></pre>

<p>This is the div element:</p>

<pre><code>&lt;div style=""font-size:13px; color:#999; text-align:center""&gt;Last updated: April 03, 2020, 03:34 GMT&lt;/div&gt;
</code></pre>

<p>Can someone please help me on this. Thanks in Advance</p>
"
61635203,"<p><a href=""https://i.stack.imgur.com/nUcUX.png"" rel=""nofollow noreferrer"">clustered at the bottom - image</a>
I am trying to plot how the covid cases increase as a cumulative sum over a duration for various countries. So I basically wanted dates on the x axis and count on the y axis. how can I break my axis into smaller bins so that it looks cleaner? </p>

<pre><code>date_trend = covid_data[covid_data['type']=='confirmed'].pivot_table(values='cases',index='Country.Region',columns='date',aggfunc=np.sum)
final_trend = date_trend.cumsum(axis=1)
trend_t10 = final_trend.loc[top10.index]
plt.figure(figsize=[20,20])
for index, row in trend_t10.iterrows(): 
    plt.plot(trend_t10.loc[index].index,trend_t10.loc[index].values,label=index,linewidth=2,markersize=12)
plt.legend(loc='best')
params = {'legend.fontsize': 20,
          'legend.handlelength': 2}
plot.rcParams.update(params)
plt.xlabel('Dates')
plt.ylabel('Number of Confirmed Cases')
plt.title('China in comapriso to other majorly affected countries')
plt.show()
</code></pre>
"
61483054,"<p>I am trying to create a Heatmap movie for the confirmed cases of Covid 19. </p>

<p>My dataset is a <code>pd.dataFrame</code> with columns <code>Date</code>, <code>Latitude</code>, <code>Longitude</code>, <code>Confirmed</code>. </p>

<p>My issue is that I do not know how to input the Confirmed value as an input in the <code>Folium.plugin.HeatmapWithTime</code>. </p>

<p>I tried using:</p>

<pre class=""lang-py prettyprint-override""><code>new_map = folium.Map(location=[0, 0], tiles= ""cartodbpositron"",min_zoom=2, zoom_start=2, max_zoom=3)

df['Lat'] = df['Lat'].astype(float)
df['Long'] = df['Long'].astype(float)

Confirmed_df = df[['Lat', 'Long','Confirmed']]

hm = plugins.HeatMapWithTime(Confirmed_df,auto_play=True,max_opacity=0.8)
hm.add_to(new_map)

new_map
</code></pre>

<p>df looks like:</p>

<pre><code>Date                     LAT           LONG    Confirmed 
2020/04/26             48.847306     2.433284   6500
2020/04/26             48.861935     2.441292   4800      
2020/04/26             48.839644     2.655109   9000   
2020/04/25             48.924351     2.386369   12000      
2020/04/25             48.829872     2.376677   0  
</code></pre>
"
61482595,"<p>I am working on a co-authorship network between COVID19 scholars and the data I got looks like below.<a href=""https://i.stack.imgur.com/rMW4x.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/rMW4x.png"" alt=""enter image description here""></a> To build a network, I first need to convert it to an edgelist while assigning value to distinguish the effect of the main author and the co-authors.</p>

<p>Does anyone know how I can do this in Python?</p>
"
61280196,"<p>So below is the code, I ran to get my heatmap.</p>

<p>The problem is that some of the countries do not have an updated row every day so there would be some missing days before there appears a row for one of these countries. This reflects in the choropleth map where it shows the country with a case and then removes it for the days it did not have any data. I would want to keep the highlight that first appeared even if some of the days went missing but i find it difficult.</p>

<pre><code>merg['Difference'] = np.where(merg.Country_Region == merg.Country_Region.shift(), merg.LastUpdate - merg.LastUpdate.shift(), np.nan)
</code></pre>

<p>I have created a column called difference that stores difference between dates for two rows:</p>

<pre><code>fig = px.choropleth(maps, locations=""iso_alpha"",
                    color=""Confirmed"", # Confirmed is a column of confirmed cases of maps
                    hover_name=""Country_Region"", # column to add to hover information
                    animation_frame = ""LastUpdate"", #LastUpdate is the column of dates
                    color_continuous_scale=['#0d0887', '#46039f', '#7201a8', '#9c179e', '#bd3786', '#d8576b', '#ed7953', '#fb9f3a', '#fdca26', '#f0f921'])
fig.show()
</code></pre>
"
61241931,"<p>There</p>

<p>I used the code as below</p>

<pre><code>World_Covid19 &lt;- read.csv(""Covid19_data.csv"")

World_Covid19$Total_cases &lt;- as.numeric(World_Covid19$Total_cases)
</code></pre>

<p>as I convert the factor to a numeric column, I met a problem, the value has changed, how to fix it?</p>

<p><img src=""https://i.stack.imgur.com/OyE1a.png"" alt=""enter image description here""></p>

<p><img src=""https://i.stack.imgur.com/PmkjS.png"" alt=""enter image description here""></p>
"
61140860,"<p>I had Scrapped Data from <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a> for countrywise stats using bs4. but i want to use that data to populate my django model with same fields as scrapped data which i dont know how. i am also having trouble with scraping tabular data with other libraries like scrapy (celery).this is the xpath of the table i am try to scrap ""//*[@id=""main_table_countries_today""]"". if anyone could help me how to use this scarp data to store in django models would be great.
PS not using external CSV or Json Files.</p>
"
61052905,"<pre><code>url = ""https://www.worldometers.info/coronavirus/""
response = requests.get(url)
data = response.text
soup = BeautifulSoup(data, ""html.parser"")    

'''Since there are no unary operators supported between 'counter' and the variable 'i',
I must declare another variable 'counter' and set it equal to zero, with the value
of counter being updated by 1 each time.'''
total_cases = []
counter = 0;
global_case_information = soup.find_all(""div"", {""class"":""maincounter-number""})
for cases in global_case_information:
    if(counter == 13):
        break
    else:
        total_cases.append(cases.text)
        counter += 1    
global_cases = {""Total Deaths"":total_cases[1], ""Total Recovered"":total_cases[2]}

covid_figure = plt.figure()
plt.rcParams[""figure.figsize""] = [40, 40]
keys_array = np.arange(len(global_cases.keys()))

axes = plt.gca()
plt.xticks(keys_array, global_cases.keys())
plt.ylabel(""Number Of People Affected(Globally)"")
plt.title(""Global Covid-19 Statistics"")    
plt.bar(keys_array, global_cases.values())    
plt.show()
</code></pre>

<p>Alright, so I am trying to make the y-axis start at zero, and have a relative offset of 50000 units. However, that's not what's going on, and I even tried doing the following:</p>

<p>plt.yticks(np.arange(0, 300000, 50000))</p>

<p>But that isn't working.</p>
"
61052042,"<p>I have this database that updated daily. <a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports</a> I need to download all available data to date using a function that automatically does that process and also write a function that allows to check the database to see if there are new updates</p>
"
61039337,"<p>I'm working on CNN model and I'm curious to know-how converts the output given by  datagen.flow_from_directory() into a bumpy array. The format of datagen.flow_from_directory() is directoryiterator.</p>

<p>Apart from ImageDataGenerator is any other way also to fetch data from the directory. </p>

<pre><code>img_width = 150
img_height = 150

datagen = ImageDataGenerator(rescale=1/255.0, validation_split=0.2)

train_data_gen =  directory='/content/xray_dataset_covid19',
                                             target_size = (img_width, img_height),
                                             class_mode='binary',
                                             batch_size=16,
                                             subset='training')

vali_data_gen = datagen.flow_from_directory(directory='/content/xray_dataset_covid19',
                                             target_size = (img_width, img_height),
                                             class_mode='binary',
                                             batch_size=16,
                                             subset='validation')
</code></pre>
"
60940063,"<p>I am trying to create a map that tracks COVID-19 confirmed cases by county using FIPS codes. How am I able to make this code gather the data from both of those data files? </p>

<p>If you run the code as is (NY times data) then the map does not fill in counties with zero cases as zero cases. This is because the NY times data does not list the data for the places with zero cases. The other data does list places with zero cases. So, whatever doesn't get filled in with the NY times data I would like to fill in with the other data set. How do I do this? Or how do I fix my problem? Also, when hovering over the map how do I make it state the county name instead of the FIPS number? </p>

<p>Furthermore, how do I make this a live map that auto-updates when there is new data? </p>

<pre><code>from urllib.request import urlopen
import json
with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response:
    counties = json.load(response)

import pandas as pd
df = pd.read_csv(""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"",
                   dtype={""fips"": str})

df = pd.read_csv(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-28-2020.csv"",
                   dtype={""fips"": str})


import plotly.express as px

                          )

fig = px.choropleth(df, geojson=counties, locations='fips', color='cases',
                           color_continuous_scale=""dense"",
                           range_color=(0, 100),
                           scope=""usa"", 
                           labels={'cases':'Confirmed COVID:19 Cases'},

                          )
fig.update_layout(margin={""r"":0,""t"":0,""l"":0,""b"":0})
fig.show()
</code></pre>
"
61403265,"<p>Basically I am making a COVID-19 bot which tracks all the cases and deaths around the world.</p>

<pre><code>def total_cases_counter():
    # create the button
    button = pygame.Rect(63, 183, 105, 40)
    pygame.draw.rect(screen, [0, 0, 0], button)
    button_font = pygame.font.Font('GOODDP__.TTF', 32)
    button_text = button_font.render(total_cases, True, (255, 255, 255))
    screen.blit(button_text, (205, 410))
</code></pre>

<p>This is my function to display a total cases counter which I create a button for and then try to display the total_cases which I have as a variable that is updated from an API. The issue I have is I do not know how to display the variable value (number of total cases around the world) over the button. I tried using the render function but the first parameter has to be a string which means I cannot display my variable.</p>
"
61570413,"<p>I have been provided with a .csv file, which has data on covid19. It is in the form of:</p>

<pre><code>district | country   |    date1      |      date2     |    date3     |etc
victoria | australia |1 case         | 3 cases        |7 cases       | etc
</code></pre>

<p>It is a fairly large file, with 263 rows of countries/districts, and 150 columns of dates.</p>

<p>The program needs to be able to take in an input <code>district</code>, <code>country</code>, and <code>date</code> and print out the number of COVID <code>cases</code> in that location as of that date. (print the value of a specified row and column of a CSV file)</p>

<p>We have been instructed not to use the CSV module or the pandas module. I am having trouble understanding where to start. I will add my attempted solutions to this question as I go along. Not looking for a complete solution,but any ideas that I could try would be appreciated.</p>
"
60798792,"<p>I'm trying to do a Scrapping that will return the videos that a particular YouTube channel uploaded on a certain date using bs4 and requests.</p>

<p>Here's the code:</p>

<pre><code>    import requests
    from bs4 import BeautifulSoup as bs

    all_videos = requests.get('https://www.youtube.com/channel/UC16niRr50-MSBwiO3YDb3RA/videos')
    soup = bs(all_videos.text, 'html.parser')

for video in soup.findAll('h3','yt-lockup-title'):
    print(video)
</code></pre>

<p>The output is:</p>

<pre><code>&lt;h3 class=""yt-lockup-title""&gt;&lt;a aria-describedby=""description-id-721031"" class=""yt-uix-sessionlink yt-uix-tile-link spf-link yt-ui-ellipsis yt-ui-ellipsis-2"" data-sessionlink=""ei=d1R3Xu7bOfTysAKmsY2IDg&amp;amp;feature=c4-videos-u"" dir=""ltr"" href=""/watch?v=ejzQApmABdM"" rel=""nofollow"" title=""Coronavirus: People in Beijing begin to head outdoors - BBC News""&gt;Coronavirus: People in Beijing begin to head outdoors - BBC News&lt;/a&gt;&lt;span class=""accessible-description"" id=""description-id-721031""&gt; - Duration: 3 minutes, 8 seconds.&lt;/span&gt;&lt;/h3&gt;
</code></pre>

<p>How do I extract the title, link, and upload date from here? </p>
"
61002009,"<p>I am trying to create a graph of filtered values from a CSV file. Essentially, I have to filter through all the data from this dataset: <a href=""https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases#"" rel=""nofollow noreferrer"">https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases#</a>
, and tally up how many cases of coronavirus there are for each country (US, Chine, Italy, Germany and Iran), then produce a graph for each country, comparing the number of cases (y-axis) to the date (x-axis). </p>

<p>So far, I have been able to filter the data, and print each line containing the number of cases for that specific location. I have not been able to tally up the total amount for each country or produce a graph that makes sense.</p>

<p>Here is my code so far:</p>

<pre><code>import matplotlib.pyplot as plt
import numpy as np
import pandas as pd



data = pd.read_csv(r'C:*****')

countries = ['China', 'Italy', 'Germany', 'Iran', 'US']
filtered_data = data[data['Country/Region'].isin(countries)]


wanted_values = filtered_data[['Country/Region','1/22/2020','1/23/2020','1/24/2020', 
 '1/25/2020','1/26/2020','1/27/2020','1/28/2020','1/28/2020','1/29/2020',


 '1/30/2020','1/31/2020','2/1/2020','2/2/2020','2/3/2020','2/4/2020','2/5/2020','2/6/2020',
  '2/7/2020',  '2/8/2020','2/9/2020','2/10/2020',
  '2/11/2020','2/12/2020','2/13/2020','2/14/2020','2/15/2020',
  '2/16/2020','2/17/2020','2/18/2020','2/19/2020','2/20/2020','2/21/2020',
  '2/22/2020','2/23/2020',
'2/24/2020','2/25/2020','2/26/2020','2/27/2020','2/28/2020','2/29/2020','3/1/2020',
'3/2/2020','3/3/2020','3/4/2020','3/5/2020','3/6/2020','3/7/2020',
'3/8/2020','3/9/2020','3/10/2020','3/11/2020','3/12/2020','3/13/2020','3/14/2020',
'3/15/2020','3/16/2020','3/17/2020','3/18/2020','3/19/2020',
'3/20/2020','3/21/2020']]


 print(wanted_values.iloc[0])
 print(wanted_values.iloc[1])
 print(wanted_values.iloc[282])
</code></pre>

<p>There are 283 rows of data that was filtered from the original CSV file, hence the iloc[282]. </p>

<p>I'm not too sure where to go from here to be able to graph the number of cases vs. the date for each country/region.</p>

<p><a href=""https://i.stack.imgur.com/VSMLG.png"" rel=""nofollow noreferrer"">Here is a screenshot of what the data set looks like.</a></p>
"
60693024,"<p>So, I am trying to scrape data off a page to analyze it with R. In order for a complete analysis I need to be able to account for the day of each infection. The page portrays it's content as so:</p>

<pre><code>&lt;h4&gt; 5 of March &lt;/h4&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;/li&gt;
    &lt;li&gt;&lt;/li&gt;
    x10
&lt;/ul&gt;
&lt;h4&gt; 4 of March &lt;/h4&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;/li&gt;
    &lt;li&gt;&lt;/li&gt;
    x15
&lt;/ul&gt;
&lt;h4&gt; 3 of March &lt;/h4&gt;
&lt;ul&gt;
    &lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
</code></pre>

<p>and so on until the 21 of Januray. </p>

<p>What I want to do is to count the amount of <code>&lt;li&gt;</code> that are within a given <code>&lt;ul&gt;</code> that corresponds to its <code>&lt;h4&gt;</code> and for python to give me back a list that repeats the <code>&lt;h4&gt;</code> string the <code>&lt;li&gt;</code> amount of times.
So for example, in <code>&lt;h4&gt;</code> 5 of March <code>&lt;h4&gt;</code> case I would want a list that repeats ""5 of March"" 12 times, because there are 12 <code>&lt;li&gt;</code> that correspond to that <code>&lt;h4&gt;</code>. </p>

<p>so far this is my code, but it doesn't even return something to me:</p>

<pre><code>import re
from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd

driver = webdriver.Chrome(#purposefully left blank)

amount = []
cases = []
deaths = []
Country = [] 
Province = [] 

driver.get(""https://bnonews.com/index.php/2020/01/timeline-coronavirus-epidemic/"")

content = driver.page_source
soup = BeautifulSoup(content)

h4_tag = str(soup.findAll('h4'))
li_tag = str(soup.findAll('li'))

FLAGS = re.VERBOSE | re.DOTALL | re.IGNORECASE 
</code></pre>

<p>At this point I was just trying to see if I could count the amount of <code>&lt;ul&gt;</code> elements but I can't even do that... 
Any Ideas? I've checked stack and git for answers but to no avail...</p>

<p><strong>UPDATE</strong>
the code <code>findChildren</code> doesn't work because the <code>&lt;ul&gt;</code> and <code>&lt;li&gt;</code> elements are not children of the <code>&lt;h4&gt;</code> element. Removed ""recursive""</p>

<pre><code>ul_tag =  soup.find('div', attrs = {'class':'mvp-post-soc-in'})
children = ul_tag.find('li')
print(children)
</code></pre>

<p>This code returns a list with all <code>&lt;li&gt;</code> elements and their content.</p>

<p><strong>Trying to check if soup(content) is string</strong>
This is what I get when I print soup:</p>

<pre><code>&lt;html lang=""en-US"" style=""transform: none;""&gt;&lt;head&gt;&lt;meta content=""60109657413"" property=""fb:pages""/&gt;
&lt;meta charset=""utf-8""/&gt;
&lt;meta content=""width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no"" id=""viewport"" name=""viewport""/&gt;
&lt;link href=""https://bnonews.com/wp-content/uploads/2018/03/favicon2.ico"" rel=""shortcut icon""/&gt;&lt;link href=""https://bnonews.com/xmlrpc.php"" rel=""pingback""/&gt;
&lt;meta content=""article"" property=""og:type""/&gt;
&lt;meta content=""https://bnonews.com/wp-content/uploads/2019/04/2019EbolaWorker.jpg"" property=""og:image""/&gt;
&lt;meta content=""https://bnonews.com/wp-content/uploads/2019/04/2019EbolaWorker.jpg"" name=""twitter:image""/&gt;
&lt;meta content=""https://bnonews.com/index.php/2020/01/timeline-coronavirus-epidemic/"" property=""og:url""/&gt;
&lt;meta content=""TIMELINE: Coronavirus epidemic"" property=""og:title""/&gt;
&lt;meta content=""The following is a timeline of new cases in China and around the world. It is updated once a day. For the current day, click here. Timeline (GMT) 10 March 23:57: First 2 cases in Bolivia. (Source) 23:40: 21 new cases and 1 new death in Spain. (Source) 23:39: 1 new case in Nebraska, United […]"" property=""og:description""/&gt;
&lt;meta content=""summary"" name=""twitter:card""/&gt;
&lt;meta content=""https://bnonews.com/index.php/2020/01/timeline-coronavirus-epidemic/"" name=""twitter:url""/&gt;
&lt;meta content=""TIMELINE: Coronavirus epidemic"" name=""twitter:title""/&gt;
&lt;meta content=""The following is a timeline of new cases in China and around the world. It is updated once a day. For the current day, click here. Timeline (GMT) 10 March 23:57: First 2 cases in Bolivia. (Source) 23:40: 21 new cases and 1 new death in Spain. (Source) 23:39: 1 new case in Nebraska, United […]"" name=""twitter:description""/&gt;
&lt;title&gt;TIMELINE: Coronavirus epidemic - BNO News&lt;/title&gt;
&lt;link href=""https://bnonews.com/index.php/2020/01/timeline-coronavirus-epidemic/"" rel=""canonical""/&gt;
&lt;meta content=""en_US"" property=""og:locale""/&gt;
&lt;meta content=""article"" property=""og:type""/&gt;
&lt;meta content=""TIMELINE: Coronavirus epidemic - BNO News"" property=""og:title""/&gt;
&lt;meta content=""The following is a timeline of new cases in China and around the world. It is updated once a day. For the current day, click here. Timeline (GMT) 10 March 23:57: First 2 cases in Bolivia. (Source) 23:40: 21 new cases and 1 new death in Spain. (Source) 23:39: 1 new case in Nebraska, United …"" property=""og:description""/&gt;
&lt;meta content=""https://bnonews.com/index.php/2020/01/timeline-coronavirus-epidemic/"" property=""og:url""/&gt;
&lt;meta content=""BNO News"" property=""og:site_name""/&gt;
</code></pre>
"
61242118,"<p>I am trying scrape a website, loop through to get only the state names and not all the classes in the table data. But when I loop through it gives all table data is there a way to exclude the td class?</p>

<pre><code>page = requests.get(""https://www.theguardian.com/world/ng-interactive/2020/apr/13/coronavirus-map-us-latest-covid-19-cases-state-by-state"")
soup = BeautifulSoup(page.content, 'html.parser')
state_table = soup.find(id='co-table-container')
item_cases = state_table.find(class_='co-table')
states = [s.get_text() for s in item_cases.find_all('td')]
print(states)
</code></pre>
"
60621922,"<p>I've been trying to get only one value from a table on a website. I've been following a tutorial but I am currently stuck. My goal is to extract the name of the country from the table and the number of total cases of that specific country and print it on the screen. For example:</p>

<blockquote>
  <p>China: 80,761 Total cases</p>
</blockquote>

<p>I'm using Python 3.7.
This is my code so far:</p>

<pre><code>import requests
from bs4 import BeautifulSoup

url='https://www.worldometers.info/coronavirus/'
response = requests.get(url)

soup = BeautifulSoup(response.content, 'html.parser')
table = soup.findAll('table',{'id':'main_table_countries'})
</code></pre>
"
60825702,"<p>I want to download the daily data about the daily covid19 cases from the ECDC Website. How do I do that with python code and import it to my notebook.
I have previously downloaded the data from GitHub, but I have no idea how to download the data from a link provided on a live website.</p>

<pre><code>from github.MainClass import Github
g = Github('KEY')
repo = g.get_repo(""CSSEGISandData/COVID-19"")
file_list = repo.get_contents(""csse_covid_19_data/csse_covid_19_daily_reports"")
github_dir_path = 'https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_daily_reports/'
file_path = github_dir_path  + str(file_list[-2]).split('/')[-1].split(""."")[0]+ '.csv'
</code></pre>
"
60891322,"<p>I want to extract the data regarding all the CoVid19 cases in India from this <a href=""https://docs.google.com/spreadsheets/d/e/2PACX-1vSc_2y5N0I67wDU38DjDh35IZSIS30rQf7_NYZhtYYGU1jJYT6_kDx4YpF-qw0LSlGsBYP8pqM_a1Pd/pubhtml#"" rel=""nofollow noreferrer"">Google Spreadsheet</a> which updates every 5 min. 
previously i have worked with extracting data from APIs but have no idea how to do it from spreadsheets.</p>
"
61366169,"<p>I need to access the table from this website <a href=""https://www.tsa.gov/coronavirus/passenger-throughput"" rel=""nofollow noreferrer"">https://www.tsa.gov/coronavirus/passenger-throughput</a>.</p>

<p>I need to have this table as a pandas data frame.</p>

<p>Before, I worked only with the URLs which are already the xls or csv, so I do not know how to get the table from the ordinary website.</p>

<p>Help, please!</p>
"
60369957,"<p>I'm really interested in learning how to scrape data, specifically tables from websites using any libraries.
Right now I'm using this to get the table from this website <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a></p>

<pre><code>import requests
import pandas as pd    

url = 'https://www.worldometers.info/coronavirus/'
html = requests.get(url).content

df_list = pd.read_html(html)
df = df_list[-1]

print(df)
df.to_csv('my data.csv')
</code></pre>

<p>However, every time I get this '...' in the content, which skips 3 columns.
How can I fix this?</p>

<ol>
<li><p>How can I obtain the numeric data, for example just getting the number of deaths and store it in a list</p></li>
<li><p>How can I replace the 'NaN' to '-'?</p></li>
</ol>
"
61672502,"<p>I would like to use my data from excel to draw a graph and display it on Tkinter windows.
but I couldn't and I don't know how I can do it I search in many places I got only examples to show data from the code. here is my code:</p>

<blockquote>
  <p>here the file of Excel <a href=""http://webprogramozas.inf.elte.hu/students/nwyuk6/excelfiles/COVID-19.xlsm"" rel=""nofollow noreferrer"">download here</a></p>
</blockquote>

<pre><code>import tkinter as tk
import pandas as pd
from pandas import DataFrame
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

df= pd.read_excel (r'C:\Users\evil4ever\Desktop\acheraf\project\projetCorona.xlsx') 
tab1=df[0:31]

#Dates=['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31']
Dates = []
for i in range(1,32):
    Dates.append(str(i))


Values=tab1['Cas confirmés']#rmorocco
Values2=tab1['RABAT.SALE.KENITRA']#rabat

f=plt.Figure(figsize=(9,5), dpi=100)

plt.xlabel('days of March')
plt.ylabel('Confirmed cases')
plt.title('Confirmed Cases in March RABAT.SALE.KENITRA ')
plt.bar(Dates,Values,label='all morocco',color='r')
plt.bar(Dates,Values2,label='RABAT.SALE.KENITRA',color='c')
a=f.add_subplot(111)
root= tk.Tk()
canvas=FigureCanvasTkAgg(f, root)

canvas.get_tk_widget().pack(side=tk.LEFT, fill=tk.BOTH, expand=True)
root.mainloop()
</code></pre>

<blockquote>
  <p>explain the problem:
  when i run the program is showing this windows look this <a href=""https://i.stack.imgur.com/YheGR.png"" rel=""nofollow noreferrer"">image</a></p>
</blockquote>

<p>and the graph is showing here in this <a href=""https://i.stack.imgur.com/ixfop.png"" rel=""nofollow noreferrer"">image</a>
after the code showing the graph which I wanna display on windows not there</p>

<blockquote>
  <p>after this line:a=f.add_subplot(111)
  i add a.plot([1,2,3,4,5,6,7,8],[5,6,1,3,8,9,3,5]) is showing something in windows</p>
</blockquote>

<p>i search to much for 3 days without any solution.</p>
"
60738535,"<p>I am trying to add a new word to be recognized by pyspellchecker.
The following code:</p>

<pre><code>from spellchecker import SpellChecker
spell = SpellChecker(language='es')
spell.word_frequency.load_words('coronavirus')
spell.unknown(['El','coronavirus','marca','nuestros','días'])
</code></pre>

<p>Produces this output:</p>

<pre><code>{'coronavirus'}
</code></pre>

<p>And the output I expected was:</p>

<pre><code>set()
</code></pre>

<p>...an empty set, as I added the word 'coronavirus' so it should be included in the set of known words.</p>
"
61415620,"<p>This link contains CSV files for daily reports of COVID-19.</p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports</a></p>

<p>What is the best solution to get all the csv files in a dataframe?</p>

<p>I tried the code bellow from other questions but it doesnt work.</p>

<pre><code>from pathlib import Path
import pandas as pd

files = Path('https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports')

csv_only = files.rglob('*.csv')

combo = [pd.read_csv(f)
         .assign(f.stem)
         .fillna(0)
         for f in csv_only]

one_df = pd.concat(combo,ignore_index=True)

one_df = one_df.drop_duplicates('date')
print(one_df)
</code></pre>

<p>How could i fit requests to read all the files?</p>
"
61418389,"<p>I am trying to format the column 'Data' to make a pattern with dates.</p>

<p>The formats I have are:</p>

<pre><code>1/30/20 16:00
1/31/2020 23:59
2020-02-02T23:43:02
</code></pre>

<p>Here is the code for the dataframe.</p>

<pre><code>import requests
import pandas as pd
import numpy as np
url = ""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports""
csv_only  = [i.split(""="")[1][1:-1] for i in requests.get(url).text.split("" "") if '.csv' in i and 'title' in i]

combo = [pd.read_csv(url.replace(""github"",""raw.githubusercontent"").replace(""/tree/"",""/"")+""/""+f) for f in csv_only]

one_df = pd.concat(combo,ignore_index=True)

one_df[""País""] = one_df[""Country/Region""].fillna(one_df[""Country_Region""])
one_df[""Data""] = one_df[""Last Update""].fillna(one_df[""Last_Update""])
</code></pre>

<p>I tried adding the code bellow but it doesnt bring the result I wanted</p>

<pre><code>pd.to_datetime(one_df['Data'])
one_df.style.format({""Data"": lambda t: t.strftime(""%m/%d/%Y"")})
</code></pre>

<p>Any help?</p>

<p><strong>UPDATE</strong></p>

<p>This is the complete code, but it doesnt work. Many exceptions printed with different date formats.</p>

<pre><code>import requests
import pandas as pd
import numpy as np
from datetime import datetime
url = ""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports""
csv_only  = [i.split(""="")[1][1:-1] for i in requests.get(url).text.split("" "") if '.csv' in i and 'title' in i]

combo = [pd.read_csv(url.replace(""github"",""raw.githubusercontent"").replace(""/tree/"",""/"")+""/""+f) for f in csv_only]

one_df = pd.concat(combo,ignore_index=True)

df = pd.DataFrame()
DATE_FORMATS = [""%m/%d/%y %H:%M"", ""%m/%d/%Y %H:%M"", ""%Y-%m-%dT%H:%M:%S"", ""%Y-%m-%d %H:%M:%S"", ""%Y-%m-%d %H:%M:%S"", ""%Y-%m-%d  %H:%M:%S""]

df[""Região""] = one_df[""Province/State""].fillna(one_df[""Admin2""])
df[""País""] = one_df[""Country/Region""].fillna(one_df[""Country_Region""])
df[""Data""] = one_df[""Last Update""].fillna(one_df[""Last_Update""])
df[""Confirmados""] = one_df[""Confirmed""]
df[""Mortes""] = one_df[""Deaths""]
df[""Recuperados""] = one_df[""Recovered""]

def parse(x_):
    for fmt in DATE_FORMATS :
        try:
            tmp = datetime.strptime(x_, fmt).strftime(""%m/%d/%Y"")
            return tmp
        except ValueError:
            print(x_)

pd.to_datetime(df['Data'])
df['Data'] = df['Data'].apply(lambda x: parse(x))

#df['Data'].strftime('%m/%d/%Y')
#df['Data'] = df['Data'].map(lambda x: x.strftime('%m/%d/%Y') if x else '')

df.to_excel(r'C:\Users\guilh\Downloads\Covid2\Covid-19.xlsx', index=False,  encoding=""utf8"")
print(df)
</code></pre>
"
61176316,"<p>So I tried getting all the headlines of the New York Times homepage and wanted to see how many times a certain word has been mentioned. In this particular case, I wanted to see how many headlines mentioned either the Coronavirus or Trump. This is my code but it won't work as 'number' remains the integer I give it before the while loop.</p>

<pre><code>import requests
from bs4 import BeautifulSoup

url = 'https://www.nytimes.com'
r = requests.get(url)
soup = BeautifulSoup(r.text, ""html.parser"")
a = soup.findAll(""h2"", class_=""esl82me0"")

for story_heading in a:
    print(story_heading.contents[0])

lijst = [""trump"", ""Trump"", ""Corona"", ""COVID"", ""virus"", ""Virus"", ""Coronavirus"", ""COVID-19""]
number = 0
run = 0

while run &lt; len(a)+1:
    run += 1
     if any(lijst in s for s in a)
        number += 1

print(""\nTrump or the Corona virus have been mentioned"", number, ""times."")
</code></pre>

<p>So I basically want the variable 'number' to increase by 1 if a headline (which is an entry in the list a) has the word Trump or Coronavirus or both in them.</p>

<p>Does anyone know how to do this? </p>
"
61511426,"<p>I have a super long url, and I'm trying to print its final destination. I've got:</p>

<pre><code>import requests
url = ""https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.washingtonpost.com%2Fscience%2F2020%2F04%2F29%2Fcoronavirus-detection-dogs%2F%3Ffbclid%3DIwAR00eT4EHsWC9986GUSox_7JS7IIg2wAan-tB-NteYJd8I4xckmxnfaNGEI&amp;h=AT0cs4gTKPZlkSElC2uhoDYR98lsONooq_ZUFIK87khBmtZE_3r8j25EfioBPAdp-O8o7efRVG9uB-doy9vLT-AccZMrxnfpEiSYRmA2LTL21IU15bP_PTVw4SSibS1A_uE8bU-ROJexKgdk68VSTtE&amp;__tn__=H-R&amp;c[0]=AT3BNcTNFE13IJu3naJmxTRdJTWtO4O4L0_-nimmzcXpYv3N536YRpQZLg-v2FtP_Oz2DZZpBN6XQPb89JNJTsYFXlK8-1g4xdDLi1T_lfowpI5Ooh8kuLpciLiQ9t-ZmMd2CTUWaGZ_Y_JU0OEvVWfLLfjDq4VOzUtETBcvXHw2ZvQnTQ""
r = requests.get(url, allow_redirects=False)
print(r.headers['Location'])
</code></pre>

<p>It should get me to <a href=""https://www.washingtonpost.com/science/2020/04/29/coronavirus-detection-dogs/?fbclid=IwAR00eT4EHsWC9986GUSox_7JS7IIg2wAan-tB-NteYJd8I4xckmxnfaNGEI"" rel=""nofollow noreferrer"">https://www.washingtonpost.com/science/2020/04/29/coronavirus-detection-dogs/?fbclid=IwAR00eT4EHsWC9986GUSox_7JS7IIg2wAan-tB-NteYJd8I4xckmxnfaNGEI</a>. But I get the same URL I put in.</p>

<p>(By the way, if anyone happens to know how to do this in Javascript, that would be awesome, but Google tells me that's not possible.)</p>
"
60556448,"<p>I am trying to scrape data related to COVID-19. I was able to download some data from the website, for example, the number of total cases, but not data from interactive graphs. </p>

<p>I usually scrape interactive graphs with json by finding the source from 'network' in the inspect element page. However, I was not able to find the 'network' for the interactive graphs to scrape. </p>

<p>Can someone please help me to scrape data from ""total deaths"" graph? or any other graph from the website. Thanks.</p>

<p>Just to make it clear. I don't want to scrape data from the table of Countries. I already did that. What I want to do is get data from the graphs. For example, data from death ratio graph vs date or active cases vs time date graph. </p>

<p>Thanks</p>

<pre><code>import requests
import urllib.request
import time
import json
from bs4 import BeautifulSoup 
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

url= 'https://www.worldometers.info/coronavirus/#countries'
r = requests.get(url)
soup= BeautifulSoup(r.text, ""html.parser"")
</code></pre>

<p>for example, Number of effected countries:</p>

<pre><code>len(soup.find_all('table',{'id':'main_table_countries'})[0].find('tbody').find_all('tr'))
</code></pre>

<p><a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">website</a></p>
"
61417470,"<p>I'm gathering tweets about COVID19 using tweepy. I wish to collect only those tweets made by common people and not news channels. Whats the easiest way to filter those out?</p>

<pre><code>def search_for_hashtags(consumer_key, consumer_secret, access_token, access_token_secret, hashtag_phrase):

#create authentication for accessing Twitter
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)

#initialize Tweepy API
api = tweepy.API(auth)

#get the name of the spreadsheet we will write to
fname = '_'.join(re.findall(r""(\w+)"", hashtag_phrase))

#open the spreadsheet we will write to
with open('%s.csv' % (fname), 'w', encoding=""utf-8"") as file:

    w = csv.writer(file)

    #write header row to spreadsheet
    w.writerow(['timestamp', 'tweet_text', 'username', 'all_hashtags', 'followers_count'])

    #for each tweet matching our hashtags, write relevant info to the spreadsheet
    for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', \
                               lang=""en"", tweet_mode='extended').items(100):
        w.writerow([tweet.created_at, tweet.full_text.replace('\n',' ').encode('utf-8'), tweet.user.screen_name.encode('utf-8'), [e['text'] for e in tweet._json['entities']['hashtags']], tweet.user.followers_count])
</code></pre>
"
61180878,"<p>I have a xlsm file(<a href=""http://www.oecd.org/tax/tax-policy/covid-19-tax-policy-and-other-measures.xlsm"" rel=""nofollow noreferrer"">http://www.oecd.org/tax/tax-policy/covid-19-tax-policy-and-other-measures.xlsm</a>) I want to update the data and export the Data to xlsx.Image that represent the structure of Data I have tried many related codes related.Nothing worked for me.Please help me on this</p>

<p><a href=""https://i.stack.imgur.com/HUaox.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/HUaox.png"" alt=""enter image description here""></a></p>
"
61502379,"<p>I have two dataframes:</p>

<pre><code>file_date = str((date.today() - timedelta(days = 2)).strftime('%m-%d-%Y'))
file_date
</code></pre>

<p>github_dir_path = '<a href=""https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_daily_reports/"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/raw/master/csse_covid_19_data/csse_covid_19_daily_reports/</a>'
file_path = github_dir_path  + file_date + '.csv' 
first dataframe:</p>

<pre><code>  FIPS     Admin2     Province_State Country_Region          Last_Update        Lat       Long_  Confirmed  Deaths  Recovered  Active                   Combined_Key
0     45001.0  Abbeville     South Carolina             US  2020-04-28 02:30:51  34.223334  -82.461707         29       0          0      29  Abbeville, South Carolina, US
1     22001.0     Acadia          Louisiana             US  2020-04-28 02:30:51  30.295065  -92.414197        130       9          0     121          Acadia, Louisiana, US
2     51001.0   Accomack           Virginia             US  2020-04-28 02:30:51  37.767072  -75.632346        195       3          0     192         Accomack, Virginia, US
3     16001.0        Ada              Idaho             US  2020-04-28 02:30:51  43.452658 -116.241552        650      15          0     635                 Ada, Idaho, US
4     19001.0      Adair               Iowa             US  2020-04-28 02:30:51  41.330756  -94.471059          1       0          0       1                Adair, Iowa, US
</code></pre>

#

<pre><code>                            0                          0  ...          0         Kerala       0         Kerala       1
2     2020-02-01             Kerala                                        2                                           0                          0  ...          0         Kerala       0         Kerala       2
3     2020-02-02             Kerala                                        3                                           0                          0  ...          0         Kerala       0         Kerala       3
4     2020-02-03             Kerala                                        3                                           0                          0  ...          0         Kerala       0         Kerala       3
</code></pre>

<p>Please guide me on how to concatenate both the data frames. I tried a couple of things but did not get the expected result.</p>
"
61084092,"<p>I have the following code:</p>

<pre><code>from pandas import DataFrame
import pandas as pd

data = {'City': ['NY', 'NY', 'Arizona'], 'Doctor': ['Dr. Prof. Vera', 'Dr. Prof. Vera', 'Dr. Martin'], 'Type': ['Checked', 'Checked', 'Ordered'], 'Covid-Patient': ['yes', 'no', 'no']}
df = DataFrame(data).set_index(['City', 'Doctor', 'Type'])
df['Dr-Nr.'] = pd.Series(df.groupby(['Doctor']).cumcount()+1)
</code></pre>

<p>Which results in:</p>

<p><a href=""https://i.stack.imgur.com/3on7L.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/3on7L.png"" alt=""enter image description here""></a></p>

<p>But what I want is an individual number of the <code>Doctor</code> in a new column <code>Dr-Nr.</code>.
<a href=""https://i.stack.imgur.com/jOfzI.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jOfzI.png"" alt=""enter image description here""></a></p>

<p>Apparently, the grouping by level <code>Doctor</code> does not seem to have an effect. Any help is appreciated!</p>
"
61369594,"<p>Data:
NonCovid Images: 91 patient  CT scan Images: Each patient has a variable number of images; Total: 396 Images
Covid Images: 216 patient CT scan Images(Total 349 Images)</p>

<p>Tasks:
1.Organize and label the data properly.
   Because each patient has variable number of images, organise as follows:
 Covid:--->Patient0-->Imge0,Image1,
           --->Patient1--->Image0,Image1,
Similarly Organise it for NonCovid also.</p>
"
61558693,"<p>When we use geopandas to draw a chloropleth, using the following code:</p>

<pre><code>import geopandas as gpd
import matplotlib.pyplot as plt
us = gpd.read_file(r'C:\Users\ASUS\Desktop\Python code\Covid\USA_States.shp')
fig = plt.figure()
ax1 = fig.add_subplot(111)
us.plot(ax = ax1, cmap = 'jet' )
</code></pre>

<p>under which attribute of <code>ax1</code> is the geopandas plot stored in. For example, when we plot 2D lines, it is stored in <code>ax1.lines</code>, and we can remove a 2d plot, for example, using <code>ax1.lines.remove(ax1.lines[1])</code>. However I can't find where a geopandas plot is stored in the attributes of ax1 to delete it. Where is the geopandas plot stored and how can we delete it?</p>
"
60964656,"<p>Good morning,
As a school project I have to do a python script that will export data from an online csv file and then use the data from only my country (Lebanon) to make line graphs and other type of graphics about the spread of COVID-19. I have sorted out how to make the graphics but I am having problems with getting the data out of the csv file.</p>

<p>This is my code:</p>

<pre><code>from pandas import set_option, read_csv

inp_file=read_csv(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_co\
vid_19_time_series/time_series_covid19_confirmed_global.csv"")
set_option(""display.max_rows"", 999)
out_file=inp_file.transpose()

write_to_out_file=open(""/Users/bechara/Desktop/projects/python/data_corona2.csv"", ""w"")
write_to_out_file.write(str(out_file[147]))
write_to_out_file.close()

df=read_csv(""/Users/bechara/Desktop/projects/python/data_corona2.csv"", error_bad_lines=False)
a=df.values
write_to_out_file2=open(""/Users/bechara/Desktop/projects/python/data_corona3.csv"", ""w"")
write_to_out_file2.write(str(a))
write_to_out_file2.close()
</code></pre>

<p>The file I am taking from the internet is <a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">here</a>.  </p>

<p>The output I was expecting was to get the numbers only like so:  </p>

<pre><code>0
0
0
(67 other lines)
438
446
470
</code></pre>

<p>The problems I am having is in data_corona2.csv I am getting alongside the numbers dates and unwanted information (latitude, longitude, etc.) and in data_corona3.csv I am also getting some unwanted information.  </p>

<p>Is there a way I can get my expected output?</p>

<p>Thank you.</p>
"
60843080,"<p>I have a Pandas Series that contains the price evolution of a product (my country has high inflation), or say, the amount of coronavirus infected people in a certain country. The values in both of these datasets grows exponentially; that means that if you had something like [3, NaN, 27] you'd want to interpolate so that the missing value is filled with 9 in this case. I checked the interpolation method in the Pandas documentation but unless I missed something, I didn't find anything about this type of interpolation. </p>

<p>I can do it manually, you just take the geometric mean, or in the case of more values, get the average growth rate by doing (final value/initial value)^(1/distance between them) and then multiply accordingly. But there's a lot of values to fill in in my Series, so how do I do this automatically? I guess I'm missing something since this seems to be something very basic.</p>

<p>Thank you.</p>
"
60499437,"<p>I am trying to save Google Trend's widget that outputs a line graph, map, etc. as an image using Python. The URL I am using has only one widget on the page, and I would like to save it as a static image. I want to save this image based on the size of the widget; I do not want to screenshot the page and crop this image. Could someone assist with this please? BS4 is not picking up any widgets when I search for them. I know that I haven't added any steps to save the widget because I haven't found it yet. The URL and code is below:</p>

<p><a href=""https://trends.google.com/trends/embed/explore/TIMESERIES?req=%7B%22comparisonItem%22%3A%5B%7B%22keyword%22%3A%22Coronavirus%22%2C%22geo%22%3A%22%22%2C%22time%22%3A%222020-01-15%202020-03-02%22%7D%5D%2C%22category%22%3A0%2C%22property%22%3A%22%22%7D&amp;tz=300&amp;forceMobileMode=false&amp;isPreviewMode=true&amp;eq=date%3D2020-01-15%25202020-03-02%26q%3DCoronavirus&amp;hl=enUS"" rel=""nofollow noreferrer"">https://trends.google.com/trends/embed/explore/TIMESERIES?req=%7B%22comparisonItem%22%3A%5B%7B%22keyword%22%3A%22Coronavirus%22%2C%22geo%22%3A%22%22%2C%22time%22%3A%222020-01-15%202020-03-02%22%7D%5D%2C%22category%22%3A0%2C%22property%22%3A%22%22%7D&amp;tz=300&amp;forceMobileMode=false&amp;isPreviewMode=true&amp;eq=date%3D2020-01-15%25202020-03-02%26q%3DCoronavirus&amp;hl=enUS</a></p>

<pre><code>import datetime
import requests
import warnings
from urllib3.exceptions import InsecureRequestWarning
from bs4 import BeautifulSoup 
from [redacted] import SETTINGS


d = datetime.date.today()
current_month = f""{d.month:02d}""
current_day = f""{d.day:02d}""

URL1 = 'https://trends.google.com/trends/embed/explore/TIMESERIES?req=%7B%22comparisonItem%22%3A%5B%7B%22keyword%22%3A%22Coronavirus%22%2C%22geo%22%3A%22%22%2C%22time%22%3A%222020-01-15%202020-'
URL2 = str(current_month)+""-""+str(current_day)
URL3 = '%22%7D%5D%2C%22category%22%3A0%2C%22property%22%3A%22%22%7D&amp;tz=300&amp;forceMobileMode=false&amp;isPreviewMode=true&amp;eq=date%3D2020-01-15%25202020-'
URL4 = URL2
URL5 = '%26q%3DCoronavirus&amp;hl=enUS'

URL = URL1 + URL2 + URL3 + URL4 + URL5
print(URL)


def get_widget():
    #gets rid of request errors
    warnings.filterwarnings('ignore', message='Unverified HTTPS request')
    warnings.simplefilter('ignore',InsecureRequestWarning)
    #from internal core 
    proxies=SETTINGS['proxies']    
    resp = requests.get(URL, proxies=proxies, verify=False)
    html = resp.text
    #finds widgets
    soup = BeautifulSoup(html,'lxml')
    tags = soup.findAll(""h2"", {""class"": ""embed-logo""})
    for tag in tags:
        print(tag.getText())
    #another attempt to find the widgets
    widgets = soup.find_all('trends-wrapper ng-scope')
    number_of_widgets = len(widgets)
    print('Number of widgets: ' + str(number_of_widgets))

get_widget()
</code></pre>
"
60893903,"<p>I'm trying to find out what names of list are in a news text.</p>

<p>I have a big text file (around 100MB) with many place names. Each name is a line in the file.</p>

<p>Part of the file.</p>

<pre><code>Brasiel
Brasier Gap
Brasier Tank
Brasiilia
Brasil
Brasil Colonial
</code></pre>

<p>and the news texts are like this:</p>

<pre><code>""It's thought the couple may have contracted the Covid-19 virus in the US or while travelling to Australia, according to Queensland Health officials.
Hanks is not the only celebrity to have tested positive for the virus. British actor Idris Elba also revealed last week he had tested positive.""
</code></pre>

<p>For instance, in this text the strings Australia and Queensland should be founded.
I'm using the NLTK library and creating ngrams from the news.</p>

<p>To do this, I'm doing this:</p>

<pre><code>from nltk.util import ngrams

# readings the place name file
file = open(""top-ord.txt"", ""r"")
values = file.readlines()

news = ""It's thought the couple may have contracted the Covid-19 virus in the US or while travelling to Australia, according to Queensland Health officials.""

# ngrams_list is all ngrams from the news
for item in ngrams_list:
    if item in values:
        print(item)

</code></pre>

<p>This is too slow. How can I improve it?</p>
"
61173095,"<p>using data from this website: <a href=""https://ourworldindata.org/grapher/total-daily-covid-deaths?tab=map"" rel=""nofollow noreferrer"">https://ourworldindata.org/grapher/total-daily-covid-deaths?tab=map</a></p>

<p>I am trying to interact with the link 'total-daily-covid-deaths.csv' which has the href link 'blob:<a href=""https://ourworldindata.org/b1c6f69e-4df4-4458-8aa0-35173733b364"" rel=""nofollow noreferrer"">https://ourworldindata.org/b1c6f69e-4df4-4458-8aa0-35173733b364</a>'. After clicking on the link I am taken to a page with a lot of data and I am merely trying to write a python script to take that data and put it into a csv file for me to use. While researching this I found that there was an overwhelming amount of information and I got confused very quickly. I have experience web scraping using beautiful soup and requests however I haven't been able to get it working since the blob link isn't an actual website. I was hoping someone could shed some light for me and point me in the right direction.</p>

<p>This is the code I'm using:</p>

<pre><code>import urllib.request as request

url = 'https://ourworldindata.org/grapher/total-daily-covid-deaths?tab=map'
# fake user agent of Safari
fake_useragent = 'Mozilla/5.0 (iPad; CPU OS 6_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10A5355d Safari/8536.25'
r = request.Request(url, headers={'User-Agent': fake_useragent})
f = request.urlopen(r)

# print or write
print(f.read())
</code></pre>
"
60745445,"<p>i implemented the SIR model with Python, and the result seems correct:</p>

<pre><code>import scipy.integrate
import numpy
import matplotlib.pyplot as plt

def SIR_model(y,t,N,beta,gamma):
    S,I,R=y
    dS_dt=-beta*S*I/N
    dI_dt=beta*S*I/N-gamma*I
    dR_dt=gamma*I
    return([dS_dt,dI_dt,dR_dt])

N=1000
I0=1
R0=0.0
S0=N-I0-R0
beta=0.2
gamma=0.1

t=numpy.linspace(0,160,160)

sol=scipy.integrate.odeint(SIR_model,[S0,I0,R0],t,args=(N, beta,gamma))
sol=numpy.array(sol)

plt.figure(figsize=[6,4])
plt.plot(t,sol[:,0],label=""S(t)"")
plt.plot(t,sol[:,1],label=""I(t)"")
plt.plot(t,sol[:,2],label=""R(t)"")
plt.grid()
plt.legend()
plt.xlabel(""Time"")
plt.ylabel(""Number"")
plt.title(""SIR model"")
plt.show()
</code></pre>

<p>Now i want to fit real data with the model ( <a href=""https://github.com/pcm-dpc/COVID-19"" rel=""nofollow noreferrer"">https://github.com/pcm-dpc/COVID-19</a> ). I know <code>N0</code>, <code>S0</code>, <code>I0</code>, <code>R0</code>, and i need to find the best values for <code>beta</code> and <code>gamma</code>. In my previous projects i fitted data on well defined functions (i knew the analytical expression), but now i don't know how to do that with the results of the integrated system. I usually use the Numpy <code>curve_fit</code> function:</p>

<pre><code>popt, pcov = curve_fit(f, x_list, y_list, sigma=y_err)
</code></pre>

<p>What is the best approach to do this? There was a nice project on github few days ago, but now the author deleted it.</p>
"
61153105,"<p>I'm trying to do some exploratory data analysis on the data that is provided by CSSE at Johns Hopkins University. They have it on Github at this link <a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_daily_reports</a>
I'm trying to download the entire file using python that will save it to my current directory. That way I'll have all the up to date, data and can reload it to use. I'm using two functions <code>fetch_covid_daily_data()</code> that will go to the website and download all the CSV files. Then ill have a <code>load_covid_daily_data()</code> that will go in the current repo and read the data so I can process it with pandas. </p>

<p>I'm doing this way because if I go back to my code I can call the function <code>fetch_covid_daily_data()</code> and it will download all the new changes made such as another daily CSV added.</p>
"
61212937,"<p>I wrote a script for modeling the evolution of a pandemic (with graphs and scatter plots).
I tried several libraries to display results in real-time (8 countries x 500 particles):</p>

<ul>
<li>Matplotlib (not fast enough) </li>
<li>PyQtGraph (better but still not fast enough)</li>
<li>OpenGL (good, but I did not find how to use it in 2D efficiently, using subplots, titles, legends...)</li>
<li>Bokeh (good, but the scatter plots ""blink"" each time their particles turn color. Code is <a href=""https://github.com/Skryge/epidemic-simulation/blob/master/attempts/Pandemic_simulation_Bokeh.py"" rel=""nofollow noreferrer"">here</a> if you are interested)</li>
</ul>

<p>That is why I am turning now to VisPy.</p>

<p>I am using a class <code>Visualizer</code> to display the results, with the method <code>app.Timer().connect</code> to manage the real-time side. <code>Pandemic</code> code is <a href=""https://github.com/Skryge/epidemic-simulation/blob/master/final-project/normal/Pandemic.py"" rel=""nofollow noreferrer"">here</a>.</p>

<pre><code>from Pandemic import *
from vispy.plot import Fig
from vispy import app

class Visualizer:
    def __init__(self, world):
        self.fig = Fig()
        self.world = world
        self.traces = {}

        #Scatter plots
        for idx, c in world.countries.items():
            pos_x = idx % self.world.nb_cols
            pos_y = idx // self.world.nb_cols
            subplot = self.fig[pos_y, pos_x]
            data = np.array([c.x_coord, c.y_coord]).reshape(-1,2)
            self.traces[idx] = subplot.plot(data, symbol='o', width=0, face_color=c.p_colors, title='Country {}'.format(idx+1))

    def display(self): 
        for idx, c in self.world.countries.items():
            data = np.array([c.x_coord, c.y_coord]).reshape(-1,2)
            self.traces[idx].set_data(data, face_color=c.p_colors)

    def update(self, event):
        self.world.update(quarantine=False)
        self.display()

    def animation(self):
        self.timer = app.Timer()
        self.timer.connect(self.update)
        self.timer.start(0)
        self.start()

    def start(self):
        if (sys.flags.interactive != 1):
            self.status = app.run()


if __name__ == '__main__':
    w = World(move=0.001)
    for i in range(8):
        w.add_country(nb_S=500)
    v = Visualizer(w)
    v.animation()
</code></pre>

<p>The scatter plots ""blink"" each time their particles turn color, as with Bokeh. Am I doing something wrong? </p>

<p>Is there a more efficient way for real-time display, maybe using vispy.gloo or vispy.scene? (It is slower than pyqtgraph.opengl for the moment)</p>
"
61673618,"<p>I want to fetch some data from api but it takes longer time to fetch data from url.</p>

<pre><code>import json
import urllib.request
from datetime import datetime
def home():
    print(datetime.now())
    total=urllib.request.urlopen('https://api.covid19api.com/summary')
    total.encoding='UTF-8'
    data=json.loads(total.read())
    Total=data['Global']['TotalConfirmed']
    print(datetime.now())

home()
</code></pre>

<p>output</p>

<pre><code>2020-05-08 12:12:24.715765
2020-05-08 12:12:53.998154
</code></pre>
"
60972036,"<p>I am having a Python script that pulls data from a third party API.</p>

<p>Below is the part of code that runs the post command on the API.</p>

<pre><code>data = json.dumps({""filters"": [""(headline:coronavirus OR summary:coronavirus OR headline:covid-19 OR summary:covid-19) AND categories:164""], ""sort_by"":""created_at"", ""size"":5000})

type(data)

r = requests.post(url = api_endpoint, data = data).json()
</code></pre>

<p>In above filters the ""categories"" number depicts city code for example 164 belongs to Atlanta. I have total 50 cities with different category numbers to run. </p>

<p>Currently I am running line of code  50 times by changing the category number to each city. Is there a better way to run this in one script run instead of 50 times? </p>

<p>That category number is not a serial numbers, each city has been assigned random numbers.</p>
"
60921585,"<p>I have recently starting at react js and trying my first demo website in react js which gets json data from <a href=""https://covid19.mathdro.id"" rel=""nofollow noreferrer"">https://covid19.mathdro.id</a> website.
for the simple case where json has single value such as confirmed cases, deaths etc, i am pulling and works fine. however when i am trying to pull countries data, i am having issue in mapping through the array of data.  <b>My Landing Page snipest</b><br></p>

<pre><code>import React, { Component } from 'react';

import Country from './Country'
import Cases from './Cases';

class Landing_Page extends Component{
render(){
    return(
        &lt;&gt;
        &lt;Cases /&gt;
        &lt;Country /&gt;
        &lt;/&gt;
    );
}
}
export default Landing_Page;
</code></pre>

<p>and here is my <b>Country</b> component</p>

<pre><code>import React, { Component } from 'react';
import Axios from 'axios'
import 'antd/dist/antd.css'

class Country extends Component{
state=[
{
  country_name:""USA"",
  country_code:""US""
},
]

componentDidMount(){
this.getCountries();
}
async getCountries(){
const res=await Axios.get('https://covid19.mathdro.id/api/countries');
console.log(res);
this.setState({
  country_name:res.data.countries.name,
  country_code:res.data.countries.code
});
}
render(){
return(
&lt;div&gt;
  {
    this.state.map(() =&gt; { 

    &lt;li key={country_code} className={country_code}&gt;{country_name}&lt;/li&gt;
    })
  }
&lt;/div&gt;
)
}
}
export default Country;
</code></pre>

<p>and here is the api link 
<a href=""https://covid19.mathdro.id/api/countries"" rel=""nofollow noreferrer"">https://covid19.mathdro.id/api/countries</a></p>

<pre><code>{
""countries"":
[
{""name"":""Afghanistan"",""iso2"":""AF"",""iso3"":""AFG""},
{""name"":""Albania"",""iso2"":""AL"",""iso3"":""ALB""},
{""name"":""Algeria"",""iso2"":""DZ"",""iso3"":""DZA""},
{""name"":""Andorra"",""iso2"":""AD"",""iso3"":""AND""},
{""name"":""Angola"",""iso2"":""AO"",""iso3"":""AGO""},
{""name"":""Antigua and Barbuda"",""iso2"":""AG"",""iso3"":""ATG""}, 
{""name"":""Argentina"",""iso2"":""AR"",""iso3"":""ARG""},
{""name"":""Armenia"",""iso2"":""AM"",""iso3"":""ARM""},
{""name"":""Australia"",""iso2"":""AU"",""iso3"":""AUS""},
{""name"":""Austria"",""iso2"":""AT"",""iso3"":""AUT""},
{""name"":""Azerbaijan"",""iso2"":""AZ"",""iso3"":""AZE""},
{""name"":""Bahamas"",""iso2"":""BS"",""iso3"":""BHS""},
{""name"":""Bahrain"",""iso2"":""BH"",""iso3"":""BHR""},
{""name"":""Bangladesh"",""iso2"":""BD"",""iso3"":""BGD""},
{""name"":""Barbados"",""iso2"":""BB"",""iso3"":""BRB""},
{""name"":""Belarus"",""iso2"":""BY"",""iso3"":""BLR""},
{""name"":""Belgium"",""iso2"":""BE"",""iso3"":""BEL""},
{""name"":""Belize"",""iso2"":""BZ"",""iso3"":""BLZ""},
{""name"":""Benin"",""iso2"":""BJ"",""iso3"":""BEN""},
{""name"":""Bhutan"",""iso2"":""BT"",""iso3"":""BTN""},
{""name"":""Bolivia"",""iso2"":""BO"",""iso3"":""BOL""},
{""name"":""Bosnia and Herzegovina"",""iso2"":""BA"",""iso3"":""BIH""}, 
{""name"":""Brazil"",""iso2"":""BR"",""iso3"":""BRA""},
{""name"":""Brunei"",""iso2"":""BN"",""iso3"":""BRN""},
{""name"":""Bulgaria"",""iso2"":""BG"",""iso3"":""BGR""},
{""name"":""Burkina Faso"",""iso2"":""BF"",""iso3"":""BFA""},
{""name"":""Burma""},{""name"":""Cabo Verde""},
{""name"":""Cambodia"",""iso2"":""KH"",""iso3"":""KHM""},
{""name"":""Cameroon"",""iso2"":""CM"",""iso3"":""CMR""},
{""name"":""Canada"",""iso2"":""CA"",""iso3"":""CAN""},
{""name"":""Central African Republic"",""iso2"":""CF"",""iso3"":""CAF""}, 
{""name"":""Chad"",""iso2"":""TD"",""iso3"":""TCD""},
{""name"":""Chile"",""iso2"":""CL"",""iso3"":""CHL""},
{""name"":""China"",""iso2"":""CN"",""iso3"":""CHN""},
{""name"":""Colombia"",""iso2"":""CO"",""iso3"":""COL""},
{""name"":""Congo (Brazzaville)""},
{""name"":""Congo (Kinshasa)""},
{""name"":""Costa Rica"",""iso2"":""CR"",""iso3"":""CRI""},
{""name"":""Cote d'Ivoire""},
{""name"":""Croatia"",""iso2"":""HR"",""iso3"":""HRV""},
{""name"":""Cuba"",""iso2"":""CU"",""iso3"":""CUB""},
{""name"":""Cyprus"",""iso2"":""CY"",""iso3"":""CYP""},
{""name"":""Czechia"",""iso2"":""CZ"",""iso3"":""CZE""},
{""name"":""Denmark"",""iso2"":""DK"",""iso3"":""DNK""},
{""name"":""Diamond Princess""},
{""name"":""Djibouti"",""iso2"":""DJ"",""iso3"":""DJI""},
{""name"":""Dominica"",""iso2"":""DM"",""iso3"":""DMA""},
{""name"":""Dominican Republic"",""iso2"":""DO"",""iso3"":""DOM""}, 
{""name"":""Ecuador"",""iso2"":""EC"",""iso3"":""ECU""},
{""name"":""Egypt"",""iso2"":""EG"",""iso3"":""EGY""},
{""name"":""El Salvador"",""iso2"":""SV"",""iso3"":""SLV""},
{""name"":""Equatorial Guinea"",""iso2"":""GQ"",""iso3"":""GNQ""}, 
{""name"":""Eritrea"",""iso2"":""ER"",""iso3"":""ERI""},
</code></pre>

<p>and the list goes on. </p>

<p>I would much appreciate a solution to parsing/mapping above json. Thanks in advance </p>

<p>
<b>Error Screenshot </b></p>

<p><a href=""https://i.stack.imgur.com/Jud9D.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Jud9D.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/j9J88.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/j9J88.png"" alt=""enter image description here""></a></p>

<p>Here is my update code and snapshot</p>

<p><a href=""https://i.stack.imgur.com/RNskM.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RNskM.png"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/dnpag.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/dnpag.png"" alt=""enter image description here""></a></p>
"
61138605,"<p>This is the first time i'm using PapaParse. I'm trying to parse a remote CSV file, which works fine and store data, which is displaying in console.log but when i try to output with v-for loop. It's not working.</p>

<p>I'm using <a href=""https://www.npmjs.com/package/vue-papa-parse"" rel=""nofollow noreferrer"">vue-papa-parse</a> library.</p>

<p>Here is my code.</p>

<pre><code>&lt;template&gt;
    &lt;div class=""uk-section""&gt;
        &lt;div class=""uk-container""&gt;
            &lt;ul v-if=""cases""&gt;
                &lt;li v-for=""(item, index) in cases"" :key=""index""&gt;{{item.date}} / {{item.World}}&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/template&gt;
&lt;script&gt;
export default {
    data() {
        return {
            cases: [],
        }
    },
    methods: {
        totalCases(){
            let url = ""https://covid.ourworldindata.org/data/ecdc/total_cases.csv"";
            this.$papa.parse(url, {
                header: true,
                download: true,
                dynamicTyping: true,
                complete: function(results) {
                    this.cases = results.data;
                    console.log(this.cases);
                }
            })
        }
    },
    mounted() {
        this.totalCases();        
    }
}
&lt;/script&gt;
</code></pre>

<p><a href=""https://i.stack.imgur.com/pmErZ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pmErZ.png"" alt=""console.log screenshot""></a></p>

<p>No errors. I'm stuck here. Not sure what am i doing wrong. Would appreciate any help. Thanks.</p>
"
60733131,"<p>I am very new to JAVASCRIPT so please forgive me if this is a basic question.</p>

<p>I am making a very simple api call:</p>

<pre><code>  const getWorldTotal = async () =&gt; {
        const response = await fetch('https://health-api.com/api/v1/covid-19/total');
        const myJson = await response.json();
        console.log(myJson)
      }
      getWorldTotal();
</code></pre>

<p>I keep getting an error saying:</p>

<pre><code>Access to fetch at 'https://health-api.com/api/v1/covid-19/total' from origin 'null' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource. If an opaque response serves your needs, set the request's mode to 'no-cors' to fetch the resource with CORS disabled.
</code></pre>

<p>So then I did the following:</p>

<pre><code>  const getWorldTotal = async () =&gt; {
        const response = await fetch('https://health-api.com/api/v1/covid-19/total',{
          mode: 'no-cors'
        });
        const myJson = await response.json();
        console.log(myJson)
      }
      getWorldTotal();
</code></pre>

<p>But I still get the following error:</p>

<pre><code>Uncaught (in promise) SyntaxError: Unexpected end of input
    at getWorldTotal on line 42
</code></pre>

<p>line 42 is the following         <code>const myJson = await response.json();</code></p>

<p>I am not sure what I did wrong?</p>
"
61477210,"<p>I am fairly new to web scraping with no developer background and was curious about this page: <a href=""https://www.theguardian.com/world/ng-interactive/2020/apr/27/the-traffic-data-that-shows-the-road-into-and-out-of-covid-19-lockdown"" rel=""nofollow noreferrer"">https://www.theguardian.com/world/ng-interactive/2020/apr/27/the-traffic-data-that-shows-the-road-into-and-out-of-covid-19-lockdown</a></p>

<p>It seems to have some Tomtom data in the backend that is loading some preset cities, but also provides a box to search of the db to generate a similar chart. I was wondering how one would gather this data? The link to Tommy page in the article only shows last 7 days, but this page has a 2019 reference too, hence my interest.</p>

<p>Would appreciate some ideas or guidance on how to go about it. Thanks!</p>

<p>Rob</p>
"
61066250,"<p>I would like to make a doughnut chart of the number of positively tested persons on Coronavirus and the number of deaths related to coronavirus, how do I get the same numbers as in the top container into the chart? So confirmedCases and deaths need to be put into the doughnut chart. </p>

<p>Thanks a lot. I am sorry for asking so many questions, but I learned a lot from your answers and I am slowly progressing, but I am still a beginner at all of this.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>let tId;
window.addEventListener(""load"", function() {
  document.getElementById(""countrySel"").addEventListener(""change"", getCovidStats);
  document.getElementById(""countrySel"").value = ""169"";
  getCovidStats()
})

// Zorgt voor de optel annimatie
function countUp() {
  cnt += 100;
  let done = 0;
  let iMax = +document.getElementById('inwoners').getAttribute(""max"");
  if (cnt &lt; iMax) document.getElementById('inwoners').innerText = cnt.toLocaleString('en');
  else done++
    let pMax = +document.getElementById('patienten').getAttribute(""max"");
  if (cnt &lt; pMax) document.getElementById('patienten').innerText = cnt.toLocaleString('en');
  else done++
    let dMax = +document.getElementById('doden').getAttribute(""max"");
  if (cnt &lt; dMax) document.getElementById('doden').innerText = cnt.toLocaleString('en');
  else done++



    document.getElementById('procent').innerHTML = ((Number(document.getElementById('doden').innerText.replace(/\D/g, """")) / Number(document.getElementById('patienten').innerText.replace(/\D/g, """"))) * 100).toLocaleString(""en"", {
      minimumFractionDigits: 2, // Minimum aantal getallen achter comma
      maximumFractionDigits: 2 // Maximum aantal getallen achter comma
    }) + ""%""; // Zet een procent teken achter het getal
  if (done === 3) clearInterval(tId); 
}


function getCovidStats() {
  const cc = document.getElementById(""countrySel"").value; // Gekozen nummer van het land
  if (cc === """") return; // Als er een land gekozen is voer dan uit

  fetch('https://coronavirus-tracker-api.herokuapp.com/v2/locations/' + cc) // De database met gegevens van landen, CC is de country value die in de selector als waarde staat.
    .then(function(resp) {
      return resp.json()
    })
    .then(function(data) {
      let population = data.location.country_population; // Inwoners van het land gekozen in de selector
      let update = data.location.last_updated; // Laatste update van de data
      let confirmedCases = data.location.latest.confirmed; // Aantal geregistreerde geinfecteerden in het gekozen land
      let deaths = data.location.latest.deaths; // Aantal doden in het gekozen land

      document.getElementById('inwoners').innerText = population.toLocaleString('en'); // Inwoneraantal van het land
      document.getElementById('update').innerText = update.substr(0, 10);
      document.getElementById('patienten').innerText = // Aantal geregistreerde geinfecteerden
      document.getElementById('patienten').setAttribute(""max"", confirmedCases) 
      document.getElementById('doden').innerText = 0; // Aantal doden
      document.getElementById('doden').setAttribute(""max"", deaths)  
      document.getElementById('procent').innerText = 0 + ""%"" // Percentage overleden mensen van het aantal besmette mensen
      cnt = 0;
      tId = setInterval(countUp, 0.0001); // Snelheid van de counter

      document.getElementById('preciezeAantal').innerText= confirmedCases;  // Dit laat het niet afgeronde aantal besmettingen voor het geselecteerde land zien
      tId = setInterval(countUp, 1500); 
    })
    .catch(function() {
      console.log(""error"");
    })
  setInterval(getCovidStats, 43200000) // Zorgt ervoor dat de data om de 12 uur wordt geupdated
}</code></pre>
<pre class=""snippet-code-css lang-css prettyprint-override""><code>* {
	margin: 0;
	padding: 0;
}

html {
	height: 100%;
	width: 100%;
}
h1, h2 {
	font-family: 'Roboto', sans-serif;
	font-weight: 300;
	text-align: center;
	padding-bottom: 20px;
	font-size: 250%;
}

.subtitle, .over {
	padding: 20px;
	font-size: 150%;
}

body {
	background-color: #FFDC56;
	}

div {
	padding: 20px;
}

/* Add a black background color to the top navigation */
.topnav {
	background-color: #005A9C;
	overflow: hidden;
	font-family: 'Roboto', sans-serif;
	font-size: 75%;
	}

	.logo {
		float: left;
	}

	/* Style the links inside the navigation bar */
	.topnav a {
	float: right;
	color: #f2f2f2;
	text-align: center;
	padding: 14px 16px;
	text-decoration: none;
	font-size: 17px;
	}
	
	/* Change the color of links on hover */
	.topnav a:hover {
	background-color: #FFDC56;
	color: black;
	}
	
	/* Add a color to the active/current link */
	.topnav a.active {
	background-color: #4CAF50;
	color: white;
	}

.stats-container {
	text-align: center;
	float: right;
	display: inline-block;
}
.location-container {
	display: inline-block;
}
.data-container {
	border: 2px solid #005A9C;
	margin-right: 30%;
	margin-left: 30%;
}

h4, {
	font-size: 85%;
 	color: gray;
 	font-family: 'Roboto', sans-serif;
 	font-weight: 300;
 	text-align: center;
 	padding-top: 20px;
 	padding-left: 20px;
 	padding-right: 20px;
 	padding-bottom: 5px;
}

.over {
	font-family: 'Roboto', sans-serif;
	font-size: 100%;
	text-align: center;
}

.footer {
	font-family: 'Roboto', sans-serif;
	bottom: 0;
	font-size: 75%;
	padding: 5px;
}


.maatregelen {
	width: 35%;
	display: block;
	margin-left: auto;
	margin-right: auto;
	text-align: center;

}

.maatregelen-caption {
	text-align: center;
	font-family: 'Roboto', sans-serif;
	font-size: 80%;
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
	&lt;title&gt;Coronavirus Statistieken&lt;/title&gt;  
	&lt;meta charset=""UTF-8""&gt;
	&lt;link rel=""shortcut icon"" href=""masker-emoji.png""&gt;
	&lt;link href=""https://fonts.googleapis.com/css?family=Roboto:100,300,400&amp;display=swap"" rel=""stylesheet""&gt;
	&lt;link rel=""stylesheet"" type=""text/css"" href=""styles.css""&gt;
	&lt;script src=""app.js""&gt;&lt;/script&gt;
	&lt;script src=""chart.js""&gt;&lt;/script&gt;
	&lt;script src=""https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.3/Chart.min.js""&gt;&lt;/script&gt;

&lt;/head&gt;
&lt;body&gt;
	&lt;div class=""topnav""&gt;
		&lt;h1 class= ""logo""&gt;Coronavirus&lt;/h1&gt; 
		&lt;a href=""over.html""&gt;Over&lt;/a&gt;
		&lt;a class=""active"" href=""index.html""&gt;STATS&lt;/a&gt;
	  &lt;/div&gt;

	&lt;h2 class=""subtitle""&gt;TITLE&lt;/h2&gt;
	&lt;div class=""data-container""&gt;
		&lt;div class=""stats-container""&gt;
			&lt;h4&gt;TESTED POSITIVE&lt;/h4&gt;
			&lt;h1 id=""patienten""&gt;&lt;/h1&gt;
			&lt;h4&gt;DEATHS&lt;/h4&gt;
			&lt;h1 id=""doden""&gt;&lt;/h1&gt;
			&lt;h4&gt;Percentage deaths of patients&lt;/h4&gt;
			&lt;h1 id=""procent""&gt;&lt;/h1&gt;
		&lt;/div&gt;
		&lt;div class=""location-container""&gt;
			&lt;h4&gt;Land&lt;/h4&gt;
			&lt;h1 id=""country""&gt;&lt;label for=""countrySel""&gt;Country:&lt;/label&gt;
				&lt;select id=""countrySel""&gt;
				  &lt;option value=""169""&gt;🇳🇱 &lt;/option&gt;
				  &lt;option value=""120""&gt;🇩🇪 &lt;/option&gt;
				  &lt;option value=""116""&gt;🇫🇷 &lt;/option&gt;
				  &lt;option value=""201""&gt;🇪🇸 &lt;/option&gt;
				  &lt;option value=""137""&gt;🇮🇹 &lt;/option&gt;
				  &lt;option value=""187""&gt;🇷🇺 &lt;/option&gt;
				  &lt;option value=""143""&gt;🇰🇷 &lt;/option&gt;
				  &lt;option value=""225""&gt;🇺🇸 &lt;/option&gt;
				&lt;/select&gt;
			  &lt;/h1&gt;
			&lt;h4&gt;Population&lt;/h4&gt;
			&lt;h1 id=""inwoners""&gt;&lt;/h1&gt;
			&lt;h4&gt;Last update&lt;/h4&gt;
			&lt;h1 id=""update""&gt;&lt;/h1&gt;
		&lt;/div&gt;		
	&lt;/div&gt;
	&lt;h1&gt;test:&lt;/h1&gt;&lt;h1 id=""preciezeAantal""&gt;&lt;/h1&gt;
	&lt;canvas id=""doughnut-chart""&gt;&lt;/canvas&gt;
	&lt;script&gt;
		// Bar chart 
new Chart(document.getElementById(""doughnut-chart""), {
  type: 'doughnut',
  data: {
    labels: [""Deaths"",""Tested positive to Coronavirus""],
    datasets: [
      {
        label: ""."",
        backgroundColor: [""#3e95cd"", ""#8e5ea2"",""#3cba9f"",""#e8c3b9"",""#c45850"",""#3e95cd"", ""#8e5ea2"",""#3cba9f""],
        data: [100,200]
      }
    ]
  },
  options: {
    legend: { display: false },
    title: {
      display: true,
      text: 'Aantal besmettingen per land'
    }
  }
});
	&lt;/script&gt;
	&lt;h1 class=""footer""&gt;Footer&lt;/a&gt;&lt;/h1&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
</div>
</p>
"
61483109,"<p>I'm a bit new to technology. </p>

<p>i""m trying to build a dashboard. But when I pass the attribute id to the cards. it's not displaying the values. </p>

<p>Sometimes I'm only getting value for the 1st card only. do I have to add additional div? or any other ways?</p>

<p>how to resolve these?.</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-js lang-js prettyprint-override""><code>window.onload = function() {
	getCovidStats();
}

function getCovidStats() {
	fetch('https://coronavirus-tracker-api.herokuapp.com/v2/locations/225')
	.then(function(resp) { return resp.json() })
	.then(function(data) {
		let population = data.location.country_population;
		let update = data.location.last_updated;
		let confirmedCases = data.location.latest.confirmed;
		let deaths = data.location.latest.deaths;

		document.getElementById('population').innerHTML = population.toLocaleString('en');
		document.getElementById('update').innerHTML = update.substr(0, 10);
		document.getElementById('cases').innerHTML = confirmedCases.toLocaleString('en');
		document.getElementById('deaths').innerHTML = deaths.toLocaleString('en');
		document.getElementById('percent').innerHTML = ((Number(deaths)/Number(confirmedCases))*100).toLocaleString(""en"", {minimumFractionDigits: 2, maximumFractionDigits: 2}) + ""%"";




	})
	.catch(function() {
		console.log(""error"");
	})
	setTimeout(getCovidStats, 43200000) // update every 12 hours
}</code></pre>
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;

&lt;head&gt;
    &lt;meta name=""viewport"" content=""width=device-width, initial-scale=1""&gt;
    &lt;style&gt;* {box-sizing: border-box;
        }

        body {
            font-family: Arial, Helvetica, sans-serif;
        }
        
         h1{
            font-size: smaller;
        }

        /* Float four columns side by side */
        .column {
            float: left;
            width: 25%;
            padding: 0 10px;
        }

        /* Remove extra left and right margins, due to padding */
        .row {
            margin: 0 -5px;
        }

        /* Clear floats after the columns */
        .row:after {
            content: """";
            display: table;
            clear: both;
        }

        /* Responsive columns */
        @media screen and (max-width: 600px) {
            .column {
                width: 100%;
                display: block;
                margin-bottom: 20px;
            }
        }

        /* Style the counter cards */
        .card {
            box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2);
            padding: 16px;
            text-align: center;
            background-color: #f1f1f1;
        }
    &lt;/style&gt;
    &lt;script type=""text/javascript"" src=""app.js""&gt;&lt;/script&gt;
&lt;/head&gt;

&lt;body&gt;

    &lt;h2&gt;Responsive Column Cards&lt;/h2&gt;
    &lt;p&gt;Resize the browser window to see the effect.&lt;/p&gt;

    &lt;div class=""row""&gt;
        &lt;div class=""column""&gt;
            &lt;div class=""card""&gt;
                &lt;h3&gt;Card 1&lt;/h3&gt;

                &lt;h4&gt;Cases&lt;/h4&gt;
                &lt;h1 id=""population""&gt;&lt;/h1&gt;

            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class=""column""&gt;
            &lt;div class=""card""&gt;
                &lt;h3&gt;Card 2&lt;/h3&gt;
                &lt;h4&gt;Cases&lt;/h4&gt;
                &lt;h1 id=""cases""&gt;&lt;/h1&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class=""column""&gt;
            &lt;div class=""card""&gt;
                &lt;h3&gt;Card 3&lt;/h3&gt;
                &lt;h4&gt;Cases&lt;/h4&gt;
                &lt;h1 id=""deaths""&gt;&lt;/h1&gt;
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;div class=""column""&gt;
            &lt;div class=""card""&gt;
                &lt;h3&gt;Card 4&lt;/h3&gt;
                &lt;h4&gt;Cases&lt;/h4&gt;
                &lt;h1 id=""percent""&gt;&lt;/h1&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;

&lt;/body&gt;

&lt;/html&gt;</code></pre>
</div>
</div>
</p>

<p><a href=""https://i.stack.imgur.com/yG6To.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yG6To.png"" alt=""value missing""></a></p>

<p>above is how I'm getting. I need to display the values in the red boxed areas.</p>
"
61273496,"<p>I'm relatively new to Python and Stackoverflow so apologies if this question has already been asked but I've searched for quite a while now and can't really find a solution to what I'm trying to do. </p>

<p>Problem:</p>

<p>I've been trying to create a very basic model of the COVID-19 epidemic to familiarise myself with Python. My intention is to produce a basic SIR model that calculates susceptible, infected and removed individuals in a population. So far so good. </p>

<p>My problem is that I would like the plot to have an interactive slider that alters one of the constants in the differential equation. </p>

<p>I am using Bokeh and am trying to use Javascript Callbacks for this however I am having difficulty with the Javascript. All examples I have seen so far use line equations where y is a function of x, and which are relatively straightforward to code. In my case, since its a system of differential equations I'm not sure how I should be going about this. </p>

<p>I've also tried using scipy but I still encounter the same problem.  </p>

<p>Code below. Any help/feedback/suggestions would be greatly appreciated. </p>

<p>Thanks!</p>

<pre><code>from bokeh.layouts import column, row
from bokeh.models import CustomJS, Slider
from bokeh.plotting import ColumnDataSource, figure, output_file, show

t = []

for i in range(200):
    t.append(i)

slst = []
ilst = []
rlst = []

s = 489599/489609
i = 10/489609
r = 0/489609
bet = 0.28
gam = 0.189

for f in range(200):
    ds = (-bet * (s * i))
    di = ((bet * (s * i)) - (gam * i))
    dr = gam * i
    s = s + (ds)
    slst.append(s)
    i = i + (di)
    ilst.append(i)
    r = r + (dr)
    rlst.append(r)

source = ColumnDataSource(data=dict(x=t, y=[], s=slst, i=ilst))

plot = figure(plot_width=400, plot_height=400)
plot.line('x', 'y', source=source, line_width=3, line_alpha=0.6)

callback = CustomJS(args=dict(source=source), code=""""""

                    ????????????

    """""")

slider = Slider(start=0.1, end=4, value=1, step=.1, title=""Beta "")
slider.js_on_change('value', callback)

layout = column(slider, plot)

show(layout)
</code></pre>
"
61560012,"<p>As I used app.get to query in urls as localhost:3000/data?country=Italy and I get the data stored in MongoDb. How can I use app.post request method to query the parameters and get the data? I'm unable to find the proper solution and I'm completely new to this.</p>

<pre><code>const express = require(""express"");
const mongoose = require(""mongoose"");
const Schema = mongoose.Schema;
const url = ""mongodb://localhost:27017/source_scrapped_data"";
const app = express();
mongoose.connect(url, { useNewUrlParser: true });
// mongoose.Promise = global.Promise;
const db = mongoose.connection;
db.on('error', console.error.bind(console, 'connection error:'));
db.once('open', () =&gt; {
    console.log(""Connected to mongo"");
});
const covid_data = mongoose.model('Covid',
    new Schema({}),
    'covid_data');
app.get(""/data"", (req, res) =&gt; {
    const continent = req.query.continent;
    const country = req.query.country;
    covid_data.find({'Continent':continent,'Country':country},(err,docs)=&gt;{
        if(err){
            console.log(err)
            res.send(""no data found"",err)
        }
        else{
            console.log(err)
            res.send(docs)
        }
    });
});
module.exports = app;
</code></pre>
"
61193291,"<p>I'm trying to print the data from an axios request to a pug template. I'm having issues with access the data. I'm new to this and I think it has something to do with my data object being passed in to the route.</p>

<p>The Backend</p>

<pre><code>    axios.get(""https://www.worldometers.info/coronavirus/"")
        .then(res =&gt; {
            const data = [];
            const $ = cheerio.load(res.data);
            $('.maincounter-number').each((index, element) =&gt; {
                const numberData = $(element).text();
                data[0] = {numberData: numberData};
                //console.log(data);
            });
        }).catch(err =&gt; {
        console.log(""Error fetching and parsing data: "", err);
    });


app.get(""/"", (req, res) =&gt; {
    res.render('index', {title: 'Home', data: data});

});

</code></pre>

<p>The front end</p>

<pre><code>  p #{data.numberData}
</code></pre>
"
61619542,"<p>I'm a student and attending university lessons from home. My teacher just gave me this job, consisting to take all the titles and subtitles from an online italian journal that include the words ""coronavirus"" and / or ""covid 19"" in a certain time lapse (from 22th to 29th of January and just the 1st and the 8th of April), and transcribe them to an Excel file to analyze the words used.</p>

<p>I searched online and assumed that this could be considered scraping, and that made my day considering that I should find something like 100-150 titles plus subtitles and I have a very short deadline. Unfortunately, I am also a beginner at this and all I could do by myself was finding a way to collect just the title from the webpage. I'm using, like a beginner is supposed to, Data Miner with Google Chrome.</p>

<p>Practically I should find all titles and subtitles from the website ""La Gazzetta dello Sport"" (whose link I attach below) that contains the words ""coronavirus"" and/or ""covid 19"" but there is a problem: I can see just the titles in the search page, but to get the subtitles I should click on the article and go to another page. Is there a way to obtain all the results with Data Miner or should I use another program?</p>

<p>So, just to make it simple: I can't figure out how to make Data Miner collect the title from the search page, click it to go on the article page, collect the subtitle and go back to the search page to pass to the next title and subtitle and repeat. I don't know if this is possible or it's just sci-fi, like I said: I'm a total newbie at this and it's the first time using these kind of tools.</p>

<p>Url: <a href=""https://www.gazzetta.it/nuovaricerca/home.shtml?q=coronavirus&amp;dateFrom=2020-01-22&amp;dateTo=2020-01-29"" rel=""nofollow noreferrer"">https://www.gazzetta.it/nuovaricerca/home.shtml?q=coronavirus&amp;dateFrom=2020-01-22&amp;dateTo=2020-01-29</a></p>
"
72695,"<p>I am searching for trends and dataset in both .csv and api format to do predictive analysis on Coronavirus for various countries. What are good sources to browse such datasets?</p>
"
71554,"<p>im new in data sience and machine learning but i have some mathematical and statistics backgroud. I really just want some information about models (like papers or raw models). So if you have any information please share them with me.</p>

<p>thank you</p>
"
61245555,"<p>I want to display the table alone from the entire website. Many forums had suggested to use jsoup but I couldn't understand the working as I am a android newbie.</p>

<p>I also used webview but the entire website is coming. I want only a table.</p>

<p>The Url is <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a> and I want to display the table alone. Thanks</p>
"
60870354,"<p>im a little bit new at gnuplot and i want to plot the evolution of COVID-19 in my country with x axis showing days instead of numbers.</p>

<p>Here is my data</p>

<pre class=""lang-none prettyprint-override""><code>#mm/dd  , Infect
03/06   , 1
03/09   , 3
03/11   , 9 
03/13   , 16
03/15   , 24
03/16   , 45
03/17   , 57
03/18   , 75
03/19   , 102
03/20   , 128
03/21   , 158
03/22   , 235
03/23   , 306
03/24   , 378
03/25   , 470
</code></pre>

<p>and heres my sript</p>

<pre><code>set title 'COVID-19 En Colombia'
set ylabel 'Número de Personas'
set xlabel 'Día'
set xdata time
set timefmt '%m%d'
set format x '%m/%d'
set datafile sep ','
set key top left
set grid
set autoscale
set terminal png size 720,650
set output 'COVID19Col.png'
plot 'COVIDCol.dat' lt rgb 'red' w l title 'Infectados' using 1:3
</code></pre>

<p>but still telling me this</p>

<pre><code>gnuplot&gt; plot 'COVIDCol.dat' lt rgb 'red' w l title 'Infectados' using 1:3
         ""covid.gp"" line 25: Need full using spec for x time data 
</code></pre>

<p>I'd be very grateful for any help :3</p>
"
60723877,"<p><strong>I need to figure out the most streamlined way to email an existing mailing list in Mailchimp with a ""confirm/opt-in"" button in order to make sure a newsletter is GDPR compliant.</strong></p>

<p>Have a list of volunteers' email addresses, but because everything is being done by volunteers and put together quickly as we go for this project (combatting COVID-19), about half of the email addresses were collected WITHOUT a GDPR-compliant ""can we send you email"" opt-in button. So we have a list of emails that is partially compliant.</p>

<p>The plan is to send the first newsletter email and include a ""confirm/opt-in"" button inside it, so we can update the mailing database accordingly and only email those who have opted in for future newsletters. </p>

<p>I'm new to Mailchimp. I'm trying to figure out how to implement this specific feature with the least amount of user friction possible. I see a widget to add a button, but it seems to just take a link, which would require the user going to another landing page to add their email address, etc. </p>

<p><strong>Is there a way to add a button or link into a mailchimp-generated email that will return yes/no data or add an attribute that can be collected using only mailchimp (without external links)?</strong> </p>

<p>(We have different teams doing different things and I don't have access to the website to build a simple landing page, and it would increase confirmation loss due to user 'friction'.)</p>

<p><strong>Time critical. Help is appreciated.</strong></p>
"
70256,"<p>As we are going through a tough time because of the Coronavirus epidemic, is it possible to somehow include this affect of this in predicting sales as a time-series for next few weeks? </p>

<p>I am new to time series forecasting but any idea will help here. </p>
"
61655254,"<p>Iam new to geoserver. I have created shape file of my district and added certain attributes like covid count, covid zone , district name etc related to COVID . I have loaded this to postgis database and I could see attributes also in table .But when I try to retrieve the feature using postman . Attribute values are not retrieved. Can anyone help </p>

<p>Below is my request
<strong><a href=""http://localhost:8080/geoserver/rest/workspaces/DistrictWpc/datastores/district_store/featuretypes/ernakulam.json"" rel=""nofollow noreferrer"">http://localhost:8080/geoserver/rest/workspaces/DistrictWpc/datastores/district_store/featuretypes/ernakulam.json</a></strong></p>

<p>Response is
{
    ""featureType"": {
        ""name"": ""ernakulam"",
        ""nativeName"": ""ernakulam"",
        ""namespace"": {
            ""name"": ""DistrictWpc"",
            ""href"": ""<a href=""http://localhost:8080/geoserver/rest/namespaces/DistrictWpc.json"" rel=""nofollow noreferrer"">http://localhost:8080/geoserver/rest/namespaces/DistrictWpc.json</a>""
        },
        ""title"": ""ernakulam"",
        ""keywords"": {
            ""string"": [
                ""features"",
                ""ernakulam""
            ]
        },
        ""srs"": ""EPSG:404000"",
        ""nativeBoundingBox"": {
            ""minx"": 76.1618881225586,
            ""maxx"": 76.6080093383789,
            ""miny"": 9.63820648193359,
            ""maxy"": 10.1869020462036
        },
        ""latLonBoundingBox"": {
            ""minx"": 76.1618881225586,
            ""maxx"": 76.6080093383789,
            ""miny"": 9.63820648193359,
            ""maxy"": 10.1869020462036,
            ""crs"": ""EPSG:4326""
        },
        ""projectionPolicy"": ""FORCE_DECLARED"",
        ""enabled"": true,
        ""store"": {
            ""@class"": ""dataStore"",
            ""name"": ""DistrictWpc:district_store"",
            ""href"": ""<a href=""http://localhost:8080/geoserver/rest/workspaces/DistrictWpc/datastores/district_store.json"" rel=""nofollow noreferrer"">http://localhost:8080/geoserver/rest/workspaces/DistrictWpc/datastores/district_store.json</a>""
        },
        ""serviceConfiguration"": false,
        ""maxFeatures"": 0,
        ""numDecimals"": 0,
        ""padWithZeros"": false,
        ""forcedDecimal"": false,
        ""overridingServiceSRS"": false,
        ""skipNumberMatched"": false,
        ""circularArcPresent"": false,
        ""attributes"": {
            ""attribute"": [
                {
                    ""name"": ""id"",
                    ""minOccurs"": 0,
                    ""maxOccurs"": 1,
                    ""nillable"": true,
                    ""binding"": ""java.lang.Long""
                },
                {
                    ""name"": ""district"",
                    ""minOccurs"": 0,
                    ""maxOccurs"": 1,
                    ""nillable"": true,
                    ""binding"": ""java.lang.String""
                },
                {
                    ""name"": ""count"",
                    ""minOccurs"": 0,
                    ""maxOccurs"": 1,
                    ""nillable"": true,
                    ""binding"": ""java.lang.Long""
                },
                {
                    ""name"": ""zone"",
                    ""minOccurs"": 0,
                    ""maxOccurs"": 1,
                    ""nillable"": true,
                    ""binding"": ""java.lang.String""
                },
                {
                    ""name"": ""geom"",
                    ""minOccurs"": 0,
                    ""maxOccurs"": 1,
                    ""nillable"": true,
                    ""binding"": ""org.locationtech.jts.geom.MultiPolygon""
                }
            ]
        }
    }
}</p>
"
61423177,"<p>I want to use the <a href=""https://www.geany.org/"" rel=""nofollow noreferrer"">Geany</a> IDE (v1.36) on Linux/Debian/Sid for developing the <a href=""https://github.com/bstarynk/helpcovid/"" rel=""nofollow noreferrer"">helpcovid</a> GPLv3+ project.</p>

<p>It seems that the <a href=""https://github.com/bstarynk/helpcovid/blob/master/HelpCovid.geany"" rel=""nofollow noreferrer"">HelpCovid.geany</a> project file (<code>git</code> versioned, in commit <a href=""https://github.com/bstarynk/helpcovid/commit/8aa3fcf9888f4871cba5bfdd5535788cf485c4f7"" rel=""nofollow noreferrer"">8aa3fcf9888f4871cb</a>, and I manually replaced absolute paths there with relative ones) cannot contain relative paths, since I am getting on startup:</p>

<pre><code>(geany:1819382): Geany-CRITICAL **: 10:43:52.803: utils_tidy_path: assertion 'g_path_is_absolute(filename)' failed

(geany:1819382): Geany-CRITICAL **: 10:43:52.880: utils_tidy_path: assertion 'g_path_is_absolute(filename)' failed
</code></pre>

<p>I am a Geany newbie.</p>

<p>Is there any way to avoid these warnings, and still have a directory-neutral <code>HelpCovid.geany</code>  file that could be versioned under <code>git</code> ?</p>

<p>PS. Submitted <a href=""https://github.com/geany/geany/issues/2483"" rel=""nofollow noreferrer"">issue#2483</a> to Geany</p>
"
61039112,"<p>I don't know about <code>cron jobs</code> and I am trying to set them in my cPanel, so I have 2 php files I am trying to run:</p>

<pre><code>covid-19_data.php
</code></pre>

<p>And <code>utilities.php</code></p>

<p>on cPanel I run:</p>

<pre><code>/usr/local/bin/php -q -f /public_html/wp-content/themes/siteName/scripts/data/shared/utilities.php
</code></pre>

<p>And</p>

<pre><code>/usr/local/bin/php /home/siteName/public_html/wp-content/themes/siteName/scripts/covid-19_data.php
</code></pre>

<p>But i keep receiving:</p>

<pre><code>Could not open input file: /public_html/wp-content/themes/siteName/scripts/data/shared/utilities.php
</code></pre>

<p>And</p>

<pre><code>Warning: include_once(../shared/utilities.php): failed to open stream: No such file or directory in /home1/siteName/public_html/wp-content/themes/siteName/scripts/covid-19_data.php on line 3

Warning: include_once(): Failed opening '../shared/utilities.php' for inclusion (include_path='.:/opt/php56/lib/php') in /home1/siteName/public_html/wp-content/themes/siteName/scripts/covid-19_data.php on line 3

Warning: chdir(): No such file or directory (errno 2) in /home1/siteName/public_html/wp-content/themes/siteName/scripts/covid-19_data.php on line 12

Fatal error: Call to undefined function downloadFile() in /home1/siteName/public_html/wp-content/themes/siteName/scripts/covid-19_data.php on line 16
</code></pre>

<p>I tried running <code>utilities.php</code> every minute and <code>covid-19_data.php</code> every two minutes but doesn't work.</p>

<p>When I need to make it work, I only manually run via the browser wwww... <code>covid-19_data.php</code> and works fine, I don't need to run <code>utilities.php</code> I only made it run to try if that was the issue.</p>
"
61415483,"<p>I'm an extreme novice. My goal is to scrape reddit posts and comments from the subreddit r/Coronavirus by the searchterm ""smokers"". I keep getting ""AttributeError: 'MoreComments' object has no attribute 'body'"" referring to the ""commentsDict[""Body""].append(topLevelComments.body)"" line. There are two other lines using the (topLevelComments.author, .score, and .body) that keep causing it to crash. When I comment out all of the lines with "".append(topLevelComments.  )it returns: ValueError(""arrays must all be same length"")  I'm losing my mind as this code worked fine 2 days ago. Please help, code below. I commented out the lines causing trouble, but not sure what to do about error 2 either. One step at a time though:</p>

<pre><code>commentsDict = {""Post"" : [], ""Post Score"" : [], ""No of Comments"":[], ""Post Date"":[], \
                ""Body"":[],""Score"":[],""Date"":[],""Author"":[], ""id"":[], ""p_auth"":[], ""Post body"":[]}

for submission in reddit.subreddit(""Coronavirus"").search(""smoker""):
    submission.comment_sort = 'new'
    topLevelComments = list(submission.comments)
    for topLevelComments in submission.comments:
        commentsDict[""Post""].append(submission.title)#title of post with comment
        commentsDict[""Post Score""].append(submission.score)
        commentsDict[""Post body""].append(submission.selftext)
        commentsDict[""id""].append(submission.id)
        commentsDict[""p_auth""].append(submission.author)
        commentsDict[""No of Comments""].append(submission.num_comments)
        date = submission.created_utc
        timestamp = datetime.datetime.fromtimestamp(date)
        commentsDict[""Post Date""].append(timestamp.strftime('%Y-%m-%D %H:%M:%S'))
        #commentsDict[""Body""].append(topLevelComments.body)
        #commentsDict[""Score""].append(topLevelComments.score)
        #date = topLevelComments.created
        timestamp = datetime.datetime.fromtimestamp(date)
        commentsDict[""Date""].append(timestamp.strftime('%Y-%m-%D %H:%M:%S'))
        #commentsDict[""Author""].append(topLevelComments.author)

commentsDF = pd.DataFrame(commentsDict)

commentsDF.to_csv('smoker_covid.csv', index=True) 
</code></pre>
"
61677106,"<p>a question if I may.  I am using Jupyter Notebook and Python 3.  I am using 3 csv files from <a href=""https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases"" rel=""nofollow noreferrer"">https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases</a> to produce graphs to track the covid 19 epidemic.  These are purely for my use to learn Python and Data Visualisation.  I have changed the dates in row one to be Day1, Day2 ect, dropped the Province/State, Lat, Long columns and set the Country/Region column as the index.  Each dataset now has 107 columns and 267 rows.  The three datasets are cases, deaths and recover.  Things are going ok but I have a slight problem and need some advice.  The graphs are updated with a new column each day and this causes me some problems when I try write code to show the daily increase in numbers from today over yesterday.  Currently I have to manually update my code each day to compensate for the extra columns in the 3 csv files as my code reads like:- </p>

<pre><code> daily_increase_C = [(0,
    (cases[""Day1""].sum()- (0)),
    (cases[""Day2""].sum()-cases[""Day1""].sum()),
    (cases[""Day3""].sum()-cases[""Day2""].sum()),
    (cases[""Day4""].sum()-cases[""Day3""].sum()),
    (cases[""Day5""].sum()-cases[""Day4""].sum()),
    ---------------------------------------------
    (cases[""Day102""].sum()-cases[""Day101""].sum()),
    (cases[""Day103""].sum()-cases[""Day102""].sum()),
    (cases[""Day104""].sum()-cases[""Day104""].sum()),
    (cases[""Day106""].sum()-cases[""Day105""].sum()))]
</code></pre>

<p>So the last line has to be copied, pasted and then updated each day.  There has to be a better way of achieving this but new to coding as I am, I cannot seem to get my head around it and figure it out.
Any advice, pointers, help on how to look at and approach this problem would be greatly appreciated.  I hope I have explained this clearly enough for you, if not my apologies and please post your questions needing clarification.  Thanks in advance for any help.</p>
"
61318944,"<p>My Scrapy code is just crawling the links on the webpage but not Scraping any data.Actually,I'm trying to scrape some data about Coronavirus pandemic for my project(like country name,cities within that country and then no. of cases,casualties etc.).The output is Debug:Crawled(200) in the cmd. I'm trying to scrape it from worldometers website(Being a newbie to scrapy i don't know much and for output reference the image link is provided)</p>

<pre><code># -*- coding: utf-8 -*-
import scrapy
import logging

class CountriesSpider(scrapy.Spider):
    name = 'countries'
    allowed_domains = ['www.worldometers.info']
    start_urls = ['http://www.worldometers.info/coronavirus/']

def parse(self, response):
    countries = response.xpath(""//td/a"")
    for country in countries:
        country_name = country.xpath("".//text()"").get()     
        country_link = country.xpath("".//@href"").get()
        #To access the country link
        absolute_url = response.urljoin(country_link)
        yield scrapy.Request(url = absolute_url,callback = self.parse_country)     #Or do directly--&gt;  yield response.follow(url = country_link)

def parse_country(self,response):
    rows = response.xpath(""(//table[@class = 'table table-bordered table-hover table-responsive usa_table_countries dataTable no-footer'])[1]/tbody/tr"")
    for row in rows:
        city = row.xpath("".//td[1]/text()"").get()
        cases = row.xpath("".//td[2]/text()"").get()
        deaths = row.xpath("".//td[4]/text()"").get()
        active_cases = row.xpath("".//td[6]/text()"").get()

        yield {
        ""City"":city,
        ""Total_Number_of_Cases"": cases,
        ""Deaths"":deaths,
        ""Active_Cases"":active_cases
        }
</code></pre>

<p><a href=""https://i.stack.imgur.com/ye8UC.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
"
60982570,"<p>I’ve been attempting to compile a script to give me table data from a few xpaths from <a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a> to display info from just 4 of the hundreds of datasets.   </p>

<p>The issue I’ve run into after playing around with various scripts for hours and hours and doing web searches is that pythonista iOS won’t allow me to utilize pandas, beautiful soup, pyto, or a host of other parsers.  </p>

<p>I’m admittedly a noob but it seems like using the basic installed libraries for python 2.7 or 3.2 should be able to simply display Xpath data with a few lines of code with which I will eventually migrate some premade code in iOS shortcuts app to make it a widget for my Apple Watch and/or iPhone.  </p>

<p>All this to say... has anyone had success scraping using iOS Pythonista app?   If so, any pointers for an angle of attack??</p>
"
60936613,"<p>when i append each country in <strong>countries</strong> everything works well but ""China"" isnt saved in the correct potition(so far it is 4th in site's list) but it appears as the last element
...</p>

<hr>

<p>it would feel more like a problem if the first element was saved at last BUT NOT the 4th one</p>

<pre><code>countries=[]
req = Request('https://www.worldometers.info/coronavirus', headers={""User-Agent"":""Mozilla/5.0...."")
html = urlopen(req).read()
html = urlopen(req).read()
soup=bs.BeautifulSoup(html,""lxml"")
table=soup.find(""table"",id=""main_table_countries_today"")
body=table.find(""tbody"")
rows=body.find_all(""tr"")

for row in rows:
    countries.append (str(row.find_all(""td"")[0].text.strip()))


for k in range(len(countries)):
    if countries[k] == 'China':
        pos=k
        print (k)
</code></pre>

<hr>

<p>P.S i am a newbie in both html and python but i know the basics</p>
"
60892945,"<p>I'm new to python and trying some webscraping with beautifulsoup. After following some youtube videos and endlessly looking for answers on stackflow, I decided I would post for help. </p>

<p>With the below code I am hoping to extract data from the website. I've noticed that one 3 div are listed when I print(len(div)), but there are several div's on the webpage. Other posts point to soup.findAll('div', {'class': 'responsive-text-label'}) as a solution, however, when I print() that code (and others similar), I get [] as a result from pyCharm.</p>

<p><code>enter code here</code>
    from bs4 import BeautifulSoup as soup
    from urllib.request import urlopen as uReq</p>

<pre><code>my_url = 'https://coronavirus.jhu.edu/map.html'
uClient = uReq(my_url)
page_html = uClient.read()
uClient.close()

page_soup = soup(page_html, 'html.parser')
total_cases = page_soup.findAll('div', {'class': 'responsive-text-label'})

print(total_cases)

RESULTS FROM PYCHARM
[]
</code></pre>

<p>Thank you in advance for taking the time and helping me out. </p>
"
61015827,"<p>I'm new to Python and using PyCharm professional as my IDE. I have a small section of code that I want to work with from a longer file, so I created a ""scratch file"" with Python set as the interpreter. However, even just with importing modules I'm getting errors that the modules can't be found (even with standard modules). The file is set as a ""Python"" scratch file, so I'm not sure what else I need to do. The code I'm trying to run is: </p>

<pre><code>from zipfile import ZipFile
import urllib

testfile = urllib.request.urlretrieve(""https://ihmecovid19storage.blob.core.windows.net/latest/ihme-covid19.zip"", ""ihme-covid19.zip"")
print(""File saved at: "" + (str(os.getcwd())))

with ZipFile('ihme-covid19.zip', 'r') as zipobj:
    print(zipobj.printdir())
    zipobj.extractall()
</code></pre>

<p>Everything is showing up with an error - no module urllib, no module zipfile, etc. </p>
"
60837097,"<p>I'm learning how to use Serverless Functions, I'm working trying to connect a Watson assistant through webhooks using a python action that is processing a small dataset, I'm still struggling to succeed on it.</p>

<p>I’ve done my coding on Jupyter environment calling raw csv dataset from Github and using pandas to handle it. The issue is when I’m invoking the action into IBM Functions works 10% of the times. I did debug on Jupyter and Visual Studio environments and the code seems to be ok, but once I move the code to the IBM Functions environment it doesn't perform. </p>

<pre><code>import sys
import csv
import json
import pandas as pd

location = ('Germany') #Passing country parameter for testing purpose

data = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-24-2020.csv')

def main(args):
    location = args.get(""location"")

for index, row in data.iterrows():
    currentLoc = row['Country/Region']
    if currentLoc == location:
        covid_statistics = {
            ""Province/State"": row['Province/State'], 
            ""Country/Region"": row['Country/Region'], 
            ""Confirmed"":row['Confirmed'], 
            ""Deaths"":row['Deaths'], 
            ""Recovered"":row['Recovered']     
        }
        return {""message"": covid_statistics}
    else:
        return {""message"": ""Data not available""}
</code></pre>
"
61641238,"<p>I am building a dataset, ultimately to be used to make an interactive online data visualization app with Dash.</p>

<p>This is my first project with Python (and programming in general), and I am trying to decide how best to go about retrieving, storing and updating the data for the dataset.</p>

<p>This is the api I am using:
<a href=""https://covid19api.com/"" rel=""nofollow noreferrer"">https://covid19api.com/</a></p>

<p>documentation:
<a href=""https://documenter.getpostman.com/view/10808728/SzS8rjbc?version=latest"" rel=""nofollow noreferrer"">https://documenter.getpostman.com/view/10808728/SzS8rjbc?version=latest</a></p>

<p>I have written some code that pulls down the data I need on a per country basis and manipulates it to create series' that I need</p>

<pre><code># Import the libraries
import requests

import pandas as pd
import numpy as np
from pandas import Series, DataFrame
from pandas import json_normalize

from datetime import datetime

import matplotlib.pyplot as plt


url = 'https://api.covid19api.com/total/dayone/country/ireland'
data = requests.get(url)

# Store the API response in a variable.
available_data = data.json()
df_ire = json_normalize(available_data)

# rename the date to datetime
df_ire = df_ire.rename(columns={""Date"" : ""datetime""})

#convert the data to datetime format
df_ire[""datetime""] = pd.to_datetime(df_ire[""datetime""])

# Create Daily new cases column &amp; SMA
df_ire[""New Cases""] = df_ire['Confirmed'].diff()
df_ire[""SMA_10 New Cases""] = df_ire[""New Cases""].rolling(window=10).mean()

# Create Daily new deaths column &amp; SMA
df_ire[""New Deaths""] = df_ire['Deaths'].diff()
df_ire[""SMA_10 New Deaths""] = df_ire[""New Deaths""].rolling(window=10).mean()

df_ire.fillna(0)

#set datetime as index
df_ire.set_index('datetime')

#Plot New Cases
fig, ax = plt.subplots(figsize=(15,7))
plt.grid(False)
plt.plot(df_ire[""SMA_10 New Cases""], label=""New Cases - 10-Day Moving Average"", 
         color = ""orange"", linewidth = 4 )
ax.bar(df_ire.index, df_ire[""New Cases""], label = ""Daily New Confirmed Cases"")

ax.set(xlabel='Days Since First Confirmed Case', ylabel='Number of Infections',
       title='Ireland: Average vs Daily New Cases')

fig.autofmt_xdate()

plt.legend(loc=2);

plt.savefig('ireland_avg_vs_daily_cases', dpi = 1067, bbox_inches='tight' )
</code></pre>

<p>As of right now I am just working with data for one country and using matplotlib as I figure out best how to present and process the data. Here is an example of what I have done so far: <a href=""https://i.stack.imgur.com/c0SMb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/c0SMb.png"" alt=""chart""></a></p>

<p>The finished project should look something like this, but with rates of change on all countries:
<a href=""https://dash-gallery.plotly.host/dash-opioid-epidemic/"" rel=""nofollow noreferrer"">https://dash-gallery.plotly.host/dash-opioid-epidemic/</a></p>

<p>First of all, the API is a community project and in development and I don't want to overload their system with requests, so I am trying to structure my project so as to minimize the amount of load that I put on their system. I'm - quite simply - not aware of what good/bad practices are with regards using apis, and I don't want to be ""that guy"".</p>

<p>As I said above, I also need to think about storing the data and updating it at appropriate intervals. It is time series data for 248 countries, and recording several variables, all of which will need to be manipulated in pandas and appended to regularly. Should I build one massive dataframe? Should I build a dataframe for each country, each variable?</p>

<p>Once I have created the dataset, I am hoping to update &amp; append it using similar code to what I have above, using this api call:
<a href=""https://api.covid19api.com/summary"" rel=""nofollow noreferrer"">https://api.covid19api.com/summary</a></p>

<p>Is that a good plan and what should it look like?</p>

<p>My plan is to host on Heroku (or something similar), when it is finished.</p>

<p>Thank you very much if you are still reading at this point. I know this is a very long-winded post, and I am asking a lot of questions in one go. I have been trying to think about how to proceed with this all afternoon, and I know that I need to make some fundamental decisions in order to proceed. Any help at all would be massively appreciated.</p>
"
60685308,"<p>this is my first post and I will try to be as complete as I can:</p>

<p>I am trying to perform my first web scrubbing program using Python. I am studying the coronavirus and am trying to obtain the data myself from pages that upload the rawdata.
The main goal is to create a dataframe with ""Day of Month"" ""New Cases (cases)"" and ""new deaths (death)""
as well as country and provinces, but I will ask about these two in another question. </p>

<p>So far with the imported libraries I am able to scrub the elements of the html file, in particular the <code>&lt;li&gt;</code> elements and <code>&lt;h4&gt;</code> elements. </p>

<pre><code>import re
from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd

driver = webdriver.Chrome(#Purposefully left blank)

#names of my lists

cases = [] 
death = []
Country = [] 
Province = [] 

#the page i'm scrumming

driver.get(""https://bnonews.com/index.php/2020/01/timeline-coronavirus-epidemic/"")

content = driver.page_source
soup = BeautifulSoup(content)

#Regex for finding [""Any number"" + new + case(s)] in a &lt;li&gt; element

newcaseReg = re.compile(r'''(
\d+\s\bn?e?w?\scases?\b
)''',re.VERBOSE)

#Regex for finding [""Any number"" + new + death(s)] in a &lt;li&gt; element

deathcaseReg = re.compile(r'''(
\d+\s?\bn?e?w?\sdeaths?
)''',re.VERBOSE)

#Regex for finding [""in province(s), country""]

provconReg = re.compile(r'''(
\bin\s\w+?.*?
[?\s\bprovince?s]
?[,\s]
?\w+\..?
)''',re.VERBOSE)

#Regex for cleaning the country and province regex and returning a list with only the names

SepProvConReg = re.compile(r'''(
[A-Z]\w+
)''',re.VERBOSE)

#variables that contain all the &lt;h4&gt; and &lt;li&gt; elements of the page. 

h4Tag = str(soup.findAll('h4'))
liTag = str(soup.findAll('li'))

#Cleans string and adds the amount of new cases per &lt;li&gt; element to ""cases"" variable

for i in newcaseReg.findall(liTag):
    cleanNCReg = re.compile(r'''(
    \d+
    )''', re.VERBOSE)
    cases.append(str(cleanNCReg.findall(i)))

#This is supposed to append ""0"" when deathcaseReg.findall(liTag) == 'None' and also append ""value"" when
#deathcaseReg.findall(liTag) finds the regex. 

for i in deathcaseReg.findall(liTag):
    if i == 'None':
        death.append('None')
    else:
        death.append(i)



len(cases)

</code></pre>

<p>So the output for ""cases"" is 1950+, but the <code>len(death)</code> is 284. This is because the regex is only counting the positive results and not appending ""0"" like I want it to. This is where I need help because I've searched and checked and the answers from: <a href=""https://stackoverflow.com/questions/56855558/how-to-return-a-string-if-a-re-findall-finds-no-match"">How to return a string if a re.findall finds no match</a> didn't help me at all because the output keeps returning 278 (having used all answers from that result search).</p>

<p>One more question:
Since I am trying to build a column based dataframe for analyzing my data in R I was wondering if anybody could think of a way to write a code that would repeat the <code>&lt;h4&gt;</code> element for the same amount of <code>&lt;li&gt;</code> tags corresponding to that <code>&lt;h4&gt;</code> tag:
What I mean is, suppose </p>

<pre><code>&lt;h4&gt; 4th of March &lt;\h4&gt;

&lt;li&gt;&lt;\li&gt;
&lt;li&gt;&lt;\li&gt;
&lt;li&gt;&lt;\li&gt;
.
.
.
x50
&lt;h4&gt;3rd of March&lt;\h4&gt;
&lt;li&gt;&lt;\li&gt;
.
x30
&lt;h4&gt;2nd of March&lt;\h4&gt;
</code></pre>

<p>So what I would like is to write a code that would identify the number of <code>&lt;li&gt;</code> between the first <code>&lt;h4&gt;</code> and the second <code>&lt;h4&gt;</code> and to create a list that repeats the <code>&lt;h4&gt;</code> string that amount of times. </p>

<p>Any help would be well appreciated. Thank you for taking your time to read this.  </p>
"
60609760,"<p>I am a beginner and I'm developing a code to visualize the spread of corona virus globally, I want to extract the .csv file from the <strong>GitHub Repo(<a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data"" rel=""nofollow noreferrer"">csse_covid_19_data</a>)</strong> where a new .csv file is uploaded every 2 days.
Instead of downloading the file manually is it possible to import the latest csv file to notebook automatically?</p>

<p>I have tried scraping the data but it doesn't help  </p>

<pre><code>import requests

url = 'https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_daily_reports/03-08-2020.csv'
response = requests.get(url)
print(response.text)
</code></pre>
"
60485988,"<p>My partner and I started learning Python at the beginning of the year. I am at the point where a) my partner and I are almost finished with our code, but b) are pulling our hair out trying to get it to work.</p>

<p>Assignment: Pull 250 tweets based on a certain topic, geocode location of tweets, analyze based on sentiment, then display them on a web-map. We have accomplished almost all of that except the 250 tweets requirement.</p>

<p>And I do not know how to pull the tweets more efficiently. The code works, but it writes around seven-twelve rows of information onto a CSV before it times out. </p>

<p>I tried setting a tracking parameter, but received this error: <code>TypeError: 'NoneType' object is not subscriptable'</code></p>

<p>I tried expanding the locations parameter to stream.filter(locations=[-180,-90,180,90]), but received the same problem: <code>TypeError: 'NoneType' object has no attribute 'latitude'</code></p>

<p>I really do not know what I am missing and I was wondering if anyone has any ideas.</p>

<p>CODE BELOW:</p>

<pre><code>from geopy import geocoders
from geopy.exc import GeocoderTimedOut
import tweepy
from tweepy.streaming import StreamListener
from tweepy import OAuthHandler
from tweepy import Stream
from textblob import TextBlob
import json
import csv

def geo(location):
    g = geocoders.Nominatim(user_agent='USER')
    if location is not None:
        loc = g.geocode(location, timeout=None)
        if loc.latitude and loc.longitude is not None:
            return loc.latitude, loc.longitude

def WriteCSV(user, text, sentiment, lat, long):
    f = open('D:/PATHWAY/TO/tweets.csv', 'a', encoding=""utf-8"")
    write = csv.writer(f)
    write.writerow([user, text, sentiment, lat, long])
    f.close()

CK = ''
CS = ''
AK = ''
AS = ''

auth = tweepy.OAuthHandler(CK, CS)
auth.set_access_token(AK, AS)

#By setting these values to true, our code will automatically wait as it hits its limits
api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)

#Now I'm going to set up a stream listener
#https://stackoverflow.com/questions/20863486/tweepy-streaming-stop-collecting-tweets-at-x-amount
#https://wafawaheedas.gitbooks.io/twitter-sentiment-analysis-visualization-tutorial/sentiment-analysis-using-textblob.html        
class StdOutListener(tweepy.StreamListener):
    def __init__(self, api=None):
        super(StdOutListener, self).__init__()
        self.num_tweets = 0

    def on_data(self, data):
        Data = json.loads(data)
        Author = Data['user']['screen_name']
        Text = Data['text']
        Tweet = TextBlob(Data[""text""])
        Sentiment = Tweet.sentiment.polarity
        x,y = geo(Data['place']['full_name'])
        if ""coronavirus"" in Text:
            WriteCSV(Author, Text, Sentiment, x,y)
            self.num_tweets += 1
            if self.num_tweets &lt; 50:
                return True
            else:
                return False

stream = tweepy.Stream(auth=api.auth, listener=StdOutListener())
stream.filter(locations=[-122.441, 47.255, -122.329, 47.603])
</code></pre>
"
60872588,"<p>I'm new to coding and am still learning. I want to Data Analysis of Coronavirus Outbreak with Python now the problem is that my python<code>enter code here</code> code show an error when I run the code in Pycharm but the same code when i run in the Jupyter Notebook program run successfully.</p>

<pre><code>import matplotlib.pyplot as plt
import pandas

data = pandas.read_csv('time_series_2019-ncov-Confirmed.csv')
print(data)

data.sum().plot()
plt.title(""Number of infection"")
plt.show()
</code></pre>
"
61685263,"<p>I am new to python and pandas. <strong>I am having difficulties comming up with a column with the elapsed days since the occurence of the first case by country.</strong> Similiar to the date column, but instead of a date I want the days since de first case (since the first occurence of a case/death/recovered within a country)</p>

<p>I have grouped the data by the country and date and summed confirmed, deaths and recovered cases. (Because the original data had some countries split withing regions) I also erased the days where there were no deaths, recovered or deaths (I want to count since the first case appeared).</p>

<p>I would appreciate any help! Thanks in advance!</p>

<pre><code>covid_data = covid_data.groupby(['Country/Region', 'Date'])[['Confirmed', 'Deaths', 'Recovered']].apply(sum)
covid_data.sort_values(by=['Country/Region', 'Date'])
covid_data.reset_index()
covid_data = covid_data[(covid_data.T != 0).any()] #eliminates rows with no suspected, no deaths and no cured
</code></pre>

<p>Output:</p>

<pre><code>Country/Region  Date       Confirmed    Deaths  Recovered
Afghanistan     2020-02-24  1            0       0
                2020-02-25  1            0       0
                2020-02-26  1            0       0
                2020-02-27  1            0       0
                2020-02-28  1            0       0
                2020-02-29  1            0       0
                2020-03-01  1            0       0
                2020-03-02  1            0       0
                2020-03-03  1            0       0
                2020-03-04  1            0       0
(and many other countries)
</code></pre>
"
61420038,"<p>I am new to the BI field and I was trying to predict the coronavirus cases for Italy. I am using tableau and exponential smoothing to predict cases. Both of my forecast(One with the trend, The other with seasonality) have Good model quality and Metrics. Which model should I choose?</p>

<p><a href=""https://i.stack.imgur.com/oYEeb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/oYEeb.png"" alt=""Multiplicative""></a></p>

<p><a href=""https://i.stack.imgur.com/Ddq5D.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Ddq5D.png"" alt=""Additive""></a></p>
"
61048407,"<p>I'm new to using Seaborn and usually only use Matplotlib.pyplot. </p>

<p>With the recent COVID developments I was asked by a supervisor to put together estimates of how changes to the student population &amp; expenses we need to fund affected student fees (I work in a college budgeting office). I've been able to put together my scenario analysis, but am now trying to visualize these results in a heatmap.</p>

<p>What I'd like to be able to do is have the:</p>

<pre><code> x-axis be my population change rates,
 y_axis be my expense change rates,
 cmap be my new student fees depending on the x &amp; y axis.
</code></pre>

<p>What my code is currently doing is:</p>

<pre><code> x-axis is displaying the new student fee category (not sure how to describe this - see picture)
 y-axis is displaying the population change and expense change (population, expenses)
 cmap is displaying accurately
</code></pre>

<p>Essentially, my code is stacking each scenario on top of the others along the y-axis.</p>

<p>Here is a picture of what is currently being produced, which is not correct:</p>

<p><img src=""https://i.stack.imgur.com/Wn5Rl.jpg"" alt=""Example Output - NOT Correct""></p>

<p>I've attached a link to a <a href=""https://colab.research.google.com/drive/1PlUTE94rgANMJbQHUmgUKciJlPpq-9fw"" rel=""nofollow noreferrer"">Colab Jupyter notebook</a> with my code, and below is a snippet of the section giving me problems.</p>

<pre><code># Create Pandas DF of Scenario Analysis       
df = pd.DataFrame(list(zip(Pop, Exp, NewStud, NewTotal)), 
                  index = [i for i in range(0,len(NewStud))], 
                  columns=['Population_Change', 'Expense_Change', 'New_Student_Activity_Fee', 'New_Total_Fee'])

# Group this scenario analysis 
df = df.groupby(['Population_Change', 'Expense_Change'], sort=False).max()

# Create Figure 
fig = plt.figure(figsize=(15,8))
ax = plt.subplot(111)

# Drop New Student Activity Fee Column. Analyze Only New Total Fee
df = df.drop(['New_Student_Activity_Fee'], axis=1)

########################### Not Working As Desired
sb.heatmap(df)
########################### 

</code></pre>
"
61301122,"<p>I am a relative newbie to python and bokeh and trying to create an interactive bokeh plot of COVID incidence and deaths by country.
The code works perfectly without the Select tool, but when I rewrite it with the select tool I execute it, the graph does not update with a new selection.
I've obviously gone wrong in some fundamental issue, but I simply cannot figure this out. 
This code should run independently for anyone who is checking. I'm not sure if I have goofed up the update function, or if updating a variable does not work.</p>

<pre><code>import pandas as pd
from bokeh.plotting import figure, output_file
from bokeh.io import curdoc
from bokeh.models import ColumnDataSource, HoverTool, NumeralTickFormatter, DatetimeTickFormatter, Select
from bokeh.palettes import Category20b
from bokeh.layouts import layout

url_confirmed = 'https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv&amp;filename=time_series_covid19_confirmed_global.csv'
url_deaths = 'https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv&amp;filename=time_series_covid19_deaths_global.csv'


covid_confirmed = pd.read_csv(url_confirmed)
covid_confirmed_grp = covid_confirmed.groupby('Country/Region').sum()
covid_deaths = pd.read_csv(url_deaths)
covid_deaths_grp = covid_deaths.groupby('Country/Region').sum()


covid_confirmed_dates = covid_confirmed_grp.drop(columns = ['Lat', 'Long'])
covid_confirmed_dates = covid_confirmed_dates.transpose()
covid_confirmed_dates = covid_confirmed_dates.reset_index()
covid_confirmed_dates = covid_confirmed_dates.rename(columns = {'index':'date'})
covid_confirmed_dates['date'] = pd.to_datetime(covid_confirmed_dates['date'])


covid_deaths_dates = covid_deaths_grp.drop(columns = ['Lat', 'Long'])
covid_deaths_dates = covid_deaths_dates.transpose()
covid_deaths_dates = covid_deaths_dates.reset_index()
covid_deaths_dates = covid_deaths_dates.rename(columns = {'index':'date'})
covid_deaths_dates['date'] = pd.to_datetime(covid_deaths_dates['date'])


countrylist = covid_confirmed_dates.columns.tolist()
countrylist.remove('date')

# reset the output so that the file size does not increase
#bokeh.io.reset_output()

source_confirmed = ColumnDataSource(covid_confirmed_dates)
source_deaths = ColumnDataSource(covid_deaths_dates)
countrylist = ['India','US', 'Spain', ""Italy"", ""Germany"", ""United Kingdom"", 
               ""France"", ""China"", ""Iran"", ""Turkey"", ""Belgium"", 
               ""Brazil"", ""Canada"", ""Netherlands"", ""Switzerland""]
mypallette = Category20b[20]
country = 'India'

# name the output file
output_file('covid_confirmed_deaths.html')

def update_country(attr,old,new):
    global country
    country = select.value

# define the figure variable
f = figure(plot_width=800, plot_height=500, x_axis_type=""datetime"")

f.xaxis.axis_label = ""Date""
f.yaxis.axis_label = ""Cases""
f.title.text = 'COVID19 Cases'

f.line(x = 'date', y = country, color='red', alpha=1, source = source_confirmed, line_width = 3, name = country, legend_label=country)

f.legend.location = ""top_left""
f.legend.click_policy=""hide""
f.legend.title = 'Tap to toggle on/off'
f.yaxis[0].formatter = NumeralTickFormatter(format=""0,000,000"")
f.xaxis[0].formatter = DatetimeTickFormatter(days=""%d/%m"")
hover = HoverTool(
    tooltips = [
        (""country"", ""$name""),
        (""date"", ""@date{%d/%m}""),
        (""cases"", ""$y{0,000,000}"")
    ],
    formatters={
        '@date': 'datetime',
        },
    )
f.add_tools(hover)

# define the figure variable
g = figure(plot_width=800, plot_height=500, x_axis_type=""datetime"")

g.xaxis.axis_label = ""Date""
g.yaxis.axis_label = ""Deaths""
g.title.text = 'COVID19 Deaths'

g.line(x = 'date', y = country, color='blue', alpha=1, source = source_deaths, line_width = 3, name = country, legend_label=country)

g.legend.location = ""top_left""
g.legend.click_policy=""hide""
g.legend.title = 'Tap to toggle on/off'
g.yaxis[0].formatter = NumeralTickFormatter(format=""0,000,000"")
g.xaxis[0].formatter = DatetimeTickFormatter(days=""%d/%m"")
hover = HoverTool(
    tooltips = [
        (""country"", ""$name""),
        (""date"", ""@date{%d/%m}""),
        (""cases"", ""$y{0,000,000}"")
    ],
    formatters={
        '@date': 'datetime',
        },
    )
g.add_tools(hover)

countrylist1 = [('India', 'India'),('US','US'), ('Spain', 'Spain'), 
               ('Italy', 'Italy'), ('Germany', 'Germany'), ('United Kingdom', 'United Kingdom'), 
               ('France', 'France'), ('China', 'China'), ('Iran', 'Iran'),('Turkey', 'Turkey'), ('Belgium', 'Belgium'),
               ('Brazil', 'Brazil'), ('Canada', 'Canada'), ('Netherlands', 'Netherlands'), ('Switzerland', 'Switzerland')]
select = Select(title=""Select Country:"", value=""India"", options=countrylist1)
select.on_change(""value"", update_country)

lay_out=layout([[select]])
curdoc().add_root(lay_out)
curdoc().add_root(f)
curdoc().add_root(g)

</code></pre>
"
61068887,"<p>I am simply trying to pull lat/lon data from recent tweets (similar to the code structure below). No radius, no maps, just the raw lat/lon data. I have gone through the tweepy documentation and can't seem to find what I need. It's probably a simple fix, but I'm pretty new to this. Any help would be great! TIA.</p>

<pre><code>from tweepy import *
from tweepy.streaming import StreamListener
import json

consumer_key = """"
consumer_secret = """"
access_token = """"
access_token_secret = """"

#Creating authentication object
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)

#Setting your access token and secret
auth.set_access_token(access_token, access_token_secret)

#Creating the API object while passing in auth information
api = tweepy.API(auth)

#The search term you want to find
query = [""COVID-19"", ""deaths""]

#Language code (Follows ISO 639-1 standards)
language = ""en""

#Calling the user_timeline function with our parameters
results = api.search(q=query, lang=language)

#foreach through all tweets pulled
for tweet in results:
    print (tweet.user.screen_name,""Tweeted:"",tweet.text)
    print (""Location:"", tweet.user.location, tweet.text)
    #print (api.update_status(tweet.text))
    print (""Date:"", tweet.created_at, tweet.text)
</code></pre>
"
60825824,"<p>I'm v new to creating chatbots. </p>

<pre><code>import telebot

bot = telebot.TeleBot('123345677789')

def sendMessage(message, text):
   bot.send_message(message.chat.id, text)

@bot.message_handler(func=lambda msg: msg.text is not None)
def reply_to_message(message):
    if 'hello' in message.text.lower():
        sendMessage(message, 'Hello! How are you doing today?')
    else:
        bot.reply_to(message,'try hi or hello')

@bot.message_handler(func=lambda msg: msg.text is not None)
def getresponse(user_input):
    if 'virus' in user_input.text.lower():
        url = ""https://covid-19-coronavirus-statistics.p.rapidapi.com/v1/stats""
        querystring = {""country"":""USA""}
        headers = {
            'x-rapidapi-host': ""covid-19-coronavirus-statistics.p.rapidapi.com"",
            'x-rapidapi-key': ""ea33a4fd9cmshd4ead0c7290""}
        response = requests.request(""GET"", url, headers=headers, params=querystring)
        bot.reply_to(user_input,response.text)
    else:
        bot.reply_to(user_input,'type virus')
</code></pre>

<p>I've been trying to get the api to return the data. But whenever i try to send the requests, the bot doesnt remind me anything. Any help is appreciated.</p>

<p>Thanks!</p>
"
60852000,"<p>I have a JSON File which contains some data as below:</p>

<pre><code>{
  'count': 2,
  'next': '?page=2',
  'previous': None,
  'results': [
    {
      'category': 'Triggers',
      'id': '783_23058',
      'name': 'Covid-19'
    }, 
    {
      'category': 'Sources',
      'id': '426_917746',
      'name': 'Covid19Conversations'
    }
  ]
}
</code></pre>

<p>I am able to extract the first 'id' and 'name' values as below</p>

<pre class=""lang-py prettyprint-override""><code>Doc_details = dict() 
for item in companies:
  doc_id = companies['results'][0]['id']
  doc_name = companies['results'][0]['name']
  Doc_details[doc_name] = doc_id

for key, value in Doc_details.items():
  print(key,value)
</code></pre>

<p>Output:</p>

<pre><code>Covid-19 783_23058
</code></pre>

<p>I am new to python. Can someone help me with:</p>

<ol>
<li>Loop through it and extract all the key,value pairs</li>
<li>Save the results to an excel file.</li>
</ol>
"
60870063,"<p>I have a dataframe created on a csv file about Italian Covid-19 spread all over regions. I was trying to create a px.choropleth plot in which showing Total Positive values for every regions in Italy. 
This the code tried:</p>

<pre><code>italy_regions=[i for i in region['Region'].unique()]
fig = px.choropleth(italy_last, locations=""Country"",
                    locationmode=italy_regions,
                    color=np.log(italy_last[""TotalPositive""]), 
                    hover_name=""Region"", hover_data=['TotalPositive'],
                    color_continuous_scale=""Sunsetdark"", 
                    title='Regions with Positive Cases')
fig.update(layout_coloraxis_showscale=False)
fig.show()
</code></pre>

<p>Now I report some info: 'Country' is the name given to my dataframe and is filled only with the same values: 'Italy'. If I only input 'location=""Country""' the graph is fine and I can see Italy colored into the world map.
The problems start when I try to make pyplot color my regions. As I'm a newbye in pyplot express, I read some examples and I thought I had to create a list of italian regions names and then put into 'choropleth' as input for 'barmode'. 
Clearly I'm wrong.
So, what is the procedure to follow to make it run (if any)?
In case of need, I can provide both the csv file that the jupyter file I'm working on.</p>
"
61378180,"<p>Here is my data, It's based on a schema and I need to generate mapping to be indexed on ES. My background with ES is not much but I thought I got it until I tried it and failed and can't find the right answer online..</p>

<pre><code>{
  ""@context"": {
    ""schema"": ""http://schema.org/"",
    ""outbreak"": ""https://discovery.biothings.io/view/outbreak/""
  },
  ""@type"": ""outbreak:Publication"",
  ""keywords"": [
    ""COVID-19"",
    ""City lockdown"",
    ""Epidemic"",
    ""Governmental action"",
    ""Individual reaction"",
    ""Mathematical modelling""
  ],
  ""author"": [
    {
      ""@type"": ""outbreak:Person"",
      ""affiliation"": [
        {
          ""@type"": ""outbreak:Organization"",
          ""name"": ""Department of Applied Mathematics, Hong Kong Polytechnic University, Hong Kong, China. Electronic address: daihai.he@polyu.edu.hk.""
        }
      ],
      ""familyName"": ""He"",
      ""givenName"": ""Daihai"",
      ""name"": ""Daihai He""
    }
  ],
  ""publicationType"": [
    ""Journal Article""
  ],
  ""_id"": ""pmid32145465"",
  ""curatedBy"": {
    ""@type"": ""schema:WebSite"",
    ""name"": ""litcovid"",
    ""url"": ""https://www.ncbi.nlm.nih.gov/research/coronavirus/publication/32145465""
  },
  ""name"": ""A conceptual model for the coronavirus disease 2019 (COVID-19) outbreak in Wuhan, China with individual reaction and governmental action."",
  ""identifier"": ""32145465"",
  ""pmid"": ""32145465"",
  ""abstract"": ""The ongoing coronavirus disease 2019 (COVID-19) outbreak, emerged in Wuhan, China in the end of 2019, has claimed more than 2600 lives as of 24 February 2020 and posed a huge threat to global public health. The Chinese government has implemented control measures including setting up special hospitals and travel restriction to mitigate the spread. We propose conceptual models for the COVID-19 outbreak in Wuhan with the consideration of individual behavioural reaction and governmental actions, e.g., holiday extension, travel restriction, hospitalisation and quarantine. We employe the estimates of these two key components from the 1918 influenza pandemic in London, United Kingdom, incorporated zoonotic introductions and the emigration, and then compute future trends and the reporting ratio. The model is concise in structure, and it successfully captures the course of the COVID-19 outbreak, and thus sheds light on understanding the trends of the outbreak."",
  ""license"": ""Copyright © 2020 The Authors. Published by Elsevier Ltd.. All rights reserved."",
  ""journalName"": ""International journal of infectious diseases : IJID : official publication of the International Society for Infectious Diseases"",
  ""journalAbbreviation"": ""Int. J. Infect. Dis."",
  ""issueNumber"": ""1878-3511"",
  ""doi"": ""S1201-9712(20)30117-X"",
  ""url"": ""https://www.doi.org/S1201-9712(20)30117-X"",
  ""datePublished"": ""2020-03-04"",
  ""dateModified"": ""2020-02-26""
}
</code></pre>

<p>and here is my mapping so far:</p>

<pre><code>{
                'fields':{
                    'type': 'string'
                },
                'abstract': {
                    'type': 'text'
                },
                'pmid': {
                    'type': 'integer'
                },
                'author': {
                    'type': 'nested',
                    'properties': {
                        'name':{
                            'type': 'text'
                        },
                        'givenName':{
                            'type': 'text'
                        },
                        'familyName':{
                            'type': 'text'
                        },
                        'affiliation':{
                            'type': 'nested',
                            'properties': {
                                'name':{
                                    'type': 'text'
                                }
                            }
                        }
                    }
                },
                'isBasedOn': {
                    'type': 'text'
                },
                'funding': {
                    'type': 'nested',
                    'properties': {
                        'funder':{
                            'type': 'nested',
                            'properties':{
                                'name': 'text'
                            }
                        },
                        'identifier':{
                            'type': 'text'
                        }
                    }
                },
                'license': {
                    'type': 'text'
                },
                'keywords': {
                    'normalizer': 'keyword_lowercase_normalizer',
                    'type': 'keyword',
                    'copy_to': ['all']
                },
                'publicationType': {
                    'normalizer': 'keyword_lowercase_normalizer',
                    'type': 'keyword',
                    'copy_to': ['all']
                },
                'name': {
                    'type': 'text'
                },
                'journalName': {
                    'type': 'text'
                },
                'identifier': {
                    'type': 'text'
                },
                'doi': {
                    'type': 'text'
                },
                'datePublished': {
                    'type': 'date'
                },
                'dateModified': {
                    'type': 'date'
                },
                'issueNumber': {
                    'type': 'text'
                }
         }
</code></pre>

<p>I don't have a field ""fields"" in my data so I'm not sure what this means and ""name"" is a simple string </p>

<p>I've tried this and also including ""mappings"" :{""properties"":{...}} but that also fails. Any pointers??</p>
"
61541368,"<p>I am working on COVID19 analysis and am using a JSON data source. I have converted the json to dataframe. I am working on plotting a daily case, daily death and daily recovered bar chart over a datetime x-axis for each state and the state can be selected using a Select widget. I don't know Javascript so, I am trying to avoid using Javascript callbacks but have been using a function to update the select.value. I am not sure why is the plot not getting updated even when i am running the code on Bokeh server and there are no exceptions raised by the interpreter. </p>

<p>Can someone provide me with any direction or help with what might be causing the issue as I am new to Python and any help is appreciated? Or if there's any other alternative. This code is a derivation from a similar plot on [bokeh discourse][1]</p>

<pre><code>#Creating DataFrame
cases_summary = requests.get('https://api.rootnet.in/covid19-in/stats/history')
json_data = cases_summary.json()
cases_summary=pd.json_normalize(json_data['data'], record_path='regional', meta='day')
cases_summary['day']=pd.to_datetime(cases_summary['day'])
cases_summary['daily deaths']=cases_summary['deaths'].groupby(cases_summary['loc']).diff(1)
cases_summary['daily confirmed']=cases_summary['totalConfirmed'].groupby(cases_summary['loc']).diff(1)
cases_summary['daily discharged']=cases_summary['discharged'].groupby(cases_summary['loc']).diff(1)

#Initializing the first default plot
cases=cases_summary[cases_summary['loc']=='Delhi']


source=ColumnDataSource(data=cases)

a = figure(plot_width=1200, plot_height=700, sizing_mode=""scale_both"", x_axis_type='datetime')


def make_plot(cases_val):
    a.vbar('day', top='daily confirmed', width=timedelta(days=0.5),
                   legend_label='Daily Confirmed', color='#5e4fa2', source=cases_val)
    a.vbar('day', bottom='daily discharged', width=timedelta(days=0.5),
                        legend_label='Daily Recovered', color='#66c2a5', source=cases_val)
    a.vbar('day', bottom='daily deaths', width=timedelta(days=0.5),
                      legend_label='Daily Deaths', color='#3288bd', source=cases_val)
   return a

def update_plot(attr,old,new):
    location=select.value
    data_loc = cases_summary[cases_summary['loc'] == location]
    source = ColumnDataSource(data=dict()).from_df(data_loc)
    layout.children[0]=make_plot(source)

select = Select(title=""Select State:"", value=""Delhi"", options=cases_summary['loc'].unique().tolist())

plot = make_plot(cases)

controls = column(select)
layout = row(a, controls)
select.on_change('value', update_plot)

curdoc().add_root(layout)


  [1]: https://discourse.bokeh.org/t/how-to-update-the-bar-chart-that-has-dataframe-as-source-with-bokeh-select-widget/2031/8
</code></pre>
"
61680818,"<p>I have developed a COVID19 Dashboard and have integrated Google Analytics to the dashboard as it is deployed on <a href=""http://covid19analysis.live"" rel=""nofollow noreferrer"">http://covid19analysis.live</a> .</p>

<p>I have used components() to append them in index.html file under Templates. It is functioning perfectly with Tabs but when I add Select widget to the existing tab, the dashboard opens on bokeh serve but the Select options aren’t updating the plot. When I remove the below components, the Select widget values are updating the plot as expected:</p>

<pre><code>tabs = Tabs(tabs=[tab1, tab2, tab3,  tab4, tab5, tab6,  tab7, tab8, tab9, tab10, tab11])

curdoc().add_root(tabs)

script, div = components(tabs, CDN)

curdoc().template_variables[""script""] = script
curdoc().template_variables[""div""] = div  
</code></pre>

<p>The above Python script and index.html are working perfectly until I added a Select widget to the first tab. After I remove the last 3 lines of the code, the charts are perfectly interactive but wuthout the last 3 lines of code, the Google Analytics isn't integrated. </p>

<p>I  have updated {{ script | safe }} and {{ div | safe}} in index.html as per a static HTML template so, Google Analytics is functional.</p>

<p>Is there any way, I can fix this?</p>

<p>PS - I am new to Python and a newly become fan of Bokeh.</p>

<p>Thank you.</p>
"
60991573,"<p>I'm new to web crawling and I want to build a web crawler on python which gets certain data of coronavirus from CDC, which is JUST the total number of cases in U.S right now.
Below is my code</p>

<pre class=""lang-py prettyprint-override""><code>from create import *
from data_finder import *
import pandas as pd
import urllib.request
import ssl


def crawl(pg_url):
    html_string=''
    try:
        ssl._create_default_https_context = ssl._create_unverified_context
        req = urllib.request.Request(pg_url)
        response = urllib.request.urlopen(req)
        the_page = response.read()
        html_string=the_page.decode(""utf-8"")
        print(html_string)
        finder = data_finder()#my own function that select certain elements from  &lt;td&gt; tag 
        finder.feed(html_string)
        create_dir('corona_data')
        df=pd.DataFrame(finder.dict.items(),columns=['Number of Days','Total Cases'])
        df.to_csv('./corona_data/data.csv', sep='\t', encoding='utf-8')
    except:
        print('bad page')

crawl('https://www.cdc.gov/TemplatePackage/contrib/widgets/cdcCharts/iframe.html?chost=www.cdc.gov&amp;cpath=/coronavirus/2019-ncov/cases-updates/cases-in-us.html&amp;csearch=&amp;chash=&amp;ctitle=Cases%20in%20U.S.%20%7C%20CDC&amp;wn=cdcCharts&amp;wf=/TemplatePackage/contrib/widgets/cdcCharts/&amp;wid=cdcCharts2&amp;mMode=widget&amp;mPage=&amp;mChannel=&amp;host=www.cdc.gov&amp;displayMode=wcms&amp;configUrl=/coronavirus/2019-ncov/cases-updates/total-cases-onset.json&amp;class=mb-3')
</code></pre>

<p>My problem is that I inspect the tr and td elements in chrome, however, they didn't show up when I do the urlopen, then read and then decode. After doing some search, I've found that the problem might relate to the data table generated using javascript instead of plain HTML. So I'm wondering how should I fix it so that I can preload the whole page, inspect and copy all HTML like what I did when I was doing browsing and then parse myself.</p>
"
61017361,"<p>I'm looking to pass a variable to the URL when a specific navbar item is clicked. While searching through Flask's documentation, I saw a nav.Item component called <code>nav.Item('Latest News', 'news', {'page': 1}),</code> and decided I'd try it myself.</p>

<p>If I go to URL ""localhost:5000/average/recovery/"" and ""localhost:5000/average/mortality"" it uses the same method called getAverageInfectedRate(options), and inside that method it'll either go through the ""recovery"" if statement or ""deaths"" if statement depending on options variable, passed in by the URL that's entered. </p>

<p>Without separating the app route into two separate methods, is it possible for me to pass the ""options""variable through the navigation buttons? </p>

<pre><code>nav.Bar('top', [
    nav.Item('Home', 'index'),
    nav.Item('# of Cases', 'getActiveCases'),
    nav.Item('Mortality Rate', 'getAverageInfectedRate', {'deaths': 'deaths'}),
## clicking button would navigate to localhost:5000/average/deaths
    nav.Item('Recovery Rate', 'getAverageInfectedRate', {'recovery': 'recovery'})
## clicking button would navigate to localhost:5000/average/recovery
])
</code></pre>

<p>This is the parameter specific If statement route, discussed above. </p>

<pre><code>def getAverageInfectedRate(option):
    if (option == 'deaths'):
        first = requests.get(""https://covid2019-api.herokuapp.com/total"")
        second = requests.get(""https://covid2019-api.herokuapp.com/deaths"")
        first = first.json()
        second = second.json()
        convertConfirmed = int(first[""confirmed""])
        convertDeaths = int(second[""deaths""])
        stats = int(convertConfirmed/convertDeaths)
        return render_template_string('''
        &lt;h1&gt;Mortality Rate, worldwide&lt;/h2&gt;
        &lt;h2&gt;{{stats}}%&lt;/h2&gt;
    ''', stats = stats)
    if (option == 'recovery'):
        first = requests.get(""https://covid2019-api.herokuapp.com/total"")
        second = requests.get(""https://covid2019-api.herokuapp.com/total"")
        first = first.json()
        second = second.json()
        convertConfirmed = int(first[""confirmed""])
        convertRecovered = int(second[""recovered""])
        stats = int(convertConfirmed/convertRecovered)
        return render_template_string('''
        &lt;h1&gt;Recovery Rate, worldwide&lt;/h2&gt;
        &lt;h2&gt;{{stats}}%&lt;/h2&gt;
    ''', stats = stats)
</code></pre>

<p>I'm fairly new at web development obviously and would love for suggestions on how to make this code clearer, I thought about seperating the routes into two different ones, but I like the possibility of adding an additional parameter to select an individual country. Working with API's is so fun!</p>
"
60983438,"<p>I'm attempting to put together a Jupyter Notebook that allows a user to input a state in a dropdown, which would change the result in the second dropdown to only show cities from that state.  Once the city is selected, a button could be pressed to refresh the graph (I realize there's you can use manual with interact, but was unable to get this to function properly) and show the resultant data (covid cases over time).  I've had some success making the widgets, but I can't get the data to plot correctly.</p>

<p>This is my first time using widgets in Jupyter and I'm a bit lost what with interact, interactivity, display, and observe (not to mention the deprecated on_trait_change).  Here's what I have so far...</p>

<pre><code>from ipywidgets import interact, widgets
from bqplot import pyplot as plt
import pandas as pd

#make example DF
date_list = ['2020-02-01','2020-02-01','2020-02-01','2020-02-01','2020-02-02','2020-02-02','2020-02-02','2020-02-02']
state_list = ['CA','NY','CA','NY','CA','NY','CA','NY']
city_list = ['San Fran','NYC','LA','Albany','San Fran','NYC','LA','Albany']
cases_list = [0,0,0,0,2,6,4,8]

df = pd.DataFrame(index=date_list)
df['state'] = state_list
df['city'] = city_list
df['cases'] = cases_list

#getting unique state and city list sorted in alphabetical order
state_unique = df['state'].unique()
state_unique.sort()

state = widgets.Dropdown(
    options=['All'] + list(state_unique),
    value='CA', #indicates default starting value
    description='State:', #this is the label for the dropdown
)

city = widgets.Dropdown(
    description='City:',
)


# function that updates 'city' dropdown depending on value in 'state' dropdown
def list_cities(x):
    if state.value == 'All':
        city.options = ['']
        return city_list
    else:
        temp = ['All'] + sorted(df.loc[df['state'].eq(state.value),'city'].unique())
        city.options = temp

state.observe(list_cities, names = 'value') #the names part tells the observe the change name to look for, this is only looking for value changes



b_refresh = widgets.Button(
    description='Refresh',
    icon='fa-refresh',
    button_style='warning',
    layout=widgets.Layout(width='100px')
)

# plotting function
def set_plot(x_data,y_data):
    plt.plot(x_data, y_data)
    plt.show()

x = list(df.index.unique())
y = df.loc[\
    (df['city']==city.value)&amp;\
    (df['state']==state.value),'cases']

b_refresh.on_click(set_plot(x, y))

display (state,city,b_refresh)
</code></pre>
"
61592981,"<p>I have the following curl statement that is providing a response in json format:</p>

<pre><code>curl 'https://www.accenture.com/nl-en/searchbykeywords.search' \
 -H 'authority: www.accenture.com' \
 -H 'accept: application/json, text/javascript, */*; q=0.01' \
 -H 'dnt: 1' \
 -H 'x-requested-with: XMLHttpRequest' \
 -H 'user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36' \
 -H 'content-type: application/json; charset=UTF-8' \
 -H 'origin: https://www.accenture.com' \
 -H 'sec-fetch-site: same-origin' \
 -H 'sec-fetch-mode: cors' \
 -H 'sec-fetch-dest: empty' \
 -H 'referer: https://www.accenture.com/nl-en/search/results?srk=covid&amp;pg=1&amp;sb=0&amp;filter=' \
 -H 'accept-language: en-GB,en-US;q=0.9,en;q=0.8' \
 -H 'cookie: eVar46=covid' \
 --data-binary '{""k"":""covid"",""f"":1,""s"":10, ""sb"":0, ""ss"":"""" ,""cs"":""true""}' \
 --compressed
</code></pre>

<p>But when I'm trying to replicate this via Python with help of the requests module I'm not receiving back the json which is causing the decode error. </p>

<pre><code>import requests

with requests.Session() as session:

    header = {
        'authority': 'www.accenture.com', 
        'accept': 'application/json, text/javascript, */*; q=0.01' ,
        'dnt': '1',
        'x-requested-with': 'XMLHttpRequest',
        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36',
        'content-type': 'application/json; charset=UTF-8' ,
        'origin': 'https://www.accenture.com' ,
        'sec-fetch-site': 'same-origin', 
        'sec-fetch-mode': 'cors' ,
        'sec-fetch-dest': 'empty',
        'referer': 'https://www.accenture.com/nl-en/search/results?srk=covid&amp;pg=1&amp;sb=0&amp;filter=', 
        'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8',
        'cookie': 'eVar46=covid'
    }

    data = '{""k"":""COVID"",""f"":1,""s"":10, ""sb"":0, ""ss"":"""", ""cs"":""true""}'

    search_url = 'https://www.accenture.com/nl-en/searchbykeywords.search'

    r = session.post(search_url, headers=header, data=data)

    data = r.json()

    print(data)
</code></pre>

<p>Can you please help me out since the available answers didn't provide me with a working solution . Thanks</p>
"
61442670,"<p><a href=""https://i.stack.imgur.com/NFhiY.png"" rel=""nofollow noreferrer"">This is the model accuracy in train and validation</a></p>

<p><a href=""https://i.stack.imgur.com/61mfP.png"" rel=""nofollow noreferrer"">This is the model loss</a></p>

<p>Batch generator:</p>

<pre><code>train_batches = ImageDataGenerator(rotation_range=8).flow_from_directory(train_path,target_size=(224,224),  classes=['Covid','Normal','Pneumonia'],batch_size=64)
valid_batches = ImageDataGenerator().flow_from_directory(valid_path,target_size=(224,224), classes=['Covid','Normal','Pneumonia'],batch_size=32)
</code></pre>

<p>I'm using a pretrained model:</p>

<pre><code>model=keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_tensor=None,  input_shape=(224, 224, 3), pooling=None, classes=1000)
</code></pre>

<p>Performed regularisation:
regularizer = tf.keras.regularizers.l1(0.0001)</p>

<pre><code>for layer in model.layers:
    for attr in ['kernel_regularizer']:
        if hasattr(layer, attr):
          setattr(layer, attr, regularizer)
</code></pre>

<p>Used chopped off the last fully connected layers of the pretrained model and added the layers below:</p>

<pre><code>x = AveragePooling2D(pool_size=(4, 4))(last_layer)
x = Flatten(name=""flatten"")(x)
x = Dense(64, activation=""relu"",kernel_regularizer=regularizers.l2(0.001))(x)
x = Dropout(0.6)(x)
# x = Dropout(0.6)(x)

out = Dense(3, activation=""softmax"",name='output_layer')(x)
</code></pre>

<p>Froze the upper layers:</p>

<pre><code>for layer in custom_resnet_model.layers[:-7]:
    layer.trainable = False
</code></pre>

<p>Using Adam optimizer:</p>

<pre><code>custom_resnet_model.compile(Adam(lr=.0001),loss='binary_crossentropy',metrics=['accuracy'])
</code></pre>

<p>And the model fit:</p>

<pre><code>history = custom_resnet_model.fit_generator(train_batches, steps_per_epoch=36,
                    validation_data=valid_batches, validation_steps=18, epochs=25, verbose=2)
</code></pre>

<p>As you can see below, towards the end the validation loss is all over the place:</p>

<pre><code>Epoch 1/25
 - 67s - loss: 0.7458 - accuracy: 0.7076 - val_loss: 0.7266 - val_accuracy: 0.7584
Epoch 2/25

 - 64s - loss: 0.5467 - accuracy: 0.8139 - val_loss: 0.5276 - val_accuracy: 0.8022
Epoch 3/25
 - 62s - loss: 0.4723 - accuracy: 0.8543 - val_loss: 0.4393 - val_accuracy: 0.8336
Epoch 4/25
 - 62s - loss: 0.4274 - accuracy: 0.8800 - val_loss: 0.6082 - val_accuracy: 0.8384
Epoch 5/25
 - 62s - loss: 0.4017 - accuracy: 0.8862 - val_loss: 0.5227 - val_accuracy: 0.8490
Epoch 6/25
 - 62s - loss: 0.3698 - accuracy: 0.9004 - val_loss: 0.5691 - val_accuracy: 0.8532
Epoch 7/25
 - 63s - loss: 0.3524 - accuracy: 0.9093 - val_loss: 0.4616 - val_accuracy: 0.8425
Epoch 8/25
 - 63s - loss: 0.3379 - accuracy: 0.9183 - val_loss: 0.4604 - val_accuracy: 0.8467
Epoch 9/25
 - 62s - loss: 0.3206 - accuracy: 0.9248 - val_loss: 0.5499 - val_accuracy: 0.8526
Epoch 10/25
 - 61s - loss: 0.3240 - accuracy: 0.9244 - val_loss: 0.4745 - val_accuracy: 0.8526
Epoch 11/25
 - 63s - loss: 0.3134 - accuracy: 0.9297 - val_loss: 0.4533 - val_accuracy: 0.8567
Epoch 12/25
 - 62s - loss: 0.2995 - accuracy: 0.9337 - val_loss: 0.5668 - val_accuracy: 0.8555
Epoch 13/25
 - 63s - loss: 0.2898 - accuracy: 0.9404 - val_loss: 0.6349 - val_accuracy: 0.8603
Epoch 14/25
 - 62s - loss: 0.2845 - accuracy: 0.9386 - val_loss: 0.5612 - val_accuracy: 0.8650
Epoch 15/25
 - 63s - loss: 0.2961 - accuracy: 0.9330 - val_loss: 0.7284 - val_accuracy: 0.8579
Epoch 16/25
 - 64s - loss: 0.2759 - accuracy: 0.9429 - val_loss: 0.4720 - val_accuracy: 0.8650
Epoch 17/25
 - 62s - loss: 0.2707 - accuracy: 0.9482 - val_loss: 0.9979 - val_accuracy: 0.8650
Epoch 18/25
 - 63s - loss: 0.2744 - accuracy: 0.9416 - val_loss: 0.8098 - val_accuracy: 0.8733
Epoch 19/25
 - 63s - loss: 0.2771 - accuracy: 0.9428 - val_loss: 0.1989 - val_accuracy: 0.8662
Epoch 20/25
 - 62s - loss: 0.2647 - accuracy: 0.9440 - val_loss: 0.8921 - val_accuracy: 0.8686
Epoch 21/25
 - 63s - loss: 0.2566 - accuracy: 0.9478 - val_loss: 0.3362 - val_accuracy: 0.8745
Epoch 22/25
 - 62s - loss: 0.2645 - accuracy: 0.9402 - val_loss: 1.2044 - val_accuracy: 0.8662
Epoch 23/25
 - 63s - loss: 0.2550 - accuracy: 0.9472 - val_loss: 0.6615 - val_accuracy: 0.8745
Epoch 24/25
 - 62s - loss: 0.2486 - accuracy: 0.9519 - val_loss: 0.4722 - val_accuracy: 0.8674
Epoch 25/25
 - 62s - loss: 0.2542 - accuracy: 0.9507 - val_loss: 0.8232 - val_accuracy: 0.8721
</code></pre>

<p><strong>I have posted the code so that someone can pointout if I'm doing something wrong.</strong></p>
"
61352148,"<p>So I followed the answer in this question (<a href=""https://stackoverflow.com/questions/60116419/extract-entity-from-dataframe-using-spacy"">Extract entity from dataframe using spacy</a>) and that solved me being able to iterate on a DF. </p>

<p>Issues I am facing is trying to take these results, add a column from original df then put all this into a new df. I want the DOI from original df, the entity text and entity labels from the NER.</p>

<p>Code to grab and put into list:</p>

<pre><code>entities=[]
nlp = spacy.load(""en_ner_bionlp13cg_md"")
for i in df['Abstract'].tolist():
    doc = nlp(i)
    for entity in doc.ents:
        entities.append((df.DOI, entity.text , entity.label_))
</code></pre>

<p>Then I take the entities list and feed into a new df:</p>

<pre><code>df_ner = pd.DataFrame.from_records(entities, columns =['DOI', 'ent_name', 'ent_type'])
</code></pre>

<p>Unfortunately, only the first records gets loaded into the df. What am i missing?</p>

<pre><code>DOI ent_name    ent_type
0   3 10.7501/j.issn.0253-2670.2020.... COVID-19    GENE_OR_GENE_PRODUCT
1   3 10.7501/j.issn.0253-2670.2020.... ACE2    GENE_OR_GENE_PRODUCT
2   3 10.7501/j.issn.0253-2670.2020.... angiotensin converting enzyme II    GENE_OR_GENE_PRODUCT
3   3 10.7501/j.issn.0253-2670.2020.... ACE2    GENE_OR_GENE_PRODUCT
4   3 10.7501/j.issn.0253-2670.2020.... UniProt GENE_OR_GENE_PRODUCT
</code></pre>
"
61059457,"<p>I'm writing my own code to analyse/visualise COVID-19 data from the European CDC.
<a href=""https://opendata.ecdc.europa.eu/covid19/casedistribution/csv"" rel=""nofollow noreferrer"">https://opendata.ecdc.europa.eu/covid19/casedistribution/csv</a>'</p>

<p>I've got a simple code to extract the data and make plots with cumulative deaths against time, and am trying to add functionality.</p>

<p>My aim is something like the attached graph, with all countries time shifted to match at (in this case the 5th death) I want to make a general bit of code to shift countries to match at the 'n'th death. 
<a href=""https://ourworldindata.org/grapher/covid-confirmed-deaths-since-5th-death"" rel=""nofollow noreferrer"">https://ourworldindata.org/grapher/covid-confirmed-deaths-since-5th-death</a></p>

<p>The current way I'm trying to do this is to have a maze of ""if group is 'country' shift by ..."" terms.</p>

<p>Where ... is a lookup to find the date for the particular 'country' when there were 'n' deaths, and to interpolate fractional dates where appropriate.</p>

<p>i.e. currently deaths are assigned as 00:00 day/month, but the data can be shifted by 2/3 a day as below.</p>

<p>datetime       cumulative deaths<br>
00:00  15/02  80
00:00  16/02  110</p>

<p>my '...' should give 16:00 15/02</p>

<p>I'm working on this right now but it doesn't feel very efficient and I'm sure there must be a much simpler way that I'm not seeing. </p>

<p>Essentially despite copious googling I can't seem to find a simple way of automatically shifting a bunch of timeseries to match at a particular y value, which feels like it should have some built-in functionality, i.e. a Lookup with interpolation.</p>

<pre><code>####Live url (I've downloaded my own csv and been calling that for code development)
url = 'https://opendata.ecdc.europa.eu/covid19/casedistribution/csv'

dataraw = pd.read_csv(url)

#extract relevanty colums
data = dataraw.loc[:,[""dateRep"",""countriesAndTerritories"",""deaths""]]

####convert date format
data['dateRep'] = pd.to_datetime(data['dateRep'],dayfirst=True)

####sort by date
data = data.sort_values([""dateRep""],ascending=True)

data['cumdeaths'] = data.groupby(['countriesAndTerritories']).cumsum()




##### limit to countries with cumulative deaths &gt; 500

data = data.groupby('countriesAndTerritories').filter(lambda x:x['cumdeaths'].max() &gt;500)

###### remove China from data for now as it doesn't match so well with dates
data = data.groupby('countriesAndTerritories').filter(lambda x:(x['countriesAndTerritories'] != ""China"").any())

##### only recent dates
data = data[data['dateRep'] &gt; '2020-03-01']

print(data)
</code></pre>
"
60968880,"<p><a href=""https://i.stack.imgur.com/lCmqT.png"" rel=""nofollow noreferrer"">This is the output I am getting.</a>I am trying to place a label at the very top and centre of the top area(centre top), but when I try to do it it just goes out of the screen.Please help by changing the only code I am writing.
Thanks.
What I tried.</p>

<pre><code>.py file:
from kivy.app import App
from kivy.uix.floatlayout import FloatLayout
from kivy.config import Config
from kivy.uix.widget import Widget
from kivy.graphics import Line, Color
from kivy.lang import Builder
from kivy.uix.image import Image
from kivy.uix.label import Label
from kivy.uix.relativelayout import RelativeLayout
from kivy.uix.boxlayout import BoxLayout
from kivy.uix.anchorlayout import AnchorLayout


class kivyclass(Widget):
    pass


class MainApp(App):
    def build(self):
        return kivyclass()

if __name__ == '__main__':
    MainApp().run()





.kv file:
#:import utils kivy.utils

&lt;kivyclass&gt;:
    canvas.before:
        Color:
            rgba: utils.get_color_from_hex('#d6fffc')

        Rectangle:
            size: self.size
            pos: self.pos
    AnchorLayout:
        anchor_x: 'center'
        anchor_y: 'top'
        Label:
            id: labcovid
            text: 'Covid-19 Uttarakhand'
            font_size: root.width/15
            font_name: 'vollkorn.ttf'
            color: utils.get_color_from_hex('#4a4a4a')


</code></pre>

<p>this is the output I am getting</p>
"
60841051,"<p>so this website im trying to scrub data from </p>

<p>nytimes.com/interactive/2020/us/coronavirus-us-cases.html</p>

<p>is only printing the first 9 states due to a ""show more"" tab hiding more tables.</p>

<pre><code>import pandas as pd
tables = pd.read_html(""nytimes.com/interactive/2020/us/coronavirus-us-cases.html"")
print(Tables[0])
</code></pre>

<p>Is there any way to have it print out the hidden tables? I was thinking along the lines of using selenium to click on the ""show more"" option for me but was unsure that would be an efficient way or not</p>
"
61686963,"<p>I have a dictionary of dataframes (248 countries) that I want to concat into one dataframe.</p>

<p>the data frame is called dfs, so if I want to access the contents for Albania I use:</p>

<pre><code>dfs[""Albania""]
</code></pre>

<p>I used the below code to do this with 4 dataframes earlier while learning how to merge dataframes. </p>

<p>Can I adapt this to work as a loop with the 248 countries that I want to include now, and also set the key for each concatenated df as the country name?</p>

<p>I have made very little progress on this in the last few hours!</p>

<pre><code>datasets = [df_ireland, df_italy, df_france, df_germany]

frames = []

for frame in datasets:
    frames.append(frame)

df_join = pd.concat(frames, keys=['Ireland', 'Italy', 'France', 'Germany'])
</code></pre>

<p>Here is the loop I used to build the dictionary in case that is of any benefit:</p>

<pre><code># Import the libraries
import requests
import requests_cache

import json

import pandas as pd
import numpy as np
from pandas import Series, DataFrame, json_normalize

from datetime import datetime

# Make an API call and store the response.
sum_url = 'https://api.covid19api.com/summary'
sum_data = requests.get(sum_url)

# Store the API response in a variable.
available_sum_data = sum_data.json()
sum_df = json_normalize(available_sum_data[""Countries""])

# Make a list of countries
countries = sum_df['Country'].tolist()

# Make a empty dictionary to hold dataframes
dfs = {}


for country in countries:
    print(country)

    try:
        # check the cache and if old data call api
        requests_cache.install_cache(f'{country} cache', expire_after=21600)
        url = f'https://api.covid19api.com/total/dayone/country/{country}'
        data = requests.get(url)

        # test if cache used
        print(data.from_cache)

    except requests.exceptions.RequestException as e:  # This is the correct syntax
        print(e)
        print('cant print' + country)

    try:
        available_data = data.json()
        dfs[f'{country}'] = pd.json_normalize(available_data)


        # Create Daily new cases column &amp; SMA
        dfs[f'{country}'][""New Cases""] = dfs[f'{country}']['Confirmed'].diff()
        dfs[f'{country}'][""SMA_10 New Cases""] = dfs[f'{country}'][""New Cases""].rolling(window=10).mean()

        # Create Daily new deaths column &amp; SMA
        dfs[f'{country}'][""New Deaths""] = dfs[f'{country}']['Deaths'].diff()
        dfs[f'{country}'][""SMA_10 New Deaths""] = dfs[f'{country}'][""New Deaths""].rolling(window=10).mean()


    except:
        print('cant format to json: ' + country)
</code></pre>
"
60798547,"<p>I'm making a jupyter notebook for accessing and plotting number of confirmed cases of corona.  You can access my notebook here: <a href=""https://gitlab.com/knjakob-blomquist/corona-data-analysis"" rel=""nofollow noreferrer"">https://gitlab.com/knjakob-blomquist/corona-data-analysis/</a> or clone it via:</p>

<pre><code>git clone git@gitlab.com:knjakob-blomquist/corona-data-analysis.git 
</code></pre>

<p>The data is downloaded as a wide format csv-file, and imported to a pandas DataFrame as is, so that there are columns for provinces, regions/countries, Lat-, Long-coordinates, individual columns for cumulative sum confirmed case for each province each day (dates are strings) for each province/country. Se figure via link here <a href=""https://gitlab.com/knjakob-blomquist/corona-data-analysis/-/blob/master/corona_database_wide_format.png"" rel=""nofollow noreferrer"">corona_database_wideformat.png</a>.</p>

<p>I would like to know if there is a simpler way to clean the data for plotting / apply curve fit to the data than the way I did here (for example using pd.melt or pd.wide_to_short or something). I feel that there should be some standard way but I can't seem to find it:</p>

<pre><code># load libraries and set plot style 
%pylab inline
import datetime as dt
import pandas as pd

# Download daily updates of corona confirmed cases from
# https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases
import requests
url = 'https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_19-covid-Confirmed.csv&amp;filename=time_series_2019-ncov-Confirmed.csv'
r = requests.get(url, allow_redirects=True)

with open('corona_data.csv', 'wb') as f:
    f.write(r.content)

# Import the data from csv file into a pandas DataFrame
# and do initial processing
df = pd.read_csv('corona_data.csv')

# remove some columns as I'm only interested in total 
# per each country
df = df.drop(columns=['Province/State', 'Lat','Long'])

# group and sum all data into individual countries from their provinces
df = df.groupby('Country/Region').sum()

# invert the table so that dates become index
df = df.stack().unstack(0)

# process the date format from date strings
# add a column for dates
df['date'] = df.index

# string -&gt; datetime format and add to day column
df['day'] = pd.to_datetime(df.date, format='%Y%m%d', infer_datetime_format=True)

# make 21 st of March into day 0
df['day'] = df['day'] - df['day'][0]
df.day = (df['day']).dt.days + 1
</code></pre>

<p>With the code above I will get the following table see figure in link: <a href=""https://gitlab.com/knjakob-blomquist/corona-data-analysis/-/blob/master/corona_database_cleaned.png"" rel=""nofollow noreferrer"">corona_database_cleaned.png</a>
And with that format I can perform curve fits etc. 
Any suggestions are appreciated</p>
"
60926439,"<p>I just learn Plotly and I am trying to make my python code better. This is my dataframe:
<a href=""https://i.stack.imgur.com/wESAA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wESAA.png"" alt=""enter image description here""></a></p>

<p>To visualize, this is my code but I think it could be done with For loop:</p>

<pre><code>fig = go.Figure()

fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,0], mode ='lines', name = 'Australian Capital Territory'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,1], mode ='lines', name = 'New South Wales'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,2], mode ='lines', name = 'Northern Territory'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,3], mode ='lines', name = 'Queensland'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,4], mode ='lines', name = 'South Australia'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,5], mode ='lines', name = 'Tasmania'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,6], mode ='lines', name = 'Victoria'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,7], mode ='lines', name = 'Western Australia'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,8], mode ='lines', name = 'New Zealand'))

annotations = []

annotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,
                              xanchor='left', yanchor='bottom',
                              text=""Covid 19 Death Cases between Australian' states vs New Zealand"",
                              font=dict(family='Arial',
                                        size=18,
                                        color='rgb(37,37,37)'),
                              showarrow=False))

fig.update_layout(legend=dict(y=0.5, traceorder='reversed', font_size=16), 
                  plot_bgcolor='white',
                  annotations=annotations,
                  xaxis_title=""Date"",
                  yaxis_title=""Number of Death""
                 )

fig.show()
</code></pre>

<p>I am trying to use For loop for this part:</p>

<pre><code>fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,0], mode ='lines', name = 'Australian Capital Territory'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,1], mode ='lines', name = 'New South Wales'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,2], mode ='lines', name = 'Northern Territory'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,3], mode ='lines', name = 'Queensland'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,4], mode ='lines', name = 'South Australia'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,5], mode ='lines', name = 'Tasmania'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,6], mode ='lines', name = 'Victoria'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,7], mode ='lines', name = 'Western Australia'))
fig.add_trace(go.Scatter(x = anz_d_df.index , y = anz_d_df.iloc[:,8], mode ='lines', name = 'New Zealand'))
</code></pre>

<p>Any thought on how to use For loop for this, will be much appreciated. 
This is an example from Plotly:</p>

<pre><code>import plotly.graph_objects as go
import numpy as np

title = 'Main Source for News'
labels = ['Television', 'Newspaper', 'Internet', 'Radio']
colors = ['rgb(67,67,67)', 'rgb(115,115,115)', 'rgb(49,130,189)', 'rgb(189,189,189)']

mode_size = [8, 8, 12, 8]
line_size = [2, 2, 4, 2]

x_data = np.vstack((np.arange(2001, 2014),)*4)

y_data = np.array([
    [74, 82, 80, 74, 73, 72, 74, 70, 70, 66, 66, 69],
    [45, 42, 50, 46, 36, 36, 34, 35, 32, 31, 31, 28],
    [13, 14, 20, 24, 20, 24, 24, 40, 35, 41, 43, 50],
    [18, 21, 18, 21, 16, 14, 13, 18, 17, 16, 19, 23],
])

fig = go.Figure()

for i in range(0, 4):
    fig.add_trace(go.Scatter(x=x_data[i], y=y_data[i], mode='lines',
        name=labels[i],
        line=dict(color=colors[i], width=line_size[i]),
        connectgaps=True,
    ))

    # endpoints
    fig.add_trace(go.Scatter(
        x=[x_data[i][0], x_data[i][-1]],
        y=[y_data[i][0], y_data[i][-1]],
        mode='markers',
        marker=dict(color=colors[i], size=mode_size[i])
    ))

fig.update_layout(
    xaxis=dict(
        showline=True,
        showgrid=False,
        showticklabels=True,
        linecolor='rgb(204, 204, 204)',
        linewidth=2,
        ticks='outside',
        tickfont=dict(
            family='Arial',
            size=12,
            color='rgb(82, 82, 82)',
        ),
    ),
    yaxis=dict(
        showgrid=False,
        zeroline=False,
        showline=False,
        showticklabels=False,
    ),
    autosize=False,
    margin=dict(
        autoexpand=False,
        l=100,
        r=20,
        t=110,
    ),
    showlegend=False,
    plot_bgcolor='white'
)

annotations = []

# Adding labels
for y_trace, label, color in zip(y_data, labels, colors):
    # labeling the left_side of the plot
    annotations.append(dict(xref='paper', x=0.05, y=y_trace[0],
                                  xanchor='right', yanchor='middle',
                                  text=label + ' {}%'.format(y_trace[0]),
                                  font=dict(family='Arial',
                                            size=16),
                                  showarrow=False))
    # labeling the right_side of the plot
    annotations.append(dict(xref='paper', x=0.95, y=y_trace[11],
                                  xanchor='left', yanchor='middle',
                                  text='{}%'.format(y_trace[11]),
                                  font=dict(family='Arial',
                                            size=16),
                                  showarrow=False))
# Title
annotations.append(dict(xref='paper', yref='paper', x=0.0, y=1.05,
                              xanchor='left', yanchor='bottom',
                              text='Main Source for News',
                              font=dict(family='Arial',
                                        size=30,
                                        color='rgb(37,37,37)'),
                              showarrow=False))
# Source
annotations.append(dict(xref='paper', yref='paper', x=0.5, y=-0.1,
                              xanchor='center', yanchor='top',
                              text='Source: PewResearch Center &amp; ' +
                                   'Storytelling with data',
                              font=dict(family='Arial',
                                        size=12,
                                        color='rgb(150,150,150)'),
                              showarrow=False))

fig.update_layout(annotations=annotations)

fig.show()
</code></pre>
"
60744228,"<p>I am trying to concatenate some dataframes but I getting the wrong order of columns after done.</p>

<p>My code is:</p>

<pre><code>def numOfDays(date1, date2): 
return (date2-date1).days

first_case_report = datetime.strptime('22-01-2020', '%d-%m-%Y')
NumOfdays_reported = numOfDays(first_case_report, datetime.today())

column_names = ['Province/State','Country/Region','Last Update','Confirmed','Deaths','Recovered']
df = pd.DataFrame(columns = column_names)
df.to_csv(index=True)

df.head()
Output:
    Province/State  Country/Region  Last Update Confirmed   Deaths  Recovered

ind = 0
while ind &lt; NumOfdays_reported:
    date_report = (pd.Timestamp(first_case_report) + pd.DateOffset(days=ind)).strftime('%m-%d-%Y')
    url = ""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{0}.csv"".format(date_report)
    source = pd.read_csv(url,index_col=0,parse_dates=[0])

    df = pd.concat([df,source], sort=True)
    ind += 1   

df.head()
Output:
Confirmed   Country/Region  Deaths  Last Update Latitude    Longitude   Province/State  Recovered
</code></pre>

<p>The last df.head() shows that the columns are messed up, for example compare the column Province/State with the df.head() executed, why is that happening?</p>

<p>Any ideas would be highly appreciated.</p>

<p>Thanks a lot beforehand.</p>
"
61482578,"<p>I have a dataframe which looks like the following (Name of the first dataframe(image below) is <code>relevantdata</code> in the code):</p>

<p><a href=""https://i.stack.imgur.com/bh6Ru.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bh6Ru.png"" alt=""enter image description here""></a></p>

<p>I want the dataframe to be transformed to the following format:</p>

<p><a href=""https://i.stack.imgur.com/9yA4x.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9yA4x.png"" alt=""enter image description here""></a></p>

<p>Essentially, I want to get the relevant confirmed number for each Key for all the dates that are available in the dataframe. If a particular date is not available for a Key, we make that value to be zero. </p>

<p>Currently my code is as follows (A try/except block is used as some Keys don't have the the whole range of dates, hence a Keyerror occurs the first time you refer to that date using <code>countrydata.at[date,'Confirmed']</code> for the respective Key, hence the <code>except</code> block will make an entry of zero into the dictionary for that date):</p>

<pre><code>relevantdata = pandas.read_csv('https://raw.githubusercontent.com/open-covid-19/data/master/output/data_minimal.csv')
dates = relevantdata['Date'].unique().tolist()
covidcountries = relevantdata['Key'].unique().tolist()
data = dict()
data['Country'] = covidcountries
confirmeddata = relevantdata[['Date','Key','Confirmed']]

for country in covidcountries:
    for date in dates:
        countrydata = confirmeddata.loc[lambda confirmeddata: confirmeddata['Key'] == country].set_index('Date')
        try:
            if (date in data.keys()) == False:
                data[date] = list()
                data[date].append(countrydata.at[date,'Confirmed'])
            else:
                data[date].append(countrydata.at[date,'Confirmed'])
        except:
            if (date in data.keys()) == False:
                data[date].append(0)
            else:
                data[date].append(0)
finaldf = pandas.DataFrame(data = data)

</code></pre>

<p>While the above code accomplished what I want in getting the dataframe in the format I require, it is way too slow, having to loop through every key and date. I want to know if there is a better and faster method to doing the same without having to use a nested for loop. Thank you for all your help. </p>
"
61075665,"<p>I've had issues with my project because I'm getting unexpected behaviors when I try to compare two strings, one from a pandas dataframe and one from code. 
I loaded my pandas Dataframe with columns: ['Country','Region','City','Population','Covid Cases'] to find an eventual correlation between the last two variables. </p>

<pre class=""lang-py prettyprint-override""><code>df = pd.DataFrame(columns = ['Country','Region','City','Population','Cases'])
</code></pre>

<p>I wanted to save all populations of a given area (e.g. Southern Italy) in a list to plot it, so I did this, using list comprehension:  </p>

<pre class=""lang-py prettyprint-override""><code>pop_sud = [int(df.iloc[i][3]) for i in range(len(df.index)) if str(df.iloc[i][0])=='Italy' 
if str(df.iloc[i][1])=='Sicilia']
</code></pre>

<p>The result is that the second 'if' statement appears to be false always, giving me an empty list, which is not the case as shown in a  small debug I made while printing all elements of the Region column with the word 'Sicilia':</p>

<pre><code> Region type: &lt;class 'str'&gt;
 ---
 Puglia Sicilia
 Lombardia Sicilia
 Emilia Sicilia
 Sicilia Sicilia &lt;--
 Toscana Sicilia
 Veneto Sicilia
 Veneto Sicilia
</code></pre>

<p>I also tried this version but still gives me an empty list because the if check is not passed:</p>

<pre class=""lang-py prettyprint-override""><code>cases_sud = [int(df.iloc[i][4]) for i in range(len(df.index)) if df.iloc[i][0] == 'Italy' 
if df.loc[i][1] in ['Sicilia','Puglia','Campania']]
</code></pre>

<p>I also tried concatenating the if statements with the keyword <code>and</code> obtaining the same result.
Why does this happen?</p>

<p><strong>Update</strong>:<br>
Thank you all for your answers. By reading WGP's answer I found out that my dataset had a space before all region names, therefore not even reading the word! I also tried Gergely's method and it worked despite the space in the dataset. Thank you all! :)</p>
"
61044298,"<p>I am currently participating in the Kaggle competition for forecasting COVID-19 cases (week 3).  The goal is to predict COVID-19 cases from a dataset with daily cases for every country.
<a href=""https://www.kaggle.com/c/covid19-global-forecasting-week-3"" rel=""nofollow noreferrer"">https://www.kaggle.com/c/covid19-global-forecasting-week-3</a>
<br><br>
My input data for the model look like this:</p>

<blockquote>
  <p>t-10, t-9, t-8, ..., t ====> predict t+1<br>
  t-9, t-8, t-7, ..., t+1 =====> predict t+2<br>
  ......<br>
  Where t is a time step<br>
  <br>
  After I fit the model, I am trying to predict next 33 time-steps<br></p>
</blockquote>

<p>I'm trying to use Convolutional NNs and LSTMs,
My model looks like this: </p>

<pre><code>model = Sequential()
model.add(Conv1D(filters=250, kernel_size=3, activation='relu', input_shape=(10,1), padding='same', kernel_initializer='truncated_normal'))
model.add(Dropout(0.2))
model.add(LSTM(64, activation='relu', kernel_initializer='truncated_normal'))
model.add(Dropout(0.2))
model.add(Dense(16, activation='relu', kernel_initializer='truncated_normal'))
model.add(Dropout(0.2))
model.add(Dense(1))
model.compile(loss='mse', optimizer='adam')
</code></pre>

<p>I'm fitting 5 different models and then averaging their results.<br>
I've tried a lot of different models (by changing the layers or how many nodes there are) but this one seems the best so far.
I'm not sure why but it either doesn't fit well or it overfits. Either case, it still makes awful predictions like 79 cases in one run and 10^4 cases in another.
<br>
Here are some plots of my model (the second one is what I am trying to achieve):<br>
<a href=""https://i.stack.imgur.com/y5yo4.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/y5yo4.png"" alt=""bad prediction""></a>
<a href=""https://i.stack.imgur.com/9AE4Y.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9AE4Y.png"" alt=""good prediction""></a>
<br>
Can you please give me some advice regarding this problem? Should I use a different model, do something on my data, change the number of epochs, etc ...
<br>
<br>
Thank you in advance!</p>
"
61239669,"<p>I'm trying to show the fetched data on an API to the Django template. </p>

<p>Here's what I've tried on
<code>home.html</code></p>

<pre><code>&lt;h1&gt;Title: {{data.title}}&lt;/h1&gt;
</code></pre>

<p>Here's my <code>views.py</code> which gets the data from <code>services.py</code></p>

<pre><code>class IndexData(TemplateView):
    def get(self, request):
        article_data = services.get_data()
        return render(request, 'pages/home.html', article_data)
</code></pre>

<p>Here's the <code>services.py</code></p>

<pre><code>def get_data(title, url, description, body, datePublished):
  url = 'https://contextualwebsearch-websearch-v1.p.rapidapi.com/api/Search/WebSearchAPI'
    params = {""autoCorrect"": ""true"", ""pageNumber"": ""1"", ""pageSize"": ""10"", ""q"": ""police"", ""safeSearch"": ""true"" }
    headers = {...}
    r = requests.get(url, headers=headers, params=params)
    data = r.json()
    article_data = {'data': data['value']}
    return article_data
</code></pre>

<p>The returned <code>json</code> is </p>

<pre><code>{   ""_type"":""all"",
    ""didUMean"":"""",
    ""totalCount"":2923,
    ""relatedSearch"":[
       ""coronavirus"",
       ""new york"",
       ""post"",
       ""getty"",
       ""times"",
       ""china"",
       ""council"",
       ""shares"",
       ""americans"",
       ""pandemics"",
       ""prime"",
       ""19 crisis""

 ],
    ""value"":[      
      {         
          ""title"":""COVID-19 And The Failure Of Populism"",
          ""url"":""https://www.forbes.com/sites/riskmap/2020/04/02/covid-19-and-the-failure-of-populism/"",
          ""description"":""Populist presidents, reliant on their need to constantly convey positive messaging that bolsters their support, have struggled to take the decisive, forward-looking action that the coronavirus crisis demands."",
          ""body"":"").\nHow will the pandemic play out in these countries?\nSteering countries through the pandemic and an eventual recovery will then be the responsibility of leaders who will have lost credibility, as well as the veneer of their all is well message. The narrative that allowed people in certain countries to latch on to something they approved of in their leader (the economy is doing well, the corruption of previous regimes was intolerable, there was no alternative, etc) while disregarding all the caveats of things they disliked, may now give way to harsher judgement. Hopefully, if there is any silver lining, the public might start trusting experts and reliable sources of information again, and will begin to question their leaders more actively.\nEither way, populist leaders like Trump, AMLO, and Bolsonaro will each have demonstrated a great inability to manage any criticism, no matter who it comes from or how constructive it might be. On the contrary, they seem to double-down"",
     ""keywords"":"""",
     ""language"":""en"",
     ""isSafe"":true,
     ""datePublished"":""2020-04-02T11:00:00"",
     ""provider"":{
        ""name"":""forbes""

 },
          ""image"":{
             ""url"":""https://thumbor.forbes.com/thumbor/fit-in/1200x0/filters%3Aformat%28jpg%29/https%3A%2F%2Fspecials-images.forbesimg.com%2Fdam%2Fimageserve%2F99b82bcbe089442095046d2dbb9ecbf9%2F0x0.jpg%3Ffit%3Dscale"",
            ""height"":800,
        ""width"":1200,
        ""thumbnail"":""https://rapidapi.contextualwebsearch.com/api/thumbnail/get?value=37416569554313599"",
        ""thumbnailHeight"":200,
        ""thumbnailWidth"":300,
        ""base64Encoding"":null,
        ""name"":null,
        ""title"":null,
        ""imageWebSearchUrl"":null

}

}
</code></pre>

<p>What did I miss?</p>
"
61115229,"<p>I would like to get the axes (x, y) from the peak of the plot (the final part of a plot) to show the last amount I get from a COVID prediction in my country.</p>

<hr>

<p><strong>Code:</strong></p>

<pre class=""lang-py prettyprint-override""><code>date_pred = start_date + datetime.timedelta(days=days_future)
start_date_str = start_date.strftime('%d %b, %Y')
date_pred_str = date_pred.strftime('%d %b, %Y')

plt.figure(figsize = (10, 6))
plt.plot(adjusted_dates, y)
plt.plot(future_forecast_days, svm_prediction, linestyle='dashed', color='red')
plt.title('CODVID-19 30 days prediction', size = 20)
plt.xlabel('30 days prediction', size = 13)
plt.ylabel('Cases', size = 13)
plt.legend([f'Confirmed cases | Growth rate: {round(growth_rate)}%', f'SVM predictions | MAX: {int(round(svm_prediction[-1]))}'])
plt.figtext(x = 0.14, y = 0.72, s = f'from: {start_date_str} \nto:     {date_pred_str}')

plt.figtext(x = 0.78, y = 0.83, s = f'{int(round(svm_prediction[-1]))} --&gt;')
plt.figtext(x = 0.45, y = 0.25, s = f'{int(np.array(df.Confirmed)[-1])} --&gt;')

plt.xticks(size=10)
plt.yticks(size=10)
plt.show()
</code></pre>

<hr>

<p><strong>Expected output:</strong></p>

<p>The idea is to replace x, y in <code>plt.figtext</code> from the actual plot or the prediction plot (in here I'm showing just the prediction value):</p>

<p><code>plt.figtext(x = x_pred_final, y = y_pred_final, s = f'{int(round(svm_prediction[-1]))} --&gt;')</code></p>

<p><code>plt.figtext(x = x_actual_final, y = y_actual_final, s = f'{int(np.array(df.Confirmed)[-1])} --&gt;')
</code></p>

<p><a href=""https://i.stack.imgur.com/pYSXh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/pYSXh.png"" alt=""enter image description here""></a></p>
"
61136746,"<p>Hello There I am Tim and I am creating this code that will extract all covid19 cases in the whole world
I want to create a pie with the data that I extract</p>

<pre><code>import datetime # So the user can see what time did he/she update the covid19 lists
import time # I use time.sleep to make stop CPU throttling for very slow systems
print(""Importing Tkinter"")# I add This Callouts so the user can understand what is happening in the background 
from tkinter import *
time.sleep(1)
print(""Tkinter Imported"")
print(""Importing Tkinter Messagebox"")
from tkinter import messagebox
time.sleep(1)
print(""Tkinter Messagebox Imported"")
print(""Importing COVID19Py"")
import COVID19Py
time.sleep(1)
print(""COVID19Py Imported"")
print(""Importing Pandas"")
import pandas as pd
time.sleep(1)
print(""Pandas Imported"")
def corona(conf_list):
    d = pd.DataFrame.from_dict(conf_list)
    d = pd.concat([d, d['coordinates'].apply(pd.Series),d['latest'].apply(pd.Series)], axis=1)
    d.drop(columns= ['coordinates', 'latest'], inplace= True)
    return d
def confirmed_wrld():
    messagebox.showinfo('Wait',""This Might Take A Min or More"")
    conf_list = covid19.getLocations(rank_by='confirmed')
    df = corona(conf_list)
    df.to_excel('confirmed.xlsx')
    print(""Confirmed.xlsx is updated on "" + str(datetime.datetime.now()))
    messagebox.showinfo('Saved','Saved In confirmed.xlsx')
def ph():
    messagebox.showinfo(""Wait"",""This may take a few minutes"")
    location = covid19.getLocationByCountryCode(""PH"")
    df = corona(location)
    df.to_excel('ph.xlsx')
    print(""Ph.xlsx is updated on "" + str(datetime.datetime.now()))
    messagebox.showinfo('Saved','Saved in PH.xlsx')
def find():
    messagebox.showinfo(""Wait"",""This may take a few minutes"")
    code = find_Entry.get()
    findLocation = covid19.getLocationByCountryCode(code)
    df = corona(findLocation)
    df.to_excel(code + "".xlsx"")
    print(code + "".xlsx is updated on "" + str(datetime.datetime.now()))
    messagebox.showinfo(""Saved"", ""Saved in"" + code +"".xlsx"")

print(""Connecting In Johns Hopkins University's(jhu) Database"")
covid19 = COVID19Py.COVID19(data_source=""jhu"")
print(""This may take a few seconds depending on your internet connection"")
time.sleep(1)
print(""Connection Done"")
print(""exiting CLI"")
print(""Opening GUI"")
print(""""""The list is not updating real time each country should report new covid19 cases in JHU so they can update their database.
But the list will be updated day by day &lt;3"""""")
root = Tk()
messagebox.showinfo(""Special Thanks"",""Special Thanks For The FrontLiners Out There Trying To Find Cure And Helping Serve Their Country And The World #BeatCovid19!"")
root.geometry(""400x300"")
root.title(""CoronaVirusLocator Version 1.4"")

confirmedBtn = Button(text=""confirmed cases death and recoveries of COVID19"", command = confirmed_wrld)
confirmedBtn.pack()

phBtn = Button(text = ""Covid19 Cases in the PH"",command = ph)
phBtn.pack()

find_Entry = Entry()
find_Entry.pa ck() 

findBtn = Button(text = ""Search By Country Code eg.(PH)"", command = find)
findBtn.pack()
root.mainloop()
print(""Quiting"")
print(""Thanks For Using This Application"")
time.sleep(2)
print(""Confirmed Quit"")
</code></pre>

<p>i tried tutorials online and those did not work.
i try to save the output as a xlsx file and i work now i just need to make a pie using those data 
i use pandas to save json file as a xlsx file </p>
"
61090901,"<p>I like to obtain actual informaction about the numbers of infected from this website: <a href=""https://www.gov.pl/web/koronawirus/wykaz-zarazen-koronawirusem-sars-cov-2"" rel=""nofollow noreferrer"">https://www.gov.pl/web/koronawirus/wykaz-zarazen-koronawirusem-sars-cov-2</a></p>

<p>my code looks like:</p>

<pre><code>import requests
from bs4 import BeautifulSoup
adresURL = 'https://www.gov.pl/web/koronawirus/wykaz-zarazen-koronawirusem-sars-cov-2'
res = requests.get(adresURL)
soup = BeautifulSoup(res.text, 'html.parser')
data = soup.select('.details-property-value')
print(data)
</code></pre>

<p>as a result I'm receiving:</p>

<pre><code>[&lt;div class=""details-property-value"" tabindex=""0""&gt;{{selectedRecord[commonColumns[index]] || '-'}}&lt;/div&gt;]
</code></pre>

<p>Any ideas how to get value of fields ? Am i missing sth ?</p>
"
61002224,"<p>I want to store the error message and continue the execution but when I store the error message using the except exception e:  then I am not able to continue the execution. The function stops execution if URL does not get the HTTP URL, the function gives an error if </p>

<pre><code>url=""www.boomlive.in/fact-file/did-the-race-to-5g-cause-the-coronavirus-outbreak-7404""
</code></pre>

<p>My code is </p>

<pre class=""lang-py prettyprint-override""><code>def twitter_link(url):
    twitter_title=[]
    response = requests.get(url)
    soup = BeautifulSoup(response.text, ""html.parser"")
    for i in soup.find_all(""p""):
        try:
           for a in i.find_all(""a"", href=True):
              if ""twitter"" in a[""href""]:
                 x=a[""href""]
               twitter_title.append(x)
        except Exception as e:
           twitter_title.append(str(e))
           continue  

    return twitter_title
</code></pre>

<p>My excepted output is function stores URL in list twitter_title, if there is an error then store the error message and continue the executions</p>
"
60910332,"<p>I'm trying my hand at the Kaggle COVID-19 competition (<a href=""https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks"" rel=""nofollow noreferrer"">https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge/tasks</a>) just to see if I can help.  I have a question about improving the efficiency of regular expression search in a pandas DataFrame.</p>

<p>I've organised the dataset so I have dataframe with a title, abstract and the full text of the article in each row. The goal is to search the full text for keywords using a regular expression, and then return a set in a new column.  As a first step, I am searching for the virus mentioned in each article.  I am also using a dataset from the International Committee on Taxonomy of Viruses to help me identify the virus (<a href=""https://talk.ictvonline.org/files/master-species-lists/m/msl/8266"" rel=""nofollow noreferrer"">https://talk.ictvonline.org/files/master-species-lists/m/msl/8266</a>)</p>

<p>While I understand that my dataset is large, and there is a lot of data in the ""Full text"" column (400,000+ lines, and 100s of words in the full text column) , my current script run has ran for 2 days non-stop.  I would like to check whether if there is a way to improve it's efficiency, as I want to run other regular expression searches, and preferably not have to wait for so long.</p>

<p>I've created a mock dataset, but with the script I am using. Is there anyway for me to improve it's efficiency?</p>

<pre><code>import pandas as pd
import re
</code></pre>

<p>Mock dataset</p>

<pre><code>df = pd.DataFrame(data = {""Title"": [""Article 1"", ""Article 2"", ""Article 3""],
                          ""Abstract"":[""Abstract 1"", ""Abstract 2"", ""Abstract 3""],
                        ""Text"":[""Lorem ipsum dolor sit amet, consectetur adipiscing elit, coronavirus sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, papavirus, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia paleovirus deserunt mollit anim id est laborum."",
                               ""Lorem ipsum dolor sit amet, paleovirus consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui coronavirus officia deserunt mollit anim id est laborum."",
                               ""Lorem coronavirus ipsum dolor sit amet, astrovirus consectetur adipiscing elit, sed do eiusmod tempor astrovirus incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.""]
                         })
</code></pre>

<p>This is from the ICTV website, I downloaded the spreadsheet from the website, to replicate, please download the spreadsheet, and change the folder path</p>

<pre><code>virus  =  pd.read_excel(r""D:\Python work\2020-03-13\ICTV Master Species List 2018b.v2.xlsx"", sheet_name = ""ICTV 2018b Master Species #34 v"")
</code></pre>

<p>Organising the data</p>

<pre><code>virus = virus[['Realm', 'Subrealm', 'Kingdom', 'Subkingdom', 'Phylum',
       'Subphylum', 'Class', 'Subclass', 'Order', 'Suborder', 'Family',
       'Subfamily', 'Genus', 'Subgenus', 'Species']]
</code></pre>

<p>I've melted the dataset into a single column. Articles may mention the same virus in different conjucations (coronavirus, coronaviridae, coronavirale etc. I want to capture all versions)</p>

<pre><code>virus = virus.melt(id_vars= None,  var_name = ""virus_class"", value_name = ""virus_name"")
virus.drop_duplicates(subset = [""virus_name""], inplace=True)
virus.dropna(subset = [""virus_name""], inplace=True)
virus[""virus_name""] = virus[""virus_name""] .apply(lambda x : x.lower())
</code></pre>

<p>From my understanding, all virus names will have the stem ""vir"" in it's name, it can be at the beginning, the middle or in the end.</p>

<p>These lines attempt to capture prefix fof the virus using a regular expressions</p>

<pre><code>virus[""tgt""] = virus[""virus_name""].apply(lambda x: re.findall(""[a-z].*(?=vir)"", x))
</code></pre>

<p>This converts the list returned from the regular expression to a string.</p>

<pre><code>virus[""tgt""] = virus[""tgt""].astype(str)
virus[""tgt""] = virus[""tgt""].apply(lambda x: x.strip())
virus[""tgt""] = virus[""tgt""].apply(lambda x: x.replace(""["",""""))
virus[""tgt""] = virus[""tgt""].apply(lambda x: x.replace(""]"",""""))
virus[""tgt""] = virus[""tgt""].apply(lambda x: x.replace(""'"",""""))
virus[""tgt""] = ""[a-z]+"" + virus[""tgt""] + ""vir[a-z0-9]+""

virus[""tgt""].drop_duplicates(inplace=True)
</code></pre>

<p>This step takes all the virus in panda's series and puts it into a single string. Also, thank you for providing this code (<a href=""https://stackoverflow.com/questions/3040716/python-elegant-way-to-check-if-at-least-one-regex-in-list-matches-a-string"">Python: Elegant way to check if at least one regex in list matches a string</a>) </p>

<pre><code>regexes = virus[""tgt""].tolist()
combined = ""("" + "")|("".join(regexes) + "")""
</code></pre>

<p>This is the code I am most worried about. It runs the regular expression, and returns what it finds to a string.
The ""set"" is to remove duplicates</p>

<pre><code>def working(x):
    x = set(["""".join(x) for x in re.findall(combined, x)])
    print(x)
    return x    
</code></pre>

<p>This line runs the code and picks up the text by row. However, as mentioned, this is taking a long time.</p>

<pre><code>df[""ID_virus""] = df[""Text""].apply(lambda x: working(x))
</code></pre>

<p>The script returns what I want, but it is slow</p>

<p>I apologise for the very long entry, but I wanted to provide as much information to recreate the problem. The script works (I think), but as mentioned, the script has been running for two days.  </p>

<p>Any help would be appreciated.</p>
"
61434286,"<p>I made this simple chat bot in Python and Flask. It works perfectly when I run it in a local server but I uploaded it to Heroku (my first time uploading) and some options only work sometimes. </p>

<p><a href=""https://i.stack.imgur.com/O8p0w.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/O8p0w.png"" alt=""enter image description here""></a></p>

<p>In the above image, entering 3 should prompt the app to ask user for a city name but it doesn't most of the times.</p>

<pre><code>#imports
import requests
from flask import Flask, render_template, request
app = Flask(__name__)
import random
newsApiKey = 'c0f976e7caac4b608d84c4546e0b892c'
isGreeted = False
isThree = False

def getRequest(location):
    global newsApiKey
    url = ""http://newsapi.org/v2/everything?q={} AND +corona AND english&amp;qInTitle=+corona&amp;language=en&amp;from=2020-03-25&amp;sortBy=relevancy&amp;apiKey={}"".format(location,newsApiKey)
    r = requests.get(url)
    return r

def getGreeting():
    greets = ['Hello there General Kenobi!', 'Hi there!', 'Hi, how are you?']
    return random.choice(greets)

#define app routes
@app.route(""/"")
def index():
    return render_template(""index.html"")


@app.route(""/get"")
#function for the bot response
def get_bot_response():
    global isGreeted
    global isThree
    userText = request.args.get('msg')
    # return str(englishBot.get_response(userText))
    responseMessage = """"
    if userText in ['Hi!', 'Hello!', 'Hi'] and isGreeted == False:
        responseMessage = getGreeting() + ""\n\nChoose an option from below menu:\n\n1 - What is Covid-19?\n\n2 - What are the symptoms of Covid-19?\n\n3 - Local news about Covid-19\n\n4 - What should I do?""
        isGreeted = True
    elif userText in ['1','2','3','4'] and isGreeted:
        if userText == '1':
            responseMessage = ""Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus.""
        elif userText == '2':
            responseMessage = ""Common symptoms include fever, tiredness, dry cough. Other symptoms include shortness of breath, aches and pains, sore throat, diarrhoea, runny nose. People with mild symptoms should try self isolating and others should seek medical attention.""
        elif userText == '3' and isThree == False:
            responseMessage = 'Enter your city name'
            isThree = True
        elif userText == '4':
            responseMessage = 'Stay at home. If you plan to go outside, avoid using public transportation. Seek medical attention if you have trouble breathing, pain in chest, bluish lips. Cover your face with an N95 mask. Clean your hands often.'
    elif isThree:
        r = getRequest(userText).json()
        # print(r)
        isThree = False
        counter = 0
        for article in r['articles']:
            if counter != 3:
                responseMessage += article['title'] + '\n' + article['description'] + '\n\n'
                counter = counter + 1
            else:
                break
    return responseMessage

if __name__ == ""__main__"":
    app.run()
</code></pre>

<p>Does it have anything to do with the way I handle responses? Or the fact I am using global variables? If yes, what is the better way to do this? Thank you in advance.</p>
"
60689829,"<p>So I developed a script that would pull data from a live-updated site tracking coronavirus data. I set it up to pull data every 30 minutes but recently tested it on updates every 30 seconds. </p>

<p>The idea is that it creates the request to the site, pulls the html, creates a list of all of the data I need, then restructures into a dataframe (basically it's the country, the cases, deaths, etc.).</p>

<p>Then it will take each row and append to the rows of each of the 123 excel files that are for the various countries. This will work well for, I believe, somewhere in the range of 30-50 iterations before it either causes file corruptions or weird data entries.</p>

<p>I have my code below. I know it's poorly written (my initial reasoning was I felt confident I could set it up quickly and I wanted to collect data quickly.. unfortunately I overestimated my abilities but now I want to learn what went wrong). Below my code I'll include sample output.</p>

<p>PLEASE note that this 30 second interval code pull is only for quick testing. I don't usually look to send that many requests for months. I just wanted to see what the issue was. Originally it was set to pull every 30 minutes when I detected this issue.</p>

<p>See below for the code:</p>

<pre><code>import schedule
import time

def RecurringProcess2():
    import requests
    from bs4 import BeautifulSoup
    import pandas as pd
    import datetime
    import numpy as np
    from os import listdir
    import os

    try:
        extractTime = datetime.datetime.now()
        extractTime = str(extractTime)
        print(""Access Initiated at "" + extractTime)
        link = 'https://www.worldometers.info/coronavirus/'
        response = requests.get(link)
        soup = BeautifulSoup(response.text,'html.parser').findAll('td')#[1107].get_text()

        table = pd.DataFrame(columns=['Date and Time','Country','Total Cases','New Cases','Total Deaths','New Deaths','Total Recovered','Active Cases','Serious Critical','Total Cases/1M pop'])
        soupList = []

        for i in range(1107):
            value = soup[i].get_text()
            soupList.insert(i,value)

        table = np.reshape(soupList,(123,-1))
        table = pd.DataFrame(table)
        table.columns=['Country','Total Cases','New Cases (+)','Total Deaths','New Deaths (+)','Total Recovered','Active Cases','Serious Critical','Total Cases/1M pop']
        table['Date &amp; Time'] = extractTime

        #Below code is run once to generate the initial files. That's it.
        # for i in range(122):
        #     fileName = table.iloc[i,0] + '.xlsx'
        #     table.iloc[i:i+1,:].to_excel(fileName)

        FilesDirectory = 'D:\\Professional\\Coronavirus'
        fileType = '.csv'
        filenames = listdir(FilesDirectory)
        DataFiles = [ filename for filename in filenames if filename.endswith(fileType) ]

        for file in DataFiles:
            countryData = pd.read_csv(file,index_col=0)
            MatchedCountry = table.loc[table['Country'] == str(file)[:-4]]
            if file == ' USA .csv':
                print(""Country Data Rows: "",len(countryData))
                if os.stat(file).st_size &lt; 1500:
                    print(""File Size under 1500"")
            countryData = countryData.append(MatchedCountry)
            countryData.to_csv(FilesDirectory+'\\'+file, index=False)

    except :
        pass

    print(""Process Complete!"")

    return

schedule.every(30).seconds.do(RecurringProcess2)

while True:
    schedule.run_pending()
    time.sleep(1)
</code></pre>

<p>When I check the code after some number of iterations (usually successful for like 30-50) it has either displayed only 2 rows and lost all other rows, or it'll keep appending while deleting a single entry in the row above while two rows above loses 2 entries, etc. (essentially forming a triangle of sorts).</p>

<p><a href=""https://i.stack.imgur.com/BIEUv.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BIEUv.png"" alt=""Image of what data on USA looks like""></a></p>

<p>Above that image would be a few hundred empty rows. Does anyone have an idea of what is going wrong here? I'd consider this a failed attempt but would still like to learn from this attempt. I appreciate any help in advance.</p>
"
61373603,"<p>I wanted to prepare a dataset to some more feature my ongoing analysis.
Here I tried to fetch data from pdf. But the table was in pivoted format, So  I had to fill ""NaN"" data. My current approach is working fine. Wanted to know is there any better alternate approach to achieve this without iterating dataframe. That can help me in cases of bigger data
 set then this one.</p>

<pre><code>import tabula
df = tabula.read_pdf(""https://www.mohfw.gov.in/pdf/DistrictWiseList354.pdf"")
df.rename(columns={'Unnamed: 0':'state',
                    'State/District wise Details of COVID-19 positive cases': 'District',
                    'Unnamed: 2':'no_of_cases'},
           inplace=True)
df.drop([0,1,2],inplace=True)
df.head()
for index, row in df.iterrows():    
    if(str(df.state[index]) != 'nan'):
        statename = df.state[index]        
    df.state[index] = statename
</code></pre>
"
60826742,"<p>COVID-19 Data set is available like this. As can be seen, each date is cumulative of all past dates. I want to capture only day's additions - kind of ""ungroup by"". I have this info in a Pandas dataframe. I tried using ""explode"" but that is not the right solution.    </p>

<pre><code>    Country       3/14/20  3/15/20  3/16/20  3/17/20  3/18/20  3/19/20  3/20/20  3/21/20  
    ___________________________________________________________________________________
    China          80977    81003    81033    81058    81102    81156    81250    81305    
    Italy          21157    24747    27980    31506    35713    41035    47021    53578    
    US             2727     3499     4632     6421     7783    13677     19100    25489        
    Spain          6391     7798     9942    11748    13910    17963     20410    25374         
    Germany        4585     5795     7272     9257    12327    15320     19848    22213         
    Iran           12729    13938    14991    16169    17361    18407    19644    20610       
    France         4496     4532     6683     7715     9124    10970     12758    14463        
    Korea, South   8086     8162     8236     8320     8413     8565     8652     8799     
    Switzerland    1359     2200     2200     2700     3028     4075     5294     6575        
    United Kingdom 1144     1145     1551     1960     2642     2716     4014     5067  
</code></pre>

<p>The sample output what I want  is this - only cases added per day.</p>

<pre><code>Country    3/14/20  3/15/20  3/16/20  3/17/20  3/18/20  3/19/20  3/20/20  3/21/20  
___________________________________________________________________________________
China          32       26      30       25       44        54       94       55             
Italy         .....
US            .....
</code></pre>

<p>All help appreciated.</p>
"
61600563,"<p>I have problems with the rotation of my X-axis, I have tried to do the rotation the output plot without errors, but I do not have the results.</p>

<pre><code># Import Data
#df = pd.read_csv(""https://github.com/selva86/datasets/raw/master/economics.csv"")
x = total_test[""Dia""].values[:]; y1 = total_test[""Confirmados""].values[:]; y2 = total_test[""Fallecidos""].values[:]

# Plot Line1 (Left Y Axis)
fig, ax1 = plt.subplots(1,1,figsize=(10,8), dpi= 200)
ax1.plot(x, y1,'g^', color='tab:red')

# Plot Line2 (Right Y Axis)
ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis
ax2.plot(x, y2,'bs', color='tab:blue')

# Just Decorations!! -------------------
# ax1 (left y axis)
ax1.set_xlabel('Dias', fontsize=10)
ax1.set_ylabel('Personas Confirmadas', color='tab:red', fontsize=20)
ax1.tick_params(axis='y', rotation=0, labelcolor='tab:red' )

# ax2 (right Y axis)
ax2.set_ylabel(""Personas Fallecidas"", color='tab:blue', fontsize=20)
ax2.tick_params(axis='y', rotation=0, labelcolor='tab:blue')
ax2.set_title(""Personas Confirmadas y Fallecidas por Covid-19 Peru"", fontsize=15)
#ax2.set_xticks(x)
ax2.set_xticklabels(x[::],fontsize=10,rotation=90)
plt.show()
</code></pre>

<p><a href=""https://i.stack.imgur.com/G6M0Y.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/G6M0Y.png"" alt=""enter image description here""></a></p>
"
61211756,"<p>I have several labels on the interface and I want an image, ""arkaplan.pbm"" to be shown in the background. I'm using this format because I made it work with label's image displaying method so I'm assuming canvas can also support pbm file.</p>

<p>So far I either managed to show labels or the image, never together. I was using a label to draw the image. So I switched to canvas method but now I don't see any image at all.</p>

<p>I'm using Python 3.7 and developing this on Raspberry Pi's 7inch screen. What am I doing wrong?</p>

<pre><code>from bs4 import BeautifulSoup
import requests
import time
from tkinter import * 
import tkinter.font 
from PIL import Image, ImageTk

country = ""Turkey""
notification_duration = 10
refresh_time = 10 #minutes
data_check= []
worldmetersLink = ""https://www.worldometers.info/coronavirus/""

win = tkinter.Tk() 
arkaplan_PIL = Image.open(""/home/pi/Desktop/arkaplan.pbm"")
arkaplan_image = ImageTk.PhotoImage(arkaplan_PIL)

def data_cleanup(array):
    L = []
    for i in array:
        i = i.replace(""+"","""")
        i = i.replace(""-"","""")
        i = i.replace("","",""."")
        if i == """":
            i = ""0""
        L.append(i.strip())
    return L

win.geometry('800x480') 
win.attributes('-fullscreen', True) 


while True:
    try:
        html_page = requests.get(worldmetersLink)
    except requests.exceptions.RequestException as e:
        print (e)
        continue
    bs = BeautifulSoup(html_page.content, 'html.parser')

    search = bs.select(""div tbody tr td"")
    start = -1
    for i in range(len(search)):
        if search[i].get_text().find(country) !=-1:
            start = i
            break
    data = []
    for i in range(1,8):
        try:
            data = data + [search[start+i].get_text()]
        except:
            data = data + [""0""]

    data= data_cleanup(data)



    if data_check != data:
        data_check = data
        toplam_vaka=data[0]
        toplam_vefat = data[2]
        toplam_taburcu = data[4]

        etiket1 = Label(win, text=(toplam_vaka),bg=""white"",fg=""black"",font = ""Helvetica 26 bold italic"")
        etiket1.place(x=500, y=200)

        etiket2 = Label(win, text=(toplam_vefat),bg=""white"",fg=""black"",font = ""Helvetica 20 bold italic"")
        etiket2.place(x=450, y=300) 

        etiket3 = Label(win, text = (toplam_taburcu),bg=""white"",fg=""black"",font = ""Helvetica 20 bold italic"")
        etiket3.place(x=600, y=300) 

        canv = Canvas(win, width=800, height=480, background=""white"")
        canv.create_image(800, 480, image = arkaplan_image)

        win.mainloop()
    else:
        time.sleep(refresh_time*60)
        continue
</code></pre>
"
60873951,"<p>Suppose I have the following pandas dataframe:</p>

<pre><code>Date    Region  Country Cases   Deaths  Lat Long
2020-03-08  Northern Territory  Australia   27  49  -12.4634    130.8456
2020-03-09  Northern Territory  Australia   80  85  -12.4634    130.8456
2020-03-12  Northern Territory  Australia   35  73  -12.4634    130.8456
2020-03-08  Western Australia   Australia   48  20  -31.9505    115.8605
2020-03-09  Western Australia   Australia   70  12  -31.9505    115.8605
2020-03-10  Western Australia   Australia   66  95  -31.9505    115.8605
2020-03-11  Western Australia   Australia   31  38  -31.9505    115.8605
2020-03-12  Western Australia   Australia   40  83  -31.9505    115.8605
</code></pre>

<p>I need to update the dataframe with the missing dates on the Northern Terriroty, 2020-3-10 and 2020-3-11. However, I want to use all the information except for cases and deaths. Like this:</p>

<pre><code>Date    Region  Country Cases   Deaths  Lat Long
2020-03-08  Northern Territory  Australia   27  49  -12.4634    130.8456
2020-03-09  Northern Territory  Australia   80  85  -12.4634    130.8456
2020-03-10  Northern Territory  Australia   0   0   -12.4634    130.8456
2020-03-11  Northern Territory  Australia   0   0   -12.4634    130.8456
2020-03-12  Northern Territory  Australia   35  73  -12.4634    130.8456
2020-03-08  Western Australia   Australia   48  20  -31.9505    115.8605
2020-03-09  Western Australia   Australia   70  12  -31.9505    115.8605
2020-03-10  Western Australia   Australia   66  95  -31.9505    115.8605
2020-03-11  Western Australia   Australia   31  38  -31.9505    115.8605
2020-03-12  Western Australia   Australia   40  83  -31.9505    115.8605
</code></pre>

<p>The only way I can think of doing this is to iterate through all combinations of dates and countries. </p>

<h2>EDIT</h2>

<p>Efran seems to be on the right track but I can't get it to work. Here is the actual data I'm working with instead of a toy example.</p>

<pre><code>import pandas as pd

unique_group = ['province','country','county']
csbs_df = pd.read_csv(
        'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/csbs_df.csv.gz', index_col=0)

csbs_df['Date'] = pd.to_datetime(csbs_df['Date'], infer_datetime_format=True)
new_df = (
    csbs_df.set_index('Date')
    .groupby(unique_group)
    .resample('D').first()
    .fillna(dict.fromkeys(['confirmed', 'deaths'], 0))
    .ffill()
    .reset_index(level=3)
    .reset_index(drop=True))
new_df.head()
Date    id  lat lon Timestamp   province    country_code    country county  confirmed   deaths  source  Date_text
0   2020-03-25  1094.0  32.534893   -86.642709  2020-03-25 00:00:00+00:00   Alabama US  US  Autauga 1.0 0.0 CSBS    03/25/20
1   2020-03-26  901.0   32.534893   -86.642709  2020-03-26 00:00:00+00:00   Alabama US  US  Autauga 4.0 0.0 CSBS    03/26/20
2   2020-03-24  991.0   30.735891   -87.723525  2020-03-24 00:00:00+00:00   Alabama US  US  Baldwin 3.0 0.0 CSBS    03/24/20
3   2020-03-25  1080.0  30.735891   -87.723525  2020-03-25 00:00:00+00:00   Alabama US  US  Baldwin 4.0 0.0 CSBS    03/25/20
4   2020-03-26  1139.0  30.735891   -87.723525  2020-03-26 16:52:00+00:00   Alabama US  US  Baldwin 4.0 0.0 CSBS    03/26/20
</code></pre>

<p>You can see that it is not inserting the day resample as its specified. I'm not sure whats wrong. </p>

<h2>Edit 2</h2>

<p>Here is my solution based on Erfan.</p>

<pre><code>import pandas as pd

csbs_df = pd.read_csv(
        'https://jordansdatabucket.s3-us-west-2.amazonaws.com/covid19data/csbs_df.csv.gz', index_col=0)
date_range = pd.date_range(csbs_df['Date'].min(),csbs_df['Date'].max(),freq='1D')
unique_group = ['country','province','county']
gb = csbs_df.groupby(unique_group)
sub_dfs =[]
for g in gb.groups:
    sub_df = gb.get_group(g)
    sub_df = (
        sub_df.set_index('Date')
        .reindex(date_range)
        .fillna(dict.fromkeys(['confirmed', 'deaths'], 0))
        .bfill()
        .ffill()
        .reset_index()
        .rename({'index':'Date'},axis=1)
        .drop({'id':1},axis=1))
    sub_df['Date_text'] = sub_df['Date'].dt.strftime('%m/%d/%y')
    sub_df['Timestamp'] = pd.to_datetime(sub_df['Date'],utc=True)
    sub_dfs.append(sub_df)
all_concat = pd.concat(sub_dfs)
assert((all_concat.groupby(['province','country','county']).count() == 3).all().all())

</code></pre>
"
61252437,"<p>Based on this example data : </p>

<pre><code>data = """"""value          
""2020-03-02""    2
""2020-03-03""    4
""2020-03-01""    3
""2020-03-04""    0
""2020-03-08""    0
""2020-03-06""    0
""2020-03-07""    2""""""
</code></pre>

<ul>
<li>I'm ordering <code>value</code> by date as datetime index</li>
<li>from <code>value</code> column i compute a new <code>cum_value</code> cumulated value column;</li>
<li>for each row value <code>vc{i from 0 to n}</code> of <code>value_cum</code>, </li>
<li>i search into the <code>vc'{j from 0 to i}</code> cutted series of <code>cum_value</code> the row which verify and maximise the ratio <code>vc{i} / vc'{j} &gt;= 2</code> </li>
</ul>

<p>At the end, i get for each day, the delta between actual day and the day which maximize the predicate. For this data, i get : </p>

<pre><code>            value  value_cum  computeValue  delta
2020-03-01      3          3           NaN    NaN
2020-03-02      2          5           NaN    NaN
2020-03-03      4          9           3.0    2.0
2020-03-04      0          9           3.0    2.0
2020-03-06      0          9           3.0    2.0
2020-03-07      2         11           2.2    5.0
2020-03-08      0         11           2.2    5.0
</code></pre>

<p><strong>Edit :</strong> More context information here</p>

<p>Actually this is a code to find the first doubling day rate for Covid19 number of accumulated death. : </p>

<ul>
<li><code>value</code> is my death by day, </li>
<li><code>value_cum</code> is the accumulated death by day.</li>
</ul>

<p>For each day, i search into the existing series when the ratio of cumulated deaths is multiplied by 2. This is why i cut series, to compute my ratio i only need the n previous date/rows (past day) before the actual day i want to test. </p>

<p>I found this computation on <a href=""https://ourworldindata.org/coronavirus#global-comparison-where-are-confirmed-deaths-increasing-most-rapidly"" rel=""nofollow noreferrer"">COVID 19 our world in data</a> charts, but i want to compute this indicators for one country and for each day and not only the last day as picture show :)  </p>

<p><a href=""https://i.stack.imgur.com/6PlMc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/6PlMc.png"" alt=""enter image description here""></a></p>

<p>For example, for the date 2020-03-04, i only need to compute ratio between 2020-03-04 and 2020-03-01 / 02 / 03 to find the FIRST date where ratio >=2</p>

<p>In this example 2020-03-04 there is no more death than 2020-03-03, so we don't want to compute a new delta ( the number of days before death multiply >=2  is the same than 2020-03-03 !). I explain this in Edit1/2 archived at the end of this post. </p>

<p>We use a dictionary to store the first occurence of each cumulated value, so when i see that cum_value = value, i search in the dictionary to get the correct date (9 return 2020-03-03) for ratio computation. </p>

<p>Here my actual working code to do that : </p>

<pre><code>    import pandas as pd
    import io
    from dfply import *

data = """"""value          
""2020-03-02""    2
""2020-03-03""    4
""2020-03-01""    3
""2020-03-04""    0
""2020-03-08""    0
""2020-03-06""    0
""2020-03-07""    2""""""

   df = pd.read_table(io.StringIO(data), delim_whitespace=True)
df.index = pd.to_datetime(df.index)

def f(x, **kwargs):

    # get numerical index of row
    numericIndex = kwargs[""df""].index.get_loc(x.name)
    dict_inverted = kwargs[""dict""]

    # Skip the first line, returning Nan
    if numericIndex == 0:
        return np.NaN, np.NaN


    # If value_cum is the same than the previous row (nothing changed),
    # we need some tweaking (compute using the datebefore) to return same data
    ilocvalue = kwargs[""df""].iloc[[numericIndex - 1]][""value_cum""][0]
    if x['value_cum'] == ilocvalue:
        name = dict_inverted[x['value_cum']]
    else:
        name = x.name

    # Series to compare with actual row
    series =  kwargs[""value_cum""]
    # Cut this series by taking in account only the days before actual date
    cutedSeries = series[series.index &lt; name]
    rowValueToCompare = float(x['value_cum'])

    # User query to filter rows
    # https://stackoverflow.com/questions/40171498/is-there-a-query-method-or-similar-for-pandas-series-pandas-series-query
    result = cutedSeries.to_frame().query(f'({rowValueToCompare} / value_cum) &gt;= 2.0')

    # If empty return Nan
    if result.empty:
        return np.NaN, np.NaN 

    # Get the last result
    oneResult = result.tail(1).iloc[:, 0]
    # Compute values to return
    value = (rowValueToCompare/oneResult.values[0])
    idx = oneResult.index[0]
    # Delta between the actual row day, and the &gt;=2 day
    delta = name - idx

    # return columns
    return value, delta.days

df_cases = df &gt;&gt; arrange(X.index, ascending=True) \
        &gt;&gt; mutate(value_cum=cumsum(X.value))


df_map_value = df_cases.drop_duplicates([""value_cum""])
dict_value = df_map_value[""value_cum""].to_dict()
dict_value_inverted = {v: k for k, v in dict_value.items()}
print(dict_value_inverted)

df_cases[[""computeValue"", ""delta""]] = df_cases.apply(f, result_type=""expand"", dict=dict_value_inverted, df=df_cases, value_cum= df_cases['value_cum'],axis=1)
print(df_cases)
</code></pre>

<p>I'm not really happy with this code, i found that passing the entire DF to my apply method was weird. </p>

<p>I'm sure there is some better code in Panda to do that in less lines, and more elegantly, using probably nested apply method, but i don't found how.</p>

<p>The dictionnary method to store date of the first duplicate is also weird, i don't know if it's possible to do that using apply (reusing result of previous computation during apply) or if the only way was to write a recursive function.</p>

<p><strong>QUESTION UPDATED WITH EDIT 1/2/3, WORKING WITH DUPLICATE VALUES</strong> </p>

<p><strong>EDIT ARCHIVED</strong></p>

<p><strong>Edit 1 :</strong> </p>

<pre><code>data = """"""value          
""2020-03-02""    1
""2020-03-03""    0
""2020-03-01""    1
""2020-03-04""    0
""2020-03-05""    4""""""
</code></pre>

<p>I see that my code doesn't take in account when there is value equal at zero. </p>

<pre><code>                value  value_cum  computeValue  delta
2020-03-01      1          1           NaN    NaN
2020-03-02      1          2           2.0    1.0
2020-03-03      0          2           2.0    2.0
2020-03-04      0          2           2.0    3.0
2020-03-05      4          6           3.0    1.0
</code></pre>

<p>2020-03-03 computeValue is equal to 3.0 and not 2.0, dela is equal to 2.0 days and not 1.0 days (like 2020-03-02) </p>

<p>I cannot access previous values during apply computation, so i search another way to do that.</p>

<p><strong>Edit 2 :</strong> </p>

<p>Found a way passing a pre-computed dictionnary :</p>

<ul>
<li>removing duplicate</li>
<li>dictionnary where value_cum return a timestamp</li>
</ul>

<pre><code>   df_map_value = df_cases.drop_duplicates([""value_cum""])
   dict_value = df_map_value[""value_cum""].to_dict()
   dict_value_inverted = {v: k for k, v in dict_value.items()}
   print(dict_value_inverted)
</code></pre>

<p>Now, when i found a cum_value equal to some value, i return the index used for computation.</p>
"
61003714,"<p>I'm trying to set 2 date pickers in one callback, the purpose of this is to create a plot with two data frames where one corresponds to a filter with the first dropdown and the second one takes the input of the second date filter.</p>

<p>Ive the following code: (I'm just going to put part of the code because it is quite large)</p>

<pre><code>cluster = dbc.Form([
        dbc.FormGroup([
                dbc.Label('Dasboard Visión de Negocios (COVID-19)', html_for=""dropdown"",style={'font-family': 'arial','font-size': '2rem'}),
                dbc.Row([
# =============================================================================
#                     # Fila de dropdowns
# =============================================================================
                        dbc.Col([
                                #####  TIME PERIOD
                                dbc.Label('Periodo:', html_for=""dropdown"",style={'padding-top': '80px','font-family': 'arial','font-size': '1.1rem'}),
                                dcc.DatePickerRange(id='periodo_sel',
                                                    display_format='DD MMM YYYY',
                                                    minimum_nights=1,
                                                    start_date=dt(2019,1,1),
                                                    end_date=df['EFFECTIVE_START_DATE'].max(),
                                                    style={'width': 'max-content','font-family': 'arial'},
                                                    day_size = 30),
                                ##### SECOND TIME PERIOD
                                dbc.Label('Periodo 2:', html_for=""dropdown"",style={'padding-top': '80px','font-family': 'arial','font-size': '1.3rem'}),
                                dcc.DatePickerRange(id='periodo_sel2',
                                                    display_format='DD MMM YYYY',
                                                    minimum_nights=1,
                                                    start_date=dt(2019,1,1),
                                                    end_date=df['EFFECTIVE_START_DATE'].max(),
                                                    style={'width': 'max-content','font-family': 'arial'},
                                                    day_size = 30),
......      
</code></pre>

<p>This is where I'm trying to create the plot:</p>

<pre><code>@app.callback(Output(component_id='product_graph', component_property='figure'),
              [Input('periodo_sel','start_date'),
               Input('periodo_sel','end_date'),
               Input('periodo_sel2','start_date'),
               Input('periodo_sel2','end_date'),
               Input('periodo_sel','end_date'),
               Input('temp_select','value'),
               Input('product_select','value')])

def product_plot(start_date, end_date, temp_select, product_select):
    """"""
    Here is where the problem begins, because I don't know how to set a ""start2"" and ""end2"", if          you see, period has only start and end as property, so when I'm trying to set the second period it becomes redundant and takes the input of the first output
    """"""
    start = pd.to_datetime(start_date)
    end = pd.to_datetime(end_date)

    start2 = pd.to_datetime(?????)
    end2 = pd.to_datetime(?????)


....
</code></pre>
"
60652996,"<p>as the Python and database novice I am also a novice in data science. However, there's a task to solve and I hope someone can give me a little help.</p>

<p>I am referring to this dataset <a href=""https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset#COVID19_line_list_data.csv"" rel=""nofollow noreferrer"">https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset#COVID19_line_list_data.csv</a></p>

<p>Now I am interested in the column ""summary"". I want to extract all those cases where someone ""imported corona"". Examples:</p>

<blockquote>
  <p>First confirmed imported COVID-19 pneumonia patient in Shenzhen (from Wuhan): male, 66, shenzheng residence, <strong>visited relatives in Wuhan</strong> on 12/29/2019, symptoms onset on 01/03/2020, returned to Shenzhe...</p>
</blockquote>

<p>Most likely imported from Wuhan</p>

<blockquote>
  <p>new confirmed COVID-19 patient in Germany: 1/28-No.1 male, 33, <strong>caught from Chinese colleague</strong> during conference in Munich from 1/20-1/21, first human-to-human transmission in Europe, confirmed 1/27/202...</p>
</blockquote>

<p>Most likely imported from China</p>

<blockquote>
  <p>new confirmed COVID-19 patient in Germany: male, 32, Baden-Wurttemberg, <strong>returned on 2/23 from Codogno</strong>, Italy</p>
</blockquote>

<p>Most likely imported from Italy</p>

<p>Now I've read some things about spacey and tensorflow but couldn't find some article describing such a task. I could however find this page <a href=""https://explosion.ai/demos/matcher"" rel=""nofollow noreferrer"">https://explosion.ai/demos/matcher</a> that helped me a lot playing around with ruled based tagging.</p>

<p>But rule based doesn't help much. With this I can find country information in the text but not the information if the patient was a resident of this particular country or if he was travelling from this country to another. And because the text is not uniform I have to look inside the sentence itself and cannot just filter phrases.</p>

<p>Anyone can help?</p>

<p>Thanks in advance!</p>
"
60635909,"<p>I am using a dataset showing Corona Virus data loaded as a Pandas DataFrame.</p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv</a></p>

<p>In this data we have each measurement date as a seperate column. What I would need is to pivot it into a tall table.</p>

<p>So one row like this</p>

<pre><code>     State      | Country |  Lat  |  Long  |  1/22/20 | 1/23/20  | ...
  Washington        US        x       x        0          0        ... 
</code></pre>

<p>Should be transformed into this </p>

<pre><code>     State     |  Country  | Lat | Long |  Date   | Cases
  Washington        US        x     x     1/22/20    0 
  Washington        US        x     x     1/23/20    0 
  Washington        US        x     x     1/24/20    0
  Washington        US        x     x       ..       .. 
</code></pre>

<p>Is there an easy way to do this with pandas?</p>
"
61002151,"<p>I have been looking for ways to import this Google sheets data into a pandas dataframe without much luck. I have tried all the methods I could find for reading it in and specifying particular pages/sheets, but to me it looks like Google has changed the format since those documents have been written.</p>

<p>I can copy/paste the Google sheet data into Excel and save that as a csv, but that does not seem pythonic.</p>

<p><a href=""https://docs.google.com/spreadsheets/u/2/d/e/2PACX-1vRwAqp96T9sYYq2-i7Tj0pvTf6XVHjDSMIKBdZHXiCGGdNC0ypEU9NbngS8mxea55JuCFuua1MUeOj5/pubhtml#"" rel=""nofollow noreferrer"">Coronavirus numbers by state</a></p>
"
60834531,"<p>I would like to only show the interested keys and their associated values. Also, None means N/A. I would also like to the keys, like capitalize them or instead of lastUpdateEt, make it Last Updated at or instead of total, make it Total Tested.</p>

<pre><code>import requests
import json
import pandas as pd


state = input(""Enter two character state code eg: NY, CA: "")
url = ""https://covidtracking.com/api/states?state={}"".format(state)

result = requests.get(url)
dataobj = result.json()

# Only intersted in showing these keys and their associated values:
# interested_keys['state','positive','grade','negative','pending','hospitalized','death','total','lastUpdateEt']


df = pd.DataFrame.from_dict(dataobj, orient='index',columns=['Values'])
df
</code></pre>

<p><a href=""https://i.stack.imgur.com/2F6wU.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2F6wU.png"" alt=""Current Output: ""></a></p>
"
61682730,"<p>I have created a simple Flask app which renders a template 'index.html' and in that HTML I am attempting to list various plots as a sort of dashboard-style webpage with other content. I know the basics of Flask and Dash though am not using Dash as I want to have more control over the HTML/CSS hence using Flask to create a website to embed the graphs using Plotly.</p>

<p>So far I've had no luck with any of the official documentation or any medium.com or suchlike articles. The closest I have come to is this answer: <a href=""https://stackoverflow.com/questions/56787941/embedding-dash-plotly-graphs-into-html"">Embedding dash plotly graphs into html</a></p>

<p>However, it isn't working when I run my app and the browser launches in localhost. Instead it just gives me a lot of text which is clearly the plotly figure, but it isn't turning into a graph.</p>

<p>Here is all my py/html/css even if the navbar stuff isn't relevant; just in case (I am still learning so I'm sure there will be some better ways to do things..)</p>

<p>Thanks for any help.</p>

<p>DataFrame class which grabs the latest Coronavirus data and returns as pandas.dataframe:</p>

<pre><code>import pandas as pd
import requests


    class DataFrame:
        """"""
        Class which grabs the data live from the ECDC and returns it in a pandas dataframe
        """"""

        def __init__(self):
            """"""
            Creating the pandas dataframe of the ECDC JSON data
            """"""
            self.url = ""https://opendata.ecdc.europa.eu/covid19/casedistribution/json""
            self.file = requests.get(self.url).json()
            self.file = self.file['records']
            self.df = pd.DataFrame(data=self.file)

        def converter(self):
            """"""
            Converting the dtypes from object to int for ints, and date to date
            Also renames the columns to more visual-friendly names
            :return: None
            """"""
            self.df['cases'] = self.df['cases'].astype(int)
            self.df['deaths'] = self.df['deaths'].astype(int)
            self.df['popData2018'] = self.df['popData2018'].astype(str).replace('', 0).astype(int)
            self.df['dateRep'] = self.df['dateRep'].to_timestamp
            cols_rename = 'date day month year cases deaths country geo_id country_id population continent'.split()
            cols_rename = [s.capitalize() for s in cols_rename]
            self.df.columns = cols_rename

        def return_df(self):
            """"""
            :return: pandas DataFrame
            """"""
            self.converter()
            return self.df
</code></pre>

<p>app.py</p>

<pre><code>from plotly.offline import plot
import plotly.graph_objects as go
from dataframe.dataframe import DataFrame
from flask import Flask, render_template, redirect, request, url_for

app = Flask(__name__)


def graph_maker():
    df = DataFrame().return_df()
    data = []

    for continent in df['Continent'].unique():
        df_filt = df[df['Continent'] == continent]
        data.append(go.Scatter(x=df_filt[""Cases""],
                               y=df_filt[""Deaths""],
                               mode='markers',
                               text=df_filt['Country'],
                               name=continent))

    layout = go.Layout(title=""Deaths (Y) v Cases (X) by continent"")

    fig = go.Figure(data=data, layout=layout)

    return plot(figure_or_data=fig,
                include_plotlyjs=False,
                output_type='div')


@app.route('/')
def index():
    graph = graph_maker()
    return render_template('index.html',
                           graph=graph)


if __name__ == '__main__':
    app.run(debug=True)
</code></pre>

<p>index.html</p>

<pre><code>{% extends ""navbar.html"" %}
&lt;head&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;link type=""text/css"" rel=""stylesheet"" href=""..\static\master.css""&gt;
    &lt;link href=""https://fonts.googleapis.com/css2?family=Maven+Pro&amp;display=swap"" rel=""stylesheet""&gt;
    &lt;!-- Plotly.js --&gt;
    &lt;script src=""https://cdn.plot.ly/plotly-latest.min.js""&gt;&lt;/script&gt;

&lt;/head&gt;
{% block nbar %}
&lt;body&gt;
&lt;div class=""global-box"" id=""global-stats""&gt;
    &lt;h1&gt;Global charts&lt;/h1&gt;
    &lt;p&gt;Title here&lt;/p&gt;
    &lt;ul class=""global-box-ul""&gt;
        &lt;li class=""global-box-ul-li""&gt;
            {{ graph }}
        &lt;/li&gt;
        &lt;li class=""global-box-ul-li""&gt;
            Another chart here
        &lt;/li&gt;
    &lt;/ul&gt;
&lt;/div&gt;
&lt;/body&gt;
{% endblock %}
</code></pre>

<p>navbar.html</p>

<pre><code>&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
&lt;head&gt;
    &lt;title&gt;C19DB&lt;/title&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;link type=""text/css"" rel=""stylesheet"" href=""..\static\master.css""&gt;
    &lt;link href=""https://fonts.googleapis.com/css2?family=Maven+Pro&amp;display=swap"" rel=""stylesheet""&gt;
&lt;/head&gt;

&lt;nav class=""navbar""&gt;
    &lt;div class=""logo""&gt;c19db&lt;/div&gt;
    &lt;div class=""list""&gt;
    &lt;ul class=""navbar_items""&gt;
       &lt;li class=""navbar_item""&gt;&lt;a href=""#""&gt;Dashboard&lt;/a&gt;&lt;/li&gt;
       &lt;li class=""navbar_item""&gt;&lt;a href=""#""&gt;About&lt;/a&gt;&lt;/li&gt;
       &lt;li class=""navbar_item""&gt;&lt;a href=""#""&gt;Register&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
    &lt;/div&gt;
&lt;/nav&gt;

{% block nbar %}

{% endblock %}
&lt;/html&gt;
</code></pre>

<p>master.css</p>

<pre><code>html, body {
    font-family: 'Maven Pro';
    height: 700px;
    margin: 0;
}

.navbar {
    background: rgb(237, 232, 232);
    vertical-align: middle;
}

.logo {
    vertical-align: middle;
    display: inline-block;
    color: rgb(196, 69, 69);
    font-size: 50px;
    width: 250px;
    padding: 5px 15px 5px 15px;
}

.list{
    vertical-align: middle;
    display: inline-block;
    width: calc(100% - 285px);
    text-align: right;
}

.navbar_items {
    list-style: none;
    font-size: 20px;
    color: rgb(61, 61, 61)
}

.navbar_item{
    display: inline-block;
    padding: 5px 15px 5px 15px;
}

a {
    text-decoration: none;
}

.navbar_item &gt; a{
    display: inline-block;
    padding: 5px 15px 5px 15px;
    color: rgb(61, 61, 61);
}

.navbar_item &gt; a:hover {
    display: inline-block;
    padding: 5px 15px 5px 15px;
    color: rgb(196, 69, 69);
}

.footer, .footer a {
    position: relative;
    background: rgb(237, 232, 232, 0.2);
    width: 100%;
    color: rgb(61, 61, 61, 0.2);
    text-align: center;
}

span {
    font-weight: bold;
}

.global-box {
    text-align: center;
    border: 2px black solid;
    list-style: none;
    margin: auto;
}

.global-box &gt; h1, .global-box &gt; p {
    margin: 1px;
}

ul {
    display: contents;
}

.global-box-ul-li {
    display: inline-block;
    border: 2px lightblue solid;
    list-style: none;
    margin: auto;
    width: 48%;
    height: 100%;
}
</code></pre>

<p>Thank you for any help!</p>
"
60548131,"<p>I am writing a site in Python, Django. After updating PyCharm, the HTML page in the browser displays not its contents, but the code! What can be done with this?</p>

<p>Here's how it displays in a browser:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;!DOCTYPE html&gt;
&lt;html lang=""en""&gt;
&lt;head&gt;
    &lt;meta charset=""UTF-8""&gt;
    &lt;link href=""https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css"" rel=""stylesheet"" integrity=""sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh"" crossorigin=""anonymous""&gt;
    &lt;title&gt;News Agent&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;

    &lt;a href=""https://www.cbsnews.com/live-updates/coronavirus-outbreak-death-toll-us-infections-latest-news-updates-2020-03-05/""&gt;hhjhj&lt;/a&gt;

    &lt;a href=""https://www.cbsnews.com/news/flat-earth-climate-change-conspiracies-students-teachers-war-on-science-cbsn-originals/""&gt;hhjhj&lt;/a&gt;

    &lt;a href=""https://www.cbsnews.com/news/mcconnell-slams-schumers-comments-on-supreme-court-justices-watch-live-stream-03-05-2020/""&gt;hhjhj&lt;/a&gt;

    &lt;a href=""https://www.cbsnews.com/news/first-coronavirus-death-california-linked-grand-princess-cruise-ship-quarantine/""&gt;hhjhj&lt;/a&gt;

    &lt;a href=""https://www.cbsnews.com/news/lori-vallow-update-extradited-idaho-charges-tylee-ryan-jj-missing/""&gt;hhjhj&lt;/a&gt;

    &lt;a href=""https://www.cbsnews.com/news/james-paul-markowitz-border-patrol-waited-to-call-for-help-after-us-man-who-died-in-custody-showed-signs-distress/""&gt;hhjhj&lt;/a&gt;

    &lt;a href=""https://www.cbsnews.com/news/bernie-sanders-says-joe-biden-should-be-winner-of-democratic-nomination-if-he-has-plurality-of-delegates/""&gt;hhjhj&lt;/a&gt;

    &lt;a href=""https://www.cbsnews.com/news/mlks-son-asks-alabama-to-stop-looming-execution-of-nathaniel-woods/""&gt;hhjhj&lt;/a&gt;

    &lt;a href=""https://www.cbsnews.com/news/stock-markets-down-coronavirus-hit/""&gt;hhjhj&lt;/a&gt;

&lt;/body&gt;
&lt;/html&gt;</code></pre>
</div>
</div>
</p>

<p>Code from the view:</p>

<pre><code>def index(request):
    url = ""https://www.cbsnews.com/""
    all_links = get_all_links(get_html(url))
    for link in all_links:
         html = get_html(link)

    return render(request, 'main/index.html', {'all_links': all_links})
</code></pre>
"
60730105,"<p>So I'm trying to get the left bar of this website: <a href=""https://experience.arcgis.com/experience/685d0ace521648f8a5beeeee1b9125cd"" rel=""nofollow noreferrer"">https://experience.arcgis.com/experience/685d0ace521648f8a5beeeee1b9125cd</a> to get the current WHO coronavirus data. I'm locating the countries by Xpath, my code is:</p>

<pre><code>from selenium import webdriver

import time


driver = webdriver.Firefox()

driver.get(""link_to_the_page"")

time.sleep(30)


countries = country = ""/html/body/div/div/div[2]/div/div/div/margin-container/full-container/div[10]/margin-container/full-container/div/div[2]/nav/span/div/div/p/span""

countries_name = driver.find_elements_by_xpath(countries)
</code></pre>

<p>But when I run this, the list is empty which is weird because the page looks exactly the same when being displayed by Firefox using Selenium. So why can't the browser find the elements?</p>
"
61668712,"<p>I'm using VirtualStudio code and when I print page_soup I get a whole bunch of html code, but it seems to be missing the beginning lines including the first ""doctype html"" statement. </p>

<pre><code>   import bs4
import urllib
from urllib.request import  urlopen as uReq
from urllib.request import Request, urlopen
from bs4 import BeautifulSoup as soup

#For sites that can't be opened due to Urllib blocker, use a Mozilla User agent to get access
pageRequest = Request('https://coronavirusbellcurve.com/', headers = {'User-Agent': 'Mozilla/5.0'})
htmlPage = urlopen(pageRequest).read()


page_soup = soup(htmlPage, 'html.parser')
print(page_soup)
</code></pre>
"
61688655,"<p>There are 8 individual tr tags inside of a Tbody, with their own respective contents. I count 8 in the source from the page, and when I run len(inTbody) it tells me 8, so I know there are 8 tr tags. However, when I do inTbody[0], it returns blank. inTbody[1] gives me the contents of only the first tr tag. When I do inTbody[7] it lists the contents of the 4th tr tag, which should really be the 3rd tr tag due to computer indexes, but alongside listing the contents of the 4th tr tag, it lists the contents of the 5th, 6th, 7th, and 8th! It seems so arbitrary and randomized, Ive spent over an hour trying to figure out the ordering of the indexes amongst the tags and contents and I'm really lost.</p>

<pre><code>import csv
import bs4
import urllib
from urllib.request import  urlopen as uReq
from urllib.request import Request, urlopen
from bs4 import BeautifulSoup as soup

#For sites that can't be opened due to Urllib blocker, use a 
#Mozilla User agent to get access
pageRequest = Request('https://coronavirusbellcurve.com/', headers 
= {'User-Agent': 'Mozilla/5.0'})
htmlPage = urlopen(pageRequest).read()
page_soup = soup(htmlPage, 'html.parser')
#overarchDiv = page_soup.findAll(""div"",{""class"": ""main""})
specificDiv = page_soup.find(""div"", {""class"": ""table-responsive- 
xl""})

inTbody = specificDiv.table.tbody.contents
print(len(inTbody))
print(inTbody[7])
</code></pre>
"
61197713,"<p>i am trying to pull information about corona cases by countries from worldometers.
For some reason i can not target specific TR Tags by classes (classes on them are just missing in python console but they have it in chrome developer). so i target all of the tr elements and then filter them. everything works fine but for some strange reason CHINA is missing from top 10 countries. Nothing is different about china's html tags but still i cant put it there. any ideas?
'''</p>

<pre><code>r = requests.get(""https://www.worldometers.info/coronavirus/"")
content = r.content
soup = BeautifulSoup(content, ""html.parser"")
all_rows = soup.find_all(""tr"") 
startingIndex = None

for index,each in enumerate(all_rows,start=0):
    if ""World"" in each.text: # After that word ""WORLD"" comes TR elements of individual countries. 
        startingIndex = index
        break

top10 = all_rows[startingIndex+1:startingIndex+11] # here i select top 10 countries that i need.

for index,each in enumerate(top10,start = 1):
    droebiti_list = each.text.split(""\n"")
    print(f""{index}){droebiti_list[1]} - {droebiti_list[6]}"") # and printing info about recovered people
</code></pre>

<p>.</p>

<p>'''</p>
"
61461364,"<p><a href=""https://www.apple.com/covid19/mobility"" rel=""nofollow noreferrer"">https://www.apple.com/covid19/mobility</a></p>

<pre><code>source=requests.get(""https://www.apple.com/covid19/mobility"")
soup=BeautifulSoup(source.text,""lxml"")
</code></pre>

<p>I'm currently trying to get the url contained in the All Data CSV button which can be found by inspecting element. The <code>requests.get</code> doesn't seem to return the full body and all the  elements.</p>
"
60913130,"<p>there is something wrong for extract all data using python scraping</p>

<pre class=""lang-py prettyprint-override""><code>from bs4 import BeautifulSoup 
import requests 

url = ""https://www.worldometers.info/coronavirus/"" 
req_data = requests.get(url)
soup = BeautifulSoup(req_data.text, 'html.parser') 
table = soup.find('table', attrs={'id': 'main_table_countries_today'}) 
for row in table.findAll('tr', attrs = {'class':['odd','even','total_row']}): 
    print(row.text)
</code></pre>
"
61695200,"<p>I am trying to extract data (59,805) from the mentioned URL. And I am using BeautifulSoup and requests package of Python.</p>

<p>Below is the code I am trying, however its giving me no result. Down below is the HTML code, where from I am trying to extract. The result should be 'Confirmed', 59,805</p>

<pre><code>import requests
from bs4 import BeautifulSoup as bs
import pandas as pd

case_type = []
count = []

url = requests.get('https://www.covid19india.org/')
soup = bs(url.content,'html.parser')

for a in soup.findAll('div',  attrs={'class':'level-item is-cherry fadeInUp'}):
    b = a.find('h1')
    c = a.find('h5')
    case_type.append(c.text)
    count.append(b.text)

df = pd.DataFrame({'Case Type':case_type, 'Count':count})
print(df)
</code></pre>

<p>HTML code snippet from the said page</p>

<pre><code> &lt;div class=""Level""&gt;
      &lt;div class=""level-item is-cherry fadeInUp"" style=""animation-delay: 1s;""&gt;
        &lt;h5&gt;Confirmed&lt;/h5&gt;
        &lt;h4&gt;[+115]&lt;/h4&gt;
        &lt;h1&gt;59,805 &lt;/h1&gt;
      &lt;/div&gt;
      &lt;div class=""level-item is-blue fadeInUp"" style=""animation-delay: 1.1s;""&gt;
        &lt;h5 class=""heading""&gt;Active&lt;/h5&gt;
        &lt;h4&gt;&amp;nbsp;&lt;/h4&gt;
        &lt;h1 class=""title has-text-info""&gt;39,914&lt;/h1&gt;
      &lt;/div&gt;
      &lt;div class=""level-item is-green fadeInUp"" style=""animation-delay: 1.2s;""&gt;
        &lt;h5 class=""heading""&gt;Recovered&lt;/h5&gt;
        &lt;h4&gt;[+14]&lt;/h4&gt;
        &lt;h1 class=""title has-text-success""&gt;17,901 &lt;/h1&gt;
      &lt;/div&gt;
</code></pre>
"
61339899,"<p>I am trying to scrap data from <a href=""http://covid.gov.pk/stats/pakistan"" rel=""nofollow noreferrer"">http://covid.gov.pk/stats/pakistan</a>. I want the script to be able to click the date range picker to change the dates, but I cannot seem to select it the XPATH I am using is as follows.</p>

<pre><code>//*[@id=""body""]/div/div/div[1]/div[2]/div/div[1]/div[1]/div[1]/div/lego-report/lego-canvas-container/div/file-drop-zone/span/content-section/canvas-component[66]
</code></pre>

<p>Python script I am using</p>

<pre><code>from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

driver = webdriver.Chrome()
driver.implicitly_wait(30)
driver.get(""http://covid.gov.pk/stats/pakistan"")

#wait for Page to load
WebDriverWait(driver, 30, ).until(EC.invisibility_of_element((By.XPATH, ""//div[@id=\""preloader\""]"")))

#select date range picker
element = driver.find_element_by_xpath(""//*[@id=\""body\""]/div/div/div[1]/div[2]/div/div[1]/div[1]/div[1]/div/lego-report/lego-canvas-container/div/file-drop-zone/span/content-section/canvas-component[66]"")
element.click()
</code></pre>

<p>The error I encounter is as follows </p>

<blockquote>
  <p>Unable to locate element: {""method"":""xpath"",""selector"":""//*[@id=""body""]/div/div/div[1]/div[2]/div/div[1]/div[1]/div[1]/div/lego-report/lego-canvas-container/div/file-drop-zone/span/content-section/canvas-component[66]""}
    (Session info: chrome=81.0.4044.113)</p>
</blockquote>

<p>I can not seem to figure out what exactly isn't working I copied the xpath by inspecting the element using developer tools in chrome.</p>
"
61433218,"<p>I would like to convert the Last Updated time to EDT. Also, fix the alignment of the id and Values row. </p>

<pre><code>import requests
import json
import pandas as pd

state = input(""Enter two character state code eg: NY, CA: "")
url = ""https://covidtracking.com/api/states?state={}"".format(state)

result = requests.get(url)
dataobj = result.json()

# Only intersted in showing these keys and their associated values:
interested_keys = ['state','positive','dataQualityGrade','negative','pending','hospitalizedCurrently','hospitalizedCumulative','inIcuCurrently','inIcuCumulative','onVentilatorCurrently','onVentilatorCumulative','recovered','death','total','dateModified']

df = pd.DataFrame.from_dict(dataobj, orient='index',columns=['Values']).loc[interested_keys]
interested_now = ['State','Positive Cases','Data Quality Grade','Negative Cases','Pending Cases', 'Currently Hospitalized','Hospitalized Cumulative','In ICU Currently','In ICU Cumulative','On Ventilator Currently','On Ventilator Cumulative','Recovered','Deaths','Total Cases (Pos + Neg)','Last Updated']

df['id'] = interested_now

df.set_index('id' , inplace = True)
df.replace(to_replace=[None], value=""N/A"", inplace=True)
df
</code></pre>
"
60752050,"<pre><code>results = [] 
for tweet in tweepy.Cursor(api.search,
                           q=""coronavirus"",
                           result_type=""recent"",
                           include_entities=True,
                           wait_on_rate_limit=True,
                           wait_on_rate_limit_notify=True,
                           lang=""en"").items(50):
        results.append(tweet)
</code></pre>

<p>I know how to search keyword by using tweepy.cursor. But I want to append tweets only that a particular user has over 10000 followers and satisfy the keyword criterion. I am not sure how to do these two things simultaneously. Could anyone help? Thanks! </p>
"
60872246,"<p>I tried to predict the number of infected people proceeding as follows:</p>

<ul>
<li><p>Create a df with data</p></li>
<li><p>Filtering data and calculate the field 'new_postives'</p></li>
<li><p>Plot curve</p></li>
<li><p>Create a polinomial function with high R-Sqaure</p></li>
<li><p>Plot polinomial curve</p></li>
<li><p>Trying to predict data</p></li>
</ul>

<p>Here below the code with which I tried to forecast the number of infected people for day 45 (day_pred=45) that is very close to the last day in the database (day 43, infected 3039).
My question is:
Since I have a good previsional curve (in red) that is actually showing a prevision, why my my prevision is not coherent with the curve? Where I was wrong?
I am not looking for advice on the type of curve used to describe the epidemic but I am looking for advice on how to make predictions that are in line with the model I created (with the polynomial curve I found). Can anyone help me?</p>

<pre><code>'exec(%matplotlib inline)'
import pandas as pd
import seaborn as sns
import numpy as np
import io
import requests
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
import statsmodels.api as sm



url='https://raw.githubusercontent.com/pcm-dpc/COVID-19/master/dati-regioni/dpc-covid19-ita-regioni.csv'
s=requests.get(url).content
df=pd.read_csv(io.StringIO(s.decode('utf-8')))
db=df
df1=df[df['denominazione_regione']=='Toscana']
df_new_pos=df[['dates','new_postives']]
df_new_pos=df_new_pos.groupby('dates')['new_postives'].sum().reset_index()
df_new_pos['dates']=df_new_pos['dates'].apply(lambda x: x[:x.find(' 1')])
df_new_pos['dates']=df_new_pos['dates'].apply(lambda x: x[:x.find('T')])
df_new_pos=df_new_pos.reset_index()
plt.figure(figsize=(9,5))
plt.plot('index', 'new_postives', dates=df_new_pos, marker='o', markerfacecolor='red', markersize=4, color='black', linewidth=3)
plt.xticks(rotation=45)
plt.legend('Nuovi infetti COVID-19', loc='upper left')
plt.gcf().subplots_adjust(bottom=0.15)
plt.title('New_inf_Day_By_Day')

x=np.arange(df_new_pos['dates'].size)
y=np.array(df_new_pos['new_postives'].astype(int))
p4=np.poly1d(np.polyfit(x,y,4))
size=x.size
xp=np.linspace(0,size,size)
plt.plot(x, p4(xp),c='r')


from sklearn.metrics import r2_score
r2=r2_score(y,p4(x))
print(r2)
plt.title(""R2 = ""+str(r2)[:str(r2).find('.')+3])

scale = StandardScaler()
X=df_new_pos[['new_postives']]
y=x

X[['new_postives']]=scale.fit_transform(X[['new_postives']].values)
X=np.array(X)
X.reshape(-1,1)

est = sm.OLS(y, X).fit()

print(est.summary())
day_pred=45
scaled = scale.transform([[day_pred]])
predicted = est.predict(scaled[0])
predicted=int(round(predicted.max()))

plt.text(0,3500,'Prevision for day '+str(day_pred)+' is '+str(predicted)[1:str(predicted).find('.')+3]+' infected')


plt.savefig(""COVID_new_infected_previsional.png"")

</code></pre>
"
61423054,"<p>I am trying to make a dashboard with plotly Dash using COVID-19 dataset available from here: <a href=""https://github.com/RamiKrispin/coronavirus-csv"" rel=""nofollow noreferrer"">https://github.com/RamiKrispin/coronavirus-csv</a></p>

<p>Now, I want to show summary for the country selected through dropdown menu. But, I can't figure out how to just display the variable value.</p>

<p>I have done this for the total summary like this:
<a href=""https://i.stack.imgur.com/1udK2.png"" rel=""nofollow noreferrer"">Summary using just HTML</a></p>

<pre><code>html.Div([html.H1('Summary'),

                              html.Div([html.H2('Confirmed'), 
                                        html.H2(t_confirmed)
                                       ], style = {'width': '30%','display': 'inline-block', 'border':'2px solid black', 'text-align' : 'center', 'font-family': 'Century Gothic'}),
                              html.Div([html.H2('Recovered'), 
                                        html.H2(t_recovered)
                                       ], style = {'width': '30%','display': 'inline-block', 'border':'2px solid black', 'text-align' : 'center', 'font-family': 'Century Gothic'}),
                              html.Div([html.H2('Deaths'), 
                                        html.H2(t_deaths)
                                       ], style = {'width': '30%','display': 'inline-block', 'border':'2px solid black', 'text-align' : 'center', 'font-family': 'Century Gothic'}),

                             ], style = {'width': '50%','display': 'inline-block', 'vertical-align' : 'top', 'font-family' : 'Century Gothic'})
</code></pre>

<p>What I want is, the values should change according to the country selected. I have the code and function which returns these values to me according to country. No idea how to display them. Any help would be appreciated!</p>
"
60930720,"<p>I am trying to import the data found on this website (<a href=""http://epidemicforecasting.org/"" rel=""nofollow noreferrer"">http://epidemicforecasting.org/</a>) into a Pandas Dataframe. Ideally, I would like the daily forecasts for every country and each mitigation scenario.</p>

<p>The link to the data on their website is contained in here: <a href=""https://storage.googleapis.com/static-covid/static/data-main-v3.json"" rel=""nofollow noreferrer"">https://storage.googleapis.com/static-covid/static/data-main-v3.json</a></p>

<p>The documentation provided: <a href=""https://github.com/epidemics/covid/blob/master/docs/data-specification.md#plotly-traces"" rel=""nofollow noreferrer"">https://github.com/epidemics/covid/blob/master/docs/data-specification.md#plotly-traces</a></p>

<p>The data I want seems to be stored under the Plotly Traces. </p>

<p>I have tried:</p>

<pre><code>import pandas
df = pandas.read_json(""https://storage.googleapis.com/static-covid/static/data-main-v3.json"")
</code></pre>

<p>But because the data is located in a url within several layers of nesting it does not help me. </p>

<p>Is it possible to import all countries data into a pandas dataframe just using Python code?</p>
"
61325317,"<p>I'm scraping worldometers home page to pull the data in the table in Python, but I am struggling as the values aren't pulling in correctly. (The strings are... (Country: USA, Spain, Italy...). </p>

<pre><code>import requests
import lxml.html as lh
import pandas as pd
from tabulate import tabulate

url=""https://www.worldometers.info/coronavirus/""
#Create a handle, page, to handle the contents of the website
page = requests.get(url)
#Store the contents of the website under doc
doc = lh.fromstring(page.content)
#Parse data that are stored between &lt;tr&gt;..&lt;/tr&gt; of HTML
tr_elements = doc.xpath('//tr')

#Create empty list
col=[]
colLen = len(tr_elements[1])
i=0
#For each row, store each first element (header) and an empty list
for t in tr_elements[0]:
    i+=1
    name=t.text_content()
    print ('%d:""%s""'%(i,name))
    col.append((name,[]))

print(colLen)


#Since out first row is the header, data is stored on the second row onwards

for j in range(1,len(tr_elements)):
    #T is our j'th row
    T=tr_elements[j]

    if len(T)!=len(tr_elements[0]): break

    #i is the index of our column
    i=0
    #Iterate through each element of the row
    for t in T.iterchildren():
        data=t.text_content() 
        #Append the data to the empty list of the i'th column
        col[i][1].append(data)
        #Increment i for the next column
        i+=1

Dict={title:column for (title,column) in col}
df=pd.DataFrame(Dict)
df.head()

#Print Total Cases Col (this is incorrect when comparing to the webpage)
print(col[1][0:])

#Print Country Col (this is correct)
print(col[0][0:])

</code></pre>

<p>I can't seem to figure out what the issue is. Please help to solve the issue. I'm also open for suggestion to do this another way :)</p>

<p><a href=""https://i.stack.imgur.com/3zZEW.png"" rel=""nofollow noreferrer"">Data Table on Webpage</a></p>

<p><a href=""https://i.stack.imgur.com/fUZmU.png"" rel=""nofollow noreferrer"">Command Prompt output for Country ( Correct)</a></p>

<p><a href=""https://i.stack.imgur.com/T9vId.png"" rel=""nofollow noreferrer"">Command Prompt output for Total Cases ( incorrect)</a></p>
"
60887286,"<p>I've recently got into coding and am now running a data analysis on open source Corona data.
I built an interactive graph using Python3 inside of Jupyter Notebook.
The only thing is, I built in an interaction but it is only showing inside of the Notebook, not when it is exported into a html. Could someone give me a hint of why this is? 
Many thanks in advance.</p>

<p>Code:</p>

<pre><code># Import the necessary packages

import pandas as pd
import numpy as np 
import requests
import io

from bokeh.io import push_notebook,output_file
from bokeh.io import show, curdoc
from bokeh.plotting import figure, output_notebook
from bokeh.models import HoverTool, ColumnDataSource, Select
from bokeh.layouts import row
from bokeh.models.tickers import FixedTicker
from bokeh.models.callbacks import CustomJS

from ipywidgets import interact

output_notebook()

#---------------------------------------------------------------------------------------------------   
# Import the data
#---------------------------------------------------------------------------------------------------

url = 'https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv&amp;filename=time_series_covid19_confirmed_global.csv'
s=requests.get(url).content

url2 = 'https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv&amp;filename=time_series_covid19_deaths_global.csv'
s2 =requests.get(url2).content

df = pd.read_csv(io.StringIO(s.decode('utf-8')))
df = df.fillna("""")

df2 = pd.read_csv(io.StringIO(s2.decode('utf-8')))
df2 = df2.fillna("""")

#--------------------------------------------------------------------------------------------------- 
# Number of reported Corona cases
#---------------------------------------------------------------------------------------------------

Numb_cases = df.iloc[:,0:2].merge(df.iloc[:,4:],how='inner',right_index=True,left_index=True).fillna("""")
Numb_cases.iloc[:,1] = Numb_cases.iloc[:,1]+ "" : "" + Numb_cases.iloc[:,0]
Numb_cases = Numb_cases.iloc[:,1:]
Numb_cases = Numb_cases.transpose()
Numb_cases.columns = Numb_cases.iloc[0,:]
Numb_cases = Numb_cases.iloc[1:,:]
Numb_cases.index = pd.to_datetime(Numb_cases.index)


#---------------------------------------------------------------------------------------------------
# Number of reported Corona deaths
#---------------------------------------------------------------------------------------------------

Numb_deaths = df2.iloc[:,0:2].merge(df2.iloc[:,4:],how='inner',right_index=True,left_index=True).fillna("""")
Numb_deaths.iloc[:,1] = Numb_deaths.iloc[:,1]+ "" : "" + Numb_deaths.iloc[:,0]
Numb_deaths = Numb_deaths.iloc[:,1:]
Numb_deaths = Numb_deaths.transpose()
Numb_deaths.columns = Numb_deaths.iloc[0,:]
Numb_deaths = Numb_deaths.iloc[1:,:]

dates = pd.DataFrame(Numb_deaths.index)

Numb_deaths.index = pd.to_datetime(Numb_deaths.index)

#---------------------------------------------------------------------------------------------------
# Create the interactive graphs
#---------------------------------------------------------------------------------------------------

x = Numb_deaths.index
countries = list(Numb_cases.columns)

#plot1
source = ColumnDataSource(data={
'x' : Numb_cases.index,
'y' : Numb_cases
})

p = figure(x_axis_type=""datetime"", plot_width=400, plot_height=400, tools=""box_zoom,reset"")

p.yaxis.axis_label = ""Total Number of Cases""
p.xaxis.axis_label = ""Date""

countries = list(Numb_cases.columns)

# Create a HoverTool: hover
hover = HoverTool(tooltips = [('Numb cases:', '@y'),('Date :','$x{%F}')],formatters={'$x': 'datetime'},mode='mouse')

# Add the hover tool to the figure p
p.add_tools(hover)


#Plot2
source2 = ColumnDataSource(data={
'x' : Numb_deaths.index,
'y' : Numb_deaths
})

p2 = figure(x_axis_type=""datetime"", plot_width=400, plot_height=400,tools=""box_zoom,reset"")

p2.yaxis.axis_label = ""Total Number of Deaths""
p2.xaxis.axis_label = ""Date""


countries = list(Numb_deaths.columns)

# Create a HoverTool: hover
hover = HoverTool(tooltips = [('Numb deaths:', '@y'),('Date :','$x{%F}')],formatters={'$x': 'datetime'},mode='mouse')

# Add the hover tool to the figure p
p2.add_tools(hover)

# Define a callback function: update_plot
def update(Country):
source.data = {
        'x' : x,
        'y' : Numb_cases.loc[:,Country]
    }
p.circle('x', 'y',source=source ,size=10,
     fill_color='grey', alpha=0.40, line_color='grey',
     hover_fill_color='firebrick', hover_alpha=0.90,
     hover_line_color='white')
source2.data = {
        'x' : x,
        'y' : Numb_deaths.loc[:,Country]
    }
p2.circle('x', 'y',source=source2 ,size=10,
     fill_color='grey', alpha=0.40, line_color=None,
     hover_fill_color='firebrick', hover_alpha=0.90, 
     hover_line_color='white')
push_notebook()

interact(update, Country=countries)

show(row(p,p2),notebook_handle=True)
</code></pre>

<p><a href=""https://i.stack.imgur.com/5NZRb.png"" rel=""nofollow noreferrer"">Graph inside of Jupyter Notebook</a></p>

<p><a href=""https://i.stack.imgur.com/HwnkL.png"" rel=""nofollow noreferrer"">Graph inside of an exported html</a></p>
"
61606348,"<p>I have 2 models: Patient and Location. Locations are connected to Patients 1-to-1. When a user goes into a PatientDetailView for a specific patient, he can query for the locations with same names between patients. The user is choosing the query location from a dropdown menu. </p>

<p>Currently, the dropdown menu shows all the Location objects but I want to show only the locations connected to this specific patient whose DetailView we are in. </p>

<p>Basically, I want this line to query locations which are connected to the patient whose DetailView we are in.</p>

<pre><code>queryset=Location.objects.all().order_by('location_name')
</code></pre>

<p>View</p>

<pre><code>def profile_search(request,pk):
    if request.method == 'POST':
        query_form = QueryForm(request.POST)
        if query_form.is_valid():
            model=Location

            location = query_form.cleaned_data['location']
            location_str = str(location).split(',')[0]
            period = query_form.cleaned_data['period']


            entry_list = list(Location.objects.all())
            return_dict = {}


            for i in range(len(entry_list)):
                if location_str == entry_list[i].location_name and \ 
                   location.patient.idn != entry_list[i].patient.idn:

                    print('match')

            return render(request, 'covidapp/query_page.html',{'return_dict':return_dict, 'query_form':query_form})

    else:
        query_form = QueryForm()

    return render(request, 'covidapp/query_page.html',{'query_form':query_form})
</code></pre>

<p>Form:</p>

<pre><code>class QueryForm(forms.Form):
    period = forms.IntegerField()
    location = forms.ModelChoiceField(queryset=Location.objects.all().order_by('location_name'))
</code></pre>

<p>Models:</p>

<pre><code>
class Patient(models.Model):
    name = models.CharField(max_length=200)
    idn = models.CharField(max_length=200, unique=True)
    date_of_birth = models.DateField()
    date_of_confirm = models.DateField()
    case_number = models.IntegerField()

    def get_absolute_url(self):
        return reverse(""patient_detail"", kwargs={'pk':self.pk})

    def __str__(self):
        return self.name

class Location(models.Model):
    patient = models.ForeignKey(Patient, related_name='locations', on_delete=models.CASCADE, null=True, blank=True)
    location_name = models.CharField(max_length=50, null=True, blank=True)
    address = models.CharField(max_length=300, null=True, blank=True)
    district = models.CharField(max_length=300, null=True, blank=True)
    grid_x = models.IntegerField(null=True, blank=True)
    grid_y = models.IntegerField(null=True, blank=True)
    date_from = models.DateField(null=True, blank=True)
    date_to = models.DateField(null=True, blank=True)
    details = models.CharField(max_length=300, null=True, blank=True)
    category = models.CharField(max_length=300, null=True, blank=True)

    def __str__(self):
        return self.location_name
</code></pre>

<p>I thought I could make use of <code>instance</code> but that only works for ModelForms and my Form is not connected to any models.</p>
"
61060503,"<p>I am having difficulties parsing the layers of this KML file in R and Python.  I have included a link to download the file from my Dropbox.  This file was shared with me oringinally.  However, I am being told the file originates at <a href=""https://www.distilleriesfightingcovid.com"" rel=""nofollow noreferrer"">Distilleries Fighting Covid</a>, but I couldn't figure out how to find it or get to it.</p>

<p>What I am wanting is to extract all layers and ultimately separate them into their own <code>csv</code> files.  The nodes that I am wanting to retrieve are Name, Address, City, State, Zip.  The closest that I have gotten with this is from the stack post <a href=""https://gis.stackexchange.com/questions/194945/read-multiple-layers-of-kml-file-using-r"">Read multiple layers of KML file using R</a>.  </p>

<p>For this first attempt, my code looks as follows:</p>

<pre><code>library(rgdal)
allKmlLayers &lt;- function(kmlfile){
  lyr &lt;- ogrListLayers(kmlfile)
  mykml &lt;- list()
  for (i in 1:length(lyr)){
    mykml[i] &lt;- readOGR(kmlfile, lyr[i])
  }
  names(mykml) &lt;- lyr
  return(mykml)
}

kmlfile &lt;- ""Distilleries and Hospitals.kml""
mykml &lt;- allKmlLayers(kmlfile)
</code></pre>

<p>However, when doing so, I am getting the following error and warning:</p>

<blockquote>
  <p>Error in readOGR(""Distilleries and Hospitals.kml"", ""Distilleries"") :<br>
  no features found In addition: Warning message: In ogrFIDs(dsn = dsn,
  layer = layer) : no features found</p>
</blockquote>

<p>Now, I am able to read the layers stored in the lyr variable.</p>

<p>The code below will produce a list of 7.</p>

<pre><code>lyr &lt;- ogrListLayers(""Distilleries and Hospitals.kml"")
</code></pre>

<p>Next, I tried to just pull from he one layer with the following code:</p>

<pre><code>mykml &lt;- readOGR(""Distilleries and Hospitals.kml"", ""Distilleries"")
</code></pre>

<p>This resulted in the following error and warning (same as above):</p>

<blockquote>
  <p>Error in readOGR(""Distilleries and Hospitals.kml"", ""Distilleries"") :<br>
  no features found In addition: Warning message: In ogrFIDs(dsn = dsn,
  layer = layer) : no features found</p>
</blockquote>

<p>Finally, I tried to use a similar approach with the <code>lapply</code> using the <code>sf</code> package.</p>

<pre><code>library(sf)
kmlfile &lt;- ""Distilleries and Hospitals.kml""
mykml &lt;- lapply(lyr, function(i) st_read(kmlfile, i))
names(mykml) &lt;- lyr
</code></pre>

<p>I get 7 0x3 lists with no information.</p>

<p>Any assistance with this would be wonderful.</p>

<p>One final note, if you do end up getting the file from the website instead, please note that there are several instances near the end of the file where R won't read the file (at least not for me) because of special characters.  The error will tell you where this is when using the sf function.</p>

<p>Thank you for your time on this.</p>

<p><a href=""https://www.dropbox.com/sh/ivhetranxuvprz9/AADVp-31mCqVQcBP194qSv8Oa?dl=0"" rel=""nofollow noreferrer"">KML File at Dropbox for Download (~28mb)</a></p>

<p>Edit 1:
From a comment left below, it seems that the layers are empty in this file.  If that is accurate, then the question is, how would I get the data I need out of this file and into a CSV file.</p>

<p>Edit 2:
Further Investigation the KML document it appears that all of my information may be found within the <code>placemark</code> tags (...).  However, I am not certain how to pull that data out.  This is the ultimate goal.  If these are not layers, then it would be great if someone could point me in the direction to solving this.  Again, I want to thank you in advance for all of your help.</p>

<p>Edit 3 Data Excerpt and Python Attempt:
I have manually manipulated the file to remove everything that I am not really interested in having in the long run.  Below is a small excerpt of the file.  It lists the first three companies.</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;kml xmlns=""http://www.opengis.net/kml/2.2""&gt;
  &lt;Document&gt;
    &lt;Folder&gt;
      &lt;name&gt;Distilleries&lt;/name&gt;
      &lt;Placemark&gt;
        &lt;name&gt;Bomb City Enterprises&lt;/name&gt;
        &lt;description&gt;&lt;![CDATA[Address: 306 S Cleveland St&lt;br&gt;Address Line2: &lt;br&gt;City: Amarillo&lt;br&gt;Location: Alabama&lt;br&gt;State_Abbrev: AL&lt;br&gt;Postal Code: 79102&lt;br&gt;unnamed (1): &lt;br&gt;unnamed (2): &lt;br&gt;unnamed (3): &lt;br&gt;Updated 2020-04-12 20:30:13.383810: ]]&gt;&lt;/description&gt;
        &lt;ExtendedData&gt;
          &lt;Data name=""Address""&gt;
            &lt;value&gt;306 S Cleveland St&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""Address Line2""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
          &lt;Data name=""City""&gt;
            &lt;value&gt;Amarillo&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""Location""&gt;
            &lt;value&gt;Alabama&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""State_Abbrev""&gt;
            &lt;value&gt;AL&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""Postal Code""&gt;
            &lt;value&gt;79102&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""unnamed (1)""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
          &lt;Data name=""unnamed (2)""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
          &lt;Data name=""unnamed (3)""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
          &lt;Data name=""Updated 2020-04-12 20:30:13.383810""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
        &lt;/ExtendedData&gt;
      &lt;/Placemark&gt;
      &lt;Placemark&gt;
        &lt;name&gt;Cahaba Brewing Company&lt;/name&gt;
        &lt;address&gt;4500 5th Ave. S building C Birmingham Alabama AL 35222&lt;/address&gt;
        &lt;description&gt;&lt;![CDATA[Address: 4500 5th Ave. S&lt;br&gt;Address Line2: building C&lt;br&gt;City: Birmingham&lt;br&gt;Location: Alabama&lt;br&gt;State_Abbrev: AL&lt;br&gt;Postal Code: 35222&lt;br&gt;unnamed (1): &lt;br&gt;unnamed (2): &lt;br&gt;unnamed (3): &lt;br&gt;Updated 2020-04-12 20:30:13.383810: ]]&gt;&lt;/description&gt;
        &lt;styleUrl&gt;#icon-1517-0288D1&lt;/styleUrl&gt;
        &lt;ExtendedData&gt;
          &lt;Data name=""Address""&gt;
            &lt;value&gt;4500 5th Ave. S&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""Address Line2""&gt;
            &lt;value&gt;building C&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""City""&gt;
            &lt;value&gt;Birmingham&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""Location""&gt;
            &lt;value&gt;Alabama&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""State_Abbrev""&gt;
            &lt;value&gt;AL&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""Postal Code""&gt;
            &lt;value&gt;35222&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""unnamed (1)""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
          &lt;Data name=""unnamed (2)""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
          &lt;Data name=""unnamed (3)""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
          &lt;Data name=""Updated 2020-04-12 20:30:13.383810""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
        &lt;/ExtendedData&gt;
      &lt;/Placemark&gt;
      &lt;Placemark&gt;
        &lt;name&gt;Redmont Distilling Company&lt;/name&gt;
        &lt;address&gt;4550 5th Ave South building N Birmingham Alabama AL 35222&lt;/address&gt;
        &lt;description&gt;&lt;![CDATA[Address: 4550 5th Ave South&lt;br&gt;Address Line2: building N&lt;br&gt;City: Birmingham&lt;br&gt;Location: Alabama&lt;br&gt;State_Abbrev: AL&lt;br&gt;Postal Code: 35222&lt;br&gt;unnamed (1): &lt;br&gt;unnamed (2): &lt;br&gt;unnamed (3): &lt;br&gt;Updated 2020-04-12 20:30:13.383810: ]]&gt;&lt;/description&gt;
        &lt;styleUrl&gt;#icon-1517-0288D1&lt;/styleUrl&gt;
        &lt;ExtendedData&gt;
          &lt;Data name=""Address""&gt;
            &lt;value&gt;4550 5th Ave South&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""Address Line2""&gt;
            &lt;value&gt;building N&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""City""&gt;
            &lt;value&gt;Birmingham&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""Location""&gt;
            &lt;value&gt;Alabama&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""State_Abbrev""&gt;
            &lt;value&gt;AL&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""Postal Code""&gt;
            &lt;value&gt;35222&lt;/value&gt;
          &lt;/Data&gt;
          &lt;Data name=""unnamed (1)""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
          &lt;Data name=""unnamed (2)""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
          &lt;Data name=""unnamed (3)""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
          &lt;Data name=""Updated 2020-04-12 20:30:13.383810""&gt;
            &lt;value/&gt;
          &lt;/Data&gt;
        &lt;/ExtendedData&gt;
      &lt;/Placemark&gt;
      &lt;Placemark&gt;
</code></pre>

<p>Since I have had no luck with R, I have added my Python attempt below.  I am hoping.  However, with the added data, if someone is able to do this in R, I will be happy with that as well.</p>

<p>What I am trying to get is first the name.  Then from the extended data section, I am looking ultimatly to get Address 1, Address 2, City, State Abbreviation, and Zip.  I am fine if I end up with everything so long as it puts an empty field where there is no data.  For example, Address 2 is often empty, just return an empty field and keep moving so that when I merge the lists, everything lines up.</p>

<p>The example below only attempts to get Name and Address Line 1.  I figure, if I can get this, then I should be able to extend it all the way.</p>

<p>The additional code that I have tried is below:</p>

<pre><code>import xml.etree.ElementTree as et

doc = et.parse(filename)
nmsp = '{http://www.opengis.net/kml/2.2}'

name = []
address1 = []

for pm in doc.iterfind('.//{0}Placemark'.format(nmsp)):
    print(pm.find('{0}name'.format(nmsp)).text)
    name.append(pm.find('{0}name'.format(nmsp)).text)
    for adr1 in pm.iterfind('{0}ExtendedData//{0}value'.format(nmsp)):
        address1.append(adr1.text.strip().replace('\n',''))
        print(adr1.text.strip().replace('\n',''))

</code></pre>

<p>When I run this, I get the first record with the first address line 1 perfectly, but I also get the following error:</p>

<blockquote>
  <p>AttributeError: 'NoneType' object has no attribute 'strip'</p>
</blockquote>

<p>I believe that this is because in the first record, Address 2 is empty.  Therefore, I believe that this is trying actually pull everything at once from the extended Data which is also not what I want.</p>

<p>The real difficulty I am having is pulling the <code>&lt;Data name = ""...""&gt; ... &lt;/Data&gt;</code> fields.</p>

<p>This is my first crack at XML/KML parsing, so any help I would greatly appreciate.  I really have not a clue what to try next at this point.  </p>

<p>End file will be a CSV file with headers: Name, Address 1, Address 2, City, State, Zip.  Honestly, I am also fine just getting rid of Address 2 as well.  It's not critical to have.</p>

<p>If you need further clarification, please just ask.  Thank you in advance for your time.</p>
"
61033141,"<p>I am trying to get Covid-19 JSON data from <a href=""http://europepmc.org/"" rel=""nofollow noreferrer"">Europe Pubmed Central</a>. The JSON results returned by Europe PMC server looks like <a href=""https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=(%E2%80%9C2019-nCoV%E2%80%9D)&amp;format=json"" rel=""nofollow noreferrer"">this</a>.</p>

<p>My initial code querying the server looks like this:</p>

<pre><code>import requests
import json


mydata = ""https://www.ebi.ac.uk/europepmc/webservices/rest/search?query=(%E2%80%9C2019-nCoV%E2%80%9D)&amp;format=json""

#get Server response
reply = requests.get(mydata)

#print out results
print(reply.json())
</code></pre>

<p>I wish to get rid of these part of the JSON:</p>

<pre><code>{'version': '6.2', 'hitCount': 847, 'nextCursorMark': 'AoIIQVJxdCg0MTI2NjU3Mw==', 'request': {'queryString': '(“2019-nCoV”)', 'resultType': 'lite', 'cursorMark': '*', 'pageSize': 25, 'sort': '', 'synonym': False}, 'resultList':
</code></pre>

<p>How can i get rid of this part in python? I apologize in advance for the long url querystring.</p>
"
61598369,"<p>I've currently hit a roadblock with a python parser that I'm supposed to use to extract information from a website that is tracking COVID-19 cases in the state of Michigan. The parser is utilizing the XML Dom Minidom library from python and works as intended, but when I go to insert the information into a MySQL database, it yields no results, and instead has an empty table. I'm not sure what's wrong with my code, and I've tried multiple things including:</p>

<ul>
<li>Converting the list that stores the scraped data into a tuple</li>
<li>Looping through the list and executing the insert statement
... and other minor tweaks to no avail. The table is supposed to have the county name, confirmed cases, and confirmed deaths in a format like this:</li>
</ul>

<p>+--------------+----------------+-----------------+</p>

<p>| countyName   | confirmedCases | confirmedDeaths |</p>

<p>+--------------+----------------+-----------------+</p>

<p>Can someone please help me?</p>

<p>Here's the file, parser.py:</p>

<pre><code>import sys
import xml.dom.minidom
import MySQLdb
document = xml.dom.minidom.parse(sys.argv[1])
tableElements = document.getElementsByTagName('table')

db = MySQLdb.connect(
      host=""localhost"",
      user=""root"",
      passwd=""root"",
      db=""temp""
)

curr = db.cursor()

curr.execute(""CREATE DATABASE IF NOT EXISTS cases"")
curr.execute(""USE cases"")
query = ""CREATE TABLE IF NOT EXISTS casesBreakdown (countyName varchar(255), confirmedCases INT, confirmedDeaths INT, newCases INT, newDeaths INT)""
curr.execute(query)

#for tr in tableElements[1].getElementsByTagName('tr'):
for tr in tableElements[0].getElementsByTagName('tr'):
      data = []
      for td in tr.getElementsByTagName('td'):
      for node in td.childNodes:
              if node.nodeType == node.TEXT_NODE:
                  data.append(node.nodeValue)
      x = "","".join(data)
      test = []
      for case in x.split("",""):
          test.append(case)
      #print(test)
sql = ""INSERT INTO casesBreakdown (countyName, confirmedCases, confirmedDeaths) VALUES (%s, %s, %s)""
curr.executemany(sql, test)

db.commit()
</code></pre>

<p>And here's the link to the page that I've converted into xhtml using tagsoup that I'm passing as a command line arg:
<a href=""https://pastebin.com/JU8cDJJ5"" rel=""nofollow noreferrer"">https://pastebin.com/JU8cDJJ5</a></p>

<p>Any help would be much appreciated. Thanks!</p>
"
61204746,"<p>I'm trying to run an sql commands with sqlalchemy in python, all the queries I'm trying to do are running successfully besides one, and the error I get is about syntax. when I take the code the an sql environment it works successfully. Here is the code I'm trying to run (this part is working!):</p>

<pre><code>con.execute(""USE covid19_korea"")
con.execute(""SET @currdate := (select min(confirmed_date) from facts)"")
con.execute(""SET @enddate :=  (select DATE_ADD((select max(confirmed_date) from facts), INTERVAL 14 DAY))"")
</code></pre>

<p>From this part it doesn't work:</p>

<pre><code>query = """"""
        delimiter $$
        DROP PROCEDURE IF EXISTS BuildDate$$
        CREATE PROCEDURE BuildDate()
            BEGIN
                 WHILE @currdate &lt; @enddate DO
                    INSERT INTO Dimension_Date (date, day, month, year, day_name)
                    VALUES (
                             @currdate, DAY(@currdate), MONTH(@currdate), YEAR(@currdate), DAYNAME(@currdate)
                            );
                    SET @currdate:= DATE_ADD(@currdate, INTERVAL 1 DAY);
                END WHILE;

            END$$
        CALL BuildDate();""""""

con.execute(query)
</code></pre>

<p>and here is the error I get:</p>

<pre><code>ProgrammingError: (pymysql.err.ProgrammingError) (1064, **""You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'delimiter $$\n        DROP PROCEDURE IF EXISTS BuildDate$$\n        CREATE PROCEDU' at line 1"")**
[SQL: 
        delimiter $$
        DROP PROCEDURE IF EXISTS BuildDate$$
        CREATE PROCEDURE BuildDate()
            BEGIN
                 WHILE @currdate &lt; @enddate DO
                    INSERT INTO Dimension_Date (date, day, month, year, day_name)
                    VALUES (
                             @currdate, DAY(@currdate), MONTH(@currdate), YEAR(@currdate), DAYNAME(@currdate)
                            );
                    SET @currdate:= DATE_ADD(@currdate, INTERVAL 1 DAY);
                END WHILE;

            END$$
        CALL BuildDate();]
(Background on this error at: http://sqlalche.me/e/f405)
</code></pre>
"
61265239,"<p>In python, I am trying to insert some data into my table;</p>

<pre><code>   try:
        cursor.execute(""INSERT INTO covid_testtable (pid, age, state, city, notes, backnotes, type, nationality, status, announced, changed) "" +
                ""VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, STR_TO_DATE(%s, '%%d/%%m/%%Y'), STR_TO_DATE(%s, '%%d/%%m/%%Y'))"",
            (pid, age, item[""detectedstate""], item[""detectedcity""], item[""notes""], item[""backupnotes""], item[""typeoftransmission""],
                item[""nationality""], item[""currentstatus""], dateannounced, statuschanged));
    except ValueError as verr:
        print(item[""dateannounced""], verr);
        break;
</code></pre>

<p>This works till a point where one of the date columns have a empty entry.</p>

<pre><code>pymysql.err.InternalError: (1411, ""Incorrect datetime value: '' for function str_to_date""
</code></pre>

<p>I tried to change the value of the empty date to ""<strong>00/00/0000</strong>"" however it seems the issue is with the <strong>str_to_date</strong>() function.
I am fine with inserting <strong>NULL</strong> value however, not managing to insert.</p>

<p>The valid values which are succesfully inserted are of this format ""<strong>30/01/2020</strong>"" -> ""<strong>%d/%m/%Y</strong>"" </p>

<p>My table schema is as below:</p>

<pre><code>create table covid_testtable ( pid int NOT NULL, age int, state VARCHAR(255), 
city VARCHAR(255), notes VARCHAR(255), backnotes VARCHAR(255), type VARCHAR(255), 
nationality VARCHAR(255), status VARCHAR(255), announced DATE default NULL, 
changed DATE default NULL,  PRIMARY KEY (pid));
</code></pre>

<p><strong>EDIT 2: Selected Answer solved this issue:</strong></p>

<pre><code>def validate_date(val):
    try:
        return datetime.strptime(val, '%d/%m/%Y').strftime('%Y-%m-%d');
    except ValueError as verr:
        return None;

    dateannounced = validate_date(item[""dateannounced""]);
    statuschanged = validate_date(item[""statuschangedate""]);
    try:
        cursor.execute(""INSERT INTO covid_testtable (pid, age, state, city, notes, backnotes, type, nationality, status, announced, changed) "" +
                ""VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)"",
            (pid, age, item[""detectedstate""], item[""detectedcity""],
                item[""notes""], item[""backupnotes""], item[""typeoftransmission""],
                item[""nationality""], item[""currentstatus""], dateannounced,
                statuschanged));
</code></pre>
"
61036695,"<p>I'm trying to do two things here:</p>

<ol>
<li>Import all the .csv files and add them up to a df. </li>
<li>Update the df with the latest file uploaded.</li>
</ol>

<p>I have been able to import one .csv with:</p>

<pre><code>import pandas as pd
url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-22-2020.csv' 
pd.read_csv(url).fillna(0)
</code></pre>

<p>I could import all the <code>.csv</code> files one per one (or with a loop if I knew how to extract all the <code>.csv</code> filenames), but there should be a more efficient way. Once I have the df, to ""update"" it I would:</p>

<ol>
<li>Extract all the <code>.csv</code> filenames.</li>
<li>Check if all of them are in the df (with the date column). If one is missing, add the missing .csv file to the df.</li>
</ol>

<p>The problems I'm having are: (a) how can I make scalable the way to extract all the .csv files? and (b) is there any way to extract ONLY the filenames that end with <code>.csv</code> from the github folder? In order to do (2) of above.</p>
"
60844520,"<p>Do you have idea how to quickly transform a data :</p>

<p>FROM : </p>

<p>import pandas as pd</p>

<p>url_confirmed = """"""<a href=""https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv&amp;filename=time_series_covid19_deaths_global.csv"" rel=""nofollow noreferrer"">https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv&amp;filename=time_series_covid19_deaths_global.csv</a>""""""</p>

<p>read_confirmed=pd.read_csv(url_confirmed)</p>

<p>read_confirmed.head()</p>

<p>TO:</p>

<p>url_confirmed2 = """"""<a href=""https://data.humdata.org/hxlproxy/data/download/time_series-ncov-Confirmed.csv?dest=data_edit&amp;filter01=explode&amp;explode-header-att01=date&amp;explode-value-att01=value&amp;filter02=rename&amp;rename-oldtag02=%23affected%2Bdate&amp;rename-newtag02=%23date&amp;rename-header02=Date&amp;filter03=rename&amp;rename-oldtag03=%23affected%2Bvalue&amp;rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&amp;rename-header03=Value&amp;filter04=clean&amp;clean-date-tags04=%23date&amp;filter05=sort&amp;sort-tags05=%23date&amp;sort-reverse05=on&amp;filter06=sort&amp;sort-tags06=%23country%2Bname%2C%23adm1%2Bname&amp;tagger-match-all=on&amp;tagger-default-tag=%23affected%2Blabel&amp;tagger-01-header=province%2Fstate&amp;tagger-01-tag=%23adm1%2Bname&amp;tagger-02-header=country%2Fregion&amp;tagger-02-tag=%23country%2Bname&amp;tagger-03-header=lat&amp;tagger-03-tag=%23geo%2Blat&amp;tagger-04-header=long&amp;tagger-04-tag=%23geo%2Blon&amp;header-row=1&amp;url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">https://data.humdata.org/hxlproxy/data/download/time_series-ncov-Confirmed.csv?dest=data_edit&amp;filter01=explode&amp;explode-header-att01=date&amp;explode-value-att01=value&amp;filter02=rename&amp;rename-oldtag02=%23affected%2Bdate&amp;rename-newtag02=%23date&amp;rename-header02=Date&amp;filter03=rename&amp;rename-oldtag03=%23affected%2Bvalue&amp;rename-newtag03=%23affected%2Binfected%2Bvalue%2Bnum&amp;rename-header03=Value&amp;filter04=clean&amp;clean-date-tags04=%23date&amp;filter05=sort&amp;sort-tags05=%23date&amp;sort-reverse05=on&amp;filter06=sort&amp;sort-tags06=%23country%2Bname%2C%23adm1%2Bname&amp;tagger-match-all=on&amp;tagger-default-tag=%23affected%2Blabel&amp;tagger-01-header=province%2Fstate&amp;tagger-01-tag=%23adm1%2Bname&amp;tagger-02-header=country%2Fregion&amp;tagger-02-tag=%23country%2Bname&amp;tagger-03-header=lat&amp;tagger-03-tag=%23geo%2Blat&amp;tagger-04-header=long&amp;tagger-04-tag=%23geo%2Blon&amp;header-row=1&amp;url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_19-covid-Confirmed.csv</a>""""""</p>

<p>read_confirmed2=pd.read_csv(url_confirmed2)</p>

<p>read_confirmed2.loc[1:].head()</p>

<p>I want to have a dates which are presented as columns transform to row</p>

<p><a href=""https://i.stack.imgur.com/nxUAL.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nxUAL.png"" alt=""enter image description here""></a></p>
"
60731929,"<h2>Background</h2>

<p>I am looking at the <strong>Coronavirus dataset</strong> from CSSEGISandData (github.com/CSSEGISandData/COVID-19.git). I am trying to create a <strong>plotly choropleth map</strong> that shows the <strong>number of cases for each US county</strong>. </p>

<p>Here is an example of the csv dataset from CSSEGISandData. I have <strong>concatenated multiple days</strong> into one file: </p>

<pre><code>         Province/State Country/Region         Last Update  Confirmed  \
259               Chicago             US 2020-01-24 17:00:00        1.0   
3028           Orange, CA             US 2020-02-01 19:53:00        1.0   
2445       San Benito, CA             US 2020-02-03 03:53:02        2.0   
3181      San Antonio, TX             US 2020-02-13 18:53:02        1.0   
4762  Humboldt County, CA             US 2020-02-21 05:13:09        1.0   

      Deaths  Recovered  Latitude  Longitude            file  \
259      0.0        0.0       NaN        NaN  01-24-2020.csv   
3028     0.0        0.0       NaN        NaN  02-01-2020.csv   
2445     0.0        0.0       NaN        NaN  02-24-2020.csv   
3181     0.0        0.0   29.4241   -98.4936  03-04-2020.csv   
4762     0.0        0.0       NaN        NaN  02-27-2020.csv  

</code></pre>

<h2>Problem</h2>

<p>I want to modify this plotly example ( <a href=""https://plot.ly/python/mapbox-county-choropleth/"" rel=""nofollow noreferrer"">https://plot.ly/python/mapbox-county-choropleth/</a> ) and use the counties from my dataframe, to do this i first need to: </p>

<ol>
<li>Match all counties in my file, to fips codes. </li>
</ol>

<p>I found a list of fips codes here (<a href=""https://github.com/kjhealy/fips-codes"" rel=""nofollow noreferrer"">https://github.com/kjhealy/fips-codes</a>) : </p>

<pre><code>   fips            name state
0     0   UNITED STATES   NaN
1  1000         ALABAMA   NaN
2  1001  Autauga County    AL
3  1003  Baldwin County    AL
4  1005  Barbour County    AL
</code></pre>

<p>How do I create a new column in my pandas dataframe, with the right fips code?</p>

<p>Here is my code importing the COVID data and the fips codes</p>

<pre class=""lang-py prettyprint-override""><code>!git clone https://github.com/CSSEGISandData/COVID-19.git

#@title Import and Option to show print more data 
import pandas as pd 
import glob


#Get the coronavirus data for the US 
path = r'/content/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports' # use your path
all_files = glob.glob(path + ""/*.csv"") #collect all files in one
li = []
for filename in all_files:
    df = pd.read_csv(filename, index_col=None, header=0)
    li.append(df)
df = pd.concat(li, axis=0, ignore_index=True, sort=False) #one dataframe
filter_USA=frame['Country/Region']=='US'
USA= frame[filter_USA]
print (USA.head())


#Get the county data for the US with fips 
county_url= 'https://raw.githubusercontent.com/kjhealy/fips-codes/master/state_and_county_fips_master.csv'
county = pd.read_csv(county_url)
print ( county.head()) 

</code></pre>

<p>Now I need to match the USA Province/State names with the county names, and assign the the fips value.</p>

<pre class=""lang-py prettyprint-override""><code>#somethin like 
for all USA['Province/State'] match to county.name
USA['fips'] = county match fips value
</code></pre>

<h2>EDIT</h2>

<p>Putting in a longer version fo the dataframe to show the different problems with the names: </p>

<ul>
<li>upper and lower case problem</li>
<li>some are city names not counties </li>
<li>some have added writing to them</li>
</ul>

<pre><code>3027                                Los Angeles, CA
2369                                Santa Clara, CA
2003                                 San Benito, CA
2310                                    Madison, WI
2470                                    Seattle, WA
6175                                    Chicago, IL
2237                           San Diego County, CA
2805                           San Diego County, CA
1765                                San Antonio, TX
3657                            Humboldt County, CA
737                                 Santa Clara, CA
3629                           San Diego County, CA
2468                          Sacramento County, CA
1543                                    Ashland, NE
1549                                     Travis, CA
1560                                   Lackland, TX
420            Lackland, TX (From Diamond Princess)
410              Travis, CA (From Diamond Princess)
404               Omaha, NE (From Diamond Princess)
6436              Omaha, NE (From Diamond Princess)
4289           Lackland, TX (From Diamond Princess)
5047             Travis, CA (From Diamond Princess)
2421    Unassigned Location (From Diamond Princess)
1769                                      Tempe, AZ
303     Unassigned Location (From Diamond Princess)
4981    Unassigned Location (From Diamond Princess)
5015                          Sacramento County, CA
4208    Unassigned Location (From Diamond Princess)
</code></pre>
"
61414269,"<p>I have a problem updatding a column value from a second dataframe that is a dictiorany/catalog.</p>

<p>This is my main dataframe (df)</p>

<p><a href=""https://i.stack.imgur.com/BT4zW.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BT4zW.png"" alt=""df dataframe""></a></p>

<p>and the dictionary dataframe (dictionary)</p>

<p><a href=""https://i.stack.imgur.com/i8CEa.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/i8CEa.png"" alt=""dictionary dataframe""></a></p>

<p>I want to update the column df.City of the main df from the dictionary with the condition where df.id_state = dictiorary.ID_State and df.ID_City = dictionary.Id_City.</p>

<p>I don't know how to do that with a dictionary with 3 columns. I already did it with a normal dictionary of 2 columns.</p>

<p>rename_dict_E = df_Ent.set_index('ID_State').to_dict()['State']
df_CovidMx.ID_State = df_CovidMx.ID_State.replace(rename_dict_E)</p>

<p>I hope somebody can give me a hand!</p>

<p>Regard. Im learning Python</p>
"
61691382,"<p>I am trying to create a corona tracker using a entry widget except everytime i try to search two times the search result shows two times. <a href=""https://prnt.sc/sdj5rj"" rel=""nofollow noreferrer"">Here</a> is the picture.</p>

<p>I have tried deleting the variable when the button widget but it didnt work.</p>

<pre><code>import sqlite3
import tkinter

db = sqlite3.connect ('covidjakartadb.db')

window = tkinter.Tk()
window.geometry(""500x300"")
window.title(""Corona tracker"")

label = tkinter.Label(window, text=""Please enter a area"")
label.pack()

entry = tkinter.Entry(window)
entry.pack()

def Search_Completed():
    # select_all = ""SELECT * FROM locations WHERE '%{0}%'"".format(entry)
    select_all = ""SELECT positive FROM locations WHERE City LIKE '%{0}%'"".format( entry.get() )
    cursor = sqlite3.Cursor(db)
    cursor.execute(select_all)
    positive = cursor.fetchall()
    print (positive)
    tkinter.Label (window, text=positive, font='Ariel 25 bold').pack()
    tkinter.Label (window, text=""Tips to fight off the coronavirus"")


Button = tkinter.Button(window, text=""Search data"", command=Search_Completed)
Button.pack()

window.mainloop()
</code></pre>
"
60745932,"<p>I need to update a SQL Server database using a stored procedure and a table as a parameter using <code>PYODBC</code>. The stored procedure should be fine but I'm not sure about the syntax used in the Python script:</p>

<p>Python:</p>

<pre><code>import pandas as pd
import pyodbc

# Create dataframe
data = pd.DataFrame({
    'STATENAME':[state1, state2],
    'COVID_Cases':[value1, value2],
})

data

conn = pyodbc.connect('Driver={SQL Server};'
                      'Server=mydb;'
                      'Database=mydbname;'
                      'Username=username'
                      'Password=password'
                      'Trusted_Connection=yes;')

cursor = conn.cursor()

params = ('@StateValues', data)
cursor.execute(""{CALL spUpdateCases (?,?)}"", params)
</code></pre>

<p>Stored procedure:</p>

<pre><code>[dbo].[spUpdateCases]
    @StateValues tblTypeCOVID19 readonly,
    @Identity int out
AS
BEGIN
    INSERT INTO tblCOVID19 
        SELECT * FROM @StateValues

    SET @Identity = SCOPE_IDENTITY()
END
</code></pre>

<p>Here is my user-defined type:</p>

<pre><code>CREATE TYPE [dbo].[tblTypeCOVID19] AS TABLE
                                      (
                                          [ID] [int] NOT NULL,
                                          [StateName] [varchar](50) NULL,
                                          [COVID_Cases] [int] NULL,
                                          [DateEntered] [datetime] NULL
                                      )
</code></pre>

<p>I'm not getting any error when executing the Python script.</p>
"
60522775,"<p>I have multiple documents and each document has a set of tweets.
I can find the document by name as follows:</p>

<pre><code>client = MongoClient('localhost', 27017)
db = client['sample_app']
s = db['s']
s.find(
            {
                ""name"": ""temp16""
            }
        )
</code></pre>

<p>When I run the above query I get the following data:</p>

<pre><code>{""_id"": {""$oid"": ""5e57db66c6bb04eb902589a2""}, ""name"": ""temp16"", ""tweets"": [{""tweet_id"": ""1234762637361086465"", ""tweet_text"": ""Had an extensive review regarding preparedness on the COVID-19 Novel Coronavirus. Different ministries &amp; states are working together, from screening people arriving in India to providing prompt medical attention."", ""tweet_handle"": ""@narendramodi"", ""labels"": [""A"", ""B"", ""C"", ""D"", ""E""]}, {""tweet_text"": ""There is no need to panic. We need to work together, take small yet important measures to ensure self-protection."", ""tweet_id"": ""1234762662413660165"", ""tweet_handle"": ""@narendramodi"", ""labels"": [""A"", ""B"", ""C"", ""D"", ""E"", ""F""]}]}
</code></pre>

<p>My intention is to get the tweet with id <code>""1234762662413660165""</code> in this document alone. So I try the following:</p>

<pre><code>s.find(
            {
                ""name"": ""temp16"",
                'tweets': {""tweet_id"": ""1234762662413660165""}
            },
        )
</code></pre>

<p>However I get <code>None</code></p>

<p>What am I doing wrong?</p>
"
61029574,"<p>I'm trying to write a small piece of Python code to extract the data from the <a href=""https://www.gstatic.com/covid19/mobility/2020-03-29_GB_Mobility_Report_en.pdf"" rel=""nofollow noreferrer"">UK Google Community Mobility Reports</a> to a CSV file. </p>

<p>To do this I'm using this code:</p>

<pre><code>import PyPDF2

FILE_PATH = '....2020-03-29_GB_Mobility_Report_en.pdf'
file = open(FILE_PATH, 'rb')
fileReader = PyPDF2.PdfFileReader(file)

for each in range(fileReader.numPages):
     print(fileReader.getPage(each).extractText())
</code></pre>

<p>However, when I try to print the content of each page it prints no text. The code opens the correct file as it gives the correct number of pages. Why is the case &amp; how can I fix it?</p>
"
61307961,"<h3>Hi everybody</h3>

<p>I would like to add a button inside a popup you can click on it and show or hide a table. I have been trying lots of ways, but it is imposible. I only get the button and the table, but when I click on the button, nothing happens...</p>

<p>I followed a <a href=""https://www.w3schools.com/howto/tryit.asp?filename=tryhow_js_toggle_hide_show"" rel=""nofollow noreferrer"">example</a>, but it was useless...</p>

<p>Before I forget it, I'm working with R and Shiny to build a map about coronavirus of my region.</p>

<p>This is the code I'm using:</p>

<pre><code>boton.popup&lt;-c(""&lt;button onclick='myFunction()'&gt;Mostrar tabla&lt;/button&gt;"")

script.popup&lt;-c(""&lt;script&gt;
                      function myFunction() {
                        var x = document.getElementById('tabla');
                        if (x.style.display === 'none') {
                          x.style.display = 'block';
                        } else {
                          x.style.display = 'none';
                        }
                      }
                    &lt;/script&gt;"")

def.popup&lt;-paste(""&lt;h4 style='text-align:center;'&gt;Información&lt;/h4&gt;"",""&lt;br/&gt;"",
                         ""&lt;b&gt;Municipio:&lt;/b&gt;"",n_casos@data$MUNICIPIO,""&lt;br/&gt;"",""&lt;br/&gt;"",
                         ""&lt;button onclick='myFunction()'&gt;Mostrar tabla&lt;/button&gt;"",""&lt;br/&gt;"",
                         ""&lt;div id='myDIV' style:'visibility: hidden'&gt;"",
                         ""&lt;table class='table' id='tabla'&gt;&lt;tr&gt;
                         &lt;td&gt;Nº de casos detectados&lt;/td&gt;
                         &lt;td&gt;"",n_casos@data$num_casos,""&lt;/td&gt;
                         &lt;/tr&gt;
                         &lt;tr&gt;
                         &lt;td&gt;Proporción respecto al total de infectados detectados (%)&lt;/td&gt;
                         &lt;td&gt;"",round(n_casos@data$num_casos*100/temp$Total2,2),""&lt;/td&gt;
                         &lt;/tr&gt;
                         &lt;tr&gt;
                         &lt;td&gt;Proporción de población del municipio infectada detectada (%) &lt;/td&gt;
                         &lt;td&gt;"",round(n_casos@data$num_casos*100/n_casos@data$POBLACION,2),""&lt;/td&gt;
                         &lt;/table&gt;"",
                         ""&lt;/div&gt;"",
                         script.popup)
</code></pre>

<p>Thanks a lot</p>
"
60852936,"<p>I am trying to scrape tables from this website and rvest returns empty list. It works for other websites. what can be the issue?</p>

<p>Thanks,</p>

<pre><code>library(rvest)
urlONGov &lt;- ""https://www.ontario.ca/page/2019-novel-coronavirus""
ONGov &lt;- urlONGov %&gt;%
  xml2::read_html() %&gt;%
  html_nodes(xpath='//*[@id=""pagebody""]/table[1]') %&gt;%
  html_table()
ONGov
</code></pre>
"
61280675,"<p>I am trying to scrape this webpage (<a href=""https://nc.211counts.org"" rel=""nofollow noreferrer"">https://nc.211counts.org</a>) for a given region and time ('Onslow', 'Yesterday' for example). I want to pull all of the information from that top left table (COVID, Housing, etc through Other). Unfortunately, the URL does not update when the filters are selected. I have been following the tutorial <a href=""https://callumgwtaylor.github.io/blog/2018/02/01/using-rselenium-and-docker-to-webscrape-in-r-using-the-who-snake-database/"" rel=""nofollow noreferrer"">here</a> but cannot find a way to pull in the position of the region names I need to scrape for. Since the <code>html_nodes</code> function is returning empty, I think there is something to the mapping that is off. </p>

<p>What am I missing here?</p>

<pre><code># docker run -d -p 4445:4444 selenium/standalone-chrome
# docker ps

remDr &lt;- RSelenium::remoteDriver(remoteServerAddr = ""localhost"",
                                 port = 4445L,
                                 browserName = ""chrome"")
remDr$open()

remDr$navigate(""https://nc.211counts.org"") 
remDr$screenshot(display = TRUE) 
nc211 &lt;- xml2::read_html(remDr$getPageSource()[[1]]) 

str(nc211)

body_nodes &lt;- nc211 %&gt;% 
  html_node('body') %&gt;% 
  html_children()

body_nodes

body_nodes %&gt;% 
  html_children()

rank &lt;- nc211 %&gt;% 
  rvest::html_nodes('body') %&gt;% 
  xml2::xml_find_all(""//span[contains(@class, 'col-lg-12 chosen-select')]"") %&gt;% 
  rvest::html_text()

# this returns empty
nc211 %&gt;%
  rvest::html_nodes(""#region"") %&gt;%
  rvest::html_children() %&gt;%
  rvest::html_text() 

# guessing at an element number to see what happens
element&lt;- remDr$findElement(using = 'css selector', ""#region &gt; option:nth-child(1)"")
element$clickElement()
</code></pre>
"
60927921,"<p>I am using beautifulsoup and python to crawl a web page and extract the text from the paragraph tag only from the website.
<a href=""https://www.who.int/csr/disease/coronavirus_infections/faq_dec12/en/"" rel=""nofollow noreferrer"">This is the page I want to crawl</a> 
I want all the texts in all the paragraph tag.</p>

<p>Thanks in advance</p>
"
61353136,"<p>I am looking at corona data from the NY Times which can be found here: <a href=""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv</a></p>

<p>And open for everyone to use. </p>

<p>The dataset is set up like this:</p>

<pre><code>df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')
df2 = df.copy()
df2 = df2.set_index('date')
df2['cases_lagged'] = df2.groupby(['county', 'state'])['cases'].shift()
df2[df2['fips']== 34041.0].head(10)
</code></pre>

<p>I was hoping I could create a moving average column the same way using a groupby statement along with the .rolling() command from pandas to compile a 7-day and 14-day moving average for the data but it does not work. </p>

<p>I tried it two separate ways:</p>

<pre><code>#way 1
df2['moving_avg'] = df2.groupby(['county', 'state']).iloc[:4].rolling(window = 7).mean()

#way 2
df2['moving_avg'] = df2.groupby(['county', 'state'])['cases'].rolling(window = 7).mean()
</code></pre>

<p>And neither seems to work here.</p>

<p>Any thoughts on how to compile the moving average for each county within each state without having to break out each and every county into its own df for it to work? Thanks</p>
"
60701254,"<p>I have been working with the Corona Virus Dataset from <a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"" rel=""nofollow noreferrer"">CSSEGISandData/COVID-19</a> I want to slice the important data like columns 1 to 3, namely: Country/ Region, Lat, Long and want to add the last column which keeps on changing every day. </p>

<pre><code>df_new = df[['Country/Region','Lat','Long']] 
</code></pre>

<p>does give me columns 1 to 3 I want to add the last column to this. </p>
"
61312134,"<p>I am new to python and trying to process the JSON from <a href=""https://opendata.ecdc.europa.eu/covid19/casedistribution/json/"" rel=""nofollow noreferrer"">here</a></p>

<p>I managed to get the data into python and also managed to extract some part from the JSON with:</p>

<pre><code>from urllib.request import urlopen
import json
req = urlopen(""http://opendata.ecdc.europa.eu/covid19/casedistribution/json/"")
response = req.read()
data = json.loads(response)

deaths = [i[""deaths""] for i in data[""records""]]

print(deaths)
</code></pre>

<p>How can I add a condition like for instance <code>i[""geoId""] == ""AF""</code> such that <code>deaths</code> only contains the deaths from Afghanistan?</p>
"
61484672,"<p><a href=""https://i.stack.imgur.com/eWo5x.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/eWo5x.png"" alt=""enter image description here""></a></p>

<p>I would like to redo this plot, which was published in one of the newspaper about Covid 19 death toll. I am not sure what kind of graph is this, I am assuming this is percent stacked area plot.</p>
"
60678274,"<p>I wonder whether there is a way in R to read data directly from (daily) updated Google Datastudio Report. The option to download CSV data manually from each chart is enabled (after login), but I am looking for an automated way to download the data. I thought about using <code>rvest</code> to scrape the data, but it is not embedded in the code (my knowledge of html/css/javascript is very limited)...</p>

<p>The data is on current covid-19 cases in the Czech Republic, it is published by the government, but original data in flat files is unfortunately not supplied anywhere.</p>

<p>The Google Datastudio Report I wanna download the data from is here: <a href=""https://datastudio.google.com/reporting/d0af39ad-3513-4ab9-a202-4afed1f786e2/page/DzlHB"" rel=""nofollow noreferrer"">https://datastudio.google.com/reporting/d0af39ad-3513-4ab9-a202-4afed1f786e2/page/DzlHB</a></p>
"
60815361,"<p>Suppose that I have a list of titles of Wikipedia articles and I would like to measure lexical inheritance between the articles.</p>

<pre><code>title &lt;- c(""virus"", 
  ""coronavirus"",
  ""Coronaviridae"",
  ""pandemic"", 
  ""2019–20_coronavirus_pandemic"", 
  ""Coronavirus_disease_2019"",
  ""Severe_acute_respiratory_syndrome_coronavirus_2"",
  ""Severe_acute_respiratory_syndrome_coronavirus"",
  ""Severe_acute_respiratory_syndrome-related_coronavirus"",
  ""syndrome"",
  ""disease"",
  ""infection""
  )

</code></pre>

<p>Here is a solution, but I presume that it is not the quickest way to do this task for long lists of titles. First, a function to get articles with Wikipedia API. </p>

<pre><code>GetArticle &lt;- function(title){
    library(xml2)
    library(httr)
    query &lt;- paste0(""https://en.wikipedia.org/w/api.php?"", 
                    ""action=query"", ""&amp;format=xml"", ""&amp;redirects"", ""&amp;prop=extracts"",
                    ""&amp;explaintext"",""&amp;titles="", title)
    answer &lt;- httr::GET(query)
    page.xml &lt;- xml2::read_xml(answer)
    page &lt;- xml2::xml_find_all(page.xml, ""//extract"")
    text &lt;- as.character(base::trimws(xml_text(page)))
  }
</code></pre>

<p>A function to compute lexical inheritance.</p>

<pre><code>  lexicalInheritance &lt;- function(text1, text2){
    tokens1 &lt;- tolower(unlist(strsplit(text1, "" "")))
    tokens2 &lt;- tolower(unlist(strsplit(text2, "" "")))
    intersection.v &lt;- sort(intersect(tokens1, tokens2))
    cardinalityOfIntersection &lt;- length(intersection.v)
    score &lt;- cardinalityOfIntersection / length(tokens2)
    return(score)
  }
</code></pre>

<p>A function to apply in the case of Wikipedia articles:</p>

<pre><code>MeasureLexicalInheritanceOfWikipediaArticlesFromtitle &lt;- function(title){
  start_time &lt;- Sys.time()
  article &lt;- unlist(lapply(title, GetArticle))
  cleanArticle &lt;- gsub(""[[:punct:]]"", """", article)
  cleanArticle &lt;- gsub(""[0-9]"", """", cleanArticle)
  titles.df &lt;- as.data.frame(expand.grid(title, title))
  names(titles.df) &lt;- c(""title1"", ""title2"")
  couples &lt;- as.data.frame(expand.grid(cleanArticle,cleanArticle))
  score &lt;- c()
  for (i in 1:length(article)) {
    index &lt;- lexicalInheritance (as.character(couples$Var1[i]), 
                               as.character(couples$Var2[i]))
    score &lt;- c(score, index)
  }
  results.df &lt;- cbind(titles.df, score)
  end_time &lt;- Sys.time()
  time &lt;- end_time - start_time
  print(time)
  return(results.df)
}
</code></pre>

<p>Results with time :</p>

<pre><code>results.df &lt;- MeasureLexicalInheritanceOfWikipediaArticlesFromtitle(title)
View(results.df)

Time difference of 1.89983 secs

system.time(MeasureLexicalInheritanceOfWikipediaArticlesFromtitle(title))
utilisateur     système      écoulé 
       0.98        0.00        3.67

</code></pre>

<p>Thank you very much for your help !</p>
"
61623368,"<p>I apologize if this has already been solved elsewhere. I found a similar question but there was no relevant answer.</p>

<p><strong>What I am trying to do:</strong> Creating a function that selects relevant observations in three different datasets by country code, makes basic operations on these observations, then join them by common variable ""Date""</p>

<p>More precisely, I am using OWID's covid datasets and my function is attempting to create a dataframe that contains the relevant information for a given country originally spread across two files.</p>

<p>The code is below:</p>

<p>owid_may5 is the Our World in Data testing dataset</p>

<p>owid_totalcases_may5 is the Our World in Data confirmed cases dataset</p>

<p>owid_daily_may5 is the Our World in Data confirmed deaths dataset</p>

<p>""country"" in the function argument is an ISO countrycode</p>

<pre><code>    TreatCountry&lt;- function(country) {
    ##This part of the function selects the data in relevant datasets
        filtered_country_tests &lt;- owid_may5 %&gt;% filter(Code=='country') 
        filtered_country_cases &lt;- owid_totalcases_may5 %&gt;% filter(Code=='country')
        filtered_country_deaths&lt;- owid_daily_may5 %&gt;% filter(Code=='country')
    ##This part of the function adds ""Newtest"" and ""Newcases"" columns calculated from the cumulative totals in the previous datasets
        filtered_country_tests$Newtests &lt;- diff( c(0, filtered_country_tests$Total.tests))
        filtered_country_cases$Newcases &lt;- diff( c(0, filtered_country_cases$cases ) )
##This part of the function joins the three datasets and then turns the result into POSIXt.
        joined&lt;- inner_join(filtered_country_tests,filtered_country_cases,by='Date')
        joined&lt;- inner_join(joined,filtered_country_deaths,by='Date')
        joined$Date &lt;- anytime(c(joined$Date))
        return(joined)
      }
</code></pre>

<p>As a result I get a dataframe with 12 variables (as expected) but...0 observations.</p>

<p>Now for the weird part:
<strong>When I type the exact same code but replace ""country"" by any countrycode, the code works as expected and I end up with a dataframe with all relevant variables and observations.</strong></p>

<p>Thanks in advance for the help</p>
"
61690576,"<pre><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19- 
timeseries/master/countryReport/raw/rawReport.csv',
            stringsAsFactors = FALSE)

# I did wrong.
df11 &lt;- aggregate(df$confirmed, by=list(df$countryName) subset(df,df$confirmed &lt; df$recovered) , FUN 
== ""max""))
</code></pre>

<p>within countries
Find the dates when the number of recovered has passed confirmation.</p>

<p>as output ;</p>

<pre><code>day              countryName        confirmed     recovered 
2020/04/10         Spain              1500          1550
2020/01/19         italy              862            900
...
</code></pre>

<p>data are examples. are not real values.</p>
"
61683888,"<p>I'm trying to generate a map with the countries of the European Union in which the countries are colored according to the number of confirmed cases per 100,000 inhabitants. I can properly plot the raw graph <img src=""https://i.stack.imgur.com/Cr4gk.png"" alt=""raw graph"">.</p>

<p>However, when I'm trying to add data the graph changes in a weird way and I can't figure out why. <img src=""https://i.stack.imgur.com/NlgJ0.png"" alt=""Weird graph"">.</p>

<p>Do you have any ideas on how to properly plot this?</p>

<pre><code># Collect data on Covid-19

# Direct use of function fromJSON
jsonLot &lt;-
   fromJSON(""https://pomber.github.io/covid19/timeseries.json"")

# Export downloaded data to file 'covid19.json'
myjsonLot   &lt;- toJSON(jsonLot, pretty=TRUE)
fileConn    &lt;- file(paste0(dirData, ""covid19.json""))
writeLines(myjsonLot, fileConn)
close(fileConn)

# Store data into separate dataframe
dfAustria &lt;- as.data.frame(jsonLot$Austria)
dfBelgium &lt;- as.data.frame(jsonLot$Belgium)
dfBulgaria &lt;- as.data.frame(jsonLot$Bulgaria)
dfCroatia &lt;- as.data.frame(jsonLot$Croatia)
dfCyprus &lt;- as.data.frame(jsonLot$Cyprus)
dfCzechia &lt;- as.data.frame(jsonLot$Czechia)
dfDenmark &lt;- as.data.frame(jsonLot$Denmark)
dfEstonia &lt;- as.data.frame(jsonLot$Estonia)
dfFinland &lt;- as.data.frame(jsonLot$Finland)
dfFrance &lt;- as.data.frame(jsonLot$France)
dfGermany &lt;- as.data.frame(jsonLot$Germany)
dfGreece &lt;- as.data.frame(jsonLot$Greece)
dfHungary &lt;- as.data.frame(jsonLot$Hungary)
dfIreland &lt;- as.data.frame(jsonLot$Ireland)
dfItaly &lt;- as.data.frame(jsonLot$Italy)
dfLatvia &lt;- as.data.frame(jsonLot$Latvia)
dfLithuania &lt;- as.data.frame(jsonLot$Lithuania)
dfLuxembourg &lt;- as.data.frame(jsonLot$Luxembourg)
dfMalta &lt;- as.data.frame(jsonLot$Malta)
dfNetherlands &lt;- as.data.frame(jsonLot$Netherlands)
dfPoland &lt;- as.data.frame(jsonLot$Poland)
dfPortugal &lt;- as.data.frame(jsonLot$Portugal)
dfRomania &lt;- as.data.frame(jsonLot$Romania)
dfSlovakia &lt;- as.data.frame(jsonLot$Slovakia)
dfSlovenia &lt;- as.data.frame(jsonLot$Slovenia)
dfSpain &lt;- as.data.frame(jsonLot$Spain)
dfSweden &lt;- as.data.frame(jsonLot$Sweden)

# Remove rows with zero cases
dfAustria &lt;- dfAustria[!dfAustria$confirmed == 0,]
dfBelgium &lt;- dfBelgium[!dfBelgium$confirmed == 0,]
dfBulgaria &lt;- dfBulgaria[!dfBulgaria$confirmed == 0,]
dfCroatia &lt;- dfCroatia[!dfCroatia$confirmed == 0,]
dfCyprus &lt;- dfCyprus[!dfCyprus$confirmed == 0,]
dfCzechia &lt;- dfCzechia[!dfCzechia$confirmed == 0,]
dfDenmark &lt;- dfDenmark[!dfDenmark$confirmed == 0,]
dfEstonia &lt;- dfEstonia[!dfEstonia$confirmed == 0,]
dfFinland &lt;- dfFinland[!dfFinland$confirmed == 0,]
dfFrance &lt;- dfFrance[!dfFrance$confirmed == 0,]
dfGermany &lt;- dfGermany[!dfGermany$confirmed == 0,]
dfGreece &lt;- dfGreece[!dfGreece$confirmed == 0,]
dfHungary &lt;- dfHungary[!dfHungary$confirmed == 0,]
dfIreland &lt;- dfIreland[!dfIreland$confirmed == 0,]
dfItaly &lt;- dfItaly[!dfItaly$confirmed == 0,]
dfLatvia &lt;- dfLatvia[!dfLatvia$confirmed == 0,]
dfLithuania &lt;- dfLithuania[!dfLithuania$confirmed == 0,]
dfLuxembourg &lt;- dfLuxembourg[!dfLuxembourg$confirmed == 0,]
dfMalta &lt;- dfMalta[!dfMalta$confirmed == 0,]
dfNetherlands &lt;- dfNetherlands[!dfNetherlands$confirmed == 0,]
dfPoland &lt;- dfPoland[!dfPoland$confirmed == 0,]
dfPortugal &lt;- dfPortugal[!dfPortugal$confirmed == 0,]
dfRomania &lt;- dfRomania[!dfRomania$confirmed == 0,]
dfSlovakia &lt;- dfSlovakia[!dfSlovakia$confirmed == 0,]
dfSlovenia &lt;- dfSlovenia[!dfSlovenia$confirmed == 0,]
dfSpain &lt;- dfSpain[!dfSpain$confirmed == 0,]
dfSweden &lt;- dfSweden[!dfSweden$confirmed == 0,]

# Import shape file
# Add the definition of the shape file subdirectory to the 
# path definitions 
dirNbh  &lt;- paste0(dirData, ""european-union-countries/"")

# Read the shape file from the subdirectory. The readOGR
# function is from the package rgdal.
dfShape &lt;- readOGR(paste0(dirNbh, ""european-union-countries.shp""), 
                   stringsAsFactors = FALSE)

dfShape &lt;- spTransform(dfShape, CRS(""+init=epsg:3035"")) 
dfShape &lt;- spTransform(dfShape, CRS(""+proj=longlat +datum=WGS84""))

#unique(dfShape@data$brk_name)

clipRdam &lt;- as(extent(-15, 38, 25, 75), ""SpatialPolygons"")


# Apply the coordinate reference system of dfShape.Rdam
# to clipRdam
proj4string(clipRdam) &lt;- CRS(proj4string(dfShape))


# Apply the clipping. The result is stored in dfShape.RdamClip
dfShape &lt;- intersect(dfShape, clipRdam)

ggplot(data = dfShape, aes(x = long, y = lat, group = group)) +
  geom_path()

dfData.EU &lt;- fortify(dfShape, region = ""name"")
# Source: https://www.worldometers.info/population/countries-in-europe-by-population/

# Read population data
popEU &lt;- read_delim(""C:/Users/wishi/OneDrive/Documenten/BIM/BDBA/Data/population.csv"", 
     "";"", escape_double = FALSE, trim_ws = TRUE)

popEU$cases &lt;- NULL

# Get latest confirmed cases 
dfAustria&lt;-(max(dfAustria$confirmed, na.rm = TRUE))
dfBelgium&lt;-(max(dfBelgium$confirmed, na.rm = TRUE))
dfBulgaria&lt;-(max(dfBulgaria$confirmed, na.rm = TRUE))
dfCroatia&lt;-(max(dfCroatia$confirmed, na.rm = TRUE))
dfCyprus&lt;-(max(dfCyprus$confirmed, na.rm = TRUE))
dfCzechia&lt;-(max(dfCzechia$confirmed, na.rm = TRUE))
dfDenmark&lt;-(max(dfDenmark$confirmed, na.rm = TRUE))
dfEstonia&lt;-(max(dfEstonia$confirmed, na.rm = TRUE))
dfFinland&lt;-(max(dfFinland$confirmed, na.rm = TRUE))
dfFrance&lt;-(max(dfFrance$confirmed, na.rm = TRUE))
dfGermany&lt;-(max(dfGermany$confirmed, na.rm = TRUE))
dfGreece&lt;-(max(dfGreece$confirmed, na.rm = TRUE))
dfHungary&lt;-(max(dfHungary$confirmed, na.rm = TRUE))
dfIreland&lt;-(max(dfIreland$confirmed, na.rm = TRUE))
dfItaly&lt;-(max(dfItaly$confirmed, na.rm = TRUE))
dfLatvia&lt;-(max(dfLatvia$confirmed, na.rm = TRUE))
dfLithuania&lt;-(max(dfLithuania$confirmed, na.rm = TRUE))
dfLuxembourg&lt;-(max(dfLuxembourg$confirmed, na.rm = TRUE))
dfMalta&lt;-(max(dfMalta$confirmed, na.rm = TRUE))
dfNetherlands&lt;-(max(dfNetherlands$confirmed, na.rm = TRUE))
dfPoland&lt;-(max(dfPoland$confirmed, na.rm = TRUE))
dfPortugal&lt;-(max(dfPortugal$confirmed, na.rm = TRUE))
dfRomania&lt;-(max(dfRomania$confirmed, na.rm = TRUE))
dfSlovakia&lt;-(max(dfSlovakia$confirmed, na.rm = TRUE))
dfSlovenia&lt;-(max(dfSlovenia$confirmed, na.rm = TRUE))
dfSpain&lt;-(max(dfSpain$confirmed, na.rm = TRUE))
dfSweden&lt;-(max(dfSweden$confirmed, na.rm = TRUE))

temp &lt;-
  as.data.frame(cbind(dfAustria, dfBelgium, dfBulgaria, dfCroatia,dfCyprus, dfCzechia,dfDenmark, dfEstonia, dfFinland, dfFrance, dfGermany, dfGreece, dfHungary, dfIreland, dfItaly, dfLatvia, dfLithuania, dfLuxembourg, dfMalta, dfNetherlands, dfPoland, dfPortugal, dfRomania, dfSlovakia, dfSlovenia, dfSpain, dfSweden))

# Switch the rows and the columns
temp = as.data.frame(t(temp))

popEU$cases &lt;- temp$V1

# Calculation
popEU['Relative'] = (popEU['cases'] / popEU['population']) * 100000

# remove redundant columns
popEU$population &lt;- NULL
popEU$cases &lt;- NULL

dfData.EUrel     &lt;- 
  merge(dfData.EU, popEU, by = ""id"", all.x = TRUE)


ggplot(data = dfData.EUrel, aes(x = long, y = lat, group = group)) +
  geom_polygon(aes(fill = Relative), colour = ""white"") +
  scale_fill_continuous(low=""white"", high=""red"")

</code></pre>
"
61415551,"<p>I am trying to plot country wise confirmed vs recovered graph where the country names will be in a drop down menu and at a time a particular country's graph can be seen. My data source is Johns Hopkins University Corona virus dataset. </p>

<p>The drop down menu is coming properly but the plot is not coming. I am having following issues. </p>

<ol>
<li>Plot confirmed vs recovered is not coming. Only marker is showing for China.</li>
<li>But for US and France nothing is visible.</li>
<li>Also the legends are not coming for US and France.</li>
</ol>

<p>Can anyone help me out? Let me know if you need more clarification or any other data.</p>

<pre><code>library(stringdist)    
library(plotly)    
library(magrittr)   
library(dplyr)

df_str &lt;- deparse(substitute(confirmed_raw))         
var_str &lt;- substr(df_str, 1, str_length(df_str) - 4)

# Clean up the Jhon Hopkins Data, make it short to long
clean_jhd_to_long &lt;- function(df) {   
  df_str &lt;- deparse(substitute(df))  
  var_str &lt;- substr(df_str, 1, str_length(df_str) - 4)    

  df%&gt;% group_by(`Country/Region`) %&gt;%   
    filter(`Country/Region` != ""Cruise Ship"") %&gt;%    
    select(-`Province/State`, -`Lat`, -`Long`) %&gt;%     
    summarise_all(funs(sum)) %&gt;%      
    distinct() %&gt;%   
    ungroup() %&gt;%       
    rename(country = `Country/Region`) %&gt;%      
    pivot_longer(-country, names_to = ""date_str"", values_to = var_str) %&gt;%    
    mutate(date = mdy(date_str)) %&gt;%     
    select(country, date, !! sym(var_str))    
}   

# Extract data     
confirmed_raw &lt;- read_csv(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master   /csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"")         
deaths_raw &lt;- read_csv(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"")   
recovered_raw &lt;- read_csv(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv"")

# Merge confirmed, deaths and recovered data     
jh_covid19_data &lt;- clean_jhd_to_long(confirmed_raw) %&gt;%     
  full_join(clean_jhd_to_long(deaths_raw)) %&gt;%     
  full_join(clean_jhd_to_long(recovered_raw))     

#Extract ""China"", ""US"" and ""France"" data     
confirmed_vs_recovered &lt;- jh_covid19_data %&gt;% filter(`country` == ""China"" | `country` == ""France"" | `country` == ""US"") %&gt;% group_by(`country`,`date`)       
countries &lt;- unique(pull(confirmed_vs_recovered, country))    
confirmed &lt;- confirmed_vs_recovered %&gt;% select(`confirmed`)     
recovered &lt;- confirmed_vs_recovered %&gt;% select(`recovered`)     
p &lt;- plot_ly(confirmed_vs_recovered,     
             type = ""scatter"",   
             mode = ""lines"",     
             x = ~date,        
             y = confirmed[confirmed$country == countries[1],][3],     
             name = ""confirmed"")     
p &lt;- p %&gt;% add_lines(x = ~date, y = recovered[recovered$country == countries[1],][3], name =      ""recovered"", visible = T)    
for (co in 2:length(countries)) {     
  print(countries[co])        
  print(co)     
  p &lt;- p %&gt;% add_lines(x = ~date, y = confirmed[confirmed$country == countries[co],][3], name = col, visible = F)      
  p &lt;- p %&gt;% add_lines(x = ~date, y = recovered[recovered$country == countries[co],][3], name = col, visible = F)      
}     
p &lt;- p %&gt;%      
  layout(     
    title = paste0(""confirmed vs recovered"","" - "",countries[co]),    
    xaxis = list(title = ""x""),     
    yaxis = list(title = ""y""),     
    updatemenus = list(     
                   list(      
                      y = 0.7,     
                      buttons = lapply (1:length(countries), function(co){     
                                                               list(method=""restyle"", 
                                                               args = list(""visible"", 
                                                               countries == c(countries[co])),                  
                                                               label = countries[co])              
                       }
     ))))    
print(p) 
</code></pre>
"
61620822,"<p>I am trying to model the coronavirus infectious rate using SIR model in R. However, my beta (controls the transition between Susceptibles and Infected) and gamma (controls the transition between Infected and Recovered) values are not correct as you can see. </p>

<pre><code>      beta     gamma 
 1.0000000 0.8407238
</code></pre>

<p>Here is my code:</p>

<pre><code>library(deSolve)


Infected &lt;- c(994, 307, 329, 553, 587, 843, 983, 1750, 2950, 4569, 5632, 4848, 9400, 10311, 11166, 13451, 17388, 18743, 19452, 20065, 20732,24914)
Day &lt;- 1:(length(Infected))
N &lt;- 331002651 # population of the us
</code></pre>

<p>This is the SIR function</p>

<pre><code>SIR &lt;- function(time, state, parameters) {
  par &lt;- as.list(c(state, parameters))
  with(par, {
    dS &lt;- -beta/N * I * S
    dI &lt;- beta/N * I * S - gamma * I
    dR &lt;- gamma * I
    list(c(dS, dI, dR))
  })
}
</code></pre>

<p>Then I find the RSS</p>

<pre><code>init &lt;- c(S = N-Infected[1], I = Infected[1], R = 0)
RSS &lt;- function(parameters) {
  names(parameters) &lt;- c(""beta"", ""gamma"")
  out &lt;- ode(y = init, times = Day, func = SIR, parms = parameters)
  fit &lt;- out[ , 3]
  sum((Infected - fit)^2)
}

Opt &lt;- optim(c(0.5, 0.5), RSS, method = ""L-BFGS-B"", lower = c(0, 0), upper = c(1, 1)) # optimize with some sensible conditions
Opt$message
</code></pre>

<p>Then I find beta and gamma</p>

<pre><code>Opt_par &lt;- setNames(Opt$par, c(""beta"", ""gamma""))
Opt_par
##      beta     gamma 
## 1.0000000 0.8407238
</code></pre>

<p>What went wrong with my code and how can I fix it? Thank you in advance!</p>
"
60983736,"<p>My application was successfully deployed (<a href=""https://gustavonucci.shinyapps.io/Corona/"" rel=""nofollow noreferrer"">https://gustavonucci.shinyapps.io/Corona/</a>), but after trying to add one more tabItem, it doesn't render anything, neither locally, and don't return any error.
Below the abbreviate code, because the full code has 1000 lines and the Stack don't allow it:</p>

<p>The additional tab is ""tabItem ("" map "")"", as a comment.</p>

<p>Thanks,
Gustavo</p>

<pre><code>{read and manipulate datasets}

#Shiny
ui &lt;- dashboardPage(
  dashboardHeader(title = ""Corona Vírus""),
  dashboardSidebar(
    sidebarMenu(
      menuItem(""Dashboard Global"", tabName = ""global"", icon = icon(""globe"")),
      menuItem(""Brasil"", tabName = ""br"", icon = icon(""line-chart"")),
      menuItem(""Brasil (Por Estado)"", tabName = ""estado"", icon = icon(""line-chart"")),
      menuItem(""Brasil (Por Cidade) - Em breve"", tabName = ""cidade"", icon = icon(""line-chart"")),
      menuItem(""Por Continente"", tabName = ""cont"", icon = icon(""line-chart"")),
      menuItem(""Por País"", tabName = ""paises"", icon = icon(""line-chart"")),
      menuItem(""Mapas - Em breve"", tabName = ""map"", icon = icon(""map"")),
      menuItem(""Modelos Preditivos - Em breve"", tabName = ""pred"", icon = icon(""desktop""))

      )
    ),
  dashboardBody(
    tabItems(
      tabItem(""global"",
        fluidRow(
          box(width = 12,
              footer = paste(""Última atualização em:"", att),
              status = ""info"",
              h2(""COVID-19 Dashboard"")
          )
        ),
        fluidRow(
          box(width = 12,
              title = ""Números do Corona Vírus no Mundo:"",
              solidHeader = TRUE,
              status = ""primary"",
              collapsible = TRUE,

              valueBoxOutput(""TotalCasos"", width = 3),
              valueBoxOutput(""TotalMortes"", width = 3),
              valueBoxOutput(""PMaisCasos"", width = 3),
              valueBoxOutput(""PMaisMortes"", width = 3)

          )
        ),
        fluidRow(
          box(width = 12,
              title = ""Números do Corona Vírus Hoje:"",
              solidHeader = TRUE,
              status = ""primary"",
              collapsible = TRUE,

              valueBoxOutput(""NCasos"", width = 3),
              valueBoxOutput(""NMortes"", width = 3),
              valueBoxOutput(""MaisCasos"", width = 3),
              valueBoxOutput(""MaisMortos"", width = 3)

          )
        ),

        fixedRow(
          tabBox(
            title = ""Gráficos"",
            id = ""grafTab"",
            tabPanel(""Evolução"", 
                     plotlyOutput(""Evolucao"")),
            tabPanel(""Casos Globais"", 
                     plotlyOutput(""CasosGlobais"")),
            tabPanel(""Mortes Globais"",
                     plotlyOutput(""MortesGlobais"")),
            tabPanel(""Recuperados Globais"",
                     plotlyOutput(""RecGlobais""))
          ),
          tabBox(
            title = ""Ranking"",
            id = ""rankingtab"",
            tabPanel(""Global"",
                     DTOutput(""tabGlobal"")
                     ),
            tabPanel(""Brasil"",
                     DTOutput(""tabBrasil"")
            )
          )
        )
      ),

{other tab itens}



      #tabItem(""map"",
       #       tabBox(
        #        title = ""Mapas"",
         #       id = ""mapGraf"", 
          #      width = 12,
                #height = 650,
           #     tabPanel(""Mundo"", 
            #             plotlyOutput(""Evolucao"")
             #   ),
              #  tabPanel(""Brasil (Por Estado)""
               #          #plotlyOutput(""CasosGlobais"")),
              #  ),
              #  tabPanel(""Brasil (Por Cidade)"",
              #           ""Em Breve"")
              #),

    )
  )
)

server &lt;- function(input, output) { 

  output$plot &lt;- renderPlotly({
    BR %&gt;%
      filter(Status %in% input$Status) %&gt;% 
      group_by(Data, Pais, Status) %&gt;% 
      summarise(Núm = sum(Núm, na.rm = FALSE)) %&gt;%
      ggplot(aes(x = Data, y = Núm, color = Status, pch = Status)) + 
      geom_point() + 
      geom_line() +
      ylab(""Número"") +
      labs(title = paste(""Número de"", if_else(""Casos"" %in% input$Status &amp;&amp; ""Mortes"" %in% input$Status, ""Casos e Mortes"", if_else(""Casos"" %in% input$Status, ""Casos"", ""Mortes"")))) +
      ylim(0,10000) + 
      scale_x_date(date_breaks = ""3 days"") +
      theme(axis.text.x = element_text(angle = 45, hjust = 1)) -&gt; pTY
    ggplotly(pTY, tooltip = c(""Data"", ""Núm""), dynamicTicks = TRUE) %&gt;%
      rangeslider() %&gt;%
      layout(hovermode = ""x"", 
             legend = list(x = 0.1, y = 0.9), 
             yaxis = list(autorange = FALSE),
             annotations = list(x = 1, y = -0.35, 
                                text = paste(""Atualizado em"", att, ""-"", ""Fonte: Ministério da Saúde""),
                                showarrow = F, xref='paper', yref='paper', xanchor='right', 
                                yanchor='auto', xshift=0, yshift=0, font=list(size=8, color=""black""))
    )
  }) 

{other outputs}

}

shinyApp(ui, server)
</code></pre>
"
60891718,"<p>I'm in the midst of building a Shiny application that shows COVID-19 statistics. Right now, I'm trying to set the default selectInput; selected == ""World"", with data$location, but for some reason it's setting itself to the first location in the data frame, being ""Afghanistan"".</p>

<pre><code>                         selectInput(
                       ""country"",
                       ""Country:"",
                       choices =
                         data$location,
                       selected =
                         data$location == ""World""
                     )
</code></pre>

<p>Thank you very much.</p>
"
61563168,"<p>I am trying to estimate a logistic model for an exponential dataset. So that in the end the data is just used for the beginning of the logistic curve. I would like to define the xmax, where the curve becomes convex. I know that sounds wierd, but it is just experimental.</p>

<p>Background story: I would like to plot the Confirmed Cases of Coronavirus in a country if the curve would stay like for example 1.3.2020 - 20.3.2020, shifting when half of the polpulation is infected. (xmax defined)</p>

<p>if i do</p>

<pre><code> fit &lt;- nls(y ~ SSlogis(x,xmid,scal,Asym))
</code></pre>

<p>the model is stuck at the limits of my x and y observations. Do you have any idea?</p>

<p>I already estimated an exponential model and just put the inverse data ""on top"" of the estimated data. That works, but I think that is more than a ""tricky"" solution.</p>

<p>I hope you can understand my explaination.
Best regards and stay healthy, 
Simon</p>
"
60802068,"<p>everyone. This is my first post. I am making a map of Ecuador showing the number of coronavirus confirmed cases by Province. This is the data I prepared. It has the province names and cases as for today. It has some NAs because not all provinces have confirmed cases. <a href=""https://i.stack.imgur.com/S29NQ.png"" rel=""nofollow noreferrer"">covid19_confirmed_today</a> </p>

<p>When I map the data. Everything looks, but when rolling over the bubbles, they do not show the correct name of the province. Only for the first three provinces which do not have NAs. I tried changing the NAs into zeros, but then small bubbles appear for the provinces which have zero confirmed cases. I don't want any bubbles for provinces that do not have confirmed cases.</p>

<pre><code>covid19_confirmed_today_map &lt;- covid19_confirmed_today %&gt;%
  tm_shape() + tm_polygons(col = ""skyblue"", alpha = 0.2) +
  tm_bubbles(size = ""Casos"", col = ""red"", alpha = 0.6, border.lwd = NA)

covid19_confirmed_today_map &lt;- tmap_leaflet(covid19_confirmed_today_map)
covid19_confirmed_today_map %&gt;% removeLayersControl() %&gt;%
  setView(lng = -78.50374, lat = -1.289527, zoom = 7) %&gt;% fitBounds(-80.8, -4.2, -76.5, 0.8)
</code></pre>

<p><a href=""https://i.stack.imgur.com/n9Aix.jpg"" rel=""nofollow noreferrer"">Here</a>, where it say ""Carchi"", it should say ""Chimborazo"". It says ""Carchi"" because that't the first province with NA. Whenerever there is a province with NA, it jumps to the next province and adds the name to that province (without NA) to the previous province (the one that had NA). Thank you very much for any help give. </p>
"
60816257,"<p>I am trying to build a shiny app to show COVID-19 cases for the 10 worst affected countries with refreshes daily from the ECDC website. I want to be able to limit cases and deaths using slider inputs, and select date periods with date inputs, (all already added).
The code is below, but when I run the app I get a blank plot, the axis are displaying correctly but I can't get the points to appear. This should be able to run on any computer as the code just downloads the data set from the ECDC page.
Any solutions?</p>

<pre><code>library(shiny)
library(readxl)
library(dplyr)
library(httr)
library(ggplot2)
library(plotly)

url &lt;- paste(""https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide-"",format(Sys.time(), ""%Y-%m-%d""), "".xlsx"", sep = """")

GET(url, authenticate("":"", "":"", type=""ntlm""), write_disk(tf &lt;- tempfile(fileext = "".xlsx"")))

data &lt;- read_excel(tf)

include&lt;-c(""United_Kingdom"",""Italy"",""France"",""China"",
           ""United_States_of_America"",""Spain"",""Germany"",
           ""Iran"",""South_Korea"",""Switzerland"")
ui &lt;- fluidPage(

    titlePanel(""COVID-19 Daily Confirmed Cases &amp; Deaths""),

    sidebarLayout(
        sidebarPanel(
            checkboxGroupInput(""Country"", ""Select Country"", selected = NULL, inline = FALSE,
                         width = NULL),
            dateRangeInput(""DateRep"",""Select Date Range"", start = ""2019-12-31"", end = NULL),
            sliderInput(""Cases"",""Select Cases Range"", min = 1, max = 20000, value = NULL),
            sliderInput(""Deaths"", ""Select Death Range"", min = 1, max = 10000, value = 100),
            submitButton(""Refresh"")


        ),

        mainPanel(
           plotOutput(""plot"")
        )
    )
)

server &lt;- function(input, output) {

    output$plot &lt;- renderPlot({

        include&lt;-input$Country

        plot_data&lt;-filter(data, `Countries and territories` %in% include)%&gt;%
            filter(between(input$Cases))

        plot_data%&gt;% ggplot(aes(x=input$DateRep, y=input$Cases, size =input$Deaths, color = input$Country)) +
            geom_point(alpha=0.5) +
            theme_light()

    })
}

shinyApp(ui = ui, server = server)
</code></pre>
"
60069930,"<p>I'm using the rtweets library (search_tweets function) to retrieve data from twitter. All data is present except location data, for which I just get ""NA"". What's even weirder is occasionally I do get coordinates (but very infrequently). </p>

<pre><code>search_tweets(""coronavirus"", n = 1000, include_rts = FALSE, lang=""en"")
</code></pre>

<p>This is what I get for the <code>coords_coords</code> variable (just showing a random section here to highlight how I sometimes get a value). Thanks in advance for your help! </p>

<p>[[917]]
[1] NA NA</p>

<p>[[918]]
[1] NA NA</p>

<p>[[919]]
[1] NA NA</p>

<p>[[920]]
[1] NA NA</p>

<p>[[921]]
[1]  43.77429 -79.71640</p>

<p>[[922]]
[1] NA NA</p>

<p>[[923]]
[1] NA NA</p>
"
60884467,"<p>I am plotting a highchart. Cannot get rid of this 0 in X-Axis. Tried a lot of things. Please help.</p>

<pre><code>hc1 &lt;- highchart(type = ""chart"" ) %&gt;%
  hc_xAxis(categories = FALSE)%&gt;%
  hc_add_series(name = ""Confirmed"", data = 
CDR_ordered$Confirmed_ordered.Confirmed) %&gt;%
  hc_add_series(name = ""Recovered"", data = 
CDR_ordered$Recovered_ordered.Recovered, color = ""#FFFF00"") %&gt;%
  hc_add_series(name = ""Deaths"", data = CDR_ordered$Deaths_ordered.Deaths, color = ""#FF0000"") %&gt;%
  hc_xAxis(title = list(text = ""Cases"", categories = FALSE)) %&gt;%
  hc_yAxis(title = list(text = ""Affected""), minorTickInterval = ""auto"", minorGridLineDashStyle = ""LongDashDotDot"")

hc1 &lt;- hc1 %&gt;%
  hc_chart(type = ""column"",
           options3d = list(enabled = TRUE, beta = 10, alpha = 10)) %&gt;%
  hc_add_theme(hc_theme_google()) %&gt;%
  hc_credits(
    enabled = TRUE, text = ""Source: JHU CSS"",
    href = ""https://raw.githubusercontent.com/datasets/covid-19/master/time-series-19-covid-combined.csv"",
    style = list(fontSize = ""10px""))
</code></pre>

<p>Please check the image below for better understanding</p>

<p><img src=""https://i.stack.imgur.com/MIVMD.png"" alt=""Get Rid of 0 on X-Axis""></p>

<p><img src=""https://i.stack.imgur.com/z1fxx.png"" alt=""This is my data""></p>

<p><img src=""https://i.stack.imgur.com/1soG0.png"" alt=""How do I get rid of this 0 now?""></p>
"
61207024,"<p>I have scraped tweets from Twitter on which i am doing text analysis. </p>

<p>I use this:
corpus &lt;- tm_map(corpus, removePunctuation)</p>

<p>The data shows: 
[1] rt shreya2607 sendusbackhome  myogioffice narendramodi ashokgehlot51  ombirlakota covid19  sir im a student in kota but due to s…
[2] covid19 stayathome nose knows by banxcartoons httpstcowegjrzadyx auspol coronavirus stayathome thedrum<br>
[3] 5  helpful step covid19 decision making in uncertain times httpstcobjskydzydy via mckinsey</p>

<p>In [1] there are ... That won't remove. Since these three dots are in every tweet almost, they are not showing in bar charts, word clouds etc.</p>

<p>Below is my full program:</p>

<pre><code>tweets_df &lt;- read.csv('covid.csv')
str(tweets_df)
library(tm)
corpus &lt;- iconv(tweets_df$text, to = ""UTF-8"")
corpus &lt;- Corpus(VectorSource(corpus))
inspect(corpus[1:3])
corpus &lt;- tm_map(corpus, tolower)
corpus &lt;- tm_map(corpus, removePunctuation)
corpus &lt;- tm_map(corpus, removeNumbers)
corpus &lt;- tm_map(corpus, removeWords, stopwords('english'))
corpus &lt;- tm_map(corpus, removeWords, c('covid', 'rt'))
Textprocessing &lt;- function(x)
  {gsub(""http[[:alnum:]]*"",'', x)
  gsub('http\\S+\\s*', '', x) ## Remove URLs
  gsub('\\b+RT', '', x) ## Remove RT
  gsub('#\\S+', '', x) ## Remove Hashtags
  gsub('@\\S+', '', x) ## Remove Mentions
  gsub('[[:cntrl:]]', '', x) ## Remove Controls and special characters
  gsub(""\\d"", '', x) ## Remove Controls and special characters
  gsub('[[:punct:]]', '', x) ## Remove Punctuations
  gsub(""^[[:space:]]*"","""",x) ## Remove leading whitespaces
  gsub(""[[:space:]]*$"","""",x) ## Remove trailing whitespaces
  gsub(' +',' ',x) ## Remove extra whitespaces
}
corpus &lt;- tm_map(corpus, Textprocessing)
inspect(corpus[1:3])
</code></pre>
"
60995174,"<p>I am trying to plot this code.However, the line does not appear in the plot. please help me how to solve the issue.<a href=""https://i.stack.imgur.com/ZaWyP.png"" rel=""nofollow noreferrer"">enter image description here</a></p>

<pre><code>covid19x%&gt;%
    filter(Entity %in% c(""Iran"", ""Italy"",""Spain"",""China"",""Germany"",""France"",""United States""))%&gt;%
  plot_ly(x = ~cases, y = ~deaths,color = ~Entity ) %&gt;%
  group_by(Entity)%&gt;%
  add_lines(frame=~Date)
</code></pre>

<p>This is the data format:</p>

<pre><code>       Entity Code       Date deaths Daily.new.confirmed.deaths..deaths. cases
1 Afghanistan  AFG 2019-12-31      0                                   0    NA
2 Afghanistan  AFG 2020-01-01      0                                   0    NA
3 Afghanistan  AFG 2020-01-02      0                                   0    NA
4 Afghanistan  AFG 2020-01-03      0                                   0    NA
5 Afghanistan  AFG 2020-01-04      0                                   0    NA
6 Afghanistan  AFG 2020-01-05      0                                   0    NA
</code></pre>

<p>Also I have plotted without any problems by markers:</p>

<pre><code>covid19x%&gt;%
    filter(Entity %in% c(""Iran"", ""Italy"",""Spain"",""China"",""Germany"",""France"",""United States""))%&gt;%
  plot_ly(x= ~ cases, y=~deaths,color  =~Entity)%&gt;%
  add_markers(frame=~Date)
</code></pre>
"
60800242,"<p>I've created a script that reads data from two GitHub repositories, reformats the datasets, binds them together by rows and then writes everything in a new .csv file.
Then, I scheduled the run of this script every hour through the functionalities of the <strong>cronR</strong> package.</p>

<p>Here's my code:</p>

<pre><code>devtools::install_github(""tidyverse/googlesheets4"")

library(dplyr)
library(googlesheets4)
library(RCurl)

setwd(dir = ""YOUR_WORKING_DIRECTORY"")

###############################################################################
#================== TIME SERIES DATA FOR CASES AND DEATHS ====================#
###############################################################################

# 1. #####==== DATASETS =====#####

# 1.1 ###= Cases #####

# These files are updated on GitHub every day.
cases &lt;- read.csv(text = getURL(url = ""https://raw.githubusercontent.com/openZH/covid_19/master/COVID19_Cases_Cantons_CH_total.csv""),
                  header = TRUE,
                  stringsAsFactors = FALSE,
                  na.strings = c("""", ""NA""),
                  encoding = ""UTF-8"")

# Removed data for whole Switzerland and Leichtenstein
cases &lt;- subset(x = cases,
                !is.element(el = canton,
                            set = c(""CH"", ""FL"")),
                select = c(""date"",
                           ""canton"",
                           ""tested_pos""))

names(cases)[1] &lt;- ""Date""

# Dataset restructured according to the cases dataset format
cases &lt;- reshape(data = cases,
                 idvar = ""Date"",
                 timevar = ""canton"",
                 v.names = ""tested_pos"",
                 direction = ""wide"",
                 )

names(cases) &lt;- gsub(pattern = ""tested_pos."",
                     replacement = """",
                     x = names(cases))

cases[is.na(cases)] &lt;- 0

cases &lt;- cases[order(cases$Date,
                     decreasing = FALSE), ]

# More updated dataset
cases2 &lt;- read.csv(text = getURL(url = ""https://raw.githubusercontent.com/daenuprobst/covid19-cases-switzerland/master/covid19_cases_switzerland.csv""),
                   header = TRUE,
                   stringsAsFactors = FALSE,
                   na.strings = c("""", ""NA""),
                   encoding = ""UTF-8"")

# Remove total daily cases for Switzerland
cases2 &lt;- subset(x = cases2,
                 select = -c(CH))

# rbind between two cases datasets
cases_tot &lt;- bind_rows(cases[1:7, ],
                       cases2)

rownames(cases_tot) &lt;- seq(from = 1,
                           to = nrow(cases_tot),
                           by = 1)

write.csv(x = cases_tot,
          file = paste0(getwd(),
                        ""/cases_tot.csv""),
          row.names = FALSE,
          quote = FALSE)
</code></pre>

<p>When I manually run my script everything is ok and the .csv produced is fine, but if you try to schedule the run of this script through the cronR package (from RStudio IDE click on <strong>Addins</strong> -> <strong>Schedule R scripts on Linux/Unix</strong>) the .csv saved is different just for the column ""Date"". In fact, the dates of the first dataset are on the first column, but the dates of the second dataset (to bind to the first through <code>bind_rows()</code>) are at the end of the dataset, and the header has a new strange name (as you can see from <a href=""https://i.imgur.com/zHq7dhx.png"" rel=""nofollow noreferrer"">this image</a>).</p>

<p>Do you have any idea of what could be the problem? Thanks a lot!</p>

<p>P.S.: I work on a MacBook Pro late 2016, 8 Gb of RAM, with macOS Catalina installed.</p>
"
60828199,"<p>I am producing a new dataframe by binding together two dataframes obtained from two different GitHub repositories. Both dataset have a <strong>Date</strong> column.
When I do this operation on my machine everything is fine, and I can use the functions <code>rbind()</code> or <code>bind_rows()</code> to bind together the dataframes.<br>
Another user tried the same code and the result is different. In particular, the <strong>Date</strong> column is split. The dates of the first dataframe are under the first column (called <strong>Date</strong>), while the dates of the second dataframe are placed at the end of the dataframe, in a new column (that I haven't created) called <strong>X.U.FEFF.Date</strong>.</p>

<p>Below there is the code I used:</p>

<pre><code>library(dplyr)
library(RCurl)

setwd(dir = ""YOUR_WORKING_DIRECTORY"")

#####===== FIRST DATAFRAME =====#####
cases &lt;- read.csv(text = getURL(url = ""https://raw.githubusercontent.com/openZH/covid_19/master/COVID19_Cases_Cantons_CH_total.csv""),
                  header = TRUE,
                  stringsAsFactors = FALSE,
                  na.strings = c("""", ""NA""),
                  encoding = ""UTF-8"")

# Removed data for whole Switzerland and Leichtenstein
cases &lt;- subset(x = cases,
                !is.element(el = canton,
                            set = c(""CH"", ""FL"")),
                select = c(""date"",
                           ""canton"",
                           ""tested_pos""))

names(cases)[1] &lt;- ""Date""

# Dataset restructured according to the cases dataset format
cases &lt;- reshape(data = cases,
                 idvar = ""Date"",
                 timevar = ""canton"",
                 v.names = ""tested_pos"",
                 direction = ""wide"",
                 )

names(cases) &lt;- gsub(pattern = ""tested_pos."",
                     replacement = """",
                     x = names(cases))

cases[is.na(cases)] &lt;- 0

cases &lt;- cases[order(cases$Date,
                     decreasing = FALSE), ]

#####===== SECOND DATAFRAME =====#####
cases2 &lt;- read.csv(text = getURL(url = ""https://raw.githubusercontent.com/daenuprobst/covid19-cases-switzerland/master/covid19_cases_switzerland.csv""),
                   header = TRUE,
                   stringsAsFactors = FALSE,
                   na.strings = c("""", ""NA""),
                   encoding = ""UTF-8"")

# Remove total daily cases for Switzerland
cases2 &lt;- subset(x = cases2,
                 select = -c(CH))

# rbind between two cases datasets
cases_tot &lt;- bind_rows(cases[1:7, ],
                       cases2)

write.csv(x = cases_tot,
          file = paste0(getwd(),
                        ""/cases_tot.csv""),
          row.names = FALSE,
          quote = FALSE)
</code></pre>

<p>For the other user, the function <code>rbind()</code> just fails, while the function <code>bind_rows()</code> produces the output displayed in this <a href=""https://i.imgur.com/zHq7dhx.png"" rel=""nofollow noreferrer"">image</a>. I don't know how to solve this issue because I can't reproduce it on my machine.</p>

<p>Any idea about what's causing this issue? Thanks a lot.</p>
"
60850012,"<p>I'm currently creating a shiny app that load recent Dutch tweets concerning the corona virus, and on another tab I want to display a wordcloud with the most frequently used words. </p>

<p>The table works fine, but the wordcloud shows mainly chinese signs. I was thinking that it may be smileys used in the tweets, but that doesn't seem to be the case. </p>

<p>The code that i've written:</p>

<pre><code>library(tidyverse)
library(shiny)
library(rtweet)
library(dplyr)
library(glue)
library(reactable)
library(purrr)
library(wordcloud2)
library(tidytext)
library(tm)

make_url_html &lt;- function(url) {
  if(length(url) &lt; 2) {
    if(!is.na(url)) {
      as.character(glue(""&lt;a title = {url} target = '_new' href = '{url}'&gt;{url}&lt;/a&gt;"") )
    } else {
      """"
    }
  } else {
    paste0(purrr::map_chr(url, ~ paste0(""&lt;a title = '"", .x, ""' target = '_new' href = '"", .x, ""'&gt;"", .x, ""&lt;/a&gt;"", collapse = "", "")), collapse = "", "")
  }
}


# UI page instellen
ui &lt;- fluidPage(
titlePanel(""Corona op twitter""),
h4(""Meest gebruikte woorden omtrent populaire COVID-19 hashtags op de Nederlandse twitter""),
tabsetPanel(
  #Eerste tab bevat de twitter tabel
  tabPanel(
    title = ""Zoek tweets"",
    sidebarLayout(
      sidebarPanel(
        # Radiobuttons voor de hastags
        radioButtons(
          inputId = ""hashtag_to_search"",
          label = ""Kies hashtag"",
          choices = c(""#coronavirus"" = ""#coronavirus"", ""#coronahulp"" = ""#coronahulp"")
        ),
        #Slider voor het aantal tweets
        sliderInput(""num_tweets_to_download"",
                    ""Aantal tweets:"",
                    min = 1,
                    max = 100,
                    value = 50)
      ),
      mainPanel(
        reactableOutput(""tweet_table"")
      )
    )
  ),
  tabPanel(
    # Tweede tab bevat de wordcloud
    title = ""Wordcloud"",
    sidebarLayout(
      sidebarPanel(
        radioButtons(
          inputId = ""hashtag"",
          label = ""Choose hashtag"",
          choices = c(""#coronavirus"" = ""virus"", ""#coronahulp"" = ""hulp"")
        ),
        sliderInput(""num"",
                    ""Number of words:"",
                    min = 1,
                    max = 100,
                    value = 50)
      ),

      # Show a plot of the generated distribution
      mainPanel(
        wordcloud2Output(""cloud"", width = ""100%"", height = ""800px""),
        reactableOutput(""table"")
      )
    )
  )
)   
)


# Server met tabel en wordcloud
server &lt;- function(input, output) {

  # Data inladen
  tweet_df &lt;- reactive({
    search_tweets(paste(""lang:nl"", input$hashtag_to_search), n = input$num_tweets_to_download, include_rts = FALSE)
  })

  # data schoonmaken
  word &lt;- c(""we"", ""coronavirus"", ""nl"", ""nederland"", ""https"",  stopwords(""nl""))
  new_stopwords_df &lt;- data.frame(word)

  tweet_clean &lt;- reactive({
    req(tweet_df())
    tweet_df() %&gt;%
      mutate(text = lapply(text, tolower),
             text = str_replace_all(text, ""https://t.co/[a-z,A-Z,0-9]*"", """"),
             text = str_replace(text,""RT @[a-z,A-Z,0-9,_]*: "",""""),
             text = str_replace_all(text,""#[a-z,A-Z]*"",""""),
             text = str_replace_all(text,""@[a-z,A-Z]*"",""""),
             text = str_replace_all(text,""\\b[a-zA-Z]{1}\\b"",""""),
             text = str_replace_all(text,""[:digit:]"",""""),
             text = str_replace_all(text,""[^[:alnum:] ]"",""""),
             text = str_replace_all(text,"" "","" "")) %&gt;%
      select(status_id, text) %&gt;% unnest_tokens(word,text) %&gt;%
      anti_join(new_stopwords_df, by = ""word"") %&gt;% drop_na(word)
  })

  tweet_clean_freq &lt;- reactive({
    req(tweet_clean())
    tweet_clean() %&gt;%
      group_by(word) %&gt;%
      summarise(freq =n()) %&gt;%
      arrange(desc(freq)) %&gt;%
      head(data, n = 50)
  })

   output$table &lt;- renderReactable({reactable(tweet_clean())})
   output$cloud &lt;- renderWordcloud2({
     wordcloud2(data = tweet_clean_freq()
     )
   })

   # Tabel
   tweet_table_data &lt;- reactive({
     req(tweet_df())
     tweet_df() %&gt;%
       select(user_id, status_id, created_at, screen_name, text, favorite_count, retweet_count, urls_expanded_url) %&gt;%
       mutate(
         Tweet = glue::glue(""{text} &lt;a href='https://twitter.com/{screen_name}/status/{status_id}'&gt;&gt;&gt; &lt;/a&gt;""),
         URLs = purrr::map_chr(urls_expanded_url, make_url_html)
       )%&gt;%
       select(DateTime = created_at, User = screen_name, Tweet, Likes = favorite_count, RTs = retweet_count, URLs)
   })

   output$tweet_table &lt;- renderReactable({
     reactable::reactable(tweet_table_data(), 
                          filterable = TRUE, searchable = TRUE, bordered = TRUE, striped = TRUE, highlight = TRUE,
                          showSortable = TRUE, defaultSortOrder = ""desc"", defaultPageSize = 25, showPageSizeOptions = TRUE, pageSizeOptions = c(25, 50, 75, 100, 200), 
                          columns = list(
                            DateTime = colDef(defaultSortOrder = ""asc""),
                            User = colDef(defaultSortOrder = ""asc""),
                            Tweet = colDef(html = TRUE, minWidth = 190, resizable = TRUE),
                            Likes = colDef(filterable = FALSE, format = colFormat(separators = TRUE)),
                            RTs = colDef(filterable =  FALSE, format = colFormat(separators = TRUE)),
                            URLs = colDef(html = TRUE)
                          )
     )
   })

}


# Applicatie
shinyApp(ui = ui, server = server)

</code></pre>

<p>I've tried to check what the problem is by adding a table under the wordcloud, but there it also shows chinese symbols. When I try my code outside of shiny context (and without reactive aspects), it seems to work fine. </p>

<p>Btw: I know I've not connected the radiobuttons yet, I want to get the wordcloud working first. </p>

<p>Thanks!</p>
"
61276168,"<p>The value in another data frame becomes NA after I used left_join() function. And I check the answer at here[<a href=""https://stackoverflow.com/questions/35016377/dplyrleft-join-produce-na-values-for-new-joined-columns]"">dplyr::left_join produce NA values for new joined columns</a>.</p>

<p>I also specify the <code>by</code> arguement but failed.</p>

<p>I don't know why.</p>

<pre><code>

qx_p2 &lt;- structure(list(province = c(""安徽"", ""安徽"", ""安徽"", ""安徽"", ""安徽""
), date = c(""2020-01-21"", ""2020-01-22"", ""2020-01-23"", ""2020-01-24"", 
            ""2020-01-25""), PRS = c(1013.9035387141, 1011.48779584751, 1014.28302402211, 
                                   1019.16970261716, 1018.92203467498), PRS_Sea = c(1024.73084750567, 
                                                                                    1022.22210612717, 1025.02632842026, 1029.97905104403, 1029.77650132275
                                   ), PRS_Max = c(1014.26828869048, 1011.80445613662, 1014.51628117914, 
                                                  1019.43671957672, 1019.31935504063), PRS_Min = c(1013.7138513322, 
                                                                                                   1011.13447054516, 1013.86811271731, 1018.75406934996, 1018.62469257842
                                                  ), WIN_S_Max = c(2.30187606292517, 2.08586132369615, 2.76893908257748, 
                                                                   4.22074853552532, 3.63427225056689), WIN_S_Inst_Max = c(3.44360343442933, 
                                                                                                                           3.09963836923658, 4.28499952758881, 6.68930898053666, 5.80619165721844
                                                                   ), WIN_D_INST_Max = c(116.878029336735, 218.745851048753, 120.88310303288, 
                                                                                         72.1640447845805, 72.0331526360544), WIN_D_Avg_2mi = c(116.23329724764, 
                                                                                                                                                210.524530689871, 113.104009452075, 68.7694017991261, 70.322008604388
                                                                                         ), WIN_S_Avg_2mi = c(1.77558118386243, 1.49959490740741, 2.20936874055178, 
                                                                                                              3.47942613851096, 2.99431642101285), WIN_D_S_Max = c(116.68018866665, 
                                                                                                                                                                   218.180671371681, 120.40502999811, 71.0831467309146, 68.3670670351474
                                                                                                              ), TEM = c(3.81968088624339, 5.16464226662887, 6.82721856103553, 
                                                                                                                         5.98099596088435, 4.8940626181028), TEM_Max = c(4.04776301492819, 
                                                                                                                                                                         5.35075514928193, 6.97597470238095, 6.15192401266062, 5.07960293839758
                                                                                                                         ), TEM_Min = c(3.49020455404384, 4.95346053004535, 6.65049142573696, 
                                                                                                                                        5.85618067365835, 4.76455794123205), RHU = c(85.9359859221466, 
                                                                                                                                                                                     96.1710766250945, 91.749678760393, 88.3347741874528, 80.693040202192
                                                                                                                                        ), VAP = c(6.98015376984127, 8.55406509826153, 9.08114866780046, 
                                                                                                                                                   8.27843124055178, 6.98599714191232), RHU_Min = c(83.965092356387, 
                                                                                                                                                                                                    95.6411387471655, 90.9997401738473, 87.3134436413454, 79.2219635770975
                                                                                                                                                   ), PRE_1h = c(0.102133763227513, 0.422205333522298, 1488.33246492347, 
                                                                                                                                                                 0.0715384070294785, 372.116791028911)), class = c(""tbl_df"", ""tbl"", 
                                                                                                                                                                                                                   ""data.frame""), row.names = c(NA, -5L))

covid_p2 &lt;- structure(list(province = c(""安徽"", ""安徽"", ""安徽"", ""安徽"", ""安徽""
), date = c(""2020/1/21"", ""2020/1/22"", ""2020/1/23"", ""2020/1/24"", 
            ""2020/1/25""), 新增确诊 = c(0L, 1L, 14L, 24L, 21L)), class = c(""tbl_df"", 
                                                                      ""tbl"", ""data.frame""), row.names = c(NA, -5L))



dat2 &lt;- covid_p2 %&gt;% left_join(qx_p2, by = c('province' = 'province', 'date' = 'date'))
dat2
</code></pre>
"
61152350,"<p>I am trying to build a simple app using Shinydashboard. One of the tabitems (""Raw Data"") does not display anything and neither the page changes when clicked on it. I have cross-checked the syntax and the code is running fine. Don't understand what's wrong. </p>

<p><strong>Ui.R-</strong></p>

<pre><code>header = dashboardHeader(title=""COVID-19 Tracker"")

sidebar =   dashboardSidebar(collapsed = TRUE,
                   sidebarMenu(menuItem(""Dashboard"", tabName = ""Dashboard"",icon = icon(""globe"")),
                               menuItem(""Raw Data"", tabName = ""Raw Data"", icon = icon(""database"")),
                               menuItem(""Graphs"",tabName = ""Graphs"", icon = icon(""chart-bar""))
                               ))
body =  dashboardBody(
  tabItems(
    tabItem(tabName = ""Dashboard"",
                   fluidRow(valueBox(10*3, ""Cases"", width = 4), 
                            valueBoxOutput(""Recovered"", width = 4), 
                            valueBoxOutput(""Deaths"", width = 4)
                            )
                   ),
    tabItem(tabName = ""Raw Data"", h2(""Raw Data has been loaded!"")
                   ),
    tabItem(tabName = ""Graphs"",fluidRow(
             column(
               width=4, 
               selectizeInput(
                 ""country"", label=h5(""Country""), choices=NULL, width=""100%"")
             ),
             column(
               width=4, 
               selectizeInput(
                 ""state"", label=h5(""State""), choices=NULL, width=""100%"")
             ),
             column(
               width=4, 
               checkboxGroupInput(
                 ""metrics"", label=h5(""Selected Metrics""), 
                 choices=c(""Confirmed"", ""Deaths"", ""Recovered""), 
                 selected=c(""Confirmed"", ""Deaths"", ""Recovered""), 
                 width=""100%"")
             )
           ),
           fluidRow(
             plotlyOutput(""dailyMetrics"")
           ),
           fluidRow(
             plotlyOutput(""cumulatedMetrics""))
           )
  )
)

ui = dashboardPage(header, sidebar, body)
</code></pre>

<p>I appreciate all the help!</p>
"
61157328,"<p>I'm using the John Hopkin's COVID-19 dataset which can be found here: <a href=""https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases"" rel=""nofollow noreferrer"">https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases</a>
namely, the <code>Corona Confirmed Cases Narrow, the Corona Confirmed Deaths Narrow, and the Corona Confirmed Recovered Narrow</code> </p>

<p>I'm trying to convert the <code>Date</code> column to the <code>Date</code> class using <code>as.Date</code> but failing. All dates are <code>NA</code> no matter what I try. I've tried the following -
converting my locale,
using <code>stringAsFactors = False</code> when reading the csv file,
changing the formats constantly.</p>

<p>dates are formatted as <code>/m/d/Y/</code>
Before running my code, output of <code>head(recovered_data$Date)</code> is:
<code>[6] 2020-04-06 2020-04-05 2020-04-04 2020-04-03 2020-04-02
</code>
ommitted plenty
after:
<code>[1] NA NA NA NA NA NA
</code>
I've tried changing the format to be <code>m-d-Y</code> but it still doesn't work.</p>

<p>My code:</p>

<p><code>
recovered_data$Date &lt;- as.Date(as.character(recovered_data$Date),""%d%m%Y"")
death_data$Date &lt;- as.Date(as.character(death_data$Date),""%m/%d/%Y"")
confirmed_data$Date &lt;- as.Date(as.character(confirmed_data$Date),""%d%m%Y"")</code></p>

<p>All dates are NA when I access them. Looking at the dataset, it shouldn't be this way.
Thanks!</p>
"
60846493,"<p>Hello Community,</p>

<pre><code>jhu_cases &lt;- as.data.frame(data.table::fread(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv""))
</code></pre>

<p>I tired also </p>

<pre><code>jhu_cases &lt;- as.data.frame(data.table::fread(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"",
                                         header = TRUE, sep = "","", sep2 = ""/""))
</code></pre>

<p>seems doesnt work,
many thanks in advance</p>
"
61067563,"<p>I have this code to add a new row each day to my coronavirus dataframe in R (came from excel). The weirdest thing is happening: even though I clearly state Data=""2020-04-05"", the date added to rawData.Rda is ""2020-04-04"", the latest date of that dataframe. Furthermore, it suddenly starts showing a time for this date: 00:00:00 for every row except the new one, where date is 2020-04-04 23:00:00. What is going on here? Both a fix to the situation or a new way to introduce data would be good solutions.
PS: tried to add as.Date but this did not solve the problem.</p>

<pre><code>load(""rawdata.Rda"")
as.Date(rawData$Data, format=""%Y-%m-%d"")
newData &lt;- data.frame(Data = ""2020-04-05"", Casos=11278, Óbitos = 295, Recuperados = 75)
as.Date(newData$Data, format=""%Y-%m-%d"")
rawData &lt;- rbind(rawData, newData)
</code></pre>

<p>rawData initially</p>

<p><img src=""https://i.stack.imgur.com/FODDt.png"" alt=""rawData initially""></p>

<p>rawData after running the aforementioned code</p>

<p><img src=""https://i.stack.imgur.com/5lkmb.png"" alt=""rawData after running the aforementioned code""></p>

<pre><code>rawData &lt;- structure(list(Data = structure(c(1583107200, 1583193600, 1583280000, 
1583366400, 1583452800, 1583539200, 1583625600, 1583712000, 1583798400, 
1583884800, 1583971200, 1584057600, 1584144000, 1584230400, 1584316800, 
1584403200, 1584489600, 1584576000, 1584662400, 1584748800, 1584835200, 
1584921600, 1585008000, 1585094400, 1585180800, 1585267200, 1585353600, 
1585440000, 1585526400, 1585612800, 1585699200, 1585785600, 1585872000, 
1585958400), class = c(""POSIXct"", ""POSIXt""), tzone = ""UTC""), 
    Casos = c(2, 4, 6, 9, 13, 21, 30, 39, 41, 59, 78, 112, 169, 
    245, 331, 448, 642, 785, 1020, 1280, 1600, 2060, 2362, 2995, 
    3544, 4268, 5170, 5962, 6408, 7443, 8251, 9034, 9886, 10524
    ), Óbitos = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
    1, 2, 3, 6, 12, 14, 23, 24, 43, 60, 76, 100, 119, 140, 160, 
    187, 209, 246, 267), Recuperados = c(0, 0, 0, 0, 0, 0, 0, 
    0, 0, 0, 0, 0, 1, 2, 3, 3, 3, 3, 5, 5, 5, 14, 22, 22, 43, 
    43, 43, 43, 43, 43, 43, 68, 68, 75)), row.names = c(NA, -34L
), class = c(""tbl_df"", ""tbl"", ""data.frame""))
</code></pre>
"
60974629,"<p>I have two datasets both containing a common field but would like to retrieve all of the missing elements of one dataset compared to the other one.</p>

<p>My df1 looks like this:</p>

<pre><code>Account.ID       Product.ID
1                A
1                B
1                C
1                D
2                A
2                E
2                F
3                B
3                D
</code></pre>

<p>And my other dataset df2 looks like this:</p>

<pre><code>User.ID        Product.ID
X              A
X              B
X              C
Y              A
Y              U
Y              I
Z              B
Z              A
</code></pre>

<p>My ideal output would be something like this:</p>

<pre><code>Account.ID      User.ID       Missing.Products
1               X             Null
1               Y             U
1               Y             I
1               Z             Null
2               X             B
2               X             C
2               Y             U
2               Y             I
2               Z             B
3               X             A
3               X             C
3               Y             A
3               Y             U
3               Y             I
3               Z             A
</code></pre>

<p>Basically, I would like to retrieve all the Users' Product.IDs that are missing for each Account.IDs.</p>

<p>Here are my inputs sample datasets:</p>

<pre><code>df1 &lt;- tibble(Account.ID = c(1, 1, 1, 1, 2, 2, 2, 3, 3), 
          Product.ID = c(""A"", ""B"", ""C"", ""D"", ""A"", ""E"", ""F"", ""B"", ""D""))

df2 &lt;- tibble(User.ID = c(""X"", ""X"", ""X"", ""Y"",""Y"", ""Y"", ""Z"", ""Z""), 
          Product.ID = c(""A"", ""B"", ""C"", ""A"", ""U"", ""I"", ""B"", ""A"")) 
</code></pre>

<p>Any help would be greatly appreciated. Thank you very much</p>

<p>The real data is here:</p>

<pre><code>structure(list(Account.ID = c(1233248L, 25781287L, 14660627L,
14659269L, 9951007L, 3641831L), Product.ID = c(NA, NA, ""01t60000002hNV4AAM"",
""01t60000002hNV4AAM"", ""01t60000002hNV4AAM"", ""01t60000002hNV4AAM""
)), class = c(""data.table"", ""data.frame""), row.names = c(NA,
-6L), .internal.selfref = &lt;pointer: 0x00000000025a1ef0&gt;)

structure(list(Case.ID = structure(c(4L, 4L, 4L, 4L, 4L, 4L), .Label = 
c(""Business Travel Spread Detection Platform"",
""Citizens and Doctors Health Check"", ""Covid-19 Dashboard"", ""COVID19 Patient 
Information Tracking"",
""National Regional Operation Center - Covid-19""), class = ""factor""),
Product.ID = c(""8001661"", ""8003103"", ""8003145"", ""8004158"",
""8004159"", ""8005365"")), class = c(""data.table"", ""data.frame""
), row.names = c(NA, -6L), .internal.selfref = &lt;pointer: 0x00000000025a1ef0&gt;)
</code></pre>
"
61254855,"<p>I'm trying to get data for yandex self-isolation index for Russian regions.
The data is available at the <a href=""https://yandex.ru/maps/api/covid?ajax=1&amp;isolation=True&amp;csrfToken="" rel=""nofollow noreferrer"">https://yandex.ru/maps/api/covid?ajax=1&amp;isolation=True&amp;csrfToken=</a></p>

<p>So in my case it is 
<a href=""https://yandex.ru/maps/api/covid?ajax=1&amp;isolation=True&amp;csrfToken=e0603a2a7245a893328b02dfd4be069c7b87d31c:1587051231"" rel=""nofollow noreferrer"">https://yandex.ru/maps/api/covid?ajax=1&amp;isolation=True&amp;csrfToken=e0603a2a7245a893328b02dfd4be069c7b87d31c:1587051231</a></p>

<p>I'm trying to import it using this:</p>

<pre><code>url = ""https://yandex.ru/maps/api/covid?ajax=1&amp;isolation=True&amp;csrfToken=e0603a2a7245a893328b02dfd4be069c7b87d31c:1587051231""

data = fromJSON(file=""https://yandex.ru/maps/api/covid?ajax=1&amp;isolation=True&amp;csrfToken=e0603a2a7245a893328b02dfd4be069c7b87d31c:1587051231"")
</code></pre>

<p>And then parse to dataframe ""region - self-isolation"", but I fail on the step of getting the data.</p>
"
60893598,"<p>With lots of help from this forum, I had been generating animated maps of covid-19 data for the past couple of days for work.  Minus a number of overlays that my office has requested, the basic script I was using is</p>

<pre><code>library(urbnmapr) # For map
library(ggplot2)  # For map
library(dplyr)    # For summarizing
library(tidyr)    # For reshaping
library(stringr)  # For padding leading zeros
library(ggrepel)
library(ggmap)
library(usmap)
library(gganimate)
library(magrittr)
library(gifski)

# Get COVID cases, available from:
url &lt;- ""https://static.usafacts.org/public/data/covid-19/covid_confirmed_usafacts.csv""
COV &lt;- read.csv(url, stringsAsFactors = FALSE)

Covid &lt;- pivot_longer(COV, cols=starts_with(""X""),
                      values_to=""cases"",
                      names_to=c(""X"",""date_infected""),
                      names_sep=""X"") %&gt;%
  mutate(infected = as.Date(date_infected, format=""%m.%d.%Y""),
         countyFIPS = str_pad(as.character(countyFIPS), 5, pad=""0""))

# Obtain map data for counties (to link with covid data) and states (for showing borders)
states_sf &lt;- get_urbn_map(map = ""states"", sf = TRUE)
counties_sf &lt;- get_urbn_map(map = ""counties"", sf = TRUE)

# Merge county map with total cases of cov
counties_cov &lt;- inner_join(counties_sf, Covid, by=c(""county_fips""=""countyFIPS""))

setwd(""C:/mypath"")
p &lt;- counties_cov %&gt;%
  ggplot() +
  geom_sf(mapping = aes(fill = cases), color = NA) +
  geom_sf(data = states_sf, fill = NA, color = ""black"", size = 0.25) +
  coord_sf(datum = NA) +   
  scale_fill_gradient(name = ""Cases"", trans = ""log"", low='green', high='red',
                      na.value = ""white"",
                      breaks=c(1, max(counties_cov$cases))) +
  theme_bw() + 
    theme(legend.position=""bottom"", 
        panel.border = element_blank(),
        axis.title.x=element_blank(), 
        axis.title.y=element_blank())

print(p + transition_time(infected) + 
        labs(title='Confirmed COVID-19 Cases: {frame_time}'))

png_files &lt;- list.files(""C:/mypath"", pattern = "".*png$"", full.names = TRUE)
st = format(Sys.time(), ""%Y-%m-%d"")
gifName &lt;- paste(""COVID-19-Cases-byCounty_"",st,"".gif"",sep="""")
gifski(png_files, gif_file = gifName, width = 800, height = 600, delay = 0.25, loop=FALSE)
</code></pre>

<p>This had been working great. It takes about 30 minutes on my laptop, but when it was finished I had ~100 .png files representing each day's data and the animated gif that stitched them all together sitting in the working directory.</p>

<p>Earlier today I updated packages...didn't pay much attention, just used RStudio package manager to check for updates and said update all.</p>

<p>First I got an error</p>

<pre><code>Error: stat_sf requires the following missing aesthetics: geometry
</code></pre>

<p>I believe I fixed that by changing </p>

<pre><code>geom_sf(mapping = aes(fill = cases), color = NA) +
</code></pre>

<p>to</p>

<pre><code>geom_sf(mapping = aes(fill = cases, geometry=geometry), color = NA) +
</code></pre>

<p>Now the script runs, I get the rendering progress bar like I've seen before.  There's even an animated map sitting in the RStudio viewer  But no .png files appear in the working directory, and so gifski has nothing to build a gif from.</p>

<p>What do I need to do to get the output files back?  This is a) making me feel very stupid and b) keeping me from moving on to other work...</p>

<p>Thanks!</p>
"
60923486,"<p>I've been learning how to build maps for work showing covid-19 infection data.  In addition to a national map, I am producing regional maps for the northeast, south, west, and midwest.  The code is identical, I just use different filterings on the national data frame.  I produce one map for each day of data and use gganimate to make frames and finally gifski to make an animated gif.  The basic code for the national map is:</p>

<pre><code>p &lt;- pop_counties_cov %&gt;%
  ggplot() +
  geom_sf(mapping = aes(fill = infRate, geometry=geometry), color = NA) +
  geom_sf(data = states_sf, fill = NA, color = ""black"", size = 0.25) +
  coord_sf(datum = NA) +   
  scale_fill_gradient(name = ""% Population Infected"", trans = ""log"", low='green', high='red',
                      na.value = ""white"",
                      breaks=c(0, round(max(pop_counties_cov$infRate),3))) +
  geom_point(data=AFMCbases, aes(x=longitude.1, y=latitude.1,size=personnel), color = ""hotpink"") +
  #geom_label_repel(data=AFMCbases, aes(x=longitude.1, y=latitude.1, label=Base)) +
  theme_bw() + 
  labs(size='AFMC \nMil + Civ') +
  theme(legend.position=""bottom"", 
        panel.border = element_blank(),
        axis.title.x=element_blank(), 
        axis.title.y=element_blank())
</code></pre>

<p>As an example, the final frame it produces is</p>

<p><a href=""https://i.stack.imgur.com/hbQmY.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hbQmY.png"" alt=""enter image description here""></a></p>

<p>This code on the other hand:</p>

<pre><code>p &lt;- mw_pop_counties_cov %&gt;%
  ggplot() +
  geom_sf(mapping = aes(fill = infRate, geometry=geometry), color = NA) +
  geom_sf(data = mw_states_sf, fill = NA, color = ""black"", size = 0.25) +
  coord_sf(datum = NA) +   
  scale_fill_gradient(name = ""% Population Infected"", trans = ""log"", low='green', high='red',
                      na.value = ""white"",
                      breaks=c(0, round(max(mw_pop_counties_cov$infRate),3))) +
  geom_point(data=mwBases, aes(x=longitude.1, y=latitude.1,size=personnel), color = ""hotpink"") +
  #geom_label_repel(data=AFMCbases, aes(x=longitude.1, y=latitude.1, label=Base)) +
  theme_bw() + 
  labs(size='AFMC \nMil + Civ') +
  theme(legend.position=""bottom"", 
        panel.border = element_blank(),
        axis.title.x=element_blank(), 
        axis.title.y=element_blank())
</code></pre>

<p>which is the same except that the data frames have been filtered down to only the midwest states, produces</p>

<p><a href=""https://i.stack.imgur.com/hGtFQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/hGtFQ.png"" alt=""enter image description here""></a></p>

<p>Note the appearance of the color scale.</p>

<p>Is there some typo I'm not seeing because I've been staring at this too long?<br>
My script produces 5 animations, 1 each for the national map, then the 4 census regions (northeast, midwest, south and west).  The color scale appears on the west and midwest maps, but not the other three.  This is despite the fact I basically just cut and pasted and then changed the dataframe names.  </p>

<p>What am I doing wrong?  I WANT the color scale to appear on ALL maps.</p>
"
61329127,"<p>I'll apologize in advance that the example below isn't ""minimal"" but I haven't been able to reproduce this behavior except in the particular instance of my full data set.</p>

<p>I asked this question before <a href=""https://stackoverflow.com/questions/60923486/ggplot2-scale-fill-gradient-disappears-inconsistently?noredirect=1#comment107797904_60923486"">here</a> and thought I had found the answer, but the behavior has returned and is vexing me.  Basically I have a script that reads daily COVID-19 case numbers and produces maps where the counties are color-coded by the percent of the population infected.  The script produces five maps, a national one and one for each of the four official census regions: northeast, midwest, south and west.  To cut down on size, the below is just the national and widwest maps.</p>

<p>My original script actually produces animated gifs showing the spread of the disease, but they take a long time to render.  The below version just gives a single plot of the most recent data and should run pretty quickly.</p>

<p>I've used a dput in the below script to avoid you having to read a file and geocode locations (I commented out the code) but there is still a large csv file of county populations that has to be read in.    I have posted it at pastebin <a href=""https://pastebin.com/jCD9tP0X"" rel=""nofollow noreferrer"">here</a>.</p>

<pre><code>    library(urbnmapr) # For map
    library(ggplot2)  # For map
    library(dplyr)    # For summarizing
    library(tidyr)    # For reshaping
    library(stringr)  # For padding leading zeros
    library(ggrepel)
    library(ggmap)
    library(usmap)
    library(gganimate)
    library(magrittr)
    library(gifski)
    library(ggnewscale)


    #if using Microsoft R, update checkpoint to get latest packages
    #checkpoint(""2020-03-01"")


    #start the clock
    ptm &lt;- proc.time()

    set.seed(42)

    #first run setup tasks
    #these can be commented out once the data frames are in place

    ###################begin first run only################################

    #register_google(key = ""your google map key here"")

    #AFMCbases&lt;-read.csv(""C:/Users/jerem/Desktop/Work/covid_maps/AFMCbases.csv"", header=TRUE, stringsAsFactors = FALSE)

    #geocode the place names
   # for(i in 1:nrow(AFMCbases)){
   #   result &lt;- geocode(AFMCbases$Base[i])
   #   AFMCbases$longitude[i] &lt;- as.numeric(result[1])
   #   AFMCbases$latitude[i] &lt;- as.numeric(result[2])
   # }

    #transform the lat/lons to appropriate map projection
   # locations&lt;-AFMCbases[,2:3]
   # new_locations &lt;- usmap_transform(locations)
   # AFMCbases &lt;- cbind(AFMCbases,new_locations[,3:4])
    AFMCbases &lt;- structure(list(Base = c(""Gunter AFB"", ""Davis Monthan AFB"", ""Edwards AFB"", 
""Robins AFB"", ""Scott AFB"", ""Hanscom AFB"", ""Offutt AFB"", ""Holloman AFB"", 
""Kirtland AFB"", ""Rome, NY"", ""Wright-Patterson AFB"", ""Tinker AFB"", 
""Arnold AFB"", ""Joint Base San Antonio"", ""Hill AFB"", ""Arlington, VA"", 
""Eglin AFB""), longitude = c(-86.244558, -110.8592578, -117.8912085, 
-83.591719, -89.8550095, -71.2743123, -95.9145568, -106.099291, 
-106.5338817, -75.4557303, -84.0537448, -97.4158295, -86.0303306, 
-98.4523675, -111.9826984, -77.1067698, -86.5533382), latitude = c(32.4083744, 
32.1675525, 34.9240314, 32.6400014, 38.5415911, 42.4579955, 41.1242718, 
32.8440404, 35.0539718, 43.2128473, 39.8137298, 35.4277, 35.3828616, 
29.4512786, 41.10968, 38.8799697, 30.4635583), personnel = c(820L, 
605L, 5317L, 14088L, 613L, 2906L, 177L, 699L, 1264L, 822L, 15299L, 
16032L, 389L, 3443L, 13679L, 1157L, 8143L), longitude.1 = c(1292311.33608434, 
-1025218.68277084, -1622487.54697885, 1533762.39465597, 881032.996527566, 
2296805.44531269, 342224.203588191, -572424.401062999, -596268.294707156, 
1951897.82199569, 1352969.1130143, 234917.935027853, 1263808.11814915, 
151230.865464104, -1000093.31185121, 1953459.66491185, 1292835.72883446
), latitude.1 = c(-1293180.11438144, -1358896.37536667, -946347.80198453, 
-1223833.19307048, -664025.051658055, 128586.352781279, -422393.887189579, 
-1328730.76688869, -1081540.1543388, 99159.9145180969, -445535.143260001, 
-1059563.46211616, -963250.657602903, -1722291.94024992, -359543.815036425, 
-408019.910644083, -1511165.09243038)), class = ""data.frame"", row.names = c(NA, 
-17L))

    #define census regions
    west_region &lt;-c(""WA"", ""OR"",""CA"",""NV"",""ID"", ""MT"", ""WY"", ""UT"",""CO"", ""AZ"", ""NM"")
    NE_region &lt;- c(""ME"",""NH"",""VT"",""MA"", ""CT"", ""RI"", ""NY"", ""PA"", ""NJ"")
    midwest_region &lt;- c(""ND"", ""SD"", ""NE"", ""KS"", ""MN"", ""IA"", ""MO"", ""WI"", ""IL"",""MI"", ""IN"",""OH"")
    south_region &lt;- c(""TX"", ""OK"", ""AR"", ""LA"", ""MS"", ""TN"", ""KY"", ""AL"", ""GA"",""FL"",""SC"",""NC"",""VA"",""WV"",""DC"",""MD"",""DE"")

    west_region_bases &lt;- c(""Davis Monthan AFB"", ""Edwards AFB"",""Holloman AFB"",""Kirtland AFB"",""Hill AFB"")
    south_region_bases &lt;- c(""Robins AFB"",""Tinker AFB"", ""Arnold AFB"", ""Joint Base San Antonio"", ""Arlington, VA"", ""Eglin AFB"")
    mw_region_bases &lt;- c(""Scott AFB"", ""Offutt AFB"", ""Wright-Patterson AFB"")
    ne_region_bases &lt;-c(""Hanscom AFB"", ""Rome, NY"")

    # Get COVID cases, available from:
    url &lt;- ""https://static.usafacts.org/public/data/covid-19/covid_confirmed_usafacts.csv""

    COV &lt;- read.csv(url, stringsAsFactors = FALSE)

    #sometimes there are encoding issues with the first column name
    names(COV)[1] &lt;- ""countyFIPS""


    Covid &lt;- pivot_longer(COV, cols=starts_with(""X""),
                          values_to=""cases"",
                          names_to=c(""X"",""date_infected""),
                          names_sep=""X"") %&gt;%
      mutate(infected = as.Date(date_infected, format=""%m.%d.%y""),
             countyFIPS = str_pad(as.character(countyFIPS), 5, pad=""0""))

    # Obtain map data for counties (to link with covid data) and states (for showing borders)
    states_sf &lt;- get_urbn_map(map = ""states"", sf = TRUE)
    counties_sf &lt;- get_urbn_map(map = ""counties"", sf = TRUE)

    # Merge county map with total cases of cov

#this is the line to use for making animations
    #pop_counties_cov &lt;- inner_join(counties_sf, Covid, by=c(""county_fips""=""countyFIPS"")) %&gt;%

    #to make last frame only
    pop_counties_cov &lt;- inner_join(counties_sf, group_by(Covid, countyFIPS) %&gt;%
                                 summarise(cases=max(cases)), by=c(""county_fips""=""countyFIPS""))


    #read the county population data
    counties_pop &lt;- read.csv(""C:/Users/jerem/Desktop/Work/covid_maps/countyPopulations.csv"", header=TRUE, stringsAsFactors = FALSE)

    #pad the single digit state FIPS states
    counties_pop &lt;- counties_pop %&gt;% mutate(CountyFIPS=str_pad(as.character(CountyFIPS),5,pad=""0""))

    #merge the population and covid data by FIPS
    pop_counties_cov$population &lt;- counties_pop$Population[match(pop_counties_cov$county_fips,counties_pop$CountyFIPS)]

    #calculate the infection rate
    pop_counties_cov &lt;- pop_counties_cov %&gt;% mutate(infRate = (cases/population)*100)

    #counties with 0 infections don't appear in the usafacts data, so didn't get a population
    #set them to 0
    pop_counties_cov$population[is.na(pop_counties_cov$population)] &lt;- 0
    pop_counties_cov$infRate[is.na(pop_counties_cov$infRate)] &lt;- 0

    plotDate=""April20""
    basepath = ""C:/your/output/file/path""

    naColor = ""white""
    lowColor = ""green""
    midColor = ""maroon""
    highColor = ""red""
    baseFill = ""dodgerblue4""
    baseColor = ""firebrick""
    baseShape = 23
    scaleLow = ""magenta""
    scaleHigh = ""blue""


    ###################end first run only################################


    ###################National Map################################

    p &lt;- pop_counties_cov %&gt;%
      ggplot() +
      geom_sf(mapping = aes(fill = infRate, geometry=geometry), color = NA) +
      geom_sf(data = states_sf, fill = NA, color = ""black"", size = 0.25) +
      coord_sf(datum = NA) +   
      scale_fill_gradient(name = ""% Pop \nInfected"", trans = ""log"",low=lowColor, high=highColor,
                          breaks=c(0, round(max(pop_counties_cov$infRate),1)),
                          na.value = naColor) +
      new_scale_fill() +
      geom_point(data=AFMCbases, 
                 aes(x=longitude.1, y=latitude.1,fill=personnel), 
                 shape= baseShape,
                 color = ""black"",
                 size = 3) +
      scale_fill_gradient(name=""AFMC \nMil + Civ"",
                          low = scaleLow, high = scaleHigh,
                          breaks = c(1, max(AFMCbases$personnel)))+
      theme_bw() + 
      theme(legend.position=""bottom"", 
            panel.border = element_blank(),
            axis.title.x=element_blank(), 
            axis.title.y=element_blank()) +
      labs(title=paste('Confirmed COVID-19 Cases: ', max(Covid$infected),sep=""""),
                         subtitle='HQ AFMC/A9A \nData: usafacts.org')

    # a &lt;- p + transition_time(infected) + 
    #         labs(title='Confirmed COVID-19 Cases: {frame_time}',
    #              subtitle='HQ AFMC/A9A \nData: usafacts.org')
    # 
    # animate(a, 
    #        device=""png"", 
    #        renderer=file_renderer(paste(basepath,plotDate,""/national"",sep=""""),
    #                               prefix=""gganim_plot"",
    #                               overwrite=TRUE)
    # )
    # 
    # #make the national animated gif
    # png_files &lt;- list.files(paste(basepath,plotDate,""/national"",sep=""""), pattern = "".*png$"", full.names = TRUE)
    # st = format(Sys.time(), ""%Y-%m-%d"")
    # gifName &lt;- paste(basepath,plotDate,""/national/COVID-19-Cases-byCounty_"",st,"".gif"",sep="""")
    # gifski(png_files, gif_file = gifName, width = 1000, height = 750, delay = 0.25, loop=FALSE)

    #save the image
    st = format(Sys.time(), ""%Y-%m-%d"")
    SaveFilename = paste(basepath,plotDate,""/national/COVID-19-Cases-byCounty_"",st,"".png"",sep="""")
    if(!dir.exists(paste(basepath,plotDate,""/national"",sep=""""))) dir.create(paste(basepath,plotDate,""/national"",sep=""""))
    ggsave(filename=SaveFilename, plot = p, dpi = 300)

    ###################End National Map################################


    ###################Midwest Map################################

    #filter out states
    #neCovid &lt;- Covid %&gt;% filter(State %in% NE_region )
    mw_pop_counties_cov &lt;- pop_counties_cov %&gt;% filter(state_abbv %in% midwest_region)
    mw_states_sf &lt;- states_sf %&gt;% filter(state_abbv %in% midwest_region)
    mw_counties_sf &lt;- counties_sf %&gt;% filter(state_abbv %in% midwest_region)

    #filter out bases
    mwBases &lt;- AFMCbases %&gt;% filter(Base %in% mw_region_bases)

    p &lt;- mw_pop_counties_cov %&gt;%
      ggplot() +
      geom_sf(mapping = aes(fill = infRate, geometry=geometry), color = NA) +
      geom_sf(data = mw_states_sf, fill = NA, color = ""black"", size = 0.25) +
      coord_sf(datum = NA) +   
      scale_fill_gradient(name = ""% Pop \nInfected"", trans = ""log"",low=lowColor, high=highColor,
                          breaks=c(0, round(max(mw_pop_counties_cov$infRate),1)),
                          na.value = naColor) +
      new_scale_fill() +
      geom_point(data=mwBases, 
                 aes(x=longitude.1, y=latitude.1,fill=personnel), 
                 shape = baseShape,
                 color = ""black"",
                 size=3) +
      scale_fill_gradient(name=""AFMC \nMil + Civ"",
                          low=scaleLow, high = scaleHigh,
                          breaks = c(1, max(mwBases$personnel)))+
      theme_bw() + 
      theme(legend.position=""bottom"", 
            panel.border = element_blank(),
            axis.title.x=element_blank(), 
            axis.title.y=element_blank()) +
      labs(title=paste('Confirmed COVID-19 Cases: ', max(Covid$infected),sep=""""),
           subtitle='HQ AFMC/A9A \nData: usafacts.org')

    # a &lt;- p + transition_time(infected) + 
    #   labs(title='Confirmed COVID-19 Cases: {frame_time}',
    #        subtitle='HQ AFMC/A9A \nData: usafacts.org')
    # 
    # animate(a, 
    #         device=""png"", 
    #         renderer=file_renderer(paste(basepath,plotDate,""/midwest"",sep=""""),
    #                                prefix=""gganim_plot"",
    #                                overwrite=TRUE)
    # )
    # 
    # #make the midwest animated gif
    # png_files &lt;- list.files(paste(basepath,plotDate,""/midwest"",sep=""""), pattern = "".*png$"", full.names = TRUE)
    # st = format(Sys.time(), ""%Y-%m-%d"")
    # gifName &lt;- paste(basepath,plotDate,""/midwest/MW_COVID-19-Cases-byCounty_"",st,"".gif"",sep="""")
    # gifski(png_files, gif_file = gifName, width = 1000, height = 750, delay = 0.25, loop=FALSE)

    st = format(Sys.time(), ""%Y-%m-%d"")
    SaveFilename = paste(basepath,plotDate,""/midwest/MW_COVID-19-Cases-byCounty_"",st,"".png"",sep="""")
    if(!dir.exists(paste(basepath,plotDate,""/midwest"",sep=""""))) dir.create(paste(basepath,plotDate,""/midwest"",sep=""""))
    ggsave(filename=SaveFilename, plot = p, dpi = 300)

    ###################End Midwest Map################################
</code></pre>

<p>This is the national map I got this morning when I ran the code</p>

<p><a href=""https://i.stack.imgur.com/d3IVC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/d3IVC.png"" alt=""enter image description here""></a></p>

<p>Note that there is a scale for the number of personnel at the bases (the colored diamonds) but there is no scale for the shading of the counties.</p>

<p>Here is the midwest map.  You can see from the code that it is the same ggplot just with a dataset that is filtered down to the counties in the midwest region.</p>

<p><a href=""https://i.stack.imgur.com/NdnWm.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/NdnWm.png"" alt=""enter image description here""></a></p>

<p>Now the scale is there.  As mentioned in my previous question I thought that the answer had been something to do with the width of the image being insufficient to accommodate the scale.  When I added a newline in the legend text to shorten it that appeared to do the trick.  But now the legend is disappearing again, andmaking the output image wider has no effect. Plus, just by eyeball it would appear there is plenty of room in the national plot to accommodate the scale.</p>

<p>Another bizarre aspect is the behavior associated with rounding the breaks.  Below is a west map where I applied no rounding to the breaks </p>

<pre><code>scale_fill_gradient(name = ""% Pop \nInfected"",trans = ""log"", low=lowColor, high=highColor,
                       breaks=c(0, max(west_pop_counties_cov$infRate)),
                       na.value = naColor)
</code></pre>

<p><a href=""https://i.stack.imgur.com/jpnlG.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jpnlG.png"" alt=""enter image description here""></a></p>

<p>So the scale is back but it goes to 6 decimal places.  If I try to round it to 2</p>

<pre><code> scale_fill_gradient(name = ""% Pop \nInfected"",trans = ""log"", low=lowColor, high=highColor,
                       breaks=c(0, round(max(west_pop_counties_cov$infRate),2)),
                       na.value = naColor)
</code></pre>

<p>I get this map</p>

<p><a href=""https://i.stack.imgur.com/2YAqc.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2YAqc.png"" alt=""enter image description here""></a></p>

<p>which surely indicates the horizontal space isn't the issue...if it can accommodate 6 decimal places then surely there's room for 2?</p>

<p>I've spent as much time trying to figure out this inconsistent scale behavior as I spent writing the original script.  I need these things to be consistent so that I can provide them as work products on a regular interval.</p>
"
61565339,"<p>I'm trying to analyze some coronavirus data to look at cases per day and such.  I found data on the CDC website and it's in a non-tidy format, with each date having its own column.  I am using pivot_longer to transpose the data.  The following works to read in the data, pivot it, and use mutate to change the column data type of date to be date.</p>

<pre><code>library(tidyverse)
library(lubridate)
deaths = read_csv(""https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv"")

deaths2 = deaths %&gt;%
  rename(county = `County Name`, state = State) %&gt;%
  pivot_longer(-c(countyFIPS, county, state, stateFIPS), names_to = ""date"", values_to = ""deaths_cumulative"") %&gt;%
  mutate(date = mdy(date)) %&gt;%
  select(state, county, date, deaths_cumulative)
</code></pre>

<p>However, I am trying to use the names_ptypes argument of pivot_longer to specify the data type in that step.  If I do the following, the date column does end up with a data type of date, but all values in the column are NA.  I am not sure what's going on.  Perhaps it needs a format, but Date doesn't allow one, as far as I can tell.  Is there a way to do this?</p>

<pre><code>deaths2 = deaths %&gt;%
  rename(county = `County Name`, state = State) %&gt;%
  pivot_longer(-c(countyFIPS, county, state, stateFIPS), names_to = ""date"", values_to = ""deaths_cumulative"", names_ptypes = list(date = Date())) %&gt;%
  select(state, county, date, deaths_cumulative)
</code></pre>
"
61672202,"<p>I'm trying to plot US county-level data, but I can't figure out why some counties do not appear. In this toy example I focus on just California counties, and I leave in all of the daily data until the end when I filter out in the call to <code>ggplot()</code> (my actual use case involves gganimate, so I need the daily data).</p>

<p><a href=""https://i.stack.imgur.com/QT2mF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/QT2mF.png"" alt=""enter image description here""></a></p>

<pre><code>library(tidyverse)
library(sf)
library(viridis)
library(""rio"")

# get county geometry
  url &lt;- ""https://gist.githubusercontent.com/ericpgreen/717596c37478ef894c14b250477fae92/raw/c2cf4b273a2c7f0677f22a37b5e9f7e893204e3b/cali.R""
  cali &lt;- rio::import(url)

# get covid data
  covid &lt;- read.csv(""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"", 
                    stringsAsFactors = FALSE)

# prep covid data
  covidPrepped &lt;-
  covid %&gt;%
    filter(state==""California"") %&gt;%
    select(date, fips, cases, deaths) %&gt;%
    mutate(date = lubridate::ymd(date)) %&gt;%
    mutate(fips = stringr::str_pad(fips, width=5, pad=""0"")) %&gt;%
    mutate(month = lubridate::month(date, 
                                    label=TRUE, 
                                    abbr=TRUE),
           day = lubridate::day(date),
           monthDay = paste(month, day, sep="" ""))

# make sure every county has a row for every day
  complete &lt;- 
  cali %&gt;%
    left_join(covidPrepped, by = c(""GEOID"" = ""fips"")) %&gt;%
    complete(date, GEOID, fill = list(cases = 0)) %&gt;%
    select(date, GEOID, cases, monthDay)

# join back to geometry and construct casesPop
  pData &lt;- 
  complete %&gt;%
    left_join(select(cali, GEOID, NAME, estimate, geometry),
              by = ""GEOID"") %&gt;%
    st_as_sf() %&gt;%
    mutate(casesPop = (cases/estimate)*100000) %&gt;%
    mutate(casesPop = ifelse(is.na(casesPop), 0, casesPop)) %&gt;%
    mutate(group = cut(casesPop, 
                       breaks = c(0, 1, 3, 10, 30, 100, 
                                  300, 1000, 3000, 10000, 
                                  Inf),
                       labels = c(0, 1, 3, 10, 30, 100, 
                                  300, 1000, 3000, 10000),
                       include.lowest = TRUE)
    ) %&gt;%
    select(GEOID, geometry, group, monthDay) 

# plot
  ggplot(pData %&gt;% filter(monthDay==""May 5"")) +
    geom_sf(aes(fill = group), color = ""white"", size=.1) +
    scale_fill_viridis_d(option = ""magma"", drop=FALSE) +
    coord_sf(crs = 102003) +
    theme_minimal() + 
    theme(legend.position = ""top"",
          legend.box = ""horizontal"",
          legend.title = element_blank(),
          legend.justification='left') +
    guides(fill = guide_legend(nrow = 1))
</code></pre>

<p>Missing counties:</p>

<pre><code>missing &lt;- pData %&gt;% filter(monthDay==""May 5"")
cali$GEOID[!(cali$GEOID %in% test$GEOID)]
#[1] ""06035"" ""06049"" ""06091"" ""06105""
</code></pre>

<p>These counties do not have <code>covid</code> data for May 5, but I thought this would be addressed by the call to <code>complete()</code>.</p>

<p><code>complete(date, GEOID, fill = list(cases = 0))</code></p>
"
61684516,"<p>I am having trouble compiling my {<a href=""https://github.com/EvaMaeRey/flipbookr"" rel=""nofollow noreferrer""><code>flipbookr</code></a>} deck. I'm able to run the template without problems, but I'm getting a blank file that will not advance when I knit my own.</p>

<p><a href=""https://i.stack.imgur.com/yv8ta.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/yv8ta.png"" alt=""enter image description here""></a></p>

<p>If I remove the call to <code>chunk_reveal()</code> it works.</p>

<p><code>r chunk_reveal(""cars"", break_type = ""auto"")</code></p>

<p>As far as I can tell, the only thing I'm doing differently from the template (aside from shortening it), is to get external data in the setup chunk, and then working with that data in the chunk still named cars.</p>

<p>FYI, I posted <a href=""https://github.com/EvaMaeRey/flipbookr/issues/19#issue-614745922"" rel=""nofollow noreferrer"">an issue</a> on the package github repo, but it's not clear to me whether something like this is a coding problem that a SO user could help me solve or a package issue the developer should see. </p>

<p>Here is an example based on the template that should reproduce the issue.</p>

<pre><code>---
title: ""The art of flipbooking""
subtitle: ""With flipbookr and xaringan""
author: ""Gina Reynolds, December 2019""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: [default, hygge, ninjutsu]
    nature:
      ratio: 16:10
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include = F}
# This is the recommended set up for flipbooks
# you might think about setting cache to TRUE as you gain practice --- building flipbooks from scracth can be time consuming
knitr::opts_chunk$set(fig.width = 6, message = FALSE, warning = FALSE, comment = """", cache = FALSE, fig.retina = 3)
library(flipbookr)
library(tidyverse)

covid &lt;- read.csv(""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"", 
                  stringsAsFactors = FALSE)
```



# Using `flipbookr::chunk_reveal()`

You will use the `chunk_reveal()` function [inline](https://rmarkdown.rstudio.com/lesson-4.html) to generate the derivitive code chunks, rather than inside of a code chunk, so that the text that is generated is interpreted correctly when rendered.  The inline code will look something like this:

&lt;!-- The above is for the html output version, just look at the examples below if you are in the source! --&gt;
```markdown
``r ""r chunk_reveal(chunk_name = \""cars\"", break_type = \""user\"")""``
``` 

There are several modalities that you might be interested in using for ""flipbookifying"" your code and the next section is dedicated to demoing some of them below.

- **break type** -- *which lines of code should be revealed when*, `break_type` defaults to ""auto""
- **display type** -- *display code and output, or just output, or just code?*, `display_type` defaults to ""both""
- **assignment type** -- *does code chunk use left assignment?*, `left_assign` defaults to FALSE

---

At first we'll apply our flipbooking to the below input code - the code chunk is named ""cars"".  For now I set echo = TRUE for this code chunk, so you can see the code content but sometimes you might like to set echo to FALSE. This code uses tidyverse tools, so we loaded that too in the ""setup"" code chunk at the beginning of the template. 

```{r cars, include = FALSE}
covid %&gt;%
  filter(state!=""District of Columbia"" &amp;
           state!=""Puerto Rico"" &amp;
           state!=""Hawaii"" &amp;
           state!=""Alaska"") %&gt;%
  select(date, fips, cases, deaths) %&gt;%
  mutate(date = lubridate::ymd(date)) %&gt;%
  mutate(fips = stringr::str_pad(fips, width=5, pad=""0"")) %&gt;%
  mutate(month = lubridate::month(date, 
                                  label=TRUE, 
                                  abbr=TRUE),
         day = lubridate::day(date),
         monthDay = paste(month, day, sep="" "")) 
```

---

# `break_type`

Notice the regular comments and the special #BREAK comments, these will be used for a couple of the different ""break type"" modalities.


```{r, code = knitr::knit_code$get(""cars""), eval = FALSE, echo = TRUE}
```

&lt;!-- Also notice how we've created a new code chunk with the code from the previous chunk by calling knitr::knit_code$get(""cars""). --&gt;
&lt;!-- This slide is also about giving you some intuition about how flipbooking works in the background. --&gt;
&lt;!-- (more on this [here](https://emitanaka.rbind.io/post/knitr-knitr-code/)) --&gt;

---

## break_type = ""auto""

One parameter of flipbooking is the break_type.  The default is ""auto"", in which appropriate breakpoints are determined automatically --- by finding where parentheses are balanced. 

&lt;!-- display the user input code as a refresher --&gt;
```{r, code = knitr::knit_code$get(""cars""), eval = FALSE, echo = TRUE}
```


---

`r chunk_reveal(""cars"", break_type = ""auto"")`

---


```{css, eval = TRUE, echo = FALSE}
.remark-code{line-height: 1.5; font-size: 80%}
```
</code></pre>
"
61595674,"<p>Countries and continents are in this data set.</p>

<pre><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19-timeseries/master/countryReport/raw/rawReport.csv')

#This data set contains countries and population information.

df8 &lt;- read.csv ('https://raw.githubusercontent.com/hirenvadher954/Worldometers-Scraping/master/countries.csv')


library(dplyr)
library(stringr

df %&gt;% 
    left_join(df8, by = c(""countryName"" = ""country_name"")) %&gt;% 
    mutate(population = as.numeric(str_remove_all(population, "",""))) %&gt;% 
    group_by(countryName) %&gt;%
    slice_tail(1) %&gt;%
    group_by(region) %&gt;% 
    summarize(population = sum(population, na.rm = TRUE)) 
</code></pre>

<p><strong>df%>% left_join (df8, by = c (countryName = ""country_name""))%>% error:</strong>
<strong>No function ""%>%"" found</strong>   gives this error. Can you explain why and provide a solution?</p>

<p>How can I combine continental information in data set 1 with population information in data set 2?</p>

<p>for example: asia 2.8 billion, africa 800 million, europe 1 billion</p>
"
61410224,"<p>Hi I created a usmap using</p>

<pre><code>plot_usmap(regions=""counties"",data=big.covid,values = ""density"")+
  labs(title=""Unweighted Density by County"")+
  theme(panel.background = element_rect(color=""black""))+
  scale_fill_continuous(low=""white"",high=""darkblue"", name=""Density"")
</code></pre>

<p>rather than knitting, I get this error:
    Error in <code>[.data.frame</code>(result, , c(setdiff(names(result), names(data)), : undefined columns selected</p>

<p>any idea of how to identify the error and fix it? There are 59 variables would the issue be in a colname not being used in the map above? using x=x,y=y,id=fips which are built into the plot_usmap call</p>
"
61386513,"<p>I used to read data from github with no problem and now I get error with the same simple code.</p>

<pre><code>x &lt;- getURL(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"")
y &lt;- read.csv(x, header = FALSE)
</code></pre>

<blockquote>
  <p>Error in file(file, ""rt"") : cannot open the connection  </p>
</blockquote>

<p>In addition:  </p>

<blockquote>
  <p>Warning message: In file(file, ""rt"") : cannot open file 'HTTP/1.1 200
  OK</p>
</blockquote>
"
61605170,"<p>I am getting an error stating:
""Error: variable 'date' was fitted with type ""other"" but type ""numeric"" was
supplied""</p>

<p>I retry to predict an expected date for my fit model but it seems that it
might be a categorical issue with my dataset, but I don't know where.</p>

<h2>Question 2 predict positive cases from 3-30 to 4-8 &amp; predicted transformed intervals **need to compare with original scale</h2>

<pre><code>pred_data = data[data$date&gt;=""2020-03-30"" &amp; data$date&lt;=""2020-04-08"",]
pred_data$pos_trans = (pred_data$positive^lam-1)/lam
pred_data$pred = predict(fit_trans,newdata = pred_data)
predict(fit_trans, newdata = pred_data,interval = ""predict"")
pred_data


data_Test$pos_trans_pred = predict(fit_trans, newdata = data_Test)
pred_error = data_Test$pos_trans_pred-data_Test$pos_trans
pred_error_trans = mean(pred_error^2)
pred_error_trans
pred_error
plot(US$date, US$pos_trans,ylim = c(25,125))
lines(data_Train$date,fit_trans$fitted.values,col=2)
lines(data_Test$date, data_Test$pos_trans_pred, col=3)
</code></pre>

<ol>
<li><p>Error: variable 'date' was fitted with type ""other"" but type ""numeric"" was supplied</p></li>
<li><p>My original starting date are as follows: </p></li>
</ol>

<pre><code>##Model w/3/16-29
##Train 3/16-3/29
##Test 3/30-4/8

    library(data.table)
    data = fread('https://covidtracking.com/api/us/daily.csv',data.table=FALSE)
    days = 24
    loc = which(data[,1]=='20200408')
    US = data[loc:(loc+days-1),c(1,3)]
    US$date = as.Date(as.character(US$date), format = '%Y%m%d')
    fit = lm(positive ~ date, data = US)
    train_Ind = 11:24
    data_Train = US[train_Ind,]
    data_Test = US[-train_Ind,]
    fit = lm(positive ~ date, data = data_Train)
    library(MASS)
    boxcox_fit = boxcox(fit)
    lam = boxcox_fit$x[which.max(boxcox_fit$y)]
    data_Train$pos_trans = (data_Train$positive^lam-1)/lam
    data_Test$pos_trans = (data_Test$positive^lam-1)/lam
    US$pos_trans = (US$positive^lam-1)/lam
    fit_trans = lm(pos_trans ~ date, data = data_Train)
</code></pre>
"
61165774,"<p>I am trying to get sum of <code>X3.23.20</code> column group by country</p>

<p>I tried this code using <code>aggregate</code> function</p>

<pre><code>covid &lt;- read.csv(""time_series_covid_19_confirmed.csv"") %&gt;%
  select(Province.State, Country.Region, X3.23.20) %&gt;%
  aggregate(
    covid$X3.23.20,
    by = list(Country.Region = covid$Country.Region),
    FUN = sum
  )

View(covid)
</code></pre>

<p>Always returning error as :
Error in Summary.factor(1L, c(599L, 1086L, 455L, 2L, 1306L, 424L, 533L,  : 
  ‘sum’ not meaningful for factors</p>

<p>Excel available in <a href=""https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset"" rel=""nofollow noreferrer"">https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset</a>
<strong>time_series_covid_19_confirmed.csv</strong></p>
"
61111024,"<p>I have decided to brush up on my map making skills and am using the publicly available COVID data from: <a href=""https://www.kaggle.com/sudalairajkumar/covid19-in-usa"" rel=""nofollow noreferrer"">https://www.kaggle.com/sudalairajkumar/covid19-in-usa</a> </p>

<p>Below is my code:</p>

<pre><code>USdata &lt;- us_states_covid19_daily %&gt;%
    group_by(state)%&gt;%
    summarise(values = sum(positive))

#Assign each state its fips code using fips()
USdata$state &lt;- as.numeric(fips(USdata$state))
USdata$values &lt;- as.numeric(USdata$values)

#Rename columns appropriately
names(USdata)[names(USdata) == ""state""] &lt;- ""fips""
USdata &lt;- na.omit(USdata)

plot_usmap(data = USdata)
</code></pre>

<p>I keep receiving this error:</p>

<pre><code>Error in `[.data.frame`(map_df, , values) : undefined columns selected
</code></pre>

<p>This is what my data frame looks like:</p>

<pre><code>&gt; head(USdata)
# A tibble: 6 x 2
   fips values
  &lt;dbl&gt;  &lt;dbl&gt;
1     2   1908
2     1  16845
3     5   9084
4     4  21232
5     6 128974
6     8  44905
</code></pre>

<p>My data frame could also look like this if I delete a line of code:</p>

<pre><code>&gt; head(USdata)
# A tibble: 6 x 2
  fips  values
  &lt;fct&gt;  &lt;dbl&gt;
1 AK      1908
2 AL     16845
3 AR      9084
4 AZ     21232
5 CA    128974
6 CO     44905
</code></pre>

<p>Anyone know what I'm doing wrong?</p>
"
61082196,"<p>I am attempting to create two drop downs in shiny - one a list of states that then filters the second drop down which lists all counties for the selected state. The following code works BUT the counties do not update when you change states.</p>

<p>UI</p>

<pre><code>pageWithSidebar(
 headerPanel(""My chart""),
 sidebarPanel(
  uiOutput(""sel_state""),
  uiOutput(""sel_county"")
 ),
 mainPanel(
  tableOutput(""table"")
 )
)
</code></pre>

<p>Server</p>

<pre><code>function(input, output, session) {

  output$sel_state &lt;- renderUI({
   selectizeInput('state', 'Select a State', choices=c(""Choose One"" = """", state_list))
  })

  output$sel_county &lt;- renderUI({
   county_list &lt;- reactive({
    df %&gt;%
     filter(state == input$state) %&gt;%
     pull(county) %&gt;%
     sort() %&gt;%
     as.character()
   })
    selectizeInput('county', 'Select a County', choices=c(""Choose One"" = """", county_list()))
  })

  tab &lt;- reactive({
   df %&gt;%
    filter(state == input$state) %&gt;%
    filter(county == input$county)
  })

  output$table &lt;- renderTable({
   tab()
  })
 }
</code></pre>

<p>I attempted to replace the 'selectizeInput' in the county drop down with the following 'updateSelectizeInput' but keep getting the following error</p>

<p>New Server line</p>

<pre><code>updateSelectizeInput(session, 'county', 'Select a County', choices=c(""Choose One"" = """", county_list()))
</code></pre>

<p>ERROR: cannot coerce type 'environment' to vector of type 'character'</p>

<p>Code to create data frames - the county list is not a proper list yet</p>

<pre><code>    x &lt;- getURL(""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"")
    csv &lt;- read.csv(text=x)
    df &lt;- as.data.frame(csv)
    state_list &lt;- c(levels(df$state))
    county_list &lt;- subset(df, select = c(3,2))
</code></pre>

<p>dput output</p>

<pre><code>dput(head(cl))
structure(list(state = c(""Washington"", ""Washington"", ""Washington"", 
""Illinois"", ""Washington"", ""California""), county = c(""Snohomish"", 
""Snohomish"", ""Snohomish"", ""Cook"", ""Snohomish"", ""Orange"")), row.names = 
c(NA, 6L), class = ""data.frame"")
</code></pre>
"
61085538,"<p>I am attempting to rbind two data frames in shiny so I can plot them together but I receive an <strong>error ""replacement has 1 row, data has 0""</strong> when I do. I've included my full app below - and I'm assuming the error occurs in these server lines:</p>

<pre><code># create new cases and new deaths data frames and add a New ""NAME"" value to each row
ncdf &lt;- cd[,c(1,4)]
nddf &lt;- cd[,c(1,5)]
ncdf$name &lt;- ""New Cases""
nddf$name &lt;- ""New Deaths""
</code></pre>

<p>The app works locally even with the error but when I try to upload it to shinyapps it does not.</p>

<pre><code>global.R
library(RCurl)
library(dplyr)
library(ggplot2)
library(data.table)
library(ggthemes)
library(plotly)
library(DT)

# Pull the data from NYT github and turn it into a data frame
x &lt;- getURL(""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"")
csv &lt;- read.csv(text=x)
df &lt;- as.data.frame(csv)

# Create a sorted list of unique states
state_list &lt;- as.character(levels(df$state))
</code></pre>

<pre><code>ui.R
ui &lt;- fluidPage(
  title = ""Covid-19 Cases/Deaths"",
  headerPanel(""Covid-19 Cases/Deaths by County""),
  fluidRow(
    column(3, uiOutput(""sel_state"")),
    column(4, conditionalPanel(condition = ""input.state.length &gt; 0"", uiOutput(""sel_county"")))
    ),
  plotOutput(""plot""),
  hr(),
)

server.R
function(input, output, session) {

# create a list of selected counties based on which State is selected
  selected_state_counties &lt;- reactive({
    req(length(input$state) &gt; 0)
    df %&gt;% 
      filter(state == input$state) %&gt;% 
      pull(county) %&gt;% 
      as.character()
  })

# create the state drop down menu based on the state list from global
  output$sel_state &lt;- renderUI({
    selectizeInput('state', 'Select a State', choices=c(""Choose One"" = """", state_list))
  })

# create the county drop down menu based on the selected state above
  output$sel_county &lt;- renderUI({
    selectizeInput('county', 'Select a County', choices=c(""Choose One"" = """", selected_state_counties()))
  })

# create a new data frame of just the selected county data
  tab &lt;- reactive({
    df %&gt;%
      filter(state == input$state) %&gt;%
      filter(county == input$county)
  })

# plot the specific county data
  output$plot &lt;- renderPlot({

    # turn tab into a data table for calculation
    cd &lt;- as.data.table(tab())

    ## add and calculate 'new_cases' &amp; 'new_deaths' columns
    cd[, new_cases := cases - c(0, head(cases, -1))]
    cd[, new_deaths := deaths - c(0, head(deaths, -1))]

    # convert to data frame
    cd &lt;- as.data.frame(cd)

    # strip unused data
    cd &lt;- cd[, c(1,5,6,7,8)]

    # mutate fields to as date &gt; date, and all other columns as numerical
    cd &lt;- mutate(cd, date=as.Date(date), cases=as.numeric(cases), deaths=as.numeric(deaths), new_cases=as.numeric(new_cases), new_deaths=as.numeric(new_deaths))

    # create new cases and new deaths data frames and add a New ""NAME"" value to each row
    ncdf &lt;- cd[,c(1,4)]
    nddf &lt;- cd[,c(1,5)]
    ncdf$name &lt;- ""New Cases""
    nddf$name &lt;- ""New Deaths""

    #rename the column with the count in it to cases for both data frames
    ncdf &lt;- ncdf %&gt;% rename(cases = new_cases)
    nddf &lt;- nddf %&gt;% rename(cases = new_deaths)

    # rbind both 'new' data frames together to be plotted as ndf
    ndf &lt;- rbind(ncdf, nddf)

    ## line plot colors/legend
    lines &lt;- c('Cases' = 'lightskyblue3', 'Deaths' = 'lightcoral')
    ## bar plot colors/legend
    bars &lt;- c('New Cases' = 'steelblue1', 'New Deaths' = 'tomato1')
    ## chart title
    chart_title &lt;- paste(input$county, ""County - Covid-19 Cases/Deaths"")

    ## define plot formats as 'p' and add formatting/titles  
    p &lt;- ggplot() + labs(title=chart_title, x=""Date"", color=""Legend"", fill="""") + theme(legend.position=""bottom"", plot.title = element_text(hjust = 0.5), axis.text.x = element_text(angle = 90)) + scale_color_manual(values = lines) + scale_fill_manual(values = bars) + scale_y_continuous(name=""Cases"", labels = scales::number_format(accuracy = 1))

    ## plot cases/deaths as lines from cd data frame; plot new_cases/new_deaths as bar from ndf data frame; using 'p' for formatting
    p + geom_line(data=cd, aes(date, cases, group=1, color='Cases'), size=1) + geom_line(data=cd, aes(date, deaths, group=2, color='Deaths'), size=1) + geom_bar(data=ndf, aes(date, cases, fill=name), stat=""identity"", width=0.5, position = 'dodge') + geom_bar(data=ndf, aes(date, cases, fill=name), stat = 'identity', width=0.5, position=""dodge"") 

  })
}

</code></pre>
"
61071364,"<p>I run the code, it works great. I try to knit and I get this error:</p>

<blockquote>
  <p>Error: Can't rename columns that don't exist.
  The column <code>Tests&lt;U+2009&gt;/millionpeople</code> doesn't exist.</p>
</blockquote>

<p>I tried, clearing cache, loading image at start, creating a new object for the rename and mutate work, and lots more. Error likely emerges because the scraped object is not being loaded (or found) during the knit, but I cant figure out why or how to fix.</p>

<p>Any ideas?
Thanks! </p>

<p>My code:</p>

<pre><code>library(utils) library(httr) library(tidyverse) library(rvest) library(ggpubr)

#scrapes from wikipedia, xpath is correct url &lt;- ""https://en.wikipedia.org/wiki/COVID-19_testing""  tests &lt;- url %&gt;%     read_html() %&gt;%   html_nodes(xpath='//*[@id=""mw-content-text""]/div/table[4]') %&gt;%    html_table() %&gt;%    extract2(1) %&gt;% # extracts data table from html list   rename(country = ""Country or region"", tests = ""Tests"", positive
= ""Positive"", asof = ""As of"", 
         tests_per_million = ""Tests /millionpeople"" ,
         positive_per_thousand_tests = ""Positive /thousandtests"", ref = ""Ref."") %&gt;%   mutate(tests = as.numeric(gsub("","", """", tests)), positive = as.numeric(gsub("","", """", positive)),
         tests_per_million = as.numeric(gsub("","", """", tests_per_million)),
         positive_per_thousand_tests = round(positive_per_thousand_tests, 0)) #removes commas and coverts to numeric'
</code></pre>
"
61068031,"<p>I am getting Error: stat_count() can only have an x or y aesthetic. when trying to plot using data from an excel sheet</p>

<pre><code>library(readxl)
library(dplyr)
library(ggplot2)
dataset= read_excel(""D:/Downloads/Covid19.xlsx"")
dataset2= read_excel(""D:/Downloads/Covid19.xlsx"", sheet = ""Sheet2"")
dataset3= dataset[,c(4,5)]
ggplot(dataset2, aes(x=Region, y= male))+geom_bar()
</code></pre>

<p>My Data from excel file looks like this
<a href=""https://i.stack.imgur.com/oaw7B.png"" rel=""nofollow noreferrer"">Dataset</a></p>

<p><a href=""https://i.stack.imgur.com/kmsiU.png"" rel=""nofollow noreferrer"">Excel</a></p>
"
60976256,"<p>I am trying to plot the coronavirus spread in India vs Rest of the world by using the below R code
I have corona_world as a dataframe and created daily_confirmed dataframe from it .I have eliminated all values of NA in variable column 'India' . But still the error says it does not have same length. I don't understand why it isn't working. Please help</p>

<p>Error: Tibble columns must have consistent lengths, only values of length one are recycled: * Length 61: Column y * Length 10358: Column x</p>

<pre><code>daily_confirmed &lt;- corona_world %&gt;%
  dplyr::select(Confirmed) %&gt;%
  dplyr::mutate(country = dplyr::if_else(corona_world$Country.Region == ""India"",
                                         ""India"",
                                         ""Rest of the World"")) %&gt;%
  dplyr::group_by(corona_world$ObservationDate, country) %&gt;%
  dplyr::summarise(total = sum(Confirmed, rm.na=TRUE)) %&gt;%
  dplyr::ungroup() %&gt;%
  tidyr::pivot_wider(names_from = country, values_from = total)

daily_confirmed &lt;- daily_confirmed[-c(1:8),]
daily_confirmed %&gt;%
  plotly::plot_ly() %&gt;%
  plotly::add_trace(x = ~ corona_world$ObservationDate,
                    y = ~ India,
                    type = ""scatter"",
                    mode = ""lines+markers"",
                    name = ""India"") %&gt;%
  plotly::add_trace(x = ~ corona_world$ObservationDate,
                    y = ~ Rest of the World,
                    type = ""scatter"",
                    mode = ""lines+markers"",
                    name = ""Rest of the World"") %&gt;%
  plotly::layout(title = """",
                 legend = list(x = 0.1, y = 0.9),
                 yaxis = list(title = ""Number of New Cases""),
                 xaxis = list(title = ""Date""),
                 hovermode = ""compare"",
                 margin = list(b = 10,
                               t = 10,
                               pad = 2
                 ))
</code></pre>

<p>The input is <a href=""https://i.stack.imgur.com/R63v8.png"" rel=""nofollow noreferrer"">https://i.stack.imgur.com/R63v8.png</a></p>
"
60937200,"<p>I am trying to generate predictions for covid cases using a GAM model. The following code works and produces a projection of US cases. </p>

<pre><code>  US_data = covid_cases %&gt;% select(United.States, day_num)

  head(US_data)
  United.States day_num
1             0       1
2             0       2
3             0       3
4             0       4
5             0       5
6             0       6

  end_date = nrow(US_data)+28
  new_data = data.frame(seq(1:end_date))
  colnames(new_data) = ""day_num""

  US_gam &lt;- gam(United.States~s(day_num,k=45), data=US_data)

#generate predictions

  US_predictions = data.frame(predict(US_gam, new_data))
  US_predictions$day_num &lt;- as.numeric(new_data$day_num)
  names(US_predictions)[1] &lt;- ""United.States""
</code></pre>

<p>I want to apply the same code to any country I choose and therefore thought a simple function would be easiest. This function basically takes all the code above and wraps it up in a function. </p>

<pre><code>get_df &lt;- function(df,location, day_num){
  data = df %&gt;% select(location, day_num)
  return(data)
}

projection &lt;- function(df,location,day_num){
  data = get_df(df,location, day_num)
  end_date = nrow(data)+28
  new_data = as.data.frame(seq(1:end_date))
  colnames(new_data) = ""day_num""
  country_gam &lt;- gam(location~ s(day_num,k=45), data=data)
  country_predictions = data.frame(predict(country_gam, new_data))
  country_predictions$day_num &lt;- as.numeric(new_data$day_num)
  names(country_predictions)[1] &lt;- location
  return (country_predictions)
}
</code></pre>

<p>However - initially it failed at the data subsetting line, so I put the get_df as a helper function. Now it fails at the gam analysis:</p>

<pre><code>US_data &lt;- projection(covid_cases, ""United.States"", ""day_num"")
         Show Traceback

Error in model.frame.default(formula = location ~ 1 + day_num, data = data,  : 
      variable lengths differ (found for 'day_num') 
    6. model.frame.default(formula = location ~ 1 + day_num, data = data, 
        drop.unused.levels = TRUE) 
    5. stats::model.frame(formula = location ~ 1 + day_num, data = data, 
        drop.unused.levels = TRUE) 
    4. eval(mf, parent.frame()) 
    3. eval(mf, parent.frame()) 
    2. gam(location ~ s(day_num, k = 45), data = data) 
    1. projection(covid_cases, ""United.States"") 
</code></pre>

<p>The error seems to suggest that data$day_num does not equal data$location length, but I can't work out why it would say that because they are the same length. </p>

<p>I've read the various responses on stack overflow and can't find any answers, and hunting around the internet has turned up anything either. I'd greatly appreciate any help!</p>

<p>To get the covid data for a fully reproducible example:</p>

<pre><code>covid_cases &lt;- read.csv(url(""https://covid.ourworldindata.org/data/ecdc/total_cases.csv""))
covid_cases[is.na(covid_cases)] = 0
covid_cases$day_num = as.numeric(covid_cases[,1])
</code></pre>
"
60963990,"<p>I am trying to map a UK government petition data in R. I used the boundary data from ONS geography portal. The code works and the first map I created also works. </p>

<pre><code>#Install packages 

install.packages(""tidyverse"")
install.packages(""jsonlite"")
install.packages(""geojsonio"")
install.packages(""sp"")
install.packages(""parlitools"")
install.packages(""rvest"")
install.packages(""xml2"")
install.packages(""magrittr"")

#Load packages 
library(tidyverse)
library(jsonlite)
library(geojsonio)
library(sp)
library(parlitools)
library(rvest)
library(xml2)
library(magrittr)

[#GETTING PETITION DATA

#Importing petition for UK-wide lockdown from JSON format
petition &lt;- fromJSON(""https://petition.parliament.uk/petitions/301397.json"", flatten = TRUE)

signatures &lt;- petition$data$attributes$signatures_by_constituency %&gt;%
  rename(constituency = name)

#MAPPING BOUNDARIES

#Save url for boundary data UK
url &lt;- ""https://opendata.arcgis.com/datasets/b64677a2afc3466f80d3d683b71c3468_0.geojson""

#Load and save the boundary data as uk_map
uk_map &lt;- geojson_read (url, what = ""sp"")

#pcon18cd is code name for constituency (as we can see when we view uk_map). Use fortify to get this data.

fort_uk_map &lt;- fortify(uk_map, region = ""pcon18cd"")

#MAPPING PETITION DATA

#Join map data to signatures data from constituency using left_join
full_uk_map &lt;- left_join(fort_uk_map, signatures, by = c(""id"" = ""ons_code""))

#Plot-1a: Map of signatures in the whole of UK
ggplot() +
  geom_polygon(data = full_uk_map, aes(x = long, y= lat, group = group, fill = signature_count)) +
  geom_path(color = ""black"", size = 0.1) +theme(legend.position = ""bottom"") +
  theme_void() +
  labs(x = NULL, 
       y = NULL, 
       title = ""Signatories of the UK Coronavirus Lockdown Petition"", 
       subtitle = ""Let's investigate where the signatures come from"", 
       caption = ""Geometries: ONS Open Geography Portal; Data: UK Parliament and Government"",
       fill = ""Signature Count"")][1]
</code></pre>

<p>But, as you can see from the image, the higher signatures have a lighter color. I would like to change it so that the higher number of signatures have a darker color. </p>

<p>So, I tried this code just below the above code and that's where I am facing issues. </p>

<pre><code>#Change color of legend so that higher signature count equals darker color. Use quantile () [Doesn't work]
no_of_classes &lt;- 9

quantiles &lt;- quantile(full_uk_map$signature_count, probs = seq(0, 1, length.out = no_of_classes + 1))

labels &lt;- c()

for(band in 1:length(quantiles)){
  labels &lt;- c(labels, paste0(round(quantiles[band]),"" - "", round(quantiles[band + 1])))
}

full_uk_map$quantiles &lt;- cut(full_uk_map$signature_count, breaks = quantiles, labels = labels,
                             include.lowest = T)

labels &lt;- labels[1:length(labels)-1]

#Plot-1b: Map of signatures in the whole of UK [Doesn't work]

sig_map_by_quantile &lt;- ggplot() +
  geom_polygon(data = full_uk_map, aes(x = long, y = lat, group = group, fill = quantiles)) +
  geom_path(color = ""black"", size = 0.1) +
  scale_fill_brewer(type = 'qual', palette = ""Blues"", guide = ""legend"", name = ""Signature Count"", labels = labels) +
  theme_void +
  theme(legend.position = ""bottom"") +
  labs(x = NULL, 
       y = NULL, 
       title = ""Signatories of the UK Coronavirus Lockdown Petition"", 
       caption = ""Geometries: ONS Open Geography Portal; Data: UK Parliament and Government"")
</code></pre>

<p>When I run the full_uk_map$quantiles, this is the error message I see:</p>

<pre><code>&gt; full_uk_map$quantiles &lt;- cut(full_uk_map$signature_count, breaks = quantiles, labels = labels,
+                              include.lowest = T)
Error in cut.default(full_uk_map$signature_count, breaks = quantiles,  : 
  lengths of 'breaks' and 'labels' differ
</code></pre>

<p>Would anyone be able to help? Much appreciated!</p>
"
60878173,"<p>This is hard to explain but basically I have a very simple dataframe with Counties and Cases</p>

<pre><code>dat &lt;- ""County   Cases
1       Borden   5
2       Bosque   3
3       Bowue    1""
</code></pre>

<p>and I have a large dataframe from <code>TEX &lt;- map_data('county', 'texas')</code>.</p>

<pre><code>&gt; head(TEX)
       long      lat group order region subregion
1 -95.75271 31.53560     1     1  texas  anderson
2 -95.76989 31.55852     1     2  texas  anderson
3 -95.76416 31.58143     1     3  texas  anderson
4 -95.72979 31.58143     1     4  texas  anderson
5 -95.74698 31.61008     1     5  texas  anderson
6 -95.72405 31.63873     1     6  texas  anderson
</code></pre>

<p>What I want to do is check every row and if the subregion is in the dataframe <em>dat</em> then add the corresponding number of cases to a new column in <em>TEX</em> called ""cases"" or add 0 if not.</p>

<p>For example</p>

<pre><code>&gt; head(TEX)
       long      lat group order region subregion cases
1 -95.75271 31.53560     1     1  texas  anderson 0
2 -95.76989 31.55852     1     2  texas  anderson 0
3 -95.76416 31.58143     1     3  texas  anderson 0
4 -95.72979 31.58143     1     4  texas  anderson 0
5 -95.74698 31.61008     1     5  texas  Borden   5
6 -95.72405 31.63873     1     6  texas  Bosque   3
</code></pre>

<p>I tried doing it with this bit of code</p>

<pre><code>for (val in counties$counties) {
     for (vall in TEX$subregion) {
         if (val == vall) TEX$cases = counties$cases
     }
}
</code></pre>

<p>but I get this error</p>

<pre><code>Error in `$&lt;-.data.frame`(`*tmp*`, ""cases"", value = c(5L, 3L, 2L, 1L,  : 
  replacement has 10 rows, data has 4488
</code></pre>

<p>My end goal here is to be able to create a choropleth of texas counties that have COVID cases based on my growing list of Counties and Cases. If you have a better method of doing this than I would be open to that!</p>

<p>Regards!</p>

<p>UPDATE: Ian's solution worked great but it is causing a problem with ggplot and mapping. If I take a section of the dataframe TEX before merge it looks like this</p>

<pre><code>6   -96.81268   28.28693    4   76  texas   aransas
77  -96.80695   28.25828    4   77  texas   aransas
78  -96.82414   28.21817    4   78  texas   aransas
79  -96.87570   28.19525    4   79  texas   aransas
80  -96.91009   28.16660    4   80  texas   aransas
81  -96.94446   28.14942    4   81  texas   aransas
82  -96.94446   28.18379    4   82  texas   aransas
83  -96.92727   28.24109    4   83  texas   aransas
84  -96.92154   28.26974    4   84  texas   aransas
85  -96.94446   28.27547    4   85  texas   aransas
86  -96.99030   28.25255    4   86  texas   aransas
87  -96.98457   28.23536    4   87  texas   aransas
88  -96.97311   28.21817    4   88  texas   aransas
89  -96.96165   28.19525    4   89  texas   aransas
90  -96.97311   28.17233    4   90  texas   aransas
91  -97.00175   28.15515    4   91  texas   aransas
92  -97.03613   28.15515    4   92  texas   aransas
93  -97.04186   28.17233    4   93  texas   aransas
94  -97.03613   28.20098    4   94  texas   aransas
95  -97.05905   28.21817    4   95  texas   aransas
96  -97.07624   28.20671    4   96  texas   aransas
97  -97.11062   28.21817    4   97  texas   aransas
98  -97.12780   28.23536    4   98  texas   aransas
99  -97.12780   28.25255    4   99  texas   aransas
100 -97.11062   28.26401    4   100 texas   aransas
101 -97.01894   28.27547    4   101 texas   aransas
102 -96.80122   28.31557    4   102 texas   aransas
</code></pre>

<p>and after plotting</p>

<pre><code>ggplot(TEX, aes(long,lat, group = group)) + geom_polygon(aes(fill = subregion),color = ""black"") + theme(legend.position = ""none"") + coord_quickmap()
</code></pre>

<p><a href=""https://i.stack.imgur.com/kGoBT.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kGoBT.png"" alt=""what""></a></p>

<p>Looks great! Now when I execute the merge function TEX gets rearranged</p>

<pre><code>72  aransas -97.00175   28.15515    4   91  texas   1
73  aransas -97.04186   28.17233    4   93  texas   1
74  aransas -96.80695   28.25828    4   77  texas   1
75  aransas -96.80122   28.31557    4   102 texas   1
76  aransas -97.03613   28.15515    4   92  texas   1
77  aransas -96.81268   28.28693    4   76  texas   1
78  aransas -97.12780   28.25255    4   99  texas   1
79  aransas -97.11062   28.26401    4   100 texas   1
80  aransas -96.97311   28.17233    4   90  texas   1
81  aransas -97.12780   28.23536    4   98  texas   1
82  aransas -97.07624   28.20671    4   96  texas   1
83  aransas -96.94446   28.27547    4   85  texas   1
84  aransas -97.01894   28.27547    4   101 texas   1
85  aransas -96.96165   28.19525    4   89  texas   1
86  aransas -97.11062   28.21817    4   97  texas   1
87  aransas -96.87570   28.19525    4   79  texas   1
88  aransas -97.03613   28.20098    4   94  texas   1
89  aransas -97.05905   28.21817    4   95  texas   1
90  aransas -96.97311   28.21817    4   88  texas   1
91  aransas -96.92154   28.26974    4   84  texas   1
92  aransas -96.99030   28.25255    4   86  texas   1
93  aransas -96.98457   28.23536    4   87  texas   1
94  aransas -96.82414   28.21817    4   78  texas   1
95  aransas -96.80122   28.31557    4   75  texas   1
96  aransas -96.94446   28.14942    4   81  texas   1
97  aransas -96.91009   28.16660    4   80  texas   1
98  aransas -96.92727   28.24109    4   83  texas   1
99  aransas -96.94446   28.18379    4   82  texas   1
</code></pre>

<p>and now the map looks like this...
<a href=""https://i.stack.imgur.com/kOUNo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/kOUNo.png"" alt=""enter image description here""></a></p>

<p>What can I do to save the original order of TEX? or wait maybe I just need to sort by order....</p>

<p>UPDATE#2</p>

<pre><code>TEX &lt;- TEX[order(TEX$order),]
</code></pre>

<p>solved the problem. I am curious why merge changed the order like that</p>
"
60879216,"<p>Running the following code from Tim Church blog and getting the this error.  <a href=""https://timchurches.github.io/blog/posts/2020-03-18-modelling-the-effects-of-public-health-interventions-on-covid-19-transmission-part-2/"" rel=""nofollow noreferrer"">https://timchurches.github.io/blog/posts/2020-03-18-modelling-the-effects-of-public-health-interventions-on-covid-19-transmission-part-2/</a></p>

<pre><code> Error in { : task 1 failed - ""could not find function ""init_status.icm"""" 
</code></pre>

<p>Error says it can't find the function but I see the function in Environment Functions.</p>

<p><a href=""https://i.stack.imgur.com/If0R8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/If0R8.png"" alt=""enter image description here""></a></p>

<p>If you load the code and run it does it work for you?  I'm trying to get this baseline scenerio to work and than change the parameters to run different assumptions to simulate the spread of the covid-19 in the population.  Can someone please help?</p>

<pre><code>  # Churches (2020, March 18). Tim Churches Health Data Science Blog: Modelling the effects of public health interventions on COVID-19 transmission using R - part 2. Retrieved from https://timchurches.github.io/blog/posts/2020-03-18-modelling-the-effects-of-public-health-interventions-on-covid-19-transmission-part-2/


library(tidyverse)
library(magrittr)
library(lubridate)
library(stringr)
library(tibble)
library(broom)
library(ggplot2)
library(gt)
library(knitr)
library(devtools)
library(DiagrammeR)
library(parallel)
library(foreach)
library(tictoc)
suppressMessages(library(EpiModel))
library(incidence)
library(earlyR)

tic(""Time to complete"")

source_files &lt;- c(""_icm.mod.init.seiqhrf.R"", ""_icm.mod.status.seiqhrf.R"", 
                  ""_icm.mod.vital.seiqhrf.R"", ""_icm.control.seiqhrf.R"", ""_icm.utils.seiqhrf.R"", 
                  ""_icm.saveout.seiqhrf.R"", ""_icm.icm.seiqhrf.R"")

src_path &lt;- paste0(""./_posts/2020-03-18-modelling-the-effects-of-public-health-"", 
                   ""interventions-on-covid-19-transmission-part-2/"")

gist_url &lt;- ""https://gist.github.com/timchurches/92073d0ea75cfbd387f91f7c6e624bd7""

local_source &lt;- FALSE

for (source_file in source_files) {
    if (local_source) {
        source(paste(src_path, source_file, sep = """"))
    } else {
        source_gist(gist_url, filename = source_file)
    }
}

# function to set-up and run the baseline simulations
simulate &lt;- function(# control.icm params
    type = ""SEIQHRF"", 
    nsteps = 366, 
    nsims = 8,
    ncores = 4,
    prog.rand = FALSE,
    rec.rand = FALSE,
    fat.rand = TRUE,
    quar.rand = FALSE,
    hosp.rand = FALSE,
    disch.rand = TRUE,
    infection.FUN = infection.seiqhrf.icm,
    recovery.FUN = progress.seiqhrf.icm,
    departures.FUN = departures.seiqhrf.icm,
    arrivals.FUN = arrivals.icm,
    get_prev.FUN = get_prev.seiqhrf.icm,
    # init.icm params
    s.num = 9997,
    e.num=0,
    i.num = 3,
    q.num=0,
    h.num=0,
    r.num = 0,
    f.num = 0,
    # param.icm params
    inf.prob.e = 0.02, 
    act.rate.e = 10,
    inf.prob.i = 0.05, 
    act.rate.i = 10,
    inf.prob.q = 0.02, 
    act.rate.q = 2.5,                    
    quar.rate = 1/30, 
    hosp.rate = 1/100,
    disch.rate = 1/15,
    prog.rate = 1/10,
    prog.dist.scale = 5,
    prog.dist.shape = 1.5,
    rec.rate = 1/20,
    rec.dist.scale = 35,
    rec.dist.shape = 1.5,
    fat.rate.base = 1/50,
    hosp.cap = 40,
    fat.rate.overcap = 1/25,
    fat.tcoeff = 0.5,
    vital = TRUE,
    a.rate = (10.5/365)/1000, 
    a.prop.e = 0.01,
    a.prop.i = 0.001,
    a.prop.q = 0.01,
    ds.rate = (7/365)/1000, 
    de.rate = (7/365)/1000, 
    di.rate = (7/365)/1000,
    dq.rate = (7/365)/1000,
    dh.rate = (20/365)/1000,
    dr.rate = (7/365)/1000,
    out=""mean""
) {

    control &lt;- control.icm(type = type, 
                           nsteps = nsteps, 
                           nsims = nsims,
                           ncores = ncores,
                           prog.rand = prog.rand,
                           rec.rand = rec.rand,
                           infection.FUN = infection.FUN,
                           recovery.FUN = recovery.FUN,
                           arrivals.FUN = arrivals.FUN,
                           departures.FUN = departures.FUN,
                           get_prev.FUN = get_prev.FUN)

    init &lt;- init.icm(s.num = s.num,
                     e.num = e.num,
                     i.num = i.num,
                     q.num = q.num,
                     h.num = h.num,
                     r.num = r.num,
                     f.num = f.num)

    param &lt;-  param.icm(inf.prob.e = inf.prob.e, 
                        act.rate.e = act.rate.e,
                        inf.prob.i = inf.prob.i, 
                        act.rate.i = act.rate.i,
                        inf.prob.q = inf.prob.q, 
                        act.rate.q = act.rate.q,                    
                        quar.rate = quar.rate,
                        hosp.rate = hosp.rate,
                        disch.rate = disch.rate,
                        prog.rate = prog.rate,
                        prog.dist.scale = prog.dist.scale,
                        prog.dist.shape = prog.dist.shape,
                        rec.rate = rec.rate,
                        rec.dist.scale = rec.dist.scale,
                        rec.dist.shape = rec.dist.shape,
                        fat.rate.base = fat.rate.base,
                        hosp.cap = hosp.cap,
                        fat.rate.overcap = fat.rate.overcap,
                        fat.tcoeff = fat.tcoeff,
                        vital = vital,
                        a.rate = a.rate, 
                        a.prop.e = a.prop.e,
                        a.prop.i = a.prop.i,
                        a.prop.q = a.prop.q,
                        ds.rate = ds.rate, 
                        de.rate = de.rate, 
                        di.rate = di.rate,
                        dq.rate = dq.rate,
                        dh.rate = dh.rate,
                        dr.rate = dr.rate)

    sim &lt;- icm.seiqhrf(param, init, control)
    sim_df &lt;- as.data.frame(sim, out=out)

    return(list(sim=sim, df=sim_df))
}

baseline_sim &lt;- simulate(ncores = 4)
</code></pre>
"
60907116,"<p>I have a the following <a href=""/questions/tagged/model"" class=""post-tag"" title=""show questions tagged &#39;model&#39;"" rel=""tag"">model</a> that I currently run for one state of data.  It's code from this blog:  <a href=""https://blog.ephorie.de/epidemiology-how-contagious-is-novel-coronavirus-2019-ncov"" rel=""nofollow noreferrer"">https://blog.ephorie.de/epidemiology-how-contagious-is-novel-coronavirus-2019-ncov</a></p>

<p>It models future infections based on existing daily COVID-19 infections data.  I have a dataset for all US counties and want to run the same analysis county by county and output key variables into a dataset for each county.  Here is the code I ran for one state.</p>

<pre><code>library(deSolve)
library(tidyverse)

date &lt;- c('2020-03-24','2020-03-25','2020-03-26','2020-03-24','2020-03-25','2020-03-26')
fips &lt;- c(1001,1001,1001,1002,1002,1002)
Infected &lt;- c(1,2,4,4,7,9)
day &lt;- c(1,2,3,1,2,3)
N &lt;- c(55601,55601,55601,2231,2231,2231)

cp &lt;- data.frame(date,fips,Infected,day,N)
</code></pre>

<p>And the <a href=""/questions/tagged/model"" class=""post-tag"" title=""show questions tagged &#39;model&#39;"" rel=""tag"">model</a>:</p>

<pre><code>SIR &lt;- function(time, state, parameters) {
    par &lt;- as.list(c(state, parameters))
    with(par, {
        dS &lt;- -beta/N * I * S
        dI &lt;- beta/N * I * S - gamma * I
        dR &lt;- gamma * I
        list(c(dS, dI, dR))
    })
}

init &lt;- c(S = N-Infected[1], I = Infected[1], R = 0)
RSS &lt;- function(parameters) {
    names(parameters) &lt;- c(""beta"", ""gamma"")
    out &lt;- ode(y = init, times = Day, func = SIR, parms = parameters)
    fit &lt;- out[ , 3]
    sum((Infected - fit)^2)
}

Opt &lt;- optim(c(0.5, 0.5), RSS, method = ""L-BFGS-B"", lower = c(0, 0), upper = c(1, 1))
Opt_par &lt;- setNames(Opt$par, c(""beta"", ""gamma""))
t &lt;- 1:365 # time in days
fit &lt;- data.frame(ode(y = init, times = t, func = SIR, parms = Opt_par))
R0 &lt;- setNames(Opt_par[""beta""] / Opt_par[""gamma""], ""R0"")
infections &lt;- fit[fit$I == max(fit$I), ""I"", drop = FALSE]
deaths &lt;- max(fit$I) * 0.02
</code></pre>

<p>Here is a small sample of dataset I have with county level data:</p>

<pre><code>date &lt;- '2020-03-24','2020-03-25','2020-03-26','2020-03-24','2020-03-25','2020-03-26'
fips &lt;- 1001,1001,1001,1002,1002,1002
Infected &lt;- 1,2,4,4,7,9
day &lt;- 1,2,3,1,2,3
N &lt;- 55601,55601,55601,2231,2231,2231
</code></pre>

<p>I'd like to run the above model for each fips (county code).  As output, I want to have a <a href=""/questions/tagged/dataframe"" class=""post-tag"" title=""show questions tagged &#39;dataframe&#39;"" rel=""tag"">dataframe</a> that includes: 
<code>time_stamp</code>, <code>fips</code>, <code>max(Infected)</code>, <code>max(day)</code>, <code>N</code>, <code>beta</code>, <code>gamma</code>, <code>R0</code>, <code>infections</code>, <code>deaths</code></p>

<p>I'd like a <a href=""/questions/tagged/dplyr"" class=""post-tag"" title=""show questions tagged &#39;dplyr&#39;"" rel=""tag"">dplyr</a> pipe solution and have tried using <code>group_modify()</code> but continually get an error.  Can you help??</p>

<p>Here is what I have and the error I get:</p>

<pre><code>SIR &lt;- function(time, state, parameters) {
    par &lt;- as.list(c(state, parameters))
    with(par, {
        dS &lt;- -beta/N * I * S
        dI &lt;- beta/N * I * S - gamma * I
        dR &lt;- gamma * I
        list(c(dS, dI, dR))
    })
}

RSS &lt;- function(parameters) {
    names(parameters) &lt;- c(""beta"", ""gamma"")
    out &lt;- ode(y = c(S, I, R)
               , times = Day, func = SIR, parms = parameters)
    fit &lt;- out[ , 3]
    sum((Infected - fit)^2)
}

cp &lt;- cp %&gt;%
    group_by(fips) %&gt;%
    mutate(S = N-Infected[1], I = Infected[1], R = 0) %&gt;%
    group_modify(optim(c(0.5, 0.5), RSS, method = ""L-BFGS-B"", lower = c(0, 0), upper = c(1, 1)))
</code></pre>

<p>Error:</p>

<p>Error in ode(y = c(S, I, R), times = Day, func = SIR, parms = parameters) : 
  object 'S' not found </p>
"
60833490,"<p>I have created a flexdashboard with interactive shiny components, including a map. </p>

<pre><code>---
title: ""Coronavirus Dashboard""
output: 
  flexdashboard::flex_dashboard:
    orientation: rows
    vertical_layout: scroll
    theme: readable
runtime: shiny
---

```{r setup, include=FALSE, echo=FALSE, warning=FALSE}
library(flexdashboard)
library(leaflet)
library(rgdal)
library(readr)
library(dplyr)
library(sf)
library(ggplot2)
library(tmap)
</code></pre>

<p>The map displays data sourced from an online .csv and is created using a shape file sourced from a .zip file downloaded and stored locally in a directory named <code>data</code>:</p>

<pre><code>renderLeaflet({
covid_cases &lt;- read_csv(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"")

# .zip downloaded from: https://www.naturalearthdata.com/downloads/50m-cultural-vectors/50m-admin-0-countries-2/
countries &lt;- st_read(""data/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp"", stringsAsFactors=FALSE, quiet=TRUE)
</code></pre>

<p>After some processing of the data to create a single dataframe combining the <code>covid_cases</code> and <code>countries</code> dataframes, the app plots cases per country:</p>

<pre><code>map &lt;- tm_shape(map_and_cases) + tm_polygons(""Percent of Population"", id=""country_name"")
tmap_leaflet(map)
})
</code></pre>

<p>This works wonderfully in RStudio whenever I run the document. However, whenever I attempt to host the dashboard on shinyapps.io, I encounter the following error message:</p>

<p>""Error: An error has occurred. Check your logs or contact the app author for clarification.""</p>

<p>Checking the logs I have that:</p>

<pre><code>2020-03-24T14:41:08.709221+00:00 shinyapps[1985429]: List of 3
2020-03-24T14:41:08.709701+00:00 shinyapps[1985429]:  $ echo   : logi FALSE
2020-03-24T14:41:08.862558+00:00 shinyapps[1985429]: 
  |                                                                       
  |.........................................                        |  64%
2020-03-24T14:41:08.710474+00:00 shinyapps[1985429]:  $ message: logi FALSE
2020-03-24T14:41:08.710489+00:00 shinyapps[1985429]: 
2020-03-24T14:41:08.862596+00:00 shinyapps[1985429]:   ordinary text without R code
2020-03-24T14:41:08.862597+00:00 shinyapps[1985429]: 
2020-03-24T14:41:08.862698+00:00 shinyapps[1985429]: 
  |                                                                       
  |...............................................                  |  73%
2020-03-24T14:41:08.863090+00:00 shinyapps[1985429]: label: unnamed-chunk-3
2020-03-24T14:41:08.876049+00:00 shinyapps[1985429]: 
  |                                                                       
  |.....................................................            |  82%
2020-03-24T14:41:08.876064+00:00 shinyapps[1985429]:   ordinary text without R code
2020-03-24T14:41:08.876064+00:00 shinyapps[1985429]: 
2020-03-24T14:41:08.876168+00:00 shinyapps[1985429]: 
  |                                                                       
  |...........................................................      |  91%
2020-03-24T14:41:08.876547+00:00 shinyapps[1985429]: label: unnamed-chunk-4
2020-03-24T14:41:08.888545+00:00 shinyapps[1985429]:   ordinary text without R code
2020-03-24T14:41:08.889867+00:00 shinyapps[1985429]: output file: /tmp/RtmpJQ4ULR/covid_dashboard.knit.md
2020-03-24T14:41:08.889868+00:00 shinyapps[1985429]: 
2020-03-24T14:41:08.888693+00:00 shinyapps[1985429]: 
2020-03-24T14:41:08.899598+00:00 shinyapps[1985429]: /opt/connect/ext/pandoc2/pandoc +RTS -K512m -RTS /tmp/RtmpJQ4ULR/covid_dashboard.utf8.md --to html4 --from markdown+autolink_bare_uris+tex_math_single_backslash --output /tmp/RtmpJQ4ULR/file1a850267e7e.html --email-obfuscation none --standalone --section-divs --template /opt/R/3.6.1/lib/R/library/flexdashboard/rmarkdown/templates/flex_dashboard/resources/default.html --id-prefix section- --variable 'theme:readable' --mathjax --variable 'mathjax-url:https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML' --lua-filter /opt/R/3.6.1/lib/R/library/rmarkdown/rmd/lua/pagebreak.lua --lua-filter /opt/R/3.6.1/lib/R/library/rmarkdown/rmd/lua/latex-div.lua --include-in-header /tmp/RtmpJQ4ULR/file1a873f90aahtml --highlight-style pygments --include-before-body /tmp/RtmpJQ4ULR/file1a831797393.html --include-after-body /tmp/RtmpJQ4ULR/file1a857f3714c.html 
2020-03-24T14:41:09.009122+00:00 shinyapps[1985429]: 
2020-03-24T14:41:09.009124+00:00 shinyapps[1985429]: Output created: /tmp/RtmpJQ4ULR/file1a850267e7e.html
2020-03-24T14:41:08.888512+00:00 shinyapps[1985429]: 
  |                                                                       
  |.................................................................| 100%
2020-03-24T14:41:08.888546+00:00 shinyapps[1985429]: 
2020-03-24T14:41:09.758017+00:00 shinyapps[1985429]: Parsed with column specification:
2020-03-24T14:41:09.758019+00:00 shinyapps[1985429]: cols(
2020-03-24T14:41:09.758022+00:00 shinyapps[1985429]: )
2020-03-24T14:41:09.758021+00:00 shinyapps[1985429]:   .default = col_double(),
2020-03-24T14:41:09.758021+00:00 shinyapps[1985429]:   `Province/State` = col_character(),
2020-03-24T14:41:09.786949+00:00 shinyapps[1985429]:   `Province/State` = col_character(),
2020-03-24T14:41:09.786947+00:00 shinyapps[1985429]: Parsed with column specification:
2020-03-24T14:41:09.758021+00:00 shinyapps[1985429]:   `Country/Region` = col_character()
2020-03-24T14:41:09.786948+00:00 shinyapps[1985429]: cols(
2020-03-24T14:41:09.758672+00:00 shinyapps[1985429]: See spec(...) for full column specifications.
2020-03-24T14:41:09.786949+00:00 shinyapps[1985429]:   .default = col_double(),
2020-03-24T14:41:09.786949+00:00 shinyapps[1985429]:   `Country/Region` = col_character()
2020-03-24T14:41:09.786949+00:00 shinyapps[1985429]: )
2020-03-24T14:41:09.787306+00:00 shinyapps[1985429]: See spec(...) for full column specifications.
2020-03-24T14:41:09.826539+00:00 shinyapps[1985429]: Warning in CPL_read_ogr(dsn, layer, query, as.character(options), quiet,  :
2020-03-24T14:41:09.826541+00:00 shinyapps[1985429]:   GDAL Error 4: Unable to open /srv/connect/apps/covid_dashboard/data/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shx or /srv/connect/apps/covid_dashboard/data/ne_50m_admin_0_countries/ne_50m_admin_0_countries.SHX.Try --config SHAPE_RESTORE_SHX true to restore or create it
2020-03-24T14:41:09.829788+00:00 shinyapps[1985429]: Warning: Error in : Cannot open ""/srv/connect/apps/covid_dashboard/data/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp""; The source could be corrupt or not supported. See `st_drivers()` for a list of supported formats.
2020-03-24T14:41:09.837934+00:00 shinyapps[1985429]:   114: &lt;Anonymous&gt;
2020-03-24T14:41:09.874249+00:00 shinyapps[1985429]: 
</code></pre>

<p>I have tried the following to resolve this issue, but haven't found a solution:</p>

<ol>
<li>Using different functions to read in the shape file: <code>readOGR()</code> instead of <code>st_read()</code> - No change.</li>
<li>Placing the .Rmd file in the same directory as the shape file, and hosting that - No change.</li>
<li>Altering the code to download, unzip and open the shape file independently - Ran into issues accessing the correct directory.</li>
</ol>

<p>Is there anything else I can try? Is there something simple that I'm missing. Let me know if I should add more detail to the code, or if I can clarify anything. </p>
"
61655078,"<p>I've successfully deployed two applications on shinyapps.io. You can find them here:</p>

<ul>
<li><a href=""https://nicocriscuolo.shinyapps.io/eth_covid19_swiss/"" rel=""nofollow noreferrer"">https://nicocriscuolo.shinyapps.io/eth_covid19_swiss/</a></li>
<li><a href=""https://nicocriscuolo.shinyapps.io/RESBANK/"" rel=""nofollow noreferrer"">https://nicocriscuolo.shinyapps.io/RESBANK/</a></li>
</ul>

<p>The problem is that for some users, once in a while, the application doesn't start, but the frustrating part is that <strong>I got no logs error message</strong>! There's just the grey screen with the popup that says ""Disconnected from server"".</p>

<p>What happens is exactly the same that this user experienced with his Shiny app: <a href=""https://groups.google.com/forum/#!searchin/shinyapps-users/disconnected|sort:date/shinyapps-users/MizC2f8Eaj8/i8G0pbDwBgAJ"" rel=""nofollow noreferrer"">https://groups.google.com/forum/#!searchin/shinyapps-users/disconnected|sort:date/shinyapps-users/MizC2f8Eaj8/i8G0pbDwBgAJ</a></p>

<p>In addition, <strong>the strangest thing is that this error never happens on my machine, and after I try to check what's happening, I successfully connect to my app and then also the users that were experiencing the error can connect</strong>.</p>

<p>I have no clue on how to solve this also because I can't reproduce the error. Any suggestion and idea would be super appreciated! Thanks a lot!</p>

<p>This post is cross-referenced on the RStudio Community at: <a href=""https://community.rstudio.com/t/app-deployed-on-shinyapps-io-gets-disconnected-from-server-just-for-some-users-once-in-a-while/64939"" rel=""nofollow noreferrer"">https://community.rstudio.com/t/app-deployed-on-shinyapps-io-gets-disconnected-from-server-just-for-some-users-once-in-a-while/64939</a></p>
"
60648689,"<p>I want to make a map with the coronavirus infected people by state in US . So the idea is to visualize a map with all  states of US and see a  range of infected people( i.e 500-2000 , etc) in all the map. This should be represented by different shades of one color. The dark shades would be the states with more cases of coronavirus(states).</p>

<p>So this is my code:</p>

<pre><code>install.packages(""sp"")
library(sp)

install.packages(""sf"")
library(sf)

install.packages(""maptools"")
library(maptools)

install.packages(""spdep"")
library(spdep)
install.packages(""rgdal"")
     library(rgdal)
install.packages(""RColorBrewer"")
library(RColorBrewer)
install.packages(""readxl"")
library(readxl)




# 
shp_usa &lt;- readOGR(""USA_States.shp"")
names(shp_usa)                              
shp_usa@data 

# 
infected &lt;- read_excel(""C:/Users/josem/OneDrive/Escritorio/infectedUS/CasesUS.xlsx"") 
names(infected)      


usa_infected &lt;- shp_usa
usa_infected &lt;- merge(x= shp_usa@data,y= infected,by.x= ""STATE_NAME"",by.y=""State"",all.x = TRUE,sort  = FALSE)
summary(usa_infected)



# Map Cases by state USA

    spplot(usa_infected[usa_infected@Cases &gt; 0, ],""Cases.x"", at = quantile(usa_infected$Cases.x, p = c(0, .25, .5, .75, 1), na.rm = TRUE), col.regions = brewer.pal(5, ""Reds""), main = expression(""Cases by State""))
</code></pre>

<p>But I have two problems:
1. I don't know what exactly write in this part of the code : by.x=?   by.y=? in order to do the task.</p>

<pre><code>usa_infected &lt;- merge(shp_usa@data,infected,by.x= ""STATE_NAME"",by.y=""State"",all.x = TRUE,sort  = FALSE)
</code></pre>

<ol start=""2"">
<li>To visualize the map I have this code </li>
</ol>

<pre><code>    spplot(usa_infected[usa_infected@Cases &gt; 0, ],""Cases.y"", at = quantile(usa_infected$Cases.y, p = c(0, .25, .5, .75, 1), na.rm = TRUE), col.regions = brewer.pal(5, ""Reds""), main = expression(""Cases by State""))



</code></pre>

<p>But after run the code I got this message:</p>

<pre><code>Error in `[.data.frame`(usa_infected, usa_infected@Cases &gt; 0, ) : 


 trying to get slot ""Cases"" from an object (class ""data.frame"") that is not an S4 object 
</code></pre>

<p>I have these 2 data sets:
 1- This is from a shp file from USA.</p>

<pre><code> structure(list(STATE_NAME = structure(c(48L, 42L, 51L, 50L, 46L, 
    24L, 38L, 30L, 16L, 22L, 28L, 33L, 39L, 7L, 40L, 31L, 15L, 29L, 
    45L, 5L, 36L, 14L, 9L, 21L, 6L, 18L, 17L, 47L, 26L, 3L, 37L, 
    34L, 43L, 44L, 25L, 11L, 41L, 4L, 19L, 10L, 23L, 12L, 1L, 27L, 
    20L, 35L, 8L, 13L, 2L, 49L, 32L), .Label = c(""Alabama"", ""Alaska"", 
    ""Arizona"", ""Arkansas"", ""California"", ""Colorado"", ""Connecticut"", 
    ""Delaware"", ""District of Columbia"", ""Florida"", ""Georgia"", ""Hawaii"", 
    ""Idaho"", ""Illinois"", ""Indiana"", ""Iowa"", ""Kansas"", ""Kentucky"", 
    ""Louisiana"", ""Maine"", ""Maryland"", ""Massachusetts"", ""Michigan"", 
    ""Minnesota"", ""Mississippi"", ""Missouri"", ""Montana"", ""Nebraska"", 
    ""Nevada"", ""New Hampshire"", ""New Jersey"", ""New Mexico"", ""New York"", 
    ""North Carolina"", ""North Dakota"", ""Ohio"", ""Oklahoma"", ""Oregon"", 
    ""Pennsylvania"", ""Rhode Island"", ""South Carolina"", ""South Dakota"", 
    ""Tennessee"", ""Texas"", ""Utah"", ""Vermont"", ""Virginia"", ""Washington"", 
    ""West Virginia"", ""Wisconsin"", ""Wyoming""), class = ""factor""), 
        STATE_FIPS = structure(c(48L, 42L, 51L, 50L, 46L, 24L, 38L, 
        30L, 16L, 22L, 28L, 33L, 39L, 7L, 40L, 31L, 15L, 29L, 45L, 
        5L, 36L, 14L, 9L, 21L, 6L, 18L, 17L, 47L, 26L, 3L, 37L, 34L, 
        43L, 44L, 25L, 11L, 41L, 4L, 19L, 10L, 23L, 12L, 1L, 27L, 
        20L, 35L, 8L, 13L, 2L, 49L, 32L), .Label = c(""01"", ""02"", 
        ""04"", ""05"", ""06"", ""08"", ""09"", ""10"", ""11"", ""12"", ""13"", ""15"", 
        ""16"", ""17"", ""18"", ""19"", ""20"", ""21"", ""22"", ""23"", ""24"", ""25"", 
        ""26"", ""27"", ""28"", ""29"", ""30"", ""31"", ""32"", ""33"", ""34"", ""35"", 
        ""36"", ""37"", ""38"", ""39"", ""40"", ""41"", ""42"", ""44"", ""45"", ""46"", 
        ""47"", ""48"", ""49"", ""50"", ""51"", ""53"", ""54"", ""55"", ""56""), class = ""factor""), 
        STATE_ABBR = structure(c(48L, 42L, 51L, 49L, 47L, 24L, 38L, 
        31L, 13L, 20L, 30L, 35L, 39L, 7L, 40L, 32L, 16L, 34L, 45L, 
        5L, 36L, 15L, 8L, 21L, 6L, 18L, 17L, 46L, 25L, 4L, 37L, 28L, 
        43L, 44L, 26L, 11L, 41L, 3L, 19L, 10L, 23L, 12L, 2L, 27L, 
        22L, 29L, 9L, 14L, 1L, 50L, 33L), .Label = c(""AK"", ""AL"", 
        ""AR"", ""AZ"", ""CA"", ""CO"", ""CT"", ""DC"", ""DE"", ""FL"", ""GA"", ""HI"", 
        ""IA"", ""ID"", ""IL"", ""IN"", ""KS"", ""KY"", ""LA"", ""MA"", ""MD"", ""ME"", 
        ""MI"", ""MN"", ""MO"", ""MS"", ""MT"", ""NC"", ""ND"", ""NE"", ""NH"", ""NJ"", 
        ""NM"", ""NV"", ""NY"", ""OH"", ""OK"", ""OR"", ""PA"", ""RI"", ""SC"", ""SD"", 
        ""TN"", ""TX"", ""UT"", ""VA"", ""VT"", ""WA"", ""WI"", ""WV"", ""WY""), class = ""factor""), 
        Cases = c(364, 8, 1, 6, 1, 5, 21, 5, 13, 95, 10, 216, 16, 
        3, 5, 15, 6, 7, 2, 157, 4, 19, 10, 9, 33, 8, 1, 9, 1, 6, 
        2, 7, 9, 21, 1, 22, 9, 1, 13, 26, 2, 2, NA, NA, NA, NA, NA, 
        NA, NA, NA, NA)), class = ""data.frame"", row.names = c(NA, 
    -51L))
</code></pre>

<p>2- And this is database for infected :</p>

<pre><code>structure(list(State = c(""Arizona"", ""Wyoming"", ""Arkansas"", ""California"", 
""Colorado"", ""Connecticut"", ""District of Columbia"", ""Florida"", 
""Georgia"", ""Hawaii"", ""Illinois"", ""Indiana"", ""Iowa"", ""Kansas"", 
""Kentucky"", ""Louisiana"", ""Maryland"", ""Massachusetts"", ""Michigan"", 
""Minnesota"", ""Mississippi"", ""Missouri"", ""Nebraska"", ""Nevada"", 
""New Hampshire"", ""New Jersey"", ""New York"", ""North Carolina"", 
""Ohio"", ""Oklahoma"", ""Oregon"", ""Pennsylvania"", ""Rhode Island"", 
""South Carolina"", ""South Dakota"", ""Tennessee"", ""Texas"", ""Utah"", 
""Vermont"", ""Virginia"", ""Washington"", ""Wisconsin""), Cases = c(6, 
1, 1, 157, 33, 3, 10, 26, 22, 2, 19, 6, 13, 1, 8, 13, 9, 95, strong text
2, 5, 1, 1, 10, 7, 5, 15, 216, 7, 4, 2, 21, 16, 5, 9, 8, 9, 21, 
2, 1, 9, 364, 6)), row.names = c(NA, -42L), class = c(""tbl_df"", 
""tbl"", ""data.frame""))
</code></pre>
"
60644364,"<p>I'm trying to create a us map with the total cases of Covid-19 by state. In order to do that task I have this following code:</p>

<pre><code>library(readxl)
library(maptools)
library(spdep)
library(RColorBrewer)

library(sp)
library(sf)

hp_usa_states &lt;- readShapeSpatial(""USA_States.shp"")
names(shp_usa_states)                              
shp_usa_states@data 

infected &lt;- read_excel(""C:/Users/BP2646/Desktop/databaseinfUS/US.xlsx"") 
names(infected)      
</code></pre>

<p>I have problems with this part of the code ""<em>(Error in fix.by(by.x, x) : 'by' must specify a uniquely valid column)</em>""</p>

<pre><code>infected_bystate &lt;- shp_usa_states
    infected_bystate@data &lt;- merge(shp_usa_states@data,infected,by.x= ""Cases"",by.y=""Cases"",all.x = TRUE,sort  = FALSE)
    summary(infected_bystate)
</code></pre>

<p>I have this problem:<br>
<em>Error in fix.by(by.x, x) : 'by' must specify a uniquely valid column</em></p>

<p>I don't know why.
This is my dataset:</p>

<pre><code>structure(list(State = c(""Arizona"", ""California"", ""Colorado"", 
""Connecticut"", ""District of Columbia"", ""Florida"", ""Georgia"", 
""Hawaii"", ""Illinois"", ""Indiana"", ""Iowa"", ""Kansas"", ""Kentucky[384][385]"", 
""Lousiana"", ""Maryland"", ""Massachusetts"", ""Michigan"", ""Minnesota"", 
""Missouri"", ""Nebraska"", ""Nevada"", ""New Hampshire"", ""New Jersey"", 
""New York"", ""North Carolina"", ""Ohio"", ""Oklahoma"", ""Oregon"", ""Pennsylvania"", 
""Rhode Island"", ""South Carolina"", ""Soth Dakota"", ""Tennessee"", 
""Texas"", ""Utah"", ""Vermont"", ""Virginia"", ""Washington"", ""Wisconsin"", 
""Total""), Cases = c(6, 157, 18, 2, 4, 28, 22, 2, 19, 6, 13, 1, 
8, 6, 9, 92, 2, 3, 1, 5, 4, 5, 15, 176, 7, 3, 2, 15, 14, 5, 9, 
5, 7, 21, 2, 1, 9, 275, 3, 976), Recovered = c(1, 6, 0, 0, 0, 
0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 12), Deceased = c(0, 3, 
0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 
0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 24, 0, 31), Remaining = c(5, 
148, 18, 2, 4, 26, 22, 2, 17, 6, 13, 1, 8, 6, 9, 91, 2, 3, 1, 
5, 4, 5, 14, 176, 7, 3, 2, 15, 14, 5, 9, 4, 7, 21, 2, 1, 9, 250, 
2, 933)), row.names = c(NA, -40L), class = c(""tbl_df"", ""tbl"", 
""data.frame""))
</code></pre>

<p>This is the second data frame:</p>

<pre><code>structure(list(STATE_NAME = structure(c(48L, 27L, 20L, 35L, 42L, 
51L, 50L, 13L, 46L, 24L, 38L, 30L, 16L, 22L, 28L, 33L, 39L, 7L, 
40L, 31L, 15L, 29L, 45L, 5L, 36L, 14L, 9L, 8L, 49L, 21L, 6L, 
18L, 17L, 47L, 26L, 3L, 37L, 34L, 43L, 44L, 32L, 1L, 25L, 11L, 
41L, 4L, 19L, 10L, 23L, 12L, 2L), .Label = c(""Alabama"", ""Alaska"", 
""Arizona"", ""Arkansas"", ""California"", ""Colorado"", ""Connecticut"", 
""Delaware"", ""District of Columbia"", ""Florida"", ""Georgia"", ""Hawaii"", 
""Idaho"", ""Illinois"", ""Indiana"", ""Iowa"", ""Kansas"", ""Kentucky"", 
""Louisiana"", ""Maine"", ""Maryland"", ""Massachusetts"", ""Michigan"", 
""Minnesota"", ""Mississippi"", ""Missouri"", ""Montana"", ""Nebraska"", 
""Nevada"", ""New Hampshire"", ""New Jersey"", ""New Mexico"", ""New York"", 
""North Carolina"", ""North Dakota"", ""Ohio"", ""Oklahoma"", ""Oregon"", 
""Pennsylvania"", ""Rhode Island"", ""South Carolina"", ""South Dakota"", 
""Tennessee"", ""Texas"", ""Utah"", ""Vermont"", ""Virginia"", ""Washington"", 
""West Virginia"", ""Wisconsin"", ""Wyoming""), class = ""factor""), 
    STATE_FIPS = structure(c(48L, 27L, 20L, 35L, 42L, 51L, 50L, 
    13L, 46L, 24L, 38L, 30L, 16L, 22L, 28L, 33L, 39L, 7L, 40L, 
    31L, 15L, 29L, 45L, 5L, 36L, 14L, 9L, 8L, 49L, 21L, 6L, 18L, 
    17L, 47L, 26L, 3L, 37L, 34L, 43L, 44L, 32L, 1L, 25L, 11L, 
    41L, 4L, 19L, 10L, 23L, 12L, 2L), .Label = c(""01"", ""02"", 
    ""04"", ""05"", ""06"", ""08"", ""09"", ""10"", ""11"", ""12"", ""13"", ""15"", 
    ""16"", ""17"", ""18"", ""19"", ""20"", ""21"", ""22"", ""23"", ""24"", ""25"", 
    ""26"", ""27"", ""28"", ""29"", ""30"", ""31"", ""32"", ""33"", ""34"", ""35"", 
    ""36"", ""37"", ""38"", ""39"", ""40"", ""41"", ""42"", ""44"", ""45"", ""46"", 
    ""47"", ""48"", ""49"", ""50"", ""51"", ""53"", ""54"", ""55"", ""56""), class = ""factor""), 
    STATE_ABBR = structure(c(48L, 27L, 22L, 29L, 42L, 51L, 49L, 
    14L, 47L, 24L, 38L, 31L, 13L, 20L, 30L, 35L, 39L, 7L, 40L, 
    32L, 16L, 34L, 45L, 5L, 36L, 15L, 8L, 9L, 50L, 21L, 6L, 18L, 
    17L, 46L, 25L, 4L, 37L, 28L, 43L, 44L, 33L, 2L, 26L, 11L, 
    41L, 3L, 19L, 10L, 23L, 12L, 1L), .Label = c(""AK"", ""AL"", 
    ""AR"", ""AZ"", ""CA"", ""CO"", ""CT"", ""DC"", ""DE"", ""FL"", ""GA"", ""HI"", 
    ""IA"", ""ID"", ""IL"", ""IN"", ""KS"", ""KY"", ""LA"", ""MA"", ""MD"", ""ME"", 
    ""MI"", ""MN"", ""MO"", ""MS"", ""MT"", ""NC"", ""ND"", ""NE"", ""NH"", ""NJ"", 
    ""NM"", ""NV"", ""NY"", ""OH"", ""OK"", ""OR"", ""PA"", ""RI"", ""SC"", ""SD"", 
    ""TN"", ""TX"", ""UT"", ""VA"", ""VT"", ""WA"", ""WI"", ""WV"", ""WY""), class = ""factor"")), class = ""data.frame"", row.names = c(""0"", 
""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11"", ""12"", 
""13"", ""14"", ""15"", ""16"", ""17"", ""18"", ""19"", ""20"", ""21"", ""22"", ""23"", 
""24"", ""25"", ""26"", ""27"", ""28"", ""29"", ""30"", ""31"", ""32"", ""33"", ""34"", 
""35"", ""36"", ""37"", ""38"", ""39"", ""40"", ""41"", ""42"", ""43"", ""44"", ""45"", 
""46"", ""47"", ""48"", ""49"", ""50""), data_types = c(""C"", ""C"", ""C""))
</code></pre>
"
60838305,"<p>I have a problem to create a data frame. 
dat1 is perfect, but when I try to create dat2 I get this error message:</p>

<pre><code>Error in .f(.x[[i]], ...) : object 'Dia' not found
</code></pre>

<p>This is my code:</p>

<pre><code>install.packages(""magrittr"") 
library(magrittr)

install.packages(""ggplot2"")
library(ggplot2)

library(cowplot)

install.packages(""usethis"")
library(usethis)

install.packages(""devtools"")
library(devtools)

install.packages(""tidyverse"")
library(tidyverse)

library(dplyr)

devtools::install_github(""larmarange/JLutils"" , force= TRUE)
library(JLutils)


install.packages(""rio"")
library(rio)

dat &lt;- rio::import(""https://github.com/jincio/COVID_19_PERU/blob/master/docs/reportes_minsa.xlsx?raw=true"")

dat1 &lt;- dat %&gt;%
  mutate(pos_new = Positivos-lag(Positivos,default = 0),
         des_new = Descartados-lag(Descartados,default = 0)) %&gt;%
  group_by(Dia) %&gt;%
  summarise(pos_new = sum(pos_new), des_new = sum(des_new)) %&gt;%
  mutate(cum_pos = cumsum(pos_new),
         tot_pruebas = pos_new+des_new)
</code></pre>

<p>Here comes the problem:</p>

<pre><code>dat2 &lt;- dat1 %&gt;%
  mutate(neg_new = tot_pruebas-pos_new) %&gt;%
  dplyr::select(Dia, pos_new, neg_new) %&gt;%
  rename(Positivo = pos_new, Negativo = neg_new) %&gt;%
  gather(res, count, -Dia) %&gt;%
  uncount(count)
</code></pre>

<p>I get this error : Error in .f(.x[[i]], ...) : object 'Dia' not found</p>
"
61071864,"<p>I have problems to load a shp file. This is my code</p>

<pre><code>knitr::opts_chunk$set(echo = FALSE,warning = FALSE, message = FALSE)

install.packages(""geojsonio"")
library(geojsonio)
library(rio)
library(gridExtra)
library(dplyr)
library(kableExtra)
library(JLutils) # devtools::install_github(""larmarange/JLutils"")
library(tidyverse)
library(cowplot)
library(sf)
library(ggrepel)
library(readxl)
library(plyr)
library(cowplot)
library(ggpubr)
install.packages(""directlabels"")
library(directlabels)
data &lt;- rio::import(""https://github.com/jincio/COVID_19_PERU/blob/master/docs/reportes_minsa.xlsx?raw=true"")


knitr::opts_chunk$set(echo = FALSE,warning = FALSE, message = FALSE)

When I run I try to create deparamento , I get this error message:
</code></pre>

<p>Error: Cannot open ""<a href=""https://github.com/jincio/COVID_19_PERU/tree/master/data/departamentos/DEPARTAMENTOS.shp"" rel=""nofollow noreferrer"">https://github.com/jincio/COVID_19_PERU/tree/master/data/departamentos/DEPARTAMENTOS.shp</a>""; The file doesn't seem to exist.
In addition: Warning message:
In CPL_read_ogr(dsn, layer, query, as.character(options), quiet,  :
  GDAL Error 4: Failed to read GeoJSON data</p>

<pre><code>  departamento &lt;- read_sf(""https://github.com/jincio/COVID_19_PERU/tree/master/data/departamentos/DEPARTAMENTOS.shp"") %&gt;%
    select(Departamento = DEPARTAMEN, geometry)
  data2 = import(""reportes_minsa.xlsx"", sheet=2)
  data3 = data2 %&gt;%
    filter(Fecha == max(data2$Fecha)) %&gt;%
    dplyr::rename(Departamento = REGION) %&gt;%
    dplyr::group_by(Departamento) %&gt;%
    dplyr::summarise(casos = sum(Positivos))
  m1 = departamento %&gt;%
    left_join(data3, by=""Departamento"") %&gt;%
    mutate(casos = replace_na(casos,0),
           casos=as.factor(casos),
           label = paste0(Departamento, "": "", casos))%&gt;%
    ggplot() +
    geom_sf(aes(fill = casos), size = 0.05, color = ""grey40"") +
    # colorRampPalette crea una paleta de colores del tamaño de factor(casos) -1
    scale_fill_manual(values = c(""grey80"", colorRampPalette(colors = c(""#FFF5F0"",""#FB6A4A"", ""#67000D""))(length(unique(data3$casos)-1)))) +
    ggrepel::geom_label_repel(
      aes(label = label, geometry = geometry),
      stat = ""sf_coordinates"", 
      size = 2.3,
      min.segment.length = 0
    )+
    scale_x_discrete()+
    theme_bw()+
    theme(legend.position = ""none"",
          axis.title = element_blank())
</code></pre>
"
60965056,"<p>I am trying to add a new column to a data frame but am running into some issue as my train of thought does not seem to work.</p>

<p>My question is based on the countries-aggregated.csv from <a href=""https://github.com/datasets/covid-19/tree/master/data"" rel=""nofollow noreferrer"">this</a> GitHub source.</p>

<p>Taking a look at the head it shows:</p>

<p><a href=""https://i.stack.imgur.com/DXNjA.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DXNjA.jpg"" alt=""enter image description here""></a></p>

<p>What I would like to do is add a new column describing the new Deaths for that day. This is calculated by taking the Deaths of that day minus the Deaths of the day before.</p>

<p>My idea was to create a copy and use that as a reference. Like so:</p>

<pre><code>tb_copy &lt;- tb
tb &lt;- tb %&gt;% mutate(newDeaths = tb_copy %&gt;% filter(tb_copy$Country == tb$Country) %&gt;% filter(tb_copy$Date == tb$Yesterday) %&gt;% pull(Deaths))
</code></pre>

<p>This does not work, not all countries record death toll at a daily basis. For example the Netherlands seems to be in the data set every other day. How could I take this into consideration and make it so it subtracts not the amount of Deaths from the day before but the amount from the last insert for that country?</p>

<p>The error thrown using the above code is:</p>

<pre><code>Error: Column `newDeaths` must be length 175 (the number of rows) or one, not 0
In addition: Warning message:
Incompatible methods (""Ops.factor"", ""==.Date"") for ""==""
</code></pre>

<p><em>Edit: I had to edit the code in this question as I found a mistake in it that made it run without throwing an error.</em></p>
"
60720673,"<p><strong>The problem:</strong></p>

<p>I tried to run a function (ggwithinplot) to plot data in an r package, ggstatsplot. But it took a long time to run this function, and nothing turned out. </p>

<p><a href=""https://i.stack.imgur.com/n1N7a.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/n1N7a.png"" alt=""enter image description here""></a></p>

<p>So I shut down this function while it was running. I tried waiting. It didn't work. So this problem was not a time issue.</p>

<p>After that, I was wondering whether it was due to that I got a large number of data points (N=2000). So I tried another sample that includes 250 data points. And this time, I got this error: ""ERROR: Names must be unique.""</p>

<pre><code>ERROR: Names must be unique. Backtrace: 
1. ggstatsplot::ggwithinstats(...) 
27. vctrs:::validate_unique(names = names) 
28. vctrs:::stop_names_must_be_unique(which(duplicated(names))) 
29. vctrs:::stop_names(...) 
30. vctrs:::stop_vctrs(...)
</code></pre>

<p>And I checked traceback:</p>

<pre><code>33.stop(fallback)
32.signal_abort(cnd)
31.abort(message, class = c(class, ""vctrs_error""), ...)
30.stop_vctrs(message, class = c(class, ""vctrs_error_names""), locations = locations, ...)
29.stop_names(""Names must be unique."", class = ""vctrs_error_names_must_be_unique"", locations = locations)
28.stop_names_must_be_unique(which(duplicated(names)))
27.validate_unique(names = names)
26.vctrs::vec_as_names(names, repair = ""check_unique"")
25.withCallingHandlers(expr, simpleError = function(cnd) { abort(conditionMessage(cnd), parent = cnd) })
24.instrument_base_errors(expr)
23.doTryCatch(return(expr), name, parentenv, handler)
22.tryCatchOne(expr, names, parentenv, handlers[[1L]])
21.tryCatchList(expr, classes, parentenv, handlers)
20.tryCatch(instrument_base_errors(expr), vctrs_error_subscript = function(cnd) { cnd$subscript_action &lt;- subscript_action(type) cnd$subscript_elt &lt;- ""column"" cnd_signal(cnd) ...
19.with_subscript_errors(vctrs::vec_as_names(names, repair = ""check_unique""))
18.rename_impl(NULL, .vars, quo(c(...)), strict = .strict)
17.tidyselect::vars_rename(names(.data), !!!enquos(...))
16.rename.data.frame(.data = ., variable = skim_variable)
15.dplyr::rename(.data = ., variable = skim_variable)
14.function_list[[k]](value)
13.withVisible(function_list[[k]](value))
12.freduce(value, `_function_list`)
11.`_fseq`(`_lhs`)
10.eval(quote(`_fseq`(`_lhs`)), env, env)
9.eval(quote(`_fseq`(`_lhs`)), env, env)
8.withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))
7.dplyr::left_join(x = df_results %&gt;% dplyr::group_modify(.f = ~tibble::as_tibble(skimr::skim(purrr::keep(.x = ., .p = ..f))), keep = FALSE) %&gt;% dplyr::ungroup(x = .), y = dplyr::tally(df_results), by = purrr::map_chr(.x = grouping.vars, .f = rlang::as_string)) %&gt;% dplyr::mutate(.data = ., n = n - n_missing) %&gt;% purrr::set_names(x = ., ...
6.groupedstats::grouped_summary(data = data, grouping.vars = { { x } ...
5.eval(lhs, parent, parent)
4.eval(lhs, parent, parent)
3.groupedstats::grouped_summary(data = data, grouping.vars = { { x } ...
2.mean_labeller(data = data, x = { { x } ...
1.ggwithinstats(data = emotion_rating_dt_50, x = variable, y = Emotion_rating, point.path = FALSE, mean.path = FALSE, effsize.type = ""partial_eta"", p.adjust.method = ""fdr"", ggtheme = theme_classic(), palette = ""Darjeeling2"", package = ""wesanderson"", ggstatsplot.layer = FALSE, xlab = ""Dilemma types""
</code></pre>

<p><strong>What I have tried:</strong></p>

<ol>
<li>I googled about this error. Did not get much helpful information. </li>
<li>I updated r-base and all r packages. Not worked.</li>
<li>I checked whether this problem was specific to ggwithinplot. And I found ggbetweenplot worked well even in the large sample (N=2000).</li>
<li>I checked whether it was due to problems with the input data, which is required to be long-format. I did not find anything dubious.</li>
<li>I checked whether the names of columns in the data frame duplicated. No. So I was really confused about the meaning of ""name must be unique.""</li>
</ol>

<p><strong>reprex</strong></p>

<pre><code>library(""tidyverse"")
library(""ggstatsplot"")
#&gt; Registered S3 methods overwritten by 'broom.mixed':
#&gt;   method         from 
#&gt;   augment.lme    broom
#&gt;   augment.merMod broom
#&gt;   glance.lme     broom
#&gt;   glance.merMod  broom
#&gt;   glance.stanreg broom
#&gt;   tidy.brmsfit   broom
#&gt;   tidy.gamlss    broom
#&gt;   tidy.lme       broom
#&gt;   tidy.merMod    broom
#&gt;   tidy.rjags     broom
#&gt;   tidy.stanfit   broom
#&gt;   tidy.stanreg   broom
#&gt; Registered S3 methods overwritten by 'car':
#&gt;   method                          from
#&gt;   influence.merMod                lme4
#&gt;   cooks.distance.influence.merMod lme4
#&gt;   dfbeta.influence.merMod         lme4
#&gt;   dfbetas.influence.merMod        lme4
library(""bruceR"")
#&gt; 载入需要的程辑包：rio
#&gt; 载入需要的程辑包：data.table
#&gt; 
#&gt; 载入程辑包：'data.table'
#&gt; The following objects are masked from 'package:dplyr':
#&gt; 
#&gt;     between, first, last
#&gt; The following object is masked from 'package:purrr':
#&gt; 
#&gt;     transpose
#&gt; 载入需要的程辑包：psych
#&gt; 
#&gt; 载入程辑包：'psych'
#&gt; The following objects are masked from 'package:ggplot2':
#&gt; 
#&gt;     %+%, alpha
#&gt; 载入需要的程辑包：lubridate
#&gt; 
#&gt; 载入程辑包：'lubridate'
#&gt; The following objects are masked from 'package:data.table':
#&gt; 
#&gt;     hour, isoweek, mday, minute, month, quarter, second, wday, week,
#&gt;     yday, year
#&gt; The following object is masked from 'package:base':
#&gt; 
#&gt;     date
#&gt; 载入需要的程辑包：performance
#&gt; Registered S3 methods overwritten by 'huge':
#&gt;   method    from   
#&gt;   plot.sim  BDgraph
#&gt;   print.sim BDgraph
#&gt; Registered S3 method overwritten by 'GGally':
#&gt;   method from   
#&gt;   +.gg   ggplot2
#&gt; ========================================================
#&gt; BRoadly Useful Collections and Extensions of R functions
#&gt; ========================================================
#&gt; Loaded packages:
#&gt; &lt;U+2714&gt; bruceR (version 0.4.0)
#&gt; &lt;U+2714&gt; rio, dplyr, data.table, psych, stringr, lubridate, performance, ggplot2
#&gt; Update:
#&gt; devtools::install_github(""psychbruce/bruceR"")
#&gt; Citation:
#&gt; Bao, H.-W.-S. (2020). bruceR: Broadly useful collections and extensions of R functions (version 0.4.0). Retrieved from https://github.com/psychbruce/bruceR
data &lt;- import(""E:/Zengxiaoyu/zxy_projcet/!ncov/data/Covid_Q1Q2data_minus200_0316.xlsx"")
#&gt; New names:
#&gt; * hubei -&gt; hubei...1396
data$hubei&lt;-data$hubei...666
data$hubei &lt;- as.factor(data$hubei)
#data frame
emotion_df &lt;- data.frame(data$N1_disself,data$N1_disFAMI,data$N1_disHB,data$hubei)

emotion_df &lt;- as.data.table(emotion_df)

#data preparation for repeated measure

long_emotion_rating_dt&lt;-tidyr::pivot_longer(emotion_df, 1:3,names_to = 'variable', values_to = ""Emotion_rating"")

emotion_rating_dt_50&lt;-subset(long_emotion_rating_dt,data.hubei==""HuBei"")
# to plot
grid::grid.newpage()
ggwithinstats(
  data = emotion_rating_dt_50,
  x = variable, # &gt; 2 groups
  y = Emotion_rating,
  point.path = FALSE,
  mean.path = FALSE,
  effsize.type = 'partial_eta' ,
  p.adjust.method = ""fdr"",
  ggtheme = theme_classic(),
  palette = ""Darjeeling2"",
  package = ""wesanderson"",
  ggstatsplot.layer = FALSE,
  xlab = ""Dilemma types"", 
  ylab = ""Emotion rating(1=appealing,7=appaling)"",
  title = ""Emotion rating for fout types moral dilemmas""
)
#&gt; Note: 95% CI for effect size estimate was computed with 100 bootstrap samples.
#&gt; 
#&gt; Error: Names must be unique.
Created on 2020-03-17 by the reprex package (v0.3.0)
</code></pre>

<p><strong>data farame</strong></p>

<p><a href=""https://i.stack.imgur.com/ITpkB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/ITpkB.png"" alt=""input dataframe""></a></p>

<p><strong>session info</strong></p>

<pre><code>R version 3.6.3 (2020-02-29)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 15063)

Matrix products: default

locale:
[1] LC_COLLATE=Chinese (Simplified)_China.936  LC_CTYPE=Chinese (Simplified)_China.936   
[3] LC_MONETARY=Chinese (Simplified)_China.936 LC_NUMERIC=C                              
[5] LC_TIME=Chinese (Simplified)_China.936    

attached base packages:
[1] splines   stats4    stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] sessioninfo_1.1.1  reprex_0.3.0       reshape_0.8.8      gginnards_0.0.3    VGAM_1.1-2         parameters_0.6.0  
 [7] nnet_7.3-13        openxlsx_4.1.4     summarytools_0.9.6 ggcorrplot_0.1.3   bruceR_0.4.0       performance_0.4.4 
[13] lubridate_1.7.4    psych_1.9.12.31    data.table_1.12.8  rio_0.5.16         ggstatsplot_0.3.1  forcats_0.5.0     
[19] stringr_1.4.0      dplyr_0.8.5        purrr_0.3.3        readr_1.3.1        tidyr_1.0.2        tibble_2.1.3      
[25] ggplot2_3.3.0      tidyverse_1.3.0    drawMap_0.1.0     

loaded via a namespace (and not attached):
  [1] estimability_1.3          GGally_1.4.0              lavaan_0.6-5              coda_0.19-3              
  [5] acepack_1.4.1             knitr_1.28                multcomp_1.4-12           rpart_4.1-15             
  [9] inline_0.3.15             generics_0.0.2            callr_3.4.2               cowplot_1.0.0            
 [13] TH.data_1.0-10            xml2_1.2.5                httpuv_1.5.2              StanHeaders_2.21.0-1     
 [17] assertthat_0.2.1          d3Network_0.5.2.1         WRS2_1.0-0                xfun_0.12                
 [21] hms_0.5.3                 evaluate_0.14             promises_1.1.0            fansi_0.4.1              
 [25] dbplyr_1.4.2              readxl_1.3.1              igraph_1.2.4.2            htmlwidgets_1.5.1        
 [29] DBI_1.1.0                 Rsolnp_1.16               ellipsis_0.3.0            paletteer_1.1.0          
 [33] rcompanion_2.3.25         backports_1.1.5           pbivnorm_0.6.0            insight_0.8.2            
 [37] rapportools_1.0           libcoin_1.0-5             jmvcore_1.2.5             vctrs_0.2.4              
 [41] sjlabelled_1.1.3          abind_1.4-5               withr_2.1.2               pryr_0.1.4               
 [45] metaBMA_0.6.2             checkmate_2.0.0           bdsmatrix_1.3-4           emmeans_1.4.5            
 [49] fdrtool_1.2.15            prettyunits_1.1.1         fastGHQuad_1.0            mnormt_1.5-6             
 [53] cluster_2.1.0             mi_1.0                    crayon_1.3.4              pkgconfig_2.0.3          
 [57] nlme_3.1-145              statsExpressions_0.3.1    palr_0.2.0                pals_1.6                 
 [61] rlang_0.4.5               lifecycle_0.2.0           miniUI_0.1.1.1            groupedstats_0.2.0       
 [65] skimr_2.1                 LaplacesDemon_16.1.4      MatrixModels_0.4-1        sandwich_2.5-1           
 [69] kutils_1.69               EMT_1.1                   modelr_0.1.6              dichromat_2.0-0          
 [73] tcltk_3.6.3               cellranger_1.1.0          matrixStats_0.56.0        broomExtra_2.5.0         
 [77] lmtest_0.9-37             Matrix_1.2-18             regsem_1.5.2              loo_2.2.0                
 [81] mc2d_0.1-18               carData_3.0-3             boot_1.3-24               zoo_1.8-7                
 [85] base64enc_0.1-3           whisker_0.4               processx_3.4.2            png_0.1-7                
 [89] viridisLite_0.3.0         rjson_0.2.20              oompaBase_3.2.9           pander_0.6.3             
 [93] ggExtra_0.9               afex_0.26-0               multcompView_0.1-8        coin_1.3-1               
 [97] arm_1.10-1                jpeg_0.1-8.1              rockchalk_1.8.144         ggsignif_0.6.0           
[101] scales_1.1.0              magrittr_1.5              plyr_1.8.6                compiler_3.6.3           
[105] rstantools_2.0.0          bbmle_1.0.23.1            RColorBrewer_1.1-2        lme4_1.1-21              
[109] cli_2.0.2                 lmerTest_3.1-1            pbapply_1.4-2             ps_1.3.2                 
[113] TMB_1.7.16                Brobdingnag_1.2-6         htmlTable_1.13.3          Formula_1.2-3            
[117] MASS_7.3-51.5             mgcv_1.8-31               tidyselect_1.0.0          stringi_1.4.6            
[121] lisrelToR_0.1.4           sem_3.1-9                 jtools_2.0.2              OpenMx_2.17.3            
[125] latticeExtra_0.6-29       ggrepel_0.8.2             bridgesampling_1.0-0      grid_3.6.3               
[129] tools_3.6.3               parallel_3.6.3            matrixcalc_1.0-3          rstudioapi_0.11          
[133] foreign_0.8-76            gridExtra_2.3             ipmisc_1.2.0              pairwiseComparisons_0.2.5
[137] BDgraph_2.62              digest_0.6.25             shiny_1.4.0.2             nortest_1.0-4            
[141] jmv_1.2.5                 Rcpp_1.0.3                car_3.0-7                 broom_0.5.5              
[145] metafor_2.1-0             ez_4.4-0                  BayesFactor_0.9.12-4.2    metaplus_0.7-11          
[149] later_1.0.0               httr_1.4.1                effectsize_0.2.0          sjstats_0.17.9           
[153] colorspace_1.4-1          rvest_0.3.5               XML_3.99-0.3              fs_1.3.2                 
[157] truncnorm_1.0-8           rematch2_2.1.0            expm_0.999-4              mapproj_1.2.7            
[161] jcolors_0.0.4             MuMIn_1.43.15             xtable_1.8-4              jsonlite_1.6.1           
[165] nloptr_1.2.2.1            corpcor_1.6.9             rstan_2.19.3              glasso_1.11              
[169] zeallot_0.1.0             modeltools_0.2-23         scico_1.1.0               R6_2.4.1                 
[173] Hmisc_4.3-1               broom.mixed_0.2.4         pillar_1.4.3              htmltools_0.4.0          
[177] mime_0.9                  glue_1.3.2                fastmap_1.0.1             minqa_1.2.4              
[181] codetools_0.2-16          maps_3.3.0                pkgbuild_1.0.6            mvtnorm_1.1-0            
[185] lattice_0.20-40           numDeriv_2016.8-1.1       huge_1.3.4                curl_4.3                 
[189] DescTools_0.99.34         gtools_3.8.1              clipr_0.7.0               magick_2.3               
[193] logspline_2.1.15          zip_2.0.4                 survival_3.1-11           rmarkdown_2.1            
[197] qgraph_1.6.5              repr_1.1.0                munsell_0.5.0             semPlot_1.1.2            
[201] sjmisc_2.8.3              haven_2.2.0               reshape2_1.4.3            gtable_0.3.0             
[205] bayestestR_0.5.2     
</code></pre>

<p>Github issue for this problem:</p>

<p><a href=""https://github.com/IndrajeetPatil/ggstatsplot/issues/396"" rel=""nofollow noreferrer"">https://github.com/IndrajeetPatil/ggstatsplot/issues/396</a></p>
"
60969120,"<p>I want to make a animated choropleth map of US counties with the number of confirmed COVID-19 cases over time (yes, yet another coronavirus plot). <a href=""https://drive.google.com/file/d/12IVkIRbqYVFezWhmsahU8G2qtm1xezi-/view?usp=sharing"" rel=""nofollow noreferrer"">Here</a> is a link to a three day selection of the data (suggestions for a more permanent place to host it are welcome). Here is the code that creates the static map  (comment the filter to include all dates):</p>

<pre><code>library(tidyverse)
library(gganimate)
library(ggmap)
library(maps)
library(scales)

p &lt;- part_data %&gt;%
  filter(date == as.Date(""2020-03-30"")) %&gt;%
  ggplot(aes(x = long, y = lat, group = group)) +
  geom_polygon(aes(fill = confirmed_new), color = ""grey70"", size = 0.05) + 
  geom_path(data = state_map, colour = ""black"") +
  coord_map() +
  scale_fill_distiller(trans = ""log10"", direction = 1, palette = ""YlOrRd"", na.value = ""white"", limits = c(1, 1E4), labels = comma)
</code></pre>

<p>Which gives this pretty nice plot:
<a href=""https://i.stack.imgur.com/f0vOD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/f0vOD.png"" alt=""Map plot""></a></p>

<p>But how do I now make an animation that moves through the dates? I tried </p>

<pre><code>p +
  transition_time(date)
</code></pre>

<p>and</p>

<pre><code>p + 
  transition_states(date)
</code></pre>

<p>but in both cases R just seems to freeze, before the rendering progress bar even appears, and after a while I get the error <code>Error: cannot allocate vector of size 128.0 Mb</code>. The problem is that I don't know if I'm even using the correct approach here. In the <code>gganimate</code> documentation I read that the <code>group</code> aesthetic is used to link rows that belong to the same graphic element, in this case county. But <code>group</code> is also used by <code>ggplot</code> itself to make the plot, could that be the issue? Any help is appreciated. Thanks.</p>
"
61048618,"<p>I am attempting to build a <code>nonlinear mixed effects model</code> for COVID-19 data that fits a bell curve to daily case numbers from different countries (random effects being at the country level).</p>

<p>The data table is too large to include in the post but here is the structure of the <a href=""/questions/tagged/dataframe"" class=""post-tag"" title=""show questions tagged &#39;dataframe&#39;"" rel=""tag"">dataframe</a>:</p>

<pre><code>&gt; str(dat)
Classes ‘tbl_df’, ‘tbl’ and 'data.frame':   2642 obs. of  7 variables:
 $ Country.Region: Factor w/ 181 levels ""Afghanistan"",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ date          : Date, format: ""2020-03-24"" ""2020-03-25"" ""2020-03-26"" ""2020-03-27"" ...
 $ day           : num  0 1 2 3 4 5 6 7 8 9 ...
 $ total_cases   : int  74 84 94 110 110 120 170 174 237 273 ...
 $ new_cases     : int  34 10 10 16 0 10 50 4 63 36 ...
 $ total_deaths  : int  1 2 4 4 4 4 4 4 4 6 ...
 $ new_deaths    : int  0 1 2 0 0 0 0 0 0 2 ...
</code></pre>

<p>Attempt to fit the model:</p>

<pre><code>library(nlme)
dat &lt;- readRDS(""dat.rds"")

# Bell curve function defined by three parameters
bellcurve.model &lt;- function(d, mu, var, x) {
  f &lt;- d*exp(-((x - mu)^2) / (2*var))
  return(f)
}

# NLME Model
baseModel &lt;- nlme(new_cases ~ bellcurve.model(d, mu, var, x = day), 
                  data = dat, 
                  fixed = list(d ~ 1, mu ~ 1, var ~ 1),
                  random = d + mu + var ~ 1|Country.Region,
                  start = list(fixed = c(1000, 20, 20)),
                  na.action = na.omit)
</code></pre>

<p>However, this is the resulting error:</p>

<blockquote>
  <p>Error in nlme.formula(new_cases ~ bellcurve.model(d, mu, var, x = day),  : 
    Singularity in backsolve at level 0, block 1</p>
</blockquote>

<p>I have read other StackOverflow posts suggesting that certain covariates may be confounded in the model, but the only covariate I am using here to predict <code>new_cases</code> is <code>day</code>. Any advice on what this means or tips on debugging would be greatly appreciated, especially any advice on how this may be fixed.</p>
"
61450218,"<p>I am currently working with COVID-19 data from Peru and I want to use a Rmisc::multiplot to show the development of positive cases in each region of the country. So I am trying to code a loop to generate 25 plots. Only as a matter of example I am only using 4 variables:</p>

<pre><code>     Fecha    Lima     La Libertad  Madre de Dios
1 2020-04-24   10           2             1
2 2020-04-25   15           4             3
3 2020-04-26   20           8             3
</code></pre>

<p>I generated a vector with the names of the regions:</p>

<pre><code>nombre_regiones &lt;- c(""Lima"", ""La Libertad"", ""Madre de Dios"")
</code></pre>

<p>And I created an empty list to store the 25 plots within:</p>

<pre><code>regiones &lt;- list()
</code></pre>

<p>Then I used this for loop to generate and store each plot in the list ""regiones"":</p>

<pre><code>for (w in seq_along(nombre_regiones)) { 
  nombre &lt;- paste(""r"", w, sep = """")
  assign(nombre, ggplot(data = df, aes_string(x = ""Fecha"", y = nombre_regiones[w])) + geom_line() + geom_point() + scale_x_date(date_labels = ""%d, %m"", date_breaks  =""1 day"") + geom_text(aes_string(label = nombre_regiones[w])))
  regiones[[w]] &lt;- nombre
}
</code></pre>

<p>The loop created <code>r1</code> and stored the plot within but when <code>w = 2</code>, that means <code>nombre_regiones[w]</code> = <code>""La Libertad""</code> I got the next warning:</p>

<pre><code>Error in parse(text = x) : &lt;text&gt;:1:4: unexpected symbol
1: La Libertad
       ^
</code></pre>

<p>Because of that I can't create the second plot and the same thing happens with the third region <code>""Madre de Dios""</code>. I tried different things and look up for similar cases but I didn't have luck. Also <code>regiones[[w]] &lt;- nombre</code> isn't working but that's something I'll look up later. Thanks in advance.</p>
"
61131048,"<p>I have created 8 tibbles from CSV files. Each tibble has a common column, <code>person_id</code>. The values in <code>person_id</code> are integers and I would like them to be factors.</p>

<p>I'm using tidyverse</p>

<p>Import</p>

<pre><code>drugs &lt;- as_tibble(read.csv(""../raw_data/icu_covid_sample/icu_sample_drugs.csv""))
flowsheet_dirty &lt;- as_tibble(read.csv(""../raw_data/icu_covid_sample/icu_sample_flowsheet_dirty.csv""))
measurements_clean &lt;- as_tibble(read.csv(""../raw_data/icu_covid_sample/icu_sample_measurements_clean.csv""))
measurements_dirty &lt;- as_tibble(read.csv(""../raw_data/icu_covid_sample/icu_sample_measurements_dirty.csv""))
procedures_cpt &lt;- as_tibble(read.csv(""../raw_data/icu_covid_sample/icu_sample_procedures_cpt.csv""))
vent_dirty &lt;- as_tibble(read.csv(""../raw_data/icu_covid_sample/icu_sample_vent_dirty.csv""))
visits &lt;- as_tibble(read.csv(""../raw_data/icu_covid_sample/icu_sample_visits.csv""))
person &lt;- as_tibble(read.csv(""../raw_data/icu_covid_sample/sample_icu_person.csv""))
</code></pre>

<p>Create a list</p>

<pre><code>data_list &lt;- list(drugs = drugs, flowsheet_dirty = flowsheet_dirty, measurements_clean = measurements_clean, measurements_dirty = measurements_dirty, procedures_cpt = procedures_cpt, vent_dirty = vent_dirty, visits = visits, person = person)
</code></pre>

<p>Some output:</p>

<pre><code>&gt; summary(data_list)
                   Length Class  Mode
drugs              12     tbl_df list
flowsheet_dirty    38     tbl_df list
measurements_clean 13     tbl_df list
measurements_dirty 13     tbl_df list
procedures_cpt      4     tbl_df list
vent_dirty         12     tbl_df list
visits             18     tbl_df list
person             39     tbl_df list
</code></pre>

<p>Every tibble in the list has a column ""person_id""</p>

<p>ex. drugs$person_id, visits$person_id, etc.</p>

<pre><code>&gt; seq_along(data_list)
[1] 1 2 3 4 5 6 7 8
</code></pre>

<p>I would like to iterate with a for loop to convert every person_id column into factor data, instead of integer. More generally, I want to know how to apply functions to a group of tibbles by having them in a list.</p>

<pre><code>
for (i in seq_along(data_list)) {
  data_list[i]$person_id &lt;- as.factor(data_list[i]$person_id)
}
</code></pre>

<p>Error output: </p>

<pre><code>number of items to replace is not a multiple of replacement lengthnumber of items to replace is not a multiple of replacement lengthnumber of items to replace is not a multiple of replacement lengthnumber of items to replace is not a multiple of replacement lengthnumber of items to replace is not a multiple of replacement lengthnumber of items to replace is not a multiple of replacement lengthnumber of items to replace is not a multiple of replacement lengthnumber of items to replace is not a multiple of replacement length
</code></pre>

<p>One test (has to be done prior to loop error)</p>

<pre><code>data_list$drugs$person_id &lt;- as.factor(data_list$drugs$person_id)

&gt; is.factor(data_list$drugs$person_id)
[1] TRUE
&gt; is.factor(data_list$visit$person_id)
[1] FALSE
</code></pre>

<p>This also doesn't work:</p>

<pre><code>
for (i in seq_along(data_list)) {
  data_list[[i]]$person_id &lt;- as.factor(data_list[[i]]$person_id)
}
</code></pre>

<p>Error:</p>

<pre><code>Unknown or uninitialised column: `person_id`.Error: Assigned data `as.factor(data_list[[i]]$person_id)` must be compatible with existing data.
x Existing data has 6 rows.
x Assigned data has 0 rows.
i Only vectors of size 1 are recycled.
Run `rlang::last_error()` to see where the error occurred.

&gt; rlang::last_error()
&lt;error/tibble_error_assign_incompatible_size&gt;
Assigned data `as.factor(data_list[[i]]$person_id)` must be compatible with existing data.
x Existing data has 6 rows.
x Assigned data has 0 rows.
i Only vectors of size 1 are recycled.
Backtrace:
 1. base::`$&lt;-`(`*tmp*`, ""person_id"", value = structure(integer(0), .Label = character(0), class = ""factor""))
 2. tibble:::`$&lt;-.tbl_df`(`*tmp*`, ""person_id"", value = structure(integer(0), .Label = character(0), class = ""factor""))
 3. tibble:::tbl_subassign(...)
 4. tibble:::vectbl_recycle_rhs(...)
 5. base::tryCatch(...)
 6. base:::tryCatchList(expr, classes, parentenv, handlers)
 7. base:::tryCatchOne(expr, names, parentenv, handlers[[1L]])
 8. value[[3L]](cond)
Run `rlang::last_trace()` to see the full context.

&gt; rlang::last_trace()
&lt;error/tibble_error_assign_incompatible_size&gt;
Assigned data `as.factor(data_list[[i]]$person_id)` must be compatible with existing data.
x Existing data has 6 rows.
x Assigned data has 0 rows.
i Only vectors of size 1 are recycled.
Backtrace:
    x
 1. +-base::`$&lt;-`(`*tmp*`, ""person_id"", value = structure(integer(0), .Label = character(0), class = ""factor""))
 2. \-tibble:::`$&lt;-.tbl_df`(`*tmp*`, ""person_id"", value = structure(integer(0), .Label = character(0), class = ""factor""))
 3.   \-tibble:::tbl_subassign(...)
 4.     \-tibble:::vectbl_recycle_rhs(...)
 5.       \-base::tryCatch(...)
 6.         \-base:::tryCatchList(expr, classes, parentenv, handlers)
 7.           \-base:::tryCatchOne(expr, names, parentenv, handlers[[1L]])
 8.             \-value[[3L]](cond)
&gt;

</code></pre>

<p>So I know that with 8 commands I can convert the person_id columns to integers, but I am having trouble doing it in a loop. Additionally, maybe mutate() could help me, however I would like to be facile with iterations. Additionally, I am not sure that my data_list should be a list. Perhaps it should be a vector or something else. Any help is appreciated.</p>
"
60888219,"<p>I am trying to extract back end data of a chart on the following link - <a href=""https://coronavirus.jhu.edu/map.html"" rel=""nofollow noreferrer"">https://coronavirus.jhu.edu/map.html</a>.</p>

<p>On the right hand corner you will see an yellow bubble chart which plots total number of corona virus cases by country. I need to extract the back end data from chart. I did some online research an came across this website - <a href=""https://onlinejournalismblog.com/2017/05/10/how-to-find-data-behind-chart-map-using-inspector/"" rel=""nofollow noreferrer"">https://onlinejournalismblog.com/2017/05/10/how-to-find-data-behind-chart-map-using-inspector/</a>. It was quite helpful for me and I could get a weblink, which, when I put on my browser I see the back end data in JSON format.</p>

<p>Eg:<a href=""https://services9.arcgis.com/N9p5hsImWXAccRNI/arcgis/rest/services/Nc2JKvYFoAEOFCG5JSI6/FeatureServer/4/query?f=json&amp;where=(Confirmed%3C%3E0)%20AND%20(Country_Region%3D%27Finland%27)&amp;returnGeometry=false&amp;spatialRel=esriSpatialRelIntersects&amp;outFields=OBJECTID%2CConfirmed%2CLast_Update&amp;orderByFields=Last_Update%20asc&amp;outSR=102100&amp;resultOffset=0&amp;resultRecordCount=1000&amp;cacheHint=true"" rel=""nofollow noreferrer"">https://services9.arcgis.com/N9p5hsImWXAccRNI/arcgis/rest/services/Nc2JKvYFoAEOFCG5JSI6/FeatureServer/4/query?f=json&amp;where=(Confirmed%3C%3E0)%20AND%20(Country_Region%3D%27Finland%27)&amp;returnGeometry=false&amp;spatialRel=esriSpatialRelIntersects&amp;outFields=OBJECTID%2CConfirmed%2CLast_Update&amp;orderByFields=Last_Update%20asc&amp;outSR=102100&amp;resultOffset=0&amp;resultRecordCount=1000&amp;cacheHint=true</a> - this is the link for JSON data for Finland.</p>

<p>I tried extracting the data in couple of ways like - </p>

<pre><code>url = ""..above link..""
x &lt;- fromJSON(url)
x &lt;- GET(url)
</code></pre>

<p>Everytime, I received error.</p>

<p>I need to extract the back end data of this chart for all countries.</p>

<p>Thank you for your help in advance.</p>

#

<pre><code># Error I get from 
print(x) 

Response [https://services9.arcgis.com/N9p5hsImWXAccRNI/arcgis/rest/services/Nc2JKvYFoAEOFCG5JSI6/FeatureServer/4/query?f=json&amp;where=(Confirmed%3C%3E0)%20AND%20(Country_Region%3D%27Senegal%27)&amp;returnGeometry=false&amp;spatialRel=esriSpatialRelIntersects&amp;outFields=OBJECTID%2CConfirmed%2CLast_Update&amp;orderByFields=Last_Update%20asc&amp;outSR=102100&amp;resultOffset=0&amp;resultRecordCount=1000&amp;cacheHint=true]
  Date: 2020-03-27 14:15
  Status: 403
  Content-Type: text/html
  Size: 919 B
&lt;!DOCTYPE HTML PUBLIC ""-//W3C//DTD HTML 4.01 Transitional//EN"" ""http://www.w3.org/TR/html4/loose.dtd""&gt;
&lt;HTML&gt;&lt;HEAD&gt;&lt;META HTTP-EQUIV=""Content-Type"" CONTENT=""text/html; charset=iso-8859-1""&gt;
&lt;TITLE&gt;ERROR: The request could not be satisfied&lt;/TITLE&gt;
&lt;/HEAD&gt;&lt;BODY&gt;
&lt;H1&gt;403 ERROR&lt;/H1&gt;
&lt;H2&gt;The request could not be satisfied.&lt;/H2&gt;
&lt;HR noshade size=""1px""&gt;
Request blocked.
We can't connect to the server for this app or website at this time. There might be too much traffic or a config...
&lt;BR clear=""all""&gt;
</code></pre>

#

<pre><code>#str(x) gives me
str(x)

List of 10
 $ url        : chr ""https://services9.arcgis.com/N9p5hsImWXAccRNI/arcgis/rest/services/Nc2JKvYFoAEOFCG5JSI6/FeatureServer/4/query?f""| __truncated__
 $ status_code: int 403
 $ headers    :List of 9
  ..$ server        : chr ""CloudFront""
  ..$ date          : chr ""Fri, 27 Mar 2020 14:15:15 GMT""
  ..$ content-type  : chr ""text/html""
  ..$ content-length: chr ""919""
  ..$ connection    : chr ""keep-alive""
  ..$ x-cache       : chr ""Error from cloudfront""
  ..$ via           : chr ""1.1 7ddf939a79757069f5b9d04b0ce928cf.cloudfront.net (CloudFront)""
  ..$ x-amz-cf-pop  : chr ""BLR50-C1""
  ..$ x-amz-cf-id   : chr ""obYT8TG43RpvXHq8VoWYPnSYLIdSwQgf4tFkP1oshW9xtmEkSj5AJA==""
  ..- attr(*, ""class"")= chr [1:2] ""insensitive"" ""list""
 $ all_headers:List of 1
  ..$ :List of 3
  .. ..$ status : int 403
  .. ..$ version: chr ""HTTP/1.1""
  .. ..$ headers:List of 9
  .. .. ..$ server        : chr ""CloudFront""
  .. .. ..$ date          : chr ""Fri, 27 Mar 2020 14:15:15 GMT""
  .. .. ..$ content-type  : chr ""text/html""
  .. .. ..$ content-length: chr ""919""
  .. .. ..$ connection    : chr ""keep-alive""
  .. .. ..$ x-cache       : chr ""Error from cloudfront""
  .. .. ..$ via           : chr ""1.1 7ddf939a79757069f5b9d04b0ce928cf.cloudfront.net (CloudFront)""
  .. .. ..$ x-amz-cf-pop  : chr ""BLR50-C1""
  .. .. ..$ x-amz-cf-id   : chr ""obYT8TG43RpvXHq8VoWYPnSYLIdSwQgf4tFkP1oshW9xtmEkSj5AJA==""
  .. .. ..- attr(*, ""class"")= chr [1:2] ""insensitive"" ""list""
 $ cookies    :'data.frame':    0 obs. of  7 variables:
  ..$ domain    : logi(0) 
  ..$ flag      : logi(0) 
  ..$ path      : logi(0) 
  ..$ secure    : logi(0) 
  ..$ expiration: 'POSIXct' num(0) 
  ..$ name      : logi(0) 
  ..$ value     : logi(0) 
 $ content    : raw [1:919] 3c 21 44 4f ...
 $ date       : POSIXct[1:1], format: ""2020-03-27 14:15:15""
 $ times      : Named num [1:6] 0 0.000159 0.000164 0.000517 0.004218 ...
  ..- attr(*, ""names"")= chr [1:6] ""redirect"" ""namelookup"" ""connect"" ""pretransfer"" ...
 $ request    :List of 7
  ..$ method    : chr ""GET""
  ..$ url       : chr ""https://services9.arcgis.com/N9p5hsImWXAccRNI/arcgis/rest/services/Nc2JKvYFoAEOFCG5JSI6/FeatureServer/4/query?f""| __truncated__
  ..$ headers   : Named chr ""application/json, text/xml, application/xml, */*""
  .. ..- attr(*, ""names"")= chr ""Accept""
  ..$ fields    : NULL
  ..$ options   :List of 2
  .. ..$ useragent: chr ""libcurl/7.64.1 r-curl/4.3 httr/1.4.1""
  .. ..$ httpget  : logi TRUE
  ..$ auth_token: NULL
  ..$ output    : list()
  .. ..- attr(*, ""class"")= chr [1:2] ""write_memory"" ""write_function""
  ..- attr(*, ""class"")= chr ""request""
 $ handle     :Class 'curl_handle' &lt;externalptr&gt; 
 - attr(*, ""class"")= chr ""response""
</code></pre>
"
60823499,"<p>I am trying to loop through a directory and read all of the files in a list. These files are all from the same github repo found here <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19</a></p>

<pre><code>path = ""~/Documents/Corona_Virus/COVID-19/archived_data/archived_daily_case_updates/""
setwd(path)
file.names&lt;-list.files(path)
archived_DAYS&lt;-lapply(file.names,read.csv,sep="","",header=T)
</code></pre>

<p>goes off without a hitch, but then</p>

<pre><code>path2 = ""~/Documents/Corona_Virus/COVID-19/csse_covid_19_data/csse_covid_19_daily_reports/""
setwd(path2)
daily_file_names&lt;-list.files(path2)
daily_DAYS&lt;-lapply(daily_file_names,read.csv,sep="","")
</code></pre>

<p>throws the error</p>

<p>""Error in read.table(file = file, header = header, sep = sep, quote = quote,  : 
  no lines available in input""</p>

<p>however the types of files in both directories are .csv files that are all structured the same way. I don't see why it's throwing that error as every file has populated data</p>
"
60548604,"<p>Through other SO questions I've found how to get headlines but I don't know where the Google code stores the links.</p>

<p>I'm wanting a 2 column data.frame of the headlines and their corresponding links.</p>

<pre><code>library(rvest)
library(tidyverse)


dat &lt;- read_html(""https://news.google.com/search?q=coronavirus&amp;hl=en-US&amp;gl=US&amp;ceid=US%3Aen"") %&gt;%
  html_nodes('.DY5T1d') %&gt;% #
  html_text()

dat
</code></pre>
"
60877748,"<p>The data repository by Johns Hopkins University in GitHub mutates faster than COVID-19, especially as it pertains to the United States data presentation.</p>

<p>There is an alternative to dowonload these data, accessible as a csv <a href=""https://covidtracking.com/api/states.csv"" rel=""nofollow noreferrer"">here</a>.</p>

<p>However, when I try to access it from within R, I get the following error message:</p>

<pre><code>&gt; require(RCurl)
&gt; require(foreign)
&gt; require(tidyverse) 
&gt; 
&gt; x = getURL(""https://covidtracking.com/api/states.csv"")
Error in function (type, msg, asError = TRUE)  : 
  error:1407742E:SSL routines:SSL23_GET_SERVER_HELLO:tlsv1 alert protocol version
</code></pre>

<p>I have come across a post suggesting using <code>url</code> instead of <code>getURL</code>, which does get the URL, but does not allow me to read the dataset:</p>

<pre><code>&gt; require(RCurl)
&gt; require(foreign)
&gt; require(tidyverse) 
&gt; 
&gt; x = url(""https://covidtracking.com/api/states.csv"")
&gt; corona = read.csv(text = x, sep ="","",header = T)
Error in textConnection(text, encoding = ""UTF-8"") : 
  invalid 'text' argument
</code></pre>
"
60963083,"<p>I am trying to apply the <a href=""https://stackoverflow.com/a/60949275/4089351"">answer to my prior question</a> on plotting with dates in the x axis to the <a href=""https://github.com/nytimes/covid-19-data"" rel=""nofollow noreferrer"">COVID data in the New York Times</a> but I get an error message:</p>

<pre><code>require(RCurl)
require(foreign)
require(tidyverse) 

counties = read.csv(""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"", sep ="","",header = T)

Philadelphia &lt;- counties[counties$county==""Philadelphia"",]
Philadelphia &lt;- droplevels(Philadelphia)
rownames(Philadelphia) &lt;- NULL

with(as.data.frame(Philadelphia),plot(date,cases,xaxt=""n""))

axis.POSIXct(1,at=Philadelphia$date,
             labels=format(Philadelphia$date,""%y-%m-%d""),
             las=2, cex.axis=0.8)
# Error in format.default(structure(as.character(x), names = names(x), dim = dim(x),  : 
# invalid 'trim' argument
</code></pre>

<p>The structure of the data includes already a date format:</p>

<pre><code>&gt; str(Philadelphia)
'data.frame':   21 obs. of  6 variables:
 $ date  : Factor w/ 21 levels ""2020-03-10"",""2020-03-11"",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ county: Factor w/ 1 level ""Philadelphia"": 1 1 1 1 1 1 1 1 1 1 ...
 $ state : Factor w/ 1 level ""Pennsylvania"": 1 1 1 1 1 1 1 1 1 1 ...
 $ fips  : int  42101 42101 42101 42101 42101 42101 42101 42101 42101 42101 ...
 $ cases : int  1 1 1 3 4 8 8 10 17 33 ...
 $ deaths: int  0 0 0 0 0 0 0 0 0 0 ...
</code></pre>

<p>I tried changing the axis call to </p>

<pre><code>axis.Date(1,Philadelphia$date, at=Philadelphia$date,
          labels=format(Philadelphia$date,""%y-%m-%d""),
          las=2, cex.axis=0.8)
</code></pre>

<p>without success.</p>

<p>I wonder if it has to do with the strange horizontal lines in the plot (as opposed to points):</p>

<p><a href=""https://i.stack.imgur.com/j51jo.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/j51jo.png"" alt=""enter image description here""></a></p>
"
60916327,"<p>I am trying to build a shiny app to track details about Covid 19 spread in two countries. I am using <code>shiny</code> to set all content and plotly to include dynamic and interactive graphics. I have figured out some possible solutions to this problem but I am not sure what it is happening. The dataframe I am using is <code>df2</code> whose <code>dput</code> version I include in the final side of this post.</p>

<p>Everything looks fine in the app, with <code>filtered</code> the input for the <code>plotly</code> visualization but in the end when I compile the app I got this error:</p>

<pre><code>Listening on http://127.0.0.1:3082
Warning: Error in : Result must have length , not 0
</code></pre>

<p>This is the code for my app:</p>

<pre><code>#Shiny app design
library(shiny)
library(ggplot2)
library(dplyr)
library(httr)
library(reshape2)
library(tidyr)
library(stringr)
library(plotly)
# Set colors
confirmed_color &lt;- ""purple""
active_color &lt;- ""#1f77b4""
recovered_color &lt;- ""forestgreen""
death_color &lt;- ""red""
#Data put here dput version of df2
df2 &lt;- ...
#App design
#ui design
ui &lt;- fluidPage(titlePanel(""Corona Virus Tracker""),
                sidebarLayout(
                  sidebarPanel(""Choose your country"",
                               uiOutput(""countryOutput"")),
                  mainPanel(plotOutput(""coolplot""))
                ))

#server design
server &lt;- function(input, output) {
  output$countryOutput &lt;- renderUI({
    selectInput(""countryInput"", ""Country"",
                sort(unique(df2$country)),
                selected = ""Albania"")
  })
  filtered &lt;- reactive({

    filtered &lt;- df2 %&gt;%
      filter(country == input$countryInput)
    filtered &lt;- as.data.frame(filtered)
  })

  output$coolplot &lt;- renderPlotly({
    #First plot design
    plotly::plot_ly(data = filtered()) %&gt;%
      plotly::add_trace(
        x = ~Date,
        # y = ~active_cum,
        y = ~confirmed_cum,
        type = ""scatter"",
        mode = ""lines+markers"",
        # name = ""Active"",
        name = ""Confirmed"",
        line = list(color = active_color),
        marker = list(color = active_color)
      ) %&gt;%
      plotly::add_trace(
        x = ~Date,
        y = ~death_cum,
        type = ""scatter"",
        mode = ""lines+markers"",
        name = ""Death"",
        line = list(color = death_color),
        marker = list(color = death_color)
      ) %&gt;%
      plotly::layout(
        title = """",
        yaxis = list(title = ""Cumulative number of cases""),
        xaxis = list(title = ""Date""),
        legend = list(x = 0.1, y = 0.9),
        hovermode = ""compare""
      )


  })
}
shinyApp(ui = ui, server = server)
</code></pre>

<p>The <code>dput</code> version of my data <code>df2</code> is next:</p>

<pre><code>df2 &lt;- structure(list(Date = structure(c(18316, 18317, 18318, 18319, 
18320, 18321, 18322, 18323, 18324, 18325, 18326, 18327, 18328, 
18329, 18330, 18331, 18332, 18333, 18334, 18335, 18336, 18337, 
18338, 18339, 18340, 18341, 18342, 18343, 18344, 18345, 18346, 
18347, 18348, 18330, 18331, 18332, 18333, 18334, 18335, 18336, 
18337, 18338, 18339, 18340, 18341, 18342, 18343, 18344, 18345, 
18346, 18347, 18348), class = ""Date""), confirmed = c(1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L, 5L, 7L, 7L, 
7L, 11L, 16L, 21L, 22L, 22L, 22L, 24L, 24L, 40L, 40L, 74L, 84L, 
94L, 110L, 2L, 10L, 12L, 23L, 33L, 38L, 42L, 51L, 55L, 59L, 64L, 
70L, 76L, 89L, 104L, 123L, 146L, 174L, 186L), deaths = c(0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 2L, 4L, 4L, 
0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 4L, 5L, 
5L, 6L, 8L), recovered = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L, 0L, 0L, 0L, 2L, 2L, 2L, 10L, 17L, 17L, 31L), unrecovered = c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L, 5L, 7L, 
7L, 7L, 11L, 16L, 21L, 22L, 22L, 22L, 24L, 24L, 39L, 39L, 73L, 
82L, 90L, 106L, 2L, 10L, 11L, 22L, 32L, 37L, 41L, 50L, 54L, 57L, 
62L, 68L, 74L, 87L, 100L, 118L, 141L, 168L, 178L), country = structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L), .Label = c(""Afghanistan"", ""Albania""), class = ""factor""), 
    active = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 4L, 4L, 5L, 7L, 7L, 7L, 11L, 16L, 21L, 22L, 22L, 22L, 
    24L, 24L, 39L, 39L, 73L, 82L, 90L, 106L, 2L, 10L, 11L, 22L, 
    32L, 37L, 41L, 50L, 54L, 57L, 62L, 68L, 74L, 87L, 100L, 118L, 
    141L, 168L, 178L), confirmed_cum = c(1L, 2L, 3L, 4L, 5L, 
    6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 17L, 21L, 26L, 33L, 40L, 
    47L, 58L, 74L, 95L, 117L, 139L, 161L, 185L, 209L, 249L, 289L, 
    363L, 447L, 541L, 651L, 2L, 12L, 24L, 47L, 80L, 118L, 160L, 
    211L, 266L, 325L, 389L, 459L, 535L, 624L, 728L, 851L, 997L, 
    1171L, 1357L), death_cum = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
    0L, 0L, 0L, 0L, 0L, 1L, 2L, 3L, 5L, 9L, 13L, 0L, 0L, 1L, 
    2L, 3L, 4L, 5L, 6L, 7L, 9L, 11L, 13L, 15L, 17L, 21L, 26L, 
    31L, 37L, 45L), active_cum = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 
    8L, 9L, 10L, 11L, 12L, 13L, 17L, 21L, 26L, 33L, 40L, 47L, 
    58L, 74L, 95L, 117L, 139L, 161L, 185L, 209L, 248L, 287L, 
    360L, 442L, 532L, 638L, 2L, 12L, 23L, 45L, 77L, 114L, 155L, 
    205L, 259L, 316L, 378L, 446L, 520L, 607L, 707L, 825L, 966L, 
    1134L, 1312L)), row.names = c(NA, 52L), class = ""data.frame"")
</code></pre>

<p>Many thanks for your help!</p>
"
60871209,"<p>I know various forms of this question have been asked before but I haven't been able to find something I can directly apply...</p>

<p>I have a script that reads data in csv format directly from a website.  It has been working fine for a while but suddenly this morning I got an error</p>

<pre><code>Error: No common type for `X1.22.2020` &lt;integer&gt; and `X3.20.2020` &lt;character&gt;.
</code></pre>

<p>Upon review, I found that the source data had switched to using commas as thousands separators <strong><em>SOMETIMES</em></strong>, but not always.</p>

<p>I have found several answers such as in <a href=""https://stackoverflow.com/questions/1523126/how-to-read-data-when-some-numbers-contain-commas-as-thousand-separator"">this</a> thread, but it appears they require you to know which columns contain the offending numbers at the time read.csv reads them in, which I don't.  I ultimately need to hand this off to someone whose job will be to ""hit source"" and not to debug, so I need a fairly foolproof solution.  </p>

<p>Any guidance would be most appreciated.</p>

<p>Here's an MWE:</p>

<pre><code>url &lt;- ""https://static.usafacts.org/public/data/covid-19/covid_confirmed_usafacts.csv""
COV &lt;- read.csv(url, stringsAsFactors = FALSE)
names(COV)[1] &lt;- ""countyFIPS""
Covid &lt;- pivot_longer(COV, cols=starts_with(""X""), 
                      values_to=""cases"",
                      names_to=c(""X"",""date_infected""),
                      names_sep=""X"") %&gt;%
  mutate(infected = as.Date(date_infected, format=""%m.%d.%Y""),
         countyFIPS = str_pad(as.character(countyFIPS), 5, pad=""0""))
</code></pre>
"
61150810,"<p>I'm looking at covid-19 data to calculate estimates for the reproductive number R0.</p>

<pre><code>library(ggplot2)  
library(dplyr)    
library(tidyr)    
library(stringr)  
library(TTR)



# Get COVID cases, available from:
url &lt;- ""https://static.usafacts.org/public/data/covid-19/covid_confirmed_usafacts.csv""

DoubleCOV &lt;- read.csv(url, stringsAsFactors = FALSE)
names(DoubleCOV)[1] &lt;- ""countyFIPS""

DoubleCovid &lt;- pivot_longer(DoubleCOV, cols=starts_with(""X""),
                            values_to=""cases"",
                            names_to=c(""X"",""date_infected""),
                            names_sep=""X"") %&gt;%
  mutate(infected = as.Date(date_infected, format=""%m.%d.%y""),
         countyFIPS = str_pad(as.character(countyFIPS), 5, pad=""0""))

#data is by county, summarise for the state of interest
stateData &lt;- DoubleCovid %&gt;% filter(State == ""AL"") %&gt;% filter(cases != 0) %&gt;%  
  group_by(infected) %&gt;% summarise(sum(cases)) %&gt;% 
  mutate(DaysSince = infected - min(infected))

names(stateData)[2] &lt;- ""cumCases""

#3 day moving average to smooth a little
stateData &lt;- stateData %&gt;% mutate(MA = runMean(cumCases,3))

#calculate doubling rate (DR) and then R0 infectious period/doubling rate 
for(j in 4:nrow(stateData)){
  stateData$DR[j] &lt;- log(2)/log(stateData$MA[j]/stateData$MA[j-1])
  stateData$R0[j] &lt;- 14/stateData$DR[j]
}

CDplot &lt;- stateData %&gt;%
  ggplot(mapping = aes(x = as.numeric(DaysSince), y = R0)) +
  geom_line(color = ""firebrick"")

print(CDplot)
</code></pre>

<p>So in the above the state of interest is Alabama, hence <code>filter(State == ""AL"")</code> and this works.</p>

<p>But if I change the state to ""NY"" I get</p>

<pre><code>Error in `$&lt;-.data.frame`(`*tmp*`, ""DR"", value = c(NA, NA, NA, 0.733907206043719 : 
  replacement has 4 rows, data has 39
</code></pre>

<p><code>head(stateData)</code> yields</p>

<pre><code>infected   cumCases DaysSince    MA
  &lt;date&gt;        &lt;int&gt; &lt;drtn&gt;    &lt;dbl&gt;
1 2020-03-02        1 0 days    NA   
2 2020-03-03        2 1 days    NA   
3 2020-03-04       11 2 days     4.67
4 2020-03-05       23 3 days    12   
5 2020-03-06       25 4 days    19.7 
6 2020-03-07       77 5 days    41.7 
</code></pre>

<p>The moving average values in rows 3 and 4 (12 and 4.67) would yield a doubling rate of 0.734 which aligns with the value in the error message <code>value = c(NA, NA, NA, 0.733907206043719</code> but why does it throw an error after that?</p>

<p>Bonus question: I know loops are frowned upon in R...is there a way to get the moving average and R0 calculation without one?</p>
"
60820794,"<p>I am trying to create an animation using <a href=""https://www.datanovia.com/en/blog/gganimate-how-to-create-plots-with-beautiful-animation-in-r/"" rel=""nofollow noreferrer""><code>gganimate</code></a>:</p>

<pre class=""lang-r prettyprint-override""><code>library(ggplot2)
library(ggthemes)
library(gifski)
library(gganimate)

load(""covid-19-es.Rda"")
casos &lt;- ggplot(data,aes(x=Fecha))+geom_point(aes(y=casos,color=""Casos""))+geom_point(aes(y=salidas,color=""Salidas""))+theme_tufte()+transition_states(Fecha,transition_length=2,state_length=1)+labs(title='Day: {frame_time}')
animate(casos, duration = 5, fps = 20, width =800, height = 600, renderer=gifski_renderer())
anim_save(""casos.png"")
</code></pre>

<p>The data file used is <a href=""https://github.com/JJ/covid-reports/blob/master/covid-19-es.Rda"" rel=""nofollow noreferrer"">here</a>.</p>

<p>Initially I used geom_lines instead of geom_point, but that produced an error saying:</p>

<pre><code>Error in seq.default(range[1], range[2], length.out = nframes) : 
  'from' must be a finite number
</code></pre>

<p>and</p>

<pre><code>Error in transform_path(all_frames, next_state, ease, params$transition_length[i],  : 
  transformr is required to tween paths and lines
</code></pre>

<p>Either it does not like lines, or does not like couples of them. Switched to point, and followed advice in gganimate issues to create a file. However, that produces different kind of errors:</p>

<pre><code>Error: Provided file does not exist
</code></pre>

<p>which I really can't figure out, since I simply didn't provide any file. Trying to save anyway produces</p>

<pre><code>Error: The animation object does not specify a save_animation method
</code></pre>

<p>So I don't really know if I'm doing something wrong, using a deprecated version (or package) or what.</p>

<p>Versions used</p>

<ul>
<li>R 3.6</li>
<li>ggplot 2_3.3.0</li>
<li>gganimate 1.0.5</li>
<li>gifski 0.8.6</li>
</ul>
"
60827140,"<p>As a followup to <a href=""https://stackoverflow.com/questions/60820794/using-gganimate-and-getting-all-kind-of-errors/60821350#60821350"">this question</a>, I tried, as suggested by <a href=""https://stackoverflow.com/questions/60820794/using-gganimate-and-getting-all-kind-of-errors/60821350#comment107609418_60820794"">a comment</a>, to use <code>geom_line</code> and <code>transition_reveal</code>. Since using several <code>geom_line</code> statements seemed to clash with gganimate (giving warnings about using a single element in a group and not rendering anything) I tried to gather everything into a single column and a single ggplot2 statement, here. </p>

<pre><code>library(ggplot2)
library(transformr)
library(gifski)
library(gganimate)
library(tidyr)

load(""covid-19-es.Rda"")
data &lt;- gather(data,Tipo,Cuantos,c(casos,salidas))
my_plot &lt;- ggplot(data,aes(x = Fecha, y = Cuantos, group= Tipo, color=Tipo)) + 
  geom_line() +
  transition_reveal(Fecha) + ease_aes(""linear"")+
  labs(title='Day: {closest_state}')

animate(
  plot = my_plot,
  render = gifski_renderer(),
  height = 600,
  width = 800, 
  duration = 10,
  fps = 20)

anim_save('gifs/casos-salidas-linea.gif')
</code></pre>

<p>The data file used is <a href=""https://github.com/JJ/covid-reports/blob/master/covid-19-es.Rda"" rel=""nofollow noreferrer"">here</a>. I'm getting lots of warning when using animate, but it's finally killed with the unhelpful message (again):</p>

<pre><code>Error: Provided file does not exist
</code></pre>

<p>At the end of the day, what I need is to animate line charts with <code>ggplot2</code>. If there's any other method, it'll be very wellcome </p>

<p>Versions used</p>

<ul>
<li>R 3.6</li>
<li>ggplot 2_3.3.0</li>
<li>gganimate 1.0.5</li>
<li>gifski 0.8.6</li>
</ul>
"
61161465,"<p>I'm using the taskscheduleR package in R Studio to fetch data and keep it updated into a CSV file:</p>

<p>This is my code. It works when sourced manually:</p>

<pre><code>library(tidycovid19)
covid19_dta &lt;- download_merged_data(silent = TRUE, cached = TRUE)
filename &lt;- file.path(""D:\\OneDrive\\Portal Gestão\\Projetos - Documentos\\Covid19\\TaskScheduler"",
                      ""covid19.csv"")
write.csv(covid19_dta, file = filename, row.names = FALSE)
</code></pre>

<p>But when running from the scheduler, I get the error:</p>

<pre><code> Error in file(file, ifelse(append, ""a"", ""w"")) : 
  cannot open the connection
Calls: write.csv -&gt; eval.parent -&gt; eval -&gt; eval -&gt; write.table -&gt; file
In addition: Warning message:
In file(file, ifelse(append, ""a"", ""w"")) :
  cannot open file 'D:\OneDrive\Portal Gestão\Projetos - Documentos\Covid19\TaskScheduler/covid19.csv': No such file or directory
Execution halted
</code></pre>

<p>I've tried this other similar post, escaping the path, and a lot of other stuff, but can't get this runnign. Help, anyone?</p>
"
61423696,"<p>Hi I am a data analyst that recently moved on to looking at some time series analysis for Covid-19 risks. I have a large financial dataset that contains the bank account balance of customers (both Business' and Personal) for the past 5 years. </p>

<p>I am looking to do some time series analysis on this so I split the data into two datasets, Business and personal, I want to see if less money is coming in then before and if I can target specific customers with higher decreases.</p>

<p>I got the month on month percentage change using python and built out a dataset of the month on month percentage changes. The problem here is I noticed many customers have 0 balance for sporadic months throughout the year, this makes the % change -100%/+100% and skews the data significantly.</p>

<p>Does anyone have any advice on dealing with the 0 data in this context and any suggestions on how I can visually represent the data so that it is still representative</p>

<p>Thank you in advance for your help</p>
"
60658821,"<p>I have some sample code wherein I am trying to stream tweets based on covid_19 hashtag. I want to only limit the tweets from certain city or country. E.g California.</p>

<p>Here is my code. I try printing the geolocation but the last line in the code does not actually print the location under study.</p>

<pre><code>from tweepy.streaming import StreamListener
from tweepy import OAuthHandler
from tweepy import Stream
import tweepy as tw
#override tweepy.StreamListener to add logic to on_status
class MyStreamListener(tweepy.StreamListener):

    def on_status(self, status):
        if status.user.location is None:
            pass
        else:
            print(status.user.location)
consumer_key = ''
consumer_secret = ''
access_token = ''
access_token_secret = ''

auth = tw.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_token, access_token_secret)
api = tw.API(auth, wait_on_rate_limit=True)
myStreamListener = MyStreamListener()
myStream = tw.Stream(auth = api.auth, listener=myStreamListener)

region = [-122.481234, 37.714105 ,-122.409798,37.802951 ]

myStream.filter(track=[""Covid_19""], locations= region)
</code></pre>

<p>The last line in the code prints sample locations as </p>

<pre><code>Türkiye
The Netherlands.
United States
Türkiye
Paris, France
España
Florida, USA
El infierno
</code></pre>

<p>I am using tweepy 3.8</p>
"
61564786,"<p>I'm plotting covid-19 data for countries grouped by World Bank regions using pandas and Bokeh.</p>

<pre><code>from bokeh.io import output_file, show
from bokeh.palettes import Spectral5
from bokeh.plotting import figure
from bokeh.transform import factor_cmap

group = data.groupby([""region"", ""CountryName""])

index_cmap = factor_cmap(
    'region_CountryName', 
    palette=Spectral5, 
    factors=sorted(data.region.unique()), 
    end=1
)

p = figure(plot_width=800, plot_height=600, title=""Confirmed cases per 100k people by country"",
           x_range=group, toolbar_location=""left"")

p.vbar(x='region_CountryName', top='ConfirmedPer100k_max', width=1, source=group,
       line_color=""white"", fill_color=index_cmap, )

p.y_range.start = 0
p.xgrid.grid_line_color = None
p.xaxis.major_label_orientation = 3.14159/2
p.xaxis.group_label_orientation = 3.14159/2
p.outline_line_color = None

show(p)
</code></pre>

<p>And I get a 
<img src=""https://i.stack.imgur.com/941XW.png"" alt=""cluttered graph like this one""></p>

<p>I would like to set some sort of initial zoom into the x-axis to get a more manageable image 
<img src=""https://i.stack.imgur.com/H71Uw.png"" alt=""like this one"">, which I got by manually zooming in.</p>

<p>Any suggestions?</p>
"
61440196,"<p>I have read data into pandas data frame as covid_data. The feature ""location"" appears multiple times. I just want to draw one horizantal bargraph in ascending order of the following:
'total_cases' and 'total_deaths' but groupby 'locations' so that each location appears just once in a graph. Code is given below:</p>

<pre><code>total_cases = covid_data.groupby('location')['Total_Cases'].sum()
print('Total number of confirmed COVID in world till date (25th April, 2020):', total_cases)

covid_data['Total_Deaths'] = covid_data['new_deaths']
total_deaths = covid_data.groupby('location')['Total_Deaths'].sum()
print('Total deaths in world due to covid till date (25th April, 2020):', total_deaths)
</code></pre>

<p>Output is as below, I just need barplot. Thanks in advance.</p>

<p>Total number of confirmed COVID in world till date (25th April, 2020): location
Afghanistan    1351
Albania         678
Algeria        3127
Andorra         731
Angola           25
               ... 
Venezuela       318
Vietnam         272
Yemen             1
Zambia           84
Zimbabwe         29
Name: Total_Cases, Length: 206, dtype: int64
Total deaths in world due to covid till date (25th April, 2020): location
Afghanistan     43
Albania         28
Algeria        415
Andorra         40
Angola           2
              ... 
Venezuela       10
Vietnam          0
Yemen            0
Zambia           3
Zimbabwe         4
Name: Total_Deaths, Length: 206, dtype: int64</p>
"
61017533,"<p>I am trying to deploy a Dash app on Heroku. On local system the app is running perfectly. For the app I need to import multiple data files with different extensions - '.csv' / '.txt' / '.html'.</p>

<p>To deploy on Heroku, I have created a Git repository and sourcing the files from there. I am importing them using 'Raw' data path from Git for each of these files.</p>

<p>I have checked the initial logs and have fixed all package related issues in the 'requirements.txt' file</p>

<p>But I am still unable to launch the app. Even after it is deployed successfully.
This is my error log - </p>

<pre><code>2020-04-03T17:20:46.813383+00:00 app[web.1]:     self.reap_workers()
2020-04-03T17:20:46.813419+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 525, in reap_workers
2020-04-03T17:20:46.813868+00:00 app[web.1]:     raise HaltServer(reason, self.WORKER_BOOT_ERROR)
2020-04-03T17:20:46.813892+00:00 app[web.1]: gunicorn.errors.HaltServer: &lt;HaltServer 'Worker failed to boot.' 3&gt;
2020-04-03T17:20:46.913389+00:00 heroku[web.1]: State changed from up to crashed
2020-04-03T17:20:50.000000+00:00 app[api]: Build succeeded
2020-04-03T17:21:02.166696+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covid19-extractor.herokuapp.com request_id=6df7e7c2-1bcc-4390-8873-11f001c2bbf9 fwd=""106.51.31.180"" dyno= connect= service= status=503 bytes= protocol=https
2020-04-03T17:21:02.865422+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=covid19-extractor.herokuapp.com request_id=bf774cd5-fb5f-4627-ab11-137f756ee48f fwd=""106.51.31.180"" dyno= connect= service= status=503 bytes= protocol=https
2020-04-03T17:21:09.553299+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/"" host=covid19-extractor.herokuapp.com request_id=0b7a178d-b477-4caa-bf93-4619f5c9da09 fwd=""106.51.31.180"" dyno= connect= service= status=503 bytes= protocol=https
2020-04-03T17:21:10.223515+00:00 heroku[router]: at=error code=H10 desc=""App crashed"" method=GET path=""/favicon.ico"" host=covid19-extractor.herokuapp.com request_id=235901a2-1ac8-4c02-8e14-2030583dd7fd fwd=""106.51.31.180"" dyno= connect= service= status=503 bytes= protocol=https
2020-04-03T17:28:20.503577+00:00 heroku[web.1]: State changed from crashed to starting
2020-04-03T17:28:32.032154+00:00 app[web.1]: [2020-04-03 17:28:32 +0000] [4] [INFO] Starting gunicorn 20.0.4
2020-04-03T17:28:32.033060+00:00 app[web.1]: [2020-04-03 17:28:32 +0000] [4] [INFO] Listening at: http://0.0.0.0:6703 (4)
2020-04-03T17:28:32.033240+00:00 app[web.1]: [2020-04-03 17:28:32 +0000] [4] [INFO] Using worker: sync
2020-04-03T17:28:32.038216+00:00 app[web.1]: [2020-04-03 17:28:32 +0000] [10] [INFO] Booting worker with pid: 10
2020-04-03T17:28:32.077247+00:00 app[web.1]: [2020-04-03 17:28:32 +0000] [11] [INFO] Booting worker with pid: 11
2020-04-03T17:28:32.764140+00:00 heroku[web.1]: State changed from starting to up
2020-04-03T17:28:33.447784+00:00 app[web.1]: Layout complete..
2020-04-03T17:28:33.481467+00:00 app[web.1]: Layout complete..
2020-04-03T17:28:33.708697+00:00 app[web.1]: Data load complete..
2020-04-03T17:28:33.712337+00:00 app[web.1]: Data load complete..
2020-04-03T17:28:33.741698+00:00 app[web.1]: Creating Layout..
2020-04-03T17:28:33.765243+00:00 app[web.1]: Creating Layout..
2020-04-03T17:28:34.942880+00:00 app[web.1]: [2020-04-03 17:28:34 +0000] [10] [ERROR] Exception in worker process
2020-04-03T17:28:34.942929+00:00 app[web.1]: Traceback (most recent call last):
2020-04-03T17:28:34.942931+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 583, in spawn_worker
2020-04-03T17:28:34.942932+00:00 app[web.1]:     worker.init_process()
2020-04-03T17:28:34.942932+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py"", line 119, in init_process
2020-04-03T17:28:34.942932+00:00 app[web.1]:     self.load_wsgi()
2020-04-03T17:28:34.942933+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py"", line 144, in load_wsgi
2020-04-03T17:28:34.942933+00:00 app[web.1]:     self.wsgi = self.app.wsgi()
2020-04-03T17:28:34.942934+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 67, in wsgi
2020-04-03T17:28:34.942934+00:00 app[web.1]:     self.callable = self.load()
2020-04-03T17:28:34.942935+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 49, in load
2020-04-03T17:28:34.942935+00:00 app[web.1]:     return self.load_wsgiapp()
2020-04-03T17:28:34.942935+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 39, in load_wsgiapp
2020-04-03T17:28:34.942936+00:00 app[web.1]:     return util.import_app(self.app_uri)
2020-04-03T17:28:34.942936+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/util.py"", line 358, in import_app
2020-04-03T17:28:34.942937+00:00 app[web.1]:     mod = importlib.import_module(module)
2020-04-03T17:28:34.942937+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/importlib/__init__.py"", line 126, in import_module
2020-04-03T17:28:34.942938+00:00 app[web.1]:     return _bootstrap._gcd_import(name[level:], package, level)
2020-04-03T17:28:34.942938+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap&gt;"", line 994, in _gcd_import
2020-04-03T17:28:34.942939+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap&gt;"", line 971, in _find_and_load
2020-04-03T17:28:34.942939+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap&gt;"", line 955, in _find_and_load_unlocked
2020-04-03T17:28:34.942940+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap&gt;"", line 665, in _load_unlocked
2020-04-03T17:28:34.942940+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap_external&gt;"", line 678, in exec_module
2020-04-03T17:28:34.942940+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap&gt;"", line 219, in _call_with_frames_removed
2020-04-03T17:28:34.942941+00:00 app[web.1]:   File ""/app/app.py"", line 436, in &lt;module&gt;
2020-04-03T17:28:34.942941+00:00 app[web.1]:     [Input('dd','value')]
2020-04-03T17:28:34.942942+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/dash/dash.py"", line 1319, in callback
2020-04-03T17:28:34.942942+00:00 app[web.1]:     self._validate_callback(output, inputs, state)
2020-04-03T17:28:34.942942+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/dash/dash.py"", line 875, in _validate_callback
2020-04-03T17:28:34.942943+00:00 app[web.1]:     layout = self._cached_layout or self._layout_value()
2020-04-03T17:28:34.942943+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/dash/dash.py"", line 442, in _layout_value
2020-04-03T17:28:34.942944+00:00 app[web.1]:     self._cached_layout = self._layout()
2020-04-03T17:28:34.942944+00:00 app[web.1]:   File ""/app/app.py"", line 255, in serve_layout
2020-04-03T17:28:34.942947+00:00 app[web.1]:     children = [html.Iframe(srcDoc = open(str(data_path) + 'TotalCases.html').read(), width = '100%', height = '400')]
2020-04-03T17:28:34.942955+00:00 app[web.1]: FileNotFoundError: [Errno 2] No such file or directory: 'https://raw.githubusercontent.com/pratik-bose/CoronaTracker/V1/TotalCases.html'
2020-04-03T17:28:34.943015+00:00 app[web.1]: [2020-04-03 17:28:34 +0000] [10] [INFO] Worker exiting (pid: 10)
2020-04-03T17:28:35.028451+00:00 app[web.1]: [2020-04-03 17:28:35 +0000] [11] [ERROR] Exception in worker process
2020-04-03T17:28:35.028454+00:00 app[web.1]: Traceback (most recent call last):
2020-04-03T17:28:35.028455+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/arbiter.py"", line 583, in spawn_worker
2020-04-03T17:28:35.028456+00:00 app[web.1]:     worker.init_process()
2020-04-03T17:28:35.028456+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py"", line 119, in init_process
2020-04-03T17:28:35.028460+00:00 app[web.1]:     self.load_wsgi()
2020-04-03T17:28:35.028460+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/workers/base.py"", line 144, in load_wsgi
2020-04-03T17:28:35.028461+00:00 app[web.1]:     self.wsgi = self.app.wsgi()
2020-04-03T17:28:35.028461+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/base.py"", line 67, in wsgi
2020-04-03T17:28:35.028462+00:00 app[web.1]:     self.callable = self.load()
2020-04-03T17:28:35.028462+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 49, in load
2020-04-03T17:28:35.028463+00:00 app[web.1]:     return self.load_wsgiapp()
2020-04-03T17:28:35.028463+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/app/wsgiapp.py"", line 39, in load_wsgiapp
2020-04-03T17:28:35.028463+00:00 app[web.1]:     return util.import_app(self.app_uri)
2020-04-03T17:28:35.028464+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/gunicorn/util.py"", line 358, in import_app
2020-04-03T17:28:35.028464+00:00 app[web.1]:     mod = importlib.import_module(module)
2020-04-03T17:28:35.028465+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/importlib/__init__.py"", line 126, in import_module
2020-04-03T17:28:35.028465+00:00 app[web.1]:     return _bootstrap._gcd_import(name[level:], package, level)
2020-04-03T17:28:35.028466+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap&gt;"", line 994, in _gcd_import
2020-04-03T17:28:35.028466+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap&gt;"", line 971, in _find_and_load
2020-04-03T17:28:35.028467+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap&gt;"", line 955, in _find_and_load_unlocked
2020-04-03T17:28:35.028467+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap&gt;"", line 665, in _load_unlocked
2020-04-03T17:28:35.028467+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap_external&gt;"", line 678, in exec_module
2020-04-03T17:28:35.028468+00:00 app[web.1]:   File ""&lt;frozen importlib._bootstrap&gt;"", line 219, in _call_with_frames_removed
2020-04-03T17:28:35.028468+00:00 app[web.1]:   File ""/app/app.py"", line 436, in &lt;module&gt;
2020-04-03T17:28:35.028468+00:00 app[web.1]:     [Input('dd','value')]
2020-04-03T17:28:35.028469+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/dash/dash.py"", line 1319, in callback
2020-04-03T17:28:35.028469+00:00 app[web.1]:     self._validate_callback(output, inputs, state)
2020-04-03T17:28:35.028470+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/dash/dash.py"", line 875, in _validate_callback
2020-04-03T17:28:35.028470+00:00 app[web.1]:     layout = self._cached_layout or self._layout_value()
2020-04-03T17:28:35.028471+00:00 app[web.1]:   File ""/app/.heroku/python/lib/python3.6/site-packages/dash/dash.py"", line 442, in _layout_value
2020-04-03T17:28:35.028471+00:00 app[web.1]:     self._cached_layout = self._layout()
2020-04-03T17:28:35.028471+00:00 app[web.1]:   File ""/app/app.py"", line 255, in serve_layout
2020-04-03T17:28:35.028472+00:00 app[web.1]:     children = [html.Iframe(srcDoc = open(str(data_path) + 'TotalCases.html').read(), width = '100%', height = '400')]
2020-04-03T17:28:35.028480+00:00 app[web.1]: FileNotFoundError: [Errno 2] No such file or directory: 'https://raw.githubusercontent.com/pratik-bose/CoronaTracker/V1/TotalCases.html'
2020-04-03T17:28:35.028674+00:00 app[web.1]: [2020-04-03 17:28:35 +0000] [11] [INFO] Worker exiting (pid: 11)
2020-04-03T17:28:35.335859+00:00 app[web.1]: [2020-04-03 17:28:35 +0000] [4] [INFO] Shutting down: Master
2020-04-03T17:28:35.335982+00:00 app[web.1]: [2020-04-03 17:28:35 +0000] [4] [INFO] Reason: Worker failed to boot.
2020-04-03T17:28:35.419048+00:00 heroku[web.1]: State changed from up to crashed

</code></pre>

<p>It seems the 'xxx/TotalCases.html' file could not be found. But it is there at the git repo. Also before this step there are multiple <code>.csv</code> files imported. They seem to work fine using the same path.</p>

#

<p>I think I have narrowed down the problem. Momentarily it feels it is not a Heroku problem, so the heading was misleading and has been updated. Issue at hand is- downloading a file from git using its raw path dosn't work for 'HTML' files. The backend code of the file gets downloaded not the file itself.</p>

<p>How do I download a html file from Git Repo?</p>

<p>Thanks for your help in advance.</p>
"
61162077,"<p>I have two <code>dataframes</code>. I understand the time frame of the two are not exactly equal. one is an effect of the corona versus my operations. and the effect began to show after the outbreak. </p>

<p>Below is the <code>snippet</code> of my code:</p>

<pre class=""lang-py prettyprint-override""><code>plt.figure(figsize=(10,10))
ax = covid19_df[covid19_df.countriesAndTerritories == ""Germany""][""cases""].plot(label=""Reported Cases"")
ax1 = covid19_df[covid19_df.countriesAndTerritories == ""Germany""][""deaths""].plot(label=""Deaths"")
df[""NO OF CAPTURED FARMERS""].plot(label= ""Number of farmers"")
plt.ylabel(""Number of cases"", fontsize=15, labelpad=20)
plt.xlabel(""Dates"", fontsize=15, labelpad=20)
plt.legend()
sns.despine()
</code></pre>

<p>Here is the current plot:</p>

<p><a href=""https://i.stack.imgur.com/nW6Hb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/nW6Hb.png"" alt=""enter image description here""></a></p>

<p>I don't know why the blue line does not show</p>
"
61150345,"<p>I have a CSV containing some COVID-19 data. I am trying to create a table that will display information only about Hawaii. I want the index to be dates, and the columns to be counties in Hawaii. </p>

<pre><code>df_counties = pd.read_csv('us-counties.csv')
df_counties
</code></pre>

<p><a href=""https://i.stack.imgur.com/bzV1D.png"" rel=""nofollow noreferrer"">Code output here</a> </p>
"
61468378,"<p>I am trying to scrape the data contained in a table on <a href=""https://www.bop.gov/coronavirus/"" rel=""nofollow noreferrer"">https://www.bop.gov/coronavirus/</a>. However, when one first visits the page the table is hidden behind a link (<a href=""https://www.bop.gov/coronavirus/#"" rel=""nofollow noreferrer"">https://www.bop.gov/coronavirus/#</a>) that leads to the same page but expands the hidden table on the page. However, I cannot find within this link within the webpage's source code or using selenium in order to expand the table and scrape its data. How can I go about accessing the data in this table using python?</p>
"
60780994,"<p>I have been exploring various COVID-19 datasets and doing analysis.  Below is a 'cleaned' up version of my code.  I've been running in google's Colab, but should work on any machine with the modules available (tested).</p>

<p>Questions upfront:</p>

<ol>
<li><p>How do I create a function of my technique to extract the data as I do below for each country or US state? My technique is denoted below with <strong>My technique</strong></p></li>
<li><p>How do I plot (bubble plot) the data on the geopandas maps? I would like to create a new map for each date.  Then create a movie, but I haven't got that far.</p></li>
</ol>

<p>Import modules</p>

<pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()
#%matplotlib inline
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from IPython import display
from ipywidgets import interact, widgets
from datetime import datetime, timedelta
#from google.colab import files
</code></pre>

<p>Some setup parameters</p>

<pre><code>chartcol='red'
plt.rcParams['figure.figsize'] = [15, 5]
</code></pre>

<p>I am using the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) dataset that is updated nightly (daily?). </p>

<pre><code># Get the data 
#Read Data for Cases, Deaths and Recoveries

ConfirmedCases_raw=pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv')
Deaths_raw=pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Deaths.csv')
Recoveries_raw=pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Recovered.csv')
    plt.rcParams['figure.figsize'] = [15, 5]
</code></pre>

<p>Here I am creating a list of date strings that match the timeseries data column names.
The list ends 'yesterday' because the dataset isn't updated for 'today'.  </p>

<pre><code>#This produces a list of strings that matches the column names in the COVID-10 time series.
# Will use it to extract data to build country and state data later.

today = datetime.now()
today2=date.today()
yesterday = today2 - timedelta(days = 1)
covid_epoch=date(2020, 1, 22) 


delta = yesterday - covid_epoch
timeline=[]
for i in range(delta.days + 1):
    #day = sdate + timedelta(days=i)
    day = covid_epoch + timedelta(days=i)
    timeline.append(day.strftime(""%-m/%-d/%y""))
</code></pre>

<p>Now I use my 'technique' to extract the timeseries data in a way I can use it.  I would like to be able to do this with a function.</p>

<pre><code>#Extracts data from csv file into time column and value column
#Creates a list of values from each time column
#Consider using melt to do this. How?
#Create a function to do this. How?
</code></pre>

<p><strong>My technique:</strong> The block below is what I want to turn into a function</p>

<pre><code>time = [];value = [];country=[];province= []
col_value = list(ConfirmedCases_raw.columns)
for i in timeline:
    time.append(i)
    value.append(ConfirmedCases_raw[i].sum())  
</code></pre>

<p>Create a dataframe for all cases around the world. I fill the dataframe with sum values for all countries for the 'world' dataframe, 'time' and 'value'.</p>

<pre><code>world = pd.DataFrame({'Timeline':time,'Covid-19 impact':value})

#Plot the world data

plt.plot(world['Timeline'],world['Covid-19 impact'])
plt.xticks(rotation=45);

plt.suptitle('World COVID-19 Confirmed Cases', fontsize=20)
plt.xlabel('Date', fontsize=18);
plt.ylabel('Count', fontsize=16);
plt.grid(color='b', ls = '-.', lw = 0.25)
</code></pre>

<p><a href=""https://i.stack.imgur.com/T4uD3.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/T4uD3.png"" alt=""enter image description here""></a>    </p>

<p>Again, do this to create a US dataframe. Filtered Confirmed cases for the United States</p>

<pre><code>us_confirmed_raw=ConfirmedCases_raw[ConfirmedCases_raw['Country/Region']=='US']
</code></pre>

<p>Here is my data extraction block again:</p>

<pre><code>time = [];value = [];country=[];province= []
col_value = list(us_confirmed_raw.columns)
for i in timeline:
    time.append(i)
    value.append(us_confirmed[i].sum())
</code></pre>

<p>And create dataframe and plot US data</p>

<pre><code>us_confirmed = pd.DataFrame({'Timeline':time,'Covid-19 impact':value})
plt.plot(us_confirmed['Timeline'],us_confirmed['Covid-19 impact'])
plt.xticks(rotation=45);
plt.suptitle('USA COVID-19 Confirmed Cases', fontsize=20)
plt.xlabel('Date', fontsize=18);
plt.ylabel('Count', fontsize=16);
plt.grid(color='r', ls = '-.', lw = 0.55) 
</code></pre>

<p><a href=""https://i.stack.imgur.com/h4nuz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/h4nuz.png"" alt=""enter image description here""></a></p>

<p>And again for New Mexico.</p>

<pre><code>nm_confirmed=us_confirmed_raw[us_confirmed_raw['Province/State']=='New Mexico']

time = [];value = [];country=[];province= []
col_value = list(nm_confirmed.columns)
for i in timeline:
    time.append(i)
    value.append(nm_confirmed[i].sum())

nm = pd.DataFrame({'Timeline':time,'Covid-19 impact':value})
plt.plot(nm['Timeline'],nm['Covid-19 impact'],linestyle='--', marker='o')
plt.xticks(rotation=45);
plt.suptitle('New Mexico COVID-19 Confirmed Cases', fontsize=20)
plt.xlabel('Date', fontsize=18);
plt.ylabel('Count', fontsize=16);
plt.grid(color='r', ls = '-.', lw = 0.25)
</code></pre>

<p>your right, maybe too many examples.  </p>

<p>My next issue is creating maps.  Below I am using geopandas to create a map and plot data. </p>

<pre><code>!pip install geopandas;
import geopandas
</code></pre>

<p>put the New Mexico data into a geopandas dataframe:</p>

<pre><code>gdf = geopandas.GeoDataFrame(
    nm_confirmed, geometry=geopandas.points_from_xy(nm_confirmed.Long, nm_confirmed.Lat))
</code></pre>

<p>and plot the location of New Mexico.  I cannot figure out how to plot the COVID-19 data on this map.  </p>

<pre><code># Creates a map of the world
# Show the location of new mexico

world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))

ax = world[world.continent == 'North America'].plot(
    color='white', edgecolor='black')

gdf.plot(ax=ax, color='red')
</code></pre>

<p><a href=""https://i.stack.imgur.com/0fVsf.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/0fVsf.png"" alt=""enter image description here""></a></p>
"
61624663,"<p>I have been working on COVID19 analysis for a dashboard and am using a JSON data source. I have converted the json to dataframe. I was successfully able to line plot cases trajectory for each case using interactive legends. But now, I want to add a slider for the no. of days since 1st case till latest date (1st date - Day 1). I have converted the dataframe to CDSView but there is an bokeh.core.validation.check:E-1024 (CDSVIEW_FILTERS_WITH_CONNECTED): CDSView filters are not compatible with glyphs with connected topology suchs as Line and Patch. I am assuming this is the reason why I am not able to update the data source for the widget. The slider.value will be 'cum_day_count' and the values  plotted will be specific to each state.</p>

<p>I am not able to understand how do I slice the data using CDS. Would appreciate some direction. I hope I have been able to explain the problem correctly. Will be happy to help further if it is unclear. Thank you!</p>

<p>Please find the code below without the slider that I was able to execute:</p>

<pre><code>from scipy.signal import savgol_filter

cases_summary = requests.get('https://api.rootnet.in/covid19-in/stats/history')

json_data = cases_summary.json()
cases_summary=pd.json_normalize(json_data['data'], record_path='regional', meta='day')

cases_summary['loc']=np.where(cases_summary['loc']=='Nagaland#', 'Nagaland', cases_summary['loc'])
cases_summary['loc']=np.where(cases_summary['loc']=='Madhya Pradesh#', 'Madhya Pradesh', cases_summary['loc'])
cases_summary['loc']=np.where(cases_summary['loc']=='Jharkhand#', 'Jharkhand', cases_summary['loc'])

latest_date=cases_summary['day'].max()

cases_summary['newConfirmed']=cases_summary['totalConfirmed'].groupby(cases_summary['loc']).diff(1)

#Calculating the count of days since 1st case
cases_summary['day'] = pd.to_datetime(cases_summary['day'])

cases_summary['cum_day_count']=(cases_summary['day']-cases_summary['day'].min())+timedelta(days=1)

cases_summary['cum_day_count']= cases_summary['cum_day_count'].astype('str').str.strip(' days 00:00:00.000000000')

cases_summary['cum_day_count'] = pd.to_numeric(cases_summary['cum_day_count'])


#Cases Trajectory - Statewise

#Creating a Dataframe of Statewise smoothened NewConfirmed column to convert it to a CDS and then to CDSView

newConfirmed=cases_summary.groupby(['loc','day'])['newConfirmed'].sum()
cases=pd.DataFrame({'newConfirmed': newConfirmed, 'totalConfirmed':cases_summary.groupby(['loc','day'])['totalConfirmed'].sum()})\
    .reset_index()

cases_new_final= pd.DataFrame()
for i in cases['loc'].unique():
    if len(cases[cases['loc']==i])&lt;3:
        continue
    else:
        def window_size(length):
            if ((length // 2) % 2 == 1):
                return length // 2
            else:
                return (length // 2) + 1
        cases_new=DataFrame({'loc':i,'yhat':savgol_filter(cases[cases['loc']==i]['newConfirmed'], window_size(len(cases[cases['loc']==i])), 3), 'day': cases[cases['loc']==i]['day'], 'newConfirmed': cases[cases['loc']==i]['newConfirmed'], 'totalConfirmed': cases[cases['loc']==i]['totalConfirmed']})
        cases_new_final=cases_new_final.append(cases_new)

cases_new_final['day'] = cases_new_final['day'].astype('str')

#Plotting lines for each state

a = figure(plot_width=1200, plot_height=600,  sizing_mode=""scale_both"", name=""All cases - Statewise"")
a.title.text='New Confirmed Case Trends'
a.title.align='center'
a.title.text_font_size='17px'
a.xaxis.axis_label = 'Total Confirmed Cases'
a.yaxis.axis_label = 'New Confirmed Cases'

legend_it=[]

source=ColumnDataSource(data=cases_new_final)

for i, color in zip(range(len(cases_new_final['loc'].unique())),itertools.cycle(Dark2_8)):

    view=CDSView(source=source,
    filters=[GroupFilter(column_name='loc', group=cases_new_final['loc'].unique()[i])])


    renderer_yhat = a.line('totalConfirmed',
                           'yhat', line_width=2,  alpha=1,
                           muted_alpha=0.1, source=source, view=view, color=color)

#The second plot is same but is going to stay muted. Only the renderer_yhat, upon click of the legend, will bolden to alpha=1 so, the view can be differentiated from the rest of the states

    renderer_yhat_bold = a.line('totalConfirmed',
                           'yhat', line_width=2,  alpha=1,
                           muted_alpha=0.1, source=source, view=view, color=color)
    renderer_yhat.visible = False
    renderer_yhat_bold.muted = True
    legend_it.append((cases_new_final['loc'].unique()[i], [renderer_yhat]))

legend1=Legend(items=legend_it[0:16], location=(10,21), click_policy='hide', title=""Click on States to Switch ON/OFF"", title_text_font_style = ""bold"")
legend2=Legend(items=legend_it[16:33], location=(10,0), click_policy='hide', title=""Click on States to Switch ON/OFF"", title_text_font_style = ""bold"")
a.add_layout(legend1,'right')
a.add_layout(legend2,'right')

citation = Label(x=0, y=0, x_units='screen', y_units='screen',
                 text='Last Updated : {}'.format(latest_date), render_mode='css', text_font_size='12px')

a.add_layout(citation, 'above')

hover = HoverTool(line_policy='next')
hover.tooltips = [('Date', '@day'),
                  ('Total Confirmed', '@totalConfirmed{0000}'),
                  ('New Confirmed', '@newConfirmed{0000}'),
                  ('State', '@loc')
]
a.add_tools(hover)

citation = Label(x=-50, y=-15, x_units='screen', y_units='screen',
                 text='The data has been smoothened using Savitzky-Golay filter with a polynomial of 3rd degree. This chart helps understand the trajectory of case growth for each state and understand the impact of lockdown and containment efforts by administration and frontline warriors.', render_mode='css', text_font_size='14px', text_align='left')

a.add_layout(citation, 'below')

tab = Panel(child=a, title=""Case Trends - Statewise"")
tabs= Tabs(tabs=[tab])

curdoc().add_root(tabs) ```


</code></pre>
"
61426632,"<p>How can we remove first and last row in pandas <code>dataframe</code> using <code>iloc</code> method in one-Step something like <code>[[0:, :-1]]</code> , However if i only need to get the first and last row via <code>iloc</code> as below.</p>

<h2>DataFrame:</h2>

<pre><code>import pandas as pd
import numpy as np
import requests

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('expand_frame_repr', True)

header={""User-Agent"":""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36"", ""X-Requested-With"":""XMLHttpRequest""}
url = 'https://www.worldometers.info/coronavirus/'
r = requests.get(url, headers=header)

#read second table in url
df = pd.read_html(r.text)[1].iloc[[0, -1]]
#replace nan to zero
df = df[['Country,Other', 'TotalCases', 'NewCases', 'TotalDeaths', 'NewDeaths', 'TotalRecovered', 'ActiveCases', 'Serious,Critical']].replace(np.nan, ""0"")
print(df)
</code></pre>

<h2>Output:</h2>

<p>Below i can get the first and last which i need to remove.</p>

<pre><code>    Country,Other  TotalCases  NewCases  TotalDeaths NewDeaths  TotalRecovered  ActiveCases  Serious,Critical
0           World     2828826  +105,825     197099.0    +6,182        798371.0      1833356           58531.0
213        Total:     2828826  +105,825     197099.0    +6,182        798371.0      1833356           58531.0
</code></pre>

<p>However, I can remove the last row as <code>df = pd.read_html(r.text)[1].iloc[:-1]</code> , however there are other ways which i know as of now like below but those are again in  two steps.</p>

<pre><code>df.drop(df.tail(1).index,inplace=True)
df.drop(df.head(1).index,inplace=True)
</code></pre>
"
61540583,"<p>I'm trying to parse coronavirus pandemic data from <code>wikipedia</code> site with <code>pandas</code> with <code>request</code> module to ftech the data and converting it to dataframe which works for me.  This essentially contains the MultiIndex dataFrame which i have trimmed using <code>droplevel</code> at the column levels, also there are some duplicate Columns eg: <code>Locations</code> and one of which only contains <code>NaN</code> which later i've dropped using <code>duplicated()</code> method.</p>

<p>However, I see at the end of the dataFrame output, there are some rows <code>eg:</code> at Index level <code>128</code> and <code>129</code> which are not necessary to have, how to remove them?</p>

<p>I beleive there will be better way to do it entirely diffrent way!</p>

<h2>Pandas Dataframe code:</h2>

<pre><code>from __future__ import print_function
from signal import signal, SIGPIPE, SIG_DFL
signal(SIGPIPE,SIG_DFL)

import pandas as pd
import requests

pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
pd.set_option('expand_frame_repr', True)

header = {""User-Agent"":""Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36"",""X-Requested-With"":""XMLHttpRequest""}

url = 'https://en.wikipedia.org/wiki/Template:2019%E2%80%9320_coronavirus_pandemic_data'

r = requests.get(url, headers=header)

df = pd.read_html(r.text)[0]
df.columns = df.columns.droplevel(1)
df.rename(columns={'Locations[a]': 'Locations',  'Recov.[d]': 'Recovered', 'Deaths[c]': 'Deaths', 'Cases[b]': 'Cases'}, inplace=True)
df = df[['Locations','Cases','Deaths','Recovered']]
df = df.loc[:,~df.columns.duplicated(""last"")]
# df['Locations'] = df['Locations'].str.replace(r""\[.*\]"", """") &lt;-- remove links from `Location` column whch are `[]`    
print(df)
</code></pre>

<h2>Output result from above code:</h2>

<pre><code>                                             Locations                                              Cases                                             Deaths                                          Recovered
0                                     United States[e]                                            1095645                                              63746                                             132544
1                                                Spain                                             213435                                              24543                                             112050
2                                                Italy                                             205463                                              27967                                              75945
3                                    United Kingdom[f]                                             171253                                              26771                                                  —
4                                           Germany[g]                                             163009                                               6623                                             117734
5                                            France[h]                                             129581                                              24376                                              49476
6                                               Turkey                                             120204                                               3174                                              48886
7                                            Russia[i]                                             114431                                               1169                                              13220
8                                                 Iran                                              94640                                               6028                                              75103
9                                               Brazil                                              87187                                               6006                                              35935
10                                            China[j]                                              82874                                               4633                                              77642
11                                              Canada                                              53236                                               3184                                              21423
12                                          Belgium[k]                                              49032                                               7703                                              11892
13                                      Netherlands[l]                                              39316                                               4795                                                  —
14                                                Peru                                              36976                                               1051                                              10405
15                                               India                                              35043                                               1147                                               8889
16                                         Switzerland                                              29586                                               1423                                              23400
17                                            Portugal                                              25045                                                989                                               1519
18                                             Ecuador                                              24934                                                900                                               1806
19                                        Saudi Arabia                                              22753                                                162                                               3163
20                                              Sweden                                              21092                                               2586                                               1005
21                                             Ireland                                              20612                                               1232                                              13386
22                                              Mexico                                              19224                                               1859                                              11423
23                                           Singapore                                              17101                                                 15                                               1188
24                                            Pakistan                                              16817                                                385                                               4315
25                                            Chile[m]                                              16023                                                227                                               8580
26                                           Israel[n]                                              16004                                                223                                               8758
27                                             Austria                                              15450                                                584                                              12907
28                                            Japan[o]                                              14516                                                466                                               3466
29                                             Belarus                                              14027                                                 89                                               2386
30                                               Qatar                                              13409                                                 10                                               1372
31                                              Poland                                              12877                                                644                                               3236
32                                United Arab Emirates                                              12481                                                105                                               2429
33                                             Romania                                              12240                                                695                                               4017
34                                          Ukraine[p]                                              10861                                                272                                               1413
35                                         South Korea                                              10774                                                248                                               9072
36                                           Indonesia                                              10551                                                800                                               1591
37                                          Denmark[q]                                               9158                                                452                                               6546
38                                           Serbia[r]                                               9009                                                179                                               1343
39                                         Philippines                                               8772                                                579                                               1084
40                                          Bangladesh                                               8238                                                170                                                174
41                                           Norway[s]                                               7759                                                210                                                  —
42                                      Czech Republic                                               7689                                                237                                               3314
43                                  Dominican Republic                                               6972                                                301                                               1301
44                                        Australia[t]                                               6762                                                 92                                               5720
45                                              Panama                                               6532                                                188                                                576
46                                            Colombia                                               6211                                                278                                               1411
47                                            Malaysia                                               6071                                                103                                               4210
48                                        South Africa                                               5647                                                103                                               2073
49                                            Egypt[u]                                               5537                                                392                                               1381
50                                          Finland[v]                                               4995                                                211                                               3000
51                                          Morocco[w]                                               4423                                                170                                                984
52                                        Argentina[x]                                               4415                                                218                                               1299
53                                              Kuwait                                               4024                                                 26                                               1539
54                                             Algeria                                               4006                                                450                                               1779
55                                          Moldova[y]                                               3897                                                119                                               1182
56                                          Luxembourg                                               3784                                                 90                                               3213
57                                          Kazakhstan                                               3551                                                 25                                                879
58                                             Bahrain                                               3040                                                  8                                               1500
59                                            Thailand                                               2960                                                 54                                               2719
60                                             Hungary                                               2863                                                323                                                609
61                                              Greece                                               2591                                                140                                               1374
62                                                Oman                                               2348                                                 11                                                495
63                                         Afghanistan                                               2335                                                 68                                                310
64                                             Armenia                                               2148                                                 33                                                977
65                                                Iraq                                               2085                                                 93                                               1375
66                                             Croatia                                               2076                                                 69                                               1348
67                                               Ghana                                               2076                                                 17                                                212
68                                          Uzbekistan                                               2046                                                  9                                               1134
69                                             Nigeria                                               1932                                                 58                                                319
70                                            Cameroon                                               1832                                                 61                                                934
71                                       Azerbaijan[z]                                               1804                                                 24                                               1325
72                                             Iceland                                               1797                                                 10                                               1670
73                                Bosnia &amp; Herzegovina                                               1757                                                 69                                                727
74                                             Estonia                                               1694                                                 52                                                249
75                                            Bulgaria                                               1541                                                 66                                                276
76                                         Puerto Rico                                               1539                                                 92                                                  —
77                                            Cuba[aa]                                               1501                                                 61                                                681
78                                              Guinea                                               1495                                                  7                                                329
79                                     North Macedonia                                               1465                                                 77                                                738
80                                            Slovenia                                               1429                                                 91                                                233
81                                            Slovakia                                               1403                                                 23                                                558
82                                           Lithuania                                               1399                                                 45                                                594
83                                         Ivory Coast                                               1275                                                 14                                                574
84                                             Bolivia                                               1167                                                 62                                                132
85                                     New Zealand[ab]                                               1132                                                 19                                               1252
86                          USS Theodore Roosevelt[ac]                                               1102                                                  1                                                 53
87                                            Djibouti                                               1089                                                  2                                                642
88                               Charles de Gaulle[ad]                                               1081                                                  0                                                  0
89                                           Hong Kong                                               1038                                                  4                                                846
90                                             Tunisia                                                994                                                 41                                                305
91                                             Senegal                                                933                                                  9                                                334
92                                              Latvia                                                870                                                 16                                                348
93                                          Cyprus[ae]                                                850                                                 15                                                148
94                                            Honduras                                                804                                                 75                                                112
---------------------------- Stripped output ------------------
226                                            Comoros                                                  1                                                  0                                                  0
227                            Saint Pierre &amp; Miquelon                                                  1                                                  0                                                  0
228  As of 1 May 2020 (UTC) · History of cases: Chi...  As of 1 May 2020 (UTC) · History of cases: Chi...  As of 1 May 2020 (UTC) · History of cases: Chi...  As of 1 May 2020 (UTC) · History of cases: Chi...
229  Notes ^ Countries, territories, and internatio...  Notes ^ Countries, territories, and internatio...  Notes ^ Countries, territories, and internatio...  Notes ^ Countries, territories, and internatio...
</code></pre>

<p>Any help will be much appreciated.</p>
"
61594875,"<p>I'm trying to clean a COVID-19 dataset. There is a column called ""Entity"" which contains the names of the countries. A sample is shown below</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""false"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;table border=""1"" class=""dataframe""&gt;
  &lt;thead&gt;
    &lt;tr style=""text-align: right;""&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Entity&lt;/th&gt;
      &lt;th&gt;Date&lt;/th&gt;
      &lt;th&gt;Source URL&lt;/th&gt;
      &lt;th&gt;Source label&lt;/th&gt;
      &lt;th&gt;Cumulative total&lt;/th&gt;
      &lt;th&gt;Daily change in cumulative total&lt;/th&gt;
      &lt;th&gt;Cumulative total per thousand&lt;/th&gt;
      &lt;th&gt;Daily change in cumulative total per thousand&lt;/th&gt;
      &lt;th&gt;3-day rolling mean daily change&lt;/th&gt;
      &lt;th&gt;3-day rolling mean daily change per thousand&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;Argentina - tests performed&lt;/td&gt;
      &lt;td&gt;2020-04-08&lt;/td&gt;
      &lt;td&gt;https://www.argentina.gob.ar/sites/default/fil...&lt;/td&gt;
      &lt;td&gt;Government of Argentina&lt;/td&gt;
      &lt;td&gt;13330&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;0.295&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;Argentina - tests performed&lt;/td&gt;
      &lt;td&gt;2020-04-09&lt;/td&gt;
      &lt;td&gt;https://www.argentina.gob.ar/sites/default/fil...&lt;/td&gt;
      &lt;td&gt;Government of Argentina&lt;/td&gt;
      &lt;td&gt;14850&lt;/td&gt;
      &lt;td&gt;1520.0&lt;/td&gt;
      &lt;td&gt;0.329&lt;/td&gt;
      &lt;td&gt;0.034&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;Argentina - tests performed&lt;/td&gt;
      &lt;td&gt;2020-04-10&lt;/td&gt;
      &lt;td&gt;https://www.argentina.gob.ar/sites/default/fil...&lt;/td&gt;
      &lt;td&gt;Government of Argentina&lt;/td&gt;
      &lt;td&gt;16379&lt;/td&gt;
      &lt;td&gt;1529.0&lt;/td&gt;
      &lt;td&gt;0.362&lt;/td&gt;
      &lt;td&gt;0.034&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;Argentina - tests performed&lt;/td&gt;
      &lt;td&gt;2020-04-11&lt;/td&gt;
      &lt;td&gt;https://www.argentina.gob.ar/sites/default/fil...&lt;/td&gt;
      &lt;td&gt;Government of Argentina&lt;/td&gt;
      &lt;td&gt;18027&lt;/td&gt;
      &lt;td&gt;1648.0&lt;/td&gt;
      &lt;td&gt;0.399&lt;/td&gt;
      &lt;td&gt;0.036&lt;/td&gt;
      &lt;td&gt;1565.667&lt;/td&gt;
      &lt;td&gt;0.035&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;Argentina - tests performed&lt;/td&gt;
      &lt;td&gt;2020-04-13&lt;/td&gt;
      &lt;td&gt;https://www.argentina.gob.ar/sites/default/fil...&lt;/td&gt;
      &lt;td&gt;Government of Argentina&lt;/td&gt;
      &lt;td&gt;19758&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;0.437&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</code></pre>
</div>
</div>
</p>

<p>In the column ""Entity"", there are extra words like ""- tests performed"" and I need to remove them so that I can merge them with the shapefile and visualize using Bokeh. Is there any way to just to remove the extra words? </p>
"
60578312,"<p>For a college project I work with the Johns Hopkins Coronavirus COVID-19 dataset: <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19</a>. What I am trying is to make the dataset simpler. Here is my dataset now:</p>

<pre><code>        Country         Date        Confirmed   Deaths  Recovered
2600    Mainland China  2020-02-28  410.0       7.0     257.0
2601    Iran            2020-02-28  388.0       34.0    73.0
2602    Mainland China  2020-02-28  337.0       3.0     279.0
2603    Mainland China  2020-02-28  318.0       6.0     277.0
2604    Mainland China  2020-02-28  296.0       1.0     235.0
...     ...             ...         ...         ...     ...
2695    US              2020-02-25  1.0         0.0     1.0
2696    US              2020-02-24  0.0         0.0     0.0
2697    US              2020-02-24  0.0         0.0     0.0
2698    US              2020-02-24  0.0         0.0     0.0
2699    Mainland China  2020-02-29  66337.0     2727.0  28993.0
</code></pre>

<p>I want to summarize all the Confirmed, Deaths and Recovered values if the values in the Country and Date columns are the same.</p>

<p>So for instance, in the rows 2600, 2602, 2603, 2604 the values in the columns Country and Date match so I want to combine these rows and summarize the Confirmed, Deaths and Recovered columns separately. Which should give the following row:</p>

<pre><code> 2600    Mainland China  2020-02-28  1361.0       17.0     1048.0
</code></pre>

<p>What I have so far:</p>

<pre><code>duplicateRowsDF = df[df.duplicated(['Country', 'Date'])]
duplicateRowsDF
</code></pre>

<p>Hope somebody can help me out, preferably with, but not limited to, Pandas. Thanks in advance.</p>
"
61198304,"<p>I have a pandas DataFrame (df2) that has columns of <code>Country/Region</code>, <code>Date</code>, <code>NewConfirmed</code>. I want to use the countries listed under its column of <code>Country/Region</code> and look about their data on another pandas DataFrame (df1) that has more rows. I tried the <code>merge</code> function but when I looked into the output csv file, various new columns where added with <code>_x</code> and <code>_y</code> concatenated on the previous columns' name like <code>Date_x</code> and `Date_y'.</p>

<p>I just want to get the list of the countries and their different values for each dates of newly confirmed cases so I can plot them later.</p>

<p>The data I used was a cleaned/transformed data coming from the Covid-19 datasets from John Hopkins University.</p>

<p>This is my df2 (with more rows) snippet:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""true"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code snippet-currently-hidden"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Country/Region&lt;/th&gt;
      &lt;th&gt;Date&lt;/th&gt;
      &lt;th&gt;NewConfirmed&lt;/th&gt;
      &lt;th&gt;index_by_country&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2020-03-14&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2020-03-15&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2020-03-16&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;Afghanistan&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-10&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-14&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-15&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-16&lt;/td&gt;
      &lt;td&gt;9.0&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-04&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-05&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-06&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-07&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-08&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-09&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-10&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-14&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-15&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-16&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;14.0&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;Algeria&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;13.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;Andorra&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;Andorra&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;Andorra&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;14.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-08&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-09&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-10&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;12.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-14&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-15&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;44&lt;/td&gt;
      &lt;td&gt;43&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-16&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;44&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt;12.0&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;45&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;46&lt;/td&gt;
      &lt;td&gt;Argentina&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;18.0&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;131&lt;/td&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-02-25&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;132&lt;/td&gt;
      &lt;td&gt;131&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-02-26&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;133&lt;/td&gt;
      &lt;td&gt;132&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-02-27&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;134&lt;/td&gt;
      &lt;td&gt;133&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-02-28&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;135&lt;/td&gt;
      &lt;td&gt;134&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-02-29&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;135&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-01&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;137&lt;/td&gt;
      &lt;td&gt;136&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-02&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;138&lt;/td&gt;
      &lt;td&gt;137&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-03&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;139&lt;/td&gt;
      &lt;td&gt;138&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-04&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;140&lt;/td&gt;
      &lt;td&gt;139&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-05&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;141&lt;/td&gt;
      &lt;td&gt;140&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-06&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;142&lt;/td&gt;
      &lt;td&gt;141&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-07&lt;/td&gt;
      &lt;td&gt;25.0&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;142&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-08&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;144&lt;/td&gt;
      &lt;td&gt;143&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-09&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;144&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-10&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;146&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;147&lt;/td&gt;
      &lt;td&gt;146&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;148&lt;/td&gt;
      &lt;td&gt;147&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;-6.0&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;149&lt;/td&gt;
      &lt;td&gt;148&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-14&lt;/td&gt;
      &lt;td&gt;21.0&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;149&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-15&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;151&lt;/td&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-16&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;152&lt;/td&gt;
      &lt;td&gt;151&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt;14.0&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;153&lt;/td&gt;
      &lt;td&gt;152&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;28.0&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;154&lt;/td&gt;
      &lt;td&gt;153&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;22.0&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;155&lt;/td&gt;
      &lt;td&gt;154&lt;/td&gt;
      &lt;td&gt;Bangladesh&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;156&lt;/td&gt;
      &lt;td&gt;155&lt;/td&gt;
      &lt;td&gt;Bangladesh&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;157&lt;/td&gt;
      &lt;td&gt;156&lt;/td&gt;
      &lt;td&gt;Bangladesh&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;157&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;159&lt;/td&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;160&lt;/td&gt;
      &lt;td&gt;159&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-14&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;161&lt;/td&gt;
      &lt;td&gt;160&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-15&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;161&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-16&lt;/td&gt;
      &lt;td&gt;9.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;163&lt;/td&gt;
      &lt;td&gt;162&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;164&lt;/td&gt;
      &lt;td&gt;163&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;165&lt;/td&gt;
      &lt;td&gt;164&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</code></pre>
</div>
</div>
</p>

<p>this is my df1:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""true"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code snippet-currently-hidden"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;index&lt;/th&gt;
      &lt;th&gt;Country/Region&lt;/th&gt;
      &lt;th&gt;Date&lt;/th&gt;
      &lt;th&gt;NewConfirmed&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</code></pre>
</div>
</div>
</p>

<p>this was the output which has increased columns:</p>

<p><div class=""snippet"" data-lang=""js"" data-hide=""true"" data-console=""true"" data-babel=""false"">
<div class=""snippet-code snippet-currently-hidden"">
<pre class=""snippet-code-html lang-html prettyprint-override""><code>&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Country/Region&lt;/th&gt;
      &lt;th&gt;Date_x&lt;/th&gt;
      &lt;th&gt;NewConfirmed_x&lt;/th&gt;
      &lt;th&gt;index_by_country_x&lt;/th&gt;
      &lt;th&gt;index&lt;/th&gt;
      &lt;th&gt;Date_y&lt;/th&gt;
      &lt;th&gt;NewConfirmed_y&lt;/th&gt;
      &lt;th&gt;index_by_country_y&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-10&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-14&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-15&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-16&lt;/td&gt;
      &lt;td&gt;9.0&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;Albania&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;11.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-02-25&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-02-26&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-02-27&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-02-28&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-02-29&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-01&lt;/td&gt;
      &lt;td&gt;6.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-02&lt;/td&gt;
      &lt;td&gt;2.0&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-03&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-04&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-05&lt;/td&gt;
      &lt;td&gt;3.0&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-06&lt;/td&gt;
      &lt;td&gt;5.0&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-07&lt;/td&gt;
      &lt;td&gt;25.0&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-08&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-09&lt;/td&gt;
      &lt;td&gt;10.0&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-10&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;-6.0&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-14&lt;/td&gt;
      &lt;td&gt;21.0&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;29&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-15&lt;/td&gt;
      &lt;td&gt;4.0&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-16&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;21&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt;14.0&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;28.0&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;Bahrain&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;22.0&lt;/td&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2020-03-11&lt;/td&gt;
      &lt;td&gt;85.0&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;34&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-12&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-14&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;37&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-15&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;38&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-16&lt;/td&gt;
      &lt;td&gt;9.0&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;39&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-17&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;40&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-18&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;42&lt;/td&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;Belarus&lt;/td&gt;
      &lt;td&gt;2020-03-19&lt;/td&gt;
      &lt;td&gt;0.0&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;158&lt;/td&gt;
      &lt;td&gt;2020-03-13&lt;/td&gt;
      &lt;td&gt;15.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</code></pre>
</div>
</div>
</p>
"
60977632,"<p>I am trying to pivot the Johns Hopkins Data so that date columns are rows and the rest of the information stays the same. The first seven columns should stay columns, but the remaining columns (date columns) should be rows. Any help would be appreciated.</p>

<p><strong>Load and Filter data</strong></p>

<pre><code>import pandas as pd
import numpy as np
deaths_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv'
confirmed_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv'

dea = pd.read_csv(deaths_url)
con = pd.read_csv(confirmed_url)

dea = dea[(dea['Province_State'] == 'Texas')]
con = con[(con['Province_State'] == 'Texas')]
</code></pre>

<p><strong>View recency of data and pivot</strong></p>

<pre><code># get the most recent data of data
mostRecentDate = con.columns[-1] # gets the columns of the matrix

# show the data frame
con.sort_values(by=mostRecentDate, ascending = False).head(10)

# save this index variable to save the order.
index = data.columns.drop(['Province_State']) 

# The pivot_table method will eliminate duplicate entries from Countries with more than one city
data.pivot_table(index = 'Admin2', aggfunc = sum)

# formatting using a variety of methods to process and sort data
finalFrame = data.transpose().reindex(index).transpose().set_index('Admin2').sort_values(by=mostRecentDate, ascending=False).transpose()
</code></pre>

<p>The resulting data frame looks like this, however it did not preserve any of the date times </p>

<p><a href=""https://i.stack.imgur.com/bZ9or.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/bZ9or.png"" alt=""enter image description here""></a></p>

<p>I have also tried: </p>

<pre><code>date_columns = con.iloc[:, 7:].columns
con.pivot(index = date_columns, columns = 'Admin2', values = con.iloc[:, 7:])
ValueError: Must pass DataFrame with boolean values only
</code></pre>

<p>Edit:
As per guidance I tried the melt command listed in the first answer and it does not create rows of dates, it just removed all other non-date values.</p>

<pre><code>date_columns = con.iloc[:, 7:].columns
con.melt(id_vars=date_columns)
</code></pre>

<p><strong>The end result should look like this:</strong></p>

<pre><code>  Date  iso2    iso3    code3   FIPS    Admin2  Province_State  Country_Region  Lat Long_   Combined_Key
1/22/2020   US  USA 840 48001   Anderson    Texas   US  31.81534745 -95.65354823    Anderson, Texas, US
1/22/2020   US  USA 840 48003   Andrews Texas   US  32.30468633 -102.6376548    Andrews, Texas, US
1/22/2020   US  USA 840 48005   Angelina    Texas   US  31.25457347 -94.60901487    Angelina, Texas, US
1/22/2020   US  USA 840 48007   Aransas Texas   US  28.10556197 -96.9995047 Aransas, Texas, US
</code></pre>
"
61200154,"<p>I want to run code that scrapes the number of hospitalizations of the current day and store it in a data frame. I want to be able to run the code every day and each time I run it it stores the day's value as a separate row. Does anyone know how to do this?</p>

<p>I know how to scrape into a table using pandas but I don't know how to store each day's value as a separate line in the dataframe.</p>

<p>Here is the website I want to scrape from:
<a href=""https://www.ontario.ca/page/2019-novel-coronavirus"" rel=""nofollow noreferrer"">https://www.ontario.ca/page/2019-novel-coronavirus</a></p>
"
61198519,"<p>I'm trying to scrape data off the Google Covid-19 Mobility pdfs and in particular scrape the data off the charts for each county. I found someone that wrote up <a href=""https://gist.github.com/Amarang/3341c9a24da4556def7c3a03a12949b8"" rel=""nofollow noreferrer"">something</a> that's almost there but isn't quite perfect. If there's a graph in a pdf that has just one point (eg. look at the ""Parks"" category for Franklin county on <a href=""https://www.gstatic.com/covid19/mobility/2020-04-05_US_Massachusetts_Mobility_Report_en.pdf"" rel=""nofollow noreferrer"">page 5</a>), all the graphs on that page are skipped. A single point like that isn't returned as an XObject when using <code>getPageXObjectList()</code> and consequently you can't know which of the returned XObjects go with which county/category. </p>

<p>I've looked at the output of <code>_getXrefString()</code> and I'm pretty sure that the Xref is 127 for the pdf referenced but I can't figure out how to get where on the page the points are placed. It seems like there's <code>getPageXObjectList()</code> and <code>getPageText()</code> but there should be a third method like <code>getPageBasicObjects()</code> or something. Any help on how to figure out where the basic shapes are located would be appreciated. The only things I can't figure out how to index are these points and the grey axis/ticks on the graphs.</p>
"
61042909,"<p>I am working with covid-19's ECDC tables: source = <a href=""https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide"" rel=""nofollow noreferrer"">https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide</a></p>

<p>I have transformed the loooooooooong table into a pivot, more useful one using pandas. Now I have a table indexed by date with cases and deaths by some selected countries</p>

<pre><code>def downloadECDC(url)
    world = pd.read_csv(url)
    today = datetime.today().strftime(""%d%m%Y"")
    world.to_csv('ECDC' + today + '.csv')

    world['date'] = pd.to_datetime((world.year*10000+world.month*100+world.day).apply(str),format='%Y%m%d')



    dt = world[['date','deaths','cases','countriesAndTerritories', 'popData2018']]
    dt['DperHab'] = dt['deaths']/dt['popData2018']


    preoutput = pd.pivot_table(dt.loc[(dt['countriesAndTerritories']=='Spain') | (dt['countriesAndTerritories']=='Italy') | (dt['countriesAndTerritories']=='Germany') | (dt['countriesAndTerritories']=='France') |  (dt['countriesAndTerritories']=='United_Kingdom') | (dt['countriesAndTerritories']=='Portugal') | (dt['countriesAndTerritories']=='Netherlands') | (dt['countriesAndTerritories']=='Iran') | (dt['countriesAndTerritories']=='China') | (dt['countriesAndTerritories']=='South_Korea')], index = ['date'], values=['deaths','cases'], columns = 'countriesAndTerritories', aggfunc=np.sum, fill_value = 0)
    precases = pd.pivot_table(dt.loc[(dt['countriesAndTerritories']=='Spain') | (dt['countriesAndTerritories']=='Netherlands')| (dt['countriesAndTerritories']=='Italy') | (dt['countriesAndTerritories']=='France') ], index = ['date'], values=['cases'], columns = 'countriesAndTerritories', aggfunc=np.sum, fill_value = 0)
    predeaths= pd.pivot_table(dt.loc[(dt['countriesAndTerritories']=='Spain') | (dt['countriesAndTerritories']=='Netherlands')| (dt['countriesAndTerritories']=='Italy') | (dt['countriesAndTerritories']=='France')], index = ['date'], values=['deaths'], columns = 'countriesAndTerritories', aggfunc=np.sum, fill_value = 0)
    predxh= pd.pivot_table(dt.loc[(dt['countriesAndTerritories']=='Spain') | (dt['countriesAndTerritories']=='Netherlands')| (dt['countriesAndTerritories']=='Italy') | (dt['countriesAndTerritories']=='France')], index = ['date'], values=['DperHab'], columns = 'countriesAndTerritories', aggfunc=np.sum, fill_value = 0)
    output = preoutput.reindex(axis = 1, level = 1, labels = ['Spain','Italy','Germany','France','United_Kingdom','Portugal','Netherlands','Iran','China','South_Korea'])
    cases = precases.reindex(axis = 1, level = 1, labels = ['Spain','Italy','France','Netherlands'])
    deaths = predeaths.reindex(axis = 1, level = 1, labels = ['Spain','Italy','France','Netherlands'])
    dxhab = predxh.reindex(axis = 1, level = 1, labels = ['Spain','Italy','France','Netherlands'])

    output.to_excel('ECDC' + today + '.xlsx')

</code></pre>

<p>What I want is to create a new pivot table which values would be calculated summing deaths from one date backwards to the start of the timeline. I have tried several options but without result. Something like, I guess:</p>

<pre><code>preaggdeath= pd.pivot_table(dt.loc[(dt['countriesAndTerritories']=='Spain') | (dt['countriesAndTerritories']=='Netherlands')| (dt['countriesAndTerritories']=='Italy') | (dt['countriesAndTerritories']=='France')], index = ['date'], values=[XXXXX], columns = 'countriesAndTerritories', aggfunc=np.sum, fill_value = 0) # when XXXX is like to add deaths from one date to the start of series backwards
</code></pre>

<p>Thanks in advance</p>

<p>Edit: What I have</p>

<p><a href=""https://i.stack.imgur.com/uWgO7.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/uWgO7.png"" alt=""my table""></a></p>

<p>What I would like to have</p>

<p><a href=""https://i.stack.imgur.com/EkuFA.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/EkuFA.png"" alt=""new table""></a></p>
"
61461788,"<p>I've been playing around with the COVID-19 data available from Johns Hopkins. I've created a Python script to extract the data from Github, do some data cleanup, then load to a small SQL Server database I created. All of that works well.</p>

<p>Some of the data needs a little more massaging in order to accurately visualize it. There are missing FIPS numbers, missing lat/lons, etc. The issue I'm trying to resolve right now is to merge the confirmed counts which have null FIPS numbers with the FIPS number where everything else is the same. Here is a sample of the data:</p>

<p><a href=""https://i.stack.imgur.com/9U0sC.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9U0sC.png"" alt=""enter image description here""></a></p>

<p>In my searching, I found out about group by and sum:</p>

<pre><code>df1.groupby(['STATE','COUNTRY','LAT','LON','DATE'],as_index=False).sum()
</code></pre>

<p>This will merge the two lines I want, but it also merges the FIPS where that lat/lon is 0 and sums the FIPS numbers (FIPS # 80049 and 90049).</p>

<p>How do I exclude all but the rows with null FIPS and the matching rows above them?</p>

<p>(I hope that makes sense.)</p>

<p>Thanks!</p>

<p>Edited to add data:</p>

<pre><code>import pandas as pd

data = [
        [80049,'Utah','US',0.00000,0.00000,'2020-04-21',0], 
        [90049,'Utah','US',0.00000,0.00000,'2020-04-21',0], 
        [49017,'Utah','US',37.854472,-111.441876,'2020-04-21',0], 
        [None,'Utah','US',37.854472,-111.441876,'2020-04-21',70]
       ]

df1 = pd.DataFrame(data)

df1.columns=['FIPS', 'STATE', 'COUNTRY', 'LAT', 'LON', 'DATE', 'CONFIRMED']

df1
</code></pre>
"
61404728,"<p>I'm trying to analyse a covid data set and kind of at a loss on how to fix the data via pandas. The data set looks like the following:</p>

<p><a href=""https://i.stack.imgur.com/8bYaF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8bYaF.png"" alt=""enter image description here""></a></p>

<p>I'm trying to make it look like this:</p>

<pre><code>              April 2                        | April 3                       | April 4 
unique_tests  total unique tests for april 2 | total unique tests for april 3|total unique tests for april 4 
positive      total positive for april 2     | total positive for april 3    |total positive for april 4 
negative      total negative for april 2     | total negative for april 3    |total negative for april 4 
remaining      total remaining for april 2   | total remaining for april 3   |total remaining for april 4 
</code></pre>

<p>I have dates up to april 24. </p>

<p>Any ideas on how i can implement this? I can't make it work with pivot table in pandas</p>
"
61113978,"<p>With this dataset:</p>

<pre><code>df = pd.read_csv('https://covid.ourworldindata.org/data/ecdc/total_cases.csv')
</code></pre>

<p>I can extract all countries like so:</p>

<pre><code> countries = list(df)
</code></pre>

<p>ending up with:</p>

<pre><code>countries = ['Afghanistan', 'Albania', 'Algeria', 'Andorra', 'Angola', 'Anguilla', 'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bermuda', 'Bhutan', 'Bolivia', 'Bonaire Sint Eustatius and Saba', 'Bosnia and Herzegovina', 'Botswana', 'Brazil', 'British Virgin Islands', 'Brunei', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Cape Verde', 'Cayman Islands', 'Central African Republic', 'Chad', 'Chile', 'China', 'Colombia', 'Congo', 'Costa Rica', ""Cote d'Ivoire"", 'Croatia', 'Cuba', 'Curacao', 'Cyprus', 'Czech Republic', 'Democratic Republic of Congo', 'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia', 'Ethiopia', 'Faeroe Islands', 'Falkland Islands', 'Fiji', 'Finland', 'France', 'French Polynesia', 'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana', 'Gibraltar', 'Greece', 'Greenland', 'Grenada', 'Guam', 'Guatemala', 'Guernsey', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Honduras', 'Hungary', 'Iceland', 'India', 'Indonesia', 'International', 'Iran', 'Iraq', 'Ireland', 'Isle of Man', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kazakhstan', 'Kenya', 'Kosovo', 'Kuwait', 'Kyrgyzstan', 'Laos', 'Latvia', 'Lebanon', 'Liberia', 'Libya', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macedonia', 'Madagascar', 'Malawi', 'Malaysia', 'Maldives', 'Mali', 'Malta', 'Mauritania', 'Mauritius', 'Mexico', 'Moldova', 'Monaco', 'Mongolia', 'Montenegro', 'Montserrat', 'Morocco', 'Mozambique', 'Myanmar', 'Namibia', 'Nepal', 'Netherlands', 'New Caledonia', 'New Zealand', 'Nicaragua', 'Niger', 'Nigeria', 'Northern Mariana Islands', 'Norway', 'Oman', 'Pakistan', 'Palestine', 'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Romania', 'Russia', 'Rwanda', 'Saint Kitts and Nevis', 'Saint Lucia', 'Saint Vincent and the Grenadines', 'San Marino', 'Saudi Arabia', 'Senegal', 'Serbia', 'Seychelles', 'Sierra Leone', 'Singapore', 'Sint Maarten (Dutch part)', 'Slovakia', 'Slovenia', 'Somalia', 'South Africa', 'South Korea', 'South Sudan', 'Spain', 'Sri Lanka', 'Sudan', 'Suriname', 'Swaziland', 'Sweden', 'Switzerland', 'Syria', 'Taiwan', 'Tanzania', 'Thailand', 'Timor', 'Togo', 'Trinidad and Tobago', 'Tunisia', 'Turkey', 'Turks and Caicos Islands', 'Uganda', 'Ukraine', 'United Arab Emirates', 'United Kingdom', 'United States', 'United States Virgin Islands', 'Uruguay', 'Uzbekistan', 'Vatican', 'Venezuela', 'Vietnam', 'Zambia', 'Zimbabwe']
</code></pre>

<p>and latest number of cases of each respective country with:</p>

<pre><code>cases=[]
for item in df:
  if item in countries:
    # most recent is the last
    n = df[item].iloc[-1]
    cases.append(n)
</code></pre>

<p>ending up with:</p>

<pre><code> cases = [367.0, 383.0, 1468.0, 545.0, 17.0, 3.0, 15.0, 1715.0, 853.0, 74.0, 5956, 12640, 717.0, 36.0, 811.0, 164.0, 63.0, 861.0, 22194, 7.0, 26.0, 39.0, 5.0, 210.0, 2.0, 781.0, 7.0, 13717.0, 3.0, 135.0, 577.0, 384.0, 3.0, 117.0, 685.0, 17883, 7.0, 45.0, 9.0, 9.0, 5116.0, 82784, 1780.0, 45.0, 483.0, 349.0, 1282.0, 396.0, 13.0, 494.0, 5017, 180.0, 5071, 121.0, 15.0, 1956.0, 3995.0, 1322.0, 78.0, 16.0, 31.0, 1149.0, 52.0, 184.0, 5.0, 15.0, 2308.0, 78167, 47.0, 30.0, 4.0, 196.0, 103228, 287.0, 113.0, 1832.0, 11.0, 12.0, 121.0, 80.0, 166.0, 144.0, 33.0, 33.0, 25.0, 312.0, 895.0, 1586, 5194.0, 2738.0, nan, 62589, 1031.0, 5709.0, 150.0, 9248.0, 135586, 63.0, 3906, 170.0, 349.0, 704.0, 172.0, 184.0, 743.0, 270.0, 12.0, 548.0, 548.0, 14.0, 19.0, 78.0, 880.0, 2970.0, 599.0, 85.0, 8.0, 3963.0, 19.0, 56.0, 293.0, 6.0, 268.0, 2785.0, 1056.0, 79.0, 15.0, 241.0, 6.0, 1184.0, 10.0, 22.0, 16.0, 9.0, 19580, 18.0, 969.0, 6.0, 278.0, 254.0, 8.0, 5863, 419.0, 4072.0, 260.0, 2249.0, 2.0, 115.0, 2954.0, 3764.0, 4848.0, 12442.0, 573.0, 2057.0, 4417.0, 7497.0, 105.0, 11.0, 14.0, 8.0, 279.0, 2795.0, 237.0, 2447.0, 11.0, 6.0, 1481, 40.0, 581.0, 1055.0, 8.0, 1749.0, 10384, 1.0, 140510, 185.0, 14.0, 10.0, 10.0, 7693, 22164, 19.0, 376.0, 24.0, 2369.0, 1.0, 65.0, 107.0, 596.0, 34109.0, 8.0, 52.0, 1462.0, 2359.0, 55242, 398809, 45.0, 424.0, 504.0, 7.0, 166.0, 251.0, 39.0, 10.0]
</code></pre>

<p>Now I need to plot all of this on a map, and for that I need <code>ISO3</code> (alpha_3) code for each country. Order of items is crucial here.</p>

<p>Now, I've found this package which provides this info for each country:</p>

<pre><code>import pycountry
</code></pre>

<p>and if I <code>print (list(pycountry.countries))</code>, I get an iterable like this:</p>

<pre><code>[Country(alpha_2='AW', alpha_3='ABW', name='Aruba', numeric='533'), Country(alpha_2='AF', alpha_3='AFG', name='Afghanistan', numeric='004', official_name='Islamic Republic of Afghanistan'), Country(alpha_2='AO', alpha_3='AGO', name='Angola', numeric='024', official_name='Republic of Angola'), Country(alpha_2='AI', alpha_3='AIA', name='Anguilla', numeric='660'), Country(alpha_2='AX', alpha_3='ALA', name='Åland Islands', numeric='248'), Country(alpha_2='AL', alpha_3='ALB', name='Albania', numeric='008', official_name='Republic of Albania'), ...]
</code></pre>

<hr>

<p><strong>QUESTION</strong></p>

<p>How can I search this last iterable and end up with an ordered list of <code>alpha_3</code> codes, one code for each country in my countries list above (and in the same order), like so:</p>

<pre><code>alpha_codes = ['AFG', 'ALB', ...]
</code></pre>

<p>Ps: countries that are not on the list 'countries' should be discarted from the iterable and the length of the three final lists must be the same.</p>
"
61008195,"<p>I can fetch data from web page thru web scraping in Python. My data is fetched into a list. But don't know how to transform that list into a data frame. Is there any way I could web scrape and fetch data directly to a df?
Here is my code:</p>

<pre><code>import pandas as pd
import requests
from bs4 import BeautifulSoup
from tabulate import tabulate
from pandas import DataFrame
import lxml

# GET the response from the web page using requests library
res = requests.get(""https://www.worldometers.info/coronavirus/"")

# PARSE and fetch content using BeutifulSoup method of bs4 library
soup = BeautifulSoup(res.content,'lxml')
table = soup.find_all('table')[0]
df = pd.read_html(str(table))

# Here dumping the fetched data to have a look
print( tabulate(df[0], headers='keys', tablefmt='psql') )
print(df[0])
</code></pre>
"
60964828,"<p>So working on displaying chart based on state data:</p>

<pre><code>import requests
import pandas as pd
import altair as alt

URL = 'https://covidtracking.com/api/states/daily'
# sending get request and saving the response as response object 
r = requests.get(url = URL) 

# extracting data in json format 
data = r.json() 
df = pd.DataFrame(data)

state_box = alt.binding_select(options=list(df['state'].unique()))
selection = alt.selection_single(name='Data for', fields=['state'], bind=state_box)

chart1 = alt.Chart(df, title='Deaths').mark_bar().encode(
    x='dateChecked:T',
    y='death',
    tooltip=list(df.columns)
).add_selection(
    selection
).transform_filter(
    selection
).interactive()
chart2 = alt.Chart(df, title='Tests').mark_bar().encode(
    x='dateChecked:T',
    y='totalTestResults',
    tooltip=list(df.columns)
).add_selection(
    selection
).transform_filter(
    selection
).interactive()

(chart1 | chart2)
</code></pre>

<p>And I am using repeating code.  How can reuse the defintion for chart1 and simply change the y value, so in pseudocode:</p>

<pre><code>chart2 = chart1.set_y('totalTestResults')
</code></pre>

<p><a href=""https://i.stack.imgur.com/IEn6m.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IEn6m.png"" alt=""enter image description here""></a></p>
"
60908146,"<p>I'm trying to plot this <a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"" rel=""nofollow noreferrer"">dataset of COVID-19 deaths</a> as a time series of the number of deaths per country. So far, I've tried this script:</p>

<pre class=""lang-py prettyprint-override""><code>import requests
import pandas as pd
import matplotlib.pyplot as plt


def getdata():
    response = requests.get(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"")
    with open('data.csv', 'wb') as fp:
        fp.write(response.content)


if __name__ == ""__main__"":
    getdata()
    df = pd.read_csv('data.csv')

    dfg = df.groupby(by='Country/Region').sum()

    dfg.drop(labels=['Lat', 'Long'], axis=1, inplace=True)

    dfg.columns = pd.to_datetime(dfg.columns)

    dfplot = dfg.plot()

    plt.show()

</code></pre>

<p>which produces a data frame like this:</p>

<pre><code>                    2020-01-22  2020-01-23  2020-01-24  ...  2020-03-25  2020-03-26  2020-03-27
Country/Region                                          ...                                    
Afghanistan                  0           0           0  ...           2           4           4
Albania                      0           0           0  ...           5           6           8
Algeria                      0           0           0  ...          21          25          26
Andorra                      0           0           0  ...           1           3           3
Angola                       0           0           0  ...           0           0           0
...                        ...         ...         ...  ...         ...         ...         ...
Venezuela                    0           0           0  ...           0           0           1
Vietnam                      0           0           0  ...           0           0           0
West Bank and Gaza           0           0           0  ...           0           1           1
Zambia                       0           0           0  ...           0           0           0
Zimbabwe                     0           0           0  ...           1           1           1
</code></pre>

<p>However, the resulting plot does not show a time series, but rather has different countries on the X-axis:</p>

<p><a href=""https://i.stack.imgur.com/jmabK.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jmabK.png"" alt=""enter image description here""></a></p>

<p>I've tried reading the <a href=""https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.DataFrame.plot.html"" rel=""nofollow noreferrer""><code>DataFrame.plot</code></a> documentation to see how I could alter this behavior but it's pretty terse. Any ideas how I might accomplish this?</p>
"
60987598,"<p>I am trying to process covid-19 cases data</p>

<p>(the source, for interest: <a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv</a>)</p>

<p>The data forms a matrix, listing dates in columns and countries in rows. A simplified view:</p>

<pre><code>country 1/20/20 1/21/20 1/22/20 ... etc. ...
China   100     120     144     ... etc. ...
US      0       0       1       ... etc. ...
...
etc.
...
</code></pre>

<p>I am trying to turn the date columns and the figures into two new features, say ""date"" and ""confirmed"", for as in: </p>

<pre><code>country date     confirmed
China   1/20/20  100
China   1/21/20  120
China   1/22/20  144
US      1/20/20  0
US      1/21/20  0
US      1/22/20  1
...  etc.  ...
</code></pre>

<p>I am interested in any solution that embeds in Orange, though - of course - we can prepare the data before importing it!</p>
"
60877068,"<p>I'm currently trying to plot some of the <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">CSSEGISandData/COVID-19</a> data using matplotlib/Python. I have the following:</p>

<pre><code>#!/usr/bin/env python3

from pandas import read_csv, to_datetime
from matplotlib import pyplot

if __name__ == '__main__':

    data_file = 'COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'

    headers = [*read_csv(data_file, nrows=1)]

    global_fatal = read_csv(data_file, header=0, index_col=[0,1],
                            infer_datetime_format=1, parse_dates=True,
                            usecols=[c for c in headers if c != 'Long' and c != 'Lat'])

    columns = {}
    for col in global_fatal.columns:
        try:
            columns[col] = to_datetime(col, infer_datetime_format=True)
        except ValueError:
            pass
    global_fatal.rename(columns=columns, inplace=True)

    print(global_fatal.head())
    global_fatal.plot()
    pyplot.show()

</code></pre>

<p>But I get the dates as individual lines instead of the regions. I've tried to use other posts on here an tutorial to either remap the axis when I plot or change how they're pulled in via arguments to <code>pandas.read_csv</code>, but I can't get to seem to get the data to display sanely (with Countries as lines, time series/dates on the bottom/x-axis and number on the left/y-axis.</p>

<p><a href=""https://i.stack.imgur.com/RsDsz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/RsDsz.png"" alt=""Screenshot of plot from above code""></a></p>

<p>Here is the output from the <code>head()</code> function, so it looks like the data is getting imported correctly:</p>

<pre><code>python3 charts.py
                               2020-01-22  2020-01-23  2020-01-24  ...  2020-03-23  2020-03-24  2020-03-25
Province/State Country/Region                                      ...                                    
NaN            Afghanistan              0           0           0  ...           1           1           2
               Albania                  0           0           0  ...           4           5           5
               Algeria                  0           0           0  ...          17          19          21
               Andorra                  0           0           0  ...           1           1           1
               Angola                   0           0           0  ...           0           0           0

[5 rows x 64 columns]
</code></pre>
"
60575827,"<p>I have trouble following the reverse related relationship in a Django query:</p>

<pre><code>from django.db import models

class Reporter(models.Model):
    name = models.CharField(max_length=100)

class Article(models.Model):
    title = models.CharField(max_length=500)
    reporter = models.ForeignKey(Reporter, on_delete=models.CASCADE)
</code></pre>

<p>""Get the reporters who wrote an article about coronavirus"":</p>

<pre class=""lang-sql prettyprint-override""><code>SELECT * FROM myapp_reporter
    WHERE id IN (
        SELECT reporter_id FROM myapp_article WHERE title ILIKE '%coronavirus%'
    )
</code></pre>

<p>How do I write this in Django?</p>
"
61056324,"<p>I have created an animated map in Dash-Plotly (Python) to illustrate cases of COVID-19 over time. It is possible to select ""Confirmed"", ""Deaths"", and ""Recovered"" from a dropdown menu.</p>

<p>Unfortunately, no matter what I do to configure the animation slider-bar below the map, I either get no change in the margin or an error. </p>

<p>I would like to decrease the large margin that occurs between the map and the slider-bar.</p>

<p>In the app layout, I refer to the graph using: <code>dcc.Graph(id='covid-map')</code>, and the dropdown menu: </p>

<pre><code>dcc.Dropdown(id='covid-case-type', options=[{'label': m, 'value': m} for m in ['Confirmed', 'Deaths', 'Recovered']],value='Confirmed')
</code></pre>

<p>The current callback to create the map looks like this:</p>

<pre><code>@app.callback(Output('covid-map', 'figure'),
              [Input('covid-case-type', 'value')])
def update_covid_map(selected_case):
    cum_df['dateStr'] = cum_df['Date'].dt.strftime('%b %d, %Y')
    covid_world_map = go.Figure(data=px.scatter_geo(cum_df,
                                                    lon='Long',
                                                    lat='Lat',
                                                    hover_name='Country/Region',
                                                    size=selected_case,
                                                    color=selected_case,
                                                    color_continuous_scale=['Gold', 'DarkOrange', 'Crimson'],
                                                    animation_frame='dateStr',
                                                    height=450,
                                                    width=600,
                                                    title='Global COVID-19 progression'
                                                    ))

    covid_world_map.update_geos(showland=True, landcolor='LightBlue',
                                showocean=True, oceancolor='#F7FBFE',
                                showcoastlines=False)
    covid_world_map.update_layout(margin={'r': 0, 't': 40, 'l': 0, 'b': 0},
                                  font=tickFont,
                                  sliders={'margin-top': 0})
    return covid_world_map
</code></pre>

<p>The result looks like this: <a href=""https://i.stack.imgur.com/DwZh1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DwZh1.png"" alt=""map with large margin""></a></p>

<p>Any help on how to configure/style the animation slider-bar would be great!</p>
"
60881598,"<p>I am creating a  code that will extract all confirmed recovered and deaths in the whole world I want it to be saved in a xlsx file (Line By Line ) but all of the tutorial out there did not work.
this is the code that I use </p>

<pre><code>from tkinter import *
from tkinter import messagebox
import COVID19Py
def confirmed_wrld():
    conf_list = covid19.getLocations(rank_by='confirmed')
    with open(""confirmed.txt"", 'w') as output:
        for row in conf_list:
            output.write(str(row) + '\n')
    messagebox.showinfo('Saved','The list is saved in confirmed.txt file in the same folder if you dont have confirmed.txt file create one in the same directory and redo this action')

def recovered_wrld():
    recovered_lst = covid19.getLocations(rank_by='recovered')
    with open(""recovered.txt"", 'w') as output:
        for row in recovered_lst:
            output.write(str(row) + '\n')
    messagebox.showinfo('Saved',""The list is saved in recovered.txt file in the same folder if you dont have recovered.txt file create one in the same directory and redo this action"")

def deaths_wrld():
    dth_lst = covid19.getLocations(rank_by='deaths')
    messagebox.showinfo('Done', dth_lst)
    with open(""deaths.txt"", 'w') as output:
        for row in dth_lst:
            output.write(str(row) + '\n')
    messagebox.showinfo('Saved',""The list is saved in deaths.txt file in the same folder if you dont have deaths.txt file create one in the same directory and redo this action"")
covid19 = COVID19Py.COVID19(data_source=""csbs"")
root = Tk()
root.geometry(""500x500"")
root.title(""CoronaVirus Locator"")
confirmed_BTN = Button(text=""confirmed in the whole world"", command = confirmed_wrld)
confirmed_BTN.pack()
recovered_BTN = Button(text=""recovered in the whole world"", command = recovered_wrld)
recovered_BTN.pack()
deaths_BTN = Button(text=""deaths in the whole world"", command = deaths_wrld)
deaths_BTN.pack()
root.mainloop()

</code></pre>

<p>as you can see I try to save it as a txt file it works but I want it to be in xlsx so other people can see it with ease.</p>
"
61686817,"<p>I tried using beautiful soup to parse a website, however when I printed ""page_soup"" I would only get a portion of the HTML, the beginning portion of the code, which has the info I need, was omitted. No one answered my question. After doing some research I tried using Selenium to access the full HTML, however I got the same results. Below are both of my attempts with selenium and beautiful soup. When I try and print the html it starts off in the middle of the source code, skipping the doctype, lang etc initial statements.</p>

<pre><code>from selenium import webdriver
from bs4 import BeautifulSoup
browser = webdriver.Chrome( executable_path= ""/usr/local/bin/chromedriver"")
browser.get('https://coronavirusbellcurve.com/')
html = browser.page_source
soup = BeautifulSoup(html)
print(soup)
</code></pre>



<pre><code>import bs4
import urllib
from urllib.request import  urlopen as uReq
from urllib.request import Request, urlopen
from bs4 import BeautifulSoup as soup
htmlPage = urlopen(pageRequest).read()
page_soup = soup(htmlPage, 'html.parser')
print(page_soup)
</code></pre>
"
61601871,"<p><a href=""https://www.worldometers.info/coronavirus/#countries"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/#countries</a> is the website that I'm using and I'm trying to get the table with All tab selected to pull from html into my jupyter notebook. The problem I seem to be having is if I use class = 'table' it pulls all continent tabs first then the all table and it messes up how my data gets pulled in when I try looking at rows.</p>

<pre><code>import requests
import lxml.html as lh
import pandas as pd
import csv
import requests
from bs4 import BeautifulSoup
url = 'https://www.worldometers.info/coronavirus/#countries'
page = requests.get(url)
print(page.status_code) #Checking the http response status code. Should be 200
soup = BeautifulSoup(page.content, 'html.parser')
print(soup.prettify())
all_tables=soup.find_all(""table"")
right_table = soup.find('table',{'class':'table'})
col_headers = [th.getText() for th in right_table.findAll('th')]
data = [[td.getText() for td in right_table.findAll('td')] for tr in right_table()]
</code></pre>

<p>When I try to combine the col_headers and data it says I have13 columns passed, data had 2990 columns. Any guidance would be appreciated.</p>
"
60833391,"<p>I have a telegram python bot running on my raspberry pi which gives you information about coronavirus. But now I am having trouble with finding the information from this website :<a href=""https://experience.arcgis.com/experience/685d0ace521648f8a5beeeee1b9125cd"" rel=""nofollow noreferrer"">https://experience.arcgis.com/experience/685d0ace521648f8a5beeeee1b9125cd</a> whith bs4 and python. In the <code>&lt;body&gt;</code> is an <code>&lt;iframe&gt;</code> and in this is a <code>#document</code> with a new html file.</p>

<p>How can I get the information out of the <code>#document</code> html file?</p>

<p>This was my code for testing: </p>

<pre><code>import urllib.request
from bs4 import BeautifulSoup

pager = urllib.request.urlopen(""https://experience.arcgis.com/experience/685d0ace521648f8a5beeeee1b9125cd"")
inter = BeautifulSoup(pager, 'html.parser')
div = inter.find('iframe')

print(div)
</code></pre>

<p>but its only outputting 'None'</p>

<p>this is the source code of the website:
[source code of <a href=""https://experience.arcgis.com/experience/685d0ace521648f8a5beeeee1b9125cd"" rel=""nofollow noreferrer"">https://experience.arcgis.com/experience/685d0ace521648f8a5beeeee1b9125cd</a><a href=""https://i.stack.imgur.com/pFgWk.png"" rel=""nofollow noreferrer""></a></p>

<p>Many thanks for your help!</p>
"
61120843,"<p>I want to count the number of times a choice is selected by users. Here is my model</p>

<p>models.py</p>

<pre><code>from django.db import models
from django.utils import timezone
from django.contrib.auth.models import User
from multiselectfield import MultiSelectField


class MedicalHistory(models.Model):
    Anxiety = 'Anxiety'
    Arthritis = 'Arthritis'
    Asthma = 'Asthma'
    Anemia = 'Anemia'
    Cancer = 'Cancer'
    Corona_virus = 'Corona_virus'
    Diabetes = 'Diabetes'
    Ebola = 'Ebola'
    HIV = 'HIV'
    ILLNESS_CHOICES = (
        (Anxiety, ""Anxiety""),
        (Arthritis, ""Arthritis""),
        (Asthma, ""Asthma""),
        (Anemia, ""Anemia""),
        (Cancer, ""Cancer""),
        (Corona_virus, ""Corona_virus""),
        (Diabetes, ""Diabetes""),
        (Ebola, ""Ebola""),
        (HIV, ""HIV""),
    )
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    illness = MultiSelectField(choices=ILLNESS_CHOICES, max_length=50)
    symptoms = models.CharField(max_length=100)
    additional_info = models.CharField(max_length=100)
    disability = models.BooleanField(default=False)
    medications = models.BooleanField(default=False)
    created_at = models.DateTimeField(default=timezone.now)

    def __str__(self):
        return f'{self.user.username} Medical History'
</code></pre>

<p>Here I have a number of illnesses I want users to select from. A user can select more tan one illness. I want each illness to have a count, and every time the illness is selected it adds to the count. In my view I have</p>

<p>views.py</p>

<pre><code>def pie_chart(request):
labels = []
data = []

queryset = MedicalHistory.objects.values('illness').annotate(count=Sum('user')).order_by('-count')
for entry in queryset:
    labels.append(entry['illness'])
    data.append(entry['count'])

    return JsonResponse(data={
        'labels': labels,
        'data': data,
    }) 

&lt;QuerySet [{'illness': ['Asthma', 'Diabetes', 'Ebola'], 'count': 3}, {'illness': ['Anemia', 'Covid-19'], 'count': 2}]&gt;
</code></pre>

<p>The query doesn't do what I want, as I am trying to plot it in a chart. It groups the illness I think because of the <code>values</code>. My template.html looks like this.</p>

<p>chart.html</p>

<pre><code>{% block content %}
{% include 'sidebar.html' %}
&lt;div id=""container"" style=""width: 85%;""&gt;
    &lt;canvas id=""myChart""&gt;&lt;/canvas&gt;
&lt;/div&gt;
&lt;script src=""https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js""&gt;&lt;/script&gt;
&lt;script&gt;
var ctx = document.getElementById('myChart');
var myChart = new Chart(ctx, {
    type: 'bar',
    data: {
        labels: {{ labels|safe }},
        datasets: [{
            label: 'Overview of Medical History',
            data: {{ data|safe }},
            backgroundColor: [
                'rgba(255, 99, 132, 0.2)',
                'rgba(54, 162, 235, 0.2)',
                'rgba(255, 206, 86, 0.2)',
                'rgba(75, 192, 192, 0.2)',
                'rgba(153, 102, 255, 0.2)',
                'rgba(225, 400, 64, 0.2)'

            ],
            borderColor: [
                'rgba(255, 99, 132, 1)',
                'rgba(54, 162, 235, 1)',
                'rgba(255, 206, 86, 1)',
                'rgba(75, 192, 192, 1)',
                'rgba(153, 102, 255, 1)',
                'rgba(255, 159, 64, 1)'

            ],
            borderWidth: 1
        }]
    },
    options: {
        scales: {
            yAxes: [{
                ticks: {
                    beginAtZero: true
                }
            }]
        }
    }
});
&lt;/script&gt;

        &lt;/div&gt;
     &lt;!-- /#page-content-wrapper --&gt;
&lt;/div&gt;
  &lt;!-- /#wrapper --&gt;
{% endblock %}
</code></pre>

<h2>Solution:</h2>

<p>So I was able to solve this using python. I initialized a dict with the illnesses and setting their initial count as 0. Then I used values() returns a dictionary of illnesses saved in the db. The I looped through the queryset and concatenate 1 to the values of the illnesses. Then i passed the keys and values as labels and data respectively.</p>

<p>views.py</p>

<pre><code>def pie_chart(request):
    count = {'Anxiety': 0, 'Arthritis': 0, 'Asthma': 0, 'Anemia': 0, 'Cancer': 0,
             'Corona_virus': 0, 'Diabetes': 0, 'Ebola': 0, 'HIV': 0
             }

    queryset = MedicalHistory.objects.values('illness')
    for entry in queryset:
        for values in entry['illness']:
            count[values] += 1

    labels = [*count.keys()]
    data = [*count.values()]

    return render(request, 'chart.html', {
        'labels': labels,
        'data': data,
    })
</code></pre>
"
60796071,"<p>Here is the code that I have so far: </p>

<pre><code>
import numpy as np

import pandas as pd

import csv 


file = r'C:\Users\Tiago Costa\Desktop\Senior Year - 2019.2020\ME 130\Coronovirus Datasets\time_series_2019-ncov-Confirmed.xlsx'

data = pd.ExcelFile(file)

print(data.sheet_names)

['Worksheet']

df = data.parse('Worksheet')

df.info

df.head(483) 
</code></pre>

<p>I was wondering how I would be able to only extract the number of confirmed cases for China, Italy, Germany, Iran and USA, and then plot that data as a function of time. </p>

<p>I was going to be using this: <a href=""https://pythonprogramming.net/loading-file-data-matplotlib-tutorial/"" rel=""nofollow noreferrer"">https://pythonprogramming.net/loading-file-data-matplotlib-tutorial/</a>  as a reference to create my plots when I got to that point.</p>

<p>Thank you!</p>
"
60897469,"<pre><code>import sqlite3
import csv

con = sqlite3.connect(""covid_student.db"")
cur = con.cursor()

with open ('covid.csv', 'r') as f:
    reader = csv.reader(f)
    columns = next(reader) 
    query = 'insert into Patient({0}) values ({1})'
    query = query.format(','.join(columns), ','.join('?' * len(columns)))
    cursor = con.cursor()
    for data in reader:
        cursor.execute(query, data)
    cursor.commit()

con.commit()
con.close()
</code></pre>

<p>This is the code I have got so far. How can I improve it to achieve what I need.</p>
"
61032668,"<p><strong>Context</strong></p>

<p>I am scraping some coronavirus related data every day as a self-project. Given that the data is live, I'd like to store it all in a way that lets me see ""OK, Ohio had this many cases yesterday but this many today"".</p>

<p><strong>Proposed Solution</strong></p>

<p>I am uploading my pandas dataframes to an sqlite database. Right now it's just a bunch of tables, each table representing one day. Structure of each table:</p>

<p>Table name: state_[month]_[day]</p>

<ul>
<li>state: state abbreviations</li>
<li>positive: number of tested pos</li>
<li>negative: number of tested neg</li>
<li>hospitalized: num of pos in hospital</li>
<li>deaths: num of deaths</li>
<li>last_updated: date and time update</li>
</ul>

<p>I also have a reference table:</p>

<p>Table name: state_pop</p>

<ul>
<li>state: state abbreviation</li>
<li>population: population as of 2019</li>
</ul>

<p>I was imagining using state.state_pop as the reference key for all other tables. So I could just pull out Ohio and get its data from all other tables.</p>

<p><strong>Issue</strong></p>

<p>I can't find a way to either: upload my pandas dataframes and then designate a column (this is not supported by sqlite) as a primary key OR designate a column as a primary key and then upload them (this is not supported by python/pandas, as far as I can tell).</p>

<p>Would love to hear your suggestions!</p>
"
61209351,"<p>I want to download the files at <a href=""https://data.gov.hk/en-data/dataset/hk-dh-chpsebcddr-novel-infectious-agent/resource/a09134c1-53ea-4916-a573-62cf972562af"" rel=""nofollow noreferrer"">https://data.gov.hk/en-data/dataset/hk-dh-chpsebcddr-novel-infectious-agent/resource/a09134c1-53ea-4916-a573-62cf972562af</a>. I selected the date range from December 31, 2019 until April 13, 2020. I see the links like these there:</p>

<p><a href=""https://api.data.gov.hk/v1/historical-archive/get-file?url=http%3A%2F%2Fwww.chp.gov.hk%2Ffiles%2Fmisc%2Fenhanced_sur_covid_19_eng.csv&amp;time=20200411-0928"" rel=""nofollow noreferrer"">https://api.data.gov.hk/v1/historical-archive/get-file?url=http%3A%2F%2Fwww.chp.gov.hk%2Ffiles%2Fmisc%2Fenhanced_sur_covid_19_eng.csv&amp;time=20200411-0928</a></p>

<p><a href=""https://api.data.gov.hk/v1/historical-archive/get-file?url=http%3A%2F%2Fwww.chp.gov.hk%2Ffiles%2Fmisc%2Fenhanced_sur_covid_19_eng.csv&amp;time=20200412-0945"" rel=""nofollow noreferrer"">https://api.data.gov.hk/v1/historical-archive/get-file?url=http%3A%2F%2Fwww.chp.gov.hk%2Ffiles%2Fmisc%2Fenhanced_sur_covid_19_eng.csv&amp;time=20200412-0945</a></p>

<p><a href=""https://api.data.gov.hk/v1/historical-archive/get-file?url=http%3A%2F%2Fwww.chp.gov.hk%2Ffiles%2Fmisc%2Fenhanced_sur_covid_19_eng.csv&amp;time=20200413-0946"" rel=""nofollow noreferrer"">https://api.data.gov.hk/v1/historical-archive/get-file?url=http%3A%2F%2Fwww.chp.gov.hk%2Ffiles%2Fmisc%2Fenhanced_sur_covid_19_eng.csv&amp;time=20200413-0946</a></p>

<p>How can I download 10s or 100s of files from these links using R? Simple read_* function will not read these file. I  don't have a code to share here as I don't know how to attempt this? </p>
"
61618784,"<p>I'm looking for opening time table of a place, but now manly places has NULL result because of coronavirus epidemy lockdown. Are there any solutions to take result from <code>googleway::google_place_details()</code> at a specific date?</p>
"
61677498,"<pre><code> df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19- 
  timeseries/master/countryReport/raw/rawReport.csv',
            stringsAsFactors = FALSE)
  df1 &lt;- aggregate(death ~ countryName, subset(df), sum)
</code></pre>

<p>I created the data set with the number of deaths.</p>

<p>Plotting the number of deaths of the 5 countries with the most deaths as a line graph.</p>
"
61665589,"<pre><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19- 
timeseries/master/countryReport/raw/rawReport.csv',
            stringsAsFactors = FALSE)
 df8 &lt;- read.csv ('https://raw.githubusercontent.com/hirenvadher954/Worldometers- 
 Scraping/master/countries.csv',
             stringsAsFactors = FALSE)

library(tidyverse)

    df %&gt;% 
   left_join(df8, by = c(""countryName"" = ""country_name"")) %&gt;% 
   mutate(population = as.numeric(str_remove_all(population, "",""))) %&gt;% 
    group_by(countryName) %&gt;% 
     group_by(countryName) %&gt;% 
  unique() %&gt;% 
  summarize(population = sum(population, na.rm = TRUE),
        confirmed = sum(confirmed, na.rm = TRUE),
        recovered = sum(recovered, na.rm = TRUE),
        death = sum(death, na.rm = TRUE),
        death_prop = paste0(as.character(death), ""/"", as.character(population)),
        confirmed_prop = paste0(as.character(confirmed), ""/"", as.character(population)),
        recovered_prop = paste0(as.character(recovered), ""/"", as.character(population)),
        )
</code></pre>

<p>population / death ratio is calculated in this code.</p>

<p>what I want to do is
Finding 10 countries with the highest population / death ratio.</p>

<p>as output;</p>

<p><code>counrtyName     death     population      rate</code></p>

<p><code>İtaly           19000     50000000000     19/50000000</code></p>

<p><code>spain           17000     60000000000     17/60000000</code></p>

<p><code>....</code></p>

<p><code>.....</code></p>

<p><code>....</code>                     </p>

<p><code>....</code></p>

<p><code>....</code>
The examples I have given are not real data.</p>

<p>examples do not reflect reality.</p>
"
61696671,"<pre class=""lang-r prettyprint-override""><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19- 
                 timeseries/master/countryReport/raw/rawReport.csv',
                stringsAsFactors = FALSE)

yesterday &lt;- function() Sys.Date() - 1L
yesterday()
# [1] ""if it doesn't work yesterday()-1  do it""
# Data in DF is being updated. but sometimes it's too late. Please check if yesterday 
# command might have problem.

df3 &lt;- aggregate(confirmed  ~ countryName, subset(df,day == yesterday()-2), sum)

df10 &lt;-  aggregate(confirmed  ~ confirmed, subset(df), sum)
</code></pre>

<p>I found the number of confirmed. however, the three countries that give the most confirmation I want are there.</p>

<p>and this is the information of 3 countries that constitute the percentage of total confirmed.</p>

<p>as output:</p>

<pre class=""lang-r prettyprint-override""><code>date         countryName     confirmed     total-confirmed       percent (%)
2020/05/05    Spain           19800           92108838            0,0158554
2020/05/05    italy           19800           92108838            0,0158554
2020/05/05    iran            19800           92108838            0,0158554
</code></pre>

<p>data is not an example. is not real.</p>

<p>date is necessary here to make sure that the last day's data is received</p>
"
61658653,"<pre><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19- 
timeseries/master/countryReport/raw/rawReport.csv',
            stringsAsFactors = FALSE)
</code></pre>

<p>How to create a pie chart of the death, confirmed and recovered fields in this data set by region.</p>
"
61679653,"<pre><code> df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19- 
 timeseries/master/countryReport/raw/rawReport.csv',
            stringsAsFactors = FALSE)
</code></pre>

<p>I processed the dataset.</p>

<p>Can we find the day of the least death in the Asian region?</p>

<p>the important thing here;
 is the sum of deaths of all countries in the asia region. Accordingly, it is to sort and find the day.</p>

<p>as output;</p>

<p><code>date         region     death</code></p>

<p><code>2020/02/17    asia       6300 (asia region sum)</code></p>

<p>The data in the output I created are examples. The data in the example are not real.</p>
"
61702276,"<pre><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19- 
 timeseries/master/countryReport/raw/rawReport.csv',
            stringsAsFactors = FALSE)
</code></pre>

<p>america region bar chart</p>

<p>world total would be a line chart.</p>
"
61574213,"<p>I uploaded the dataset.
but how do I show those who died in Europe.</p>

<p><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19-timeseries/master/countryReport/raw/rawReport.csv')</code></p>

<p><code>europe &lt;-- df[df$region ==""Europe""]</code></p>

<p><code>df$death [europe]</code></p>
"
61617514,"<p>There are countries and continental information for covid-19 cases in the df database.</p>

<p>The df8 dataset contains population information.</p>

<p>df1 also addressed yesterday to reach the country's new case count.</p>

<p>In df4, I have printed the total deaths so far as continents.</p>

<p>I also found population information of continents.</p>

<p>my problem is to separate the data of new cases (yesterday's death) into continents. proportion to the population written in df8.</p>

<pre><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19- 
 timeseries/master/countryReport/raw/rawReport.csv',
        stringsAsFactors = FALSE)

yesterday &lt;- function() Sys.Date() - 1L
yesterday()
df1 &lt;- aggregate(death ~ countryName, subset(df, day == yesterday()), sum)
df8 &lt;- read.csv ('https://raw.githubusercontent.com/hirenvadher954/Worldometers-                      
     Scraping/master/countries.csv',
             stringsAsFactors = FALSE)

 df4 &lt;- aggregate(death ~ region, subset(df), sum)


  library(tidyverse)

      df %&gt;% 
      left_join(df8, by = c(""countryName"" = ""country_name"")) %&gt;% 
      mutate(population = as.numeric(str_remove_all(population, "",""))) %&gt;% 
      group_by(countryName) %&gt;%
      slice(1) %&gt;%
      group_by(region) %&gt;% 
      summarize(population = sum(population, na.rm = TRUE))
</code></pre>

<p>There are countries and continental information for covid-19 cases in the df database.</p>

<p>The df8 dataset contains population information.</p>

<p>df1 also addressed yesterday to reach the country's new case count.</p>

<p>In df4, I have printed the total deaths so far as continents.</p>

<p>I also found population information of continents.</p>

<p>my problem is to separate the data of new cases (yesterday's death) into continents. proportion to the population written in df8.</p>

<p>so as output</p>

<p>region    death    population   rate</p>

<p>africa   234      523452656    86/44545 </p>

<p>americas     24562    4123548621   15/4453284
.
.
.</p>
"
61635073,"<pre><code> df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19- 
  timeseries/master/countryReport/raw/rawReport.csv',
            stringsAsFactors = FALSE)

  yesterday &lt;- function() Sys.Date() - 1L
  yesterday()
 # [1] ""if it doesn't work yesterday()-1  do it""
</code></pre>

<p>I created the function of yesterday.</p>

<p>There are region, death and recovered sections in the df dataset.</p>

<p>The thing he wants your help is this.</p>

<p>To find the country that reported the most deaths in the continent, compared to yesterday in the DF data set</p>

<p>According to yesterday in the DF data set, find the country that reported the most recovered on the continent.</p>

<p>so what I want as output.</p>

<p>Date            countryName           region         death             recovered  </p>

<p>2020/05/05   İtaly(sample)      Europe       <strong>600</strong>(sample)     50</p>

<p>2020/05/05   Spain(sample)      Europe       200(sample)     <strong>580</strong></p>

<p>2020/05/05   China(sample)      Asia          <strong>1200</strong>           80</p>

<p>2020/05/05    Japan(sample)     Asia           400            <strong>780</strong></p>

<p>..</p>

<p>..</p>

<p>..</p>

<p>countries and data are given as examples.</p>

<p>one line of death.
a row recovered.</p>

<p>required for each region.</p>

<p>There are 5 regions. It becomes 10 lines.</p>
"
61394573,"<p>Does anybody know a function to substitute the plotly one? </p>

<p>I want to graph coronavirus-related cases and deaths. I have found a code that uses plotly, but I would like to save the plot in a pdf file. Is there a substitute function?</p>

<p>This is a part of the code:</p>

<pre><code>plotly::plot_ly(data = df, 
                x = ~ country, 
                y = ~ unrecovered, 
                # text =  ~ confirmed, 
                # textposition = 'auto',
                type = ""bar"", 
                name = ""Active"",
                marker = list(color = active_color)) %&gt;%
  plotly::add_trace(y = ~ recovered, 
                    # text =  ~ recovered, 
                    # textposition = 'auto',
                    name = ""Recovered"",
                    marker = list(color = recovered_color)) %&gt;%
  plotly::add_trace(y = ~ death, 
                    # text =  ~ death, 
                    # textposition = 'auto',
                    name = ""Death"",
                    marker = list(color = death_color)) %&gt;%
  plotly::layout(title = ""Distribution by type"",
                 barmode = 'stack',
                 yaxis = list(title = ""Total Cases (log scaled)"",
                              type = ""log""),
                 xaxis = list(title = paste(""Last update:"", format(max(coronavirus::coronavirus$date), '%d %B'), sep = "" "")),
                 hovermode = ""compare"",
                 annotations = list(
                   text = paste(""Last update:"", format(max(coronavirus::coronavirus$date), '%d %B'), sep = "" ""),
                   xref = ""paper"",
                   yref = ""paper"",
                   showarrow = FALSE,
                  x = 0.95,
                  y = 1
                 ),
                 margin =  list(
                   # l = 60,
                   # r = 40,
                   b = 10,
                   t = 10,
                   pad = 2))
</code></pre>
"
61393183,"<p>I'm trying to plot graphs with a Covid-2019 dataset. I was already able to plot one with the number of confirmed cases by countries, but now I need one with the number of casualties per country. How can I do that? 
This was the code I used for the number of confirmed cases:</p>

<pre><code>library(ggplot2)

library('remotes')
remotes::install_github(""GuangchuangYu/nCov2019"", dependencies = TRUE)

library('nCov2019')
get_nCov2019(lang = 'en')

x &lt;- get_nCov2019()
y &lt;- load_nCov2019()

library(magrittr)

d &lt;- y['global'] 
f &lt;- d %&gt;% dplyr::filter(time == time(y)) %&gt;% top_n(180, cum_confirm) %&gt;% arrange(desc(cum_confirm)) 

library(dplyr)

require(ggplot2)
require(ggrepel)
ggplot(filter(d, d$time &gt; '2020-02-05' &amp; country %in% f$country), mapping = aes(time, cum_confirm , color = country, label = country))  +
geom_line() +
  geom_text(data = f, aes(label = country, colour = country, x = time, y = cum_confirm))+
theme_minimal(base_size = 14)+
theme(legend.position = ""none"") +
ggtitle('Covid-19 Cases by Country', 'The progression of confirmed cases by countries')+
ylab('Confirmed Cases')
</code></pre>
"
61483036,"<p>It's not in the Rtweet-documentation how to do this properly with the additional operators available for search_fullarchive and search_30days.
It just says that the string should follow directly after the operator: , for example: place:California. And that OR can be used to search for multiple phrases.</p>

<p>My attempts:</p>

<pre><code>queryohio &lt;- '(place:OH OR place:Ohio OR place:Columbus)(corona OR covid19 OR virus)'
queryohio2 &lt;- 'corona OR covid19 OR virus place:Ohio OR place:Columbus OR place:OH'
querycalifornia &lt;- 'place:CA(corona OR covid19 OR virus) OR place:California(corona OR covid19 OR virus) OR place:""Los Angeles""(corona OR covid19 OR virus)'
</code></pre>

<p>They all kinda work to varying degrees but I'd be happy to know if there is a correct way to do it. </p>
"
61617026,"<p>So I want to create a map showing the covid19 cases per 100.000 in Europe. However, after converting my Large SpatialPolygosDataFrame into a normal data frame with the fortify function and merging my corona information data set with the data frame of polygon data, the plot does not come out correctly anymore. I know that the cause is probably the order column, which is now not ordering the coordinates correctly anymore and has random jumps as you can see in the data frame. This is causing ggplot to incorrectly plot the coordinates in the right sequence. Does anyone know how I can reorder my entire dataframe by the column order. So the ""order"" column is ascending and all values around it are included in the reorder?</p>

<p><a href=""https://i.stack.imgur.com/mMPfh.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mMPfh.png"" alt=""This is an example of my data""></a>
<a href=""https://i.stack.imgur.com/DKHZe.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DKHZe.png"" alt=""COVID-19 Cases per 100.000""></a></p>
"
61100997,"<p>I'm attempting to learn R by using the John's Hopkins COVID-19 data located at: </p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series</a></p>

<p>I'm trying to work with the time_series_covid19_confirmed_US.csv file. The data is in a time series format with resolution down to county level. I'd like to work with state level totals for each day. I'm able to remove the columns of info I don't need, but get stuck trying to group the counties into states.</p>
"
61709686,"<p>With ggplot I´ve made a histogram with some values ,I would want to change the color of the highest bar, so that it makes the plot more legible.</p>

<p>Many thanks  </p>

<pre><code>ggplot(df, 
       aes(as.Date(created_at), as.numeric(count))) +
  geom_col(fill = 'cornflowerblue') + 
  theme_minimal(base_size = 10) +
  xlab(NULL) + ylab(NULL) + 
  scale_x_date(date_labels = ""%Y/%m/%d"",date_breaks = ""days"",expand = c(0,0)) +  #El espaciado por días
  theme(axis.text.x=element_text(angle=90, vjust = 0.5))+#Cambiamos la posición del x 
  geom_text(aes(label = count, y = count+50), position = position_dodge(0.9),angle=90, vjust = 0.5,size=3)+
  ggplot2::theme(
    plot.title = ggplot2::element_text(face = ""bold"",colour = ""black""))+
  ggplot2::labs(
    x = NULL, y = NULL, #Info en cada eje 
    title = ""Tweets sobre el COVID-19 por día"", #Texto 
    subtitle = """"
  )

</code></pre>
"
61697192,"<p>I am trying to create a time series plot that has multiple data over the years. I would like to just plot the years and get the data to run from start date to end date. Here I have converted the respective columns to dates and then combined them but I do not get the result I am looking for. </p>

<p>The data is available from this  website: <a href=""https://www.businessinsider.co.za/coronavirus-deaths-how-pandemic-compares-to-other-deadly-outbreaks-2020-4?r=US&amp;IR=T"" rel=""nofollow noreferrer"">https://www.businessinsider.co.za/coronavirus-deaths-how-pandemic-compares-to-other-deadly-outbreaks-2020-4?r=US&amp;IR=T</a></p>

<p>Something like this where the data doesn't start in the same year or end in the same year:
<a href=""https://ichef.bbci.co.uk/news/410/cpsprodpb/6E25/production/_111779182_optimised-mortality-nc.png"" rel=""nofollow noreferrer"">https://ichef.bbci.co.uk/news/410/cpsprodpb/6E25/production/_111779182_optimised-mortality-nc.png</a></p>

<p>(time period vs deaths caused)</p>

<pre><code>library(lubridate)
library(ggplot2)
otherDiseaseData &lt;- structure(list(ï..Disease = structure(c(11L, 2L, 12L, 6L, 3L, 
                                                            1L, 9L, 7L, 13L, 4L, 5L, 8L, 10L), .Label = c(""Asian Flu"", ""blackdeath"", 
                                                                                                          ""Cholera"", ""Covid 19"", ""Ebola"", ""HIV"", ""Hong Kong Flu"", ""Mers"", 
                                                                                                          ""Russian Flu"", ""Sars"", ""smallpox"", ""spanish flu"", ""Swine Flu""
                                                            ), class = ""factor""), Start = c(0L, 1347L, 1918L, 1981L, 1899L, 
                                                                                            1957L, 1889L, 1968L, 2009L, 2019L, 2014L, 2012L, 2002L), End = c(1979L, 
                                                                                                                                                             1351L, 1919L, 2020L, 1923L, 1958L, 1890L, 1970L, 2010L, 2020L, 
                                                                                                                                                             2016L, 2020L, 2003L), Death = c(300000L, 225000000L, 50000L, 
                                                                                                                                                                                             2360000L, 1500000L, 1100000L, 1000000L, 1000000L, 151700L, 101526L, 
                                                                                                                                                                                             11300L, 866L, 774L)), class = ""data.frame"", row.names = c(NA, 
                                                                                                                                                                                                                                                       -13L))


yrs &lt;- otherDiseaseData$Start
    yr &lt;- as.Date(as.character(yrs), format = ""%Y"")
    yStart &lt;- year(yr)

    yrs &lt;- otherDiseaseData$End
    yr &lt;- as.Date(as.character(yrs), format = ""%Y"")
    yStart &lt;- year(yr)

    otherDiseaseData$x &lt;- paste(otherDiseaseData$Start,otherDiseaseData$End)
    otherDiseaseData
    ggplot(otherDiseaseData, aes(y = Death, x = otherDiseaseData$x),xlim=0000-2000) + geom_point()
</code></pre>
"
61052382,"<p>I acquire the data set of Coronavirus in the US from The New York Times which includes date and accumulative cases up to that date. In what way I can extract and plot new cases <strong>per day</strong> using ggpplot in R?</p>

<p>The data set: <a href=""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv</a></p>
"
70280,"<p>I'm trying to use the recent COVID-19 data from the site of Italian Civil Protection, but they use a rather complicated time format that I'm finding troublesome as a novice to plot as data in a graph.
This is how the data is presented:</p>

<pre><code>[1] 2020-02-24T18:00:00 2020-02-25T18:00:00 2020-02-26T18:00:00 2020-02-27T18:00:00 2020-02-28T18:00:00 2020-02-29T18:00:00
</code></pre>

<p>and I would like to use the format as DD-MM, without the time and the year.
How can I do it?</p>
"
61325434,"<p>I have to create a plot with the number of COVID-19 confirmed cases by date, in each country. I have to use the data inside the package: 
<a href=""https://cran.r-project.org/web/packages/coronavirus/index.html"" rel=""nofollow noreferrer"">https://cran.r-project.org/web/packages/coronavirus/index.html</a>.</p>

<p>I managed to create a subset with the variables ""Country Region"", ""Type"" (confirmed only), ""date"", and ""total of cases"". However, i don't know to plot a graph with multiple lines.</p>

<p>I have to plot a graph with all countries in it, based on the:
<a href=""https://twitter.com/thomasfujiwara/status/1249817958874001412?s=20"" rel=""nofollow noreferrer"">https://twitter.com/thomasfujiwara/status/1249817958874001412?s=20</a></p>

<p>I also want to exclude mainland china from the dataset</p>

<p><strong>Can someone help me?</strong> </p>
"
60713418,"<p>I am trying to plot COVID-19 infections in Turkey with a scatter plot graph using ggplot2. However, I couldn't connect the points with a connecting line. I've searched a lot but couldn't draw a line no matter what I did.</p>

<p>Here is my code.</p>

<pre><code>    library(ggplot2)

Date &lt;- c(""11/03"",""12/03"",""13/03"",""14/03"",""15/03"",""16/03"")
Infected &lt;- c(1,1,5,6,18,47)

Covid_19 &lt;- data.frame(Date,Infected)

pl &lt;- ggplot(Covid_19,aes(x=Date, y=Infected))

pl3 &lt;- pl + geom_point(aes(color = 'blue'), size=5) + geom_line() + ggtitle(""COVID-19 in Turkey"")

print(pl3)
</code></pre>

<p>I tried to use geom_line() function but I get a warning and the line doesn't show up.</p>

<blockquote>
  <p>geom_path: Each group consists of only one observation. Do you need to
  adjust the group aesthetic?</p>
</blockquote>
"
60673960,"<p>So far I have the code below:</p>

<pre><code>    cov_plot &lt;- ggplot(data = plot_data) +
  geom_line(aes(x = plot_data$days_since, 
                y = plot_data$total_cases, 
                color = location)) +
  scale_y_log10(breaks = c(10^1, 10^2, 10^3, 10^4, 10^5),
                labels = c(""10"", ""100"", ""1000"", ""10000"", ""100000""))+
  ggtitle(""Confirmed Covid-19 Cases in 6 Countries"") +
  xlab(""Days since first confirmed case"") +
  ylab(""Number of Confirmed Cases"") +
  theme_classic() +
  theme(legend.title = element_text(""""),
        legend.position = ""none"")
</code></pre>

<p><a href=""https://i.stack.imgur.com/CKBNQ.png"" rel=""nofollow noreferrer"">Data</a>
<a href=""https://i.stack.imgur.com/bi9V3.png"" rel=""nofollow noreferrer"">Plot</a></p>

<p>I can't find a way to add the names of countries at the end of each line. Any help is appreciated</p>
"
61402326,"<p>I got stuck when using ""rvest"" to extract the COVID data from the page: <a href=""https://www.cdc.gov/coronavirus-interactive/index.html"" rel=""nofollow noreferrer"">https://www.cdc.gov/coronavirus-interactive/index.html</a></p>

<p>Thanks for your time!</p>

<p>Here is my code:</p>

<pre><code>library(""rvest"")

url = ""https://www.cdc.gov/coronavirus-interactive/index.html""

tbl &lt;- url %&gt;%
  read_html() %&gt;%
  html_nodes(xpath = '//*[@id=""viz030_widget5_table""]') %&gt;%
  html_table(fill=TRUE)
tbl
</code></pre>
"
60760834,"<p>I am building a shiny app for Coronavirus. 
My question is,
whenever I press the RunApp, the App should automatically take the latest data set. Here we will need to change the date before running the app every day.
How do I do it? How to put the latest date and filter the data.</p>

<p>This is just collecting, separating and plotting the data.</p>

<pre><code>raw_data &lt;- getURL(""https://raw.githubusercontent.com/datasets/covid-19/master/time-series-19- 
            covid-combined.csv"")
data &lt;- read.csv(text = raw_data, stringsAsFactors = FALSE)
View(data)

Confirmed &lt;- data[which(data$Date==""2020-03-18""),] %&gt;%
  group_by(Country.Region)%&gt;%
  summarise(Confirmed = sum(Confirmed)) %&gt;%
  arrange(-Confirmed)
View(Confirmed)

Deaths &lt;- data[which(data$Date==""2020-03-18""),] %&gt;%
  group_by(Country.Region) %&gt;%
  summarise(Deaths = sum(Deaths)) %&gt;%
  arrange(-Deaths)
View(Deaths)

Recovered &lt;- data[which(data$Date==""2020-03-18""),] %&gt;%
  group_by(Country.Region) %&gt;%
  summarise(Recovered = sum(Recovered)) %&gt;%
  arrange(-Recovered)
View(Recovered)

Total_Confirmed &lt;- sum(Confirmed$Confirmed)
Total_Deaths &lt;- sum(Deaths$Deaths)
Total_Recovered &lt;- sum(Recovered$Recovered)
</code></pre>

<p>Thanks in Advance.</p>
"
61178924,"<p>I am creating an animated chart from a dataset (using ggplot2, gganimate, ggrepel...) but I can't seem to get the label to round during the transition frames. Thus it makes a big long decimal number on the label. I can semi fix it by setting the label text to 'as.factor' or 'as.character', which will then only display the actual value of each point in the dataset, but ideally, I'd love to show it growing as it does with decimal places, but as whole numbers (or a single decimal place). I tried using various 'round' functions but that doesn't seem to work. Any ideas? :)</p>

<p>Code:</p>

<pre><code>#################################################
# set libraries ----
library(fredr)
library(zoo)
library(tidyverse)
library(lubridate)
library(gganimate)
library(ggrepel)
library(dplyr)
library(readr)
library(ggplot2)
library(scales)
library(readxl)

################################################


# Import Data from XLS
my_data &lt;- read_excel(""C:\\Users\\xxx\\OneDrive\\Desktop\\total-world.xlsx"")


a3 &lt;- 

  # Decimal Places in Label when annimated
  #  ggplot(data=my_data, aes(x=Date,y=Cases,label = as.character(Cases) ))+
  ggplot(data=my_data, aes(x=Date,y=Cases,label = Cases ))+
  geom_line()+
  view_follow()+

  geom_point(color=""red"", size = 4)+
  geom_line(size = 1, colour=""#FFFFFF"") +
  geom_area(color=""white"", fill=""#093e58"", alpha = 0.4)+
  geom_label_repel(aes(label = round(Cases,1)),
                    segment.colour = ""black"",
                   fontface = 'bold',
                   box.padding = unit(0.5, ""lines""),
                   point.padding = unit(1, ""lines""),
                   segment.color = ""Red""  ) +

  scale_y_continuous(labels=scales::comma_format())+
  transition_reveal(ind)+
  theme_gray()+

# Ugly, needs cleaning up...  
  theme(plot.caption=element_text(hjust=0))+
  theme(plot.title = element_text(color = ""#ff9e2a"", size = 15, face = ""bold""))+
  theme(plot.subtitle = element_text(color = ""yellow"", size = 15, face = ""bold""))+
  theme(plot.caption = element_text(color = ""green"", size = 12, face = ""bold""))+
  theme(panel.background = element_rect(fill = ""#141e24"", colour = ""#141e24""))+
  theme(plot.background = element_rect(fill = ""black""))+
  theme(panel.grid.major = element_line(colour = ""#203039"", linetype = ""dashed""))+
  theme(panel.grid.minor = element_line(colour = ""#203039"", linetype = ""dashed""))+
  theme(axis.text.x = element_text(face=""bold"", color=""white"", size=14))+
  theme(axis.text.y = element_text(face=""bold"", color=""white"", size=14))+
  theme(axis.title.y = element_text(margin = unit(c(0, 5, 0, 0), ""mm""), angle = 0)  )+


  labs(x="""",y=""Cases"",
       title=""Worldwide Covid-19 Cases Since the Start"",
       subtitle=""... stay safe out there ..."",
       caption=""Harry Royden McLaughlin - Source: ourworldindata.org \n Updated 04-11-2020"")


animate(a3,end_pause=40, nframes=350,fps=12)
save_animation(last_animation(), file=""C:\\Users\\xxx\\OneDrive\\Desktop"")
</code></pre>

<p>Image:
<a href=""https://i.stack.imgur.com/YylKG.png"" rel=""nofollow noreferrer"">Decimal Places in Offset Label</a></p>
"
60742316,"<p>I have a following reproducible example data for COVID-19 Confirmed cases. I want to convert the date given in columns to rows by replacing the columns name as ""confirmed cases"" by each country and Lat. (Sample type is given below)</p>

<pre><code>Lat &lt;- c(15,36,1.2833, 28.1667, 2.5,49.2827,-33.8688,-37.8136,-28.0167,11.55)
country &lt;- c(""Thailand"",""Japan"",""Singapore"",""Nepal"",""Malaysia"",""Canada"",""Australia"",""Australia"",""Australia"",""Cambodia"")

d1 &lt;- c(2,  2,  0,  0,  0,  0,  0,  0,  0,  0)
d2 &lt;- c(3,  1,  1,  0,  0,  0,  0,  0,  0,  0)
d3 &lt;- c(5,  2,  3,  0,  0,  0,  0,  0,  0,  0)
d4 &lt;- c(7,  2,  3,  1,  3,  0,  0,  0,  0,  0)

confirmed_covid19 &lt;- cbind(Lat,country,d1,d2,d3,d4)

colnames(confirmed_covid19)&lt;- c(""Lat"",""country"",""1/22/20"",""1/23/20"",""1/24/20"",  ""1/25/20"")
</code></pre>

<p>This give as follows:</p>

<p><a href=""https://i.stack.imgur.com/roXuj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/roXuj.png"" alt=""enter image description here""></a></p>

<p>However, I want if we can convert it as </p>

<p><a href=""https://i.stack.imgur.com/DjZXz.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/DjZXz.png"" alt=""enter image description here""></a></p>
"
61052970,"<p>I have the next plot</p>

<pre><code>ggplot(data=Predict_Fav, aes(x=Fecha, y=TotalCases)) +
  ggtitle(""Posibles Escenarios de Casos Infectados de COVID-19 en Reino Unido,              
Según Tasa de Crecimiento del 31 de Marzo al 6 de Abril del 2020"")+
  geom_line(aes(y=TotalCases),linetype = ""twodash"",color=""orange"")+
  geom_point(color=""black"")+
  geom_line(data=Data_UK7,linetype = ""twodash"",color=""black"")+
  geom_point(data= Data_UK7,  color=""black"")+
  geom_line(data=Predict,linetype = ""twodash"",color=""blue"")+
  geom_point(data= Predict,  color=""black"")+
  geom_line(data=Predict_Desfav,linetype = ""twodash"",color=""red"")+
  geom_point(data= Predict_Desfav,  color=""black"")+
  scale_x_date(date_breaks =""2 day"")+
  xlab(""Fecha"")+
  ylab(""Casos Confirmados Totales"")

</code></pre>

<p><a href=""https://i.stack.imgur.com/MmmT6.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/MmmT6.png"" alt=""enter image description here""></a></p>

<p>How I can put a legend with the corresponding color code, like this:
<a href=""https://i.stack.imgur.com/D3BEw.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/D3BEw.jpg"" alt=""enter image description here""></a></p>
"
61642142,"<p>Here is <a href=""https://github.com/ArtieLadie/covid"" rel=""nofollow noreferrer"">github repository</a></p>

<p>I wish to create single USA map that color-codes percent of COVID infections, and thickens state borders based on COVID deaths.</p>

<p>Here is my code to color-code map based on COVID infections. How do I thicken state border to show relative percent of COVID deaths?</p>

<p><strong>r-map.R</strong></p>

<pre><code>library(ggplot2)
library(choroplethr)
data(continental_us_states)


setwd(""C:/covid"")

# input the data
library(readr)
covid &lt;- read_csv(""covid_infection_rate.csv"")


# prepare the data
covid$region &lt;- tolower(covid$State)
covid$value &lt;- covid$CasesPercent



# create the map
state_choropleth(covid, 
                 num_colors=9,
                 zoom = continental_us_states) +
  scale_fill_brewer(palette=""YlOrBr"") +
  labs(title = ""COVID Infection Rate"",
       subtitle = ""2020 COVID % Infections"",
       caption = ""source: https://www.worldometers.info/coronavirus/country/us/"",
       fill = ""CasesPercent"") 
</code></pre>

<p><strong>Output</strong></p>

<p><a href=""https://i.stack.imgur.com/2uEjJ.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/2uEjJ.jpg"" alt=""enter image description here""></a></p>
"
60595119,"<p>I'm trying to clean up some data (<a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv</a>) regarding the COVID19 Novel Coronavirus to do various types of analysis (ie. create a chart of countries with 100 cases over time, or track the death-rate over time per country). I used data which had the dates as columns and countries as rows. I transposed the Dataframe so that I got a column for each country and a single column of dates as shown below.</p>

<p><a href=""https://i.stack.imgur.com/BKVce.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BKVce.png"" alt=""enter image description here""></a></p>

<p>I have attempted to read this dataframe in as a time series object through the following code:</p>

<pre><code>covid19ts = ts(covid19, frequency = 365, start = c(2020,22))
</code></pre>

<p>The result is the following. Instead of getting dates as my index column I get a number from 1 - 47 (the number of days recorded). This results in me being unable to create charts or do any meaningful analysis. </p>

<p><a href=""https://i.stack.imgur.com/IdeAw.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/IdeAw.png"" alt=""enter image description here""></a></p>

<p>I have also tried the following code using the lubridate package with the same results: </p>

<pre><code>covid19ts = ts(covid19, frequency = 365, start= decimal_date(as.Date(""2020-01-22"")))
</code></pre>

<p>How can I make my ts dates into the actual dates for charting and analysis?</p>

<p>Or is there a completely different approach I could be using which would be better for the analysis im trying to do?</p>

<p>Thank you for your help. </p>
"
60767142,"<p>I came across this article in <a href=""https://www.nytimes.com/interactive/2020/03/19/world/coronavirus-flatten-the-curve-countries.html?fbclid=IwAR3AvCLvEA4ZfqZUbp43nCs801j6VRFFL1pvV-t6H504Amxq7A0Kvi9UPvI"" rel=""nofollow noreferrer"">The New York Times</a> today about coronavirus and I liked how the graphs were presented. I know the bar plots can is just using geom_col() in ggplot but I am more interested in the smoothing part. Just like this graph: </p>

<p><a href=""https://i.stack.imgur.com/oLtci.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/oLtci.png"" alt=""enter image description here""></a></p>

<p>They said that ""each red line is the seven-day moving average, which smooths out day-to-day anomalies..."" How do you do that? I have a dataset that I plan to present it in a similar way. </p>

<p>Thanks!</p>
"
61232471,"<p>I have some time series data where there are a few region variables and the rest of the variable names are all dates. I am trying to trying to loop through the entire list of date variables and sum each of them but am unsure how to do it using dplyr syntax. This is what I have so far</p>

<pre><code>library(dplyr)
library(lubridate)
library(data.table)
library(curl)

# county level
covid_jhu &lt;- as.data.frame(fread(paste0(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv"")))

# remove territories and assign the correct FIPS code
covid_jhu &lt;- covid_jhu %&gt;%
  filter(Admin2 != """") %&gt;%
  mutate(FIPS = substr(as.character(UID), 4, 8))

jhu_state &lt;- covid_jhu %&gt;%
  group_by(Province_State) %&gt;%
  mutate(`1/22/20` = sum(`1/22/20`))
</code></pre>

<p>I can't seem to figure out the loop here even though I seem to be able to get it right for 1 variable.</p>
"
61238756,"<p>I've been seeing a lot of news outlets talking about a ""country X reporting its lowest number of new coronavirus cases since date Y"", so I wanted to try to do this in R, but I just can't figure out how.</p>

<p>Here's the data I have for Italy, for example:</p>

<pre><code>italy &lt;- tibble::tribble(
   ~country,   ~date, ~cases_day,
  ""Italy"", ""2020-03-16"", 3233L,
  ""Italy"", ""2020-03-17"", 3526L,
  ""Italy"", ""2020-03-18"", 4207L,
  ""Italy"", ""2020-03-19"", 5322L,
  ""Italy"", ""2020-03-20"", 5986L,
  ""Italy"", ""2020-03-21"", 6557L,
  ""Italy"", ""2020-03-22"", 5560L,
  ""Italy"", ""2020-03-23"", 4789L,
  ""Italy"", ""2020-03-24"", 5249L,
  ""Italy"", ""2020-03-25"", 5210L,
  ""Italy"", ""2020-03-26"", 6203L,
  ""Italy"", ""2020-03-27"", 5909L,
  ""Italy"", ""2020-03-28"", 5974L,
  ""Italy"", ""2020-03-29"", 5217L,
  ""Italy"", ""2020-03-30"", 4050L,
  ""Italy"", ""2020-03-31"", 4053L,
  ""Italy"", ""2020-04-01"", 4782L,
  ""Italy"", ""2020-04-02"", 4668L,
  ""Italy"", ""2020-04-03"", 4585L,
  ""Italy"", ""2020-04-04"", 4805L,
  ""Italy"", ""2020-04-05"", 4316L,
  ""Italy"", ""2020-04-06"", 3599L,
  ""Italy"", ""2020-04-07"", 3039L,
  ""Italy"", ""2020-04-08"", 3836L,
  ""Italy"", ""2020-04-09"", 4204L,
  ""Italy"", ""2020-04-10"", 3951L,
  ""Italy"", ""2020-04-11"", 4694L,
  ""Italy"", ""2020-04-12"", 4092L,
  ""Italy"", ""2020-04-13"", 3153L,
  ""Italy"", ""2020-04-14"", 2972L
  )
</code></pre>

<p>I want to create a column that tells me when was the last time the number of cases was below the one in the current line. So the desired result for the first 10 rows would be something like: </p>

<pre><code>tibble::tribble(
  ~country,        ~date, ~cases_day, ~minimum_since,
   ""Italy"", ""2020-03-16"",      3233L,             NA,
   ""Italy"", ""2020-03-17"",      3526L,   ""2020-03-16"",
   ""Italy"", ""2020-03-18"",      4207L,   ""2020-03-17"",
   ""Italy"", ""2020-03-19"",      5322L,   ""2020-03-18"",
   ""Italy"", ""2020-03-20"",      5986L,   ""2020-03-19"",
   ""Italy"", ""2020-03-21"",      6557L,   ""2020-03-20"",
   ""Italy"", ""2020-03-22"",      5560L,   ""2020-03-19"",
   ""Italy"", ""2020-03-23"",      4789L,   ""2020-03-18"",
   ""Italy"", ""2020-03-24"",      5249L,   ""2020-03-23"",
   ""Italy"", ""2020-03-25"",      5210L,   ""2020-03-23""
  )
</code></pre>

<p>I guess this could be done using something like accumulate? But I'm just stuck here. Thanks in advance for any help!</p>
"
61130384,"<p>I have the attached the image of the table and I want to filter the column 'title' based on the below search criteria.Title column contains text.</p>

<p><code>word=c('COVID','coronavirus disease 19','SARS-CoV-2','2019-nCoV','nCoV','coronavirus','wuhan pneumonia','Wuhan')</code></p>

<p>for searching a word I know I  can use </p>

<p><code>merged[grep(""COVID"",merged$Title),""Title""]</code>
or</p>

<p><code>sapply(words, grepl, merged$Title)  returns TRUE and FALSE. How to select the rows for which sapply is true.</code></p>

<p><a href=""https://i.stack.imgur.com/3OnuP.jpg"" rel=""nofollow noreferrer"">enter image description here</a></p>
"
61051410,"<p>I have a dataframe with data of the daily evolution of the coronavirus with 4 columns: date, active cases, deaths and recoveries. 
Since the sum of these 3 last values is equal to the total number of cases, I want a bar chart where each day has a corresponding bar divided in 3 parts: active cases, deaths and recoveries. 
How do I do this with ggplot? Thank you in advance</p>
"
60714074,"<p>I am trying to create an automatic pull in R using the <strong><em>GET</em></strong> function from the <strong><em>HTTR</em></strong> package for a csv file located on github.</p>

<p>Here is the table I am trying to download.</p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv</a></p>

<p>I can make the connection to the file using the following GET request:</p>

<pre><code>library(httr)

x &lt;- httr::GET(""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"")
</code></pre>

<p>However I am unsure how I then convert that into a dataframe similar to the table on github.</p>

<p>Any assistance would be much appreciated.</p>
"
61444852,"<p>Hi I am looking to see how to update the dataset for the <code>coronavirus</code> R-package. </p>

<p>How do I go about to that? </p>

<p>If I test out below, the latest date is February 16th:</p>

<pre><code>library(coronavirus)
data(coronavirus)
max(coronavirus$date)
[1] ""2020-02-16""
</code></pre>
"
61577238,"<p>How do I choose the date to access yesterday's information in the dataset that provides daily information.</p>

<pre class=""lang-r prettyprint-override""><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19-timeseries/master/countryReport/raw/rawReport.csv')
</code></pre>

<p>I am trying to print how many people died yesterday.</p>

<pre class=""lang-r prettyprint-override""><code>df1 &lt;- aggregate(death~countryName, subset(df, region ==""Europe""), sum)
</code></pre>

<p>collects this code every day and gives it. I don't want their sum. With which code can I find out how many people died the previous day?</p>
"
61593730,"<p><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19-timeseries/master/countryReport/raw/rawReport.csv')</code></p>

<p><code>df8 &lt;- read.csv ('https://raw.githubusercontent.com/hirenvadher954/Worldometers-Scraping/master/countries.csv')</code></p>

<p>In the 1st dataset, there are countries divided into continents.</p>

<p>In the second data set, there is country and population information.</p>

<p>How can I combine population information in data set 2 according to the continental information in data set 1.</p>

<p>thank you. The problem is that in the 1st dataset, countries are written on a continental basis. Countries and their populations in the second dataset. Do I need the population information of the continents? eg europe = 400 million, asia = 2.4 billion</p>
"
61575443,"<p>He says that the object ""europe"" could not be found. this is what I want to learn. To find the death numbers of the European countries only in the dataset. to show the country name and number of deaths in two columns.</p>

<p><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19-timeseries/master/countryReport/raw/rawReport.csv')</code></p>

<p><code>df1 &lt;- aggregate(death~countryName, subset(df, region ==""Europe""), sum)</code></p>

<p>I will ask. but I want to learn something. In the data set, the number of deaths is given for each day. the code you have created has collected every day. my wish is only deaths. The prefix is ​​enough to give the number of deaths of the day. He added the numbers of deaths everyday to date and added them. high figures.</p>

<p>not max. because he doesn't want the highest death. he wants to know how many died yesterday.</p>
"
61681420,"<pre><code>df &lt;- read.csv ('https://raw.githubusercontent.com/ulklc/covid19-timeseries/master/countryReport/raw/rawReport.csv',
                stringsAsFactors = FALSE)
</code></pre>

<p>I found this code which finds countries that reported the highest number of deaths and recovered by region were found in this code.</p>

<pre><code>    yesterday &lt;- function() Sys.Date() - 1L
    yesterday()
    # [1] ""if it doesn't work yesterday()-1  do it"" 

    library(tidyverse)
    death_df &lt;- df %&gt;%
    filter(as.Date(day) == yesterday()) %&gt;%
    group_by(region) %&gt;%
    filter(death == max(death)) %&gt;%
    select(Date = day,
         countryName,
         region,
         death,
         recovered)

     recovered_df &lt;- df %&gt;%
     filter(as.Date(day) == yesterday()) %&gt;%
    group_by(region) %&gt;%
    filter(recovered == max(recovered)) %&gt;%
    select(Date = day,
         countryName,
         region,
         death,
         recovered)

    full_df &lt;- bind_rows(death_df, recovered_df)
</code></pre>

<p>However, I need to find the countries that report the most death and recovered to the world in general.</p>

<p>Here is the output I am looking for:</p>

<pre><code>date            countryName       death        recovered
2020/05/06       united State   **19580**        500
2020/05/06       İran             11500        **98567**
</code></pre>

<p>Note that these values are not real.</p>

<p>The data set is updated daily. However, it may not have been updated for 1 -2 days. let's pay attention to this.</p>
"
61350887,"<p>I have a dataset labeled covid19india. I used a dataset to forecast the number of cases using the following code and got the graph as desired. I am ok up to this point, but need help in calculating the RMSE and plotting the ACF plot of residuals to theoretically show that the model is feasible. </p>

<pre><code>set1 &lt;- covid19india[1:36,]
df &lt;- set1[3]
tddf1 &lt;- ts(df$`Cumulative cases`)
fit1 &lt;- auto.arima(df$`Cumulative cases`, seasonal = FALSE)
forecast3 &lt;- forecast(fit1, h=9)
plot(forecast3)
par(new=TRUE)
plot(days, df1)
</code></pre>

<p>I need help in calculating the RMSE and residual ACF plot.</p>
"
60688676,"<p>In full disclosure I have asked a similar - but different - question about plotting in log-linear without restricting to the basic R plot function and using time series.</p>

<p>I have been able to get ALMOST what I am after, but in log base 10. I need base 2. Here is the code as is:</p>

<pre><code>require(RCurl)
require(foreign)
require(tidyverse)
x = getURL(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"")
corona = read.csv(text = x, sep ="","",header = T)
corona &lt;- corona %&gt;% 
  pivot_longer(cols = -c(`Province.State`, `Country.Region`, Lat, Long),
               names_to = ""date"",
               values_to = ""cases"")
corona &lt;- corona[,c(""Country.Region"",""date"",""cases"")]
corona &lt;- corona[!is.na(corona$cases), ]

Spain &lt;- corona[corona$Country.Region=='Spain',]
Spain &lt;- Spain[Spain$cases&gt;1,]
startDate &lt;- as.Date(""2020-02-09"")
xm &lt;- seq(startDate, by=""1 day"", length.out=nrow(Spain))
#plot(Spain$cases~xm, type='l', ylab=""No. Cov-19 cases"", xlab='', lwd=3, col=2,
#     main = ""No. Cov-19 in Spain"")


Italy &lt;- corona[corona$Country.Region=='Italy',]
Italy &lt;- Italy[(nrow(Italy)-nrow(Spain)+1):nrow(Italy),]
plot(Italy$cases~xm, type='l', ylab=""No. Cov-19 cases"", xlab='', lwd=3,
    log=""y"", col=2, las=2, 
    main = ""No. Cov-19 in Italy (red) v Spain (blue)"")

lines(Spain$cases~xm, type='l', ylab=""No. Cov-19 cases"", xlab='', lwd=3, col=4)
</code></pre>

<hr>

<p>Here is the plot I want to get but with the most recent data, which puts the maximum number of cases at the time of the writing at 17,660, and dates in the x axis:</p>

<p><a href=""https://i.stack.imgur.com/8cBe1.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/8cBe1.png"" alt=""enter image description here""></a></p>

<hr>

<p>Combo of both answers:</p>

<pre><code>require(RCurl)
require(foreign)
require(tidyverse) # To tip the df from long row of dates to cols (pivot_longer())
x = getURL(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"")

corona = (read_csv(x)
          %&gt;% pivot_longer(cols = -c(`Province/State`, `Country/Region`, Lat, Long),
                           names_to = ""date"",
                           values_to = ""cases"")
          %&gt;% select(`Country/Region`, date, cases)
          %&gt;% mutate(date=as.Date(date,format=""%m/%d/%y""))
          %&gt;% drop_na(cases)
          %&gt;% rename(country=""Country/Region"")
)

cc &lt;- (corona
       %&gt;% filter(country %in% c(""Italy"",""Spain"", ""Korea, South""))
)

ccw &lt;- (cc
        %&gt;% pivot_wider(names_from=""country"",values_from=""cases"")
        %&gt;% filter(cumsum(Italy&gt;0 | Spain&gt;0)&gt;=5)
)


plot(ccw$date, ccw$Italy, type=""l"", lwd=3,
        ylab='', 
        xlab='',
        log='y',
        col=5,
        axes=FALSE,
        main = ""Log-lin cumulative COVID-19 cases in Italy and Spain v South Korea"",
        cex.main=0.9)

at1 &lt;- seq(min(ccw$date), max(ccw$date)+1, by=3);
axis.Date(1, at=at1, format=""%b %d"", las=2, cex.axis=0.7)


at2 &lt;- 2^seq(1,30,by=1)
axis(side=2, at2, cex.axis=0.7)

abline(h=at2, lty=2, col=""grey90"")  # Add faint grid lines

lines(ccw$date, ccw$`Korea, South`, lwd=3, col=4, lty=3)
lines(ccw$date, ccw$Spain, lwd=3, col=2)

legend(ccw$date[1], 15000, legend=c(""Korea"", ""Italy"", ""Spain""),
       col=c(4, 5, 2), lty=c(3,1,1), lwd=3, cex=0.8,
       box.lty=0)
</code></pre>

<p><a href=""https://i.stack.imgur.com/wkF3S.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wkF3S.png"" alt=""enter image description here""></a></p>
"
60686752,"<p>Here is the base code, kudos to <a href=""https://stackoverflow.com/a/60685733/12329347"">this answer</a>:</p>

<pre><code>require(RCurl)
require(foreign)
x = getURL(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"")
corona = read.csv(text = x, sep ="","",header = T)
Italy &lt;- corona[corona$Country.Region=='Italy',][1,5:ncol(corona)]
library(xts)
plot(xts(unlist(Italy), 
         order.by = as.Date(sub(""X"", """", names(Italy)),""%m.%d.%y"")),
         ylim=c(0,20000), main=""Number Cov-19 Italy"")
</code></pre>

<p>Naturally I would like the values in the y axis to be the number of cases, as in <a href=""https://commons.wikimedia.org/wiki/File:Log-linear_plot_of_coronavirus_cases_with_linear_regressions.png"" rel=""nofollow noreferrer"">here</a>, but instead I get the actual log base 2 if I run something like:</p>

<pre><code>LogItaly &lt;- log2(Italy[,30:ncol(Italy)])
plot(xts(unlist(LogItaly), 
         order.by = as.Date(sub(""X"", """", names(LogItaly)),""%m.%d.%y"")),
     main=expression(paste(2^y, "" - Doubling of no. cases Cov-19 ITL"")), 
     ylim=c(0,16))
</code></pre>
"
60715055,"<p>I am trying to take a look and plot the number of cases of COVID19 each date in the US and China using the dataset in <a href=""https://coronavirus.jhu.edu/map.html"" rel=""nofollow noreferrer"">this Johns Hopkins website</a>. I got a <a href=""https://stackoverflow.com/a/60688941/12329347"">great answer here</a> as to how to get subset the data for a similar plot sampling three different countries, thanks to Ben Bolker:</p>

<pre><code>require(RCurl)
require(foreign)
require(tidyverse) # To tip the df from long row of dates to cols (pivot_longer())
x = getURL(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"")

corona = (read_csv(x)
          %&gt;% pivot_longer(cols = -c(`Province/State`, `Country/Region`, Lat, Long),
                           names_to = ""date"",
                           values_to = ""cases"")
          %&gt;% select(`Country/Region`, date, cases)
          %&gt;% mutate(date=as.Date(date,format=""%m/%d/%y""))
          %&gt;% drop_na(cases)
          %&gt;% rename(country=""Country/Region"")
)

cc &lt;- (corona
       %&gt;% filter(country %in% c(""Italy"",""Spain"", ""Korea, South""))
)

ccw &lt;- (cc
        %&gt;% pivot_wider(names_from=""country"",values_from=""cases"")
        %&gt;% filter(cumsum(Italy&gt;0 | Spain&gt;0)&gt;=5)
)
</code></pre>

<p>Unfortunately, this is much more complicated in the US, and possibly China, because there are many entries for the United States, depending on the column <code>Province/State</code>, which in the US would correspond to county and state. Hence, there is overcounting (on the one hand the cases in each state are entered in different rows, and in addition, the same numbers reappear in other rows, broken down by county).</p>

<p>I just managed to get the data for the US without duplicates using the function <code>state.name</code> as below, but I don't have a similar dataset with the names of the pertinent political geographic partitions of China.</p>

<p>Here is an example of the problem:</p>

<p><a href=""https://i.stack.imgur.com/Dh3Jj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Dh3Jj.png"" alt=""enter image description here""></a></p>

<blockquote>
  <p>How can avoid duplicating counts each day due to these overlapping rows - the fact that they didn't split in two columns the state and counties? </p>
</blockquote>

<p>Here is the working code for the US (China still pending):</p>

<pre><code>require(RCurl)
require(foreign)
require(tidyverse) # To tip the df from long row of dates to cols (pivot_longer())



x = getURL(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"")

corona = (read_csv(x)
          %&gt;% pivot_longer(cols = -c(`Province/State`, `Country/Region`, Lat, Long),
                           names_to = ""date"",
                           values_to = ""cases"")
          %&gt;% select(`Province/State`, `Country/Region`, date, cases)
          %&gt;% mutate(date=as.Date(date,format=""%m/%d/%y""))
          %&gt;% drop_na(cases)
          %&gt;% rename(country=""Country/Region"")
          %&gt;% rename(state=""Province/State"")
)

cc_with_states &lt;- corona[is.element(corona$state,state.name),]
cc &lt;- cc_with_states[,2:4]
us &lt;- aggregate(cc[ ,3], FUN=""sum"", by=list(as.Date(cc$date)))
cc[,2:3] &lt;- us 
cc &lt;- cc[1:nrow(us),]

ccw &lt;- (cc
        %&gt;% pivot_wider(names_from=""country"",values_from=""cases"")
        %&gt;% filter(US&gt;1)
)
</code></pre>
"
60878804,"<p>In the dataset below the variable <code>Region</code> before subsetting has the following structure:</p>

<pre><code>&gt; levels(corona$Region)
  [1] "" Montreal, QC""                              
  [2] ""Alabama""                                    
  [3] ""Alameda County, CA""                         
  [4] ""Alaska""                                     
  [5] ""Alberta""                                    
  [6] ""American Samoa""                             
  [7] ""Anhui"" ...
</code></pre>

<p>including both United States states as well as counties, and cities, etc.</p>

<p>I want to subset just the states in the United States running the code:</p>

<pre><code>require(RCurl)
require(foreign)
require(tidyverse) 

corona = read.csv(""https://coviddata.github.io/covid-api/v1/regions/cases.csv"", sep ="","",header = T)

cor &lt;- corona[corona$Country==""United States"" &amp; corona$Region %in% state.name,]
</code></pre>

<p>which works, in a way, but somehow keeps the original levels for <code>Region</code>:</p>

<pre><code>&gt; levels(cor$Region)
  [1] "" Montreal, QC""                              
  [2] ""Alabama""                                    
  [3] ""Alameda County, CA""                         
  [4] ""Alaska""                                     
  [5] ""Alberta""                                    
  [6] ""American Samoa""                             
  [7] ""Anhui""                                      
  [8] ""Arizona""                                    
  [9] ""Arkansas""                                   
 [10] ""Aruba""   ...
</code></pre>

<p>as though the subsetting never happened. How can I keep only the levels subsetted (the states)?</p>
"
61394554,"<p>I found this trick to set a session timeout: <a href=""https://stackoverflow.com/a/53207050/3720258"">https://stackoverflow.com/a/53207050/3720258</a>.
Unfortunately, it doesn't work anymore, and I have an API + Dashboard to explore official Covid Data in my country (<a href=""https://coronavirus.mat.uc.cl/"" rel=""nofollow noreferrer"">https://coronavirus.mat.uc.cl/</a>, <a href=""https://coronavirus-api.mat.uc.cl/"" rel=""nofollow noreferrer"">https://coronavirus-api.mat.uc.cl/</a>).</p>

<p>So far, I applied a CRON job in the meanwhile to restart shiny-server, at the expense that it closes active sessions. See how the memory is releases after closing all those inactive sessions:</p>

<p><a href=""https://i.stack.imgur.com/L1878.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/L1878.png"" alt=""enter image description here""></a></p>

<p>How can I enforce that sessions  that remain inactive for more than T seconds are automatically disconnected?</p>
"
60973672,"<p>I'm trying to create a set of time series plot for different areas and want to place them into a table, which is exactly the same as what New York Times has done in their article <a href=""https://www.nytimes.com/interactive/2020/world/coronavirus-maps.html"" rel=""nofollow noreferrer"">Coronavirus Map: Tracking the Global Outbreak</a> (a snapshot of <a href=""https://i.stack.imgur.com/x1u58.png"" rel=""nofollow noreferrer"">Coronavirus case by country</a>).</p>

<p>The approach I originally came up with is to use heatmaps where each row represents an area and each column represents a time stamp. But the output won't look as nice as NYTime's example. I'm wondering if anyone could give me a hint for improvement.</p>
"
60763006,"<p>I'm building an <a href=""https://lukaszpiwek.shinyapps.io/COVID19-EuropeCasesHeatmap/"" rel=""nofollow noreferrer"">interactive time-series heatmap in R</a> using Plotly and Shiny. As part of this process, I'm re-coding heatmap values from continuous to ordinal format - so I have a heatmap where six colours represent specific count categories, and those categories are created from aggregated count values. However, this causes a major performance issue with the speed of the creation of heatmap using <code>ggplotly()</code>. I've traced it to the <code>tooltip()</code> function from Plotly which renders interactive boxes. Labels data from my heatmap somehow overload this function in a way that it performs very slowly, even if I just add a single label component to the <code>tooltip()</code>. I'm using a processed subset of COVID-19 outbreak data from <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">Johns Hopkins CSSE repository</a>. Here is a simplified heatmap code, which also uses <a href=""https://nanx.me/ggsci/reference/pal_simpsons.html"" rel=""nofollow noreferrer"">The Simpsons colour theme from <code>ggsci</code></a>:</p>

<pre><code>#Load packages
library(shiny)
library(plotly)
library(tidyverse)
library(RCurl)
library(ggsci)

#Read example data from Gist
confirmed &lt;- read_csv(""https://gist.githubusercontent.com/GeekOnAcid/5638e37c688c257b1c381a15e3fb531a/raw/80ba9704417c61298ca6919343505725b8b162a5/covid_selected_europe_subset.csv"")

#Wrap ggplot of time-series heatmap in ggplotly, call ""tooltip""  
ggplot_ts_heatmap &lt;- confirmed %&gt;%
  ggplot(aes(as.factor(date), reorder(`Country/Region`,`cases count`), 
             fill=cnt.cat, label = `cases count`, label2 = as.factor(date), 
             text = paste(""country:"", `Country/Region`))) + 
  geom_tile(col=1) +
  theme_bw(base_line_size = 0, base_rect_size = 0, base_size = 10) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),legend.title = element_blank()) +
  scale_fill_manual(labels = levels(confirmed$cnt.cat),
                    values = pal_simpsons(""springfield"")(7)) +
  labs(x = """", y = """")
ggplotly(ggplot_ts_heatmap, tooltip = c(""text"",""label"",""label2""))
</code></pre>

<p>Performance improves once <code>tooltip = c(""text"",""label"",""label2"")</code> is reduced (for instance to <code>tooltip = c(""text"")</code>). Now, I know that delay is not ""massive"", but I'm integrating this with a Shiny app. And once it's integrated with Shiny and scaled with more data, it is really, really, really slow. I don't even show all variables in <code>tooltip</code> and its still slow - you can see it in <a href=""https://lukaszpiwek.shinyapps.io/COVID19-EuropeCasesHeatmap/"" rel=""nofollow noreferrer"">the current version of the app</a> when you click on 'confirmed' cases. </p>

<p>Any suggestions? I've considered  alternative interactive heatmap packages like <a href=""https://blog.rstudio.com/2015/06/24/d3heatmap/"" rel=""nofollow noreferrer""><code>d3heatmap</code></a>, <a href=""https://cran.r-project.org/web/packages/heatmaply/vignettes/heatmaply.html"" rel=""nofollow noreferrer""><code>heatmaply</code></a> and <a href=""https://cran.r-project.org/web/packages/shinyHeatmaply/index.html"" rel=""nofollow noreferrer""><code>shinyHeatmaply</code></a> but all those solutions are more intended for correlation heatmaps and they lack customisation options of <code>ggplot</code>.   </p>

<p><a href=""https://i.stack.imgur.com/FwrQD.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FwrQD.png"" alt=""enter image description here""></a></p>
"
61094915,"<p>I am new to Flutter. I wanted to get a request from a API from the website <a href=""https://rapidapi.com/"" rel=""nofollow noreferrer"">https://rapidapi.com/</a>. Please help me to translate the Python to Dart. </p>

<p>I am able to get the total data using the link  <code>https://covid-19-data.p.rapidapi.com/totals</code> in place of uri, but unable to get country data by passing the name of the country.</p>

<p><strong>This is a Python Code and i want this in Dart(Flutter)</strong></p>

<pre><code>import requests

url = ""https://covid-19-data.p.rapidapi.com/country""

querystring = {""format"":""undefined"",""name"":""italy""}

headers = {
    'x-rapidapi-host': ""covid-19-data.p.rapidapi.com"",
    'x-rapidapi-key': ""84768ddbd5mshe582f65a69666d5p1fea75jsn3a2b9202cc14""
    }

response = requests.request(""GET"", url, headers=headers, params=querystring)

print(response.text)
</code></pre>

<p><strong>This is what i did in Dart. I get the Error</strong> </p>

<p><code>{""type"":""https:\/\/tools.ietf.org\/html\/rfc2616#section-10"",""title"":""An error occurred"",""detail"":""Parameter name is missing""}</code></p>

<p>The Status Code is 400. </p>

<pre><code>import 'package:flutter/cupertino.dart';
import 'package:http/http.dart' as http;

class NetworkingBrain {
  NetworkingBrain({@required this.params});

  final params;

  Future&lt;void&gt; getData() async {
    try {
      var value = {'country1': params};
      var uri = Uri.parse('https://covid-19-data.p.rapidapi.com/country')
          .replace(queryParameters: value)
          .toString();

      http.Response response = await http.get(uri, headers: {
        'x-rapidapi-host': ""covid-19-data.p.rapidapi.com"",
        'x-rapidapi-key': ""84768ddbd5mshe582f65a69666d5p1fea75jsn3a2b9202cc14""
      });
      print(response.body);
      print(response.statusCode);
    } catch (e) {
      print(e);
    }
  }
}
</code></pre>

<p>Please help me with this.</p>
"
61497819,"<p>I'm learning about data scraping in Pyhton right now. And when I debug this program it seems to be fine, but when I run it I get an error in saving file. </p>

<p>What it does is, it collects tweets from twitter with the keyword COVID and it should save the file in a database. </p>

<p>Here's what I have right now:</p>

<pre><code>from tweepy import Stream
from tweepy import OAuthHandler
from tweepy.streaming import StreamListener
import json
import sqlite3
import re

import twitter_credentials

class SaveErrortoFile():
    """"""in progress""""""
    pass

class DbConnection():
    """"""in progress""""""
    pass

class MyStreamListener(StreamListener):
def __init__(self, track):
    self.track = track

def on_data(self, data):
    conn = sqlite3.connect('tweets1.db')
    c = conn.cursor()
    data = json.loads(data)
    _username = data['user']['screen_name']
    try:
        _message = data['text']
        _message = re.sub(r'@[\w]*', '', _message, flags=re.MULTILINE)
        _message = _message.replace('RT : ', '')
    except:
        _message = data['text']
    _language = data['user']['lang']
    _date = data['created_at']
    _creationAccountDate = data['user']['created_at']
    _profileImageUrl = data['user']['profile_image_url']
    _track = str(self.track)
    try:
        c.execute(
            '''INSERT INTO Tweets ('username','lang','track','profileImageUrl','date','creationAccountDate','message') VALUES (""''' + _username + '''"",""'''
            + _language + '''"",""''' +_track + '''"",""''' + _profileImageUrl + '''"",""''' +_date+'''"",""'''+_creationAccountDate + '''"",""'''+_message+'''"")''')
        conn.commit()
        conn.close()
        print('up')
    except Exception as _e:
        try:
            _error_file = open('error_file','a')
            _error_file.write('Error: ' + str(_e) +
            'Username: '+ _username +
            'Msg: '+ _message +
            'Lang: '+ _language +
            'Msg Date: '+ _date +
            'Create acnt date: '+ _creationAccountDate +
            'Profile picture: '+ _profileImageUrl)
        except:
            print('error with saving file')
    return(True)

def on_error(self, status_code):
    print(status_code)
    if status_code == 420:
        return False


auth = OAuthHandler(twitter_credentials.ckey, twitter_credentials.csecret)
auth.set_access_token(twitter_credentials.atoken, twitter_credentials.asecret)

twitterStream = Stream(auth, MyStreamListener('COVID'))
twitterStream.filter(track=['COVID'], is_async=True)
</code></pre>

<p>Alternatively, here's a link to the code: <a href=""https://pastecode.xyz/view/01f69f5f"" rel=""nofollow noreferrer"">https://pastecode.xyz/view/01f69f5f</a>
Any help is appreciated, thank you. </p>
"
61555581,"<p>i am new to r learning sentiment analysis using twitter tweets using R.
when i extract tweets in r they are in list class type but, then i need to convert them to dataframe to consider only one column with text type only because other types are irrelevant for my study like screenname, created, replyToSID, and others, and hence, i created dataframe and kept only one column with text. </p>

<p>but, when i convert the dataframe in list to further convert it into corpus for data cleaning using tm. i am getting output i expect in single list to do my study. below are my code lines..</p>

<pre><code>covid_tweets &lt;- searchTwitter('#COVID-19', n = 100, since = '2020-02-01')
options(stringsAsFactors = FALSE)

df_tweets &lt;- twListToDF(covid_tweets)
df_text_tweets &lt;- df_tweets[-c(2:16)]
View(df_text_tweets)

library(BBmisc)
data&lt;-convertRowsToList(df_text_tweets)
datacorpus &lt;- Corpus(VectorSource(data))

Covid_data&lt;-tm_map(datacorpus, stripWhitespace)
Covid_data&lt;-tm_map(Covid_data,tolower)
Covid_data&lt;-tm_map(Covid_data,removeNumbers)
Covid_data&lt;-tm_map(Covid_data,removePunctuation)
Covid_data&lt;-tm_map(Covid_data,removeWords, stopwords('english'))
</code></pre>

<p>output is not satisfactory.. when i use view function i can see 1 with 2 list i.e. content and metadata. 
I just want only text in the output in a list form..</p>

<p>if any further information needed please, free to ask me..or explain me how i simply convert the tweets into dataframe then to list followed by creating corpus and cleaning data using tm. Much appreciated in advance.</p>

<p>attached, the screenshots</p>

<p><a href=""https://i.stack.imgur.com/lzuCj.png"" rel=""nofollow noreferrer"">output of df tweets</a>
<a href=""https://i.stack.imgur.com/YEvdx.png"" rel=""nofollow noreferrer"">code i ran</a></p>
"
61118051,"<p>I am trying to clone my repository from GitHub to Rstudio, however, I get the error in Rstudio:</p>

<pre><code> &gt;&gt;&gt; C:/Program Files/Git/bin/git.exe clone --progress https://github.com/cheryltky/covid19 https://github.com/cheryltky/covid19
fatal: could not create leading directories of 'https://github.com/cheryltky/covid19': Invalid argument
</code></pre>

<p>I am new to Github and Rstudio and tried using other people's comments to solve this but I have no idea what the comments mean. I am using a windows laptop and would love to have some step through help with this error. Thanks!</p>
"
60930990,"<p>I am new to web scraping and been trying to scrape the right-hand side list of UK local authorities and the number of Covid-19 cases. </p>

<p>Here is the website:
<a href=""https://www.arcgis.com/apps/opsdashboard/index.html#/f94c3c90da5b4e9f9a0b19484dd4bb14"" rel=""nofollow noreferrer"">https://www.arcgis.com/apps/opsdashboard/index.html#/f94c3c90da5b4e9f9a0b19484dd4bb14</a></p>

<p>I have been able to scrape Wikipedia, but I don't have any idea where to start with the above website. Any tip/links would be very helpful and much appreciated!</p>
"
60777815,"<p>I am new to <strong>R</strong>. I was trying to generate a bar graph from WHO COVID19 dataset. I was able to see the graph but it seemed not accurately reflecting the actual data. Please take a look at my code and let me know where it went wrong. </p>

<p>Data: <a href=""https://covid.ourworldindata.org/data/ecdc/full_data.csv"" rel=""nofollow noreferrer"">Full dataset</a></p>

<p><img src=""https://i.stack.imgur.com/HqCaf.jpg"" alt=""new cases in 3 countries""></p>

<pre><code>#COVID 19

library(ggplot2)

library(tidyverse)

stats &lt;- read.csv(file.choose())

stats

dim(stats)

colnames(stats) &lt;- c(""date"",""location"",""new_cases"",""new_deaths"",""total_cases"",""total_deaths"")


ThreeCountries &lt;- subset(stats, location ==""United States"" | location ==""China"" | location ==""Italy"")

dim(ThreeCountries)

ggplot(ThreeCountries, aes(x=date, y=new_cases, fill = location)) + 
  geom_bar(stat=""identity"", position = ""dodge"")
</code></pre>
"
60728210,"<p>I'm wanting to plot the country vs a date range of exposures to COVID-19, as a learning tool in RStudio.</p>

<p>I've been trying to read the CSV and store as a dataframe, then plot via ggplot, but I think that I'm doing this incorrectly, since this is a date range.</p>

<p>How could I approach this to plot the infected countries to the dates, which increase daily in the header?</p>

<pre><code>| Province/State | 1/21/2020 22:00 | 1/22/2020 12:00 | 1/23/2020 12:00 | 1/24/2020 0:00 |...
|----------------|-----------------|-----------------|-----------------|----------------|
| Anhui          | 1               | 1               | 2               | 5              |...
| Beijing        | 1               | 1               | 3               | 4              |...
| Chongqing      | 2               | 4               | 5               | 6              |...
</code></pre>

<p>These cases are not accurate, just generated through MD to provide a table of data.</p>

<p>Thank you!</p>
"
60832006,"<p>I am new to R and I am currently learning how to plot with ggplot2. 
I downloaded some COVID-19 data and I am trying to create a plot where the x axis is the date and the y is the cases. </p>

<p><a href=""https://i.stack.imgur.com/ITuF7.png"" rel=""nofollow noreferrer"">Data frame</a></p>

<p>My code is given below:</p>

<pre><code>data&lt;- structure(list(date = structure(c(18344, 18343, 18341, 18340, 
18339, 18338, 18337, 18336, 18333, 18331, 18330, 18329, 18328, 
18325), class = ""Date""), cases = c(69L, 71L, 36L, 91L, 92L, 57L, 48L, 23L, 
252L, 75L, 7L, 8L, 3L, 3L)), class = ""data.frame"", row.names = 
c(1548L,1549L, 1551L, 1552L, 1553L, 1554L, 1555L, 1556L, 1559L, 1561L, 
1562L, 1563L, 1564L, 1567L))

library(ggplot2)

a&lt;- ggplot(data=data, aes(x=date, y=cases)) +
geom_point() +
geom_line()+
scale_x_date(date_breaks = ""1 day"", date_labels =  ""%d %b %Y"") +
theme(axis.text.x=element_text(angle=60, hjust=1)) 

a
</code></pre>

<p>Unfortunately, I am not able to make the line smooth (it appears as jagged from day to day), although I have tried to use the information I have seen on other posts. </p>

<p>I would appreciate any help :) Thanks </p>
"
60380622,"<p>I'm an old FOTRAN, C programmer trying to learn R. I started working with data on the COVID19 epidemic and have run aground. </p>

<p>The data I'm working with started out as wide data and I have converted it row data. It contains a daily case count of cases by ProvinceState, Region/Country, Lat, Long, Date, Cases.</p>

<p>I want to filter the dataframe for Mainland China and summarize cases by date as a first step.  The code below generates a NULL data set when I try to group the data.</p>

<p>Thanks for any help!</p>

<pre><code>library(dplyr)
library(dygraphs)
library(lubridate)
library(tidyverse) 
library(timeSeries)

# Set current working directory.
#
     setwd(""/Users/markmcleod/MarksRepository/Data"")

# Read a  Case csv files
#
     Covid19ConfirmedWideData &lt;- read.csv(""Covid19Deaths.csv"",header=TRUE,check.names = FALSE)

# count the number of days of data
#
    Covid19ConfirmedDays = NCOL(Covid19ConfirmedWideData)

# Gather Wide Data columns starting at column 5 until NCOL() into RowData DataFrame
#
    Covid19ConfirmedRowData &lt;- gather(Covid19ConfirmedWideData, Date, Cases, 5:Covid19ConfirmedDays, na.rm = FALSE, convert = TRUE)

    tibble(Covid19ConfirmedRowData)

    # # A tibble: 2,204 x 1
    # Covid19ConfirmedRowData$ProvinceState $CountryRegion  $Lat $Long $Date   $Cases
    # &lt;fct&gt;                                 &lt;fct&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;int&gt;
    #   1 Anhui                                 Mainland China  31.8  117. 1/22/20      0
    # 2 Beijing                               Mainland China  40.2  116. 1/22/20      0
    # 3 Chongqing                             Mainland China  30.1  108. 1/22/20      0

# Transmute date from chr to date
#
   Covid19ConfirmedFormatedData &lt;- transmute(Covid19ConfirmedRowData,CountryRegion,Date=as.Date(Date,format=""%m/%d/%Y""),Cases) 

   tibble(Covid19ConfirmedFormatedData)

   # # A tibble: 2,204 x 1
   # Covid19ConfirmedFormatedData$CountryRegion $Date      $Cases
   # &lt;fct&gt;                                      &lt;date&gt;      &lt;int&gt;
   #   1 Mainland China                             0020-01-22      0
   # 2 Mainland China                             0020-01-22      0


Covid19ConfirmedGroupedData  &lt;- Covid19ConfirmedFormatedData %&gt;%
  filter(Covid19ConfirmedFormatedData$CountryRegion=='Mainland China')

  tibble(Covid19ConfirmedGroupedData)

  # A tibble: 2,204 x 1
  Covid19ConfirmedGroupedData[,1]  [,2]  [,3]
  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
    1                              NA    NA    NA
</code></pre>
"
60999087,"<p>So I'm trying to render a reactive treemap in Shiny.</p>

<p>I have a 'pensions' DF with one row per person that looks like:</p>

<pre><code>set.seed(2)
Pensions &lt;- data.frame(ID = c(""21000"", ""23400"", ""26800"",""21076"", ""23490"", ""169800""),
                  Plan_Name = c(""Good Plan"", ""Great Plan"", ""Nice Plan"", ""Bad Plan"", ""Good Plan"", ""Great Plan""),
                  Benefit_Type = c(""DEFC"", ""DEFB"", ""DEFC"", ""COMBO"", ""DEFC"", ""DEFB""),
                  Members = c(43, 563, ""5"", ""12"", ""43"", ""563""))
</code></pre>

<p>Right now I'm making the treemap in a traditional way, where I'm counting ""Members"":</p>

<pre><code>treemap(Pensions, #Your data frame object
        index=c(""Benefit_Type""),  
        vSize = (""Members""), 
        type=""index"", 
        vColor = ""Benefit_Type"",
)
</code></pre>

<p><a href=""https://i.stack.imgur.com/mEP7l.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/mEP7l.png"" alt=""And getting this:""></a></p>

<p>It's skewed as hell because when I use <code>vSize = (""Members"")</code> I'm saying: ""sum the number of members by benefit type"". <strong>How can I instead <code>count(ID)</code>?</strong> FYI doing <code>vSize = count(""ID"")</code> doesn't work.</p>

<p>Probably a simple solution but these small variations always cross me up in R. I want to avoid setting a data.frame off my main DF to avoid one being updated while the other is not (if that makes sense).I'm starting from basic and scaling up but I eventually want this treemap from the World Banks' Covid-19 tracker:
<a href=""http://datatopics.worldbank.org/universal-health-coverage/covid19/"" rel=""nofollow noreferrer"">here</a>
<a href=""https://i.stack.imgur.com/wZMzb.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/wZMzb.png"" alt=""enter image description here""></a></p>

<p>Thanks everyone!</p>
"
61574003,"<p>I am relatively new to using R and have a JSON file with a facebook messenger chat history of interest.</p>

<p>I loaded the JSON with the code below which displays a list of 5 other nested lists. I am only interested in the 'messages' data hence I have isolated this into the variable 'messages'.</p>

<pre><code>json_file &lt;- ""/EXAMPLEFILEPATH/message_1.json""
JSON &lt;- fromJSON(file=json_file)

messages &lt;- JSON$messages
</code></pre>

<p>When printing messages to the console the output seperates each message into its own list. </p>

<pre><code>Example: 
 $ :List of 4
  ..$ sender_name : chr ""User1""
  ..$ timestamp_ms: num 1.59e+12
  ..$ content     : chr ""Just seeing how it was handled""
  ..$ type        : chr ""Generic""
</code></pre>

<p>I tried using dplyr to create a dataframe with the below code:</p>

<pre><code>messages %&gt;% 
  bind_rows() %&gt;%
    select(sender_name, timestamp_ms, content, reactions)

</code></pre>

<p>Unfortunately it throws this error. ""<strong>Error: Argument 4 must be length 1, not 4</strong>""</p>

<p>I tried limiting the list to see if I could narrow down what messages were causing the error and found that my code above worked perfectly when only including the first 17 observations/lists from 'messages'.</p>

<p>It seems that the 18th list in 'messages' has a different data structure to the rest because it's an image. (example of the difference between 17 and 18 at the end of this).</p>

<p>My dataframe works with the following code limiting the calculation to only the first 17 lists in 'messages'.</p>

<pre><code>messages &lt;- JSON$messages[1:17]

messages %&gt;% 
  bind_rows() %&gt;%
    select(sender_name, timestamp_ms, content, reactions)
</code></pre>

<p><strong>output:</strong></p>

<pre><code>sender_name        timestamp_ms content                                             reactions   
   &lt;chr&gt;                     &lt;dbl&gt; &lt;chr&gt;                                               &lt;list&gt;      
 1 User 1            1588369033388 Oh wow                                              &lt;NULL&gt;      
 2 User 2            1588338582569 haha.                                               &lt;NULL&gt;      
 3 User 3            1588338577484 https://www.indy100.com/article/coronavirus-nurses… &lt;named list…
</code></pre>

<p>For some reason when I include the 18th observation (or the entire list which is what i'm trying to process) the code doesn't work. </p>

<p>All of the available variables are:</p>

<pre><code> [1] ""sender_name""                    ""timestamp_ms""                  
 [3] ""content""                        ""type""                          
 [5] ""reactions.reaction""             ""reactions.actor""               
 [7] ""share.link""                     ""gifs.uri""                      
 [9] ""photos.uri""                     ""photos.creation_timestamp""     
[11] ""sticker.uri""                    ""videos.uri""                    
[13] ""videos.creation_timestamp""      ""videos.thumbnail.uri""          
[15] ""users.name""                     ""audio_files.uri""               
[17] ""audio_files.creation_timestamp""
</code></pre>

<p>I am trying create a data frame this using the above code but as i mentioned am getting the below error when trying to apply the code to all of the data (rather than just the first 17 observations):</p>

<p><em>""Error: Argument 4 must be length 1, not 4""</em></p>

<p>Any ideas on what I can include to accommodate the potential issues in observation 18 (and all differences thereafter)?</p>

<p>Thanks in Advance</p>

<hr>

<p>Difference in data from observation 17 to 18 - You can see that observation 18 seems to be an image with some data on 'reactions'</p>

<pre><code>[[17]]
[[17]]$sender_name
[1] ""User1""

[[17]]$timestamp_ms
[1] 1.588324e+12

[[17]]$content
[1] ""Did they tho""

[[17]]$type
[1] ""Generic""


[[18]]
[[18]]$sender_name
[1] ""User2""

[[18]]$timestamp_ms
[1] 1.588324e+12

[[18]]$photos
[[18]]$photos[[1]]
[[18]]$photos[[1]]$uri
[1] ""messages/inbox/squad_8SfnITzltg/photos/95500085_550504409210490_444682123345920000_n_550504399210491.jpg""

[[18]]$photos[[1]]$creation_timestamp
[1] 1588324427

[[18]]$reactions
[[18]]$reactions[[1]]
[[18]]$reactions[[1]]$reaction
[1] ""ð\u009f\u0091\u008d""

[[18]]$reactions[[1]]$actor
[1] ""User3""


[[18]]$reactions[[2]]
[[18]]$reactions[[2]]$reaction
[1] ""ð\u009f\u0098\u0086""

[[18]]$reactions[[2]]$actor
[1] ""User4""


[[18]]$reactions[[3]]
[[18]]$reactions[[3]]$reaction
[1] ""ð\u009f\u0098®""

[[18]]$reactions[[3]]$actor
[1] ""User5""


[[18]]$reactions[[4]]
[[18]]$reactions[[4]]$reaction
[1] ""ð\u009f\u0098\u0086""

[[18]]$reactions[[4]]$actor
[1] ""User6""

[[18]]$type
[1] ""Generic""
</code></pre>
"
60736817,"<p>please i want to get the table in this website into Rstudio :
""<a href=""https://www.worldometers.info/coronavirus/#countries"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/#countries</a>""</p>

<p>Am one month into learning R from scratch, this is what i have done:</p>

<pre><code>library(XML)     
library(rvest)
library(xml2)

url&lt;-(""https://www.worldometers.info/coronavirus/#countries"")

covid&lt;-readHTMLTable(url,which=1)

head(covid)
</code></pre>

<p>output error message</p>

<pre><code>url&lt;-(""https://www.worldometers.info/coronavirus/#countries"")
&gt; covid&lt;-readHTMLTable(url,which=1)
Error in (function (classes, fdef, mtable)  : 
  unable to find an inherited method for function ‘readHTMLTable’ for signature ‘""NULL""’
In addition: Warning message:
XML content does not seem to be XML: '' 
</code></pre>

<p>please i need help</p>
"
60840971,"<p>I'm trying to produce a choropleth map of county level data on COVID-19 infections using R.  I'm a relative newbie to R so....</p>

<p>I've done some fairly basic stuff with ggmap to plot spatial data, but never anything quite like this.  Typically I just have points of interest that I need to overlay on a map, so I can use geom_point and their lat/lon.  In this case I need to construct the underlying map and then fill regions and I'm struggling with doing that in the ggplot world.</p>

<p>I've followed some online examples I've found to get as far as this:</p>

<pre><code>library(ggplot2)
library(broom)
library(geojsonio)

#get a county level map geoJSON file
counties &lt;- geojson_read(""https://eric.clst.org/assets/wiki/uploads/Stuff/gz_2010_us_050_00_500k.json"", what = ""sp"")

#filter our alaska and Hawaii
lower48 &lt;- counties[(counties@data$STATE != ""02"" &amp; counties@data$STATE != ""15"") ,]

#turn it into a dataframe for ggmap
new_counties &lt;- tidy(lower48)

# Plot it
print(ggplot() +
  geom_polygon(data = new_counties, aes( x = long, y = lat, group = group), fill=""#69b3a2"", color=""white"") +
  theme_void() +
  coord_map())
</code></pre>

<p>Which produces this plot:</p>

<p><a href=""https://i.stack.imgur.com/UD9X0.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/UD9X0.jpg"" alt=""enter image description here""></a></p>

<p>So far so good.  But my new_counties dataframe now looks like this:</p>

<pre><code>head(new_counties)
# A tibble: 6 x 7
   long   lat order hole  piece group id  
  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;
1 -85.4  33.9     1 FALSE 1     0.1   0    
2 -85.4  33.9     2 FALSE 1     0.1   0    
3 -85.4  33.9     3 FALSE 1     0.1   0    
4 -85.4  33.9     4 FALSE 1     0.1   0    
5 -85.4  33.9     5 FALSE 1     0.1   0    
6 -85.4  33.8     6 FALSE 1     0.1   0 
</code></pre>

<p>So I've lost anything that I might be able to tie back to my county level data on infections.</p>

<p>My data has a 5-digit FIPS code for each county.  First two digits are the state and last three are the county.  My geoJSON file has a much more detailed FIPS code.  I tried grabbing just the first 5 and creating my own data element I could map back to</p>

<pre><code>library(ggplot2)
library(broom)
library(geojsonio)

#get a county level map geoJSON file
counties &lt;- geojson_read(""https://eric.clst.org/assets/wiki/uploads/Stuff/gz_2010_us_050_00_500k.json"", what = ""sp"")

#filter our alaska and Hawaii
lower48 &lt;- counties[(counties@data$STATE != ""02"" &amp; counties@data$STATE != ""15"") ,]

#add my own FIPS code
lower48@data$myFIPS &lt;- substr(as.character(lower48@data$GEO_ID),1,5)  

#turn it into a dataframe for ggmap
new_counties &lt;- tidy(lower48, region = ""myFIPS"")


# Plot it
print(ggplot() +
  geom_polygon(data = new_counties, aes( x = long, y = lat, group = group), fill=""#69b3a2"", color=""white"") +
  theme_void() +
  coord_map())
</code></pre>

<p>But that produces this plot</p>

<p><a href=""https://i.stack.imgur.com/9SDv2.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9SDv2.jpg"" alt=""enter image description here""></a></p>

<p>And I have to say I'm not quite familiar enough with broom::tidy to know exactly why.
I also notice as I type this that I need to filter out Puerto Rico!</p>

<p>If anybody can point me back in a useful direction....I'm not wedded to the current approach, though I would like to stick to ggplot2 or ggmap.  My boss eventually wants me to overlay certain features.  Ultimately the goal is to follow the example <a href=""https://rstudio-pubs-static.s3.amazonaws.com/315157_73b802e0532c4ea3839f98afc0378ca1.html#choropleth_maps"" rel=""nofollow noreferrer"">here</a> and produce an animated map showing data over time, but I'm obviously a long way from that.</p>
"
61684872,"<p>I'm new to <code>gganimate</code>. Great package. </p>

<p>I'm able to reproduce the package examples, but I'm struggling to render my actual use cases. I wonder if any <code>gganimate</code> users would be willing to determine if there is more efficient way to run this code. I've tried on my local machine and on RStudio Cloud. I've also tried plotting weekly data rather than daily data (so reducing the overall data by 6/7.</p>

<pre><code># load packages 
  library(tidyverse)
  library(sf)
  library(viridis)
  library(""rio"")

# get county geometry
  url &lt;- ""https://gist.githubusercontent.com/ericpgreen/717596c37478ef894c14b250477fae92/raw/c2cf4b273a2c7f0677f22a37b5e9f7e893204e3b/cali.R""
  cali &lt;- rio::import(url)

# get covid data
  covid &lt;- read.csv(""https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"", stringsAsFactors = FALSE)

# prep covid data
  covidPrepped &lt;-
  covid %&gt;%
  filter(state==""California"") %&gt;%
  select(date, fips, cases, deaths) %&gt;%
  mutate(date = lubridate::ymd(date)) %&gt;%
  mutate(fips = stringr::str_pad(fips, width=5, pad=""0"")) 

# make sure every county has a row for every day
  complete &lt;- 
  cali %&gt;%
  left_join(covidPrepped, by = c(""GEOID"" = ""fips"")) %&gt;%
  complete(GEOID, date, fill = list(cases = 0)) %&gt;%
  select(date, GEOID, cases)

# join back to geometry and construct casesPop
  pData &lt;- 
  complete %&gt;%
  left_join(select(cali, GEOID, NAME, estimate, geometry),
            by = ""GEOID"") %&gt;%
  st_as_sf() %&gt;%
  mutate(casesPop = (cases/estimate)*100000) %&gt;%
  mutate(casesPop = ifelse(is.na(casesPop), 0, casesPop)) %&gt;%
  mutate(group = cut(casesPop, 
                     breaks = c(0, 1, 3, 10, 30, 100, 
                                300, 1000, 3000, 10000, 
                                Inf),
                     labels = c(0, 1, 3, 10, 30, 100, 
                                300, 1000, 3000, 10000),
                     include.lowest = TRUE)
  ) %&gt;%
  mutate(month = lubridate::month(date, 
                                  label=TRUE, 
                                  abbr=TRUE),
         day = lubridate::day(date),
         monthDay = paste(month, day, sep="" "")) %&gt;%
  select(GEOID, geometry, group, monthDay) 

# animate
  ggplot(pData) +
  geom_sf(aes(fill = group), color = ""white"", size=.1) +
  scale_fill_viridis_d(option = ""magma"", drop=FALSE) +

  coord_sf(crs = 102003) +
  # on RStudio Cloud I got a CRS error with the line above
  # switching to the line below works
  #coord_sf(crs = ""+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=37.5 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80"", datum=NA) + 

  theme_minimal() + 
  theme(legend.position = ""top"",
        legend.box = ""horizontal"",
        legend.title = element_blank(),
        legend.justification='left') +
  guides(fill = guide_legend(nrow = 1)) +

# gganimate portion
  transition_states(monthDay,
                    transition_length = 4,
                    state_length = 1) +
  ease_aes('cubic-in-out') 
</code></pre>
"
61688229,"<pre><code>&gt; glimpse(mn)
Observations: 63
Variables: 5
$ date   &lt;dttm&gt; 2020-03-06, 2020-03-07, 2020-03-08, 2020-03-09, 2020-0…
$ state  &lt;chr&gt; ""Minnesota"", ""Minnesota"", ""Minnesota"", ""Minnesota"", ""Mi…
$ fips   &lt;dbl&gt; 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,…
$ cases  &lt;dbl&gt; 1, 1, 2, 2, 3, 5, 9, 14, 21, 35, 54, 60, 77, 89, 115, 1…
$ deaths &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1…
&gt; glimpse(events)
Observations: 7
Variables: 2
$ date  &lt;date&gt; 2020-03-06, 2020-03-13, 2020-03-15, 2020-03-16, 2020-03…
$ event &lt;chr&gt; ""First Cases Confirmed"", ""State of emergency Declared"", …
</code></pre>

<p>I created a plot for MN cases</p>

<pre><code>mn_plot &lt;- ggplot(mn, aes(x = date, y = cases)) +
  geom_line() +
  ggtitle(""COVID-19 Cases in Minnesota"") +
  xlab(""Date(2020)"") + 
  ylab(""Cases"")
</code></pre>

<p>Wanted to add some important dates, so I did this</p>

<pre><code>events &lt;- tribble(
  ~ date, ~ event,
  ""2020-03-06"", ""First Cases Confirmed"",
  ""2020-03-13"", ""State of emergency Declared"",
  ""2020-03-15"", ""Temporary shut down of schools"",
  ""2020-03-16"", ""All non-erssential businesses close"",
  ""2020-03-21"", ""First death recorded in MN"",
  ""2020-04-08"", ""Stay-at-Home Order Placed"",
  ""2020-04-30"", ""Stay-at-Home Order Extended"",
) %&gt;%
  mutate(date = as.Date(date))
</code></pre>

<p>Now I want to add the tribble I just made to my plot to show time stamps of when events happened.</p>

<pre><code>mn_plot +
  geom_vline(data = events, aes(xintercept = as.numeric(date)), linetype = ""dotted"")
</code></pre>

<p>My problem is that the vertical lines will not show up.</p>

<p>Here are the packages I am using:</p>

<pre><code>library(""readxl"")
library(dplyr)
library(ggplot2)
library(tidyverse)
library(scales)
library(lubridate)
</code></pre>
"
61441687,"<p>I want to find the class value for ali(öksürük=var,ateş=yok,halsizlik=var) using bayesian classification. The code below is working but I get </p>

<p>Warning messages:</p>

<p>1: naive_bayes(): Feature Öksürük - zero probabilities are present. Consider Laplace smoothing.    </p>

<p>2: naive_bayes(): Feature Ateş - zero probabilities are present. Consider Laplace smoothing.</p>

<p>3: naive_bayes(): Feature Halsizlik - zero probabilities are present. Consider Laplace smoothing. </p>

<pre><code>Öksürük&lt;-c(""Var"",""Yok"",""Yok"",""Yok"",""Var"",""Yok"",""Yok"",""Yok"",""Var"",""Yok"",""Var"")
Ateş&lt;-c(""Var"",""Var"",""Yok"",""Yok"",""Yok"",""Var"",""Yok"",""Var"",""Var"",""Var"",""Yok"")
Halsizlik&lt;-c(""Yok"",""Var"",""Yok"",""Var"",""Yok"",""Yok"",""Var"",""Var"",""Yok"",""Var"",""Var"")
COVID19&lt;-c(""POZİTİF"",""POZİTİF"",""POZİTİF"",""POZİTİF"",""NEGATİF"",""NEGATİF"",""NEGATİF"",""NEGATİF"",""NEGATİF"",""NEGATİF"","""")
df&lt;-data.frame(""Öksürük""=Öksürük,""Ateş""=Ateş,""Halsizlik""=Halsizlik,""COVID-19""=COVID19)     
nbfit&lt;-naivebayes::naive_bayes(df[1:10,1:3],df[1:10,4])
ali&lt;-predict(nbfit,df[11,1:3])
</code></pre>
"
61695615,"<p>I am trying to predict new dates using a model I have created.
The first question is to build a model to study the relationship b/w date and positive variable from 2020-03-16 to 2020-03-29. 
I have used below code: </p>

<pre><code>Covid = Covid[, c(1,3)]
head(Covid)
subset = Covid$date&gt;=""2020-03-16"" &amp; Covid$date &lt;= ""2020-03-29""`
Covid_sub = Covid[subset,]`
M1 = lm(positive ~ date, data = Covid_sub)
</code></pre>

<p>Then I needed to predict new dates using the model
the dates are 2020-03-30 to 2020-04-08
it's only 10 dates, but I'm always getting rows 11 -24. Is that correct and I just have to interpret data from the first 10 rows? Here is the code I used for it</p>

<pre><code>subset2 = Covid$date&gt;=""2020-03-30"" &amp; Covid$date &lt;= ""2020-04-08"" 
Covid_sub2 = Covid[subset2,]
predict(Covid = subset2,M1, interval = ""confidence"")

   fit        lwr       upr
11 115947.657  70520.579 161374.73
12 105766.435  61302.585 150230.29
13  95585.213  51940.289 139230.14
14  85403.991  42425.441 128382.54
15  75222.769  32750.860 117694.68
16  65041.547  22910.783 107172.31
17  54860.325  12901.174  96819.48
18  44679.103   2719.952  86638.25
19  34497.881  -7632.883  76628.65
20  24316.659 -18155.250  66788.57
21  14135.437 -28843.113  57113.99
22   3954.215 -39690.709  47599.14
23  -6227.007 -50690.857  38236.84
24 -16408.229 -61835.306  29018.85
</code></pre>

<p>Here is the data</p>

<pre><code>     date      positive
1   2020-04-08  423164
2   2020-04-07  392594
3   2020-04-06  361331
4   2020-04-05  332308
5   2020-04-04  305755
6   2020-04-03  271988
7   2020-04-02  239099
8   2020-04-01  210816
9   2020-03-31  184683
10  2020-03-30  160530
11  2020-03-29  139061
12  2020-03-28  118234
13  2020-03-27  99413
14  2020-03-26  80735
15  2020-03-25  63928
16  2020-03-24  51954
17  2020-03-23  42152
18  2020-03-22  31879
19  2020-03-21  23197
20  2020-03-20  17033
21  2020-03-19  11719
22  2020-03-18  7730
23  2020-03-17  5722
24  2020-03-16  4019
</code></pre>
"
60887187,"<p>I have analyzed current data (ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide) from the European Centre for Disease Prevention and Control that keeps track about COVID-19 cases across months and countries. This way I would like to gain insights about the spread of active cases, but also about the way they relate to deaths related to the disease. My goal: to create a variable that stores the percentage of deaths per total infections for every day in march, divided by countries. </p>

<p>Here is my code:</p>

<pre><code>library(readxl)
d &lt;- read_excel(""C:/Users/hanna/Downloads/COVID-19-geographic-disbtribution-worldwide.xlsx"")
#View(d)

corona_de &lt;- d %&gt;% filter(`Countries and territories` == ""Germany"" &amp; Month == 3)

# explore the data
library(skimr)
skim(corona_de)

library(ggplot2)
ggplot(corona_de, aes (x = Day, y = Cases)) +
  geom_line(color = ""red"")+ theme_classic()

# deutschland, england, spanien, italien, frankreich, österreich
corona &lt;- d %&gt;% filter(`Countries and territories` == ""Germany"" |
                      `Countries and territories` == ""France"" |
                      `Countries and territories` == ""Italy"" |
                      `Countries and territories` == ""Spain"") #filter for month later %&gt;% filter(Month == 3) 
#----------------------------------------------------------------
# Preprocess data and create cumulative and percent variables
#----------------------------------------------------------------
# format dates
library(lubridate)
corona$DateRep &lt;-as.Date(corona$DateRep,""%Y-%m-%d UTC"")
# store in list for later
dates &lt;- corona_march$DateRep
# store countries list to loop through
countries &lt;- unique(corona$`Countries and territories`)
#create empty objects
active_cases&lt;- NULL
deaths_cum &lt;- NULL
active_percent &lt;- NULL
death_percent &lt;- NULL

#loop through number of countries 
for (c in 1:4){
  current_country &lt;- subset(corona_march, `Countries and territories` == countries[c])
  # loop trhough days of march
  for (i in 25:1){
    # get new cases, deaths and population size for that day
    current_interval = current_country %&gt;% filter(DateRep &gt;= dates[i])
    current_case = current_interval %&gt;% select(Cases)
    current_death = current_interval %&gt;% select(Deaths)
    pop = current_country %&gt;% filter(DateRep == dates[i]) %&gt;% select(Pop_Data.2018)

    # calculate cumulative cases, deaths and percent active 
    active_cum = sum(current_case$Cases) 
    percent_active = active_cum / pop[[1]]
    cum_death = sum(current_death)
    # avoid scientific notation
    options(""scipen""=100, ""digits""=7)
    percent_death = cum_death / pop[[1]]

    # store variables in list
    active_cases &lt;- append(active_cases,active_cum)
    deaths_cum &lt;- append(deaths_cum,cum_death)
    active_percent &lt;- append(active_percent,percent_active)
    percent_death &lt;- append(death_percent, percent_death)
  }
}

</code></pre>

<p>Surprisingly, everything works fine except for the percent_death variable. For the cumulative deaths, the output looks like this:</p>

<pre><code>deaths_cum
  [1] 1098 1098 1098 1097 1096 1096 1093 1091 1090 1081 1070 1067 1052 1039 1021 1009  973
 [18]  952  925  856  728  650  538  426  240  149  149  149  149  149  149  149  149  149
 [35]  149  147  147  146  144  144  141  137  136  136  136  106  104   82   55   23 6799
 [52] 6791 6785 6768 6740 6713 6672 6623 6587 6454 6356 6189 5993 5804 5552 5379 5009 4662
 [69] 4315 3842 3413 2788 1993 1344  743 2696 2696 2696 2696 2696 2695 2693 2691 2691 2691
 [86] 2668 2661 2649 2612 2575 2560 2408 2387 2205 2098 1929 1694 1370  976  514
</code></pre>

<p>But for the <strong>percent_death</strong> variable, it seems to stop after 1 iteration:</p>

<pre><code>&gt; percent_death
[1] 0.00001100083
</code></pre>

<p>Any idea what happened? Why does the append function work for all of the variables except for small numbers? Is there a smarter way to do it?</p>
"
60995108,"<p>I've posted about the same question before here but the other thread is dying and I'm getting desperate.</p>

<p>I'm trying to scrape a webpage using rvest etc. Most of the stuff works but now I need R to loop trough a list of links and all it gives me is NA.</p>

<p>This is my code:</p>

<pre><code>install.packages(""rvest"")

site20min &lt;- read_xml(""https://api.20min.ch/rss/view/1"")

urls &lt;- site20min %&gt;% html_nodes('link') %&gt;% html_text()
</code></pre>

<p>I need the next one because the first two links the api gives me direct back to the homepage</p>

<pre><code>urls &lt;- urls[-c(1:2)]
</code></pre>

<p>If I print my links now it gives me a list of 109 links.</p>

<pre><code>urls
</code></pre>

<p>Now this is my loop. I need it to give me the first link of urls so I can read_html it </p>

<p>I'm looking for something like: ""<a href=""https://beta.20min.ch/story/so-sieht-die-coronavirus-kampagne-des-bundes-aus-255254143692?legacy=true"" rel=""nofollow noreferrer"">https://beta.20min.ch/story/so-sieht-die-coronavirus-kampagne-des-bundes-aus-255254143692?legacy=true</a>"". </p>

<p>I use break so it shows me only the first link but all I get is NA.</p>

<pre><code>for(i in i:length(urls)) {
  link &lt;- urls[i]
  break
} 
link
</code></pre>

<p>If I can get this far, I think I can handle the rest with rvest but I've tried for hours now and just ain't getting anywhere.</p>

<p>Thx for your help.</p>
"
60683271,"<p>I am trying simulate a plot like the picture, how can I make my plot's <strong>white text</strong> more readable like the picture below.</p>

<p>The picture I simulated:</p>

<p><a href=""https://i.stack.imgur.com/S05hD.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/S05hD.jpg"" alt=""enter image description here""></a></p>

<p>My plot:</p>

<p><a href=""https://i.stack.imgur.com/9Frvy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/9Frvy.png"" alt=""enter image description here""></a></p>

<p>My code:</p>

<pre><code># remotes::install_github(""GuangchuangYu/nCov2019"")
# get COVID-19 data
require(nCov2019)
y = load_nCov2019(lang = 'zh')
d = y['global']

# filter data
require(dplyr)

dd &lt;- filter(d, time == time(y) &amp; country != '中国') %&gt;% 
  arrange(desc(cum_confirm))

dd = dd[1:40, ]
dd$country = factor(dd$country, levels = dd$country)

dd$angle = 1:40*360/40

# plot data
require(ggplot2)

 ggplot(dd, aes(country, cum_confirm, fill = cum_confirm)) +
  geom_col(width = 1, color = 'grey90') +
  geom_col(aes(y = I(2)), width = 1, fill = 'white') +
  scale_y_log10()+
  scale_fill_gradientn(colours = c('darkgreen', 'green', 'orange', 'firebrick', 'red'), trans = 'log') +
  geom_text(aes(label = paste(country, cum_confirm, sep = '\n'),
                y = cum_confirm*0.8, angle = angle),
            data = function(d) d[d$cum_confirm &gt; 100,],
            color = 'white', fontface = 'bold', vjust = 1)+
  geom_text(aes(label = paste0(cum_confirm, "" "", country),
                y = cum_confirm*5, angle = angle + 90),
            data = function(d) d[d$cum_confirm &lt; 100,],
            vjust = 0) +
  coord_polar(direction = -1) +
  theme_void()+
  theme(legend.position = ""none"")



</code></pre>
"
61616524,"<p>I'm trying to run an extension of V3 of the Imperial College London COVID model (their github repo is here: <a href=""https://github.com/ImperialCollegeLondon/covid19model"" rel=""nofollow noreferrer"">https://github.com/ImperialCollegeLondon/covid19model</a>). The only things I've changed are adding data for the four large Canadian provinces to the data from the 14 European countries for which the model is built, and extending the forecast to 30 days into the future (the default is 7, but the code is designed to allow this kind of extension). </p>

<p>The core function of the model is to estimate expected daily death tolls based on country fixed effects and the interventions that are in place to slow down the virus. It also produces expected death tolls under a counterfactual scenario where no interventions are ever used (e.g. the only thing that affects death tolls is the predicted total infections and the infection fatality rate), in the generated quantities block of the stan code.</p>

<p>Every time I run it, though, I get warnings like these:</p>

<pre><code>1: In validityMethod(object) :
  The following variables have undefined values:  E_deaths0[128,18]. Many subsequent functions will not work correctly.
</code></pre>

<p>E_deaths0 refers to expected deaths given no mitigation interventions on day 128, the last day of the forecast, in region 18 (June 2 in Quebec, in this case). </p>

<p>the code for generating these estimates is</p>

<pre><code>E_deaths0[1, m]= 1e-15 * prediction0[1,m];
        for (i in 2:N2){
          E_deaths0[i,m] = ifr_noise[m] * dot_product(sub_col(prediction0, 1, m, i-1), tail(f_rev[m], i-1));
        }
</code></pre>

<p>Where prediction0[i, m] is the estimated infections on day i in country m, N2 being the total number of days to estimate (128). ifr_noise[m] is a modifier for the infection fatality rate in country m, and f_rev[m] is a vector of probabilities of dying on each day after being infected. There's no reason any of the elements that go into calculating E_deaths0 would ever be NA, and while prediction0 is estimated at 0 in a lot of samples for late dates and the later values of f_rev[m] round to 0, that doesn't seem like it should cause a problem because no division is happening.</p>

<p>This happens for different geographies each time. The dates also vary, although it's always the last n days of the simulation in a given region, with n between 1 and 8 or so. I assume the problem is in <code>sub_col(prediction0, 1, m, i-1)</code>, because <code>f_rev[m]</code> is data, so there's no potential for sampling issues, and if <code>ifr_noise[m]</code> were taking NA values then all dates for geography m would fail. I don't see how, though, because prediction0 is generated immediately before E_deaths0 and never causes warnings.</p>

<p>When I extract predictions of E_deaths0[128,18] or whichever estimates have problems in that run from the model fit, there are as many samples as I'd expect and they're all in a plausible range. I'm not sure whether I can trust those results, though, when the process to generate them throws random warnings.</p>

<p>Anybody have experience with issues like this, or any ideas? Thanks.  </p>
"
61004817,"<p><a href=""https://i.stack.imgur.com/im4C8.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/im4C8.png"" alt=""enter image description here""></a>
<a href=""https://i.stack.imgur.com/p9uPu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/p9uPu.png"" alt=""enter image description here""></a></p>

<p>When I select a date to plot my data, it plots for all dates, causing the bubbles in the plot to overlap. In my file input, all dates are in the same column. My code follows below, could anyone solve this problem, please?</p>

<p>My file csv is in 
<a href=""https://github.com/igorcobelo/covid19nodf/blob/master/data2.csv"" rel=""nofollow noreferrer"">https://github.com/igorcobelo/covid19nodf/blob/master/data2.csv</a></p>

<pre><code>library(tidyverse)
library(osmdata)
library(viridis)
library(htmlwidgets)
library(plotly)
library(ggplot2)
library(shiny)
library(lubridate)


data2&lt;-read.table(""data2.csv"", header=T,sep="";"")

data2 &lt;- data2 %&gt;%
    arrange(Casos) %&gt;%
    mutate(name = factor(name, unique(name)), mytext = paste(
                                                        ""RA: "", name, ""\n"", 
                                                        ""Casos: "", Casos, sep="""")) %&gt;%
    mutate(""data"" = ydm(data))

datas &lt;- unique(data2$data)


#ruas
streets &lt;- getbb(""Distrito Federal Brazil"") %&gt;%
            opq() %&gt;%
            add_osm_feature(key = ""highway"", 
                            value = c(""motorway"", ""primary"", 
                          ""secondary"", ""tertiary"")) %&gt;%
            osmdata_sf()

link&lt;-tags$a(href=""http://www.saude.df.gov.br/informativos-do-centro-de-operacoes-de-emergencia-coe/"", ""Boletins Epidemiologicos do Centro de Operacoes de Emergencia da Secretaria de Saude do Distrito Federal"")


ui &lt;- basicPage(

    tags$h1(""Covid-19""),
    tags$h3(""Mapa dos casos confirmados no DF""),
    hr(),
    dateInput(""datas"", ""Data""),
    plotlyOutput(""myplot""),
    tags$div(
        tags$p(""Fonte:"",link))
)
?tags

server &lt;- function(input, output, session) {

    dat &lt;- reactive(data2[1:input$data,])

    output$myplot &lt;- renderPlotly({
        streets$osm_lines %&gt;% 
            ggplot() + 
            geom_sf(inherit.aes = FALSE,
                    color = ""#7fc0ff"",
                    size = .4,
                    alpha = .8) + 
            coord_sf(xlim = c(-48.28579, -47.30839),
                     ylim = c(-16.05056, -15.50018),
                     expand = FALSE) + 
            theme_void() + 
            theme(legend.title = element_text(colour=""white""), 
                  legend.text = element_text(colour=""white""),
                  plot.background = element_rect(fill = ""#282828"")) + 
            geom_point(data = data2,aes(x=long, y=lat, size=Casos, color=Casos, text=mytext, alpha=0.5)) +
            scale_size_continuous(range=c(1,15)) + 
            scale_color_viridis(option=""plasma"") -&gt; p

        ggplotly(p,tooltip=""text"")

        })
}



shinyApp(ui, server)
</code></pre>
"
61298437,"<p>I'm working on a dataframe which has 4 features, <code>County</code>, <code>State</code>, # COVID <code>cases</code>, and <code>date</code>. I want to add a column which calculates the number of days since the lowest date value for that county. I found a way to do it, but it requires a for loop and takes way too long to execute considering there are over 60k rows. I'm confused if and how I can calculate this in a vectored way so it takes a reasonable about of time. </p>

<pre><code>daysSinceFirstCase &lt;- function (x) {
    # create vector the length of the row count 
    vals &lt;- 1:nrow(x)

    # for each row 
    for(i in 1:nrow(x)) {
        row &lt;- x[i, ]
        # get occurrences of that county and state
        countyCases &lt;- x[x$county == row$county &amp; x$state == row$state,]

        # get first date
        firstDate &lt;- countyCases[order(countyCases$date),]$date[1]

        #calculate difference
        diff &lt;- as.integer(row$date - firstDate)

        #store difference
        vals[i] &lt;- diff 
        print(i)
    }
    return(vals)
}
df['days_since_first_case'] &lt;- daysSinceFirstCase(df)
</code></pre>

<p><strong>Edit: Here's an example of my data and the column I am trying to create.</strong> </p>

<pre><code>Date       |  County      | State | Cases | Days since first case 
2020-03-14 | Philadelphia | PA    | 500   | 0
2020-03-15 | Philadelphia | PA    | 892   | 1
2020-03-16 | Philadelphia | PA    | 1502  | 2
2020-03-22 | Baltimore    | MD    | 12    | 0
2020-03-23 | Baltimore    | MD    | 152   | 1
2020-03-24 | Baltimore    | MD    | 348   | 2
</code></pre>
"
61198792,"<p>Trying to plot total cases of covid19 at the country level with a histogram of daily new cases to show a sustained drop in new cases leads to a 'flattening of the curve' (assuming that is the case).</p>

<pre><code>library(tidyverse)

#clean raw data source
c19 = read_csv(""https://raw.githubusercontent.com/datasets/covid-19/master/data/time-series-19-covid-combined.csv"") %&gt;% 
  mutate(Cases = Confirmed) %&gt;% 
  mutate(Country = `Country/Region`) %&gt;%
  select(Date, Country, Cases, Deaths) %&gt;%
  group_by(Date, Country) %&gt;%
  summarise(Cases = sum(Cases),
            Deaths = sum(Deaths)) %&gt;%
  ungroup() %&gt;%
  group_by(Country) %&gt;%
  mutate(Lagged_Cases = ifelse(is.na(lag(Cases)), 0, lag(Cases))) %&gt;%
  mutate(NewCases = Cases - Lagged_Cases) %&gt;%
  mutate(IndexDate = ifelse(Lagged_Cases == 0 &amp; Cases &gt; 0, 1, ifelse(Lagged_Cases &gt; 0, 2, 0))) %&gt;%
  filter(IndexDate &gt; 0) %&gt;%
  mutate(Index = row_number()) %&gt;%
  ungroup() %&gt;%
  select(-IndexDate) %&gt;%
  filter(Country %in% c(""US"",""Korea, South"",""Sweden"")) %&gt;%
  inner_join(data.frame(Country = c(""US"",""Korea, South"",""Sweden""),
                        Pop = c(328000000,51245707,10230000)))

c19 %&gt;%
  ggplot() +
  geom_line(aes(x=Index, y=Cases/1000, color=Country), size=2) +
  geom_histogram(aes(x=Index, y=NewCases/75, group=Country), stat=""identity"", alpha=.4) + 
  #scale_y_continuous(sec.axis = sec_axis(~./data$Cases)) +
  facet_wrap(vars(Country), scales=""free_y"") +
  ggtitle(""Flattening The Curve?"") +
  xlab(""Days Since First Case"") +
  ylab(""Total Cases (thousands) - Daily New Cases (not to scale)"")
</code></pre>

<p><a href=""https://i.stack.imgur.com/T7bJy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/T7bJy.png"" alt=""enter image description here""></a></p>
"
61662827,"<p>I'm trying to create an animation with ggplot using COVID-19 data from <a href=""https://raw.githubusercontent.com/datasets/covid-19/master/data/countries-aggregated.csv"" rel=""nofollow noreferrer"">here</a>. I use the <code>ne_countries()</code> function from the <code>rnaturalearth</code> package to add sfc data to the COVID-19 dataset. </p>

<p>The COVID-19 dataset has a row for each country for each day so when I add the sfc data, I obviously have the sfc data for each country multiple times in the data frame. When I then animate the data using the code below, it's re-plotting the sfc polygons for every frame so it's taking ages. </p>

<p>Is there a way I can just plot the sfc polygons once and then animate on top of that?</p>

<pre><code>plot_anim = ggplot(data = dat) +
  geom_sf(aes(geometry = geometry, fill = Confirmed_cases)) +
  transition_manual(as.factor(Date))

animate(plot_anim, renderer = gifski_renderer(loop = TRUE))
</code></pre>
"
61639535,"<p>I'm trying to make a bubble plot of deaths in the US. I'm new to shiny, so forgive me if this is obvious. </p>

<p>Current Outcome: 
Warning: Error in : <code>data</code> must be a data frame, or other object coercible by <code>fortify()</code>, not an S3 object with class reactiveExpr/reactive.</p>

<pre><code>#-------------------------------------------------------------------------------
# Data for USA
#-------------------------------------------------------------------------------

get_us_map_data &lt;- function(chosen_states) {

  state_map &lt;- us_map(regions = ""states"")


  # location of state capitals
  state_capitals &lt;- maps::us.cities %&gt;%
    filter(capital == 2) %&gt;%
    select(long, lat, name, country.etc) %&gt;%
    usmap_transform() %&gt;%
    select(x = long.1, y = lat.1, state_abbr = country.etc)

  # Join the state capitals with state deaths per capita
  deaths &lt;- covidtracking %&gt;%
    group_by(state) %&gt;%
    filter(date == max(date)) %&gt;%
    ungroup() %&gt;%
    left_join(select(census_state_pop, GEOID, POP),
              by = c(""fips"" = ""GEOID"")) %&gt;%
    mutate(deaths_per_1M = 1e6 * deaths / POP) %&gt;%
    select(state_abbr, deaths)

  bubble_data &lt;- left_join(state_capitals, deaths, by = ""state_abbr"")

}

#-------------------------------------------------------------------------------
# USA chart
#-------------------------------------------------------------------------------

plot_us_deaths_map &lt;- function(df) {

  p3 &lt;- ggplot() +
        geom_polygon(aes(x = x, y = y, group = group),
                     color = ""black"", fill = ""white"",
                     data = df) +
        geom_point(aes(x = x, y = y, size = deaths),
                   fill = scales::muted(""red""), alpha = 0.5, pch = 21,
                   data = bubble_data) +
        scale_size_area(name = ""Deaths per 1M capita"", max_size = 24) +
        coord_equal() + theme_map() + theme(legend.position = ""bottom"")

  # Return the plot
  p3
}



ui &lt;- fluidPage(
sidebarLayout(
               sidebarPanel(
                 checkboxGroupInput(""chosen_states"", ""Which states would you like to include?"", states, selected = states),

               ),

               mainPanel(

                 plotOutput(""us_map_plot"")
               )

             )
)

server &lt;- function(input, output, session) {
 # Reactive data for plot
  USA_data &lt;- reactive({
    get_us_map_data(input$chosen_states)
  })

  #Render US map
  output$us_map_plot &lt;- renderPlot({
    plot_us_deaths_map(USA_data)
  })
}

shinyApp(ui, server)
</code></pre>
"
60992611,"<p>I am unable to publish an update to my app on shinyapps.io. When I try to publish from RStudio, I get the following deployment message:</p>

<pre><code>Preparing to deploy application...DONE
Uploading bundle for application: 2018028...DONE
Deploying bundle: 2959131 for application: 2018028 ...
Error: HTTP 409
POST https://api.shinyapps.io/v1/applications/2018028/deploy
Unable to dispatch task for application=2018028, there are 1 tasks in progress
Execution halted
</code></pre>

<p>Clicking the link gives the error: <code>{""error"": ""Method Not Allowed""}</code></p>

<p>I have tried to publish the app about 10 times over the last hour, hoping that the error would go away, but have not had any luck. Thankfully the app has remained operational, here: <a href=""https://gopalpenny.shinyapps.io/covid19/"" rel=""nofollow noreferrer"">https://gopalpenny.shinyapps.io/covid19/</a></p>

<p>I have tried to Archive the app from the shinyapps.io Dashboard, but I get a similar message: <code>Unable to dispatch task for application=2018028, there are 1 tasks in progress</code>. I can't seem to find this task anywhere within the dashboard. </p>

<p>I have also tried stopping and starting the Instance from the Dashboard, but that has not made a difference.</p>

<p>Any suggestions for what I can try next?</p>

<p><strong>EDIT</strong> 
One note that I forgot to mention is that before getting this error, I had attempted to deploy the app and the deploy process seemed to hang. After 15 minutes, I stopped that deployment and tried again, at which point I received this error.</p>
"
61373144,"<p>I am trying to create a plot in SQL Server R using the <strong>sp_execute_external_script</strong> command, but it fails to create the plot png image:</p>

<pre><code>DECLARE @stateName nvarchar(50) = 'Michigan'
EXEC sp_execute_external_script
 @language = N'R',
 @script = N'
    covidWeeklyDataSet &lt;- InputDataSet
    # set up report file for chart
    reportfile &lt;- ""C:\\temp\\Covid19-Weekly.png""
    png(file = reportfile)
    plot(x = covidWeeklyDataSet[, 1], y = covidWeeklyDataSet[, 2],
        main = paste(state_name, ""Weekly Covid 19 Counts"", sep = """"),
        col = 3, ylab = ""Cases"", xlab = ""Dates"", ylim = c(0, 35000))
    par(new = TRUE)
    plot(x = covidWeeklyDataSet[, 1], y = covidWeeklyDataSet[, 3],
         col = 2, ylab = ""Cases"", xlab = ""Dates"", ylim = c(0, 35000))
    dev.off()
 ',
 @input_data_1 = N'SELECT [date], cases, deaths FROM #weekly',
 @params = N'@state_name nvarchar(20)',
 @state_name = @stateName
</code></pre>

<p>The error message is as follows:</p>

<blockquote>
  <p>Msg 39004, Level 16, State 20, Line 13 A 'R' script error occurred
  during execution of 'sp_execute_external_script' with HRESULT
  0x80004004. Msg 39019, Level 16, State 2, Line 13 An external script
  error occurred:  Error in png(file = reportfile) : unable to start
  png() device Calls: source -> withVisible -> eval -> eval -> png In
  addition: Warning messages: 1: In png(file = reportfile) :   unable to
  open file 'C:\temp\Covid19-Weekly.png' for writing 2: In png(file =
  reportfile) : opening device failed</p>
  
  <p>Error in execution.  Check the output for more information. Error in
  eval(ei, envir) :    Error in execution.  Check the output for more
  information. Calls: runScriptFile -> source -> withVisible -> eval ->
  eval -> .Call Execution halted</p>
</blockquote>

<p>It also fails as an administrator.  Please help.</p>
"
61196132,"<p>I'm trying to get data from this external data source and display it in my app locally and in production, and since requesting the data fresh every time can be resource-intensive, I want to cache it for a relative amount of time which could be 15 minutes, 1 hour, etc. I wrote this code, but it doesn't show any kind of caching at all.</p>

<p>covid_controller.rb</p>

<pre><code>require ""net/http""
class Covid19::CovidController &lt; ApplicationController
  def index
    @covid_news_posts = CovidNewsPost.published.limit(10).order(""created_at DESC"").includes([:user])
    cache_key_with_version = CovidNewsPost.last
        @cache = Rails.cache.fetch(""#{cache_key_with_version}"", expires_in: 15.minutes) do
            covid_api_url = ""https://bing.com/covid/data""
            resp = Net::HTTP.get_response(URI.parse(covid_api_url))
            covidapi = JSON.parse(resp.body)
        end
  end
end
</code></pre>

<p>production.rb</p>

<pre><code>  ## CACHING RELATED THINGS
  config.action_controller.perform_caching = true

  # Use a different cache store in production.
  config.cache_store = :memory_store, { size: 64.megabytes }
</code></pre>

<p>development.rb</p>

<pre><code>  # Enable/disable caching. By default caching is disabled.
  if Rails.root.join('tmp/caching-dev.txt').exist?
    config.action_controller.perform_caching = true

    config.cache_store = :memory_store
    config.public_file_server.headers = {
      'Cache-Control' =&gt; ""public, max-age=#{2.days.seconds.to_i}""
    }
  else
    config.action_controller.perform_caching = false

    config.cache_store = :null_store
  end
</code></pre>

<p>Not sure what to do here, just want to load the request server side once and then serve it cached for however long is needed.</p>

<p>Here's a request from production not showing any caching</p>

<pre><code>I, [2020-04-13T20:46:40.057029 #2088]  INFO -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9] Started GET ""/covid19"" for 71.113.156.118 at 2020-04-13 20:46:40 +0000
I, [2020-04-13T20:46:40.060499 #2088]  INFO -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9] Processing by Covid19::CovidController#index as HTML
D, [2020-04-13T20:46:40.063881 #2088] DEBUG -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   User Load (0.7ms)  SELECT  ""users"".* FROM ""users"" WHERE ""users"".""id"" = $1 ORDER BY ""users"".""id"" ASC LIMIT $2  [[""id"", 1], [""LIMIT"", 1]]
D, [2020-04-13T20:46:40.065930 #2088] DEBUG -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   CovidNewsPost Load (0.6ms)  SELECT  ""covid_news_posts"".* FROM ""covid_news_posts"" ORDER BY ""covid_news_posts"".""id"" DESC LIMIT $1  [[""LIMIT"", 1]]
I, [2020-04-13T20:46:40.458451 #2088]  INFO -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   Rendering layouts/application.html.erb
I, [2020-04-13T20:46:40.458928 #2088]  INFO -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   Rendering covid19/covid/index.html.erb within layouts/application
I, [2020-04-13T20:46:40.460280 #2088]  INFO -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   Rendered covid19/_covid19_menu.html.erb (0.3ms)
D, [2020-04-13T20:46:40.462798 #2088] DEBUG -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   CovidNewsPost Load (1.7ms)  SELECT  ""covid_news_posts"".* FROM ""covid_news_posts"" WHERE ""covid_news_posts"".""published"" = $1 ORDER BY created_at DESC LIMIT $2  [[""published"", true], [""LIMIT"", 10]]
D, [2020-04-13T20:46:40.465690 #2088] DEBUG -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   User Load (0.9ms)  SELECT ""users"".* FROM ""users"" WHERE ""users"".""id"" IN ($1, $2, $3, $4, $5, $6)  [[""id"", 251], [""id"", 3], [""id"", 860], [""id"", 208], [""id"", 1985], [""id"", 2794]]
I, [2020-04-13T20:46:40.476577 #2088]  INFO -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   Rendered static/global/_footer.html.erb (1.6ms)
I, [2020-04-13T20:46:40.476792 #2088]  INFO -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   Rendered covid19/covid/index.html.erb within layouts/application (17.8ms)
I, [2020-04-13T20:46:40.477422 #2088]  INFO -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   Rendered application/_favicon.html.erb (0.4ms)
I, [2020-04-13T20:46:40.478655 #2088]  INFO -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9]   Rendered layouts/application.html.erb (20.1ms)
I, [2020-04-13T20:46:40.479248 #2088]  INFO -- : [aee0a42a-0d29-432d-af0e-0f21bb5253d9] Completed 200 OK in 419ms (Views: 18.4ms | ActiveRecord: 3.9ms)
</code></pre>
"
61416516,"<p>I have a fairly long R script that produces a bunch of charts.  I'm hoping this is a fairly easy questions whose answer is independent of the exact data...</p>

<p>As an example, one of the plots is drawn by</p>

<pre><code>natPlot &lt;- smNatData %&gt;% 
  ggplot(mapping = aes(x = as.numeric(DaysSince), y = infRate)) +
  geom_line(aes(color=abbv, linetype=abbv),show.legend = FALSE) +
  geom_point(data = NatEndpoints,size = 1.5,shape = 21,
             aes(color = Base,fill = Base), show.legend = FALSE) +
  geom_label_repel(data=NatEndpoints, aes(label=Base), show.legend = FALSE) +
  labs(x = ""Days Since First Confirmed Case"", 
       y = ""% Local Population Infected"", 
       title = ""Infection rate of COVID-19, AFMC States vs National"", 
       subtitle = paste(""Data as of"", format(max(smData$infected), ""%A, %B %e, %y"")), 
       caption = ""HQ AFMC/A9A - Data: usafacts.org"") +
  theme(plot.title = element_text(size = rel(1), face = ""bold""),
        plot.subtitle = element_text(size = rel(0.7)),
        plot.caption = element_text(size = rel(1))) +
  facet_zoom(xy = Base != 'Massachusetts')
</code></pre>

<p>That produces this plot</p>

<p><a href=""https://i.stack.imgur.com/GbXCy.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/GbXCy.png"" alt=""enter image description here""></a></p>

<p>Which is fine...except that I've been asked to make all of the lines ""solid"".  Is there a one-line way to force that?  Right now I have <code>linetype=abbv</code> in the geom_line aes()...</p>

<p>I've seen some solutions that look like</p>

<pre><code>scale_linetype_manual(values=c(""twodash"", ""dotted""))+
scale_color_manual(values=c('#999999','#E69F00'))
</code></pre>

<p>but I'd rather not have to manually specify all 10 lines...</p>
"
60837509,"<p>I am using r to study the Covid19 case and death data. I am programmatically gathering Johns Hopkins <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">data</a> from GitHub to do my analysis. However, the data are updated periodically and for my analysis it is useful to know when that last update happened. I saw some solutions on how to do this using languages that I don't use (such as <a href=""https://stackoverflow.com/questions/50194241/get-when-the-file-was-last-updated-from-a-github-repository"">Curl / JQ</a> and <a href=""https://stackoverflow.com/questions/29877783/github-last-commit"">C#</a>). How can I do this with r? In case it matters, the repository contains a small number of files and the file I'm studying is one of a few that is updated approximately daily. </p>

<p>Here is a MWA of the code that gets the file I need. I would like to build on this to get the last change date. </p>

<pre><code>library(httr) 
text_confirmed = GET(""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"")
df_confirmed &lt;- content(text_confirmed, type = ""text/csv"", encoding=""UTF-8"")
</code></pre>
"
61146967,"<p>I am trying to learn how to collect data from the Web into R. There's a website from Brazilian Ministery of Health that is sharing the numbers of the disease here in Brazil, it is a public portal. </p>

<p><a href=""https://covid.saude.gov.br/"" rel=""nofollow noreferrer"">COVIDBRASIL</a></p>

<p>So, on this page, I am interested in the graph that displays the daily reporting of cases here in Brazil. Using the inspector on Google Chrome I can access the JSON file feeding the data to this chart, my question is how could I get this file automatically with R. When I try to open the JSON in a new tab outside the inspector ""Response"" tab, I get an ""Unauthorized"" message. There is any way of doing this or every time I would have to manually copy the JSON from the inspector and update my R script?</p>

<p><a href=""https://i.stack.imgur.com/oiBzx.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/oiBzx.png"" alt=""enter image description here""></a></p>

<p>In my case, I am interested in the ""PortalDias"" response. Thank you.</p>

<p><a href=""https://xx9p7hp1p7.execute-api.us-east-1.amazonaws.com/prod/PortalDias"" rel=""nofollow noreferrer"">URL PORTAL DIAS</a></p>
"
61194639,"<p><a href=""https://i.stack.imgur.com/WeolF.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/WeolF.png"" alt=""enter image description here""></a></p>

<p>As you can see the equals symbol is not being displayed correctly.</p>

<p>My full code is here:</p>

<pre><code>---
title: ""Something""
author: ""Murpholinox Peligro""
date: ""11 abril 2020""
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r}
# Carga paquetes
library(ggplot2)
library(latex2exp)
```

```{r}
# Carga los datos limpios
smalldf &lt;- read.csv(""~/Repos/plotcovid19mx/smalldf.csv"")
# Crea una gráfica base
p&lt;-ggplot(data = smalldf, aes(x=days, y=y2)) + geom_point()
```

```{r}
# Crea el modelo exponencial
model = nls(y2 ~ a * exp(b*days), data=smalldf, start = list(a=0.67, b=0.16))
# Imprime información del modelo
summary(model)
# Agrega el ajuste con los parámetros del modelo
p +
  stat_smooth(method = 'nls', formula = y ~ a * exp(b * x), se=FALSE,
              method.args = list(start = list(a = 0.67, b = 0.16))) +
# la ecuación de la exponencial,
      annotate(""label"", x=5, y=30, label=TeX('$y  =  0.67  e^{0.16  x }$')) +
# los títulos necesarios,
  ylab(""y"") + xlab(""x"") +  ggtitle(""Something"") +
# Cambia el tema base 
  theme_classic(base_size = 15)
   ```
</code></pre>

<p>This only happens if I click on Knit -> HTML document. If I do Knit -> PDF document, there is no problem. I am not sure if this is related to <code>knitr</code> or <code>ggplot2</code> or <code>latex2exp</code>. Data is <a href=""https://raw.githubusercontent.com/murpholinox/plotcovid19mx/master/nice.csv"" rel=""nofollow noreferrer"">here</a>.</p>

<p>Ps. Stackoverflow did not let me to put my data here. Says it is a lot of code.</p>

<p>Thanks a lot</p>
"
60730549,"<p>I am a beginner on rust but I am really interested to try to do the same simulation from <a href=""https://www.washingtonpost.com/graphics/2020/world/corona-simulator/?fbclid=IwAR3ytZqDZGErvX7KSDWUn3WUg8N0bkWQtWOzr7aMs0YAHAnNDWtQ-PJuVok"" rel=""nofollow noreferrer"">Washington Post</a> about how coronavirus spreads.</p>

<p>My idea is to create the same simulation in Rust language in order to translate this content into my mother tongue and to create more scenarios.</p>

<p>I would like to know some information before getting into this project.</p>

<ul>
<li><p>Can I use jupyter with rust? (apparently this <a href=""https://github.com/google/evcxr"" rel=""nofollow noreferrer"">https://github.com/google/evcxr</a> is what I am looking for but I would like a confirmation.)</p></li>
<li><p>Is it possible to export to HTML the jupyter notebooks with rust? (apparently, yes)</p></li>
<li><p>Can I create some animations or just static content (and export to HTML)?</p></li>
<li><p>Is it possible to have animations just with WASM? Can I compile to javascript (and still have the animation)?</p></li>
<li><p>What are the crates to create plots and animations?</p></li>
</ul>

<p>Thanks</p>
"
60977814,"<p>I set up a dash app to visualize the <a href=""http://www.corona.fabianbosler.de"" rel=""nofollow noreferrer"">development of COVID-19 Infections in Germany</a> over time on a Google virtual machine running Ubuntu 18.04. </p>

<p>The app is based on three docker container:</p>

<ol>
<li>The app itself served by gunicorn (on Port 5000)</li>
<li>NGINX container (does the translation from 80 -> 443 -> 5000)</li>
<li>Certbot container (to acquire and renew SSL certificates)</li>
</ol>

<p>Now my problem is, no matter what I do, the app I get served is a fairly outdated version of the app (data exactly as when I first deployed it. Up until March 28). I tried changing the source data to include newer, but also to include fewer data and did not see any change whatsoever. I also tried changing the Nginx-settings around proxy_buffers, proxy_buffer_size, proxy_buffering, but to no avail. </p>

<p>This leads me to believe that I am getting served a cached app. I tried different browser/machines/devices which leads me to believe that the caching happens server-side.</p>

<p>I am not very familiar with Nginx nor Gunicorn nor Dash for that matter. But what I find very strange is that the results seemed to be cashed, even after <code>docker-compose up</code> and <code>down</code> multiple times.</p>

<p>What am I missing here?</p>

<p>Find the repo <a href=""https://github.com/FBosler/COVID-19-CONTAINERDEPLOY"" rel=""nofollow noreferrer"">here</a>:</p>

<p>based on the following <code>docker-compose</code> file:</p>

<pre><code>version: '3.7'

services:
  web:
    build: ./services/web
    command: gunicorn --bind 0.0.0.0:5000 wsgi:app
    expose:
      - 5000

  nginx:
    image: nginx:1.17-alpine
    restart: unless-stopped
    volumes:
      - ./data/nginx:/etc/nginx/conf.d
      - ./data/certbot/conf:/etc/letsencrypt
      - ./data/certbot/www:/var/www/certbot
    ports:
      - ""80:80""
      - ""443:443""
    depends_on:
      - web
    command: ""/bin/sh -c 'while :; do sleep 6h &amp; wait $${!}; nginx -s reload; done &amp; nginx -g \""daemon off;\""'""

  certbot:
    image: certbot/certbot
    restart: unless-stopped
    volumes:
      - ./data/certbot/conf:/etc/letsencrypt
      - ./data/certbot/www:/var/www/certbot
    entrypoint: ""/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h &amp; wait $${!}; done;'""
</code></pre>
"
60868897,"<p>I'm using this script to generate a file with commit dates</p>

<pre><code>cat .github/workflows/header.md &gt; ""COVID 19/fechas.md""
git ls-tree -r --name-only HEAD COVID\ 19/*.csv | while read filename; do
    date=$(git log -1 --format=""%aD"" -- ""$filename"")
    echo ""| $date  | $filename |"" &gt;&gt;  ""COVID 19/fechas.md""
done
git config --global user.email ""jjmerelo@gmail.com""
git config --global user.name ""FechaActionBot""
git add ""COVID 19/fechas.md""
git commit -m ""Fichero de fechas generado""
</code></pre>

<p>In this <a href=""https://github.com/JJ/datasets/blob/master/.github/workflows/fechas.yml"" rel=""nofollow noreferrer"">GitHub Action</a>, which checks out the code and runs above as a script.</p>

<p>No matter what I use as format (commiter or author date), I get <a href=""https://github.com/JJ/datasets/blob/master/COVID%2019/fechas.md"" rel=""nofollow noreferrer"">the same result</a>, which shows the same date (the current one) for all files.</p>
"
61202944,"<p>I've deployed a registry service into a namespace <code>registry</code>:</p>

<pre><code>$ helm install registry stable/docker-registry
</code></pre>

<p>Service:</p>

<pre><code>$ kubectl get service
NAME                       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
registry-docker-registry   ClusterIP   10.43.119.11   &lt;none&gt;        5000/TCP   18h
</code></pre>

<p>this is my <code>skaffold.yaml</code>:</p>

<pre><code>apiVersion: skaffold/v2beta1
kind: Config
metadata:
  name: spring-boot-slab
build:
  artifacts:
  - image: skaffold-covid-backend
    kaniko:
      dockerfile: Dockerfile-multistage
      image: gcr.io/kaniko-project/executor:debug
      cache: {}
  cluster: {}
deploy:
  kubectl:
    manifests:
    - k8s/*
</code></pre>

<p>Everything works fine, up to when kaniko is trying to push the image to above registry:</p>

<blockquote>
  <p><code>Get ""http://registry-docker-registry.registry.svc.cluster.local:5000/v2/"": dial tcp: lookup registry-docker-registry.registry.svc.cluster.local on 127.0.0.53:53: no such host</code></p>
</blockquote>

<p>Skaffold command is:</p>

<pre><code>$ skaffold build --default-repo=registry-docker-registry.registry.svc.cluster.local:5000 
</code></pre>

<p>This is the log:</p>

<pre><code>$ skaffold build --default-repo=registry-docker-registry.registry.svc.cluster.local:5000 
INFO[0000] Skaffold &amp;{Version:v1.7.0 ConfigVersion:skaffold/v2beta1 GitVersion: GitCommit:145f59579470eb1f0a7f40d8e0924f8716c6f05b GitTreeState:clean BuildDate:2020-04-02T21:49:58Z GoVersion:go1.14 Compiler:gc Platform:linux/amd64} 
DEBU[0000] validating yamltags of struct SkaffoldConfig 
DEBU[0000] validating yamltags of struct Metadata       
DEBU[0000] validating yamltags of struct Pipeline       
DEBU[0000] validating yamltags of struct BuildConfig    
DEBU[0000] validating yamltags of struct Artifact       
DEBU[0000] validating yamltags of struct ArtifactType   
DEBU[0000] validating yamltags of struct KanikoArtifact 
DEBU[0000] validating yamltags of struct KanikoCache    
DEBU[0000] validating yamltags of struct TagPolicy      
DEBU[0000] validating yamltags of struct GitTagger      
DEBU[0000] validating yamltags of struct BuildType      
DEBU[0000] validating yamltags of struct ClusterDetails 
DEBU[0000] validating yamltags of struct DeployConfig   
DEBU[0000] validating yamltags of struct DeployType     
DEBU[0000] validating yamltags of struct KubectlDeploy  
DEBU[0000] validating yamltags of struct KubectlFlags   
INFO[0000] Using kubectl context: k3s-traefik-v2        
DEBU[0000] Using builder: cluster                       
DEBU[0000] setting Docker user agent to skaffold-v1.7.0 
Generating tags...
 - skaffold-covid-backend -&gt; DEBU[0000] Running command: [git describe --tags --always] 
DEBU[0000] Command output: [c5dfd81
]                   
DEBU[0000] Running command: [git status . --porcelain]  
DEBU[0000] Command output: [ M Dockerfile-multistage
 M skaffold.yaml
?? k8s/configmap.yaml
?? kaniko-pod.yaml
?? run_in_docker.sh
] 
registry-docker-registry.registry.svc.cluster.local:5000/skaffold-covid-backend:c5dfd81-dirty
INFO[0000] Tags generated in 3.479451ms                 
Checking cache...
DEBU[0000] Found dependencies for dockerfile: [{pom.xml /tmp true} {src /tmp/src true}] 
 - skaffold-covid-backend: Not found. Building
INFO[0000] Cache check complete in 3.995675ms           
Building [skaffold-covid-backend]...
DEBU[0000] getting client config for kubeContext: ``    
INFO[0000] Waiting for kaniko-rjsn5 to be initialized   
DEBU[0001] Running command: [kubectl --context k3s-traefik-v2 exec -i kaniko-rjsn5 -c kaniko-init-container -n registry -- tar -xf - -C /kaniko/buildcontext] 
DEBU[0001] Found dependencies for dockerfile: [{pom.xml /tmp true} {src /tmp/src true}] 
DEBU[0001] Running command: [kubectl --context k3s-traefik-v2 exec kaniko-rjsn5 -c kaniko-init-container -n registry -- touch /tmp/complete] 
INFO[0001] Waiting for kaniko-rjsn5 to be complete      
DEBU[0001] unable to get kaniko pod logs: container ""kaniko"" in pod ""kaniko-rjsn5"" is waiting to start: PodInitializing 
DEBU[0002] unable to get kaniko pod logs: container ""kaniko"" in pod ""kaniko-rjsn5"" is waiting to start: PodInitializing 
DEBU[0000] Getting source context from dir:///kaniko/buildcontext 
DEBU[0000] Build context located at /kaniko/buildcontext 
DEBU[0000] Copying file /kaniko/buildcontext/Dockerfile-multistage to /kaniko/Dockerfile 
DEBU[0000] Skip resolving path /kaniko/Dockerfile       
DEBU[0000] Skip resolving path /kaniko/buildcontext     
DEBU[0000] Skip resolving path /cache                   
DEBU[0000] Skip resolving path                          
DEBU[0000] Skip resolving path                          
DEBU[0000] Skip resolving path                          
INFO[0000] Resolved base name maven:3-jdk-8-slim to maven:3-jdk-8-slim 
INFO[0000] Resolved base name java:8-jre-alpine to java:8-jre-alpine 
INFO[0000] Resolved base name maven:3-jdk-8-slim to maven:3-jdk-8-slim 
INFO[0000] Resolved base name java:8-jre-alpine to java:8-jre-alpine 
INFO[0000] Retrieving image manifest maven:3-jdk-8-slim 
DEBU[0003] No file found for cache key sha256:53ce0b73ff3596b4feb23cd8417cf458276fd72464c790c4f732124878e6038f stat /cache/sha256:53ce0b73ff3596b4feb23cd8417cf458276fd72464c790c4f732124878e6038f: no such file or directory 
DEBU[0003] Image maven:3-jdk-8-slim not found in cache  
INFO[0003] Retrieving image manifest maven:3-jdk-8-slim 
INFO[0005] Retrieving image manifest java:8-jre-alpine  
DEBU[0007] No file found for cache key sha256:6a8cbe4335d1a5711a52912b684e30d6dbfab681a6733440ff7241b05a5deefd stat /cache/sha256:6a8cbe4335d1a5711a52912b684e30d6dbfab681a6733440ff7241b05a5deefd: no such file or directory 
DEBU[0007] Image java:8-jre-alpine not found in cache   
INFO[0007] Retrieving image manifest java:8-jre-alpine  
DEBU[0009] Resolved /tmp/target/*.jar to /tmp/target/*.jar 
DEBU[0009] Resolved /app/spring-boot-application.jar to /app/spring-boot-application.jar 
INFO[0009] Built cross stage deps: map[0:[/tmp/target/*.jar]] 
INFO[0009] Retrieving image manifest maven:3-jdk-8-slim 
DEBU[0011] No file found for cache key sha256:53ce0b73ff3596b4feb23cd8417cf458276fd72464c790c4f732124878e6038f stat /cache/sha256:53ce0b73ff3596b4feb23cd8417cf458276fd72464c790c4f732124878e6038f: no such file or directory 
DEBU[0011] Image maven:3-jdk-8-slim not found in cache  
INFO[0011] Retrieving image manifest maven:3-jdk-8-slim 
DEBU[0012] Resolved pom.xml to pom.xml                  
DEBU[0012] Resolved /tmp/ to /tmp/                      
DEBU[0012] Getting files and contents at root /kaniko/buildcontext for /kaniko/buildcontext/pom.xml 
DEBU[0012] Using files from context: [/kaniko/buildcontext/pom.xml] 
DEBU[0012] optimize: composite key for command COPY pom.xml /tmp/ {[sha256:53ce0b73ff3596b4feb23cd8417cf458276fd72464c790c4f732124878e6038f COPY pom.xml /tmp/ 7176510dcac61a3d406beab8d864708f21db23201dba11185866015a8dcd55b0]} 
DEBU[0012] optimize: cache key for command COPY pom.xml /tmp/ fc6a0ec8876277261e83ab9b647595b1df258352ba9acf92ec19c761415fb23e 
INFO[0012] Checking for cached layer registry-docker-registry.registry.svc.cluster.local:5000/skaffold-covid-backend/cache:fc6a0ec8876277261e83ab9b647595b1df258352ba9acf92ec19c761415fb23e... 
INFO[0012] Using caching version of cmd: COPY pom.xml /tmp/ 
DEBU[0012] optimize: composite key for command RUN mvn -B dependency:go-offline -f /tmp/pom.xml -s /usr/share/maven/ref/settings-docker.xml {[sha256:53ce0b73ff3596b4feb23cd8417cf458276fd72464c790c4f732124878e6038f COPY pom.xml /tmp/ 7176510dcac61a3d406beab8d864708f21db23201dba11185866015a8dcd55b0 RUN mvn -B dependency:go-offline -f /tmp/pom.xml -s /usr/share/maven/ref/settings-docker.xml]} 
DEBU[0012] optimize: cache key for command RUN mvn -B dependency:go-offline -f /tmp/pom.xml -s /usr/share/maven/ref/settings-docker.xml 18ffc2eda5a9ef5481cc865da06e9a4e3d543bf9befb35bd7ac3cb9dc3b62fc7 
INFO[0012] Checking for cached layer registry-docker-registry.registry.svc.cluster.local:5000/skaffold-covid-backend/cache:18ffc2eda5a9ef5481cc865da06e9a4e3d543bf9befb35bd7ac3cb9dc3b62fc7... 
INFO[0012] Using caching version of cmd: RUN mvn -B dependency:go-offline -f /tmp/pom.xml -s /usr/share/maven/ref/settings-docker.xml 
DEBU[0012] Resolved src to src                          
DEBU[0012] Resolved /tmp/src/ to /tmp/src/              
DEBU[0012] Using files from context: [/kaniko/buildcontext/src] 
DEBU[0012] optimize: composite key for command COPY src /tmp/src/ {[sha256:53ce0b73ff3596b4feb23cd8417cf458276fd72464c790c4f732124878e6038f COPY pom.xml /tmp/ 7176510dcac61a3d406beab8d864708f21db23201dba11185866015a8dcd55b0 RUN mvn -B dependency:go-offline -f /tmp/pom.xml -s /usr/share/maven/ref/settings-docker.xml COPY src /tmp/src/ 13724ad65fa9678727cdfb4446f71ed586605178d3252371934493e90d7fc7c5]} 
DEBU[0012] optimize: cache key for command COPY src /tmp/src/ 177d8852ce5ec30e7ac1944b43363857d249c3fb4cdb4a26724ea88660102e52 
INFO[0012] Checking for cached layer registry-docker-registry.registry.svc.cluster.local:5000/skaffold-covid-backend/cache:177d8852ce5ec30e7ac1944b43363857d249c3fb4cdb4a26724ea88660102e52... 
INFO[0012] Using caching version of cmd: COPY src /tmp/src/ 
DEBU[0012] optimize: composite key for command WORKDIR /tmp/ {[sha256:53ce0b73ff3596b4feb23cd8417cf458276fd72464c790c4f732124878e6038f COPY pom.xml /tmp/ 7176510dcac61a3d406beab8d864708f21db23201dba11185866015a8dcd55b0 RUN mvn -B dependency:go-offline -f /tmp/pom.xml -s /usr/share/maven/ref/settings-docker.xml COPY src /tmp/src/ 13724ad65fa9678727cdfb4446f71ed586605178d3252371934493e90d7fc7c5 WORKDIR /tmp/]} 
DEBU[0012] optimize: cache key for command WORKDIR /tmp/ cc93f6a4e941f6eb0b907172ea334a00cdd93ba12f07fe5c6b2cddd89f1ac16c 
DEBU[0012] optimize: composite key for command RUN mvn -B -s /usr/share/maven/ref/settings-docker.xml package {[sha256:53ce0b73ff3596b4feb23cd8417cf458276fd72464c790c4f732124878e6038f COPY pom.xml /tmp/ 7176510dcac61a3d406beab8d864708f21db23201dba11185866015a8dcd55b0 RUN mvn -B dependency:go-offline -f /tmp/pom.xml -s /usr/share/maven/ref/settings-docker.xml COPY src /tmp/src/ 13724ad65fa9678727cdfb4446f71ed586605178d3252371934493e90d7fc7c5 WORKDIR /tmp/ RUN mvn -B -s /usr/share/maven/ref/settings-docker.xml package]} 
DEBU[0012] optimize: cache key for command RUN mvn -B -s /usr/share/maven/ref/settings-docker.xml package f09ec8d47c0476fe4623fbb7bedd628466d43cd623c82a298c84d43c028c4518 
INFO[0012] Checking for cached layer registry-docker-registry.registry.svc.cluster.local:5000/skaffold-covid-backend/cache:f09ec8d47c0476fe4623fbb7bedd628466d43cd623c82a298c84d43c028c4518... 
INFO[0012] Using caching version of cmd: RUN mvn -B -s /usr/share/maven/ref/settings-docker.xml package 
DEBU[0012] Mounted directories: [{/kaniko false} {/etc/mtab false} {/tmp/apt-key-gpghome true} {/var/run false} {/proc false} {/dev false} {/dev/pts false} {/dev/mqueue false} {/sys false} {/sys/fs/cgroup false} {/sys/fs/cgroup/systemd false} {/sys/fs/cgroup/cpu,cpuacct false} {/sys/fs/cgroup/devices false} {/sys/fs/cgroup/net_cls,net_prio false} {/sys/fs/cgroup/pids false} {/sys/fs/cgroup/rdma false} {/sys/fs/cgroup/memory false} {/sys/fs/cgroup/freezer false} {/sys/fs/cgroup/cpuset false} {/sys/fs/cgroup/perf_event false} {/sys/fs/cgroup/blkio false} {/sys/fs/cgroup/hugetlb false} {/busybox false} {/kaniko/buildcontext false} {/etc/hosts false} {/dev/termination-log false} {/etc/hostname false} {/etc/resolv.conf false} {/dev/shm false} {/var/run/secrets/kubernetes.io/serviceaccount false} {/proc/asound false} {/proc/bus false} {/proc/fs false} {/proc/irq false} {/proc/sys false} {/proc/sysrq-trigger false} {/proc/acpi false} {/proc/kcore false} {/proc/keys false} {/proc/timer_list false} {/proc/sched_debug false} {/proc/scsi false} {/sys/firmware false}] 
DEBU[0014] Not adding /dev because it is whitelisted    
DEBU[0014] Not adding /etc/hostname because it is whitelisted 
DEBU[0014] Not adding /etc/resolv.conf because it is whitelisted 
DEBU[0018] Not adding /proc because it is whitelisted   
DEBU[0019] Not adding /sys because it is whitelisted    
DEBU[0026] Not adding /var/run because it is whitelisted 
DEBU[0080] Whiting out /var/lib/apt/lists/.wh.auxfiles  
DEBU[0080] not including whiteout files                 
INFO[0085] Taking snapshot of full filesystem...        
INFO[0085] Resolving paths                              
FATA[0095] build failed: building [skaffold-covid-backend]: getting image: Get ""http://registry-docker-registry.registry.svc.cluster.local:5000/v2/"": dial tcp: lookup registry-docker-registry.registry.svc.cluster.local on 127.0.0.53:53: no such host
</code></pre>

<p>At the same time kaniko Pod is running I've been able to perform some actions:</p>

<pre><code>$ kubectl exec -ti kaniko-8nph4 -c kaniko -- sh
/ # wget registry-docker-registry.registry.svc.cluster.local:5000/v2/_catalog
Connecting to registry-docker-registry.registry.svc.cluster.local:5000 (10.43.119.11:5000)
saving to '_catalog'
_catalog             100% |**************************************************************************************************************|    75  0:00:00 ETA
'_catalog' saved
/ # cat _catalog
{""repositories"":[""skaffold-covid-backend"",""skaffold-covid-backend/cache""]}
</code></pre>

<p>So it seems it's able to connect to it, but at logs are saying it's not able to connect to it.</p>

<p>Any ideas about how to get access to this registry deployed inside the same kubernetes?</p>

<p>I've tried to get access to the registry from another pod:</p>

<pre><code>$ kubectl exec -ti graylog-1 -- curl registry-docker-registry.registry:5000/v2/_catalog
{""repositories"":[""skaffold-covid-backend"",""skaffold-covid-backend/cache""]}
</code></pre>

<p>As you can see, it's able to get access to the registry.</p>

<p>I've also took a look on container <code>/etc/resolv.conf</code>:</p>

<pre><code>$ kubectl exec -ti kaniko-zqhgf -c kaniko -- cat /etc/resolv.conf
search registry.svc.cluster.local svc.cluster.local cluster.local
nameserver 10.43.0.10
options ndots:5
</code></pre>

<p>I've also checked connections during container is running:</p>

<pre><code>$ kubectl exec -ti kaniko-sgs5x -c kaniko -- netstat
Active Internet connections (w/o servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       
tcp        0    210 kaniko-sgs5x:40104      104.18.124.25:443       ESTABLISHED 
tcp        0      0 kaniko-sgs5x:46006      registry-docker-registry.registry.svc.cluster.local:5000 ESTABLISHED 
tcp        0      0 kaniko-sgs5x:45884      registry-docker-registry.registry.svc.cluster.local:5000 ESTABLISHED 
tcp        0      0 kaniko-sgs5x:39772      ec2-52-3-104-67.compute-1.amazonaws.com:443 ESTABLISHED 
Active UNIX domain sockets (w/o servers)
Proto RefCnt Flags       Type       State         I-Node Path
</code></pre>

<p>As you can see, it seems it's able that container has established connection to <code>egistry-docker-registry.registry.svc.cluster.local:5000</code>. However, when it tries to push it at registry, error log appears...</p>

<p>It's really strange.</p>
"
61251788,"<p>I've deployed an docker registry inside my kubernetes:</p>

<pre><code>$ kubectl get service
NAME                       TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE
registry-docker-registry   ClusterIP   10.43.39.81   &lt;none&gt;        443/TCP   162m
</code></pre>

<p>I'm able to pull images from my machine (service is exposed via an ingress rule):</p>

<pre><code>$ docker pull registry-docker-registry.registry/skaffold-covid-backend:c5dfd81-dirty@sha256:76312ebc62c4b3dd61b4451fe01b1ecd2e6b03a2b3146c7f25df3d3cfb4512cd
...
Status: Downloaded newer image for registry-do...
</code></pre>

<p>When I'm trying to test it in order to deploy my image into the same kubernetes:</p>

<pre><code>apiVersion: apps/v1
kind: Deployment
metadata:
  name: covid-backend
  namespace: skaffold
spec:
  replicas: 3
  selector:
    matchLabels:
      app: covid-backend
  template:
    metadata:
      labels:
        app: covid-backend
    spec:
      containers:
      - image: registry-docker-registry.registry/skaffold-covid-backend:c5dfd81-dirty@sha256:76312ebc62c4b3dd61b4451fe01b1ecd2e6b03a2b3146c7f25df3d3cfb4512cd
        name: covid-backend
        ports:
        - containerPort: 8080
</code></pre>

<p>Then, I've tried to deploy it:</p>

<pre><code>$ cat pod.yaml | kubectl apply -f -
</code></pre>

<p>However, kubernetes isn't able to reach registry:</p>

<p>Extract of <code>kubectl get events</code>:</p>

<pre><code>6s          Normal    Pulling             pod/covid-backend-774bd78db5-89vt9    Pulling image ""registry-docker-registry.registry/skaffold-covid-backend:c5dfd81-dirty@sha256:76312ebc62c4b3dd61b4451fe01b1ecd2e6b03a2b3146c7f25df3d3cfb4512cd""
1s          Warning   Failed              pod/covid-backend-774bd78db5-89vt9    Failed to pull image ""registry-docker-registry.registry/skaffold-covid-backend:c5dfd81-dirty@sha256:76312ebc62c4b3dd61b4451fe01b1ecd2e6b03a2b3146c7f25df3d3cfb4512cd"": rpc error: code = Unknown desc = failed to pull and unpack image ""registry-docker-registry.registry/skaffold-covid-backend@sha256:76312ebc62c4b3dd61b4451fe01b1ecd2e6b03a2b3146c7f25df3d3cfb4512cd"": failed to resolve reference ""registry-docker-registry.registry/skaffold-covid-backend@sha256:76312ebc62c4b3dd61b4451fe01b1ecd2e6b03a2b3146c7f25df3d3cfb4512cd"": failed to do request: Head https://registry-docker-registry.registry/v2/skaffold-covid-backend/manifests/sha256:76312ebc62c4b3dd61b4451fe01b1ecd2e6b03a2b3146c7f25df3d3cfb4512cd: dial tcp: lookup registry-docker-registry.registry: Try again
1s          Warning   Failed              pod/covid-backend-774bd78db5-89vt9    Error: ErrImagePull
</code></pre>

<p>As you can see, kubernetes is not able to get access to the internal deployed registry...</p>

<p>Any ideas?</p>
"
61172370,"<p>I've deployed a registry service into a namespace <code>registry</code>:</p>

<pre><code>$ kubectl get service -n registry
NAME                       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
registry-docker-registry   ClusterIP   10.43.119.11   &lt;none&gt;        5000/TCP   18h
</code></pre>

<p>this is my <code>skaffold.yaml</code>:</p>

<pre><code>apiVersion: skaffold/v2beta1
kind: Config
metadata:
  name: spring-boot-slab
build:
  artifacts:
  - image: skaffold-covid-backend
    kaniko:
      dockerfile: Dockerfile-multistage
      cache: {}
  cluster: {}
deploy:
  kubectl:
    manifests:
    - k8s/*
</code></pre>

<p>Everything works fine, up to when kaniko is trying to push the image to above registry:</p>

<blockquote>
  <p>Get ""<a href=""http://registry-docker-registry.registry.svc.cluster.local:5000/v2/"" rel=""nofollow noreferrer"">http://registry-docker-registry.registry.svc.cluster.local:5000/v2/</a>"": dial tcp: lookup registry-docker-registry.registry.svc.cluster.local on 127.0.0.53:53: no such host</p>
</blockquote>

<p>Any ideas about how to get access to this registry deployed inside the same kubernetes?</p>

<p>I've tried to get access to the registry from another pod:</p>

<pre><code>$ kubectl exec -ti graylog-1 -- curl registry-docker-registry.registry:5000/v2/_catalog
{""repositories"":[""skaffold-covid-backend"",""skaffold-covid-backend/cache""]}
</code></pre>

<p>As you can see, it's able to get access to registry.</p>
"
61453765,"<p>I'm not able to push an image to my local registry</p>

<pre><code>$ docker image push registry.local:5000/covid-backend:60988b0-dirty
The push refers to repository [registry.local:5000/covid-backend]
eff147c1024b: Preparing 
790a9d8e41bb: Preparing 
20dd87a4c2ab: Preparing 
78075328e0da: Preparing 
9f8566ee5135: Preparing 
error parsing HTTP 404 response body: invalid character '&lt;' looking for beginning of value: ""&lt;HTML&gt;&lt;HEAD&gt;\r\n&lt;TITLE&gt;Network Error&lt;/TITLE&gt;\r\n&lt;/HEAD&gt;\r\n&lt;BODY&gt;\r\n&lt;FONT face=\""Helvetica\""&gt;\r\n&lt;big&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/big&gt;&lt;BR&gt;\r\n&lt;/FONT&gt;\r\n&lt;blockquote&gt;\r\n&lt;TABLE border=0 cellPadding=1 width=\""80% \""&gt;\r\n&lt;TR&gt;&lt;TD&gt;\r\n&lt;FONT face=\""Helvetica\""&gt;\r\n&lt;big&gt;Network Error (dns_unresolved_hostname)&lt;/big&gt;\r\n&lt;BR&gt;\r\n&lt;BR&gt;\r\n&lt;/FONT&gt;\r\n&lt;/TD&gt;&lt;/TR&gt;\r\n&lt;TR&gt;&lt;TD&gt;\r\n&lt;FONT face=\""Helvetica\""&gt;\r\nYour requested host \""registry.local\"" could not be resolved by DNS.\r\n&lt;/FONT&gt;\r\n&lt;/TD&gt;&lt;/TR&gt;\r\n&lt;TR&gt;&lt;TD&gt;\r\n&lt;FONT face=\""Helvetica\""&gt;\r\n\r\n&lt;/FONT&gt;\r\n&lt;/TD&gt;&lt;/TR&gt;\r\n&lt;TR&gt;&lt;TD&gt;\r\n&lt;FONT face=\""Helvetica\"" SIZE=2&gt;\r\n&lt;BR&gt;\r\nFor assistance, contact your network support team.\r\n&lt;/FONT&gt;\r\n&lt;/TD&gt;&lt;/TR&gt;\r\n&lt;/TABLE&gt;\r\n&lt;/blockquote&gt;\r\n&lt;/FONT&gt;\r\n&lt;/BODY&gt;&lt;/HTML&gt;\r\n""
</code></pre>

<p>HTML content response contains:</p>

<blockquote>
  <p>Network Error (dns_unresolved_hostname)
  Your requested host \\""registry.local\\"" could not be resolved by DNS.</p>
</blockquote>

<p>I've tried to reach it using <code>curl</code>:</p>

<pre><code>$ curl -s registry.local:5000/v2/_catalog
{""repositories"":[""covid-backend"",""skaffold-covid-backend""]}
</code></pre>

<p>My <code>/etc/hosts</code>:</p>

<pre><code>127.0.0.1   localhost registry.local
</code></pre>

<p>I've also tried to add it into my <code>~/.docker/config.json</code> as insecure registry:</p>

<pre><code>""insecure-registries"" : [
    ""registry.local:5000""
]
</code></pre>

<p>I've also took a look on docker logs:</p>

<pre><code>abr 27 09:30:25 psgd dockerd[15476]: time=""2020-04-27T09:30:25.967945384+02:00"" level=info msg=""Attempting next endpoint for push after error: Get https://registry.local:5000/v2/: Service Unavailable""
abr 27 09:30:29 psgd dockerd[15476]: time=""2020-04-27T09:30:29.121878880+02:00"" level=error msg=""Upload failed: error parsing HTTP 404 response body: invalid character '&lt;' looking for beginning of value: \""&lt;HTML&gt;&lt;HEAD&gt;\\r\\n&lt;TITLE&gt;Network Error&lt;/TITLE&gt;\\r\\n&lt;/HEAD&gt;\\r\\n&lt;BODY&gt;\\r\\n&lt;FONT face=\\\""Helvetica\\\""&gt;\\r\\n&lt;big&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/big&gt;&lt;BR&gt;\\r\\n&lt;/FONT&gt;\\r\\n&lt;blockquote&gt;\\r\\n&lt;TABLE border=0 cellPadding=1 width=\\\""80% \\\""&gt;\\r\\n&lt;TR&gt;&lt;TD&gt;\\r\\n&lt;FONT face=\\\""Helvetica\\\""&gt;\\r\\n&lt;big&gt;Network Error (dns_unresolved_hostname)&lt;/big&gt;\\r\\n&lt;BR&gt;\\r\\n&lt;BR&gt;\\r\\n&lt;/FONT&gt;\\r\\n&lt;/TD&gt;&lt;/TR&gt;\\r\\n&lt;TR&gt;&lt;TD&gt;\\r\\n&lt;FONT face=\\\""Helvetica\\\""&gt;\\r\\nYour requested host \\\""registry.local\\\"" could not be resolved by DNS.\\r\\n&lt;/FONT&gt;\\r\\n&lt;/TD&gt;&lt;/TR&gt;\\r\\n&lt;TR&gt;&lt;TD&gt;\\r\\n&lt;FONT face=\\\""Helvetica\\\""&gt;\\r\\n\\r\\n&lt;/FONT&gt;\\r\\n&lt;/TD&gt;&lt;/TR&gt;\\r\\n&lt;TR&gt;&lt;TD&gt;\\r\\n&lt;FONT face=\\\""Helvetica\\\"" SIZE=2&gt;\\r\\n&lt;BR&gt;\\r\\nFor assistance, contact your network support team.\\r\\n&lt;/FONT&gt;\\r\\n&lt;/TD&gt;&lt;/TR&gt;\\r\\n&lt;/TABLE&gt;\\r\\n&lt;/blockquote&gt;\\r\\n&lt;/FONT&gt;\\r\\n&lt;/BODY&gt;&lt;/HTML&gt;\\r\\n\""""
abr 27 09:30:29 psgd dockerd[15476]: time=""2020-04-27T09:30:29.122824956+02:00"" level=info msg=""Attempting next endpoint for push after error: error parsing HTTP 404 response body: invalid character '&lt;' looking for beginning of value: \""&lt;HTML&gt;&lt;HEAD&gt;\\r\\n&lt;TITLE&gt;Network Error&lt;/TITLE&gt;\\r\\n&lt;/HEAD&gt;\\r\\n&lt;BODY&gt;\\r\\n&lt;FONT face=\\\""Helvetica\\\""&gt;\\r\\n&lt;big&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/big&gt;&lt;BR&gt;\\r\\n&lt;/FONT&gt;\\r\\n&lt;blockquote&gt;\\r\\n&lt;TABLE border=0 cellPadding=1 width=\\\""80% \\\""&gt;\\r\\n&lt;TR&gt;&lt;TD&gt;\\r\\n&lt;FONT face=\\\""Helvetica\\\""&gt;\\r\\n&lt;big&gt;Network Error (dns_unresolved_hostname)&lt;/big&gt;\\r\\n&lt;BR&gt;\\r\\n&lt;BR&gt;\\r\\n&lt;/FONT&gt;\\r\\n&lt;/TD&gt;&lt;/TR&gt;\\r\\n&lt;TR&gt;&lt;TD&gt;\\r\\n&lt;FONT face=\\\""Helvetica\\\""&gt;\\r\\nYour requested host \\\""registry.local\\\"" could not be resolved by DNS.\\r\\n&lt;/FONT&gt;\\r\\n&lt;/TD&gt;&lt;/TR&gt;\\r\\n&lt;TR&gt;&lt;TD&gt;\\r\\n&lt;FONT face=\\\""Helvetica\\\""&gt;\\r\\n\\r\\n&lt;/FONT&gt;\\r\\n&lt;/TD&gt;&lt;/TR&gt;\\r\\n&lt;TR&gt;&lt;TD&gt;\\r\\n&lt;FONT face=\\\""Helvetica\\\"" SIZE=2&gt;\\r\\n&lt;BR&gt;\\r\\nFor assistance, contact your network support team.\\r\\n&lt;/FONT&gt;\\r\\n&lt;/TD&gt;&lt;/TR&gt;\\r\\n&lt;/TABLE&gt;\\r\\n&lt;/blockquote&gt;\\r\\n&lt;/FONT&gt;\\r\\n&lt;/BODY&gt;&lt;/HTML&gt;\\r\\n\""""
</code></pre>

<p>My <code>NO_PROXY</code> environment variable content:</p>

<pre><code>$ echo $NO_PROXY
localhost,127.0.0.1/8,::1,192.168.99.0/8,registry.local
</code></pre>
"
60773690,"<p>I have </p>

<pre><code>days&lt;-c(""X1.22.20"", ""X1.23.20"", ""X1.24.20"", ""X1.25.20"", ""X1.26.20"", 
""X1.27.20"", ""X1.28.20"", ""X1.29.20"", ""X1.30.20"", ""X1.31.20"", ""X2.1.20"", 
""X2.2.20"", ""X2.3.20"", ""X2.4.20"", ""X2.5.20"", ""X2.6.20"", ""X2.7.20"", 
""X2.8.20"", ""X2.9.20"", ""X2.10.20"", ""X2.11.20"", ""X2.12.20"", ""X2.13.20"", 
""X2.14.20"", ""X2.15.20"", ""X2.16.20"", ""X2.17.20"", ""X2.18.20"", ""X2.19.20"", 
""X2.20.20"", ""X2.21.20"", ""X2.22.20"", ""X2.23.20"", ""X2.24.20"", ""X2.25.20"", 
""X2.26.20"", ""X2.27.20"", ""X2.28.20"", ""X2.29.20"", ""X3.1.20"", ""X3.2.20"", 
""X3.3.20"", ""X3.4.20"", ""X3.5.20"", ""X3.6.20"", ""X3.7.20"", ""X3.8.20"", 
""X3.9.20"", ""X3.10.20"", ""X3.11.20"", ""X3.12.20"", ""X3.13.20"", ""X3.14.20"", 
""X3.15.20"", ""X3.16.20"", ""X3.17.20"", ""X3.18.20"", ""X3.19.20"")
</code></pre>

<p>I want these days (row names of <a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series</a>) formatted as.Date. </p>

<p>However I have the following problem: 1. The leading X, 2. There is no leading zero in days 3. There is no leading zero in months 3. Year is abbreviated as 20. </p>

<p>I havent found a way to tackle all these issues.</p>
"
61373416,"<p>I'm working on an UPDATE from a SELECT query from current COVID-19 data from the NY Times GitHub site at <a href=""https://github.com/nyti%20mes/covid-19-data/archive/master.zip"" rel=""nofollow noreferrer"">https://github.com/nytimes/covid-19-data/archive/master.zip</a> . This is CSV data with 5 columns (date, county, state, FIPS (a 5 character geographic identifier which sometimes has leading 0's and also has some NULLs), cases and deaths). The problem is that cases and deaths are cumulative.  The problem was to try to reorganized the data by date, state, and county, then determine the number of new cases and new deaths each day.  The first thought was to do this by a Cursor, which took forever.  A crafty contributor here had suggested self-joining the import table with an added RowID, and off-setting the RowID by 1 in a WHERE clause, hence:</p>

<pre><code>T1 LEFT OUTER JOIN T2
ON T1.Row_ID - 1 = T2.Row_ID
</code></pre>

<p>The next job was doing a conditional subtraction of the previous day's cases / deaths from the current day's.  There were three cases to deal with
1. The first row of the join where the previous day was NULL - this needed the first row values are those of the current day.
2. When the previous day's row was from a different state and/or county, the current day's values are those of the current day (like 1 above).
3. Where the state and county were the same as the previous day, a simple subtraction was performed</p>

<pre><code>CASE
  WHEN T2.Row_ID IS NULL                                    THEN T1.Total_Cases
  WHEN (T1.State &lt;&gt; T2.State) OR (T1.County &lt;&gt; T2.County)   THEN T1.Total_Cases
  ELSE T1.Total_Cases - T2.Total_Cases  
END
</code></pre>

<p>In SQL-Server syntax, the whole statement is: </p>

<pre><code>UPDATE COVID_19.dbo.US_Counties
SET
  New_Cases = New_Values.New_Cases1,
  New_Deaths = New_Values.New_Deaths1
FROM (
  SELECT
    T1.Row_ID,
    CASE
      WHEN T2.Row_ID IS NULL                                    THEN T1.Total_Cases
      WHEN (T1.State &lt;&gt; T2.State) OR (T1.County &lt;&gt; T2.County)   THEN T1.Total_Cases
      ELSE T1.Total_Cases - T2.Total_Cases
    END AS New_Cases1,
    CASE
      WHEN T2.Row_ID IS NULL                                    THEN T1.Total_Deaths
      WHEN (T1.State &lt;&gt; T2.State) OR (T1.County &lt;&gt; T2.County)   THEN T1.Total_Deaths
      ELSE T1.Total_Deaths - T2.Total_Deaths
    END AS New_Deaths1
  FROM COVID_19.dbo.US_Counties T1
    LEFT OUTER JOIN COVID_19.dbo.US_Counties T2                         
    ON T1.Row_ID - 1 = T2.Row_ID) AS New_Values
WHERE COVID_19.dbo.US_Counties.Row_ID = New_Values.Row_ID;
</code></pre>

<p>This executed quickly (1 sec?) on SQL-Server with 80,000 rows</p>

<p>I rewrote this for MySQL as:</p>

<pre><code> UPDATE covid_19.us_counties
    SET
      New_Cases = New_Values.New_Cases1,
      New_Deaths = New_Values.New_Deaths1
    FROM (
      SELECT
        T1.Row_ID,
        CASE
          WHEN T2.Row_ID IS NULL                                    THEN T1.Tot_Cases
          WHEN (T1.State &lt;&gt; T2.State) OR (T1.County &lt;&gt; T2.County)   THEN T1.Tot_Cases
          ELSE T1.Tot_Cases - T2.Tot_Cases
        END AS New_Cases1,
        CASE
          WHEN T2.Row_ID IS NULL                                    THEN T1.Tot_Deaths
          WHEN (T1.State &lt;&gt; T2.State) OR (T1.County &lt;&gt; T2.County)   THEN T1.Tot_Deaths
          ELSE T1.Tot_Deaths - T2.Tot_Deaths
        END AS New_Deaths1
      FROM covid_19.us_counties T1
        LEFT JOIN covid_19.us_counties T2                           
        ON T1.Row_ID - 1 = T2.Row_ID) AS New_Values
    WHERE us_counties.Row_ID = New_Values.Row_ID;
</code></pre>

<p>Unfortunately, this kept throwing an error immediately before</p>

<pre><code>FROM (
</code></pre>

<p>Eventually, I rewrote this without the FROM as</p>

<pre><code>UPDATE
    covid_19.us_counties,
    (SELECT
        T1.Row_ID,
        CASE
          WHEN T2.Row_ID IS NULL                                    THEN T1.Total_Cases
          WHEN (T1.State &lt;&gt; T2.State) OR (T1.County &lt;&gt; T2.County)   THEN T1.Total_Cases
          ELSE T1.Total_Cases - T2.Total_Cases
        END AS New_Cases1,
        CASE
          WHEN T2.Row_ID IS NULL                                    THEN T1.Total_Deaths
          WHEN (T1.State &lt;&gt; T2.State) OR (T1.County &lt;&gt; T2.County)   THEN T1.Total_Deaths
          ELSE T1.Total_Deaths - T2.Total_Deaths
        END AS New_Deaths1
      FROM covid_19.us_counties T1
        LEFT JOIN covid_19.us_counties T2                           
        ON T1.Row_ID - 1 = T2.Row_ID) AS New_Values
    SET
      covid_19.us_counties.New_Cases = New_Values.New_Cases1,
      covid_19.us_counties.New_Deaths = New_Values.New_Deaths1
    WHERE covid_19.us_counties.Row_ID = New_Values.Row_ID;
</code></pre>

<p>This actually worked and executed in 4.4 seconds</p>

<p>It appears the results are now the same for both SQL-Server and MySQL.  My takeaway from this is that somethings don't directly ""translate"", and the Auto-complete feature in SQL-Server with more robust coloring of keywords and wavy red underscores and more complete error messages do make the coding easier that the editor in MySQL.</p>

<p>I'd appreciate any thoughts about the SQL itself, and better editing tools (IDEs?) especially for MySQL.</p>

<p>Thanks in advance...</p>
"
60799889,"<p>I am trying to find row_number based on confirmed order by country but getting unique row number for same confirmed value.</p>

<p>Data looks like :</p>

<pre><code>confirmed | country              | row_nmb |
+-----------+----------------------+---------+
|         1 | Australia            |       1 |
|         1 | Belgium              |       2 |
|         1 | Cambodia             |       3 |
|         1 | Canada               |       4 |
|         2 | China                |       5 |
|         2 | Egypt                |       6 |
|         2 | Finland              |       7 |
|         2 | Germany              |       8 |
|         2 | India                |       9 |
|         2 | Japan                |      10 |
|         2 | Mainland China       |      11 |
</code></pre>

<p>Code I am writing:</p>

<pre><code> select confirmed, country, @row_number:= CASE WHEN @confirmed:= confirmed THEN @row_number+1 ELSE 1 END as ""row_nmb"" from (select confirmed, country from COVID_DB.COVID2019 group by confirmed,country  order by confirmed, country) X , (select  @row_number:=0, @confirmed:= 0) t where confirmed &lt;&gt; 0 group by confirmed, country order by confirmed, row_nmb;
</code></pre>

<p>Expectations:</p>

<pre><code>confirmed | country              | row_nmb |
+-----------+----------------------+---------+
|         1 | Australia            |       1 |
|         1 | Belgium              |       2 |
|         1 | Cambodia             |       3 |
|         1 | Canada               |       4 |
|         2 | China                |       1 |
|         2 | Egypt                |       2 |
|         2 | Finland              |       3 |
|         2 | Germany              |       4 |
|         2 | India                |       5 |
|         2 | Japan                |       6 |
|         2 | Mainland China       |       7 |
</code></pre>
"
61485610,"<p>The join returns the view I want but when I go to create the table I get 0 rows processed. I'm sure I'm missing something simple but this is my first time creating tables using queries. Help is appreciated.</p>

<p>THE JOIN:</p>

<pre><code>Select 
 a.*,
 b.acct_sk,
 b.voice_estbd_dt,
 b.data_estbd_dt,
 b.video_estbd_dt,
 b.voice_term_dt,
 b.data_term_dt,
 b.video_term_dt,
 b.voice_svc_type_id,
 b.voice_acct_status_id,
 b.data_svc_type_id,
 b.data_acct_status_id,
 b.video_svc_type_id,
 b.video_acct_status_id,
 b.video_svc_type,
 b.data_down_spd_mb,
 b.data_up_spd_mb,
 b.dsl_down_spd_mb,
 b.dsl_up_spd_mb,
 b.fios_down_spd_mb,
 b.fios_up_spd_mb,
 b.prov_speed,
 b.nbr_voice_lines,
 b.tot_trouble_tkts,
 b.trouble_tkts_rslvd,
 b.trouble_tkts_not_rslvd,
 b.tot_truck_rolls,
 b.run_date,
 b.snapshot_dt,
 b.hsi_line_count

from xxx.COVID19_LTRS a

left joinxx.CAR_SERVICE b
ON a.acct_sk = b.acct_sk
AND snapshot_dt = DATE '2020-02-01'
</code></pre>

<p>THE CREATE TABLE:</p>

<pre><code>CREATE TABLE xxx.aw_smbsuspend_dev_1 as
(Select 
    a.acct_sk,
    a.product_id,
    a.order_save_date,
    a.comments,
    a.b_name,
    a.bill_addr,
    a.bill_city,
    a.bill_state,
    a.bill_zip5,
    a.bill_zip4,
    a.marketing_primary_segment,
    a.ord_creatd_dt,
    b.voice_estbd_dt,
    b.data_estbd_dt,
    b.video_estbd_dt,
    b.voice_svc_type_id,
    b.voice_acct_status_id,
    b.data_svc_type_id,
    b.data_acct_status_id,
    b.video_svc_type_id,
    b.video_acct_status_id,
    b.video_svc_type,
    b.data_down_spd_mb,
    b.data_up_spd_mb,
    b.dsl_down_spd_mb,
    b.dsl_up_spd_mb,
    b.fios_down_spd_mb,
    b.fios_up_spd_mb,
    b.prov_speed,
    b.nbr_voice_lines,
    b.run_date,
    b.snapshot_dt,
    b.hsi_line_count

from xxx.COVID19_LTRS a

left join xx.CAR_SERVICE b
ON a.acct_sk = b.acct_sk
and b.snapshot_dt = DATE '2020-02-01') with data;
</code></pre>

<p>I have tried adding a group by clause and changing and to where...I am now just adding text because I'm being told to add more explanation but it is a very straightforward problem with a lot of columns. </p>
"
61468049,"<p>I'm working on a Google Sheets document for tracking covid-19 cases reported in nursing homes, institutions, etc. I'm heavily employing formulas across my sheets to minimize the number of ways my coworkers can accidentally screw up the numbers. <a href=""https://docs.google.com/spreadsheets/d/1bGeWiodhCR--EGI8sNlWKsF_z-J95tTzVvB3xOMnEOc/edit?usp=sharing"" rel=""nofollow noreferrer"">I've made a copy of the pertinent sheet here so you can take a look.</a></p>

<p>I've run into a problem, though. So, on one sheet, we have all records of articles that mention statewide case/death numbers. We want to continue to keep track of those, but also be able to easily retrieve/display the most recently reported numbers for any given state. Essentially what I'm trying to do is:</p>

<ol>
<li>Delimit search to only rows where column A contains a specific state (AL, FL, GA, etc)</li>
<li>Of those rows, compare the date values in column B, identify the most recent one</li>
<li>Once the most recent entry for a given state is found, then output the value of column E (or D, or C, doesn't matter, I assume that changing that part will be straightforward enough)</li>
</ol>

<p>I got as far as <code>=MAXIFS(B3:B100, A3:A100,""CT"")</code> but I'm not sure syntactically what to tell it next, or if I'm going about this the right way.</p>

<p><strong>Update:</strong> We have gotten closer with <code>=query(A1:E,""select A, C where A = 'CO' and B = date '""&amp;TEXT(DATEVALUE(max(B2:B)),""yyyy-mm-dd"")&amp;""'"",1)</code> and <code>=query(A1:E,""select A, C, D, E where A = 'CO' and B = date '""&amp;TEXT(DATEVALUE(max(B2:B)),""yyyy-mm-dd"")&amp;""'"",1)</code>, <strong>but</strong> in practice this only returns rows with the absolute most recent date, rather than the most recent date relative to which state's dataset you're looking at. </p>

<p>Need to be able to display the relative most recent entry per state.</p>

<p>UPDATE UPDATE: I figured it out! (sheet name added because I'm referencing it from a different sheet)</p>

<pre><code>=query('Statewide Reported'!A1:E,""select A, B, C, D where A = 'NJ' and B = date '""&amp;TEXT(maxifs('Statewide Reported'!B3:B100, 'Statewide Reported'!A3:A100, ""NJ""),""yyyy-mm-dd"")&amp;""'"",1)
</code></pre>

<p>Thanks so much for pointing me in the right direction!!</p>
"
61469354,"<p>I have a table that contains Covid data by county. I need to loop through the table to calculate the 
difference in cases &amp; deaths by countyname from the previous day at the same time. For example. I know that 
the total cases at 15:00 on 3/20 for Chambers is 4 and for the same time on 3/19 it's 1. The difference is 3.
I need to insert the COUNTYNAME, DateReported &amp; Difference in case count into a temp table for each row in my table.
Of course this is fictional data.</p>

<pre><code>CID    COUNTYNAME     Cases  Deaths         DateReported    
---------------------------------------------------------------------           
1   |   Baldwin     |   1   |   0   |   2020-03-19 12:00:00.000     
2   |   Cook        |   1   |   0   |   2020-03-19 12:00:00.000     |
3   |   Chambers    |   1   |   0   |   2020-03-19 12:00:00.000     |
4   |   Total       |   3   |   0   |   2020-03-19 12:00:00.000     |
5   |   Baldwin     |   1   |   0   |   2020-03-19 15:00:00.000     |
6   |   Cook        |   2   |   0   |   2020-03-19 15:00:00.000     |
7   |   Chambers    |   4   |   0   |   2020-03-19 15:00:00.000     |
8   |   Elmore      |   1   |   0   |   2020-03-19 15:00:00.000     |
9   |   Total       |   8   |   0   |   2020-03-19 15:00:00.000     |
10  |   Baldwin     |   1   |   0   |   2020-03-20 12:00:00.000     |
11  |   Cook        |   2   |   0   |   2020-03-20 12:00:00.000     |
12  |   Chambers    |   4   |   0   |   2020-03-20 12:00:00.000     |
13  |   Clarke      |   1   |   0   |   2020-03-20 12:00:00.000     |
14  |   Elmore      |   1   |   0   |   2020-03-20 12:00:00.000     |
15  |   Total       |   9   |   0   |   2020-03-20 12:00:00.000     |
16  |   Baldwin     |   1   |   0   |   2020-03-20 15:00:00.000     |
17  |   Cook        |   2   |   0   |   2020-03-20 15:00:00.000     |
18  |   Chambers    |   4   |   0   |   2020-03-20 15:00:00.000     |
19  |   Clarke      |   1   |   0   |   2020-03-20 15:00:00.000     |
20  |   Elmore      |   2   |   0   |   2020-03-20 15:00:00.000     |
21  |   Total       |   10  |   0   |   2020-03-20 15:00:00.000     |
</code></pre>

<p>Here's what I have that seems to get me close to what I need but my table has 
50,000 rows and this takes 5+ minutes to execute.</p>

<pre><code>CREATE TABLE #tempTable1 (
CountyName varchar(50),
DateReported datetime,
DiffVal int
)
DECLARE @RowCount INT
,@HourVal int = datepart(hh,getdate())
,@PreviousDayVal date = dateadd(DD, -1, cast(getdate() as date))
--Get the number of rows in our table to loop through.
SET @RowCount = (SELECT COUNT(COUNTYNAME) FROM myCovidTable)
DECLARE @I INT
SET @I = 1

WHILE (@I &lt;= @RowCount)
BEGIN
DECLARE @iCountyName VARCHAR(50)
,@iDateReported datetime
,@iDiffVal int
,@CountyNameVal varchar(50) = (SELECT COUNTYNAME FROM myCovidTable WHERE CID = @I)
,@CurrentDateVal datetime = (SELECT dateadd(DD, 0, cast(DateReported as date)) FROM myCovidTable WHERE CID = @I); -- The current row's DateReported value
--The date reported isn't always constant so I need to parse the date 
WITH tempTable2 
     AS (SELECT Cases,
                Cast(DateReported AS DATE) AS DateField 
         FROM   myCovidTable
         WHERE  Datepart(HH, ( DateReported )) = @HourVal
                AND COUNTYNAME = @CountyNameVal) 
SELECT @iDiffVal  = (
    SELECT  SUM (Cases)
    FROM    tempTable2 
    WHERE   DateField = @CurrentDateVal) -
    (SELECT SUM (Cases)
    FROM    tempTable2 
    WHERE   DateField = @PreviousDayVal)

-- Then we insert it into the table
SET @iDateReported = (SELECT DateReported FROM myCovidTable WHERE CID = @I)
SET @iCountyName = (SELECT COUNTYNAME FROM myCovidTable WHERE CID = @I)
SET @I = @I + 1
INSERT into #tempTable1 select @iCountyName as CountyName, @iDateReported as DateReported, @iDiffVal as DiffValue

END
SELECT * FROM #tempTable1
</code></pre>

<p>The results should be a table with three columns: CountyName, DateReported and DiffVal showing the difference in cases at the same time on the previous day, by county, for each row (date reported).</p>
"
59961348,"<p>I got pasted a source code to extract a particular dataset and I am having a problem understanding one of the bits. Here's the part of a query:</p>

<pre><code>WHERE r LIKE 
((COALESCE(ur.title, '') || ' ' || COALESCE(urd.reviewtext, '')) ,'.* coronavirus .*|.* SARS .*', 'si')
</code></pre>

<p>Could you help me translate what does the inside bracket of this <code>LIKE</code> operator mean? Many thanks in advance.</p>
"
61315137,"<p>I want to get 2019–20 COVID-19 pandemic (Q81068910) number of deaths (P1120)+ associated time for each country.
I use the wikidata sparql as following, I cannot get the associated time of number of deaths (P1120).
I try to add  ?num wdt:P585 ?time in the following sparql, but I get an error.
Thank you for your help.</p>

<p>SELECT ?pandemic ?pandemicLabel ?num ?time ?country  ?countryLabel
WHERE 
{
  ?pandemic wdt:P31  wd:Q3241045.
  ?pandemic wdt:P361  wd:Q81068910.
  ?pandemic wdt:P1120 ?num.
  #?num wdt:P585 ?time #error, mark it as comment
  ?pandemic wdt:P17 ?country.
  SERVICE wikibase:label { bd:serviceParam wikibase:language ""en"". }<br>
}</p>
"
60866255,"<p><strong>This is my csv file</strong></p>

<p><a href=""https://i.stack.imgur.com/J927A.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/J927A.png"" alt=""enter image description here""></a></p>

<p>I have tried to import this csv file by using <code>SQL Loader</code>.</p>

<p><strong>My <code>sql loader.txt</code></strong></p>

<pre><code>load data
 infile 'E:\time_series_19-covid-Confirmed.csv'
 into table confirmed
 fields terminated by "","" optionally enclosed by '""'
 (provice, country, lat, longi, date)
</code></pre>

<p><strong>Error</strong></p>

<pre><code>C:\Users\User&gt;sqlldr dsda/dsda

control = E:\sql loader.txt

SQL*Loader-941: Error during describe of table CONFIRMED
ORA-04043: object CONFIRMED does not exist
</code></pre>

<p>There are lot of date columns in my csv file. </p>

<p>How can I import this csv using SQL Plus?</p>

<p>My csv file <a href=""https://drive.google.com/open?id=1xsEbLwTHpB05J8jVbdvrXZV72Gw87SWU"" rel=""nofollow noreferrer"">Download link</a></p>

<p>For background about this <a href=""https://stackoverflow.com/q/60819035/146325"">please see my earlier question</a>.</p>
"
61032927,"<p>consider the following table:</p>

<pre><code>    covid_data(
        CASES               INT,
        DEATHS              INT,
        COUNTRIES           VARCHAR(64),
    );
</code></pre>

<p>I am trying to get the names of the countries which the mortality rate is greater than the AVG mortality rate. The formula I am using to get the number of deaths based on every 1000 cases is:
         (NUMBER OF DEATHS / NUMBER OF CASES) * 1000
To get the AVG I use this query:</p>

<pre><code>    SELECT AVG(rate)
    FROM (
          SELECT CAST(SUM(deaths) AS FLOAT) / SUM(cases) * 1000  AS rate
          FROM covid_data
    ) covid_data;
</code></pre>

<p>To list the countries with a greater rate than this AVG this is one of the many attempts I have tried so far.</p>

<pre><code>SELECT countries, CAST(SUM(deaths) AS FLOAT) / SUM(cases) * 1000 AS RATEM
FROM covid_data
GROUP BY countries
HAVING RATEM &gt; (SELECT AVG(RATE)
FROM (
      SELECT CAST(SUM(DEATHS) AS FLOAT) / SUM(CASES) * 1000  AS RATE
      FROM covid_data
     ) covid_data);
</code></pre>

<p>This is returning an error: no such column: RATEM</p>

<p>As you can see I am struggling with this basic concepts I would appreciate as well any books/courses/resources to better understand this relations. </p>
"
61167233,"<p>I spun a container with the <code>mysql</code> image. I am trying to load a CSV. </p>

<p>It looks sort of like this but with more rows. It is located in <code>/local/data/af_bases.csv</code> within the container. You can get a copy of the file <a href=""https://raw.githubusercontent.com/xaviermerino/nomad-jobs/master/covid19/mysql/data/af_bases.csv"" rel=""nofollow noreferrer"">here</a>.</p>

<pre><code>Tinker AFB,Oklahoma,9y69rzbsh9mz,-1
Andrews AFB,Maryland,dqckf8m8ry2c,-1
Grissom AFB,Indiana,dp4xrf0ufvjd,-1
</code></pre>

<p>I create a database <code>geolocations</code>. And then I want to run the following:</p>

<pre class=""lang-sql prettyprint-override""><code>USE geolocations;

CREATE TABLE bases( 
name varchar(255), 
state varchar(255), 
geohash varchar(255),
confirmed float,
timestamp timestamp not null default current_timestamp on update current_timestamp
);

LOAD DATA INFILE '/local/data/af_bases.csv' INTO TABLE bases 
FIELDS TERMINATED BY ',' ENCLOSED BY '' 
LINES TERMINATED BY '\n'; 
</code></pre>

<p>However, I get the following:</p>

<pre><code>ERROR 1261 (01000): Row 1 doesn't contain data for all columns
</code></pre>

<p>I have tried enclosing the data in double quotations and doing <code>ENCLOSED BY '""'</code> but it doesn't seem to like it either way.</p>

<p>Any ideas? Thanks :) </p>
"
61405629,"<p>as per the documentation BI engine is supposed to accelerate left join</p>

<p><a href=""https://cloud.google.com/bi-engine/docs/optimized-sql#unsupported-features"" rel=""nofollow noreferrer"">https://cloud.google.com/bi-engine/docs/optimized-sql#unsupported-features</a></p>

<p>I tried this dummy query as a view, connect to datastudio</p>

<pre><code>SELECT xx.country_region,yy._1_22_20 FROM `bigquery-public-data.covid19_jhu_csse.deaths` xx
left join `bigquery-public-data.covid19_jhu_csse.deaths` yy
on xx.country_region=yy.country_region
</code></pre>

<p><a href=""https://i.stack.imgur.com/BPGPt.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/BPGPt.png"" alt=""enter image description here""></a></p>

<p>my question is: is left join supported or not ?</p>

<p>bug report here : <a href=""https://issuetracker.google.com/issues/154786936"" rel=""nofollow noreferrer"">https://issuetracker.google.com/issues/154786936</a></p>

<p>Datastudio report : <a href=""https://datastudio.google.com/reporting/25710c42-acda-40a3-a3bf-68571c314650"" rel=""nofollow noreferrer"">https://datastudio.google.com/reporting/25710c42-acda-40a3-a3bf-68571c314650</a></p>

<p>edit : it seems BI engine is still under heavy development and needs more time to be feature completed, I just materialized my view, but it has a cost, 4 small tables &lt; 10 MB,  that change very 5 minutes cost 11 GB/ day , I guess it is worth it, Datastudio is substantially faster now, you can check it here (public report)</p>

<p><a href=""https://nemtracker.github.io/"" rel=""nofollow noreferrer"">https://nemtracker.github.io/</a></p>
"
60853664,"<p>When I run:</p>

<pre><code>SELECT
  CELL_ID,
  EXTRACT(date
  FROM
    TIMESTAMP( PARSE_DATE('%y%m%dT%H%M%S',
        EVENT_TM) )) AS date,
  EXTRACT(hour
  FROM
    TIMESTAMP( PARSE_DATE('%y%m%dT%H%M%S',
        EVENT_TM ))) AS hour,
  COUNT(DISTINCT CELL_ID ) AS cnt
FROM
  `cells.covid`
GROUP BY
  CELL_ID,
  date,
  hour
</code></pre>

<p>this returns an error <code>Invalid format: %H is not allowed for the DATE type.</code></p>
"
60894822,"<p>Yet another data scientist not keeping a safe distance from COVID-19 data.</p>

<p>I am making a plot of the infection and deahts doubling times which I am calculating on a running basis, say previous 14 days. I use the <code>glm</code> function in R to perform an log-link regression to get the doubling time and confidence interval (high/low) for that value. I'm putting these in the mapping as <code>ymin</code> and <code>ymax</code>. I get the confidence band, but it is understandably jagged as is the data. Is there a simple way to smooth the confidence bands?</p>

<pre><code>covid_infection_folding %&gt;%
  ggplot() + 
  geom_point(aes(x=Date, y=US_Infections, color=""US Infections"")) +
  geom_point(aes(x=Date, y=US_Deaths, color=""US Deaths"")) +
  geom_smooth(
    data=covid_infection_folding,
    mapping=aes(x=Date, y=US_Infections, ymin=US_Infections_low, ymax=US_Infections_high, color=""US Infections""),
    stat=""identity""
    ) +
  geom_smooth(
    data=covid_infection_folding,
    mapping=aes(x=Date, y=US_Deaths, ymin=US_Deaths_low, ymax=US_Deaths_high, color=""US Deaths""),
    stat=""identity""
    ) + 
  labs(
    y=""US Covid-19 Doubling Time (Days)"",
    title=""Doubling Time (95% confidence intervals)"",
    subtitle=""Based on purevious 14 days""
  )
</code></pre>

<p><em>covid_infections_folding.csv</em></p>

<pre><code>""Date"",""US_Infections"",""US_Infections_low"",""US_Infections_high"",""World_Infections"",""World_Infections_low"",""World_Infections_high"",""US_Deaths"",""US_Deaths_low"",""US_Deaths_high"",""World_Deaths"",""World_Deaths_low"",""World_Deaths_high""
2020-03-14,2.49983739883223,2.38168561730312,2.62426904052848,15.770263051682,13.9876095552037,18.0489074832855,3.99043275230409,3.69236832976168,4.32140858392337,12.8989698838882,11.4099582259867,14.8038432131489
2020-03-15,2.588057654306,2.47627312530032,2.70530124580819,14.1052241582214,12.5458193107193,16.0815164642284,4.18843478882557,3.99109724055167,4.39934762358077,11.4155530248942,10.1442558270398,13.0197551751998
2020-03-16,2.59916192635231,2.51169240835164,2.68989407531561,12.7183934752834,11.3821909647131,14.3853177366056,3.92980192885667,3.67451528683076,4.20867530268657,10.1892563438137,9.13874885076098,11.4843983540597
2020-03-17,2.50209502182501,2.41277807296645,2.59484269035652,11.5822559952822,10.4704174205308,12.9369688457438,3.65991741725404,3.38578333892515,3.96218180909321,9.22152165144878,8.36609944993533,10.2483894056885
2020-03-18,2.61215755183853,2.5110308935239,2.71767102078119,10.6653403951574,9.74603324802977,11.7586509149994,3.7539849058838,3.50894146518389,4.0213997894202,8.50182769556017,7.82837103723028,9.28511058399383
2020-03-19,2.12103811052124,1.86668177353069,2.40773667867803,9.68220899681998,8.85264088937122,10.664710714973,2.99387387850563,2.54689938108029,3.52708155887181,7.85987840683811,7.30624027338352,8.49070096408631
2020-03-20,1.99079441567267,1.81410759357454,2.18405773648449,8.80015137195741,8.06816675831183,9.65957369382066,2.80956713501713,2.47874770062383,3.18862071502173,7.25673080882034,6.76600476407113,7.81116618913957
2020-03-21,2.05278151635975,1.92120912686599,2.19340371313652,8.08237805494367,7.46494738129346,8.79499183281471,2.7798252180882,2.53323277524509,3.0530722207346,6.73383124186039,6.27979418641987,7.2451124137753
2020-03-22,2.17252528926468,2.04949059350162,2.30316218551139,7.58160689577727,7.09323516620424,8.13086338523261,2.65984002237084,2.47418817905869,2.86058591174651,6.35099806759453,5.97729955890051,6.76431384218689
2020-03-23,2.27085728917173,2.15744423749247,2.39046362864804,7.18006161242301,6.78634277949618,7.61413540189244,2.56825970738847,2.42667381891871,2.71864717722737,6.099512763381,5.8048741730648,6.41894911090602
2020-03-24,2.4531812109224,2.30077480144939,2.6164374199738,6.93254739983745,6.63082808556837,7.25805297994967,2.59389681397186,2.48718548076248,2.70554268775727,5.92711453226658,5.70556072017153,6.16268318967908
</code></pre>

<p>Note: the raw data is from here: <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19</a></p>
"
61353887,"<p>I would like to automatically run a script daily in which I append one column data frames to existing tables in certain worksheets of xlsx files. I have an xlsx file which contains epidemiological data about the spread and severity of COVID-19 in The Netherlands. Because the website that I scrape daily is only publicing current status rapports, I'm making data frames with trends myself. Everyday I want to append an one column data frame to a worksheet containing daily cumulative updates about the amount of people infected by COVID-19. This data frame needs to be appended at the end of the table in the first empty column. I tried this code:</p>

<p>addDataFrame(Meldingen, sheet = 'Meldingen', col.names = F, row.names = F
             , startRow = 1, startColumn = 10)</p>

<p>But this code overwrites the data in the xlsx file instead of appending it to the the table in the worksheet. Can somebody help me? Thank you. </p>
"
60613050,"<p>The Chartkick line</p>

<pre><code>&lt;% geo_chart Coronavirus.group(:country).count(:deaths) %&gt;
</code></pre>

<p>creates a nice map that shows death count due to Coronavirus by country (using Google Charts).
The problem is that my database includes the country name ""Mainland China"" instead of ""China.""
Therefore, the death count for China is listed as zero, which is wrong.
How can I have Chartkick correctly interpret ""Mainland China"" as ""China""?</p>
"
60643617,"<p>I'm trying to grab an updated CSV file, <a href=""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv"" rel=""nofollow noreferrer"">COVID-19</a>, that's posted on GitHub, but I keep getting an error that it's not there. It's a file that's constantly updated so I want to grab it at the source, which is GitHub.<br>
<a href=""https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"" rel=""nofollow noreferrer"">COVID-19 Time Series</a> is the third item on the page.</p>

<p>I tried the raw file URL, the CSV page URL, and GitHub consistently tells me that there is ""no such file or directory"". </p>

<p>Here's my code:</p>

<pre><code>require 'open-uri'
require 'csv'

covids = ""https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_19-covid-Confirmed.csv""

puts File.exist?(covids)
keys = CSV.open(covids, &amp;:readline)
</code></pre>

<p>How can I reference this file?  I know I am logged in, but Ruby should be able to see those file paths.   </p>
"
60994412,"<p>I am building a Rails app to pull data from the <a href=""https://github.com/CSSEGISandData/COVID-19"" rel=""nofollow noreferrer"">Johns Hopkins Covid-19 Github project</a> and to calculate the daily growth rates for cases and deaths. I started this because I wanted to see the change in the data every day for my city of Nashville. Currently, I have a hard-coded html table, which <a href=""https://covid615.com"" rel=""nofollow noreferrer"">you can see here</a>, but I'm trying to make it dynamic so that it works for every county in the US.</p>

<p>At this point I'm blocked trying to model the database and calculate the daily growth rates on a <code>before_save</code> callback because I'm not sure how to look up the records I need. </p>

<p><strong>What is a decent way to find a record in rails that is the adjacent previous record to the one you're looking up? I'm not even sure how to say that clearly in English, which is probably the root of my problem with not being able to get it into code. For instance, today vs. yesterday OR March 28th vs. March 27th OR March 31st vs March 30th, etc. I need to find the first record based on date and then find the last record from the day prior.</strong></p>

<p>It should be something similar to this <code>before_save</code> callback:</p>

<pre><code>def calculate_case_growth_rate
  current_cases  = self.cases
  previous_cases = Update.where(date: 1.day.ago).sum(:cases)
  self.case_growth_rate = (current_cases - previous_cases) / current_cases
end
</code></pre>

<p>Here's <a href=""https://github.com/leemcalilly/coronavirus/blob/master/app/models/update.rb"" rel=""nofollow noreferrer"">the model</a> where that callback happens.</p>

<p>But, <strong>that approach won't work</strong> because there are times where the data might be incorrect for a previous date and it will need to get updated. For instance, the Tennessee health department might discover they had erroneous data for March 31st, so the Johns Hopkins data gets updated and thus the record in my database would need to be updated. So with my code above, the first time that happens it would call <code>Update.last</code> and save an incorrect growth rate for March 31st. Thus, I need the callback to work whether it's calculating the growth rate for today vs. yesterday or March 28th vs. March 27th, etc.</p>

<p>It's an open project, so the entire app is <a href=""https://github.com/leemcalilly/coronavirus"" rel=""nofollow noreferrer"">here</a>. (Please send a pull request if you'd like to help directly!)</p>
"
61462376,"<p>The for loop does not work if I use the $DAYSDIFF variable but it does work if I type in the number of days since 2020-01-21. When I use $DAYSDIFF, I get an error <code>date: invalid date ‘2020-01-21 + {0..97} day’</code> Is there a way to use the calculated number of days variable in the ""IN"" clause of the loop? I'm using Ubuntu 18.04.</p>

<pre><code>REPDATE=2020-01-21 #Date of first COVID-19 report.
CURDATE=`date ""+%Y%m%d""` #Todays date.
DAYSDIFF=$(( (`date -d $CURDATE +%s` - `date -d $REPDATE +%s`) / (24*3600) ))
#echo $DAYSDIFF #The correct number of days is echoed.
REPORTNUM=1

for i in {0..$DAYSDIFF} #DAYSDIFF is not working. If I type a number here it works.
do
   NEXT_DATE=$(date +%Y%m%d -d ""$REPDATE + $i day"")
   echo wget https://www.who.int/docs/default-source/coronaviruse/situation-reports/""$NEXT_DATE""-sitrep-""$REPORTNUM""-covid-19.pdf
   #wget https://www.who.int/docs/default-source/coronaviruse/situation-reports/""$NEXT_DATE""-sitrep-""$REPORTNUM""-covid-19.pdf
   REPORTNUM=`expr $REPORTNUM + 1`
done

</code></pre>
"
61596756,"<p>Could you please confirm the correct query to list the 20 most used hashtags and the count of numbers that they have been used in a MongoDB collection of tweets called ""tweets""?</p>

<p>Each document in the collection represents a tweet.</p>

<p>Please find one of the documents (tweets) in JSON format <a href=""https://docs.google.com/document/d/1hGy4I69R6jrr3G59w1_kQyaMx1kkVF0Jb_8bXuE8ttA/edit"" rel=""nofollow noreferrer"">here</a></p>

<p>I tried the following query:</p>

<pre><code>db.tweets.aggregate([
  {
    $unwind: ""$entities.hashtags""},
    {""$group"" : {_id:""$entities.hashtags"", count:{$sum:1}}},
    { $sort   : { count : -1 } },
    { $limit  : 20 }
])
</code></pre>

<p>Unwind is used to separate documents that have multiple hashtags.</p>

<p>The output seems close:</p>

<pre><code>/* 1 */
{
    ""_id"" : {
        ""text"" : ""PrevenciónEsSalud"",
        ""indices"" : [ 
            0, 
            18
        ]
    },
    ""count"" : 118.0
}

/* 2 */
{
    ""_id"" : {
        ""text"" : ""DYK"",
        ""indices"" : [ 
            0, 
            4
        ]
    },
    ""count"" : 112.0
}

/* 3 */
{
    ""_id"" : {
        ""text"" : ""ActivadosPorLaSalud"",
        ""indices"" : [ 
            0, 
            20
        ]
    },
    ""count"" : 45.0
}

/* 4 */
{
    ""_id"" : {
        ""text"" : ""COVID19"",
        ""indices"" : [ 
            15, 
            23
        ]
    },
    ""count"" : 43.0
}

/* 5 */
{
    ""_id"" : {
        ""text"" : ""HelloMyNameIs"",
        ""indices"" : [ 
            9, 
            23
        ]
    },
    ""count"" : 41.0
}

/* 6 */
{
    ""_id"" : {
        ""text"" : ""Quito"",
        ""indices"" : [ 
            15, 
            21
        ]
    },
    ""count"" : 40.0
}

/* 7 */
{
    ""_id"" : {
        ""text"" : ""LoMásLeído"",
        ""indices"" : [ 
            20, 
            31
        ]
    },
    ""count"" : 40.0
}

/* 8 */
{
    ""_id"" : {
        ""text"" : ""COVID19"",
        ""indices"" : [ 
            18, 
            26
        ]
    },
    ""count"" : 39.0
}

/* 9 */
{
    ""_id"" : {
        ""text"" : ""COVID19"",
        ""indices"" : [ 
            0, 
            8
        ]
    },
    ""count"" : 38.0
}

/* 10 */
{
    ""_id"" : {
        ""text"" : ""PrevenciónGripe"",
        ""indices"" : [ 
            0, 
            16
        ]
    },
    ""count"" : 37.0
}

/* 11 */
{
    ""_id"" : {
        ""text"" : ""COVID19"",
        ""indices"" : [ 
            21, 
            29
        ]
    },
    ""count"" : 36.0
}

/* 12 */
{
    ""_id"" : {
        ""text"" : ""COVID19"",
        ""indices"" : [ 
            128, 
            136
        ]
    },
    ""count"" : 36.0
}

/* 13 */
{
    ""_id"" : {
        ""text"" : ""COVID19"",
        ""indices"" : [ 
            40, 
            48
        ]
    },
    ""count"" : 35.0
}

/* 14 */
{
    ""_id"" : {
        ""text"" : ""QuédateEnCasa"",
        ""indices"" : [ 
            0, 
            14
        ]
    },
    ""count"" : 35.0
}

/* 15 */
{
    ""_id"" : {
        ""text"" : ""ICYMI"",
        ""indices"" : [ 
            0, 
            6
        ]
    },
    ""count"" : 35.0
}

/* 16 */
{
    ""_id"" : {
        ""text"" : ""NosCuidamosTodos"",
        ""indices"" : [ 
            0, 
            17
        ]
    },
    ""count"" : 34.0
}

/* 17 */
{
    ""_id"" : {
        ""text"" : ""JuntosEcuador"",
        ""indices"" : [ 
            0, 
            14
        ]
    },
    ""count"" : 34.0
}

/* 18 */
{
    ""_id"" : {
        ""text"" : ""COVID19"",
        ""indices"" : [ 
            24, 
            32
        ]
    },
    ""count"" : 31.0
}

/* 19 */
{
    ""_id"" : {
        ""text"" : ""EsteVirusLoParamosUnidos"",
        ""indices"" : [ 
            0, 
            25
        ]
    },
    ""count"" : 28.0
}

/* 20 */
{
    ""_id"" : {
        ""text"" : ""COVID19"",
        ""indices"" : [ 
            23, 
            31
        ]
    },
    ""count"" : 28.0
}
</code></pre>

<p>However, the desired outcome is to have a column for the hastag and another one for the count, only for the top 20 most repeated hashtags.</p>

<p>I would appreciate your help in getting the top 20 most used hashtags in this collection.</p>

<p>Thank you.</p>
"
61087066,"<p>Help with COVID-19 data query </p>

<p>I work on a third party system SQL Server 2008 that bizarrely stores a vast amount of numbers in an <code>image</code> column.</p>

<p>These are actually data of a ventilator:</p>

<pre><code>0x7D010015001500150015001600160015......7D010015001500150015001600160015
</code></pre>

<p>When I copy the column data and paste from the clipboard into the query window, I can do the necessary below.</p>

<pre><code>7D01
0015
0015
0015
0015
0016
0016
0015
</code></pre>

<p>I can process the numbers using a table valued function quite well - convert from hex to decimal.</p>

<p>What I can't find is a means to treat the image data as literal text. I've tried:</p>

<pre><code>CAST(CAST(Data as VARBINARY(MAX)) as VARCHAR(MAX))  etc.
</code></pre>

<p>If someone could help the NHS would be very grateful!</p>
"
61578585,"<p>I have created a table for seeing how many people could die from COVID-19 in Latin country's for that i created an ADT structure which have two attributes <code>probabilidad_fallecidos</code> that means probability to death and <code>cantidad_infectados</code> that is the quantity of infected per country, The part i'm having problems is when i try to do an insert says <code>ORA-00947: not enough values</code></p>

<p>I'm very new at this, this is my first try</p>

<p>Below i will let my ADT structure,my function, my table and my try of insert</p>

<p><strong><em>ADT</em></strong></p>

<pre class=""lang-sql prettyprint-override""><code>CREATE OR REPLACE TYPE infectados AS OBJECT(
    cantidad_infectados number,
    probabilidad_fallecidos number,
    STATIC FUNCTION cantidad_fallecidos(cantidad_infectados number,probabilidad_fallecidos number) RETURN number
);
</code></pre>

<p><strong><em>Function <code>cantidad_fallecidos</code></em></strong></p>

<pre class=""lang-sql prettyprint-override""><code>CREATE OR REPLACE TYPE BODY infectados IS 
    STATIC FUNCTION cantidad_fallecidos(cantidad_infectados number,probabilidad_fallecidos number) RETURN number
    IS numero1 number(1);
        BEGIN
            IF cantidad_infectados &gt; probabilidad_fallecidos*cantidad_infectados THEN
                RETURN (probabilidad_fallecidos*cantidad_infectados);
            ELSE
                RAISE_APLICATION_ERROR(-2000,'Error: cantidad_infectados es menor a la probabilidad de fallecidos');
            END IF;
        END;
    END;
</code></pre>

<p><strong><em>Creation of my table</em></strong></p>

<pre class=""lang-sql prettyprint-override""><code>CREATE TABLE Vnzla_infectado(
    vnzlaInf_id NUMBER GENERATED BY DEFAULT ON NULL AS IDENTITY,
    num_infectados infectados
);
</code></pre>

<p><strong><em>Try of insert</em></strong></p>

<pre class=""lang-sql prettyprint-override""><code>INSERT INTO Vnzla_infectado 
VALUES (infectados(100,0.1,infectados.cantidad_fallecidos(100,0.1)));
</code></pre>
"
61044443,"<p>I was looking on Covid daily report confirmed cases, however there is only total number of cases for each country and I would like to get report of daily increase and visualize it then ...
Because I am  new in SQL I am asking here how to make this, so please help me.</p>

<p>Here is official daily report :</p>

<p><a href=""https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"" rel=""nofollow noreferrer"">https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv</a></p>

<p>The report looks like this, I changed numbers for simple.</p>

<pre><code>
Province/State, Country/Region, Lat, Long,  1/22/20,  1/23/20,  1/24/20,  1/25/20,  …,      4.4.2020,

                Afghanistan, 33.0,  65.0,   0,  3,  5,  8, ...last date
                Albania,    41.1533, 20.1683,  0,  2,  4,  10, ... last date        
                Algeria,    28.0339, 1.96, 0,  4,  4,  6, ... last date     

</code></pre>

<p>And my goal is to get something like this</p>

<pre><code>
Province/State, Country/Region, Lat, Long,  1/22/20,  1/23/20,  1/24/20,  1/25/20,  …,      4.4.2020,
                Afghanistan, 33.0, 65.0,  0,  3,  2,  3, ... last date - [last date -1 ]    
                Albania, 41.1533, 20.1683,  0,  2,  2,  6,  ... last date - [last date -1 ]     
                Algeria, 28.0339, 1.96, 0,  4,  0,  2, ... ... last date - [last date -1 ]      

</code></pre>

<p>So in summary the base logic is  (substract between next field columns ) something like this</p>

<pre><code>( 1/23/20 - 1/22/20 )   ( 1/24/20 - 1/23/20 )  ... to the last field column  ( lastN date - [last [N-1] date )
</code></pre>

<p>And because report is updating every day ( every day is 1 column increased ), I would like to make it universal  to get report / substract of all days in row.</p>

<p>Do you have any idea please ?</p>

<p>Thank you</p>

<p>BR</p>

<p>Andrew</p>
"
60867991,"<p>Imagine I have a table for February with users and their COVID-19 quarantine isolation violations during a single day. If the user didn't violate isolation whole day there is no such row in the table for this date.</p>

<pre><code>user date       violations
1    2020-02-01 2
1    2020-02-03 1
1    2020-02-15 2
3    2020-02-04 1
3    2020-02-24 3
</code></pre>

<p>What type of join should I use for my query in order to show every day in February for each user and violations column value (null or 0 if there is no such row):</p>

<pre><code>user date       violations
1    2020-02-01 2
1    2020-02-02 NULL
1    2020-02-03 1
1    2020-02-04 NULL
...
1    2020-02-29 NULL
3    2020-02-01 NULL
3    2020-02-02 NULL
3    2020-02-03 NULL
3    2020-02-04 1
...
3    2020-02-29 NULL
</code></pre>

<p>I have a calendar table for February:</p>

<pre><code>date
2020-02-01
2020-02-02
...
2020-02-29
</code></pre>

<p>I tried a full outer join, but it works as I expected only for one user.</p>
"
61181844,"<p>Hi I have this table.</p>

<pre><code>id  lat     lng     userId
1   12      23      1
2   45      34      2
3   42      34      3
4   33      34      1
5   36      79      2
6   53      98      2
7   23      90      3
8   23      67      1
</code></pre>

<p>Here we have three users. (user ids 1,2,3). I want to get lateset record (id column max value) of each user.
My excepted output is this</p>

<pre><code>userId  lat     lng
1       23      67
2       53      98
3       23      90
</code></pre>

<p>This query will give me group by option</p>

<pre><code>SELECT 
    *
FROM
    covid.locations
GROUP BY userId;
</code></pre>

<p>But how do I combine this with <code>MAX(id)</code> function.</p>
"
61101508,"<p>I am running MySQL Community Server version 8.0.19.</p>

<p>I have been struggling with the following problem whilst working through publicly available COVID19 data. I am using a dataset that is both reliable and of good quality, however the data (total_confirmed) is reported using <strong>cumulative</strong> totals instead of daily counts of infections:</p>

<pre><code>+----------------+---------------------+-----------------+
| country_region | date                | total_confirmed |
+----------------+---------------------+-----------------+
| Afghanistan    | 2020-04-05 00:00:00 |             349 |
| Afghanistan    | 2020-04-06 00:00:00 |             367 |
| Afghanistan    | 2020-04-07 00:00:00 |             423 |
| Albania        | 2020-04-05 00:00:00 |             361 |
| Albania        | 2020-04-06 00:00:00 |             377 |
| Albania        | 2020-04-07 00:00:00 |             383 |
| Algeria        | 2020-04-05 00:00:00 |            1320 |
| Algeria        | 2020-04-06 00:00:00 |            1423 |
| Algeria        | 2020-04-07 00:00:00 |            1468 |
+----------------+---------------------+-----------------+
</code></pre>

<p>My requirement is to have both the cumulative count and the daily new cases. There is an excellent solution for doing this <a href=""https://stackoverflow.com/questions/53769621/sql-how-to-subtract-result-row-1-from-row-2-row-2-from-row-3"">here</a> and it works like a charm on my dataset provided that I focus on one country only (I used a table populated with Afghanistan data only in this example):</p>

<pre><code>SET @prev := NULL;

SELECT country_region
      ,`date` AS DateCreated
      ,total_confirmed - coalesce(@prev, total_confirmed) AS new_cases
      ,(@prev := total_confirmed) AS total_confirmed
FROM (
        SELECT * FROM so_confirmed ORDER BY `date`
     ) t1
GROUP BY
     country_region, total_confirmed, `date`
ORDER BY country_region, DateCreated;
</code></pre>

<p>Output:</p>

<pre><code>+----------------+---------------------+-----------+-----------------+
| country_region | DateCreated         | new_cases | total_confirmed |
+----------------+---------------------+-----------+-----------------+
| Afghanistan    | 2020-04-05 00:00:00 |         0 |             349 |
| Afghanistan    | 2020-04-06 00:00:00 |        18 |             367 |
| Afghanistan    | 2020-04-07 00:00:00 |        56 |             423 |
+----------------+---------------------+-----------+-----------------+
</code></pre>

<p>However, the minute more than one country_region exists in the data, it completely fails and I do not know SQL quite well enough to figure out what I need to change.</p>

<pre><code>+----------------+---------------------+-----------+-----------------+
| country_region | DateCreated         | new_cases | total_confirmed |
+----------------+---------------------+-----------+-----------------+
| Afghanistan    | 2020-04-05 00:00:00 |         0 |             349 |
| Afghanistan    | 2020-04-06 00:00:00 |      -953 |             367 |
| Afghanistan    | 2020-04-07 00:00:00 |     -1000 |             423 |
| Albania        | 2020-04-05 00:00:00 |        12 |             361 |
| Albania        | 2020-04-06 00:00:00 |        10 |             377 |
| Albania        | 2020-04-07 00:00:00 |       -40 |             383 |
| Algeria        | 2020-04-05 00:00:00 |       959 |            1320 |
| Algeria        | 2020-04-06 00:00:00 |      1046 |            1423 |
| Algeria        | 2020-04-07 00:00:00 |      1085 |            1468 |
+----------------+---------------------+-----------+-----------------+
</code></pre>

<p>Desired Output:</p>

<pre><code>+----------------+---------------------+-----------+-----------------+
| country_region | DateCreated         | new_cases | total_confirmed |
+----------------+---------------------+-----------+-----------------+
| Afghanistan    | 2020-04-05 00:00:00 |         0 |             349 |
| Afghanistan    | 2020-04-06 00:00:00 |        18 |             367 |
| Afghanistan    | 2020-04-07 00:00:00 |        56 |             423 |
| Albania        | 2020-04-05 00:00:00 |         0 |             361 |
| Albania        | 2020-04-06 00:00:00 |        16 |             377 |
| Albania        | 2020-04-07 00:00:00 |         6 |             383 |
| Algeria        | 2020-04-05 00:00:00 |         0 |            1320 |
| Algeria        | 2020-04-06 00:00:00 |       103 |            1423 |
| Algeria        | 2020-04-07 00:00:00 |        45 |            1468 |
+----------------+---------------------+-----------+-----------------+
</code></pre>

<p>Any assistance would be greatly appreciated. Obviously in a real-world dataset the new_cases values wouldn't be 0 on 2020-04-05, but in this sample dataset that would be correct.</p>
"
60279157,"<p>We're using sphinx and snippets to do a basic site search.</p>

<pre><code>SELECT id FROM search WHERE MATCH('(@keywords corona)')
</code></pre>

<p>And we're getting matches on ""coronavirus"" and ""coronary"" like we would expect.</p>

<p>But when we later use</p>

<pre><code>CALL SNIPPETS(
    'Wuhan Novel Coronavirus - What you need to know',
    'search',
    'corona',
    '&lt;span class=""mark""&gt;' AS before_match,
    '&lt;/span&gt;' AS after_match,
    '…' AS chunk_separator,
    800 AS limit,
    20 AS around,
    0 AS query_mode
)
</code></pre>

<p>None of these partial matches are being highlighted.</p>

<p>If we search for a full word (replacing ""corona"" in the <code>SELECT</code> and <code>CALL SNIPPETS</code> with e.g. ""coronavirus"") then the full word results are highlighted correctly.</p>

<p>Is there a way we can get <code>CALL SNIPPETS</code> to highlight the partial word matches in the first example like it does with the full word results in the second example?</p>
"
61329327,"<p>I need to create a report for SQL Server Reporting Services (SSRS) where a user can provide an employees name and date ranges and it will return not only that employees door activity between those dates, but also other employees within a time range before and after them.  This is being used to track potential cases and see who else might have come in contact withe that person.  I can get the two separate pieces working, but I can't figure out a way to iterate through the results.</p>

<p>Variables to be set by users:</p>

<pre><code>@Person varchar(max)
@Begin datetime2
@End datetime2
</code></pre>

<p>Query 1:</p>

<pre><code>SELECT Admitted,
Time,
Person,
Door
FROM DoorJournal
WHERE Person like @Person
AND Time BETWEEN @Begin AND @End
</code></pre>

<p>From Query 1, I want to pull in the door and time of the person's access and pass it through to the next query</p>

<pre><code>@Door varchar(max) 
@Entry datetime2
</code></pre>

<p>Query 2:</p>

<pre><code>SELECT Admitted,
Time,
Person,
Door
FROM DoorJournal
WHERE Door like @Door
AND Time BETWEEN (DateAdd(minute,-2,@Entry) AND (DateAdd(minute,15,@Entry)
</code></pre>

<p>I then want to union those results together so we end up with a view like this</p>

<pre><code>Admitted     Time    Door    Person
Yes          9:05    Door 1  Person 1
Yes          9:06    Door 1  Person 2
Yes          9:07    Door 1  Query 1 Person
Yes          9:10    Door 1  Person 3
Yes          10:15   Door 2  Person 5
Yes          10:16   Door 2  Query 1 Person
Yes          10:21   Door 2  Person 4
</code></pre>

<p>The query will be run against one person per time, but each door the person goes through and the time before and after they go through the door should be included so there will be multiple values for door and the times.</p>

<p>I'm not sure how to pass the information from the one query to the other.  I've tried with some subqueries, but never got anything to function as expected.</p>

<pre><code>SELECT Admitted,
Time,
Person,
Door
FROM (SELECT Admitted,
Time,
Person,
Door
FROM DoorJournal
WHERE Person like @Person
AND Time BETWEEN @Begin AND @End) AS P
WHERE Door IN (P.Door)
AND Time BETWEEN (DateAdd(minute,-2,P.Time) AND (DateAdd(minute,15,P.Time)
</code></pre>

<p>Adding solution based on Alan's suggestion:</p>

<pre><code>Select Time, Door
INTO #specific
WHERE Person like @Person
AND Time BETWEEN @Begin AND @End

SELECT Admitted,
Time,
D.Person,
Door
FROM DoorJournal D
INNER JOIN #specific s ON D.Person = S.Person
WHERE D.Door = S.Door
AND D.Time BETWEEN (DateAdd(minute,-2,S.Time) AND (DateAdd(minute,15,S.Time)
</code></pre>
"
60836490,"<p>I do some sql work at a hospital (no COVID cases yet!). There is a table, <code>[dbo].A.diagnosis</code>, that contains a historical record of all diagnoses all of our patients have had. I'm no expert, but the table is... bad. It's used by this ancient piece of software that we use here to handle diagnoses (among other things). The way the table works, it has 30+ columns and 300k+ rows, but no index (except on its primary key). Each time a patient gets their diagnosis updated, all their diagnoses are re-written to the table under the new <code>diagnosis_date</code>. <code>diagnosis_date</code> is stored at datatype <code>date</code> instead of <code>datetime</code>, but it's not uncommon for a patient to have a diagnosis updated multiple times in a day.</p>

<p>I need to get a list of all our currently-admitted patients, and have it be reasonably up to date (I'd say within the last 24 hours is reasonable, but sooner is preferred).</p>

<p>My current best query is still highly variable in run time, taking anywhere from 1 to 15(!!!) minutes to run. That's not acceptable, so I want to know what my options are to improve it.</p>

<p>Sample of data (fictional, only the relevant columns):</p>

<pre><code>-- [dbo].A.diagnosis
+------------+----------------+----------------+----------------+-----------------------------+
| patient_id | diagnosis_type | diagnosis_date | diagnosis_code | diagnosis_text              |
+------------+----------------+----------------+----------------+-----------------------------+
| 0369344991 | I              | 2020-01-04     | E669           | Obesity, unspecified        |
| 0369344991 | I              | 2020-01-04     | M545           | Low back pain               |
| 0369344991 | I              | 2020-01-04     | NULL           | NULL                        | -- Separator
| 0369344991 | U              | 2020-01-04     | E669           | Obesity, unspecified        |
| 0369344991 | U              | 2020-01-04     | M545           | Low back pain               |
| 0369344991 | U              | 2020-01-04     | L709           | Acne, unspecified           | -- Updated later that day to add the acne diagnosis
| 0369344991 | U              | 2020-01-04     | NULL           | NULL                        |
| 0369344991 | U              | 2020-01-16     | E669           | Obesity, unspecified        |
| 0369344991 | U              | 2020-01-16     | L709           | Acne, unspecified           |
| 0369344991 | U              | 2020-01-16     | E785           | Hyperlipidemia, unspecified | -- Updated 12 days later, low back pain resolved, added hyperlipidemia
| 0369344991 | U              | 2020-01-16     | NULL           | NULL                        |
+------------+----------------+----------------+----------------+-----------------------------+

-- [dbo].A.patients
+------------+
| patient_id |
+------------+
| 0369344991 |
+------------+

-- [dbo].B.diagnosis_priority
+----------------+--------------------+
| diagnosis_type | diagnosis_priority |
+----------------+--------------------+
| I              | 1                  |
| A              | 2                  |
| U              | 3                  |
| D              | 4                  |
+----------------+--------------------+
</code></pre>

<p>The query:</p>

<pre><code>SELECT DISTINCT dx.patient_id -- (decimal(10,0), null)
,       dx.diagnosis_date -- (date, null)
,       dx.diagnosis_code -- (varchar(5), null)
,       dx.diagnosis_text -- (varchar(253, null) 
,       dx.diagnosis_type -- (varchar(1), null)
FROM    [dbo].A.patients -- Starting with a list of our current patients.
JOIN    [dbo].A.diagnosis dx
    ON  [dbo].A.patients.patient_id = dx.patient_id
JOIN    [dbo].B.diagnosis_priority dp 
    ON  dx.diagnosis_type = dp.diagnosis_type
-- This is a table I wrote to help determine which diagnoses are more 'up-to-date' if multiple updates are done on 
-- a single day. The join assigns a priority number to each diagnosis_type as diagnosis_priority.
WHERE   dx.diagnosis_code IS NOT NULL
AND     dx.diagnosis_date = ( -- Trying to get the diagnoses as of the most recent diagnosis date.
            SELECT  MAX(dx_a.diagnosis_date) 
            FROM    [dbo].A.diagnosis dx_a 
            WHERE   dx_a.patient_id = dx.patient_id
            ) 
AND     dp.diagnosis_priority = (  
-- Trying to get the highest priority diagnoses applied on the most recent date.
-- A patient will not get a lower priority diagnosis on a later date, but newer diagnoses will not 
-- necessarily get a higher priority in [dbo].A.diagnosis
            SELECT  MAX(dp_a.diagnosis_priority) 
            FROM    [dbo].A.diagnosis dx_a 
            JOIN    [dbo].B.diagnosis_priority dp_a 
                ON dx_a.diagnosis_type = dp_a.diagnosis_type 
            WHERE dx_a.patient_id = dx.patient_id
            )
</code></pre>

<p>I'm a member of <code>db_datareader</code> on <code>[dbo].A</code>, but I'm a member of <code>db_owner</code> on <code>[dbo].B</code> on the same server. Modifying the way <code>[dbo].A.diagnosis</code> functions is not feasible because of the aforementioned ancient piece of software.</p>

<p>If the query can't be improved significantly, I want to know what options I have on <code>[dbo].B</code> to maintain a list of current diagnoses for patients currently at the hospital.</p>
"
61608313,"<p>I have a big size XML document (50.000-100,000) that needs to be parsed on Azure SQL that looks like this:</p>

<pre><code>&lt;?xml version=""1.0"" encoding=""UTF-8""?&gt;
&lt;covid-19 xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns=""http://covid-19.iss.it/XMLSchema/0.1/""&gt;
    &lt;pazienti&gt;
        &lt;paziente&gt;
            &lt;codiceRegionalePaziente&gt;0123456789&lt;/codiceRegionalePaziente&gt;
            &lt;codiceFiscale/&gt;
            &lt;nome&gt;nomeBulk01&lt;/nome&gt;
            &lt;cognome&gt;cognomeBulk01&lt;/cognome&gt;
            &lt;dataNascita&gt;1989-12-31&lt;/dataNascita&gt;
            &lt;sesso&gt;F&lt;/sesso&gt;
            &lt;nazionalita&gt;380&lt;/nazionalita&gt;
            &lt;domicilioIndirizzo/&gt;
            &lt;domicilioCap&gt;00019&lt;/domicilioCap&gt;
            &lt;domicilioComune&gt;058104&lt;/domicilioComune&gt;
            &lt;domicilioProvincia&gt;RM&lt;/domicilioProvincia&gt;
            &lt;residenzaIndirizzo/&gt;
            &lt;residenzaCap/&gt;
            &lt;residenzaComune/&gt;
            &lt;residenzaProvincia/&gt;
            &lt;luogoEsposizione&gt;cinema&lt;/luogoEsposizione&gt;
            &lt;luogoEsposizioneComune&gt;058047&lt;/luogoEsposizioneComune&gt;
            &lt;operatoreSanitario&gt;1&lt;/operatoreSanitario&gt;
            &lt;casoIsolato&gt;9&lt;/casoIsolato&gt;
            &lt;casoCollegato/&gt;
            &lt;codiceTampone&gt;kkk12345&lt;/codiceTampone&gt;
            &lt;dataPrelievo&gt;2020-03-01&lt;/dataPrelievo&gt;
            &lt;codLaboratorioAnalisi&gt;999&lt;/codLaboratorioAnalisi&gt;
            &lt;sequenzaGenoma&gt;9&lt;/sequenzaGenoma&gt;
            &lt;sequenzaInviata&gt;0&lt;/sequenzaInviata&gt;
            &lt;dataInizioSintomi&gt;2020-03-01&lt;/dataInizioSintomi&gt;
            &lt;codRegione&gt;99&lt;/codRegione&gt;
            &lt;patologieCroniche&gt;9&lt;/patologieCroniche&gt;
            &lt;tumoriAttivi/&gt;
            &lt;diabeteMellito/&gt;
            &lt;malattieCardiovascolari/&gt;
            &lt;hiv/&gt;
            &lt;malattieRespiratorieCroniche/&gt;
            &lt;malattieRenali/&gt;
            &lt;altreMalattieMetaboliche/&gt;
            &lt;obesitaBmi30e40/&gt;
            &lt;obesitaBmiOltre40/&gt;
            &lt;malattieEpatiche/&gt;
            &lt;malattieCronicheNeurologiche/&gt;
            &lt;altrePatologie/&gt;
            &lt;altrePatologieDescrizione/&gt;
            &lt;note&gt;test caricamento massivo da file xml&lt;/note&gt;
            &lt;collocazioni&gt;
                &lt;collocazione&gt;
                    &lt;dataCollocazione&gt;2020-03-01&lt;/dataCollocazione&gt;
                    &lt;collocazioneTipo&gt;Ospedale&lt;/collocazioneTipo&gt;
                    &lt;ospedaleNSIS&gt;99999999&lt;/ospedaleNSIS&gt;
                    &lt;ospedaleReparto&gt;Pneumologia&lt;/ospedaleReparto&gt;
                &lt;/collocazione&gt;
            &lt;/collocazioni&gt;
            &lt;statiClinici&gt;
                &lt;statoClinico&gt;
                    &lt;tipoStatoClinico&gt;Asintomatico&lt;/tipoStatoClinico&gt;
                    &lt;dataStatoClinico&gt;2020-03-01&lt;/dataStatoClinico&gt;
                    &lt;terapiaInCorso&gt;0&lt;/terapiaInCorso&gt;
                    &lt;terapiaDescrizione/&gt;
                    &lt;intubato&gt;0&lt;/intubato&gt;
                &lt;/statoClinico&gt;
                &lt;statoClinico&gt;
                    &lt;tipoStatoClinico&gt;Lieve&lt;/tipoStatoClinico&gt;
                    &lt;dataStatoClinico&gt;2020-03-12&lt;/dataStatoClinico&gt;
                    &lt;terapiaInCorso&gt;0&lt;/terapiaInCorso&gt;
                    &lt;terapiaDescrizione/&gt;
                    &lt;intubato&gt;0&lt;/intubato&gt;
                &lt;/statoClinico&gt;
                &lt;statoClinico&gt;
                    &lt;tipoStatoClinico&gt;Critico&lt;/tipoStatoClinico&gt;
                    &lt;dataStatoClinico&gt;2020-03-18&lt;/dataStatoClinico&gt;
                    &lt;terapiaInCorso&gt;0&lt;/terapiaInCorso&gt;
                    &lt;terapiaDescrizione/&gt;
                    &lt;intubato&gt;1&lt;/intubato&gt;
                &lt;/statoClinico&gt;
            &lt;/statiClinici&gt;
        &lt;/paziente&gt;
        &lt;paziente&gt;
            &lt;codiceRegionalePaziente&gt;AABB1234567890&lt;/codiceRegionalePaziente&gt;
            &lt;codiceFiscale&gt;AAABBB00C11D222E&lt;/codiceFiscale&gt;
            &lt;nome&gt;nomeBulk02&lt;/nome&gt;
            &lt;cognome&gt;cognomeBulk02&lt;/cognome&gt;
            &lt;dataNascita&gt;2000-01-31&lt;/dataNascita&gt;
            &lt;sesso&gt;M&lt;/sesso&gt;
            &lt;nazionalita&gt;380&lt;/nazionalita&gt;
            &lt;domicilioIndirizzo&gt;Via del domicilio&lt;/domicilioIndirizzo&gt;
            &lt;domicilioCap&gt;00100&lt;/domicilioCap&gt;
            &lt;domicilioComune&gt;058091&lt;/domicilioComune&gt;
            &lt;domicilioProvincia&gt;RM&lt;/domicilioProvincia&gt;
            &lt;residenzaIndirizzo/&gt;
            &lt;residenzaCap/&gt;
            &lt;residenzaComune/&gt;
            &lt;residenzaProvincia/&gt;
            &lt;luogoEsposizione&gt;centro commerciale&lt;/luogoEsposizione&gt;
            &lt;luogoEsposizioneComune&gt;058091&lt;/luogoEsposizioneComune&gt;
            &lt;operatoreSanitario&gt;0&lt;/operatoreSanitario&gt;
            &lt;casoIsolato&gt;1&lt;/casoIsolato&gt;
            &lt;casoCollegato/&gt;
            &lt;codiceTampone&gt;00AABB-CC&lt;/codiceTampone&gt;
            &lt;dataPrelievo&gt;2020-02-29&lt;/dataPrelievo&gt;
            &lt;codLaboratorioAnalisi&gt;999&lt;/codLaboratorioAnalisi&gt;
            &lt;sequenzaGenoma&gt;1&lt;/sequenzaGenoma&gt;
            &lt;sequenzaInviata&gt;0&lt;/sequenzaInviata&gt;
            &lt;dataInizioSintomi&gt;2020-02-29&lt;/dataInizioSintomi&gt;
            &lt;codRegione&gt;99&lt;/codRegione&gt;
            &lt;patologieCroniche&gt;1&lt;/patologieCroniche&gt;
            &lt;tumoriAttivi&gt;0&lt;/tumoriAttivi&gt;
            &lt;diabeteMellito&gt;0&lt;/diabeteMellito&gt;
            &lt;malattieCardiovascolari&gt;1&lt;/malattieCardiovascolari&gt;
            &lt;hiv&gt;0&lt;/hiv&gt;
            &lt;malattieRespiratorieCroniche&gt;1&lt;/malattieRespiratorieCroniche&gt;
            &lt;malattieRenali&gt;0&lt;/malattieRenali&gt;
            &lt;altreMalattieMetaboliche&gt;0&lt;/altreMalattieMetaboliche&gt;
            &lt;obesitaBmi30e40&gt;0&lt;/obesitaBmi30e40&gt;
            &lt;obesitaBmiOltre40&gt;0&lt;/obesitaBmiOltre40&gt;
            &lt;malattieEpatiche&gt;0&lt;/malattieEpatiche&gt;
            &lt;malattieCronicheNeurologiche&gt;0&lt;/malattieCronicheNeurologiche&gt;
            &lt;altrePatologie&gt;1&lt;/altrePatologie&gt;
            &lt;altrePatologieDescrizione&gt;descrizione altra patologia cronica&lt;/altrePatologieDescrizione&gt;
            &lt;note&gt;test caricamento massivo da file xml&lt;/note&gt;
            &lt;collocazioni&gt;
                &lt;collocazione&gt;
                    &lt;dataCollocazione&gt;2020-03-01&lt;/dataCollocazione&gt;
                    &lt;collocazioneTipo&gt;Domicilio&lt;/collocazioneTipo&gt;
                    &lt;ospedaleNSIS/&gt;
                    &lt;ospedaleReparto/&gt;
                &lt;/collocazione&gt;
                &lt;collocazione&gt;
                    &lt;dataCollocazione&gt;2020-03-05&lt;/dataCollocazione&gt;
                    &lt;collocazioneTipo&gt;Ospedale&lt;/collocazioneTipo&gt;
                    &lt;ospedaleNSIS&gt;99999999&lt;/ospedaleNSIS&gt;
                    &lt;ospedaleReparto&gt;Malattie infettive e tropicali&lt;/ospedaleReparto&gt;
                &lt;/collocazione&gt;
            &lt;/collocazioni&gt;
            &lt;statiClinici&gt;
                &lt;statoClinico&gt;
                    &lt;tipoStatoClinico&gt;Pauci-sintomatico&lt;/tipoStatoClinico&gt;
                    &lt;dataStatoClinico&gt;2020-02-29&lt;/dataStatoClinico&gt;
                    &lt;terapiaInCorso&gt;0&lt;/terapiaInCorso&gt;
                    &lt;terapiaDescrizione/&gt;
                    &lt;intubato&gt;0&lt;/intubato&gt;
                &lt;/statoClinico&gt;
                &lt;statoClinico&gt;
                    &lt;tipoStatoClinico&gt;Severo&lt;/tipoStatoClinico&gt;
                    &lt;dataStatoClinico&gt;2020-03-17&lt;/dataStatoClinico&gt;
                    &lt;terapiaInCorso&gt;1&lt;/terapiaInCorso&gt;
                    &lt;terapiaDescrizione&gt;descrizione  della terapia in corso&lt;/terapiaDescrizione&gt;
                    &lt;intubato&gt;0&lt;/intubato&gt;
                &lt;/statoClinico&gt;
            &lt;/statiClinici&gt;
        &lt;/paziente&gt;
        &lt;paziente&gt;
            &lt;codiceRegionalePaziente&gt;9999999&lt;/codiceRegionalePaziente&gt;
            &lt;codiceFiscale/&gt;
            &lt;nome&gt;nomeBulk03&lt;/nome&gt;
            &lt;cognome&gt;cognomeBulk03&lt;/cognome&gt;
            &lt;dataNascita&gt;2000-01-31&lt;/dataNascita&gt;
            &lt;sesso&gt;M&lt;/sesso&gt;
            &lt;nazionalita&gt;380&lt;/nazionalita&gt;
            &lt;domicilioIndirizzo&gt;Via del domicilio&lt;/domicilioIndirizzo&gt;
            &lt;domicilioCap&gt;00100&lt;/domicilioCap&gt;
            &lt;domicilioComune&gt;058091&lt;/domicilioComune&gt;
            &lt;domicilioProvincia&gt;RM&lt;/domicilioProvincia&gt;
            &lt;residenzaIndirizzo/&gt;
            &lt;residenzaCap/&gt;
            &lt;residenzaComune/&gt;
            &lt;residenzaProvincia/&gt;
            &lt;luogoEsposizione&gt;centro commerciale&lt;/luogoEsposizione&gt;
            &lt;luogoEsposizioneComune&gt;058091&lt;/luogoEsposizioneComune&gt;
            &lt;operatoreSanitario&gt;0&lt;/operatoreSanitario&gt;
            &lt;casoIsolato&gt;1&lt;/casoIsolato&gt;
            &lt;casoCollegato/&gt;
            &lt;codiceTampone&gt;00AABB-CC&lt;/codiceTampone&gt;
            &lt;dataPrelievo&gt;2020-02-29&lt;/dataPrelievo&gt;
            &lt;codLaboratorioAnalisi&gt;999&lt;/codLaboratorioAnalisi&gt;
            &lt;sequenzaGenoma&gt;1&lt;/sequenzaGenoma&gt;
            &lt;sequenzaInviata&gt;0&lt;/sequenzaInviata&gt;
            &lt;dataInizioSintomi&gt;2020-02-29&lt;/dataInizioSintomi&gt;
            &lt;codRegione&gt;99&lt;/codRegione&gt;
            &lt;patologieCroniche&gt;1&lt;/patologieCroniche&gt;
            &lt;tumoriAttivi&gt;0&lt;/tumoriAttivi&gt;
            &lt;diabeteMellito&gt;0&lt;/diabeteMellito&gt;
            &lt;malattieCardiovascolari&gt;1&lt;/malattieCardiovascolari&gt;
            &lt;hiv&gt;0&lt;/hiv&gt;
            &lt;malattieRespiratorieCroniche&gt;1&lt;/malattieRespiratorieCroniche&gt;
            &lt;malattieRenali&gt;0&lt;/malattieRenali&gt;
            &lt;altreMalattieMetaboliche&gt;0&lt;/altreMalattieMetaboliche&gt;
            &lt;obesitaBmi30e40&gt;0&lt;/obesitaBmi30e40&gt;
            &lt;obesitaBmiOltre40&gt;0&lt;/obesitaBmiOltre40&gt;
            &lt;malattieEpatiche&gt;0&lt;/malattieEpatiche&gt;
            &lt;malattieCronicheNeurologiche&gt;0&lt;/malattieCronicheNeurologiche&gt;
            &lt;altrePatologie&gt;1&lt;/altrePatologie&gt;
            &lt;altrePatologieDescrizione&gt;descrizione altra patologia cronica&lt;/altrePatologieDescrizione&gt;
            &lt;note&gt;test caricamento massivo da file xml&lt;/note&gt;
            &lt;collocazioni&gt;
            &lt;/collocazioni&gt;
            &lt;statiClinici&gt;
            &lt;/statiClinici&gt;
        &lt;/paziente&gt;
    &lt;/pazienti&gt;
&lt;/covid-19&gt;
</code></pre>

<p>I need to split it into 3 regular table type dataset (pazienti, collocazioni, statiClinici) and I use the following T-SQL code that works:</p>

<pre><code>SET ANSI_NULLS ON
GO
SET QUOTED_IDENTIFIER ON
GO
    -- SET NOCOUNT ON added to prevent extra result sets from
    -- interfering with SELECT statements.
    SET NOCOUNT ON
DECLARE @StartTime datetime = getdate()
    -- Insert statements for procedure here
    -- DROP temp tables
    if object_id('tempdb..#xmlPazienti') is not null DROP TABLE #xmlPazienti;
    if object_id('tempdb..#xmlCollocazioni') is not null DROP TABLE #xmlCollocazioni;
    if object_id('tempdb..#xmlStatiClinici') is not null DROP TABLE #xmlStatiClinici;

    -- pazienti --
    CREATE TABLE #xmlPazienti
    (
        [patientId] [int] NULL
        ,[codiceFiscale] [varchar](16) NULL
        ,[nome] [nvarchar](255) NULL
        ,[cognome] [nvarchar](255) NULL
        ,[dataNascita] [datetime] NULL
        ,[sesso] [char](1) NULL
        ,[nazionalita] [smallint] NULL
        ,[domicilioInd] [varchar](255) NULL
        ,[domicilioCap] [varchar](10) NULL
        ,[domicilioCom] [varchar](255) NULL
        ,[domicilioProv] [varchar](255) NULL
        ,[residenzaInd] [varchar](255) NULL
        ,[residenzaCap] [varchar](10) NULL
        ,[residenzaCom] [varchar](255) NULL
        ,[residenzaProv] [varchar](255) NULL
        ,[luogoEsp] [nvarchar](500) NULL
        ,[luogoEspCom] [varchar](255) NULL
        ,[operatoreSanitario] [tinyint] NULL
        ,[casoIsolato] [tinyint] NULL
        ,[casoCollegato] [varchar](500) NULL
        ,[CodiceTampone] [varchar](255) NULL
        ,[dataPrelievo] [date] NULL
        ,[LaboratorioAnalisiId] [smallint] NULL
        ,[sequenzaGenoma] [tinyint] NULL
        ,[sequenzaInviata] [tinyint] NULL
        ,[DataInizioSintomi] [date] NULL
        ,[codRegione] [smallint] NULL
        ,[PatologieCroniche] [tinyint] NULL
        ,[TumoriAttivi] [tinyint] NULL
        ,[DiabeteMellito] [tinyint] NULL
        ,[MalattieCardiovascolari] [tinyint] NULL
        ,[HIV] [tinyint] NULL
        ,[MalattieRespiratorieCroniche] [tinyint] NULL
        ,[MalattieRenali] [tinyint] NULL
        ,[AltreMalattieMetaboliche] [tinyint] NULL
        ,[ObesitàBMI30e40] [tinyint] NULL
        ,[ObesitàBMIoltre40] [tinyint] NULL
        ,[MalattieEpatiche] [tinyint] NULL
        ,[MalattieCronicheNeurologiche] [tinyint] NULL
        ,[AltrePatologie] [tinyint] NULL
        ,[AltrePatologieDescrizione] [nvarchar](500) NULL
        ,[Note] [nvarchar](4000) NULL
        ,[patientID_reg] [nvarchar](50) NULL
        ,[flagBaseline] [int] NULL
    )
    -- pazienti --

    -- collocazioni --
    CREATE TABLE #xmlCollocazioni
    (
    dataRicovero date NULL
    ,collocazioneId int NULL
    ,idOspedale nvarchar(255) NULL
    ,CodReparto int NULL
    ,patientID int NULL
    ,patientID_reg nvarchar(50) NULL
    ,collocazioneTipo nvarchar(50) NULL
    ,ospedaleReparto nvarchar(255) NULL
    );
    -- collocazioni --

    -- stati clinici --
    CREATE TABLE #xmlStatiClinici
    (
    patientID int NULL
    ,statoClinicoId int NULL
    ,dataStatoClinico date NULL
    ,terapiaInCorso int NULL
    ,terapia nvarchar(1000) NULL
    ,Intubato int NULL
    ,patientID_reg nvarchar(50) NULL
    ,tipoStatoClinico nvarchar(50) NULL
    );
    -- stati clinici --

    -- index on temp tables --
        CREATE INDEX ixTmp_patient_patientId ON #xmlPazienti (patientId);
        CREATE INDEX ixTmp_patient_patientID_reg ON #xmlPazienti (patientID_reg);
        CREATE INDEX ixTmp_patient_codRegione ON #xmlPazienti (codRegione) INCLUDE (patientId);
        CREATE INDEX ixTmp_patient_LaboratorioAnalisiId ON #xmlPazienti (LaboratorioAnalisiId);
        CREATE INDEX ixTmp_ricovero_patientId ON #xmlCollocazioni (patientId);
        CREATE INDEX ixTmp_ricovero_patientID_reg ON #xmlCollocazioni (patientID_reg);
        CREATE INDEX ixTmp_ricovero_collocazioneID ON #xmlCollocazioni (collocazioneID);
        CREATE INDEX ixTmp_ricovero_idOspedale ON #xmlCollocazioni (idOspedale);
        CREATE INDEX ixTmp_ricovero_codReparto ON #xmlCollocazioni (codReparto);
        CREATE INDEX ixTmp_monitoring_patientId ON #xmlStatiClinici (patientId);
        CREATE INDEX ixTmp_monitoring_patientID_reg ON #xmlStatiClinici (patientID_reg);
        CREATE INDEX ixTmp_monitoring_statoClinicoId ON #xmlStatiClinici (statoClinicoId);
    -- index on temp tables --


DECLARE @StartTimeInsertPazienti datetime = getdate()
DECLARE @fId INT = 187
DECLARE @XML AS XML
SELECT @XML = XMLData FROM XMLbulkLoad WHERE Id = @fId
;WITH XMLNAMESPACES(DEFAULT 'http://covid-19.iss.it/XMLSchema/0.1/')
    -- pazienti --
    INSERT INTO #xmlPazienti WITH (TABLOCK) ([patientID_reg],[codiceFiscale],[cognome],[nome],[dataNascita],[sesso],[nazionalita],[domicilioInd],[domicilioCap],[domicilioCom],[domicilioProv],[residenzaInd],[residenzaCap],[residenzaCom],[residenzaProv],[luogoEsp],[luogoEspCom],[operatoreSanitario],[casoIsolato],[casoCollegato],[CodiceTampone],[dataPrelievo],[LaboratorioAnalisiId],[sequenzaGenoma],[sequenzaInviata],[DataInizioSintomi],[codRegione],[PatologieCroniche],[TumoriAttivi],[DiabeteMellito],[MalattieCardiovascolari],[HIV],[MalattieRespiratorieCroniche],[MalattieRenali],[AltreMalattieMetaboliche],[ObesitàBMI30e40],[ObesitàBMIoltre40],[MalattieEpatiche],[MalattieCronicheNeurologiche],[AltrePatologie],[AltrePatologieDescrizione],[Note])
    SELECT   ISNULL(paz.value('(codiceRegionalePaziente/text())[1]', 'nvarchar(50)'),NULL) AS [patientID_reg]  
            ,ISNULL(paz.value('(codiceFiscale/text())[1]', 'varchar(16)'),NULL) AS [codiceFiscale]
            ,ISNULL(paz.value('(cognome/text())[1]', 'nvarchar(255)'),NULL) AS [cognome]
            ,ISNULL(paz.value('(nome/text())[1]', 'nvarchar(255)'),NULL) AS [nome]
            ,ISNULL(paz.value('(dataNascita/text())[1]', 'datetime'),NULL) AS [dataNascita]
            ,ISNULL(paz.value('(sesso/text())[1]', 'char(1)'),NULL) AS [sesso]
            ,ISNULL(paz.value('(nazionalita/text())[1]', 'smallint'),NULL) AS [nazionalita]
            ,ISNULL(paz.value('(domicilioIndirizzo/text())[1]', 'varchar(255)'),NULL) AS [domicilioInd]
            ,ISNULL(paz.value('(domicilioCap/text())[1]', 'varchar(10)'),NULL) AS [domicilioCap]
            ,ISNULL(paz.value('(domicilioComune/text())[1]', 'varchar(255)'),NULL) AS [domicilioCom]
            ,ISNULL(paz.value('(domicilioProvincia/text())[1]', 'varchar(255)'),NULL) AS [domicilioProv]
            ,ISNULL(paz.value('(residenzaIndirizzo/text())[1]', 'varchar(255)'),NULL) AS [residenzaInd]
            ,ISNULL(paz.value('(residenzaCap/text())[1]', 'varchar(10)'),NULL) AS [residenzaCap]
            ,ISNULL(paz.value('(residenzaComune/text())[1]', 'varchar(255)'),NULL) AS [residenzaCom]
            ,ISNULL(paz.value('(residenzaProvincia/text())[1]', 'varchar(255)'),NULL) AS [residenzaProv]
            ,ISNULL(paz.value('(luogoEsposizione/text())[1]', 'nvarchar(500)'),NULL) AS [luogoEsp]
            ,ISNULL(paz.value('(luogoEsposizioneComune/text())[1]', 'varchar(255)'),NULL) AS [luogoEspCom]
            ,ISNULL(paz.value('(operatoreSanitario/text())[1]', 'tinyint'),NULL) AS [operatoreSanitario]
            ,ISNULL(paz.value('(casoIsolato/text())[1]', 'tinyint'),NULL) AS [casoIsolato]
            ,ISNULL(paz.value('(casoCollegato/text())[1]', 'varchar(500)'),NULL) AS [casoCollegato]
            ,ISNULL(paz.value('(codiceTampone/text())[1]', 'varchar(255)'),NULL) AS [CodiceTampone]
            ,ISNULL(paz.value('(dataPrelievo/text())[1]', 'date'),NULL) AS [dataPrelievo]
            ,ISNULL(paz.value('(codLaboratorioAnalisi/text())[1]', 'smallint'),NULL) AS [LaboratorioAnalisiId]
            ,ISNULL(paz.value('(sequenzaGenoma/text())[1]', 'tinyint'),NULL) AS [sequenzaGenoma]
            ,ISNULL(paz.value('(sequenzaInviata/text())[1]', 'tinyint'),NULL) AS [sequenzaInviata]
            ,ISNULL(paz.value('(dataInizioSintomi/text())[1]', 'date'),NULL) AS [dataInizioSintomi]
            ,ISNULL(paz.value('(codRegione/text())[1]', 'smallint'),'') AS [codRegione]
            ,ISNULL(paz.value('(patologieCroniche/text())[1]', 'tinyint'),NULL) AS [patologieCroniche]
            ,ISNULL(paz.value('(tumoriAttivi/text())[1]', 'tinyint'),NULL) AS [tumoriAttivi]
            ,ISNULL(paz.value('(diabeteMellito/text())[1]', 'tinyint'),NULL) AS [diabeteMellito]
            ,ISNULL(paz.value('(malattieCardiovascolari/text())[1]', 'tinyint'),NULL) AS [malattieCardiovascolari]
            ,ISNULL(paz.value('(hiv/text())[1]', 'tinyint'),NULL) AS [hiv]
            ,ISNULL(paz.value('(malattieRespiratorieCroniche/text())[1]', 'tinyint'),NULL) AS [malattieRespiratorieCroniche]
            ,ISNULL(paz.value('(malattieRenali/text())[1]', 'tinyint'),NULL) AS [malattieRenali]
            ,ISNULL(paz.value('(altreMalattieMetaboliche/text())[1]', 'tinyint'),NULL) AS [altreMalattieMetaboliche]
            ,ISNULL(paz.value('(obesitaBmi30e40/text())[1]', 'tinyint'),NULL) AS [ObesitàBMI30e40]
            ,ISNULL(paz.value('(obesitaBmiOltre40/text())[1]', 'tinyint'),NULL) AS [ObesitàBMIoltre40]
            ,ISNULL(paz.value('(malattieEpatiche/text())[1]', 'tinyint'),NULL) AS [malattieEpatiche]
            ,ISNULL(paz.value('(malattieCronicheNeurologiche/text())[1]', 'tinyint'),NULL) AS [malattieCronicheNeurologiche]
            ,ISNULL(paz.value('(altrePatologie/text())[1]', 'tinyint'),NULL) AS [altrePatologie]
            ,ISNULL(paz.value('(altrePatologieDescrizione/text())[1]', 'nvarchar(500)'),NULL) AS [altrePatologieDescrizione]
            ,ISNULL(paz.value('(note/text())[1]', 'nvarchar(4000)'),NULL) AS [note]
    FROM  
         @XML.nodes('covid-19/pazienti/paziente') AS A(paz)
         --OPTION (OPTIMIZE FOR UNKNOWN)
         --OPTION (RECOMPILE)
    -- pazienti --
DECLARE @EndTimeInsertPazienti datetime = getdate()
SELECT DATEDIFF (SS ,@StartTimeInsertPazienti,@EndTimeInsertPazienti) AS PazientiInsertDuration

DECLARE @StartTimeInsertCollocazioni datetime = getdate()
    -- collocazioni --
    --SELECT @XML = XMLData FROM XMLbulkLoadDEV WHERE Id = @fID
    --;WITH XMLNAMESPACES(DEFAULT 'http://covid-19.iss.it/XMLSchema/0.1/')
    INSERT INTO #xmlCollocazioni WITH (TABLOCK) (patientID_reg, dataRicovero, collocazioneTipo, idOspedale, ospedaleReparto)
    SELECT  COALESCE(paz.value('(codiceRegionalePaziente/text())[1]', 'nvarchar(50)'),NULL) AS [patientID_reg]      
            ,COALESCE(coll.value('(dataCollocazione/text())[1]', 'date'),NULL) AS [dataRicovero]
            ,COALESCE(coll.value('(collocazioneTipo/text())[1]', 'nvarchar(50)'),NULL) AS [collocazioneTipo]
            ,COALESCE(coll.value('(ospedaleNSIS/text())[1]', 'nvarchar(255)'),NULL) AS [idOspedale]
            ,COALESCE(coll.value('(ospedaleReparto/text())[1]', 'nvarchar(255)'),NULL) AS [ospedaleReparto]
    FROM  
         @XML.nodes('covid-19/pazienti/paziente') AS A(paz) 
     OUTER APPLY 
         paz.nodes('collocazioni/collocazione') B(coll)
         --OPTION (OPTIMIZE FOR UNKNOWN)
         --OPTION (RECOMPILE)
    -- collocazioni --
DECLARE @EndTimeInsertCollocazioni datetime = getdate()
SELECT DATEDIFF (SS ,@StartTimeInsertCollocazioni,@EndTimeInsertCollocazioni) AS CollocazioniInsertDuration

DECLARE @StarTimeInsertStatiClinici datetime = getdate()

    -- stati clinici --
    --SELECT @XML = XMLData FROM XMLbulkLoadDEV WHERE Id = @fID
    --;WITH XMLNAMESPACES(DEFAULT 'http://covid-19.iss.it/XMLSchema/0.1/')
    INSERT INTO #xmlStatiClinici WITH (TABLOCK) (patientID_reg, tipoStatoClinico, dataStatoClinico, terapiaInCorso, terapia, intubato)
    SELECT   ISNULL(paz.value('(codiceRegionalePaziente/text())[1]', 'nvarchar(50)'),NULL) AS [patientID_reg]      
            ,ISNULL(sc.value('(tipoStatoClinico/text())[1]', 'nvarchar(50)'),NULL) AS [tipoStatoClinico]
            ,ISNULL(sc.value('(dataStatoClinico/text())[1]', 'date'),NULL) AS [dataStatoClinico]
            ,ISNULL(sc.value('(terapiaInCorso/text())[1]', 'int'),0) AS [terapiaInCorso]
            ,ISNULL(sc.value('(terapiaDescrizione/text())[1]', 'nvarchar(1000)'),NULL) AS [terapia]
            ,ISNULL(sc.value('(intubato/text())[1]', 'int'),NULL) AS [intubato]
    FROM  
         @XML.nodes('covid-19/pazienti/paziente') AS A(paz) 
     OUTER APPLY 
         paz.nodes('statiClinici/statoClinico') C(sc)
        --OPTION (OPTIMIZE FOR UNKNOWN)
        --OPTION (RECOMPILE)
    -- stati clinici --
DECLARE @EndTimeInsertStatiClinici datetime = getdate()
SELECT DATEDIFF (SS ,@StarTimeInsertStatiClinici,@EndTimeInsertStatiClinici) AS StatiCliniciInsertDuration
    --
    --select * from XMLbulkLoad

DECLARE @EndTimeInsert datetime = getdate()
SELECT DATEDIFF (SS ,@StartTimeInsertPazienti,@EndTimeInsertStatiClinici) AS TotalInsertDuration

    -- DROP temp tables
    if object_id('tempdb..#xmlPazienti') is not null DROP TABLE #xmlPazienti;
    if object_id('tempdb..#xmlCollocazioni') is not null DROP TABLE #xmlCollocazioni;
    if object_id('tempdb..#xmlStatiClinici') is not null DROP TABLE #xmlStatiClinici;
</code></pre>

<p>The problem is that when there are a few hundred (or fewer)  elements in the XML, the query performs just fine. However, when there are 25,000  elements, it takes 50 seconds to finish returning the rows in SSMS and I could have 50-100,000  elements.</p>

<p>Is there a more efficient way to transform the XML document into the tabular dataset (in SQL)?</p>
"
61075734,"<h2>The context</h2>

<p>I have just one Cassandra node, installed locally on my PC with Windows 10 (Core i5, 16GB ram, SSD drive).</p>

<p>I created a table like this:</p>

<pre><code>CREATE KEYSPACE covid19 WITH replication = {
    'class':              'SimpleStrategy',
    'replication_factor': '1'
};


CREATE TABLE covid19.cases (
    pesel       text,
    test_date   date,
    result      boolean,
    PRIMARY KEY ((pesel), test_date)
)
WITH CLUSTERING ORDER BY (test_date DESC);
</code></pre>

<p>The <code>pesel</code> is unique, 10-digits id of a person.</p>

<p>Then I generated 10 000 rows of sample data, that looks like this:</p>

<pre><code>INSERT INTO cases (pesel, test_date, result) VALUES ('0000000001', '2020-03-10', true);
INSERT INTO cases (pesel, test_date, result) VALUES ('0000000002', '2020-03-10', false);
INSERT INTO cases (pesel, test_date, result) VALUES ('0000000003', '2020-03-10', false);
INSERT INTO cases (pesel, test_date, result) VALUES ('0000000004', '2020-03-12', false);
INSERT INTO cases (pesel, test_date, result) VALUES ('0000000005', '2020-03-12', false);
INSERT INTO cases (pesel, test_date, result) VALUES ('0000000006', '2020-03-12', false);
...
</code></pre>

<p>Finally, I loaded the data using cqlsh: <code>source 'cases.cql';</code></p>

<h2>Problem 1</h2>

<p>To load 10 000 rows it takes 51 seconds. Is that normal?</p>

<p>I was expecting inserts to Cassandra to be ultra fast, while this pretty much comparable with SQLite <strong>without transaction</strong> (59s). If I wrap inserts with <code>BEGIN</code> &amp; <code>COMMIT</code> in SQLite, this takes less than a second. This brings us to another problem...</p>

<h2>Problem 2</h2>

<p>Batch inserting. Slow batch inserting. To single partition, on single node.</p>

<p>I wrapped inserts with <code>BEGIN BATCH</code> and <code>APPLY BATCH;</code>. After that, the <code>source</code> was taking so long, I stopped measuring after passing 4 minutes mark.</p>

<p>Yes, I am aware of wrong usage of batch inserts. As far as I understood, it is an anti-pattern to use batch insert if it would require inserts to different partitions, which makes sense. This is not the case here.</p>

<p>Why is batch inserting so slow on single node (thus single partition)?</p>

<p>What am I missing here?</p>
"
61650005,"<p>I was wondering if any of you could help me to improve this query</p>

<pre><code>SELECT IF(cases.country_region LIKE '%Korea%', 'South Korea', IF(upper(cases.country_region) = 'IRAN (ISLAMIC REPUBLIC OF)', 'Iran',  
        IF(upper(cases.country_region) = 'REPUBLIC OF IRELAND', 'IRELAND', 
        IF(cases.country_region = 'United Kingdom', 'UK', IF(upper(cases.country_region) = 'REPUBLIC OF MOLDOVA', 'MOLDOVA', cases.country_region))))) as country, (SUM(cases.latitude)/COUNT(cases.latitude)) as latitude, 
        (SUM(cases.longitude)/COUNT(cases.longitude)) as longitude, SUM(case when cases.confirmed is null then 0 else cases.confirmed end) as total_confirmed, 
        SUM(case when cases.deaths is null then 0 else cases.deaths end) as total_deaths, SUM(case when cases.recovered is null then 0 else cases.recovered end) as total_recovered, 
        SUM(case when cases.active is null then 0 else cases.active end) as total_active_cases, MAX(cases.date) as last_update
        FROM
        `bigquery-public-data.covid19_jhu_csse.summary` cases
        INNER JOIN (
            SELECT c.country_region, MAX(c.date) as maxdate
            FROM    `bigquery-public-data.covid19_jhu_csse.summary` c
            WHERE c.date &lt;= '2020-05-07'
            GROUP BY c.country_region
        ) lcases ON cases.country_region = lcases.country_region AND cases.date = lcases.maxdate
        GROUP BY country
        HAVING total_confirmed &gt; 0
        ORDER BY total_confirmed desc;
</code></pre>

<p>I don't really know if there is any way to simplify the first IF(case) part.</p>

<p>If someone has any idea please comment below!
Thank you very much!</p>
"
61399150,"<p>Using PostgreSQL 12, I am attempting to import data from a CSV with the following format:</p>

<pre><code>country,state,county,lat,lng,type,measure,beds,population,year,source,source_url
US,AK,ketchikan gateway,63.588753,-154.493062,ICU,1000HAB,3.928701,13745,2018,arcgis,https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0
US,AK,kodiak island,63.588753,-154.493062,ACUTE,1000HAB,,n,2018,arcgis,https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_1/FeatureServer/0

</code></pre>

<p>Notice that the second row's ""population"" field has an <code>n</code> instead of empty. My goal is to import the CSV so that the ""population"" column is BIGINT and ""n"" is replaced with NULL. My current solution is:</p>

<pre><code>CREATE TABLE temp_table
(
    country CHAR(2),
    state CHAR(2),
    county VARCHAR(255),
    lat DOUBLE PRECISION,
    lng DOUBLE PRECISION,
    type VARCHAR(11),
    measure VARCHAR(255),
    beds DOUBLE PRECISION,
    pop VARCHAR(255),
    year SMALLINT,
    source VARCHAR(255),
    source_url VARCHAR(255)
);

COPY temp_table 
FROM 'C:\\Users\\mconr\\Downloads\\global-hospital-beds-capacity-for-covid19\\hospital_beds_USA_v1.CSV' 
WITH (DELIMITER ',', FORMAT CSV, HEADER TRUE);

SELECT country, state, county, lat, lng, type, measure, beds, CAST (NULLIF (pop, 'n') AS BIGINT) AS population, year, source, source_url 
INTO USA
FROM temp_table;

DROP TABLE temp_table;
</code></pre>

<p>My current solution is to create a temporary table where ""population"" is VARCHAR(255), import the data, create a new table from a SELECT statement that replaces ""n"" with NULL and casts the column to BIGINT, then delete the temp table. However, this seems to be a little inefficient, since I am creating and deleting an intermediate table. Does anyone know a better way of doing this?</p>
"
61406838,"<p>First UseCase:- </p>

<pre><code>let htmlStringPara =""&lt;p&gt;&lt;strong&gt;What is the 2019 novel coronavirus (COVID-19)?&lt;/strong&gt;&lt;br /&gt;&lt;br /&gt;It is a virus that causes a respiratory infection.&lt;br /&gt;&lt;strong&gt;How you can protect yourself against the 2019 novel coronavirus:&lt;/strong&gt;&lt;br /&gt;&lt;br /&gt;These everyday tips below can help to prevent the spread, reduce exposure and protect your health:&lt;/p&gt;

let StringPara =  htmlStringPara.html2String
print(StringPara)

What is the 2019 novel coronavirus (COVID-19)?  It is a virus that causes a respiratory infection.  How you can protect yourself against the 2019 novel coronavirus:  These everyday tips below can help to prevent the spread, reduce exposure and protect your health

Second UseCase:- 

let htmlStrng = ""@@@@-/:;()$&amp;amp;@“‘!?,.[]{}#%^*+=•£¥€&amp;gt;&lt;|\\_.,?!’😍😂😂😂😀😌😞😝😝😝😝😝😛😛😛🚠🚠🚠😊😊😊😊zzzz /&gt;""
let convertHtmlString = htmlStrng.html2String
print(convertHtmlString)
//output 
""@@@@-/:;()$&amp;@â€œâ€˜!?,.[]{}#%^*+=â€¢Â£Â¥â‚¬&gt;&lt;|\\_.,?!â€™ðŸ˜ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜€ðŸ˜ŒðŸ˜žðŸ˜ðŸ˜ðŸ˜ðŸ˜ðŸ˜ðŸ˜›ðŸ˜›ðŸ˜›ðŸš ðŸš ðŸš ðŸ˜ŠðŸ˜ŠðŸ˜ŠðŸ˜Šzzzz /&gt;
</code></pre>

<p>I am really confused because I am trying to convert html to string and show on textview. In Frist use case html converts properly to string, but in second use case in html contain emoji or or special charter are not working properly. I am using below code to convert html to string. Please Let me know its right way if I am wrong, please let me know the right and best way to convert html to string and show on textview.</p>

<pre><code>var html2AttributedString: NSAttributedString? {
    do {
        return try NSAttributedString(data: Data(utf8), options: [NSAttributedString.DocumentReadingOptionKey.defaultAttributes : String.Encoding.utf8.rawValue,NSAttributedString.DocumentReadingOptionKey.documentType: NSAttributedString.DocumentType.html], documentAttributes: nil)
    } catch {
        return nil
    }
}

var html2String: String {
    return html2AttributedString?.string ?? """"
}
</code></pre>

<p>Can someone please explain to me how to show html to string with emoji. Any help would be greatly appreciated.</p>

<p>Thanks in advance.</p>
"
60728897,"<p>I added a notice for the COVID-19 pandemic to the website I maintain for my chiropractor and it is not rendering properly on her iPhone X. (The colour of the text and background and the padding around the paragraph are all wrong.) How do I figure out what is going wrong? Everything is fine in my Windows laptop and my Android phone. She literally bought her phone yesterday so it is presumably up-to-date with the latest version of the OS and Safari.</p>

<p>I have to admit that I don't normally test for iPhones because no one has ever had a complaint about how the site looked in their iPhone. But now I have a complaint and it turns out to be from the customer herself. Naturally, I want to fix the problem and get in the habit of always testing for the most common phones. Better late than never, right?</p>

<p>So what is standard practice for testing on different operating systems and phones? Which OSes and phones do people normally test on and what tools do they use to do the testing? Am I correct in assuming that I should use an iOS simulator or emulator to test on iPhones? </p>
"
60762021,"<p>When I want to log out of my app I want to show the initial view that has the ""log in"" / ""create account"" page using the NavigationLink. I used the exact same method in other places of the app and it works there, but here it doesn't. Here is my code:</p>

<pre><code>import SwiftUI

var signOut = false

struct SignOut: View {

    @Environment(\.presentationMode) var presentationMode: Binding&lt;PresentationMode&gt;
    @State private var curent: Int? = nil

    var body: some View {
        VStack {
            NavigationLink(destination: ContentView(), tag: 1, selection: $curent) {
                EmptyView()
            }.buttonStyle(PlainButtonStyle())

            Button(action: {
                let defaults = UserDefaults.standard
                defaults.set(false, forKey: ""isLoggedIn"")
                defaults.set("""", forKey: ""token"")

                if contentViewVerify
                {
                    print(""content true"")
                    self.presentationMode.wrappedValue.dismiss()
                }
                else if contentViewVerify == false
                {
                    print(""content false"")
                    self.curent = 1 // if contentViewVerify is false I want to use the NavigationLink method which activates once curent = 1
                }

            }) {
                Text(""SignOut"")
            }.navigationBarTitle(""covid"")
            .navigationBarBackButtonHidden(true)
            .onAppear(perform: {
                signOut = true
            })
        }
    }
}

struct SignOut_Previews: PreviewProvider {
    static var previews: some View {
        SignOut()
    }
}
</code></pre>

<p>Thank you in advance!</p>
"
61104043,"<p>I'm using Swift 5 to make an iOS app that interacts with an API based on the user's locale. I'm currently having issues only parsing one JSONObject, rather than parsing/printing the results of all JSONObjects in the array. In other words, I'd like to get a key/value pair based on another key/value pair. The endpoint I'm using is <a href=""https://covid19api.herokuapp.com/confirmed"" rel=""nofollow noreferrer"">https://covid19api.herokuapp.com/confirmed</a>. I'm trying to get the user's country code with this snippet (which works, no problems there): </p>

<pre><code>import Foundation

let locale = NSLocale.current

func requestLocale() -&gt; String {
    return(locale.regionCode!)
}
</code></pre>

<p>And I need to search within a JSONObject that contains that country code for an item called <code>latest</code>. Here's my code for the API Request (This returns some data I have put below the code):</p>

<pre><code>import Foundation

struct WorldWide: Decodable {
    let latest: Int
    let locations: [Country]
}
struct Country: Decodable {
    let country_code: String = ""\(requestLocale())""
    let latest: Int
}

func APIRequest() {
    guard let url = URL(string: ""https://covid19api.herokuapp.com/confirmed"") else {fatalError(""Could not get data from the API"")}
    let session = URLSession.shared
    session.dataTask(with: url) {(data, response, error) in
        guard let data = data else {return}
        do {
            let decoded = try JSONDecoder().decode(WorldWide.self, from: data)
            print(decoded)
        } catch {print(error)}
    }.resume()
}
</code></pre>

<p>Keep in mind the first <code>latest</code> within <code>WorldWide</code> is at the top level, while the JSONObjects are within an array called <code>locations</code> and each JSONObject contains a <code>latitude</code>, <code>longitude</code>, <code>country</code>, <code>country_code</code>, <code>history</code>, and <code>latest</code> (I'm not using camelCase because the dataset doesn't). All I need to access are the <code>country_code</code>, which I have from the user's locale, and the <code>latest</code>, which I need to get ONLY from the JSONObject that contains the <code>country_code</code>. </p>

<p>Running the above code will give me this: </p>

<pre><code>WorldWide(latest: 1426096, locations: [Dark.Country(country_code: ""US"", latest: 423), Dark.Country(country_code: ""US"", latest: 383), Dark.Country(country_code: ""US"", latest: 1468), Dark.Country(country_code: ""US"", latest: 545), Dark.Country(country_code: ""US"", latest: 17), Dark.Country(country_code: ""US"", latest: 19), Dark.Country(country_code: ""US"", latest: 1628), Dark.Country(country_code: ""US"", latest: 853), Dark.Country(country_code: ""US"", latest: 96), Dark.Country(country_code: ""US"", latest: 2686), Dark.Country(country_code: ""US"", latest: 28), Dark.Country(country_code: ""US"", latest: 934), Dark.Country(country_code: ""US"", latest: 411), Dark.Country(country_code: ""US"", latest: 89), Dark.Country(country_code: ""US"", latest: 1191), Dark.Country(country_code: ""US"", latest: 460), Dark.Country(country_code: ""US"", latest: 12639), Dark.Country(country_code: ""US"", latest: 717), Dark.Country(country_code: ""US"", latest: 33), Dark.Country(country_code: ""US"", latest: 811), Dark.Country(country_code: ""US"", latest: 164), Dark.Country(country_code: ""US"", latest: 63), Dark.Country(country_code: ""US"", latest: 861), Dark.Country(country_code: ""US"", latest: 22194), Dark.Country(country_code: ""US"", latest: 26), Dark.Country(country_code: ""US"", latest: 5), Dark.Country(country_code: ""US"", latest: 194), Dark.Country(country_code: ""US"", latest: 764), Dark.Country(country_code: ""US"", latest: 14034), Dark.Country(country_code: ""US"", latest: 135), Dark.Country(country_code: ""US"", latest: 577), Dark.Country(country_code: ""US"", latest: 384), Dark.Country(country_code: ""US"", latest: 7), Dark.Country(country_code: ""US"", latest: 115), Dark.Country(country_code: ""US"", latest: 658), Dark.Country(country_code: ""US"", latest: 1373), Dark.Country(country_code: ""US"", latest: 1266), Dark.Country(country_code: ""US"", latest: 13), Dark.Country(country_code: ""US"", latest: 217), Dark.Country(country_code: ""US"", latest: 105), Dark.Country(country_code: ""US"", latest: 228), Dark.Country(country_code: ""US"", latest: 310), Dark.Country(country_code: ""US"", latest: 4726), Dark.Country(country_code: ""US"", latest: 22), Dark.Country(country_code: ""US"", latest: 9340), Dark.Country(country_code: ""US"", latest: 260), Dark.Country(country_code: ""US"", latest: 8), Dark.Country(country_code: ""US"", latest: 10), Dark.Country(country_code: ""US"", latest: 5116), Dark.Country(country_code: ""US"", latest: 990), Dark.Country(country_code: ""US"", latest: 587), Dark.Country(country_code: ""US"", latest: 579), Dark.Country(country_code: ""US"", latest: 351), Dark.Country(country_code: ""US"", latest: 139), Dark.Country(country_code: ""US"", latest: 1533), Dark.Country(country_code: ""US"", latest: 254), Dark.Country(country_code: ""US"", latest: 146), Dark.Country(country_code: ""US"", latest: 168), Dark.Country(country_code: ""US"", latest: 327), Dark.Country(country_code: ""US"", latest: 544), Dark.Country(country_code: ""US"", latest: 1276), Dark.Country(country_code: ""US"", latest: 935), Dark.Country(country_code: ""US"", latest: 67803), Dark.Country(country_code: ""US"", latest: 1019), Dark.Country(country_code: ""US"", latest: 121), Dark.Country(country_code: ""US"", latest: 651), Dark.Country(country_code: ""US"", latest: 937), Dark.Country(country_code: ""US"", latest: 98), Dark.Country(country_code: ""US"", latest: 144), Dark.Country(country_code: ""US"", latest: 44), Dark.Country(country_code: ""US"", latest: 75), Dark.Country(country_code: ""US"", latest: 18), Dark.Country(country_code: ""US"", latest: 256), Dark.Country(country_code: ""US"", latest: 781), Dark.Country(country_code: ""US"", latest: 538), Dark.Country(country_code: ""US"", latest: 138), Dark.Country(country_code: ""US"", latest: 560), Dark.Country(country_code: ""US"", latest: 180), Dark.Country(country_code: ""US"", latest: 1), Dark.Country(country_code: ""US"", latest: 76), Dark.Country(country_code: ""US"", latest: 184), Dark.Country(country_code: ""US"", latest: 1265), Dark.Country(country_code: ""US"", latest: 1780), Dark.Country(country_code: ""US"", latest: 45), Dark.Country(country_code: ""US"", latest: 180), Dark.Country(country_code: ""US"", latest: 483), Dark.Country(country_code: ""US"", latest: 349), Dark.Country(country_code: ""US"", latest: 1282), Dark.Country(country_code: ""US"", latest: 712), Dark.Country(country_code: ""US"", latest: 396), Dark.Country(country_code: ""US"", latest: 494), Dark.Country(country_code: ""US"", latest: 5017), Dark.Country(country_code: ""US"", latest: 184), Dark.Country(country_code: ""US"", latest: 11), Dark.Country(country_code: ""US"", latest: 5071), Dark.Country(country_code: ""US"", latest: 90), Dark.Country(country_code: ""US"", latest: 1956), Dark.Country(country_code: ""US"", latest: 3747), Dark.Country(country_code: ""US"", latest: 1450), Dark.Country(country_code: ""US"", latest: 78), Dark.Country(country_code: ""US"", latest: 16), Dark.Country(country_code: ""US"", latest: 31), Dark.Country(country_code: ""US"", latest: 1149), Dark.Country(country_code: ""US"", latest: 10), Dark.Country(country_code: ""US"", latest: 52), Dark.Country(country_code: ""US"", latest: 15), Dark.Country(country_code: ""US"", latest: 2308), Dark.Country(country_code: ""US"", latest: 72), Dark.Country(country_code: ""US"", latest: 47), Dark.Country(country_code: ""US"", latest: 139), Dark.Country(country_code: ""US"", latest: 171), Dark.Country(country_code: ""US"", latest: 18), Dark.Country(country_code: ""US"", latest: 358), Dark.Country(country_code: ""US"", latest: 6), Dark.Country(country_code: ""US"", latest: 32), Dark.Country(country_code: ""US"", latest: 152), Dark.Country(country_code: ""US"", latest: 109069), Dark.Country(country_code: ""US"", latest: 30), Dark.Country(country_code: ""US"", latest: 4), Dark.Country(country_code: ""US"", latest: 196), Dark.Country(country_code: ""US"", latest: 107663), Dark.Country(country_code: ""US"", latest: 287), Dark.Country(country_code: ""US"", latest: 1832), Dark.Country(country_code: ""US"", latest: 77), Dark.Country(country_code: ""US"", latest: 144), Dark.Country(country_code: ""US"", latest: 33), Dark.Country(country_code: ""US"", latest: 25), Dark.Country(country_code: ""US"", latest: 7), Dark.Country(country_code: ""US"", latest: 305), Dark.Country(country_code: ""US"", latest: 817), Dark.Country(country_code: ""US"", latest: 1586), Dark.Country(country_code: ""US"", latest: 5311), Dark.Country(country_code: ""US"", latest: 2738), Dark.Country(country_code: ""US"", latest: 62589), Dark.Country(country_code: ""US"", latest: 1122), Dark.Country(country_code: ""US"", latest: 5709), Dark.Country(country_code: ""US"", latest: 9248), Dark.Country(country_code: ""US"", latest: 135586), Dark.Country(country_code: ""US"", latest: 63), Dark.Country(country_code: ""US"", latest: 3906), Dark.Country(country_code: ""US"", latest: 353), Dark.Country(country_code: ""US"", latest: 697), Dark.Country(country_code: ""US"", latest: 172), Dark.Country(country_code: ""US"", latest: 10331), Dark.Country(country_code: ""US"", latest: 743), Dark.Country(country_code: ""US"", latest: 228), Dark.Country(country_code: ""US"", latest: 548), Dark.Country(country_code: ""US"", latest: 548), Dark.Country(country_code: ""US"", latest: 14), Dark.Country(country_code: ""US"", latest: 78), Dark.Country(country_code: ""US"", latest: 880), Dark.Country(country_code: ""US"", latest: 2970), Dark.Country(country_code: ""US"", latest: 88), Dark.Country(country_code: ""US"", latest: 3963), Dark.Country(country_code: ""US"", latest: 19), Dark.Country(country_code: ""US"", latest: 293), Dark.Country(country_code: ""US"", latest: 6), Dark.Country(country_code: ""US"", latest: 268), Dark.Country(country_code: ""US"", latest: 2439), Dark.Country(country_code: ""US"", latest: 1056), Dark.Country(country_code: ""US"", latest: 79), Dark.Country(country_code: ""US"", latest: 15), Dark.Country(country_code: ""US"", latest: 241), Dark.Country(country_code: ""US"", latest: 1184), Dark.Country(country_code: ""US"", latest: 16), Dark.Country(country_code: ""US"", latest: 9), Dark.Country(country_code: ""US"", latest: 74), Dark.Country(country_code: ""US"", latest: 13), Dark.Country(country_code: ""US"", latest: 40), Dark.Country(country_code: ""US"", latest: 19580), Dark.Country(country_code: ""US"", latest: 1160), Dark.Country(country_code: ""US"", latest: 6), Dark.Country(country_code: ""US"", latest: 278), Dark.Country(country_code: ""US"", latest: 254), Dark.Country(country_code: ""US"", latest: 599), Dark.Country(country_code: ""US"", latest: 6086), Dark.Country(country_code: ""US"", latest: 371), Dark.Country(country_code: ""US"", latest: 4035), Dark.Country(country_code: ""US"", latest: 2100), Dark.Country(country_code: ""US"", latest: 2), Dark.Country(country_code: ""US"", latest: 115), Dark.Country(country_code: ""US"", latest: 2954), Dark.Country(country_code: ""US"", latest: 3764), Dark.Country(country_code: ""US"", latest: 4848), Dark.Country(country_code: ""US"", latest: 12442), Dark.Country(country_code: ""US"", latest: 2057), Dark.Country(country_code: ""US"", latest: 4417), Dark.Country(country_code: ""US"", latest: 7497), Dark.Country(country_code: ""US"", latest: 105), Dark.Country(country_code: ""US"", latest: 14), Dark.Country(country_code: ""US"", latest: 8), Dark.Country(country_code: ""US"", latest: 279), Dark.Country(country_code: ""US"", latest: 2795), Dark.Country(country_code: ""US"", latest: 237), Dark.Country(country_code: ""US"", latest: 2447), Dark.Country(country_code: ""US"", latest: 11), Dark.Country(country_code: ""US"", latest: 1481), Dark.Country(country_code: ""US"", latest: 581), Dark.Country(country_code: ""US"", latest: 1059), Dark.Country(country_code: ""US"", latest: 8), Dark.Country(country_code: ""US"", latest: 1749), Dark.Country(country_code: ""US"", latest: 141942), Dark.Country(country_code: ""US"", latest: 185), Dark.Country(country_code: ""US"", latest: 14), Dark.Country(country_code: ""US"", latest: 10), Dark.Country(country_code: ""US"", latest: 7693), Dark.Country(country_code: ""US"", latest: 22253), Dark.Country(country_code: ""US"", latest: 376), Dark.Country(country_code: ""US"", latest: 24), Dark.Country(country_code: ""US"", latest: 2258), Dark.Country(country_code: ""US"", latest: 65), Dark.Country(country_code: ""US"", latest: 107), Dark.Country(country_code: ""US"", latest: 623), Dark.Country(country_code: ""US"", latest: 34109), Dark.Country(country_code: ""US"", latest: 52), Dark.Country(country_code: ""US"", latest: 1462), Dark.Country(country_code: ""US"", latest: 2359), Dark.Country(country_code: ""US"", latest: 39), Dark.Country(country_code: ""US"", latest: 45), Dark.Country(country_code: ""US"", latest: 335), Dark.Country(country_code: ""US"", latest: 113), Dark.Country(country_code: ""US"", latest: 150), Dark.Country(country_code: ""US"", latest: 9), Dark.Country(country_code: ""US"", latest: 55242), Dark.Country(country_code: ""US"", latest: 424), Dark.Country(country_code: ""US"", latest: 396223), Dark.Country(country_code: ""US"", latest: 520), Dark.Country(country_code: ""US"", latest: 165), Dark.Country(country_code: ""US"", latest: 249), Dark.Country(country_code: ""US"", latest: 39), Dark.Country(country_code: ""US"", latest: 11), Dark.Country(country_code: ""US"", latest: 0), Dark.Country(country_code: ""US"", latest: 15), Dark.Country(country_code: ""US"", latest: 12), Dark.Country(country_code: ""US"", latest: 10), Dark.Country(country_code: ""US"", latest: 19), Dark.Country(country_code: ""US"", latest: 1), Dark.Country(country_code: ""US"", latest: 7), Dark.Country(country_code: ""US"", latest: 0), Dark.Country(country_code: ""US"", latest: 14), Dark.Country(country_code: ""US"", latest: 20), Dark.Country(country_code: ""US"", latest: 261), Dark.Country(country_code: ""US"", latest: 33), Dark.Country(country_code: ""US"", latest: 56), Dark.Country(country_code: ""US"", latest: 11), Dark.Country(country_code: ""US"", latest: 5), Dark.Country(country_code: ""US"", latest: 7), Dark.Country(country_code: ""US"", latest: 170), Dark.Country(country_code: ""US"", latest: 22), Dark.Country(country_code: ""US"", latest: 3), Dark.Country(country_code: ""US"", latest: 3), Dark.Country(country_code: ""US"", latest: 8), Dark.Country(country_code: ""US"", latest: 9), Dark.Country(country_code: ""US"", latest: 6), Dark.Country(country_code: ""US"", latest: 3), Dark.Country(country_code: ""US"", latest: 6), Dark.Country(country_code: ""US"", latest: 2), Dark.Country(country_code: ""US"", latest: 8), Dark.Country(country_code: ""US"", latest: 2), Dark.Country(country_code: ""US"", latest: 1), Dark.Country(country_code: ""US"", latest: 2), Dark.Country(country_code: ""US"", latest: 4), Dark.Country(country_code: ""US"", latest: 4)])
</code></pre>

<p>I looked back through the dataset, and what I'm getting here is the program printing <strong>every</strong> instance of <code>latest</code> and just pairing it with the <code>country_code</code> that I provided. 
Basically I need to do</p>

<pre><code>if country_code == requestLocale() {
    print(latest)
}
</code></pre>

<p>But this isn't exactly what would work, it's just a theory.
If someone could walk me through this, that would be great!</p>
"
60519642,"<p>I am trying to get data from Json url for this specific line ""ConfirmedCount"" from <a href=""https://raw.githubusercontent.com/BlankerL/DXY-COVID-19-Data/master/json/DXYOverall.json"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/BlankerL/DXY-COVID-19-Data/master/json/DXYOverall.json</a> to a UiLabel that I created but keeps getting error. I have been trying to do this for week now.</p>

<p>Here is my code:</p>

<pre class=""lang-swift prettyprint-override""><code>import UIKit

class ViewController: UIViewController {


    @IBOutlet weak var labeltest: UILabel!

    //the json file url
    let URL_HEROES = ""https://raw.githubusercontent.com/BlankerL/DXY-COVID-19-Data/master/json/DXYOverall.json"";

    //the label we create
    @IBOutlet weak var labelTest: UILabel!

    //A string array to save all the names
    var nameArray = [String]() 

    override func viewDidLoad() {
        super.viewDidLoad()

        //calling the function that will fetch the json
        getJsonFromUrl()
    }

    //this function is fetching the json from URL
    func getJsonFromUrl(){
        //creating a NSURL
        let url = NSURL(string: URL_HEROES)

        //fetching the data from the url
        URLSession.shared.dataTask(with: (url as URL?)!, completionHandler: {(data, response, error) -&gt; Void in

            if let jsonObj = try? JSONSerialization.jsonObject(with: data!, options: .allowFragments) as? NSDictionary {

                //printing the json in console
                print(jsonObj.value(forKey: ""results"")!)

                //getting the avengers tag array from json and converting it to NSArray

                if let heroeArray = jsonObj.value(forKey: ""results"") as? NSArray {
                    //looping through all the elements
                    for results in heroeArray{

                        //converting the element to a dictionary
                        if let heroeDict = results as? NSDictionary {

                            var  confirmedCount: Int

                            //getting the name from the dictionary
                            if let confirmedCount = heroeDict.value(forKey: ""confirmedCount"") {

                                //adding the name to the array
                                self.nameArray.append((String (format: ""1234"", confirmedCount as! Int)))
                            }

                        }
                    }
                }

                OperationQueue.main.addOperation({
                    //calling another function after fetching the json
                    //it will show the names to label
                    self.showNames()
                })
            }
        }).resume()
    }

    func showNames(){
        //looping through all the elements of the array
        for confirmedCount in nameArray{
            labelTest.text = (confirmedCount)
        }
    }
}
</code></pre>

<p>This is the error that I am getting:</p>

<pre><code>(
        {
        abroadRemark = """";
        confirmedCount = 80422;
        confirmedIncr = 120;
        curedCount = 49923;
        curedIncr = 2663;
        currentConfirmedCount = 27515;
        currentConfirmedIncr = ""-2581"";
        deadCount = 2984;
        deadIncr = 38;
        generalRemark = ""\U7591\U4f3c\U75c5\U4f8b\U6570\U6765\U81ea\U56fd\U5bb6\U536b\U5065\U59d4\U6570\U636e\Uff0c\U76ee\U524d\U4e3a\U5168\U56fd\U6570\U636e\Uff0c\U672a\U5206\U7701\U5e02\U81ea\U6cbb\U533a\U7b49"";
        note1 = ""\U75c5\U6bd2\Uff1aSARS-CoV-2\Uff0c\U5176\U5bfc\U81f4\U75be\U75c5\U547d\U540d COVID-19"";
        note2 = ""\U4f20\U67d3\U6e90\Uff1a\U65b0\U51a0\U80ba\U708e\U7684\U60a3\U8005\U3002\U65e0\U75c7\U72b6\U611f\U67d3\U8005\U4e5f\U53ef\U80fd\U6210\U4e3a\U4f20\U67d3\U6e90\U3002"";
        note3 = ""\U4f20\U64ad\U9014\U5f84\Uff1a\U7ecf\U547c\U5438\U9053\U98de\U6cab\U3001\U63a5\U89e6\U4f20\U64ad\U662f\U4e3b\U8981\U7684\U4f20\U64ad\U9014\U5f84\U3002\U6c14\U6eb6\U80f6\U4f20\U64ad\U548c\U6d88\U5316\U9053\U7b49\U4f20\U64ad\U9014\U5f84\U5c1a\U5f85\U660e\U786e\U3002"";
        remark1 = ""\U6613\U611f\U4eba\U7fa4\Uff1a\U4eba\U7fa4\U666e\U904d\U6613\U611f\U3002\U8001\U5e74\U4eba\U53ca\U6709\U57fa\U7840\U75be\U75c5\U8005\U611f\U67d3\U540e\U75c5\U60c5\U8f83\U91cd\Uff0c\U513f\U7ae5\U53ca\U5a74\U5e7c\U513f\U4e5f\U6709\U53d1\U75c5"";
        remark2 = ""\U6f5c\U4f0f\U671f\Uff1a\U4e00\U822c\U4e3a 3\Uff5e7 \U5929\Uff0c\U6700\U957f\U4e0d\U8d85\U8fc7 14 \U5929\Uff0c\U6f5c\U4f0f\U671f\U5185\U53ef\U80fd\U5b58\U5728\U4f20\U67d3\U6027\Uff0c\U5176\U4e2d\U65e0\U75c7\U72b6\U75c5\U4f8b\U4f20\U67d3\U6027\U975e\U5e38\U7f55\U89c1"";
        remark3 = ""\U5bbf\U4e3b\Uff1a\U91ce\U751f\U52a8\U7269\Uff0c\U53ef\U80fd\U4e3a\U4e2d\U534e\U83ca\U5934\U8760"";
        remark4 = """";
        remark5 = """";
        seriousCount = 6416;
        seriousIncr = ""-390"";
        suspectedCount = 520;
        suspectedIncr = 143;
        updateTime = 1583295001876;
    }
)
Fatal error: Unexpectedly found nil while implicitly unwrapping an Optional value: file /Users/AbdalQaydi/Desktop/jnews/jnews/ViewController.swift, line 84
2020-03-04 00:26:49.829895-0500 jnews[12702:1192396] Fatal error: Unexpectedly found nil while implicitly unwrapping an Optional value: file /Users/AbdalQaydi/Desktop/jnews/jnews/ViewController.swift, line 84
(lldb) 
</code></pre>

<p>It looks like it can parse the data but I don't know how to add the json data for line ""confirmedCount"" to label.</p>

<p>Please any help is really appreciated. I have been trying to figure out how to do this and just can't find a way.</p>
"
60818840,"<p>After I tried changing the display name of the project, whenever I run it, as it launches it crashes with this error message:</p>

<blockquote>
  <p>2020-03-23 19:32:05.010069+0200 Coronavirus Tool[10927:4335736]
  Unknown class _TtC8CoronaMT18TipsViewController in Interface Builder
  file. 2020-03-23 19:32:05.059007+0200 Coronavirus Tool[10927:4335736]
  Unknown class _TtC8CoronaMT24StatisticsViewController in Interface
  Builder file. 2020-03-23 19:32:05.061510+0200 Coronavirus
  Tool[10927:4335736] Unknown class
  _TtC8CoronaMT28RiskCalculatorViewController in Interface Builder file. 2020-03-23 19:32:05.063672+0200 Coronavirus Tool[10927:4335736]
  Unknown class _TtC8CoronaMT27NotificationsViewController in Interface
  Builder file. 2020-03-23 19:32:05.067168+0200 Coronavirus
  Tool[10927:4335736] Unknown class _TtC8CoronaMT18MoreViewController in
  Interface Builder file. 2020-03-23 19:32:05.131735+0200 Coronavirus
  Tool[10927:4335736] <strong>* Terminating app due to uncaught exception
  'NSUnknownKeyException', reason: ‘[&lt;UIViewController 0x101c0e820>
  setValue:forUndefinedKey:]: this class is not key value
  coding-compliant for the key blueButton.'
  *</strong> First throw call stack: (0x181086d8c 0x1802405ec 0x1810869f0 0x1819dc44c 0x18b1375a0 0x18b3097e4 0x180f94b24 0x18b3081f4
  0x18b139aa8 0x18ad7d074 0x18aca1b14 0x18ad4fe1c 0x18ad4f2d8
  0x18ad4ec14 0x18ad4e6a4 0x18ad423a8 0x18ac9a6f4 0x18520fe54
  0x185213fe4 0x1851806c8 0x1851a81b0 0x18b084680 0x18102f2bc
  0x18102ea7c 0x18102c7b0 0x180f4cda8 0x182f32020 0x18af6c758
  0x100bc550c 0x1809ddfc0) libc++abi.dylib: terminating with uncaught
  exception of type NSException</p>
</blockquote>

<p>I've tried adding the Bundle display name in the info.plist, and reverting the name back to the way it was, along with cleaning the project, restarting xcode, and deleting the app/reinstalling it. </p>

<p>Can someone please help me fix this???</p>
"
60869404,"<p>I am trying to make an HTTP GET request using Combine to the <a href=""https://myLink.com"" rel=""nofollow noreferrer"">https://myLink.com</a> URL (this is a fake URL, the one that I use is a real API link and it works, but I can't post it), but when I call the function I get the following error:</p>

<p>Task &lt;18F5A03A-96DF-4309-B263-B6B0CB275779>.&lt;1> finished with error [-999] Error Domain=NSURLErrorDomain Code=-999 ""cancelled"" UserInfo={NSErrorFailingURLStringKey=<a href=""https://myLink.com"" rel=""nofollow noreferrer"">https://myLink.com</a>, NSLocalizedDescription=cancelled, NSErrorFailingURLKey=<a href=""https://myLink.com"" rel=""nofollow noreferrer"">https://myLink.com</a>}</p>

<p>Here is my code:</p>

<pre><code>import SwiftUI
import Foundation
import Combine

struct ContentView: View {
   var body: some View {
      Button(action: {
         loadPatients()
      })
      {
         Text(""Load Patients"")
      }
   }
}

//MARK: - Your object to retrieve from JSON
struct Doctor: Codable, Identifiable {
  let id = UUID()
  let patients: [Patients]
}

struct Patients: Codable {
  let id: String
  let name: String
  let phone: String
}

class Network {

  // Handle your request errors
  enum Error: LocalizedError {
    case invalidResponse
    case addressUnreachable(URL)

    var errorDescription: String? {
      switch self {
      case .invalidResponse:
        return ""The server responded with garbage.""
      case .addressUnreachable(let url):
        return ""\(url.absoluteString) is unreachable.""
      }
    }
  }

  // Add your url
  let urlRequest = URL(string: ""https://coronavirus-med.herokuapp.com/api/v1/doctor/getPatients/bogdand"")!

  // Networking on concurrent queue
  let networkQueue = DispatchQueue(label: ""Networking"",
                                   qos: .default,
                                   attributes: .concurrent)

  // Combine network call (This replace your previous code)
  func downloadPatients() -&gt; AnyPublisher&lt;Doctor, Error&gt; {
    URLSession.shared
      .dataTaskPublisher(for: urlRequest)
      .receive(on: networkQueue)
      .map(\.data)
      .decode(type: Doctor.self, decoder: JSONDecoder())
      .mapError { (error) -&gt; Network.Error in
        switch error {
        case is URLError:
          return Error.addressUnreachable(self.urlRequest)
        default:
          return Error.invalidResponse
        }
    }
    .eraseToAnyPublisher()
  }
}

let networkRequest = Network()

//MARK: - Call this function where you want to make your call
func loadPatients() {
  _ = networkRequest.downloadPatients()
    .sink(
      receiveCompletion: {
        print(""Received Completion: \($0)"") },
      receiveValue: { doctor in
        // doctor is your response and [0].name is your first patient name
        print(doctor.patients[0].name) }
  )
}
</code></pre>

<p>I found another question on StackOverflow addressing this error, but the answer just says what the error means, but not how to solve it. They said that it means that a request is made before another one is finished, but I don't make any requests before this one, I even tried to run this in a new empty project but it still gives me the same error.</p>

<p>I was on iOS 13.2 and Xcode 11.2 and I updated to iOS 13.4 and Xcode 11.4, still the same error.</p>

<p>This is the JSON response:</p>

<pre><code>{
    ""code"": 200,
    ""status"": ""success"",
    ""patients"": [
        {
            ""_id"": ""5e77c7bbc7cbd30024f3eadb"",
            ""name"": ""Bogdan Patient"",
            ""username"": ""bogdanp"",
            ""phone"": ""0732958473""
        },
        {
            ""_id"": ""5e77c982a2736a0024e895fa"",
            ""name"": ""Robert Patient"",
            ""username"": ""robertp"",
            ""phone"": ""0739284756""
        }
    ]
}
</code></pre>
"
61234975,"<p>So, I have the following View Model where I fetch the data: </p>

<pre><code>import Foundation
import SwiftUI
import Combine
import Alamofire


class AllStatsViewModel: ObservableObject {
    @Published var isLoading: Bool = true
    @Published var stats = [CountryStats]()

    func fetchGlobalStats() {
        let request = AF.request(""https://projectcovid.deadpool.wtf/all"")
       request.responseDecodable(of: AllCountryStats.self) { (response) in
         guard let globalStats = response.value else { return }
        DispatchQueue.main.async {
            self.stats = globalStats.data
        }

        self.isLoading = false
       }
    }
}
</code></pre>

<p>And this is the view:</p>

<pre><code>struct CardView: View {
    @ObservedObject var allStatsVM = AllStatsViewModel()

    var body: some View {
        VStack {
            Text(self.allStatsVM.stats[0].country)

        }


        .onAppear {
            self.allStatsVM.fetchGlobalStats()
        }
    }

}
</code></pre>

<p>I'd like to access only the first element of the data, but the problem I face is that when the view loads, the data is not loaded, so I get an index out of range error at</p>

<pre><code>Text(self.allStatsVM.stats[0].country)
</code></pre>

<p>Is there a way, I can access the first element?</p>
"
61149906,"<p>So here is the query</p>

<pre><code>SELECT TOP 10 * FROM
(SELECT
    Country_Region AS CR,
    WeekOfYear,

    (SELECT SumConfWeekly FROM
    (
        SELECT Country_Region, SUM(ConfirmedWeekly) AS SumConfWeekly
        FROM covid_19_aggr
        GROUP BY CUBE (Country_Region)
    ) AS C
    WHERE C.Country_Region=T1.CR) AS SC2,
    ConfirmedWeekly
FROM 
    covid_19_aggr
)
AS T1
PIVOT(
    SUM(ConfirmedWeekly)
    FOR WeekOfYear IN ([4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14])
) AS PT1
ORDER BY SC2 DESC;
</code></pre>

<p>The problem is in the where clause, where I want to match Country_Region from the subquery to the outside query. How to go about this?
Any help would be appreciated.</p>
"
60868699,"<p>I found this code <a href=""https://github.com/Flowminder/COVID-19/blob/master/indicators_1_2.sql"" rel=""nofollow noreferrer"">here</a>... besides syntax problems (a missing comma, using functions as fields, at least...), it gives me an error in Google BigQuery with the ""date"" in the <code>WHERE</code> clause. Not sure if this is an error in BQ or just not possible to ""guess"" date yet... </p>

<pre><code>CREATE TABLE count_unique_subscribers_per_region_per_day AS (
    SELECT date(calls.datetime) AS date,
        cells.region AS region
        COUNT(DISTINCT msisdn) AS count
    FROM calls
    INNER JOIN cells
        ON calls.location_id = cells.cell_id
    WHERE date &gt;= '2020-02-01'
          AND date &lt;= CURRENT_DATE
    GROUP BY 1, 2

);
</code></pre>

<p>How do you reference <code>date</code> in the <code>WHERE</code> clause?</p>
"
61426973,"<p>I am using this code to convert a html-text string into an attributedString.</p>

<pre><code>if let description = article.description {
    let data = Data(description.utf8)
    if let attributedString = try? NSMutableAttributedString(data: data, options: [.documentType: NSAttributedString.DocumentType.html], documentAttributes: nil) {
        attributedString.addAttributes([NSAttributedString.Key.font: UIFont.systemFont(ofSize: 18), NSAttributedString.Key.foregroundColor: UIColor.subtitleColor], range: NSRange(location: 0, length: attributedString.length))
        articleView.contentTextView.attributedText = attributedString
     }
}
</code></pre>

<p>and a weird symbols coming out <a href=""https://i.stack.imgur.com/KOhtC.png"" rel=""nofollow noreferrer"">like here</a>.
How to remove them?</p>

<p>description is a</p>

<pre><code>&lt;p&gt;Greece prepares to end lockdown; Bill Gates vows to fund vaccine production; Australia and New Zealand mark Anzac Day from driveways&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=""https://www.theguardian.com/world/2020/apr/24/revealed-leader-group-peddling-bleach-cure-lobbied-trump-coronavirus""&gt;Leader of group peddling bleach as‘cure’ wrote to Trump this week&lt;/a&gt;&lt;br&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=""https://www.theguardian.com/world/2020/apr/24/sweden-queries-basis-of-lockdowns-as-germany-keeps-its-guard-up""&gt;Global report: Sweden queries lockdowns as Germany keeps guard up&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=""https://www.theguardian.com/world/2020/apr/25/coronavirus-latest-at-a-glance-25-april""&gt;Coronavirus latest: at a glance&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=""https://www.theguardian.com/world/live/2020/apr/24/coronavirus-us-live-news-trump-cuomo-georgia-cases-latest""&gt;US coronavirus updates– live&lt;/a&gt;&lt;br&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=""https://www.theguardian.com/world/coronavirus-outbreak""&gt;See all our coronavirus coverage&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p class=""block-time published-time""&gt;&lt;time datetime=""2020-04-25T14:09:45.760Z""&gt;3.09pm&lt;span class=""timezone""&gt;BST&lt;/span&gt;&lt;/time&gt;&lt;/p&gt;&lt;p&gt;Today is World Malaria Day. As we approach 200,000 deaths so far this year from Covid-19, it’s worth remembering that the World Health Organization has warned that&lt;a href=""https://www.theguardian.com/global-development/2020/apr/23/pandemic-could-turn-back-the-clock-20-years-on-malaria-deaths-warns-who""&gt;deaths from malaria could double to 700,000 this year&lt;/a&gt;as a result of the disruption caused by the new disease.&lt;/p&gt;&lt;p lang=""en"" dir=""ltr""&gt;As we work on tackling&lt;a href=""https://twitter.com/hashtag/COVID19?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#COVID19&lt;/a&gt;, we can't afford to lose ground on the gains we have made against other diseases like malaria.&lt;br&gt;&lt;br&gt;On&lt;a href=""https://twitter.com/hashtag/WorldMalariaDay?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#WorldMalariaDay&lt;/a&gt;I join&lt;a href=""https://twitter.com/WHO?ref_src=twsrc%5Etfw""&gt;@WHO&lt;/a&gt;'s call for maintained malaria prevention&amp;amp; treatment services during the&lt;a href=""https://twitter.com/hashtag/coronavirus?src=hash&amp;amp;ref_src=twsrc%5Etfw""&gt;#coronavirus&lt;/a&gt;crisis to save lives.&lt;a href=""https://twitter.com/vtm3X6twva""&gt;pic.twitter.com/vtm3X6twva&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Related:&lt;/span&gt;&lt;a href=""https://www.theguardian.com/global-development/2020/apr/23/pandemic-could-turn-back-the-clock-20-years-on-malaria-deaths-warns-who""&gt;Pandemic could 'turn back the clock' 20 years on malaria deaths, warns WHO&lt;/a&gt;&lt;/p&gt;&lt;p class=""block-time published-time""&gt;&lt;time datetime=""2020-04-25T13:53:37.287Z""&gt;2.53pm&lt;span class=""timezone""&gt;BST&lt;/span&gt;&lt;/time&gt;&lt;/p&gt;&lt;p&gt;Dozens of doctors and nurses in&lt;strong&gt;Pakistan&lt;/strong&gt;have launched a hunger strike over a lack of protective masks and other equipment for treating patients with Covid-19.&lt;/p&gt;&lt;p&gt;More than 150 doctors in Pakistan have tested positive for coronavirus, according to the Young Doctors Association in Punjab, the country’s worst-hit province.&lt;br tabindex=""-1""&gt;&lt;/p&gt;&lt;a href=""https://www.theguardian.com/world/live/2020/apr/25/coronavirus-live-news-brazils-health-system-on-verge-of-collapse-medics-warn""&gt;Continue reading...&lt;/a&gt;
</code></pre>
"
60702543,"<p>I'm trying to decode some JSON data from a URL and display it in a list. I've tried different ways but no one works(some times it returns me unknown error or simply not displaying data)
This should be the struct to represent the JSON format</p>

<pre><code>import SwiftUI

struct Country : Decodable {
    var thailand : [Case]
}

struct Case : Decodable  {
    var date : String
    var confirmed : Int
    var deaths : Int
    var recovered : Int
}
</code></pre>

<p>A little part of the JSON(but it's all the same):</p>

<pre><code>
{
  ""Thailand"": [
    {
      ""date"": ""2020-1-22"",
      ""confirmed"": 2,
      ""deaths"": 0,
      ""recovered"": 0
    },
    {
      ""date"": ""2020-1-23"",
      ""confirmed"": 3,
      ""deaths"": 0,
      ""recovered"": 0
    },
    {
      ""date"": ""2020-1-24"",
      ""confirmed"": 5,
      ""deaths"": 0,
      ""recovered"": 0
    },
    {
      ""date"": ""2020-1-25"",
      ""confirmed"": 7,
      ""deaths"": 0,
      ""recovered"": 0
    },
    {
      ""date"": ""2020-1-26"",
      ""confirmed"": 8,
      ""deaths"": 0,
      ""recovered"": 2
    },
    {
      ""date"": ""2020-1-27"",
      ""confirmed"": 8,
      ""deaths"": 0,
      ""recovered"": 2
    },
    {
      ""date"": ""2020-1-28"",
      ""confirmed"": 14,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-1-29"",
      ""confirmed"": 14,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-1-30"",
      ""confirmed"": 14,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-1-31"",
      ""confirmed"": 19,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-2-1"",
      ""confirmed"": 19,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-2-2"",
      ""confirmed"": 19,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-2-3"",
      ""confirmed"": 19,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-2-4"",
      ""confirmed"": 25,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-2-5"",
      ""confirmed"": 25,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-2-6"",
      ""confirmed"": 25,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-2-7"",
      ""confirmed"": 25,
      ""deaths"": 0,
      ""recovered"": 5
    },
    {
      ""date"": ""2020-2-8"",
      ""confirmed"": 32,
      ""deaths"": 0,
      ""recovered"": 10
    },
    {
      ""date"": ""2020-2-9"",
      ""confirmed"": 32,
      ""deaths"": 0,
      ""recovered"": 10
    },
    {
      ""date"": ""2020-2-10"",
      ""confirmed"": 32,
      ""deaths"": 0,
      ""recovered"": 10
    },
    {
      ""date"": ""2020-2-11"",
      ""confirmed"": 33,
      ""deaths"": 0,
      ""recovered"": 10
    },
    {
      ""date"": ""2020-2-12"",
      ""confirmed"": 33,
      ""deaths"": 0,
      ""recovered"": 10
    },
    {
      ""date"": ""2020-2-13"",
      ""confirmed"": 33,
      ""deaths"": 0,
      ""recovered"": 12
    },
    {
      ""date"": ""2020-2-14"",
      ""confirmed"": 33,
      ""deaths"": 0,
      ""recovered"": 12
    },
    {
      ""date"": ""2020-2-15"",
      ""confirmed"": 33,
      ""deaths"": 0,
      ""recovered"": 12
    },
    {
      ""date"": ""2020-2-16"",
      ""confirmed"": 34,
      ""deaths"": 0,
      ""recovered"": 14
    },
    {
      ""date"": ""2020-2-17"",
      ""confirmed"": 35,
      ""deaths"": 0,
      ""recovered"": 15
    },
    {
      ""date"": ""2020-2-18"",
      ""confirmed"": 35,
      ""deaths"": 0,
      ""recovered"": 15
    },
    {
      ""date"": ""2020-2-19"",
      ""confirmed"": 35,
      ""deaths"": 0,
      ""recovered"": 15
    },
    {
      ""date"": ""2020-2-20"",
      ""confirmed"": 35,
      ""deaths"": 0,
      ""recovered"": 15
    },
    {
      ""date"": ""2020-2-21"",
      ""confirmed"": 35,
      ""deaths"": 0,
      ""recovered"": 17
    },
    {
      ""date"": ""2020-2-22"",
      ""confirmed"": 35,
      ""deaths"": 0,
      ""recovered"": 17
    },
    {
      ""date"": ""2020-2-23"",
      ""confirmed"": 35,
      ""deaths"": 0,
      ""recovered"": 21
    },
    {
      ""date"": ""2020-2-24"",
      ""confirmed"": 35,
      ""deaths"": 0,
      ""recovered"": 21
    },
    {
      ""date"": ""2020-2-25"",
      ""confirmed"": 37,
      ""deaths"": 0,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-26"",
      ""confirmed"": 40,
      ""deaths"": 0,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-27"",
      ""confirmed"": 40,
      ""deaths"": 0,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-28"",
      ""confirmed"": 41,
      ""deaths"": 0,
      ""recovered"": 28
    },
    {
      ""date"": ""2020-2-29"",
      ""confirmed"": 42,
      ""deaths"": 0,
      ""recovered"": 28
    },
    {
      ""date"": ""2020-3-1"",
      ""confirmed"": 42,
      ""deaths"": 1,
      ""recovered"": 28
    },
    {
      ""date"": ""2020-3-2"",
      ""confirmed"": 43,
      ""deaths"": 1,
      ""recovered"": 31
    },
    {
      ""date"": ""2020-3-3"",
      ""confirmed"": 43,
      ""deaths"": 1,
      ""recovered"": 31
    },
    {
      ""date"": ""2020-3-4"",
      ""confirmed"": 43,
      ""deaths"": 1,
      ""recovered"": 31
    },
    {
      ""date"": ""2020-3-5"",
      ""confirmed"": 47,
      ""deaths"": 1,
      ""recovered"": 31
    },
    {
      ""date"": ""2020-3-6"",
      ""confirmed"": 48,
      ""deaths"": 1,
      ""recovered"": 31
    },
    {
      ""date"": ""2020-3-7"",
      ""confirmed"": 50,
      ""deaths"": 1,
      ""recovered"": 31
    },
    {
      ""date"": ""2020-3-8"",
      ""confirmed"": 50,
      ""deaths"": 1,
      ""recovered"": 31
    },
    {
      ""date"": ""2020-3-9"",
      ""confirmed"": 50,
      ""deaths"": 1,
      ""recovered"": 31
    },
    {
      ""date"": ""2020-3-10"",
      ""confirmed"": 53,
      ""deaths"": 1,
      ""recovered"": 33
    },
    {
      ""date"": ""2020-3-11"",
      ""confirmed"": 59,
      ""deaths"": 1,
      ""recovered"": 34
    },
    {
      ""date"": ""2020-3-12"",
      ""confirmed"": 70,
      ""deaths"": 1,
      ""recovered"": 34
    },
    {
      ""date"": ""2020-3-13"",
      ""confirmed"": 75,
      ""deaths"": 1,
      ""recovered"": 35
    },
    {
      ""date"": ""2020-3-14"",
      ""confirmed"": 82,
      ""deaths"": 1,
      ""recovered"": 35
    },
    {
      ""date"": ""2020-3-15"",
      ""confirmed"": 114,
      ""deaths"": 1,
      ""recovered"": 35
    }
  ],
  ""Japan"": [
    {
      ""date"": ""2020-1-22"",
      ""confirmed"": 2,
      ""deaths"": 0,
      ""recovered"": 0
    },
    {
      ""date"": ""2020-1-23"",
      ""confirmed"": 1,
      ""deaths"": 0,
      ""recovered"": 0
    },
    {
      ""date"": ""2020-1-24"",
      ""confirmed"": 2,
      ""deaths"": 0,
      ""recovered"": 0
    },
    {
      ""date"": ""2020-1-25"",
      ""confirmed"": 2,
      ""deaths"": 0,
      ""recovered"": 0
    },
    {
      ""date"": ""2020-1-26"",
      ""confirmed"": 4,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-1-27"",
      ""confirmed"": 4,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-1-28"",
      ""confirmed"": 7,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-1-29"",
      ""confirmed"": 7,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-1-30"",
      ""confirmed"": 11,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-1-31"",
      ""confirmed"": 15,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-2-1"",
      ""confirmed"": 20,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-2-2"",
      ""confirmed"": 20,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-2-3"",
      ""confirmed"": 20,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-2-4"",
      ""confirmed"": 22,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-2-5"",
      ""confirmed"": 22,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-2-6"",
      ""confirmed"": 45,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-2-7"",
      ""confirmed"": 25,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-2-8"",
      ""confirmed"": 25,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-2-9"",
      ""confirmed"": 26,
      ""deaths"": 0,
      ""recovered"": 1
    },
    {
      ""date"": ""2020-2-10"",
      ""confirmed"": 26,
      ""deaths"": 0,
      ""recovered"": 4
    },
    {
      ""date"": ""2020-2-11"",
      ""confirmed"": 26,
      ""deaths"": 0,
      ""recovered"": 9
    },
    {
      ""date"": ""2020-2-12"",
      ""confirmed"": 28,
      ""deaths"": 0,
      ""recovered"": 9
    },
    {
      ""date"": ""2020-2-13"",
      ""confirmed"": 28,
      ""deaths"": 1,
      ""recovered"": 9
    },
    {
      ""date"": ""2020-2-14"",
      ""confirmed"": 29,
      ""deaths"": 1,
      ""recovered"": 9
    },
    {
      ""date"": ""2020-2-15"",
      ""confirmed"": 43,
      ""deaths"": 1,
      ""recovered"": 12
    },
    {
      ""date"": ""2020-2-16"",
      ""confirmed"": 59,
      ""deaths"": 1,
      ""recovered"": 12
    },
    {
      ""date"": ""2020-2-17"",
      ""confirmed"": 66,
      ""deaths"": 1,
      ""recovered"": 12
    },
    {
      ""date"": ""2020-2-18"",
      ""confirmed"": 74,
      ""deaths"": 1,
      ""recovered"": 13
    },
    {
      ""date"": ""2020-2-19"",
      ""confirmed"": 84,
      ""deaths"": 1,
      ""recovered"": 18
    },
    {
      ""date"": ""2020-2-20"",
      ""confirmed"": 94,
      ""deaths"": 1,
      ""recovered"": 18
    },
    {
      ""date"": ""2020-2-21"",
      ""confirmed"": 105,
      ""deaths"": 1,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-22"",
      ""confirmed"": 122,
      ""deaths"": 1,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-23"",
      ""confirmed"": 147,
      ""deaths"": 1,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-24"",
      ""confirmed"": 159,
      ""deaths"": 1,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-25"",
      ""confirmed"": 170,
      ""deaths"": 1,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-26"",
      ""confirmed"": 189,
      ""deaths"": 2,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-27"",
      ""confirmed"": 214,
      ""deaths"": 4,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-28"",
      ""confirmed"": 228,
      ""deaths"": 4,
      ""recovered"": 22
    },
    {
      ""date"": ""2020-2-29"",
      ""confirmed"": 241,
      ""deaths"": 5,
      ""recovered"": 32
    },
    {
      ""date"": ""2020-3-1"",
      ""confirmed"": 256,
      ""deaths"": 6,
      ""recovered"": 32
    },
    {
      ""date"": ""2020-3-2"",
      ""confirmed"": 274,
      ""deaths"": 6,
      ""recovered"": 32
    },
    {
      ""date"": ""2020-3-3"",
      ""confirmed"": 293,
      ""deaths"": 6,
      ""recovered"": 43
    },
    {
      ""date"": ""2020-3-4"",
      ""confirmed"": 331,
      ""deaths"": 6,
      ""recovered"": 43
    },
    {
      ""date"": ""2020-3-5"",
      ""confirmed"": 360,
      ""deaths"": 6,
      ""recovered"": 43
    },
    {
      ""date"": ""2020-3-6"",
      ""confirmed"": 420,
      ""deaths"": 6,
      ""recovered"": 46
    },
    {
      ""date"": ""2020-3-7"",
      ""confirmed"": 461,
      ""deaths"": 6,
      ""recovered"": 76
    },
    {
      ""date"": ""2020-3-8"",
      ""confirmed"": 502,
      ""deaths"": 6,
      ""recovered"": 76
    },
    {
      ""date"": ""2020-3-9"",
      ""confirmed"": 511,
      ""deaths"": 10,
      ""recovered"": 76
    },
    {
      ""date"": ""2020-3-10"",
      ""confirmed"": 581,
      ""deaths"": 10,
      ""recovered"": 101
    },
    {
      ""date"": ""2020-3-11"",
      ""confirmed"": 639,
      ""deaths"": 15,
      ""recovered"": 118
    },
    {
      ""date"": ""2020-3-12"",
      ""confirmed"": 639,
      ""deaths"": 16,
      ""recovered"": 118
    },
    {
      ""date"": ""2020-3-13"",
      ""confirmed"": 701,
      ""deaths"": 19,
      ""recovered"": 118
    },
    {
      ""date"": ""2020-3-14"",
      ""confirmed"": 773,
      ""deaths"": 22,
      ""recovered"": 118
    },
    {
      ""date"": ""2020-3-15"",
      ""confirmed"": 839,
      ""deaths"": 22,
      ""recovered"": 118
    }
  ]}
</code></pre>

<p>Here I try to decode the JSON and insert it in a dynamic list</p>

<pre><code>
import SwiftUI

struct ContentView: View {

    @State private var cases = [Case]()

    var body: some View {
        List(cases , id: \.date) { i in
            VStack{
                Text(i.date)
                Text(""\(i.deaths)"")
                Text(""\(i.confirmed)"")
                Text(""\(i.recovered)"")

            }.onAppear(perform: self.loadData)

    }

}
    func loadData() {
        guard let url = URL(string: ""https://pomber.github.io/covid19/timeseries.json"") else {
            print(""Invalid URL"")
            return
        }
        let request = URLRequest(url: url)
        URLSession.shared.dataTask(with: request) { data, response, error in

            if let data = data {
                if let decodedResponse = try? JSONDecoder().decode(Country.self, from: data) {

                    DispatchQueue.main.async {
                        print(decodedResponse)
                        self.cases = decodedResponse.thailand
                    }
                    return
                }
            }

            // if we're still here it means there was a problem
            print(""Fetch failed: \(error?.localizedDescription ?? ""Unknown error"")"")

        }.resume()

    }
}

struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
    }
}

</code></pre>
"
60777698,"<p>Ian building an app which uses son data for web service I used QuickType website to convert the son data to struct but now I don't know how to access the members of that structure after decoding the son data
This is my entire view controller file I need to decode and print the coordinate values so that I can access it in a map kit </p>

<pre><code>import UIKit
import MapKit
import Foundation
struct Welcome: Codable {
    let locations: [Location]
}

// MARK: - Location
struct Location: Codable {
    let coordinates: Coordinates
    let country, countryCode: String
    let id: Int
    let latest: Latest
    let province: String

    enum CodingKeys: String, CodingKey {
        case coordinates, country
        case countryCode = ""country_code""
        case id, latest, province
    }
}

// MARK: - Coordinates
struct Coordinates: Codable {
    let latitude, longitude: String
}

// MARK: - Latest
struct Latest: Codable {
    let confirmed, deaths, recovered: Int
}
class ViewController: UIViewController {

    @IBAction func btn(_ sender: UIButton) {

        loaddata()
    }
    @IBOutlet weak var mapview: MKMapView!
    override func viewDidLoad() {
        super.viewDidLoad()




    }

    func loaddata()
    {

         let url = URL(string: ""https://coronavirus-tracker-api.herokuapp.com/v2/locations"")

        var session = URLSession.shared

        var data = session.dataTask(with: url!) { (data, response, error) in
            let decoder = JSONDecoder()
            do
            {
                  var info =  try decoder.decode(Welcome.self, from: data!)

                print(info.locations[0].coordinates.latitude)            }

            catch
            {
                print(""\(error)"")
            }

        }
    }


}
</code></pre>
"
61236662,"<p>So, this is my View Model</p>

<pre><code>import Foundation
import SwiftUI
import Combine
import Alamofire


class AllStatsViewModel: ObservableObject {
    @Published var isLoading: Bool = true
    @Published var stats = [CountryStats]()

    func fetchGlobalStats() {
        let request = AF.request(""https://projectcovid.deadpool.wtf/all"")
       request.responseDecodable(of: AllCountryStats.self) { (response) in
         guard let globalStats = response.value else { return }
        DispatchQueue.main.async {
            self.stats = globalStats.data
        }

        self.isLoading = false
       }
    }
}
</code></pre>

<p>And this is my view where I subscribe to change: </p>

<pre><code>struct CardView: View {
    @ObservedObject var allStatsVM = AllStatsViewModel()

    var body: some View {
        VStack {
            if self.allStatsVM.stats.count &gt; 0 {
                Text(self.allStatsVM.stats[0].country)
            } else {
                Text(""data loading"")
            }   

        }


        .onAppear {
            self.allStatsVM.fetchGlobalStats()
        }
    }

}
</code></pre>

<p>So, when I open the app for the first time, I get the data and then when I go home and reopen the app, all I can see is data loading.</p>

<p>Is there a way to persist data? I know @State helps but, I'm a beginner in SwiftUI and not sure how it works</p>
"
60984981,"<p>I'm a beginner and currently work on this self-practicing project. I'm trying to get data from JSON and filter data by country (below I'm filtering for Italy data only). Then I want to save this filtered array to <em>dataArray</em> and show it on Table View but it doesn't work. Please let me know what I'm missing. Thanks!</p>

<pre><code>import Foundation
import UIKit
import CoreLocation
import SwiftyJSON

class ViewController: UIViewController, UITableViewDelegate, UITableViewDataSource {


    @IBOutlet weak var label1: UILabel!

    struct Spot : Decodable {
        let Province: String
        let Country : String
        let Last_Update : String
        let Confirmed : String
        let Deaths : String
        let Recovered : String
        let Latitude : String?
        let Longitude : String?

        enum CodingKeys: String, CodingKey {
            case Province = ""Province/State""
            case Country = ""Country/Region""
            case Last_Update = ""Last Update""
            case Confirmed
            case Deaths
            case Recovered
            case Latitude
            case Longitude
        }
    }

    @IBOutlet weak var TableView: UITableView!

    //Constants

    let covid_URL = ""https://raw.githubusercontent.com/zmsp/coronavirus-json-api/master/latest.json""
    var dataArray : [[String : Any]] = []
    let cellReuseIdentifier = ""cell""

    override func viewDidLoad() {
        super.viewDidLoad()

        self.TableView.register(UITableViewCell.self, forCellReuseIdentifier: cellReuseIdentifier)
        TableView.delegate = self
        TableView.dataSource = self

        getData()

        TableView.reloadData()
    }

    @IBAction func getButtonPressed(_ sender: UIButton) {



    }


    //MARK: - Networking

    //getData method:
    func getData () {

        let url = URL(string: covid_URL)!

        let task = URLSession.shared.dataTask(with: url) {(data, response, error) in
            guard let data = data else { return }
            let decoder = JSONDecoder()

            do {
                let rates = try decoder.decode([Spot].self, from: data)
                let rate = rates.filter { $0.Country == ""Italy""}
                let dataArray = rate

                self.TableView.reloadData()
            }

            catch {
                print(""Error after loading"",error)
            }
        }.resume()

    }

    func numberOfSections(in tableView: UITableView) -&gt; NSInteger {
        return 1
    }

    func tableView(_ tableView: UITableView, numberOfRowsInSection section: NSInteger) -&gt; NSInteger {
        return dataArray.count
    }

    func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -&gt; UITableViewCell {

        var dict = dataArray[indexPath.row] as! [String : String]
        let cell : UITableViewCell = tableView.dequeueReusableCell(withIdentifier: ""cell"")!
        let confirmed = dict[""Confirmed""]
        cell.textLabel!.text = confirmed

        return cell
    }
}

</code></pre>
"
61359155,"<p>New to Swift and coding in general. Trying to put an array of JSON objects into a tableView. Having trouble converting my Ints to Strings in the tableView delegate method's detailTextView.text. Getting an error ""Initializer 'init(_:)' requires that 'Int?' conform to 'LosslessStringConvertible.'"" Try to use that, but it's a rabbit hole of errors from there. Been browsing SO most of the day but no luck.</p>

<pre><code>class AllCountriesVC: UITableViewController {


    struct CovidData: Codable {
        let country: String
        let cases: Int?
        let todayCases: Int?
        let deaths: Int?
        let todayDeaths: Int?
        let recovered: Int?
        let active: Int?
        let critical: Int?
        let totalTests: Int?
    }


    var data = [CovidData]()

    override func viewWillAppear(_ animated: Bool) {
        load()
        self.tableView.reloadData()
    }


    override func viewDidLoad() {
        super.viewDidLoad() 
    }

    func load() {
        if let url = URL(string: ""https://coronavirus-19-api.herokuapp.com/countries/"") {
        let jsonData = try! Data(contentsOf: url)
            self.data = try! JSONDecoder().decode([CovidData].self, from: jsonData)

            self.tableView.reloadData()
        }
    }

    override func tableView(_ tableView: UITableView, numberOfRowsInSection section: Int) -&gt; Int {
        return data.count ?? 1       
    }
    override func tableView(_ tableView: UITableView, cellForRowAt indexPath: IndexPath) -&gt; UITableViewCell {
        let cell = tableView.dequeueReusableCell(withIdentifier: ""Cell"", for: indexPath)
        let countryData = data[indexPath.row]
        cell.textLabel?.text = countryData.country
        cell.detailTextLabel?.text = String(countryData.cases)
        //this is where it fails with error ""Initializer 'init(_:)' requires that 'Int?' conform to 'LosslessStringConvertible'""

        return cell
    } 
}
</code></pre>
"
60836111,"<p>I wonder if someone could help me out with the best way to handle a type that should be numeric but occasionally shows as string. </p>

<p><a href=""https://i.stack.imgur.com/lkMkQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/lkMkQ.png"" alt=""enter image description here""></a></p>

<p>This has only just started happening, the struct that I am using is below, I can't fix this on the server, but obviously the inconsistant data is crashing JSONDecoder</p>

<pre><code>struct CountryInfo: Codable {
    var iso2: String
    var iso3: String
    var _id: Int
    var lat: Double
    var long: Double
    var flag: String
}
</code></pre>

<p>Any help would be much appreciated.</p>

<p><strong>EDIT: sample.json ADDED</strong></p>

<p>Notice in China _id = 156 but in Iran _id = ""NO DATA""</p>

<p>[{""country"":""China"",""countryInfo"":{""iso2"":""CN"",""iso3"":""CHN"",""_id"":156,""lat"":35,""long"":105,""flag"":""<a href=""https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/cn.png"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/cn.png</a>""},""cases"":81171,""todayCases"":78,""deaths"":3277,""todayDeaths"":7,""recovered"":73159,""active"":4735,""critical"":1573,""casesPerOneMillion"":56,""deathsPerOneMillion"":2},{""country"":""Italy"",""countryInfo"":{""iso2"":""IT"",""iso3"":""ITA"",""_id"":380,""lat"":42.8333,""long"":12.8333,""flag"":""<a href=""https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/it.png"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/it.png</a>""},""cases"":69176,""todayCases"":5249,""deaths"":6820,""todayDeaths"":743,""recovered"":8326,""active"":54030,""critical"":3393,""casesPerOneMillion"":1144,""deathsPerOneMillion"":113},{""country"":""USA"",""countryInfo"":{""iso2"":""NO DATA"",""iso3"":""NO DATA"",""_id"":""NO DATA"",""lat"":0,""long"":0,""flag"":""<a href=""https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/unknow.png"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/unknow.png</a>""},""cases"":49976,""todayCases"":6242,""deaths"":634,""todayDeaths"":81,""recovered"":368,""active"":48974,""critical"":1175,""casesPerOneMillion"":151,""deathsPerOneMillion"":2},{""country"":""Spain"",""countryInfo"":{""iso2"":""ES"",""iso3"":""ESP"",""_id"":724,""lat"":40,""long"":-4,""flag"":""<a href=""https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/es.png"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/es.png</a>""},""cases"":39676,""todayCases"":4540,""deaths"":2800,""todayDeaths"":489,""recovered"":3794,""active"":33082,""critical"":2355,""casesPerOneMillion"":849,""deathsPerOneMillion"":60},{""country"":""Germany"",""countryInfo"":{""iso2"":""DE"",""iso3"":""DEU"",""_id"":276,""lat"":51,""long"":9,""flag"":""<a href=""https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/de.png"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/de.png</a>""},""cases"":32781,""todayCases"":3725,""deaths"":156,""todayDeaths"":33,""recovered"":3133,""active"":29492,""critical"":23,""casesPerOneMillion"":391,""deathsPerOneMillion"":2},{""country"":""Iran"",""countryInfo"":{""iso2"":""NO DATA"",""iso3"":""NO DATA"",""_id"":""NO DATA"",""lat"":0,""long"":0,""flag"":""<a href=""https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/unknow.png"" rel=""nofollow noreferrer"">https://raw.githubusercontent.com/NovelCOVID/API/master/assets/flags/unknow.png</a>""},""cases"":24811,""todayCases"":1762,""deaths"":1934,""todayDeaths"":122,""recovered"":8913,""active"":13964,""critical"":0,""casesPerOneMillion"":295,""deathsPerOneMillion"":23}]</p>
"
61119710,"<pre><code> Try correcting the name to the name of an existing getter, or defining a getter or field named 'LogicalKeyboardKey'.
    if (key == LogicalKeyboardKey.keyC) {
               ^^^^^^^^^^^^^^^^^^
../../Documents/flutter/packages/flutter/lib/src/rendering/editable.dart:654:16: Error: The getter 'LogicalKeyboardKey' isn't defined for the class 'RenderEditable'.
 - 'RenderEditable' is from 'package:flutter/src/rendering/editable.dart' ('../../Documents/flutter/packages/flutter/lib/src/rendering/editable.dart').
Try correcting the name to the name of an existing getter, or defining a getter or field named 'LogicalKeyboardKey'.
    if (key == LogicalKeyboardKey.keyX) {
               ^^^^^^^^^^^^^^^^^^
../../Documents/flutter/packages/flutter/lib/src/rendering/editable.dart:665:16: Error: The getter 'LogicalKeyboardKey' isn't defined for the class 'RenderEditable'.
 - 'RenderEditable' is from 'package:flutter/src/rendering/editable.dart' ('../../Documents/flutter/packages/flutter/lib/src/rendering/editable.dart').
Try correcting the name to the name of an existing getter, or defining a getter or field named 'LogicalKeyboardKey'.
    if (key == LogicalKeyboardKey.keyV) {
               ^^^^^^^^^^^^^^^^^^
../../Documents/flutter/packages/flutter/lib/src/rendering/editable.dart:682:16: Error: The getter 'LogicalKeyboardKey' isn't defined for the class 'RenderEditable'.
 - 'RenderEditable' is from 'package:flutter/src/rendering/editable.dart' ('../../Documents/flutter/packages/flutter/lib/src/rendering/editable.dart').
Try correcting the name to the name of an existing getter, or defining a getter or field named 'LogicalKeyboardKey'.
    if (key == LogicalKeyboardKey.keyA) {
               ^^^^^^^^^^^^^^^^^^
Target kernel_snapshot failed: Exception: Errors during snapshot creation: null
Failed to build bundle.
Failed to package /Users/mac/Desktop/covid_19_malaysia.
Command PhaseScriptExecution failed with a nonzero exit code
note: Using new build system
note: Building targets in parallel
note: Planning build
note: Constructing build description
</code></pre>

<p>Could not build the precompiled application for the device.</p>

<p>Error launching application on Jehovah’s iPhone.</p>
"
61623635,"<p>I wish I could tell you what the error is on the console, but my React app seems to be freezing up all functionality on the Safari browser.  </p>

<p>The MAC JavaScript console doesn't work.  Actually, none of the 'Develop' commands works in my attempt to debug this issue (but only when I'm on my site).  </p>

<p>Here's my deployed site.  <a href=""https://global-covid-19-tracker.herokuapp.com"" rel=""nofollow noreferrer"">https://global-covid-19-tracker.herokuapp.com</a></p>

<p>You've probably heard this many times...""It works fine on Chrome and IE"", but gets choked up on Safari and iOS devices.  </p>

<p>That seems to be my issue here, but at a grander scale since I can't even open up the JavaScript console to debug the issue.</p>

<p>It's not a Mac issue.  The app works fine on my Mac Internet Explorer browser.  </p>

<p>I've googled this issue for hours and the only results I'm getting are instructions on how to open the Developer console.  I already know how to do that.  </p>

<p>My Problem is:  My React app has disabled my Developer Console. </p>

<p>Any assistance would be GREATLY appreciated.  Please and Thank You!  </p>
"
61671313,"<p>I was wondering how I would make only sections of a text bold while keep the rest 'regular' in SwiftUI. </p>

<p>I currently have:</p>

<pre><code>Text(""Coronavirus Disease of 2019"")
</code></pre>

<p>and I want it to print out <strong>CO</strong>rona<strong>Vi</strong>rus <strong>D</strong>isease of 20<strong>19</strong> and haven't been able to get only some parts bold. </p>
"
60779918,"<p>I'm writing an app to track symptoms - started it before the world fell apart, so not COVID-19 related.</p>

<p>I have the following data structure...</p>

<p><strong>Symptom</strong>
- name: String
- instances: [Instance]</p>

<p><strong>Instance</strong>
- dateTime: Date
- note: String
- severity: Int
- triggers: [Trigger]</p>

<p><strong>Trigger</strong>
- name: String</p>

<p>Trigger is just a list of items that you think may have triggered the instance of your symptom.</p>

<p>I'd like to display some meaningful statistics for each symptom, but I'm having a hard time determining exactly what I relevant to display and how to display it.
I'm not looking for the Swift/Objective-C code to accomplish this, I already have that under control.</p>

<p>It's just that I want to display a good set of data that would help a person notice patterns or see how often things are happening - I'm just having problems trying to figure out the best way to organize my data.</p>

<p>I appreciate your help!</p>
"
60409805,"<p>I would like to sort some results in ascending way.</p>

<p>First I have a spreadsheet with values (in A1:B10). </p>

<p>I enter the formula in D2 :</p>

<pre><code>=FILTRE(Tableau1[#Tout];Tableau1[[#Tout];[Coronavirus]] = ""yes"";"""")
</code></pre>

<p>To have the result of what I want (cities who have coronavirus)</p>

<p>Then I have numbers linked to this cities and I want to sort them by ascending.</p>

<p><a href=""https://i.stack.imgur.com/P8yHj.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/P8yHj.png"" alt=""enter image description here""></a></p>

<p>The problem is that I can't sort them by filter or formula, because the range D2:E9 will not change because it's a formula inside.</p>
"
60792675,"<p>I'm creating a resources spreadsheet in Google Sheets for my community to post their haves/needs in response to the coronavirus. I'd like to automatically assign a person who has an item to a person who needs that item, but only if that person hasn't already been assigned to others.</p>

<p>In other words, if person A and person B both have one roll of toilet paper each, and person C needs 1, person D needs 1, and person E needs 1, I would like person C to be matched with A, D with B, and person E to show ""IN NEED"" (of someone to donate). Example:</p>

<p><a href=""https://i.stack.imgur.com/FvE4Q.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/FvE4Q.png"" alt=""example A""></a></p>

<p>Or, as another example, say that person A has 3 rolls of TP and person B has 1. Person C asks for 2 and person D asks for 1, so both C and D should both be assigned person A but the next person who asks should be assigned to person B.</p>

<p>Obviously those numbers work out nicely, but it would get complicated if say person A and B each had 1 roll1 of TP and person C asked for 2 (then would need to show both people as assigned to person C).</p>

<p>This is my formula as of now (very basic): <code>=if(ISTEXT(I4),IFERROR(index($C$4:$E$1000,match(I4,$D$4:$D$1000,0),1),""IN NEED""),"""")</code></p>

<p>Thank you for any help you can offer!!</p>

<p><a href=""https://docs.google.com/spreadsheets/d/1dsDN_Fm-wk5VdbxpzLgbA8MIBb6OVRzj5V-h200bN_0/edit?usp=sharing"" rel=""nofollow noreferrer"">Link to sheet for more detailed example</a></p>
"
61461507,"<p>I am building a react-native project to track Covid19 cases, it is simple and minimal, which is my first project and I only intend to get data that I want to view. </p>

<p>I have been building it in Windows and I have even generated .apk file which works pretty fine and I have let some of my friends tested it.</p>

<p>Unfortunately, I use iOS and I want to use it for myself. I do own a mac, so I pushed the original file to the github and cloned it in my mac. I have run npm install and pod install, but it just isn't working fine. I have tried two things.</p>

<p>I have tried to run it in the traditional way, running it in the iOS emulator with npx react-native run-ios. </p>

<p>And I have also tried to deploy it into my iPhone by following an article from medium. But it seems like I am doing something not possible. Is it possible to use the same code base and structure for both ios and android? Or what did I miss when I cloned it from the github? I do know many files are being .gitignore'ed.</p>
"
61017999,"<p>I am trying to track the average doubling time of deaths from COVID19, how long will it be at this rate of growth before we have twice as many deaths as the day before?  On a daily basis I:</p>

<ol>
<li>Look at the number of deaths that day.</li>
<li>Calculate the increase as a % of the previous day's deaths.</li>
<li>Divide 70 by (number in 2 * 100).  This is the Rule of 70 (The rule of 70 is an easy method of estimating how quickly a variable will double if you know its annual growth rate. If a variable is growing at a rate of x% per period, you simply take 70 and divide it by x.)</li>
<li>Average that number.</li>
</ol>

<p>The problem is that the doubling time you get for the beginning of the crisis are in the 1 and 2 digit range but the ones today are in the 4  digit range.  Doing a simple average gives too much weight to the small numbers, I think.</p>

<p>Is there a simple method using Excel to give the ""proper"" weight to the larger numbers or does it make enough difference to worry about?</p>

<p>Thanks for any help.</p>
"
61337417,"<p>I was trying to plot some reports for Covid-19 cases around the Globe, using Excel and Power BI. With Power BI is easier and fancier to do definitely, but I need an Excel file or calculation that makes sense - similar to the PBI. What I actually wanted is to calculate the daily increase in new cases (with %) and also death rate but per day, or total death by day and so on.. </p>

<p>I did some calculations (% of column total and I calculated one field to get death rate%)  here using Pivot tables but not sure how to do daily increase/decrease? Did anyone get an idea for additional calculations?
This is copied from PBI (calculations) which I wanna have similar in Excel - but I am not sure If I can calculate it properly (last 2 pictures).</p>

<p>The data source from the input data is here: </p>

<p><a href=""https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide.xlsx"" rel=""nofollow noreferrer"">https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide.xlsx</a></p>

<p><a href=""https://i.stack.imgur.com/W6S3v.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/W6S3v.jpg"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/C9Ebx.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/C9Ebx.jpg"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/CUEIA.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/CUEIA.jpg"" alt=""enter image description here""></a></p>

<p><a href=""https://i.stack.imgur.com/AxsQH.jpg"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/AxsQH.jpg"" alt=""enter image description here""></a></p>
"
61454233,"<p>I was playing a bit with the data of nowadays topic: <strong>Covid-19</strong> and I downloaded some data to do some Analytics from: </p>

<p><a href=""https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide.xlsx"" rel=""nofollow noreferrer"">https://www.ecdc.europa.eu/sites/default/files/documents/COVID-19-geographic-disbtribution-worldwide.xlsx</a></p>

<p>And this is what I managed to do using Power Query and Pivot tables:</p>

<p><a href=""https://i.stack.imgur.com/jtwiD.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jtwiD.gif"" alt=""enter image description here""></a></p>

<p>From this data here - it is just a small piece of huge dataset:</p>

<p><a href=""https://i.stack.imgur.com/jt6H8.gif"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/jt6H8.gif"" alt=""enter image description here""></a></p>

<p>Pivot tables are great and you can do a lot of things as you can see, BUT, what I wanted to do is do <strong>calculations (sum per Continent with excel formulas</strong> for the Total Population per Continent. There in the data set is lot of countries with certain Population and I am not managing the right way using <code>=max/if/sumif</code>. I just wanna know this way for myself! </p>

<p>I am sure that ain't that hard but I am now bit out of logic =) </p>

<p>I hope you got the point!!</p>

<p><strong>First Edit:</strong></p>

<p><strong>=sumif</strong> doesn't work at the first place, because you have repetitive Population per one Country per day...it is summing the same land with its population per day - not what I need but only 1x the general sum of population. </p>
"
61073751,"<p>we have a hudge database of people who will receive financial help on the COVID-19 situation. I'm trying to create a VBA code that allows me to fill the Google Form that will be used to collect the data: <a href=""https://docs.google.com/forms/d/e/1FAIpQLSfmOe5my6a0OwGj5jOY1hFNreZCjDGLuK7qllEr18tlGxys-w/viewform"" rel=""nofollow noreferrer"">https://docs.google.com/forms/d/e/1FAIpQLSfmOe5my6a0OwGj5jOY1hFNreZCjDGLuK7qllEr18tlGxys-w/viewform</a>. </p>

<p>The problem is, there's a dropdown option in this form, and for some reason I can't select any of the options in the list. Here's what I've tried so far:</p>

<pre><code>Dim IE As Object
Set IE = CreateObject(""InternetExplorer.Application"")

    IE.navigate ""https://docs.google.com/forms/d/e/1FAIpQLSfmOe5my6a0OwGj5jOY1hFNreZCjDGLuK7qllEr18tlGxys-w/viewform""
    IE.Visible = True

    IE.document.all(""entry.2084723474"").InnerText = ""Teste Nome""
    IE.document.all(""entry.1921177593"").InnerText = ""37121851890""

Set HTML = IE.document
Set elements = HTML.getElementsByclassName(""quantumWizMenuPaperselectOptionList"")

For Each element In elements
    If element.className = ""quantumWizMenuPaperselectOptionList"" Then
        element.Click
    End If
Next element

Dim e
For Each e In IE.document.getElementsByTagName(""span"")
    If e.InnerText = ""Paraisópolis (SP)"" Then

        ' Found the &lt;span&gt;.
        e.parentelement.Click

        Exit For

    End If
Next
</code></pre>

<p>In this part I found the option on the list, but when I send the command to Click in it's parent element, nothig happens:</p>

<pre><code>Dim e
For Each e In IE.document.getElementsByTagName(""span"")
    If e.InnerText = ""Paraisópolis (SP)"" Then

        ' Found the &lt;span&gt;.
        e.parentelement.Click

        Exit For

    End If
Next
</code></pre>

<p>That's it, any help will be very usefull to me in this moment. And I'm sorry for my terrible english.</p>
"
60802868,"<p>I would like to push Excel to its limit by trying to make a car game.
The tricky part is when I try to move the car (so take account the key pressed by the user) during the game (when the macro is executed).</p>

<p>I have a screen that has to be refreshed faster and faster as the game goes (it simulates the road and the difficulty increased as time flies). Basically, it's just <code>Application.Wait (Now + delta_T)</code> inside a loop that decides what the road will be.</p>

<p>I rebinded key -> and &lt;- with <code>Application.OnKey ""{LEFT}"", procedure:=""GoLeft""</code> (same for right)</p>

<p>However when these keys are pushed during the execution of a main macro, ""the procedures"" are executed after the main macro... That's pretty inconvenient :/</p>

<p>Disclaimer : I'm aware that a lots of languages are more suitable for this. It's just my way of dealing with Covid19 ...</p>

<p>Thanks :)</p>
"
60634264,"<p>I have downloaded the coronovirus covid-19 time series dataset and need to convert the column headings in the .csv file to UK date format. I then want to set the column headings as a date axis on a graph to plot infection rates.</p>

<p>The dataset starts with 1/22/20, 1/23/20, then later changes to 02/01/2020, 02/02/2020, then changes to 2/13/20, 2/14/20 and then 03/01/2020, 03/02/2020. These are all M/D/Y.</p>

<p>I have written an Excel VBA macro which checks if the M value is 1 or 2 digits and adds a zero if 1 for consistency. As the text to column conversion still didn't work as expected, I then added to amend the year from 20 to 2020 to provide a consistent input dataset.</p>

<p>The code I am using is:</p>

<pre><code>Sub usDateToUkDate()

    Dim r As Range
    Dim cells As Integer
    Dim cell As Range

    Set r = Range(""E1"", Range(""E1"").End(xlToRight))
    For Each cell In r
        cell.Select
        If Left(ActiveCell.Value, 1) &lt;&gt; 0 Then
            cell.Value = ""0"" &amp; cell.Value
        End If
        If Len(ActiveCell.Value) &lt;&gt; 10 Then
            cell.Value = Replace(cell.Value, ""20"", ""2020"", 7)
        End If

        Selection.TextToColumns Destination:=ActiveCell(), DataType:=xlDelimited, _
            TextQualifier:=xlDoubleQuote, ConsecutiveDelimiter:=False, Tab:=False, _
            Semicolon:=False, Comma:=True, Space:=False, Other:=False, OtherChar _
            :=""/"", FieldInfo:=Array(0, 3), TrailingMinusNumbers:=True
        ActiveCell.EntireColumn.AutoFit
    Next cell
End Sub
</code></pre>

<p>While I don't fully understand the TextToColumns syntax as I copied a recorded macro, why am I getting inconsistent results. I did change the FieldInfo:=Array(1,3) to Array(0,3) as I wanted to start at the first character. The results I get are:
<a href=""https://i.stack.imgur.com/tDSkt.png"" rel=""nofollow noreferrer"">Summary output</a></p>

<p>Dataset:  1/22/20
Output:   22 Jan 2020
Result:   Correct</p>

<p>Dataset:  02/01/2020
Output:   02 Jan 2020
Result:   Incorrect</p>

<p>The results repeat based on input format.</p>

<p>What am I doing wrong? Is there a better way to convert dates from US to UK format?</p>
"
61702377,"<p>I have a problem with VBA throwing an error in my project, which parses a website with COVID-19 statistics(""<a href=""https://www.worldometers.info/coronavirus/"" rel=""nofollow noreferrer"">https://www.worldometers.info/coronavirus/</a>"" - good site btw, you can find daily stats a month back). </p>

<p>In ""A2:H2"" I have headers, like ""Country"". In ""A3:H &amp; function that calculates last row in column A"" is the data for each country. In ""I4:P4""  I have headers from ""A2:H2""</p>

<p>The below event passes <strong>t's</strong> address to  string <strong>x_1</strong> with prefix ""x_"", so that a specific Sub can be called based
on which cell was selected, i.e. Sub x_J3 and ignores non-key cells with On Error Resume Next</p>

<pre><code>Private Sub Worksheet_SelectionChange(ByVal t As Range)

Dim x_1 As String
x_1 = ""x_"" &amp; t.Address(0, 0)
On Error Resume Next
Application.Run x_1

End Sub
</code></pre>

<p>The idea is that, having a full list of countries from the website, one can make a custom ""view"" of selected countries under ""I4:P4"" headers. Once a country is selected, the below code, in standard module,  ""remembers"" the cell row and column and then if the ""Add"" cell is selected the country is added to the ""view"".</p>

<pre><code>Public pr, cr, pc, cc As Long

Sub cur_prev()

On Error Resume Next
pr = cr  
pc = cc

cr = ActiveCell.Row
cc = ActiveCell.Column

End Sub

</code></pre>

<p>Each Sub calls the above Sub every time a key-cell is hit.</p>

<p>When all the code is in Sheet1 (event code + rest), everything is ok, when in separate standard modules, the below code throws ""Error 1004"" with arrow pointing at the second line, pr and pc both equal 0.</p>

<pre><code>If ActiveCell.Address(0, 0) = ""J3"" _
And Not Intersect(Cells(pr, pc), Range(```""a3:h"" &amp; lastt(8)```)) Is Nothing Then
</code></pre>

<p>Also, other version of the project, broken into subs,  correctly adds countries, but deleting them throws the error, the offending code is:</p>

<pre><code>If ActiveCell.Address(0, 0) = ""K3"" _
And Not Intersect(Cells(pr, pc), Range(""i5:p"" &amp; lastt(9))) Is Nothing Then
</code></pre>

<p>as you can see, both examples only differ with their searched ranges and somehow the first is ok. Could you advise on what I am missing here, cheers in advance.</p>
"
61710868,"<p>I am trying to write a script which will cycle through the worksheets in my workbook and delete the worksheet if the cells directly under the strings ""detected"", ""not detected"" and ""other"" are empty. If there is something entered under any of the three strings the worksheet shouldn't be deleted.</p>

<p>I have some code (below) which will delete the worksheet if a specific cell is empty, but I need to integrate a piece to FIND any of the three strings (if they are there, they will be in column A), and to offset this to check whether the cell below is empty.</p>

<pre><code>Sub DeleteEmptyWorksheets()

Dim MySheets As Worksheet

Application.DisplayAlerts = False

For Each MySheets In ActiveWorkbook.Worksheets
     If MySheets.Range(“A1”) = “” Then
     MySheets.Delete

End If

Next

Application.DisplayAlerts = True

End Sub
</code></pre>

<p>The script will be used in processing COVID19 test results, so if you can help it will be extra karma points!! </p>

<p>Thankyou.</p>
"
61015023,"<p>I am trying to load csv file and download it to my hard disk from a link of GitHub. Here's my try</p>

<pre><code>#If Win64 Then
Private Declare PtrSafe Function URLDownloadToFile Lib ""urlmon"" Alias ""URLDownloadToFileA"" (ByVal pCaller As LongLong, ByVal szURL As String, ByVal szFileName As String, ByVal dwReserved As LongLong, ByVal lpfnCB As LongLong) As LongLong
#Else
Private Declare Function URLDownloadToFile Lib ""urlmon"" Alias ""URLDownloadToFileA"" (ByVal pCaller As Long, ByVal szURL As String, ByVal szFileName As String, ByVal dwReserved As Long, ByVal lpfnCB As Long) As Long
#End If

Function DownloadFile(Url As String, SavePathName As String) As Boolean
DownloadFile = URLDownloadToFile(0, Replace(Url, ""\"", ""/""), SavePathName, 0, 0) = 0
End Function

Sub Demo()
Dim strUrl As String, strSavePath As String, strFile As String

strUrl = ""https://github.com/pcm-dpc/COVID-19/blob/master/dati-regioni/dpc-covid19-ita-regioni-20200224.csv""    'SharePoint Path For The File
strSavePath = ThisWorkbook.Path &amp; ""\""
strFile = ""FileName"" &amp; Format(Date, ""dd.mm.yyyy"") &amp; "".csv""

If DownloadFile(strUrl, strSavePath &amp; strFile) Then
    MsgBox ""File Saved To: "" &amp; vbNewLine &amp; strSavePath
Else
    MsgBox ""Unable To Download File:"" &amp; vbNewLine &amp; strFile &amp; vbNewLine &amp; ""Check URL String And That Document Is Shared"", vbCritical
End If
End Sub
</code></pre>

<p>I used the code before to download some files and it worked well but as for this link the downloaded file is as HTML page not csv file. How can I download it as CSV file?</p>
"
61324904,"<p>I am trying to create a custom function in VBA in Excel. It is my first time. </p>

<p>I want to determine the benefit that a typical person would get (if our government expanded social assistance in response to the covid-19 lockdown), based on data from nine different deciles of the earnings distribution. I have called the function which finds the grant at each decile <code>onerow</code>, and the function that averages those <code>UIFavg</code>. </p>

<p>In my Excel file, the deciles are listed in a column, so I only want to use the cell at the top as the argument. That would require me to find the row of the <code>firstrow</code> argument, then add 1 to the row number for the other nine points. Unfortunately, I don't know how to stipulate the row numbers that the function should use for the various deciles in this way. I didn't know how to search <a href=""https://docs.microsoft.com/en-us/dotnet/visual-basic/"" rel=""nofollow noreferrer"">the documentation</a> for this.</p>

<p>I show my attempt below. Do you know how to break lines?</p>

<pre><code>Public Function onerow(decile As Double, propzero As Double, propupper As Double, upperbound As Double, natminwage As Double)
    If decile &lt; upperbound Then
        If decile &lt; natminwage Then
            onerow = (propzero - (propzero - propupper) / upperbound * decile) * natminwage       'UIF benefit at the minimum wage
        ElseIf decile &gt;= natminwage Then
            onerow = (propzero - (propzero - propupper) / upperbound * decile) * decile
        End If
    Else
        onerow = propupper * upperbound   'Maximum benefit (for those who earn above the upper limit)
    End If
End Function

Public Function UIFavg(firstrow As Double, secondrow As Double, thirdrow As Double, fourthrow As Double, fifthrow As Double, sixthrow As Double, seventhrow As Double, eighthrow As Double, ninthrow As Double, propzero As Double, propupper As Double, upperbound As Double, natminwage As Double)
UIFavg = (1.5 * onerow(firstrow, propzero, propupper, upperbound, natminwage) + onerow(secondrow, propzero, propupper, upperbound, natminwage) + onerow(thirdrow, propzero, propupper, upperbound, natminwage) + onerow(fourthrow, propzero, propupper, upperbound, natminwage) + onerow(fifthrow, propzero, propupper, upperbound, natminwage) + onerow(sixthrow, propzero, propupper, upperbound, natminwage) + onerow(seventhrow, propzero, propupper, upperbound, natminwage) + onerow(eighthrow, propzero, propupper, upperbound, natminwage) + 1.5 * onerow(ninthrow, propzero, propupper, upperbound, natminwage)) / 10
End Function
</code></pre>
"
60196894,"<p>I'm trying to extract some content and put it in tabular format on Excel. One column would be countries, the second column would be the measures they're implementing against the coronavirus. Here is what the HTML looks like:</p>

<pre><code>&lt;strong&gt;AUSTRALIA&lt;/strong&gt; - published 11.02.2020&lt;br /&gt;
1. Passengers who have transited through or have been in China (People's Rep.) on or after 1 February 2020, will not be allowed to transit or enter Australia.&lt;br /&gt;
- This does not apply to nationals of Australia. They will be required to self-isolate for a period of 14 days from their arrival into Australia.&lt;br /&gt;
- This does not apply to permanent residents of Australia and their immediate family members. They will be required to self-isolate for a period of 14 days from their arrival into Australia.&lt;br /&gt;
- This does not apply to airline crew.&lt;br /&gt;
2. Nationals of Australia who have transited through or have been in China (People's Rep.) on or after 1 February 2020 will be required to self-isolate for a period of 14 days from their arrival into Australia.&lt;br /&gt;
3. Permanent residents of Australia and their immediate family members who have transited through or have been in China (People's Rep.) on or after the 1 February 2020 will be required to self-isolate for a period of 14 days from their arrival into Australia.&lt;br /&gt;
&lt;br /&gt;
&lt;strong&gt;AZERBAIJAN&lt;/strong&gt; - published 06.02.2020
</code></pre>

<p>So there is no real structure to speak of. However I'd like to be able to extract the list of countries as one column (that's easy since they're between <em>strong</em> tags). But I would like the other column to be the corresponding text for each country. That's harder since there is nothing to isolate this. The only thing that I can think of is to ask VBA to loop between two sets of <em>strong</em> tags and extract this content as the second column. I'm not sure how to do this though. The code I've found so far allows me to extract the list of countries and not much else:</p>

<pre><code>Sub Test()

Dim IE As New SHDocVw.InternetExplorer
Dim HTMLDoc As MSHTML.HTMLDocument
Dim HTMLAs As MSHTML.IHTMLElementCollection
Dim HTMLA As MSHTML.IHTMLElement

IE.Visible = True
IE.navigate ""https://www.iatatravelcentre.com/international-travel-document-news/1580226297.htm""

Do While IE.ReadyState &lt;&gt; READYSTATE_COMPLETE
Loop

Set HTMLDoc = IE.Document

ProcessHTMLPage HTMLDoc

    Set HTMLAs = HTMLDoc.getElementsByTagName(""strong"")

    For Each HTMLA In HTMLAs

    Debug.Print HTMLA.innerText
    If HTMLA.getAttribute(""href"") = ""http://x-rates.com/table/"" And HTMLA.getAttribute(""rel"") = ""ratestable"" Then
        HTMLA.Click
'I don't understand why, but the previous line of code is essential to making this work. Otherwise I only get the first country
        Exit For
        End If

Next HTMLA

End Sub
</code></pre>
"